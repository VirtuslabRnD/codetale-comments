[
  {
    "id" : "16476884-f4d9-4543-b5d5-275d990d7d62",
    "prId" : 4485,
    "prUrl" : "https://github.com/apache/kafka/pull/4485#pullrequestreview-164240341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "155253bd-e9c2-4f09-88a6-8e5f5e852679",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "remove unnecessary newline",
        "createdAt" : "2018-10-12T13:31:57Z",
        "updatedAt" : "2018-10-13T16:40:58Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "85cae7d6538b8cd8c4ecd485bec14485ae10a1c4",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +498,502 @@\n    private static TransactionManager configureTransactionState(ProducerConfig config, LogContext logContext, Logger log) {\n\n        TransactionManager transactionManager = null;\n"
  },
  {
    "id" : "eb750a4c-8535-4c47-bc91-fd1dcf364a5e",
    "prId" : 4485,
    "prUrl" : "https://github.com/apache/kafka/pull/4485#pullrequestreview-164240341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ff0418c-b494-4001-beaf-8843b00e35da",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "remove unnecessary newline",
        "createdAt" : "2018-10-12T13:32:07Z",
        "updatedAt" : "2018-10-13T16:40:58Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "85cae7d6538b8cd8c4ecd485bec14485ae10a1c4",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +500,504 @@\n        TransactionManager transactionManager = null;\n\n        boolean userConfiguredIdempotence = false;\n        if (config.originals().containsKey(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG))"
  },
  {
    "id" : "5b0d29ba-70ac-478f-920b-5d83dee9213e",
    "prId" : 4563,
    "prUrl" : "https://github.com/apache/kafka/pull/4563#pullrequestreview-104772957",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bd4e5f55-477d-40f0-b77e-b8d9da23ff38",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can you add a comment to the javadoc mentioning that this method may be retried if a `TimeoutException` or an `InterruptException` is raised?",
        "createdAt" : "2018-03-20T15:42:29Z",
        "updatedAt" : "2018-03-27T15:59:59Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "754249e243260d32faea0ca9d27ff043563988c2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +568,572 @@     *         transactional.id is not authorized. See the exception for more details\n     * @throws KafkaException if the producer has encountered a previous fatal error or for any other unexpected error\n     * @throws TimeoutException if the time taken for initialize the transaction has surpassed <code>max.block.ms</code>.\n     * @throws InterruptException if the thread is interrupted while blocked\n     */"
  },
  {
    "id" : "5fb7126b-41a6-4925-b60a-3c41039de3ad",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-137190980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63f679c1-ce51-4bcb-b558-b628729217ae",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Why changing linger to int ?",
        "createdAt" : "2018-07-12T04:14:37Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "a230cf55-a4b1-4ebb-b55e-b6a6f5236463",
        "parentId" : "63f679c1-ce51-4bcb-b558-b628729217ae",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "we have `request.timeout.ms` and `delivery.timeout.ms` of `int` type. this is to make the type of `linger.ms` be consistent with other timeout related settings. ",
        "createdAt" : "2018-07-13T21:09:45Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +400,404 @@                    config.getInt(ProducerConfig.BATCH_SIZE_CONFIG),\n                    this.compressionType,\n                    config.getInt(ProducerConfig.LINGER_MS_CONFIG),\n                    retryBackoffMs,\n                    deliveryTimeoutMs,"
  },
  {
    "id" : "9a050ab2-169c-4995-a748-369a1fa62f8a",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-138475262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d134dcf8-a211-4f14-a31f-e60a17f1e8de",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Should this be of type long ?\r\nWith long, there is no overflow on line 478\r\n\r\nIn ProducerBatch, deliveryTimeoutMs is long in hasReachedDeliveryTimeout",
        "createdAt" : "2018-07-12T04:15:18Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "b724e85e-9b90-4e9a-8d81-137f326ffa1e",
        "parentId" : "d134dcf8-a211-4f14-a31f-e60a17f1e8de",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "`ProducerBatch.hasReachedDeliveryTimeout` is called by RecordAccumulator. In RecordAccumulator's construct, we have had using `long` type for `lingerMs`, and `retryBackoffMs`. It will be inconsistent to use `int` for `deliveryTimeoutMs`. And it will require changes at many places (especially in the test cases) if we use `int` type for `lingerMs` and `retryBackoffMs`.  I thought that it would be better to have another PR for data type related changes for `lingerMs` etc.\r\n\r\n        public RecordAccumulator(LogContext logContext,\r\n                                 int batchSize,\r\n                                 CompressionType compression,\r\n                                 long lingerMs,\r\n                                 long retryBackoffMs,\r\n                                 ...\r\n",
        "createdAt" : "2018-07-18T23:16:51Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +465,469 @@\n    private static int configureDeliveryTimeout(ProducerConfig config, Logger log) {\n        int deliveryTimeoutMs = config.getInt(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG);\n        int lingerMs = config.getInt(ProducerConfig.LINGER_MS_CONFIG);\n        int requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);"
  },
  {
    "id" : "44e46224-f481-46c4-8021-e8c06ec5090b",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-137192562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d193231f-2783-402c-9587-08aaaa4706b5",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Doesn't need to be warn.\r\nCan be info since there is no action from user",
        "createdAt" : "2018-07-12T04:17:42Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "ea8d7a93-7dec-4bca-8e2e-34575062afef",
        "parentId" : "d193231f-2783-402c-9587-08aaaa4706b5",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "This is try to get the user's attention as we are overriding the default  delivery.timeout.ms setting.  Previously the user may set a long `request.timeout.ms` as a work around. The user may want to explicitly set `delivery.timeout.ms` and give a smaller value for `request.timeout.ms`. ",
        "createdAt" : "2018-07-13T21:15:57Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +478,482 @@                // override deliveryTimeoutMs default value to lingerMs + requestTimeoutMs for backward compatibility\n                deliveryTimeoutMs = lingerMs + requestTimeoutMs;\n                log.warn(\"{} should be equal to or larger than {} + {}. Setting it to {}.\",\n                    ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, ProducerConfig.LINGER_MS_CONFIG,\n                    ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, deliveryTimeoutMs);"
  },
  {
    "id" : "80dc6a40-89fa-4585-8d52-f6491cadbc8e",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-191921116",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5e89e6a-3180-4212-9b8c-72540a634d0b",
        "parentId" : null,
        "authorId" : "6f96e7ef-7198-42b1-9445-532b9b5a1aab",
        "body" : "(deliveryTimeoutMs < lingerMs + requestTimeoutMs) implies (deliveryTimeoutMs < Integer.MAX_VALUE), why do we need to check (deliveryTimeoutMs < Integer.MAX_VALUE), logically it can be removed.",
        "createdAt" : "2019-01-12T01:46:44Z",
        "updatedAt" : "2019-01-12T01:46:44Z",
        "lastEditedBy" : "6f96e7ef-7198-42b1-9445-532b9b5a1aab",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +469,473 @@        int requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);\n\n        if (deliveryTimeoutMs < Integer.MAX_VALUE && deliveryTimeoutMs < lingerMs + requestTimeoutMs) {\n            if (config.originals().containsKey(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG)) {\n                // throw an exception if the user explicitly set an inconsistent value"
  },
  {
    "id" : "455bccde-dbd3-4788-97dd-d0c13d32ace5",
    "prId" : 5383,
    "prUrl" : "https://github.com/apache/kafka/pull/5383#pullrequestreview-151046149",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c88f8042-e54e-4983-9442-627500ab6188",
        "parentId" : null,
        "authorId" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "body" : "nit: please add protected keyword",
        "createdAt" : "2018-08-23T23:09:26Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "tags" : [
        ]
      },
      {
        "id" : "d3cb548f-0d44-4cd5-99ab-a2591e340cc6",
        "parentId" : "c88f8042-e54e-4983-9442-627500ab6188",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "`protected` gives more visibility than what's there now (`package visibility`) so not sure why we'd want to do that?",
        "createdAt" : "2018-08-30T15:15:15Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee59e6985e64c8109b71f4501d83dd5ed4d38158",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1205,1209 @@\n    // Visible for testing\n    String getClientId() {\n        return clientId;\n    }"
  },
  {
    "id" : "0c8d6e2a-80b6-48a1-bcd7-e44839c87f30",
    "prId" : 5667,
    "prUrl" : "https://github.com/apache/kafka/pull/5667#pullrequestreview-178676687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a962d2a9-dd70-4b3c-8d57-b5ee9a064d1c",
        "parentId" : null,
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "Do we need to add a negative timeout check like we did in [consumer](https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java#L2101)?",
        "createdAt" : "2018-11-27T08:51:22Z",
        "updatedAt" : "2019-01-15T06:10:36Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      },
      {
        "id" : "0e184e2f-1016-4330-b0a9-ae1fe6f24ab5",
        "parentId" : "a962d2a9-dd70-4b3c-8d57-b5ee9a064d1c",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "add the check and related test (see KafkaProducerTest.testNegativeTimeout)",
        "createdAt" : "2018-11-27T09:23:05Z",
        "updatedAt" : "2019-01-15T06:10:36Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4c9f2e4cac38bb7094099c44170c9ce595571b0",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1134,1138 @@\n    private void close(Duration timeout, boolean swallowException) {\n        long timeoutMs = timeout.toMillis();\n        if (timeoutMs < 0)\n            throw new IllegalArgumentException(\"The timeout cannot be negative.\");"
  },
  {
    "id" : "709627bc-51e0-4291-8670-89f3e873998c",
    "prId" : 6066,
    "prUrl" : "https://github.com/apache/kafka/pull/6066#pullrequestreview-188383163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "daec6865-bbc9-4b93-b4f1-020c9475bc22",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I think we should add some documentation here to make it clear what the user should be expected to do if either of these exceptions are raised. There are really only two options: 1) retry the operation, and 2) close the producer. ",
        "createdAt" : "2018-12-27T19:22:03Z",
        "updatedAt" : "2019-02-20T01:55:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b7108b3a-ff00-4e28-8adf-da093f09e6c9",
        "parentId" : "daec6865-bbc9-4b93-b4f1-020c9475bc22",
        "authorId" : "2b8ddac3-3f74-403c-9e9d-62dc37cb6655",
        "body" : "Once a transaction is in committing or aborting state, can user still retry it? Seems the only valid state from COMMITTING_TRANSACTION is to ABORTABLE_ERROR. Do we need to reset the state to IN_TRANSACTION after committing or aborting failed or cache the transaction result to retry later?",
        "createdAt" : "2018-12-28T00:35:03Z",
        "updatedAt" : "2019-02-20T01:55:39Z",
        "lastEditedBy" : "2b8ddac3-3f74-403c-9e9d-62dc37cb6655",
        "tags" : [
        ]
      },
      {
        "id" : "094b8a5e-766b-42a0-8b51-ed16a3d2b813",
        "parentId" : "daec6865-bbc9-4b93-b4f1-020c9475bc22",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It should be possible to retry the operation that was already begun. So if a call to `commitTransaction` timed out, the user ought to be able to retry it, in which case we would just continue waiting on the commit that was already begun. However, it should not be possible to do an `abortTransaction` instead.",
        "createdAt" : "2018-12-28T23:22:34Z",
        "updatedAt" : "2019-02-20T01:55:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0fc8d51b84cab62a769351909a27566cc4672fff",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +684,688 @@     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n     *         other unexpected error\n     * @throws TimeoutException if the time taken for committing the transaction has surpassed <code>max.block.ms</code>.\n     * @throws InterruptException if the thread is interrupted while blocked\n     */"
  },
  {
    "id" : "675daebc-3d53-4e7c-a4ad-2b8d5aa90072",
    "prId" : 6066,
    "prUrl" : "https://github.com/apache/kafka/pull/6066#pullrequestreview-191473073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09e21526-6127-4c3d-85f3-54dc26e38fe4",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can we make this comment match the one above for commitTransaction()?",
        "createdAt" : "2019-01-11T00:13:51Z",
        "updatedAt" : "2019-02-20T01:55:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0fc8d51b84cab62a769351909a27566cc4672fff",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +700,704 @@     *\n     * Note that this method will raise {@link TimeoutException} if the transaction cannot be aborted before expiration\n     * of {@code max.block.ms}. Additionally, it will raise {@link InterruptException} if interrupted.\n     * It is safe to retry in either case, but it is not possible to attempt a different operation (such as commitTransaction)\n     * since the abort may already be in the progress of completing. If not retrying, the only option is to close the producer."
  },
  {
    "id" : "5513bb93-fa1a-49c2-a84e-db0286263fe3",
    "prId" : 6502,
    "prUrl" : "https://github.com/apache/kafka/pull/6502#pullrequestreview-225278426",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b61a22e8-7900-4522-a774-c774aec631d1",
        "parentId" : null,
        "authorId" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "body" : "It seems like we didn't enforce this too well if `lingerMs + requestTimeoutMs` overflowed. It would have been possible to misconfigure the producer with specifying lower `deliveryTimeoutMs` and higher `lingerMs + requestTimeoutMs`. We will now raise an exception if that is the case.\r\n\r\nThe test fixes needed in this patch are for the same reason, where `lingerMs` was set to `Integer.MAX_VALUE` and `deliveryTimeoutMs` was set to the default value of 2 minutes.",
        "createdAt" : "2019-04-11T00:10:21Z",
        "updatedAt" : "2019-04-11T00:10:21Z",
        "lastEditedBy" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fed80a47baf100462e962e4c18a476ce971077",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +486,490 @@        int lingerAndRequestTimeoutMs = (int) Math.min((long) lingerMs + requestTimeoutMs, Integer.MAX_VALUE);\n\n        if (deliveryTimeoutMs < Integer.MAX_VALUE && deliveryTimeoutMs < lingerAndRequestTimeoutMs) {\n            if (config.originals().containsKey(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG)) {\n                // throw an exception if the user explicitly set an inconsistent value"
  },
  {
    "id" : "e81c7ef2-98b4-4d45-9cb1-ada7e2bdf86d",
    "prId" : 6997,
    "prUrl" : "https://github.com/apache/kafka/pull/6997#pullrequestreview-269295555",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c53e08e6-3193-43ad-a36d-e396fc760163",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "We need to call `transactionManager#failIfNotReadyForSend` here, so that we don't try to append to the batch when we are not ready to send.  Also, we should remove `failIfNotReadyForSend` from `TransactionManager#maybeAddPartitionToTransaction`",
        "createdAt" : "2019-07-31T21:33:48Z",
        "updatedAt" : "2019-08-01T17:34:42Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "93f350844be9c391ab375fc9b0c207b4ea4335be",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +913,917 @@            // producer callback will make sure to call both 'callback' and interceptor callback\n            Callback interceptCallback = new InterceptorCallback<>(callback, this.interceptors, tp);\n\n            if (transactionManager != null && transactionManager.isTransactional()) {\n                transactionManager.failIfNotReadyForSend();"
  },
  {
    "id" : "eb148101-523d-4f61-b431-f42beb575e96",
    "prId" : 6997,
    "prUrl" : "https://github.com/apache/kafka/pull/6997#pullrequestreview-269873842",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2b0b676-af65-4cba-a4f8-639fe32480a7",
        "parentId" : null,
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "Would \"Retrying append due to new batch creation\" be better?",
        "createdAt" : "2019-08-01T20:47:00Z",
        "updatedAt" : "2019-08-01T20:47:00Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      },
      {
        "id" : "4e20a273-5084-46ef-a63e-7a6ee43402dc",
        "parentId" : "b2b0b676-af65-4cba-a4f8-639fe32480a7",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "This log message will have the most clarity possible! 🙂",
        "createdAt" : "2019-08-01T20:55:08Z",
        "updatedAt" : "2019-08-01T20:55:08Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      }
    ],
    "commit" : "93f350844be9c391ab375fc9b0c207b4ea4335be",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +926,930 @@                tp = new TopicPartition(record.topic(), partition);\n                if (log.isTraceEnabled()) {\n                    log.trace(\"Retrying because of a new batch, sending the record to topic {} partition {}. The old partition was {}\", record.topic(), partition, prevPartition);\n                }\n                // producer callback will make sure to call both 'callback' and interceptor callback"
  }
]