[
  {
    "id" : "1716cb9a-a675-46a3-9fa2-ffa6ba6446c2",
    "prId" : 7150,
    "prUrl" : "https://github.com/apache/kafka/pull/7150#pullrequestreview-285792457",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3242e2d-6d87-4866-82c9-87a544054580",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "@guozhangwang Is it useful to have only a single error message? There may be multiple failures?",
        "createdAt" : "2019-09-09T17:52:51Z",
        "updatedAt" : "2019-09-26T17:11:37Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "373e6b53-d17a-4b88-9094-ae4f2a73c8e0",
        "parentId" : "f3242e2d-6d87-4866-82c9-87a544054580",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We would only return one type of errors: if it is due to record validation which could happen on multiple records within a batch, then we would use that error message with the list of relative offsets; for other errors like magic byte mismatch etc we will return upon the first occurrence and the list of relative offsets will be a singleton.\r\n\r\nIf multiple of such different errors happen, we would still only return one error message (the second category would take precedence).",
        "createdAt" : "2019-09-09T21:22:55Z",
        "updatedAt" : "2019-09-26T17:11:37Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1de5dc0067c5687bcf9774d00de0b11c45bf5dba",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +180,184 @@                                    RELATIVE_OFFSET_ERROR_MESSAGE_FIELD\n                            )), \"The relative offsets of records that caused the batch to be dropped\"),\n                            ERROR_MESSAGE_FIELD)))))),\n            THROTTLE_TIME_MS);\n"
  },
  {
    "id" : "eea82551-8641-45b8-abc6-0302370c2c6b",
    "prId" : 7150,
    "prUrl" : "https://github.com/apache/kafka/pull/7150#pullrequestreview-295348897",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4259b928-1963-4b0b-80ec-c52dfc6aab3d",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: we can probably do some cleanup in pr.3, e.g. line 269 above can be replaced with `setIfExist` as well.",
        "createdAt" : "2019-10-01T02:27:38Z",
        "updatedAt" : "2019-10-01T02:27:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "5f934809-ebf7-4ca8-a219-cd9843aecd62",
        "parentId" : "4259b928-1963-4b0b-80ec-c52dfc6aab3d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "cc @tuvtran ",
        "createdAt" : "2019-10-01T02:29:42Z",
        "updatedAt" : "2019-10-01T02:29:43Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "769c4f10-3d14-480d-b4f4-9aa7f8f458b8",
        "parentId" : "4259b928-1963-4b0b-80ec-c52dfc6aab3d",
        "authorId" : "38aea9c5-d7f1-4e61-920e-b35370a0109c",
        "body" : "ack :) ",
        "createdAt" : "2019-10-01T03:08:38Z",
        "updatedAt" : "2019-10-01T03:08:38Z",
        "lastEditedBy" : "38aea9c5-d7f1-4e61-920e-b35370a0109c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1de5dc0067c5687bcf9774d00de0b11c45bf5dba",
    "line" : 128,
    "diffHunk" : "@@ -1,1 +270,274 @@                    partStruct.set(LOG_APPEND_TIME_KEY_NAME, part.logAppendTime);\n                partStruct.setIfExists(LOG_START_OFFSET_FIELD, part.logStartOffset);\n\n                List<Struct> errorRecords = new ArrayList<>();\n                for (Map.Entry<Integer, String> recordOffsetAndMessage : part.errorRecords.entrySet()) {"
  }
]