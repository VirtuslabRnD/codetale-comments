[
  {
    "id" : "b694b4b4-9e2b-4f63-83b6-c84c3efc9ace",
    "prId" : 5514,
    "prUrl" : "https://github.com/apache/kafka/pull/5514#pullrequestreview-146650690",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea250dc5-799f-49f7-8c66-72260baebf53",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Is this ever possible? `result` indicate retries needed while `pendingTxnOffsetCommits.isEmpty()`?",
        "createdAt" : "2018-08-15T22:42:45Z",
        "updatedAt" : "2018-08-15T23:54:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "2a3b78b1-2039-4132-9980-541a5ab61a2d",
        "parentId" : "ea250dc5-799f-49f7-8c66-72260baebf53",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is where we complete the result if there are no errors.",
        "createdAt" : "2018-08-15T23:01:21Z",
        "updatedAt" : "2018-08-15T23:54:48Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "f67ecb3f6218a07a6a22448140c09c6c89695ffb",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1310,1314 @@            if (result.isCompleted()) {\n                pendingTxnOffsetCommits.clear();\n            } else if (pendingTxnOffsetCommits.isEmpty()) {\n                result.done();\n            } else {"
  },
  {
    "id" : "b51a7888-7dac-4324-b1fd-52418edd3ffc",
    "prId" : 5514,
    "prUrl" : "https://github.com/apache/kafka/pull/5514#pullrequestreview-147170576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "parentId" : null,
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Do you think it would make sense to put an `if (!errors.isEmpty())` check around this log line for the cases when there are no errors? If I see it correctly it'd print `Received TxnOffsetCommit response for consumer group my-consumer-group:` which is I think is a bit misleading, and also I suppose it would be empty most of the times.",
        "createdAt" : "2018-08-16T14:12:52Z",
        "updatedAt" : "2018-08-16T14:13:06Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "5682fb86-f449-4c01-8a6e-171c595c9fe0",
        "parentId" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The `errors()` method name is a little misleading. The map contains both the successful partitions as well as those that failed. Most of the time, we would just see `Errors.NONE`.",
        "createdAt" : "2018-08-16T15:22:35Z",
        "updatedAt" : "2018-08-16T15:23:26Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "7040d5b0-4f54-4aff-a416-49671f563ffa",
        "parentId" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Ok, I think I see now, thanks for the explanation.",
        "createdAt" : "2018-08-17T10:14:01Z",
        "updatedAt" : "2018-08-17T10:14:02Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "f67ecb3f6218a07a6a22448140c09c6c89695ffb",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1276,1280 @@\n            log.debug(\"Received TxnOffsetCommit response for consumer group {}: {}\", builder.consumerGroupId(),\n                    errors);\n\n            for (Map.Entry<TopicPartition, Errors> entry : errors.entrySet()) {"
  },
  {
    "id" : "9034f493-ea2b-457b-88db-40e147e8e861",
    "prId" : 5971,
    "prUrl" : "https://github.com/apache/kafka/pull/5971#pullrequestreview-212830025",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de233cc6-b144-4f6d-860b-076ef92b8740",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "What I was trying to point out in the initial comment is that a user could be blocking on the latch in one of these pending requests. When we force close, I would expect the producer to fail any waiters. So should we have a `close()` API in `TransactionManager` which iterates through all of the pending requests and forcefully finishes the `TransactionalRequestResult`?",
        "createdAt" : "2019-03-07T21:54:03Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "7a07941a-55b5-404a-956f-92b64f62afce",
        "parentId" : "de233cc6-b144-4f6d-860b-076ef92b8740",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Yep, I think that'd be a good idea. I'll create one.",
        "createdAt" : "2019-03-11T13:24:02Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e9e027171422c2f5af6d9602429702a58939036",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +739,743 @@    }\n\n    synchronized boolean hasPendingRequests() {\n        return !pendingRequests.isEmpty();\n    }"
  },
  {
    "id" : "d25f313e-cdc0-4c4d-93af-68b20735cb96",
    "prId" : 5971,
    "prUrl" : "https://github.com/apache/kafka/pull/5971#pullrequestreview-226515787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99d90996-5bfd-40dd-ba0e-e874991c88bc",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just a nit, but the name of the api suggests that this could be called in other scenarios than closing. Perhaps we should rename the method to something like `abortPendingRequestsOnForceClose`. Or maybe just `close()`? ðŸ˜‰ ",
        "createdAt" : "2019-04-04T22:22:48Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "4b9c0a5e-2701-48bd-93d1-4cfe925c43f1",
        "parentId" : "99d90996-5bfd-40dd-ba0e-e874991c88bc",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Renamed it :D",
        "createdAt" : "2019-04-15T08:39:19Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e9e027171422c2f5af6d9602429702a58939036",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +683,687 @@\n    synchronized void close() {\n        KafkaException shutdownException = new KafkaException(\"The producer closed forcefully\");\n        pendingRequests.forEach(handler ->\n                handler.fatalError(shutdownException));"
  },
  {
    "id" : "216551fc-d9ce-4597-a2c3-cd684f4b2757",
    "prId" : 6270,
    "prUrl" : "https://github.com/apache/kafka/pull/6270#pullrequestreview-210728892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Hmm.. This is an interesting case. As far as I can tell, the state would only get reset if we are changing the producerId in `resetProducerId`. So the question is whether it is valid to associate the last acked offset of the old producerId with the new one? I suspect the answer is no. The last acked offset is used in order to try and detect spurious UNKNOWN_PRODUCER_ID errors, so I think our assumption is that this offset is associated with the producerId at the time of the request.",
        "createdAt" : "2019-03-01T18:58:21Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "2598586a-0520-4f84-9083-af4b154dc95c",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "`SenderTest.testResetOfProducerStateShouldAllowQueuedBatchesToDrain` does an example for this. I was debating a lot wether the test tests a non-existent/invalid scenario or not. The test seems valid though. Basically it sends two request, one will be rejected with an \"not leader for partition\" while the other one will be rejected with \"out of order sequence number\". The first will be reenqueued while the other one causes the transaction state to reset. Since the out of order response arrived later, the reenqueued request will be resent in the next `run()`.\r\nNow based on what you're saying, perhaps it would be better to\r\n- either ignore the last acked offset in this case as the response belonged to the previous producer ID which might be still valid on the broker (it hasn't timed out or been deleted). If the producer ID not valid anymore, then broker won't accept the message anyway. The only downside is that it's hard to validate if we're in this scenario.\r\n- or to reject the message entirely saying that the producerId has changed since. This would be something like the behavior in `Sender.completeBatch` therefore may be better or maybe more expected from the user's perspective.\r\n\r\nWhat do you think?\r\n",
        "createdAt" : "2019-03-04T10:44:07Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "c4ccb170-a884-4e56-8703-f211e727279c",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I was thinking more along the lines of the first option. From a high level, when we reset the producerId, we want to start from a clean slate. Basically we want to ignore responses to requests which used the old producerId. These cases are tricky to think about. In KIP-360, I proposed that we should not reset the producerId, but should bump the epoch instead. That would make the UNKNOWN_PRODUCER_ID case unambiguous.\r\n\r\nI think I'd suggest that we leave this case handled as it is currently so that we can merge this refactor. Then we can think about the proper handling in a separate issue. If KIP-360 is adopted, maybe this logic ends up going away anyway. Sound good?",
        "createdAt" : "2019-03-04T22:06:23Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "69acff3d-c58a-444b-9f29-26cf48d56a0b",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Sounds good to me.",
        "createdAt" : "2019-03-05T15:03:26Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d4044912617863ea29723925712307228fa1b37",
    "line" : 303,
    "diffHunk" : "@@ -1,1 +525,529 @@        long lastOffset = response.baseOffset + batch.recordCount - 1;\n        OptionalLong lastAckedOffset = lastAckedOffset(batch.topicPartition);\n        // It might happen that the TransactionManager has been reset while a request was reenqueued and got a valid\n        // response for this. This can happen only if the producer is only idempotent (not transactional) and in\n        // this case there will be no tracked bookkeeper entry about it, so we have to insert one."
  },
  {
    "id" : "2935f97a-0fb4-4507-9fd8-ef1580ec88da",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248862011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e6ae379-061c-4b30-a261-d135b4da8b25",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Just to clarify this function is just moved here, no logical changes?\r\n\r\nAlso if it is indeed the case, could you make some comments when creating the PR for ease of review :) ?",
        "createdAt" : "2019-06-12T15:31:42Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "9ba92663-062f-42f6-95f5-e74c4cee6bd5",
        "parentId" : "1e6ae379-061c-4b30-a261-d135b4da8b25",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yes, it is moved to simplify the TransactionManager API so that I could write better test cases. Otherwise it was very difficult to hit the cases without effectively rewriting this logic in the test case.",
        "createdAt" : "2019-06-12T15:58:54Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +567,571 @@    }\n\n    public synchronized void handleCompletedBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response) {\n        if (!hasProducerIdAndEpoch(batch.producerId(), batch.producerEpoch())) {\n            log.debug(\"Ignoring completed batch {} with producer id {}, epoch {}, and sequence number {} \" +"
  },
  {
    "id" : "de877b06-15aa-400c-9a40-aec12c9e141d",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248876676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88856603-1557-4f9e-849a-79e6f0662131",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Same here, the caller function moved here seems not changing any logic (the key change is in `adjustSequencesDueToFailedBatch`) right?",
        "createdAt" : "2019-06-12T15:35:04Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "3f205fdc-7df9-408a-a3b6-d5653fe3dd3d",
        "parentId" : "88856603-1557-4f9e-849a-79e6f0662131",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The main fix is the producerId and epoch check below.",
        "createdAt" : "2019-06-12T16:24:47Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 154,
    "diffHunk" : "@@ -1,1 +597,601 @@\n    public synchronized void handleFailedBatch(ProducerBatch batch, RuntimeException exception, boolean adjustSequenceNumbers) {\n        maybeTransitionToErrorState(exception);\n\n        if (!hasProducerIdAndEpoch(batch.producerId(), batch.producerEpoch())) {"
  },
  {
    "id" : "0f75ef74-f002-4d59-9ef4-651defd2693b",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248897010",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The caller function `canRetry` is synchronized, do we need an atomic integer?",
        "createdAt" : "2019-06-12T15:38:34Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e7d3fd00-762a-42c3-be31-7818baa7b6a6",
        "parentId" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It was needed only because of the lambda. I guess this is the ugly side of Java 8.",
        "createdAt" : "2019-06-12T16:24:14Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "5bc3ac98-633b-4955-827f-386cdd2c73e3",
        "parentId" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ah right.",
        "createdAt" : "2019-06-12T17:03:25Z",
        "updatedAt" : "2019-06-12T17:03:25Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 220,
    "diffHunk" : "@@ -1,1 +656,660 @@\n    private void startSequencesAtBeginning(TopicPartition topicPartition) {\n        final AtomicInteger sequence = new AtomicInteger(0);\n        topicPartitionBookkeeper.getPartition(topicPartition).resetSequenceNumbers(inFlightBatch -> {\n            log.info(\"Resetting sequence number of batch with current sequence {} for partition {} to {}\","
  }
]