[
  {
    "id" : "b694b4b4-9e2b-4f63-83b6-c84c3efc9ace",
    "prId" : 5514,
    "prUrl" : "https://github.com/apache/kafka/pull/5514#pullrequestreview-146650690",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea250dc5-799f-49f7-8c66-72260baebf53",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Is this ever possible? `result` indicate retries needed while `pendingTxnOffsetCommits.isEmpty()`?",
        "createdAt" : "2018-08-15T22:42:45Z",
        "updatedAt" : "2018-08-15T23:54:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "2a3b78b1-2039-4132-9980-541a5ab61a2d",
        "parentId" : "ea250dc5-799f-49f7-8c66-72260baebf53",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is where we complete the result if there are no errors.",
        "createdAt" : "2018-08-15T23:01:21Z",
        "updatedAt" : "2018-08-15T23:54:48Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "f67ecb3f6218a07a6a22448140c09c6c89695ffb",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1310,1314 @@            if (result.isCompleted()) {\n                pendingTxnOffsetCommits.clear();\n            } else if (pendingTxnOffsetCommits.isEmpty()) {\n                result.done();\n            } else {"
  },
  {
    "id" : "b51a7888-7dac-4324-b1fd-52418edd3ffc",
    "prId" : 5514,
    "prUrl" : "https://github.com/apache/kafka/pull/5514#pullrequestreview-147170576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "parentId" : null,
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Do you think it would make sense to put an `if (!errors.isEmpty())` check around this log line for the cases when there are no errors? If I see it correctly it'd print `Received TxnOffsetCommit response for consumer group my-consumer-group:` which is I think is a bit misleading, and also I suppose it would be empty most of the times.",
        "createdAt" : "2018-08-16T14:12:52Z",
        "updatedAt" : "2018-08-16T14:13:06Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "5682fb86-f449-4c01-8a6e-171c595c9fe0",
        "parentId" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The `errors()` method name is a little misleading. The map contains both the successful partitions as well as those that failed. Most of the time, we would just see `Errors.NONE`.",
        "createdAt" : "2018-08-16T15:22:35Z",
        "updatedAt" : "2018-08-16T15:23:26Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "7040d5b0-4f54-4aff-a416-49671f563ffa",
        "parentId" : "6aefb5ad-0605-46d3-b0c8-7bc6dc50eb1f",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Ok, I think I see now, thanks for the explanation.",
        "createdAt" : "2018-08-17T10:14:01Z",
        "updatedAt" : "2018-08-17T10:14:02Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "f67ecb3f6218a07a6a22448140c09c6c89695ffb",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1276,1280 @@\n            log.debug(\"Received TxnOffsetCommit response for consumer group {}: {}\", builder.consumerGroupId(),\n                    errors);\n\n            for (Map.Entry<TopicPartition, Errors> entry : errors.entrySet()) {"
  },
  {
    "id" : "9034f493-ea2b-457b-88db-40e147e8e861",
    "prId" : 5971,
    "prUrl" : "https://github.com/apache/kafka/pull/5971#pullrequestreview-212830025",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de233cc6-b144-4f6d-860b-076ef92b8740",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "What I was trying to point out in the initial comment is that a user could be blocking on the latch in one of these pending requests. When we force close, I would expect the producer to fail any waiters. So should we have a `close()` API in `TransactionManager` which iterates through all of the pending requests and forcefully finishes the `TransactionalRequestResult`?",
        "createdAt" : "2019-03-07T21:54:03Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "7a07941a-55b5-404a-956f-92b64f62afce",
        "parentId" : "de233cc6-b144-4f6d-860b-076ef92b8740",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Yep, I think that'd be a good idea. I'll create one.",
        "createdAt" : "2019-03-11T13:24:02Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e9e027171422c2f5af6d9602429702a58939036",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +739,743 @@    }\n\n    synchronized boolean hasPendingRequests() {\n        return !pendingRequests.isEmpty();\n    }"
  },
  {
    "id" : "d25f313e-cdc0-4c4d-93af-68b20735cb96",
    "prId" : 5971,
    "prUrl" : "https://github.com/apache/kafka/pull/5971#pullrequestreview-226515787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99d90996-5bfd-40dd-ba0e-e874991c88bc",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just a nit, but the name of the api suggests that this could be called in other scenarios than closing. Perhaps we should rename the method to something like `abortPendingRequestsOnForceClose`. Or maybe just `close()`? ðŸ˜‰ ",
        "createdAt" : "2019-04-04T22:22:48Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "4b9c0a5e-2701-48bd-93d1-4cfe925c43f1",
        "parentId" : "99d90996-5bfd-40dd-ba0e-e874991c88bc",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Renamed it :D",
        "createdAt" : "2019-04-15T08:39:19Z",
        "updatedAt" : "2019-04-15T13:56:56Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e9e027171422c2f5af6d9602429702a58939036",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +683,687 @@\n    synchronized void close() {\n        KafkaException shutdownException = new KafkaException(\"The producer closed forcefully\");\n        pendingRequests.forEach(handler ->\n                handler.fatalError(shutdownException));"
  },
  {
    "id" : "216551fc-d9ce-4597-a2c3-cd684f4b2757",
    "prId" : 6270,
    "prUrl" : "https://github.com/apache/kafka/pull/6270#pullrequestreview-210728892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Hmm.. This is an interesting case. As far as I can tell, the state would only get reset if we are changing the producerId in `resetProducerId`. So the question is whether it is valid to associate the last acked offset of the old producerId with the new one? I suspect the answer is no. The last acked offset is used in order to try and detect spurious UNKNOWN_PRODUCER_ID errors, so I think our assumption is that this offset is associated with the producerId at the time of the request.",
        "createdAt" : "2019-03-01T18:58:21Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "2598586a-0520-4f84-9083-af4b154dc95c",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "`SenderTest.testResetOfProducerStateShouldAllowQueuedBatchesToDrain` does an example for this. I was debating a lot wether the test tests a non-existent/invalid scenario or not. The test seems valid though. Basically it sends two request, one will be rejected with an \"not leader for partition\" while the other one will be rejected with \"out of order sequence number\". The first will be reenqueued while the other one causes the transaction state to reset. Since the out of order response arrived later, the reenqueued request will be resent in the next `run()`.\r\nNow based on what you're saying, perhaps it would be better to\r\n- either ignore the last acked offset in this case as the response belonged to the previous producer ID which might be still valid on the broker (it hasn't timed out or been deleted). If the producer ID not valid anymore, then broker won't accept the message anyway. The only downside is that it's hard to validate if we're in this scenario.\r\n- or to reject the message entirely saying that the producerId has changed since. This would be something like the behavior in `Sender.completeBatch` therefore may be better or maybe more expected from the user's perspective.\r\n\r\nWhat do you think?\r\n",
        "createdAt" : "2019-03-04T10:44:07Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "c4ccb170-a884-4e56-8703-f211e727279c",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I was thinking more along the lines of the first option. From a high level, when we reset the producerId, we want to start from a clean slate. Basically we want to ignore responses to requests which used the old producerId. These cases are tricky to think about. In KIP-360, I proposed that we should not reset the producerId, but should bump the epoch instead. That would make the UNKNOWN_PRODUCER_ID case unambiguous.\r\n\r\nI think I'd suggest that we leave this case handled as it is currently so that we can merge this refactor. Then we can think about the proper handling in a separate issue. If KIP-360 is adopted, maybe this logic ends up going away anyway. Sound good?",
        "createdAt" : "2019-03-04T22:06:23Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "69acff3d-c58a-444b-9f29-26cf48d56a0b",
        "parentId" : "5f180194-b6aa-47e2-9529-d2c9e906b3a2",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Sounds good to me.",
        "createdAt" : "2019-03-05T15:03:26Z",
        "updatedAt" : "2019-03-06T13:51:49Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d4044912617863ea29723925712307228fa1b37",
    "line" : 303,
    "diffHunk" : "@@ -1,1 +525,529 @@        long lastOffset = response.baseOffset + batch.recordCount - 1;\n        OptionalLong lastAckedOffset = lastAckedOffset(batch.topicPartition);\n        // It might happen that the TransactionManager has been reset while a request was reenqueued and got a valid\n        // response for this. This can happen only if the producer is only idempotent (not transactional) and in\n        // this case there will be no tracked bookkeeper entry about it, so we have to insert one."
  },
  {
    "id" : "2935f97a-0fb4-4507-9fd8-ef1580ec88da",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248862011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e6ae379-061c-4b30-a261-d135b4da8b25",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Just to clarify this function is just moved here, no logical changes?\r\n\r\nAlso if it is indeed the case, could you make some comments when creating the PR for ease of review :) ?",
        "createdAt" : "2019-06-12T15:31:42Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "9ba92663-062f-42f6-95f5-e74c4cee6bd5",
        "parentId" : "1e6ae379-061c-4b30-a261-d135b4da8b25",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yes, it is moved to simplify the TransactionManager API so that I could write better test cases. Otherwise it was very difficult to hit the cases without effectively rewriting this logic in the test case.",
        "createdAt" : "2019-06-12T15:58:54Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +567,571 @@    }\n\n    public synchronized void handleCompletedBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response) {\n        if (!hasProducerIdAndEpoch(batch.producerId(), batch.producerEpoch())) {\n            log.debug(\"Ignoring completed batch {} with producer id {}, epoch {}, and sequence number {} \" +"
  },
  {
    "id" : "de877b06-15aa-400c-9a40-aec12c9e141d",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248876676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88856603-1557-4f9e-849a-79e6f0662131",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Same here, the caller function moved here seems not changing any logic (the key change is in `adjustSequencesDueToFailedBatch`) right?",
        "createdAt" : "2019-06-12T15:35:04Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "3f205fdc-7df9-408a-a3b6-d5653fe3dd3d",
        "parentId" : "88856603-1557-4f9e-849a-79e6f0662131",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The main fix is the producerId and epoch check below.",
        "createdAt" : "2019-06-12T16:24:47Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 154,
    "diffHunk" : "@@ -1,1 +597,601 @@\n    public synchronized void handleFailedBatch(ProducerBatch batch, RuntimeException exception, boolean adjustSequenceNumbers) {\n        maybeTransitionToErrorState(exception);\n\n        if (!hasProducerIdAndEpoch(batch.producerId(), batch.producerEpoch())) {"
  },
  {
    "id" : "0f75ef74-f002-4d59-9ef4-651defd2693b",
    "prId" : 6883,
    "prUrl" : "https://github.com/apache/kafka/pull/6883#pullrequestreview-248897010",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The caller function `canRetry` is synchronized, do we need an atomic integer?",
        "createdAt" : "2019-06-12T15:38:34Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e7d3fd00-762a-42c3-be31-7818baa7b6a6",
        "parentId" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It was needed only because of the lambda. I guess this is the ugly side of Java 8.",
        "createdAt" : "2019-06-12T16:24:14Z",
        "updatedAt" : "2019-06-12T16:30:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "5bc3ac98-633b-4955-827f-386cdd2c73e3",
        "parentId" : "b41d523f-f331-4a03-8540-16c197d9a95e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ah right.",
        "createdAt" : "2019-06-12T17:03:25Z",
        "updatedAt" : "2019-06-12T17:03:25Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e75b64f3d1d9c82742472b4cee70d85c2e5df5",
    "line" : 220,
    "diffHunk" : "@@ -1,1 +656,660 @@\n    private void startSequencesAtBeginning(TopicPartition topicPartition) {\n        final AtomicInteger sequence = new AtomicInteger(0);\n        topicPartitionBookkeeper.getPartition(topicPartition).resetSequenceNumbers(inFlightBatch -> {\n            log.info(\"Resetting sequence number of batch with current sequence {} for partition {} to {}\","
  },
  {
    "id" : "c644e9c4-0c2d-4a90-8576-42c4e7f6cc17",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-337912889",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89df2f43-a51a-43a0-aaa8-0c7df80327f1",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Would be helpful to mention what the value type here represents in the comment.",
        "createdAt" : "2020-01-03T01:03:23Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +198,202 @@    // record count to its sequence number. This is used to tell if a subsequent batch is the one immediately following\n    // the expired one.\n    private final Map<TopicPartition, Integer> partitionsWithUnresolvedSequences;\n\n    // The partitions that have received an error that triggers an epoch bump. When the epoch is bumped, these"
  },
  {
    "id" : "448a459f-248f-4735-9eb1-aae53b21ccf6",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-349767694",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce0133a3-0753-4b06-91b0-fa62257f28bf",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Once we have decided to bump the epoch, is there any harm in doing so right away? In other words, do we benefit by ending the transaction first? ",
        "createdAt" : "2020-01-03T01:20:35Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "d018aa38-3e8f-4b38-877d-1af53083ff06",
        "parentId" : "ce0133a3-0753-4b06-91b0-fa62257f28bf",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "I initially thought that doing the state tracking would be hard if we just bumped right away without aborting. But actually it should be fine, since InitProducerId already aborts any ongoing transactions for that producer. It will have to retry at least once, because on the first call it gets a CONCURREN_TRANSACTIONS error, but that error is already handled. So this suggestion is actually what I went with.",
        "createdAt" : "2020-01-28T23:05:36Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 162,
    "diffHunk" : "@@ -1,1 +275,279 @@        ADD_PARTITIONS_OR_OFFSETS(2),\n        END_TXN(3),\n        EPOCH_BUMP(4);\n\n        final int priority;"
  },
  {
    "id" : "cd79e4b0-2a40-40d7-97a4-9ddd6e3a8a20",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350476109",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "928c41ed-2740-4e6c-812f-983d5615e1e6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Trying to follow this. The check above has failed, so this is handling the transactional case, which means we should be in the abortable or fatal error states. If we are aborting and we can bump the epoch, then sequence numbers will be reset after receiving the `InitProducerId` response. If we cannot bump the epoch, does it make sense to reset sequence numbers here? It should be for the partition that raised the `UNKNOWN_PRODUCER_ID` error, but how about the rest?",
        "createdAt" : "2020-01-29T07:06:53Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "86eb5764-c40a-4c09-ad13-5cc016267e6b",
        "parentId" : "928c41ed-2740-4e6c-812f-983d5615e1e6",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "If we get an UNKNOWN_PRODUCER_ID, then we have no producer state in the log, right? So every partition should start the next transaction at sequence 0. You're right that this only applies in the case where we can't bump the epoch, I could add a check for that to make this more explicit. ",
        "createdAt" : "2020-01-29T15:06:59Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "7d9b7399-290f-48fc-8a12-5eefc9d8e57e",
        "parentId" : "928c41ed-2740-4e6c-812f-983d5615e1e6",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We have lost partition state for one partition, but other partitions may be fine. If we reset all sequences to 0, then we are likely to get out of order sequence errors. Perhaps we should only be resetting for this one partition?",
        "createdAt" : "2020-01-29T16:43:28Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a0fdbd77-0554-4d99-97c9-8a7f70b00e50",
        "parentId" : "928c41ed-2740-4e6c-812f-983d5615e1e6",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "Yes, I see now. I think I got this crossed in my head with the epoch bump case. Changed to reset only one partition state and changed a test to check that case.",
        "createdAt" : "2020-01-29T22:40:50Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 459,
    "diffHunk" : "@@ -1,1 +721,725 @@            // partition, which will reset the sequence number to 0 and allow us to continue\n            requestEpochBumpForPartition(batch.topicPartition);\n        } else if (exception instanceof UnknownProducerIdException) {\n            // If we get an UnknownProducerId for a partition, then the broker has no state for that producer. It will\n            // therefore accept a write with sequence number 0. We reset the sequence number for the partition here so"
  },
  {
    "id" : "41969ff9-9cdd-4d64-adbf-70c1b093a9f1",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350511309",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "273a07aa-9417-4439-a0db-d6fefe5712cd",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Something's puzzling me in this logic. If there are still inflight requests for a partition, then we will hit the `else` branch and the partition will remain in `partitionsWithUnresolvedSequences`. Inside `Sender.runOnce`, following the call to `checkUnresolvedSequences`, we immediately transition to a fatal state if there are unresolved sequences and we are not already in a fatal state. That doesn't seem to make sense. I think this may be a bug introduced in my PR to consolidate the InitProducerId logic.\r\n\r\nAssuming we fix this, a second question is about the logic to await the inflight batches. This should only be necessary if we actually need to resolve the next sequence. In the transactional case, if we can bump the epoch, then could we just abort the inflight batches since we will be resetting the sequence anyway? (We don't necessarily have to implement this, just checking my understanding.)",
        "createdAt" : "2020-01-29T07:41:48Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ffc5ca7e-0ce9-422f-88a1-31e7c010ff7d",
        "parentId" : "273a07aa-9417-4439-a0db-d6fefe5712cd",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "(Deleted an earlier comment that was inaccurate)\r\n\r\nYes, you are correct about the sender logic. That transition to fatal shouldn't be there, I either neglected to remove it or added it back when I merged in your refactor. I removed it and added a test to catch that case.\r\n\r\nYou are also right about the in-flight batches, we could abort them early. I'd rather do that in a separate change, though.",
        "createdAt" : "2020-01-30T00:11:42Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 534,
    "diffHunk" : "@@ -1,1 +798,802 @@        for (Iterator<TopicPartition> iter = partitionsWithUnresolvedSequences.keySet().iterator(); iter.hasNext(); ) {\n            TopicPartition topicPartition = iter.next();\n            if (!hasInflightBatches(topicPartition)) {\n                // The partition has been fully drained. At this point, the last ack'd sequence should be one less than\n                // next sequence destined for the partition. If so, the partition is fully resolved. If not, we should"
  },
  {
    "id" : "7ce78787-593c-4681-bbda-3242ce5d7da2",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350609548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9975a682-d4ab-4850-86d7-8aa368161f85",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Why is `INVALID_PRODUCER_ID_MAPPING` no longer fatal? Does that not indicate we have likely been fenced?",
        "createdAt" : "2020-01-29T08:14:18Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "1e6457c3-a744-485a-b8d3-ae48136fcfb6",
        "parentId" : "9975a682-d4ab-4850-86d7-8aa368161f85",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "According to the KIP, it could mean that the producer ID had expired. On the server side, we'll generate a new ID and return it if there's no existing producer ID for the given transactional ID, or we'll fence the producer if a new producer ID already exists",
        "createdAt" : "2020-01-29T13:09:31Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "443626ce-e07a-48dc-965a-30e588f42154",
        "parentId" : "9975a682-d4ab-4850-86d7-8aa368161f85",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ok, that makes sense. I had forgotten about it. If you can find a good place, I think this would be good to document.",
        "createdAt" : "2020-01-30T08:28:21Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 804,
    "diffHunk" : "@@ -1,1 +1415,1419 @@                            \"batch had errors.\", topicPartition);\n                    hasPartitionErrors = true;\n                } else if (error == Errors.UNKNOWN_PRODUCER_ID || error == Errors.INVALID_PRODUCER_ID_MAPPING) {\n                    abortableErrorIfPossible(error.exception());\n                    return;"
  },
  {
    "id" : "fd8bd4e8-4541-476c-8cce-b517c697af11",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350609548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2560785-bfaa-4795-b1ee-43e99843189f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This method is invoked from `KafkaProducer.initializeTransactions`. Previously, the producer would only support one call to this API and each subsequent call would fail. If we want to preserve this, we may need to bring back the overloaded method.",
        "createdAt" : "2020-01-30T07:33:29Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 193,
    "diffHunk" : "@@ -1,1 +307,311 @@    }\n\n    public synchronized TransactionalRequestResult initializeTransactions() {\n        return initializeTransactions(ProducerIdAndEpoch.NONE);\n    }"
  },
  {
    "id" : "1c49f2c0-1576-40d2-abbb-a93bca36c50d",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350609548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e143198-676a-4cfb-a3c2-e6e904c99bbd",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It may be useful to have a comment explaining this case.",
        "createdAt" : "2020-01-30T08:01:54Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 465,
    "diffHunk" : "@@ -1,1 +727,731 @@            // will also fail with an UnknownProducerId error, so the sequence will remain at 0. Note that if the\n            // broker supports bumping the epoch, we will later reset all sequence numbers after calling InitProducerId\n            resetSequenceForPartition(batch.topicPartition);\n        } else {\n            if (adjustSequenceNumbers) {"
  },
  {
    "id" : "c8574ad5-758d-48bb-99fc-0b4f96ef117f",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-350609548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0dd48560-1cb0-4ea6-ad27-0760787cadb2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Would it make sense to move this state into `TopicPartitionEntry`?",
        "createdAt" : "2020-01-30T08:07:02Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +198,202 @@    // record count to its sequence number. This is used to tell if a subsequent batch is the one immediately following\n    // the expired one.\n    private final Map<TopicPartition, Integer> partitionsWithUnresolvedSequences;\n\n    // The partitions that have received an error that triggers an epoch bump. When the epoch is bumped, these"
  },
  {
    "id" : "a1f41d04-1c53-4956-8d4b-02e00eeece6d",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-353414829",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78a1631a-4621-4dbb-8ce2-35943fbabd8b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Below we use the InitProducerId API as another way to abort a transaction. Rather than transitioning to `INITIALIZING` in this case, I wonder if it makes sense to stay in `ABORTING_TRANSACTION`?",
        "createdAt" : "2020-02-06T05:05:06Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 145,
    "diffHunk" : "@@ -1,1 +245,249 @@                    return source == READY;\n                case INITIALIZING:\n                    return source == UNINITIALIZED || source == ABORTING_TRANSACTION;\n                case READY:\n                    return source == INITIALIZING || source == COMMITTING_TRANSACTION || source == ABORTING_TRANSACTION;"
  },
  {
    "id" : "4b717e25-f137-4532-bda6-374f3516106b",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-353414829",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17aa76bb-5285-4767-9a72-4b215bc120f0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: If we `maybeUpdateLastAckedSequence` return the last acked sequence, then we could avoid the awkward line above `lastAckedSequence(batch.topicPartition).orElse(-1)`",
        "createdAt" : "2020-02-06T05:27:16Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 412,
    "diffHunk" : "@@ -1,1 +678,682 @@                batch.topicPartition,\n                lastAckedSequence);\n\n        updateLastAckedOffset(response, batch);\n        removeInFlightBatch(batch);"
  },
  {
    "id" : "80c1f8e1-354b-4c65-a52f-bc956519a248",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-355495738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b35b7a7f-ef00-42d4-870f-32576dc38aee",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I think this works, just checking my understanding. Suppose we still have inflight requests and we are talking to a broker that doesn't support epoch bumps. When we reset sequence numbers above, we also drop the state of those inflight requests. I think we are implicitly relying on those inflights also returning the same UNKNONW_PRODUCER_ID error. Is that right?",
        "createdAt" : "2020-02-06T05:41:33Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "df6ffd46-a943-4c03-b7c4-e5f155c45cda",
        "parentId" : "b35b7a7f-ef00-42d4-870f-32576dc38aee",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "That's the assumption I was making, yes. If we have one request in-flight that gets an UNKNOWN_PRODUCER_ID, I wouldn't expect any other in-flights to be able to succeed.",
        "createdAt" : "2020-02-10T18:25:15Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "ce13156f-6918-4e8e-8cd0-0a9dbc0d12c6",
        "parentId" : "b35b7a7f-ef00-42d4-870f-32576dc38aee",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Maybe worth mentioning this in the comment. ",
        "createdAt" : "2020-02-10T20:57:35Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 465,
    "diffHunk" : "@@ -1,1 +727,731 @@            // will also fail with an UnknownProducerId error, so the sequence will remain at 0. Note that if the\n            // broker supports bumping the epoch, we will later reset all sequence numbers after calling InitProducerId\n            resetSequenceForPartition(batch.topicPartition);\n        } else {\n            if (adjustSequenceNumbers) {"
  },
  {
    "id" : "cfe170b5-dca3-4f95-b359-9de28d28e335",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-356432353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91d78648-3092-44bf-92bc-a4aa5d1952a4",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "For my own education, I know `producerIdAndEpoch` is volatile, what's the gain by doing an assignment here?",
        "createdAt" : "2020-02-06T23:51:22Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "2fdd5b94-2764-4637-9dfb-5a2ae1fd371d",
        "parentId" : "91d78648-3092-44bf-92bc-a4aa5d1952a4",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We need to read two fields from ProducerIdAndEpoch. The copy ensures we are seeing the same object.",
        "createdAt" : "2020-02-11T06:13:34Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 280,
    "diffHunk" : "@@ -1,1 +505,509 @@\n    boolean matchesProducerIdAndEpoch(ProducerBatch batch) {\n        ProducerIdAndEpoch idAndEpoch = this.producerIdAndEpoch;\n        return idAndEpoch.producerId == batch.producerId() && idAndEpoch.epoch == batch.producerEpoch();\n    }"
  },
  {
    "id" : "7ba96af4-2530-4efc-87e2-663fa3e22f9e",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-354845237",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de99edf2-d22e-44f9-90cf-d0efd48a3045",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could be simplified as:\r\n`hasUnresolvedSequence(topicPartition) && sequence == this.partitionsWithUnresolvedSequences.get(topicPartition)`",
        "createdAt" : "2020-02-07T00:05:39Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 581,
    "diffHunk" : "@@ -1,1 +842,846 @@    }\n\n    private boolean isNextSequenceForUnresolvedPartition(TopicPartition topicPartition, int sequence) {\n        return this.hasUnresolvedSequence(topicPartition) &&\n                sequence == this.partitionsWithUnresolvedSequences.get(topicPartition);"
  },
  {
    "id" : "1f4d7684-e36e-4bb8-9c43-81cce35e9efa",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-355196538",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b2a0637-c919-422b-94f9-ccd3a2108c8b",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we make this class private?",
        "createdAt" : "2020-02-07T00:20:49Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "2c4c2959-e5d2-4b9c-b506-fdae2dfcb9b1",
        "parentId" : "2b2a0637-c919-422b-94f9-ccd3a2108c8b",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "It's used in Sender when we actually send the requests",
        "createdAt" : "2020-02-07T14:34:46Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 738,
    "diffHunk" : "@@ -1,1 +1195,1199 @@    }\n\n    abstract class TxnRequestHandler implements RequestCompletionHandler {\n        protected final TransactionalRequestResult result;\n        private boolean isRetry = false;"
  },
  {
    "id" : "f47eac6c-b1b6-42f3-8643-e7a5a0d3a7eb",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-355194077",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3eaf13b4-637f-4aee-a794-744bbd051867",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "nit: UNINITIALIZED and IN_TRANSACTION could be merged.",
        "createdAt" : "2020-02-07T06:16:30Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "d9647f15-3d91-459a-b1b1-008c9bba3f60",
        "parentId" : "3eaf13b4-637f-4aee-a794-744bbd051867",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "They could be, but I think leaving them separate is more readable because it makes it easier to find the source state that you're interested in",
        "createdAt" : "2020-02-07T14:31:15Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +243,247 @@            switch (target) {\n                case UNINITIALIZED:\n                    return source == READY;\n                case INITIALIZING:\n                    return source == UNINITIALIZED || source == ABORTING_TRANSACTION;"
  },
  {
    "id" : "880ed0d4-976b-41fb-a95b-807ead05a541",
    "prId" : 7389,
    "prUrl" : "https://github.com/apache/kafka/pull/7389#pullrequestreview-357657639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee9d5893-c9a2-4a75-9c46-bd324beddb4c",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "For the idempotent producer, we transition to `UNINITIALIZED` when we need to reset the producerId. Does it make sense to do the same for a transactional epoch bump?",
        "createdAt" : "2020-02-10T20:49:51Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "77bd24bf-fa56-400c-bab4-0603b2dd944a",
        "parentId" : "ee9d5893-c9a2-4a75-9c46-bd324beddb4c",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "We generally transition when we enqueue the relevant request, and we enqueue the abort and init at the same time. To my mind that means we go straight from `ABORTING` to `INITIALIZING`, but I'm not wedded to it if you think going through `UNINITIALIZED` makes more sense.",
        "createdAt" : "2020-02-10T22:17:19Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "92fd0627-1f02-4741-9ccb-06fa7c7efbd3",
        "parentId" : "ee9d5893-c9a2-4a75-9c46-bd324beddb4c",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I don't feel strongly about it, I was considering it mostly for consistency. For the idempotent producer, we could have transitioned directly from READY to INITIALIZING, but we chose to go through UNINITIALIZED because we thought it simplified the state machine. If we allow the transition through ABORTING, perhaps we should allow it through READY as well. Or let them both go through UNINITIALIZED.",
        "createdAt" : "2020-02-11T06:10:32Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ab91bcbb-8251-4017-a894-c2848bb58b27",
        "parentId" : "ee9d5893-c9a2-4a75-9c46-bd324beddb4c",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "In that case, I think I would prefer to remove UNINITIALIZED from that path and go directly from READY to INITIALIZING. Removing the producer ID should be enough signal in that case that we need to get a new producer ID.",
        "createdAt" : "2020-02-12T17:16:12Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "60e3ed8c-29eb-436a-90f4-df8ca8e79c8c",
        "parentId" : "ee9d5893-c9a2-4a75-9c46-bd324beddb4c",
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "Hmm, blocking READY -> INITIALIZING is how we catch duplicate `initializeTransactions` calls, so keeping that is actually useful. And going from ABORTING to UNINITIALIZED would actually open up a window where a new `initializeTransactions` call would not be blocked, which seems bad. I think I'd prefer to keep this as is, anything else actually seems more complicated. It makes the transactional and idempotent paths slightly different, but I think it's more indicative of what each path is doing (we never set the ID and epoch to `None` in the transactional path, for example).",
        "createdAt" : "2020-02-12T17:45:34Z",
        "updatedAt" : "2020-02-15T22:01:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe88cc1ea6addd6c8597829bdfa41d9d1d68cef2",
    "line" : 145,
    "diffHunk" : "@@ -1,1 +245,249 @@                    return source == READY;\n                case INITIALIZING:\n                    return source == UNINITIALIZED || source == ABORTING_TRANSACTION;\n                case READY:\n                    return source == INITIALIZING || source == COMMITTING_TRANSACTION || source == ABORTING_TRANSACTION;"
  },
  {
    "id" : "ef85140a-32a7-482d-868d-72e2fb313b9f",
    "prId" : 7920,
    "prUrl" : "https://github.com/apache/kafka/pull/7920#pullrequestreview-343592884",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14ff96ec-3b58-4ecc-950c-52c94f841c43",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "qq: is that a piggy-backed fix, or is it necessary for the refactoring?",
        "createdAt" : "2020-01-15T22:29:34Z",
        "updatedAt" : "2020-01-23T00:20:39Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0d8179fb-b1c5-4bf5-8a11-6d1db837753e",
        "parentId" : "14ff96ec-3b58-4ecc-950c-52c94f841c43",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "More of an optimization than a fix I guess, but it simplified one of the tests in `TransactionManagerTest`. ",
        "createdAt" : "2020-01-15T23:35:13Z",
        "updatedAt" : "2020-01-23T00:20:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e45a5aec8150398eaec3a4aefaa37a07c65239f",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +418,422 @@        transitionTo(State.FATAL_ERROR, exception);\n\n        if (pendingResult != null) {\n            pendingResult.fail(exception);\n        }"
  },
  {
    "id" : "09b53271-ac77-4569-a802-653e643821a4",
    "prId" : 7920,
    "prUrl" : "https://github.com/apache/kafka/pull/7920#pullrequestreview-343636127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0fa029aa-7c1b-42b1-bc42-52de1aacf721",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Reducing visibility here to make sure that test cases are forced through the proper state transitions.",
        "createdAt" : "2020-01-16T02:04:49Z",
        "updatedAt" : "2020-01-23T00:20:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e45a5aec8150398eaec3a4aefaa37a07c65239f",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +455,459 @@     * Set the producer id and epoch atomically.\n     */\n    private void setProducerIdAndEpoch(ProducerIdAndEpoch producerIdAndEpoch) {\n        log.info(\"ProducerId set to {} with epoch {}\", producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n        this.producerIdAndEpoch = producerIdAndEpoch;"
  },
  {
    "id" : "15474339-7129-4b27-8144-d41ccfe45d16",
    "prId" : 7920,
    "prUrl" : "https://github.com/apache/kafka/pull/7920#pullrequestreview-346725058",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7a3a9c1-4c6a-46c8-8720-83ffbf5aa7d9",
        "parentId" : null,
        "authorId" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "body" : "Just FYI, for KIP-360 I'm doing this check for both idempotent and transactional, since it triggers an epoch bump instead of a producerId reset. I'll just pull this call out to a shared code path, the rest of this method shouldn't need to change.",
        "createdAt" : "2020-01-22T10:11:32Z",
        "updatedAt" : "2020-01-23T00:20:39Z",
        "lastEditedBy" : "e88252f3-8879-452a-8098-afb39cb614dc",
        "tags" : [
        ]
      },
      {
        "id" : "291216bf-b44d-46eb-ae7b-5b5e132a8aca",
        "parentId" : "c7a3a9c1-4c6a-46c8-8720-83ffbf5aa7d9",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Sounds good. We can rename the method as well.",
        "createdAt" : "2020-01-22T16:27:49Z",
        "updatedAt" : "2020-01-23T00:20:39Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e45a5aec8150398eaec3a4aefaa37a07c65239f",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +489,493 @@    synchronized void resetIdempotentProducerIdIfNeeded() {\n        if (!isTransactional()) {\n            if (shouldResetProducerStateAfterResolvingSequences()) {\n                // Check if the previous run expired batches which requires a reset of the producer state.\n                resetIdempotentProducerId();"
  },
  {
    "id" : "314663fd-9b79-4b3e-8b4c-087245ecbb44",
    "prId" : 7952,
    "prUrl" : "https://github.com/apache/kafka/pull/7952#pullrequestreview-343577450",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "161519fb-5ac0-4a0c-8031-9eb3f7d32b49",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "This separation is to avoid if-else loop complexity warning from checkstyle.",
        "createdAt" : "2020-01-15T22:54:30Z",
        "updatedAt" : "2020-01-22T18:43:33Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "e81e0daaec396ec5be7cc3d3cc2adae42f242e95",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +1511,1515 @@    }\n\n    private boolean isFatalException(Errors error) {\n        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n                   || error == Errors.INVALID_PRODUCER_EPOCH"
  },
  {
    "id" : "b09430a1-77ba-45da-8cf4-34a8cb965541",
    "prId" : 7952,
    "prUrl" : "https://github.com/apache/kafka/pull/7952#pullrequestreview-344131082",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf401d7a-fdee-4511-95b6-365ce3834ac8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`ConsumerGroupMetadata` does not have a proper `toString()` implementation -- if we want to log the object, we should add `ConsumerGroupMetadata#toString()` to ensure a readable log message.",
        "createdAt" : "2020-01-16T18:45:25Z",
        "updatedAt" : "2020-01-22T18:43:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e81e0daaec396ec5be7cc3d3cc2adae42f242e95",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +338,342 @@                    \"active transaction\");\n\n        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, groupMetadata);\n        AddOffsetsToTxnRequest.Builder builder = new AddOffsetsToTxnRequest.Builder(transactionalId,\n            producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, groupMetadata.groupId());"
  }
]