[
  {
    "id" : "7bc30566-c86e-4419-8d11-0d233dffa5ff",
    "prId" : 7967,
    "prUrl" : "https://github.com/apache/kafka/pull/7967#pullrequestreview-345022911",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e20a9c61-9d0f-49fc-92e0-3cbb13f99905",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@bdbyrne @hachikuji Currently on Producer.send our javadoc mentioned \"If a Kafka related error occurs that does not belong to the public API exceptions.\" for KafkaException and most callers default it to fatal. However if we consider the pattern where thread A blocked on send#bufferPool, and then thread B calls producer.close which would cause thread A to be unblocked by throwing a KafkaException to be a recommended pattern, should we use a different exception than KafkaException to differentiate it with other other fatal exceptions?\r\n\r\nI'm thinking for Streams if we eventually want to move to this pattern, i.e. the stream thread blocked on `producer.send` while the closing thread calls `producer.close` then stream thread would throw KafkaException that in turn would be interpreted as fatal and then the stream thread tries to shutdown itself as \"shutdown unclean\" whereas here since we are indeed closing we should just proceed with \"shutdown clean\" --- of course this is still doable with some extra check but I'm wondering if such complexity would be universal for any callers like Streams.",
        "createdAt" : "2020-01-19T20:08:02Z",
        "updatedAt" : "2020-01-19T20:08:04Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4c63d11596d51b9ddd8907fc23eefdb1f0588306",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +149,153 @@\n                        if (this.closed)\n                            throw new KafkaException(\"Producer closed while allocating memory\");\n\n                        if (waitingTimeElapsed) {"
  },
  {
    "id" : "10508edf-d385-41c3-afef-eb789fd4cc61",
    "prId" : 8399,
    "prUrl" : "https://github.com/apache/kafka/pull/8399#pullrequestreview-391686972",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eb5caf3-3450-44ca-9f80-113df68afea8",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since we mark the sensor here, there seems to be no need for the caller to know this is a BufferExhaustedException. Could we just throw TimeoutException and get rid of BufferExhaustedException?",
        "createdAt" : "2020-04-09T00:41:46Z",
        "updatedAt" : "2020-04-09T00:43:19Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "12ff6145-3911-4fb6-8c15-3e87c19b0e8a",
        "parentId" : "4eb5caf3-3450-44ca-9f80-113df68afea8",
        "authorId" : "2f3fbc93-2875-4df0-8f43-329c41f891e4",
        "body" : "We could absolutely do that. \r\nI'd say that depends on whether it would be useful for code that uses the producer to distinguish between a timeout during metadata refresh and a timeout waiting for the buffer to free up enough space.\r\nPersonally I see no harm in allowing this distinction and since BufferExhaustedException extends TimeoutException no one is forced to do this, they can just catch both in one try block.\r\n\r\nOn the other hand I also see no huge benefit, as you would not treat these two any differently in code - your record wasn't sent, you either do something about it or ignore it. Unless you want to dynamically reconfigure your producer with a larger buffer when this occurred I don't see a real use-case. Maybe someone else can come up with one?",
        "createdAt" : "2020-04-09T22:34:07Z",
        "updatedAt" : "2020-04-09T22:34:08Z",
        "lastEditedBy" : "2f3fbc93-2875-4df0-8f43-329c41f891e4",
        "tags" : [
        ]
      },
      {
        "id" : "e84e7afc-535e-4b71-98d7-dea91e002a76",
        "parentId" : "4eb5caf3-3450-44ca-9f80-113df68afea8",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Ok, we can keep this as its.",
        "createdAt" : "2020-04-10T22:17:51Z",
        "updatedAt" : "2020-04-10T22:18:15Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fba83628f3c0f1f094d11ec2f8dfa38d0f7c615",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +159,163 @@                        if (waitingTimeElapsed) {\n                            this.metrics.sensor(\"buffer-exhausted-records\").record();\n                            throw new BufferExhaustedException(\"Failed to allocate memory within the configured max blocking time \" + maxTimeToBlockMs + \" ms.\");\n                        }\n"
  }
]