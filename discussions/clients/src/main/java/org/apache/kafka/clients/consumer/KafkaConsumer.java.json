[
  {
    "id" : "34eec099-b158-4ccb-b1e2-0dd6c683b3f8",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96402531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "`retryBackoffMs` is typically much lower than request timeout. Should `poll(largeValue)`  poll until request timeout to fetch offsets? Perhaps not, just want to make sure I understand.",
        "createdAt" : "2018-02-13T22:07:20Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "82de8225-ee6d-4e50-83c4-3abcfc055b64",
        "parentId" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm trying to handle the case in which we are in the middle of a backoff after a failed offset fetch. There wouldn't be any pending IO in the worst case (say if we only had one partition assigned), so `poll()` would just block. We could alternatively do a bit more bookkeeping to keep track of when we are backing off, and when we have offset fetches pending, but it seemed simpler this way.",
        "createdAt" : "2018-02-14T07:21:47Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1166,1170 @@        // We do not want to be stuck blocking in poll if we are missing some positions\n        // since the offset lookup may be backing off after a failure\n        if (!hasAllFetchPositions && pollTimeout > retryBackoffMs)\n            pollTimeout = retryBackoffMs;\n"
  },
  {
    "id" : "51489b38-1d24-47ac-9d27-220a326303e0",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96465977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I thought this was changed because it actually requests something, but it is just setting a flag?",
        "createdAt" : "2018-02-13T22:09:38Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "4e80d391-da8e-417c-b663-f1607e82e94b",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I just didn't like the name. We had both `isOffsetResetNeeded` and `needOffsetReset`, which both sound like boolean flag checks. I wanted the mutation to be obvious in the name and I thought this was analogous with `Metadata.requestUpdate`. For some reason, we frown on names like `setOffsetResetNeeded`, but that would be an alternative which would arguably be less misleading.",
        "createdAt" : "2018-02-14T07:24:07Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ff8d4254-6fca-4c95-9e46-d98438dbc150",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "OK, since we have `Metadata.requestUpdate`, let's leave as is.",
        "createdAt" : "2018-02-14T11:34:51Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +1366,1370 @@            for (TopicPartition tp : parts) {\n                log.debug(\"Seeking to beginning of partition {}\", tp);\n                subscriptions.requestOffsetReset(tp, OffsetResetStrategy.EARLIEST);\n            }\n        } finally {"
  },
  {
    "id" : "0592813d-e584-4dda-b131-95afd8c9c6ea",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23d00e6d-4e97-4bba-b21e-c8bed8bcd1cc",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note this new exception.",
        "createdAt" : "2018-05-22T18:08:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 181,
    "diffHunk" : "@@ -1,1 +1138,1142 @@     * @throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any\n     *             partitions to consume from\n     * @throws java.lang.ArithmeticException if the timeout is greater than {@link Long#MAX_VALUE} milliseconds.\n     */\n    @Override"
  },
  {
    "id" : "508fb7ce-bb68-444d-b2fa-a9ef1352be5e",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99256ca1-915f-41ac-afdd-b2059992d721",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:14:49Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 391,
    "diffHunk" : "@@ -1,1 +1499,1503 @@                while (!updateFetchPositions(Long.MAX_VALUE)) {\n                    log.warn(\"Still updating fetch positions\");\n                }\n                client.poll(retryBackoffMs);\n                offset = this.subscriptions.position(partition);"
  },
  {
    "id" : "c205486e-802a-4055-8795-710a10532aca",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "837257d9-99de-4442-ab6c-52db440dcb2e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:15:14Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 406,
    "diffHunk" : "@@ -1,1 +1536,1540 @@                    Long.MAX_VALUE\n                );\n            }\n            return offsets.get(partition);\n        } finally {"
  },
  {
    "id" : "38ee4747-356f-4e27-be79-43bccc546b1b",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d19d9104-0d7e-46ef-abe6-0a6948835138",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This method used to block indefinitely, so we have to add a timeout parameter. Callers need to know whether it timed out or not, and they can easily check directly if all partitions have an assigned position, so we're using the boolean return value to indicate whether the operation completed or timed out.\r\n\r\nWe could throw and catch timeout exceptions instead, but I felt it was cleaner to return instead, and we can also avoid a context switch this way.",
        "createdAt" : "2018-05-22T18:28:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "70902e3f-647b-4670-9d9e-8921087235fe",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2f13b62-d20c-44eb-9fd5-85e59150007c",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "If this call times out, then `updateFetchPositions` as a whole times out.",
        "createdAt" : "2018-05-22T18:30:45Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 472,
    "diffHunk" : "@@ -1,1 +1865,1869 @@        // a consumer with manually assigned partitions can avoid a coordinator dependence\n        // by always ensuring that assigned partitions have an initial position.\n        if (!coordinator.refreshCommittedOffsetsIfNeeded(timeoutMs)) return false;\n\n        // If there are partitions still needing a position and a reset policy is defined,"
  },
  {
    "id" : "2e270569-883c-413b-9f02-ae586d660999",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123041406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is a bit of a meta comment. We have structured all of these internal APIs to use a timeout. It makes sense in isolation, but when you have a sequence of operations, it's annoying to repeatedly recompute the remaining time. I wonder what it would look like to structure them in terms of deadlines instead. So we just compute a deadline at the start of the call in `KafkaConsumer` and carry it through each operation.\r\n\r\nThe other thing is that we seem to have more calls to system time than we had before. For example, there are three in `internalUpdateAssignmentMetadataIfNeeded` which would hit every call to poll(). It may not seem like a big deal, but we have actually found it to be a performance bottleneck in some cases, which is why we do seemingly silly optimizations like passing around the current time. Consider a case where someone configures `max.poll.records` to 1, then every record return to the user will be accompanied by a bunch of system calls. It would be nice to reduce these calls at least for the common path where we have all our offsets and we are just awaiting fetches.",
        "createdAt" : "2018-05-23T22:22:46Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a4abf3dc-3ca3-43f6-871a-25ea696a6888",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The deadline thing would be more elegant, but I'm concerned that, carelessly applied, it would spider through the clients code base; I think I'd wind up changing much more than I strictly have to. I'm not opposed, and I'll go ahead and give it a crack to see what it looks like, just wanted to point this out.",
        "createdAt" : "2018-05-24T15:09:15Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8bfde804-7f8d-4a81-83f3-b06bc16cb188",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "About the extra calls to system time... Yeah, I did that deliberately because it made the code simpler, but I didn't consider that the call itself could become a bottleneck, which is completely plausible. I'll switch it back to the prior strategy, of only checking the time when it really matters.\r\n\r\nApplying the deadline-instead-of-timeout approach would also save one call to system time at the start of every method to get the \"startTime\".",
        "createdAt" : "2018-05-24T15:13:31Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "c0f20e15-fa77-4ada-bf13-cb7db9647d5c",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123563710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We might also consider moving this into `SubscriptionState`? We can invalidate the value whenever the assignment changes or an offset is reset. That would also give us a shortcut for `missingFetchPositions()`. ",
        "createdAt" : "2018-05-25T22:15:07Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0452318a-4f56-429f-82ff-f66e00abfc16",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think we'd better defer this for later.",
        "createdAt" : "2018-05-25T23:51:34Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "246882c1-b17e-4cc9-845e-103cf77def19",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Sounds good.",
        "createdAt" : "2018-05-26T18:24:09Z",
        "updatedAt" : "2018-05-26T18:24:09Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 301,
    "diffHunk" : "@@ -1,1 +1231,1235 @@        // NOTE: the use of cachedSubscriptionHashAllFetchPositions means we MUST call\n        // updateAssignmentMetadataIfNeeded before this method.\n        if (!cachedSubscriptionHashAllFetchPositions && pollTimeout > retryBackoffMs) {\n            pollTimeout = retryBackoffMs;\n        }"
  },
  {
    "id" : "5690df7c-545f-46c5-913b-e7ecc9d2fb8e",
    "prId" : 5084,
    "prUrl" : "https://github.com/apache/kafka/pull/5084#pullrequestreview-124629683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could we update the KIP wiki: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=75974886#KIP-266:AddTimeoutExceptiontoKafkaConsumer#position()-Consumer#committedandConsumer#commitSync\r\n\r\nas well?",
        "createdAt" : "2018-05-30T22:50:57Z",
        "updatedAt" : "2018-05-30T22:50:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "952cdab4-b728-4e24-9f79-c5ed0b4aa0c9",
        "parentId" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ack, will do. I've had the editor on that wiki open since this morning, but keep getting distracted.",
        "createdAt" : "2018-05-30T23:34:52Z",
        "updatedAt" : "2018-05-30T23:34:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea9fe01ef54c446cfddb36fba41218d989f6e275",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +1323,1327 @@     */\n    @Override\n    public void commitSync(Duration timeout) {\n        acquireAndEnsureOpen();\n        try {"
  },
  {
    "id" : "d7ff8421-2e42-484c-9982-cba719088a87",
    "prId" : 5087,
    "prUrl" : "https://github.com/apache/kafka/pull/5087#pullrequestreview-145406094",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acdef6fc-6c85-48f8-94ca-5273d5013126",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@hachikuji I found this issue overlooked during the review: it should be `timeout` here..",
        "createdAt" : "2018-08-10T21:39:29Z",
        "updatedAt" : "2018-08-10T21:39:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ef469881a5e14aecbaa3dbe890d30335c2c75a8",
    "line" : 227,
    "diffHunk" : "@@ -1,1 +1750,1754 @@                return parts;\n\n            Timer timer = time.timer(requestTimeoutMs);\n            Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                    new MetadataRequest.Builder(Collections.singletonList(topic), true), timer);"
  },
  {
    "id" : "eaeb9cb9-c5c2-4ce6-b2e2-dde8283d9ae5",
    "prId" : 5383,
    "prUrl" : "https://github.com/apache/kafka/pull/5383#pullrequestreview-151046189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01bbbd92-804a-4ab2-ae0b-c69dc416774b",
        "parentId" : null,
        "authorId" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "body" : "nit: please add protected keyword",
        "createdAt" : "2018-08-23T23:09:35Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "tags" : [
        ]
      },
      {
        "id" : "21421804-1c7e-403e-a9b4-ad7530fd9fd4",
        "parentId" : "01bbbd92-804a-4ab2-ae0b-c69dc416774b",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "`protected` gives more visibility than what's there now (`package visibility`) so not sure why we'd want to do that?",
        "createdAt" : "2018-08-30T15:15:21Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee59e6985e64c8109b71f4501d83dd5ed4d38158",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +2214,2218 @@\n    // Visible for testing\n    String getClientId() {\n        return clientId;\n    }"
  },
  {
    "id" : "cfb7786f-0000-4076-b025-47d2b44966b9",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-145414501",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a34a720-363a-46b6-91be-b91facfcae27",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for fixing https://github.com/apache/kafka/pull/5087/files#r209391022. cc @hachikuji ",
        "createdAt" : "2018-08-10T22:24:18Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1750,1754 @@                return parts;\n\n            Timer timer = time.timer(timeout);\n            Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                    new MetadataRequest.Builder(Collections.singletonList(topic), true), timer);"
  },
  {
    "id" : "3e0a6730-a1ac-441a-9e75-e7504bb17e86",
    "prId" : 5877,
    "prUrl" : "https://github.com/apache/kafka/pull/5877#pullrequestreview-175661898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3af6240d-81bc-4d92-9361-5c5e8b9b3ea6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Shouldn't we handle the `else` case? I was thinking that if the user enables auto commit explicitly, but provides no group id, then we should raise a configuration exception.",
        "createdAt" : "2018-11-15T08:00:27Z",
        "updatedAt" : "2018-11-16T08:55:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "fa0c4b08-c753-4275-9397-a2e9d304da57",
        "parentId" : "3af6240d-81bc-4d92-9361-5c5e8b9b3ea6",
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "What I had here was to let the consumer run and throw an exception when a commit is triggered (or even earlier when e.g. `subscribe` is called). But I think your suggestion makes more sense because it points directly to the root cause, i.e. the misconfiguration. Updated in the new patch.",
        "createdAt" : "2018-11-16T05:27:28Z",
        "updatedAt" : "2018-11-16T08:55:52Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      }
    ],
    "commit" : "f8b1b9ef3edffefc1b11d99055968dca2e09c1fb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +669,673 @@            boolean enableAutoCommit = config.getBoolean(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG);\n            if (groupId == null) { // overwrite in case of default group id where the config is not explicitly provided\n                if (!config.originals().containsKey(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG))\n                    enableAutoCommit = false;\n                else if (enableAutoCommit)"
  },
  {
    "id" : "98f8471b-d8dd-4630-a3bf-ed9f3e0fd124",
    "prId" : 6045,
    "prUrl" : "https://github.com/apache/kafka/pull/6045#pullrequestreview-189982682",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb70bf8a-8614-4c64-b9c2-217f17dfd844",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We should add this API to the `Consumer` interface.",
        "createdAt" : "2019-01-07T21:01:33Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba0768420c04aa546906895016671fd544ff38f",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1520,1524 @@     */\n    @Override\n    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {"
  },
  {
    "id" : "61c22675-97eb-4c66-b3a2-452f4285ca64",
    "prId" : 6045,
    "prUrl" : "https://github.com/apache/kafka/pull/6045#pullrequestreview-190872253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e47e8132-379c-421e-ab33-662cc25faa2b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Since this is the more general method, would it make sense to change `seek(TopicPartition, long)` to delegate to this?",
        "createdAt" : "2019-01-09T00:20:41Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0bab6807-15c8-4050-a32d-9c291327b194",
        "parentId" : "e47e8132-379c-421e-ab33-662cc25faa2b",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "done",
        "createdAt" : "2019-01-09T18:42:20Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba0768420c04aa546906895016671fd544ff38f",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1520,1524 @@     */\n    @Override\n    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {"
  },
  {
    "id" : "60e81853-f127-4c77-ac1f-61b1204fe393",
    "prId" : 6279,
    "prUrl" : "https://github.com/apache/kafka/pull/6279#pullrequestreview-204540667",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3350fb5-0a7d-4853-8961-1e865e2c9da8",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I guess we may as well make a similar change in `seekToEnd`?",
        "createdAt" : "2019-02-17T00:37:45Z",
        "updatedAt" : "2019-02-17T00:43:44Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "de7ba6a8-10dc-42a9-88e9-5d3b86bbbaf1",
        "parentId" : "e3350fb5-0a7d-4853-8961-1e865e2c9da8",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Good point, done.",
        "createdAt" : "2019-02-17T00:44:21Z",
        "updatedAt" : "2019-02-17T00:44:21Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "96dc4b58f076dc65871c450db7b47cfdb508835f",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +1557,1561 @@            Collection<TopicPartition> parts = partitions.size() == 0 ? this.subscriptions.assignedPartitions() : partitions;\n            for (TopicPartition tp : parts) {\n                log.info(\"Seeking to beginning of partition {}\", tp);\n                subscriptions.requestOffsetReset(tp, OffsetResetStrategy.EARLIEST);\n            }"
  },
  {
    "id" : "20a7b18b-e163-4548-b995-8382be62fa96",
    "prId" : 6299,
    "prUrl" : "https://github.com/apache/kafka/pull/6299#pullrequestreview-206415421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6dcc53ec-033b-4a2c-90cb-57884634c354",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Is there a reason why you added quotes here but not elsewhere?",
        "createdAt" : "2019-02-21T16:40:40Z",
        "updatedAt" : "2019-02-21T16:41:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "6abe36d7-bbef-4f28-ac86-c2f787bb2778",
        "parentId" : "6dcc53ec-033b-4a2c-90cb-57884634c354",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The regex may have funny characters. I thought it would be helpful to have it clearly delimited.",
        "createdAt" : "2019-02-21T16:43:17Z",
        "updatedAt" : "2019-02-21T19:21:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "60970222ff7a9528f4e4100c2c0365f3594ee97c",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +997,1001 @@        try {\n            throwIfNoAssignorsConfigured();\n            log.info(\"Subscribed to pattern: '{}'\", pattern);\n            this.subscriptions.subscribe(pattern, listener);\n            this.metadata.needMetadataForAllTopics(true);"
  },
  {
    "id" : "6b50a054-e2c3-4b96-8417-878bae6e4363",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228048411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69a3da99-c58c-40a5-8baa-a20682318dbd",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is interesting. There is always a race with the next leader election for a valid position. Do you think we need to be strict about the timing? I guess if you provide an epoch in seek(), this would be a good way to force validation before fetching.",
        "createdAt" : "2019-04-18T02:19:08Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +1679,1683 @@            Timer timer = time.timer(timeout);\n            do {\n                SubscriptionState.FetchPosition position = this.subscriptions.validPosition(partition);\n                if (position != null)\n                    return position.offset;"
  },
  {
    "id" : "0190d2c8-d905-439d-958d-ce6f827e9d96",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228048411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1501bc97-5f68-4362-bac2-a35f7377d1cb",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Already mentioned, but I think we can be smarter about caching some state to avoid unnecessary work here. Validation is only needed if we do an unprotected seek or a metadata update arrives. Probably this can be left for a follow-up. It's only a concern when the number of partitions and the poll frequency is high.",
        "createdAt" : "2019-04-18T02:20:57Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +2218,2222 @@    private boolean updateFetchPositions(final Timer timer) {\n        // If any partitions have been truncated due to a leader change, we need to validate the offsets\n        fetcher.validateOffsetsIfNeeded();\n\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();"
  },
  {
    "id" : "a3b69087-183c-4773-bd84-ed7a4091e8a1",
    "prId" : 6650,
    "prUrl" : "https://github.com/apache/kafka/pull/6650#pullrequestreview-235889184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think commitAsync cannot throw exception directly: only if you registered a callback, then the callback can expose the exception?",
        "createdAt" : "2019-05-09T23:23:00Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d9d95b79-b080-4f06-9151-537b00056f47",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "@guozhangwang Actually it could, when calling `invokeCompletedOffsetCommitCallbacks` it will potentially throw the fenced instance exception.",
        "createdAt" : "2019-05-09T23:58:02Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "b0831abf-6011-4d3c-9ed4-eb80618f463f",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I see. I thought the trace a bit different though: when you call `commitAsync` -> `coordinator.commitOffsetsAsync` -> `invokeCompletedOffsetCommitCallbacks` note that `invokeCompletedOffsetCommitCallbacks` call is just to clear the previous async commit's callback, if there are any, but not related to this commit --- they will be only sent over after that call returns. Which means, if that exception is thrown from `commitAsync`, it would not be for this offset-to-commit, but for a previous call. \r\n\r\nBut from user's perspective, if it's fenced, it's fenced, no matter if it was triggered by this call or a previous call. So the javadoc looks good.",
        "createdAt" : "2019-05-10T00:05:34Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a7846eef-9a19-4255-a145-db78a3557914",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Yes, great summary here. It is trying to populate exception for previous round, so either from `poll` or `commitAsync` calling `invokeCompletedOffsetCommitCallbacks`",
        "createdAt" : "2019-05-10T01:12:27Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a0c245434329139d931b0cc904704ef8c26a62c",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +1460,1464 @@     * Commit offsets returned on the last {@link #poll(Duration)} for all the subscribed list of topics and partition.\n     * Same as {@link #commitAsync(OffsetCommitCallback) commitAsync(null)}\n     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if this consumer instance gets fenced by broker.\n     */\n    @Override"
  },
  {
    "id" : "67d435bb-be3c-40b6-8d8c-bf8adab08d31",
    "prId" : 6884,
    "prUrl" : "https://github.com/apache/kafka/pull/6884#pullrequestreview-271732485",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d494d8a9-041c-4ced-83ac-bfba82aa9d99",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It might be worth mentioning in the upgrade notes the fact that we now invoke revocation logic in `unsubscribe` and `close`.",
        "createdAt" : "2019-08-07T00:44:53Z",
        "updatedAt" : "2019-08-08T21:28:14Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "97632325-ac43-4bc3-a24d-492dc0b71700",
        "parentId" : "d494d8a9-041c-4ced-83ac-bfba82aa9d99",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yes, that's in my plan -- I have another PR on web docs for the changes related, but wanted to keep this one from continue growing.",
        "createdAt" : "2019-08-07T05:16:12Z",
        "updatedAt" : "2019-08-08T21:28:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6041a792f58b0b9a38983a60e052e9018319a6e6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1048,1052 @@     * This also clears any partitions directly assigned through {@link #assign(Collection)}.\n     *\n     * @throws org.apache.kafka.common.KafkaException for any other unrecoverable errors (e.g. rebalance callback errors)\n     */\n    public void unsubscribe() {"
  },
  {
    "id" : "01a30043-0c9d-4cab-b3e4-e8888920e8b5",
    "prId" : 7304,
    "prUrl" : "https://github.com/apache/kafka/pull/7304#pullrequestreview-288387050",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b10dc4e3-240c-4745-a299-584b11807abe",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "nit: Should the description here match https://github.com/apache/kafka/pull/7304/files#diff-267b7c1e68156c1301c56be63ae41dd0R1779-R1782 from above with the exception that the user specifies the timeout in this case.",
        "createdAt" : "2019-09-10T16:01:53Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "54216473-c135-423b-9318-bef15ca06cb1",
        "parentId" : "b10dc4e3-240c-4745-a299-584b11807abe",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack.",
        "createdAt" : "2019-09-15T23:17:20Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bc8bf0f0703bf557bff6c8ae5c9a347599c8d4f",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +1814,1818 @@     * If any of the partitions requested do not exist, an exception would be thrown.\n     * <p>\n     * This call will block to do a remote call to get the latest committed offsets from the server.\n     *\n     * @param partitions The partitions to check"
  },
  {
    "id" : "3ade4fd8-2dd1-4d64-82de-94fcd1171e97",
    "prId" : 7304,
    "prUrl" : "https://github.com/apache/kafka/pull/7304#pullrequestreview-288941698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbd63f90-c9bd-4b2c-9cf2-43f7708c770e",
        "parentId" : null,
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Minor: Probably obvious, but since this doc is pretty good about being clear on details, maybe it is worth pointing out that this is for the consumer group?",
        "createdAt" : "2019-09-16T15:28:06Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "b45e270c-b03d-450c-840e-560d0193a208",
        "parentId" : "bbd63f90-c9bd-4b2c-9cf2-43f7708c770e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Actually even if the consumer is not part of a group and not using subscribe as well it can still commit offsets, and others can get its committed offsets as long as they know its group.id.",
        "createdAt" : "2019-09-16T22:52:26Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bc8bf0f0703bf557bff6c8ae5c9a347599c8d4f",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +1775,1779 @@\n    /**\n     * Get the last committed offsets for the given partitions (whether the commit happened by this process or\n     * another). The returned offsets will be used as the position for the consumer in the event of a failure.\n     * <p>"
  },
  {
    "id" : "3a993e34-10fd-4796-9578-78727cc2f39c",
    "prId" : 7304,
    "prUrl" : "https://github.com/apache/kafka/pull/7304#pullrequestreview-288945898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58fb8caf-499d-4d0d-b577-905255cdab96",
        "parentId" : null,
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Now that we're batching calls it might be nice to return all of the valid ones we received and some marker for those we did not.\r\n\r\nSans that, we should specify what type of exception you get and it would be nice to be able to get details about which partitions did not exist.",
        "createdAt" : "2019-09-16T15:31:12Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "d329d398-29aa-4ad3-984b-dd18ed4cbfd1",
        "parentId" : "58fb8caf-499d-4d0d-b577-905255cdab96",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I've thought about that when discussing about KIP-520, e.g. on admin client when getting committed offsets we return a `map<topic-partition, future<>>` and each future can either be an exception or the actual value. But for consumer we do not have such APIs so I've decided to stick with consistency.\r\n\r\nAs for the exception, it would indicate which topic-partition(s) do not exist.",
        "createdAt" : "2019-09-16T22:55:06Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f8e8ab0f-2185-4027-bca9-5dd167706404",
        "parentId" : "58fb8caf-499d-4d0d-b577-905255cdab96",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Sounds reasonable. Is the non-existant topic partition list accessible programmatically or just in the exception text? The former seems a bit nicer in allowing for potential recovery at runtime.",
        "createdAt" : "2019-09-16T23:06:52Z",
        "updatedAt" : "2019-09-20T20:04:08Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bc8bf0f0703bf557bff6c8ae5c9a347599c8d4f",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +1812,1816 @@     * Partitions that do not have a committed offset would not be included in the returned map.\n     * <p>\n     * If any of the partitions requested do not exist, an exception would be thrown.\n     * <p>\n     * This call will block to do a remote call to get the latest committed offsets from the server."
  },
  {
    "id" : "1cdeb91f-49a6-4a0a-890c-586e674bf2c0",
    "prId" : 7312,
    "prUrl" : "https://github.com/apache/kafka/pull/7312#pullrequestreview-330236618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93f6c44c-2d4d-4fcb-833c-35a5df642753",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "nit: Can we make this more specific, or maybe provide examples? eg this happens if you try to commit offsets for partitions you don't own, or you fell out of the group",
        "createdAt" : "2019-12-11T00:36:27Z",
        "updatedAt" : "2020-01-09T19:24:32Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "27f76b7b68256a0b935ed2ffb490616718608782",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +1427,1431 @@     *\n     * @param offsets A map of offsets by partition with associated metadata\n     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n     *             This can only occur if you are using automatic group management with {@link #subscribe(Collection)},\n     *             or if there is an active group with the same <code>group.id</code> which is using group management. In such cases,"
  },
  {
    "id" : "f8681090-55d1-4ec9-b101-ef6e0e6cd44e",
    "prId" : 7312,
    "prUrl" : "https://github.com/apache/kafka/pull/7312#pullrequestreview-336271055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74e3e137-49a6-445c-b28d-fa3e32b7ee82",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This seems a little self-contradictory... The next throws declaration says that if I'm not in the group, I can call `poll` to rejoin and retry the commit. But this javadoc seems to suggest that if I get the `CommitFailedException`, I can definitely not retry the commit. Should it instead just simply say that I'm trying to commit partitions that I no longer own? I.e., that I _am_ an active member of the group (because I have assigned partitions), but I don't own some of the partitions I'm trying to commit offsets on?\r\n\r\nAlso, what happens if I _do_ still own some other partitions? How can I know whether or not those got committed?",
        "createdAt" : "2019-12-12T18:32:27Z",
        "updatedAt" : "2020-01-09T19:24:33Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "fa47e8f9-c576-4d10-ba70-c2e600075928",
        "parentId" : "74e3e137-49a6-445c-b28d-fa3e32b7ee82",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "If you try to commit and it fails because you no longer own some (or any) partitions because a rebalance just occurred, that's retriable. If you dropped out of the group and for that reason do not own those (or any) partitions, that's not retriable.\r\n@guozhangwang I do agree that we could clarify the wording a bit: in particular, it seems to matter explicitly _why_ the consumer no longer owns those partitions",
        "createdAt" : "2019-12-17T23:21:32Z",
        "updatedAt" : "2020-01-09T19:24:33Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e44612a4-5398-4cd2-8659-3ecbfc0c2a61",
        "parentId" : "74e3e137-49a6-445c-b28d-fa3e32b7ee82",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yup, I've reworded the statement a bit.",
        "createdAt" : "2019-12-24T22:05:28Z",
        "updatedAt" : "2020-01-09T19:24:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "27f76b7b68256a0b935ed2ffb490616718608782",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +1376,1380 @@     *             or if there is an active group with the same <code>group.id</code> which is using group management. In such cases,\n     *             when you are trying to commit to partitions that are no longer assigned to this consumer because the\n     *             consumer is for example no longer part of the group this exception would be thrown.\n     * @throws org.apache.kafka.common.errors.RebalanceInProgressException if the consumer instance is in the middle of a rebalance\n     *            so it is not yet determined which partitions would be assigned to the consumer. In such cases you can first"
  },
  {
    "id" : "7c52bf36-e2d8-49e8-a48b-a25f81b1812c",
    "prId" : 7514,
    "prUrl" : "https://github.com/apache/kafka/pull/7514#pullrequestreview-302010300",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e80ff6e-17ac-48fe-8411-69176913cd18",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: do we need the \"\" in the end for conversion? I think Java is smart enough without it.",
        "createdAt" : "2019-10-15T01:54:12Z",
        "updatedAt" : "2019-10-15T01:54:49Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e92b4248-d4d1-4e77-9991-51d1be9548c0",
        "parentId" : "8e80ff6e-17ac-48fe-8411-69176913cd18",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It doesn't compile without it because the supplier passed to `orElseGet` must have type `Supplier<? extends String>`.",
        "createdAt" : "2019-10-15T15:41:14Z",
        "updatedAt" : "2019-10-15T15:41:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f4c21a43ef9bb76ff01a19ba9ab447497d49b60",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +861,865 @@        if (rebalanceConfig.groupId != null && !rebalanceConfig.groupId.isEmpty())\n            return \"consumer-\" + rebalanceConfig.groupId + \"-\" + rebalanceConfig.groupInstanceId.orElseGet(() ->\n                    CONSUMER_CLIENT_ID_SEQUENCE.getAndIncrement() + \"\");\n\n        return \"consumer-\" + CONSUMER_CLIENT_ID_SEQUENCE.getAndIncrement();"
  },
  {
    "id" : "dc0e2d20-acba-4c03-afc1-2b322ad82607",
    "prId" : 7590,
    "prUrl" : "https://github.com/apache/kafka/pull/7590#pullrequestreview-309573730",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "266f9169-23df-49d2-be3b-a27767c7714f",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Why did we make this not final?",
        "createdAt" : "2019-10-30T21:49:34Z",
        "updatedAt" : "2019-10-30T21:49:34Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "802c398e-d5de-4f5a-84b0-03f048957dfc",
        "parentId" : "266f9169-23df-49d2-be3b-a27767c7714f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Because when an error is thrown at initializing groupInstanceConfig, the log would not be initialized yet where we checked it ` == null` below.",
        "createdAt" : "2019-10-30T23:10:06Z",
        "updatedAt" : "2019-10-30T23:10:06Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e4cbe9622bc8db07113fab9edf498ada9697395",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +569,573 @@    final KafkaConsumerMetrics kafkaConsumerMetrics;\n\n    private Logger log;\n    private final String clientId;\n    private String groupId;"
  },
  {
    "id" : "64fda156-d314-4b9a-9510-881d2e57d802",
    "prId" : 7613,
    "prUrl" : "https://github.com/apache/kafka/pull/7613#pullrequestreview-311377903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54b50fa0-f96a-4b60-9662-ceb1ae4d0b7e",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Would it be more robust to also wrap the whole if statement in a try/catch?\r\nMy understanding is that we never want to throw an exception after we've updated the positions in `pollForFetches()`.\r\n\r\n\r\n> If an exception is thrown and the callers decide to capture and continue, those records would never be returned again, causing data loss.\r\n\r\nFor my edification, what else can the caller do to not lose data in this scenario?",
        "createdAt" : "2019-10-30T09:38:06Z",
        "updatedAt" : "2019-11-05T03:14:32Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "7971420b-1bc6-48ed-b6d5-758f3c3cd136",
        "parentId" : "54b50fa0-f96a-4b60-9662-ceb1ae4d0b7e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "if we `try-catch` the block, we still need to \"remember\" whatever errors was thrown so that later callers can still be informed of such errors otherwise they will be swallowed silently. So I think \"not checking them\" is actually better since this is a one-off best-effort send shot anyways.",
        "createdAt" : "2019-10-30T17:16:37Z",
        "updatedAt" : "2019-11-05T03:14:32Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "3ddb5a0a-57d9-4bef-bb83-acccf022be0a",
        "parentId" : "54b50fa0-f96a-4b60-9662-ceb1ae4d0b7e",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The errors that we are trying to handle here are already remembered anyway (primarily inside of `Metadata`). So they will still get thrown on the next call to `poll`.",
        "createdAt" : "2019-11-04T21:42:44Z",
        "updatedAt" : "2019-11-05T03:14:32Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6162e14bec895c0b7abafec33394ee11cb25a75d",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +1249,1253 @@                    // NOTE: since the consumed position has already been updated, we must not allow\n                    // wakeups or any other errors to be triggered prior to returning the fetched records.\n                    if (fetcher.sendFetches() > 0 || client.hasPendingRequests()) {\n                        client.transmitSends();\n                    }"
  },
  {
    "id" : "8a7ba75e-1677-4137-91b0-f05708b34919",
    "prId" : 7943,
    "prUrl" : "https://github.com/apache/kafka/pull/7943#pullrequestreview-342792811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06f0834b-5ea9-4eed-8ba2-881897ec033a",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Perhaps we can improve this. If the groupId is null, perhaps we can leave it out of the log context?",
        "createdAt" : "2020-01-13T21:42:37Z",
        "updatedAt" : "2020-01-13T21:42:38Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "268f8462-66fb-44af-9c1d-6f49b136a833",
        "parentId" : "06f0834b-5ea9-4eed-8ba2-881897ec033a",
        "authorId" : "8e51c258-6d35-4135-935a-9dfcd20079b7",
        "body" : "I admit that 'null' is not flattering, but I was preserving the current behavior.  Would you like something else?  We can improve this is a follow-up JIRA if you'd like to discuss.",
        "createdAt" : "2020-01-13T23:41:17Z",
        "updatedAt" : "2020-01-13T23:41:17Z",
        "lastEditedBy" : "8e51c258-6d35-4135-935a-9dfcd20079b7",
        "tags" : [
        ]
      },
      {
        "id" : "01e5ad6d-ea20-45a2-8796-74087d4623b1",
        "parentId" : "06f0834b-5ea9-4eed-8ba2-881897ec033a",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We can do it separately if you like.",
        "createdAt" : "2020-01-14T19:44:52Z",
        "updatedAt" : "2020-01-14T19:44:53Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "56e89874bd53f5a859f7659cff45ed0b9b12c9e1",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +682,686 @@            if (groupRebalanceConfig.groupInstanceId.isPresent()) {\n                logContext = new LogContext(\"[Consumer instanceId=\" + groupRebalanceConfig.groupInstanceId.get() +\n                        \", clientId=\" + clientId + \", groupId=\" + groupId.orElse(\"null\") + \"] \");\n            } else {\n                logContext = new LogContext(\"[Consumer clientId=\" + clientId + \", groupId=\" + groupId.orElse(\"null\") + \"] \");"
  }
]