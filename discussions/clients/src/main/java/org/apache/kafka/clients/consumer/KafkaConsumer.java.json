[
  {
    "id" : "34eec099-b158-4ccb-b1e2-0dd6c683b3f8",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96402531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "`retryBackoffMs` is typically much lower than request timeout. Should `poll(largeValue)`  poll until request timeout to fetch offsets? Perhaps not, just want to make sure I understand.",
        "createdAt" : "2018-02-13T22:07:20Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "82de8225-ee6d-4e50-83c4-3abcfc055b64",
        "parentId" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm trying to handle the case in which we are in the middle of a backoff after a failed offset fetch. There wouldn't be any pending IO in the worst case (say if we only had one partition assigned), so `poll()` would just block. We could alternatively do a bit more bookkeeping to keep track of when we are backing off, and when we have offset fetches pending, but it seemed simpler this way.",
        "createdAt" : "2018-02-14T07:21:47Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1166,1170 @@        // We do not want to be stuck blocking in poll if we are missing some positions\n        // since the offset lookup may be backing off after a failure\n        if (!hasAllFetchPositions && pollTimeout > retryBackoffMs)\n            pollTimeout = retryBackoffMs;\n"
  },
  {
    "id" : "51489b38-1d24-47ac-9d27-220a326303e0",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96465977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I thought this was changed because it actually requests something, but it is just setting a flag?",
        "createdAt" : "2018-02-13T22:09:38Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "4e80d391-da8e-417c-b663-f1607e82e94b",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I just didn't like the name. We had both `isOffsetResetNeeded` and `needOffsetReset`, which both sound like boolean flag checks. I wanted the mutation to be obvious in the name and I thought this was analogous with `Metadata.requestUpdate`. For some reason, we frown on names like `setOffsetResetNeeded`, but that would be an alternative which would arguably be less misleading.",
        "createdAt" : "2018-02-14T07:24:07Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ff8d4254-6fca-4c95-9e46-d98438dbc150",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "OK, since we have `Metadata.requestUpdate`, let's leave as is.",
        "createdAt" : "2018-02-14T11:34:51Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +1366,1370 @@            for (TopicPartition tp : parts) {\n                log.debug(\"Seeking to beginning of partition {}\", tp);\n                subscriptions.requestOffsetReset(tp, OffsetResetStrategy.EARLIEST);\n            }\n        } finally {"
  },
  {
    "id" : "0592813d-e584-4dda-b131-95afd8c9c6ea",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23d00e6d-4e97-4bba-b21e-c8bed8bcd1cc",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note this new exception.",
        "createdAt" : "2018-05-22T18:08:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 181,
    "diffHunk" : "@@ -1,1 +1138,1142 @@     * @throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any\n     *             partitions to consume from\n     * @throws java.lang.ArithmeticException if the timeout is greater than {@link Long#MAX_VALUE} milliseconds.\n     */\n    @Override"
  },
  {
    "id" : "508fb7ce-bb68-444d-b2fa-a9ef1352be5e",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99256ca1-915f-41ac-afdd-b2059992d721",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:14:49Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 391,
    "diffHunk" : "@@ -1,1 +1499,1503 @@                while (!updateFetchPositions(Long.MAX_VALUE)) {\n                    log.warn(\"Still updating fetch positions\");\n                }\n                client.poll(retryBackoffMs);\n                offset = this.subscriptions.position(partition);"
  },
  {
    "id" : "c205486e-802a-4055-8795-710a10532aca",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "837257d9-99de-4442-ab6c-52db440dcb2e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:15:14Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 406,
    "diffHunk" : "@@ -1,1 +1536,1540 @@                    Long.MAX_VALUE\n                );\n            }\n            return offsets.get(partition);\n        } finally {"
  },
  {
    "id" : "38ee4747-356f-4e27-be79-43bccc546b1b",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d19d9104-0d7e-46ef-abe6-0a6948835138",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This method used to block indefinitely, so we have to add a timeout parameter. Callers need to know whether it timed out or not, and they can easily check directly if all partitions have an assigned position, so we're using the boolean return value to indicate whether the operation completed or timed out.\r\n\r\nWe could throw and catch timeout exceptions instead, but I felt it was cleaner to return instead, and we can also avoid a context switch this way.",
        "createdAt" : "2018-05-22T18:28:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "70902e3f-647b-4670-9d9e-8921087235fe",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2f13b62-d20c-44eb-9fd5-85e59150007c",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "If this call times out, then `updateFetchPositions` as a whole times out.",
        "createdAt" : "2018-05-22T18:30:45Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 472,
    "diffHunk" : "@@ -1,1 +1865,1869 @@        // a consumer with manually assigned partitions can avoid a coordinator dependence\n        // by always ensuring that assigned partitions have an initial position.\n        if (!coordinator.refreshCommittedOffsetsIfNeeded(timeoutMs)) return false;\n\n        // If there are partitions still needing a position and a reset policy is defined,"
  },
  {
    "id" : "2e270569-883c-413b-9f02-ae586d660999",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123041406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is a bit of a meta comment. We have structured all of these internal APIs to use a timeout. It makes sense in isolation, but when you have a sequence of operations, it's annoying to repeatedly recompute the remaining time. I wonder what it would look like to structure them in terms of deadlines instead. So we just compute a deadline at the start of the call in `KafkaConsumer` and carry it through each operation.\r\n\r\nThe other thing is that we seem to have more calls to system time than we had before. For example, there are three in `internalUpdateAssignmentMetadataIfNeeded` which would hit every call to poll(). It may not seem like a big deal, but we have actually found it to be a performance bottleneck in some cases, which is why we do seemingly silly optimizations like passing around the current time. Consider a case where someone configures `max.poll.records` to 1, then every record return to the user will be accompanied by a bunch of system calls. It would be nice to reduce these calls at least for the common path where we have all our offsets and we are just awaiting fetches.",
        "createdAt" : "2018-05-23T22:22:46Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a4abf3dc-3ca3-43f6-871a-25ea696a6888",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The deadline thing would be more elegant, but I'm concerned that, carelessly applied, it would spider through the clients code base; I think I'd wind up changing much more than I strictly have to. I'm not opposed, and I'll go ahead and give it a crack to see what it looks like, just wanted to point this out.",
        "createdAt" : "2018-05-24T15:09:15Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8bfde804-7f8d-4a81-83f3-b06bc16cb188",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "About the extra calls to system time... Yeah, I did that deliberately because it made the code simpler, but I didn't consider that the call itself could become a bottleneck, which is completely plausible. I'll switch it back to the prior strategy, of only checking the time when it really matters.\r\n\r\nApplying the deadline-instead-of-timeout approach would also save one call to system time at the start of every method to get the \"startTime\".",
        "createdAt" : "2018-05-24T15:13:31Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "c0f20e15-fa77-4ada-bf13-cb7db9647d5c",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123563710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We might also consider moving this into `SubscriptionState`? We can invalidate the value whenever the assignment changes or an offset is reset. That would also give us a shortcut for `missingFetchPositions()`. ",
        "createdAt" : "2018-05-25T22:15:07Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0452318a-4f56-429f-82ff-f66e00abfc16",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think we'd better defer this for later.",
        "createdAt" : "2018-05-25T23:51:34Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "246882c1-b17e-4cc9-845e-103cf77def19",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Sounds good.",
        "createdAt" : "2018-05-26T18:24:09Z",
        "updatedAt" : "2018-05-26T18:24:09Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 301,
    "diffHunk" : "@@ -1,1 +1231,1235 @@        // NOTE: the use of cachedSubscriptionHashAllFetchPositions means we MUST call\n        // updateAssignmentMetadataIfNeeded before this method.\n        if (!cachedSubscriptionHashAllFetchPositions && pollTimeout > retryBackoffMs) {\n            pollTimeout = retryBackoffMs;\n        }"
  },
  {
    "id" : "5690df7c-545f-46c5-913b-e7ecc9d2fb8e",
    "prId" : 5084,
    "prUrl" : "https://github.com/apache/kafka/pull/5084#pullrequestreview-124629683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could we update the KIP wiki: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=75974886#KIP-266:AddTimeoutExceptiontoKafkaConsumer#position()-Consumer#committedandConsumer#commitSync\r\n\r\nas well?",
        "createdAt" : "2018-05-30T22:50:57Z",
        "updatedAt" : "2018-05-30T22:50:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "952cdab4-b728-4e24-9f79-c5ed0b4aa0c9",
        "parentId" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ack, will do. I've had the editor on that wiki open since this morning, but keep getting distracted.",
        "createdAt" : "2018-05-30T23:34:52Z",
        "updatedAt" : "2018-05-30T23:34:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea9fe01ef54c446cfddb36fba41218d989f6e275",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +1323,1327 @@     */\n    @Override\n    public void commitSync(Duration timeout) {\n        acquireAndEnsureOpen();\n        try {"
  },
  {
    "id" : "d7ff8421-2e42-484c-9982-cba719088a87",
    "prId" : 5087,
    "prUrl" : "https://github.com/apache/kafka/pull/5087#pullrequestreview-145406094",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acdef6fc-6c85-48f8-94ca-5273d5013126",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@hachikuji I found this issue overlooked during the review: it should be `timeout` here..",
        "createdAt" : "2018-08-10T21:39:29Z",
        "updatedAt" : "2018-08-10T21:39:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ef469881a5e14aecbaa3dbe890d30335c2c75a8",
    "line" : 227,
    "diffHunk" : "@@ -1,1 +1750,1754 @@                return parts;\n\n            Timer timer = time.timer(requestTimeoutMs);\n            Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                    new MetadataRequest.Builder(Collections.singletonList(topic), true), timer);"
  },
  {
    "id" : "eaeb9cb9-c5c2-4ce6-b2e2-dde8283d9ae5",
    "prId" : 5383,
    "prUrl" : "https://github.com/apache/kafka/pull/5383#pullrequestreview-151046189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01bbbd92-804a-4ab2-ae0b-c69dc416774b",
        "parentId" : null,
        "authorId" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "body" : "nit: please add protected keyword",
        "createdAt" : "2018-08-23T23:09:35Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "2d677cb0-7f58-4f02-8104-880b46eb7fb3",
        "tags" : [
        ]
      },
      {
        "id" : "21421804-1c7e-403e-a9b4-ad7530fd9fd4",
        "parentId" : "01bbbd92-804a-4ab2-ae0b-c69dc416774b",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "`protected` gives more visibility than what's there now (`package visibility`) so not sure why we'd want to do that?",
        "createdAt" : "2018-08-30T15:15:21Z",
        "updatedAt" : "2018-10-01T22:09:56Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee59e6985e64c8109b71f4501d83dd5ed4d38158",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +2214,2218 @@\n    // Visible for testing\n    String getClientId() {\n        return clientId;\n    }"
  },
  {
    "id" : "cfb7786f-0000-4076-b025-47d2b44966b9",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-145414501",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a34a720-363a-46b6-91be-b91facfcae27",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for fixing https://github.com/apache/kafka/pull/5087/files#r209391022. cc @hachikuji ",
        "createdAt" : "2018-08-10T22:24:18Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1750,1754 @@                return parts;\n\n            Timer timer = time.timer(timeout);\n            Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                    new MetadataRequest.Builder(Collections.singletonList(topic), true), timer);"
  },
  {
    "id" : "3e0a6730-a1ac-441a-9e75-e7504bb17e86",
    "prId" : 5877,
    "prUrl" : "https://github.com/apache/kafka/pull/5877#pullrequestreview-175661898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3af6240d-81bc-4d92-9361-5c5e8b9b3ea6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Shouldn't we handle the `else` case? I was thinking that if the user enables auto commit explicitly, but provides no group id, then we should raise a configuration exception.",
        "createdAt" : "2018-11-15T08:00:27Z",
        "updatedAt" : "2018-11-16T08:55:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "fa0c4b08-c753-4275-9397-a2e9d304da57",
        "parentId" : "3af6240d-81bc-4d92-9361-5c5e8b9b3ea6",
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "What I had here was to let the consumer run and throw an exception when a commit is triggered (or even earlier when e.g. `subscribe` is called). But I think your suggestion makes more sense because it points directly to the root cause, i.e. the misconfiguration. Updated in the new patch.",
        "createdAt" : "2018-11-16T05:27:28Z",
        "updatedAt" : "2018-11-16T08:55:52Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      }
    ],
    "commit" : "f8b1b9ef3edffefc1b11d99055968dca2e09c1fb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +669,673 @@            boolean enableAutoCommit = config.getBoolean(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG);\n            if (groupId == null) { // overwrite in case of default group id where the config is not explicitly provided\n                if (!config.originals().containsKey(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG))\n                    enableAutoCommit = false;\n                else if (enableAutoCommit)"
  },
  {
    "id" : "98f8471b-d8dd-4630-a3bf-ed9f3e0fd124",
    "prId" : 6045,
    "prUrl" : "https://github.com/apache/kafka/pull/6045#pullrequestreview-189982682",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb70bf8a-8614-4c64-b9c2-217f17dfd844",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We should add this API to the `Consumer` interface.",
        "createdAt" : "2019-01-07T21:01:33Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba0768420c04aa546906895016671fd544ff38f",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1520,1524 @@     */\n    @Override\n    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {"
  },
  {
    "id" : "61c22675-97eb-4c66-b3a2-452f4285ca64",
    "prId" : 6045,
    "prUrl" : "https://github.com/apache/kafka/pull/6045#pullrequestreview-190872253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e47e8132-379c-421e-ab33-662cc25faa2b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Since this is the more general method, would it make sense to change `seek(TopicPartition, long)` to delegate to this?",
        "createdAt" : "2019-01-09T00:20:41Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0bab6807-15c8-4050-a32d-9c291327b194",
        "parentId" : "e47e8132-379c-421e-ab33-662cc25faa2b",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "done",
        "createdAt" : "2019-01-09T18:42:20Z",
        "updatedAt" : "2019-01-17T15:43:00Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba0768420c04aa546906895016671fd544ff38f",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1520,1524 @@     */\n    @Override\n    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {"
  },
  {
    "id" : "60e81853-f127-4c77-ac1f-61b1204fe393",
    "prId" : 6279,
    "prUrl" : "https://github.com/apache/kafka/pull/6279#pullrequestreview-204540667",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3350fb5-0a7d-4853-8961-1e865e2c9da8",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I guess we may as well make a similar change in `seekToEnd`?",
        "createdAt" : "2019-02-17T00:37:45Z",
        "updatedAt" : "2019-02-17T00:43:44Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "de7ba6a8-10dc-42a9-88e9-5d3b86bbbaf1",
        "parentId" : "e3350fb5-0a7d-4853-8961-1e865e2c9da8",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Good point, done.",
        "createdAt" : "2019-02-17T00:44:21Z",
        "updatedAt" : "2019-02-17T00:44:21Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "96dc4b58f076dc65871c450db7b47cfdb508835f",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +1557,1561 @@            Collection<TopicPartition> parts = partitions.size() == 0 ? this.subscriptions.assignedPartitions() : partitions;\n            for (TopicPartition tp : parts) {\n                log.info(\"Seeking to beginning of partition {}\", tp);\n                subscriptions.requestOffsetReset(tp, OffsetResetStrategy.EARLIEST);\n            }"
  },
  {
    "id" : "20a7b18b-e163-4548-b995-8382be62fa96",
    "prId" : 6299,
    "prUrl" : "https://github.com/apache/kafka/pull/6299#pullrequestreview-206415421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6dcc53ec-033b-4a2c-90cb-57884634c354",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Is there a reason why you added quotes here but not elsewhere?",
        "createdAt" : "2019-02-21T16:40:40Z",
        "updatedAt" : "2019-02-21T16:41:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "6abe36d7-bbef-4f28-ac86-c2f787bb2778",
        "parentId" : "6dcc53ec-033b-4a2c-90cb-57884634c354",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The regex may have funny characters. I thought it would be helpful to have it clearly delimited.",
        "createdAt" : "2019-02-21T16:43:17Z",
        "updatedAt" : "2019-02-21T19:21:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "60970222ff7a9528f4e4100c2c0365f3594ee97c",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +997,1001 @@        try {\n            throwIfNoAssignorsConfigured();\n            log.info(\"Subscribed to pattern: '{}'\", pattern);\n            this.subscriptions.subscribe(pattern, listener);\n            this.metadata.needMetadataForAllTopics(true);"
  },
  {
    "id" : "6b50a054-e2c3-4b96-8417-878bae6e4363",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228048411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69a3da99-c58c-40a5-8baa-a20682318dbd",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is interesting. There is always a race with the next leader election for a valid position. Do you think we need to be strict about the timing? I guess if you provide an epoch in seek(), this would be a good way to force validation before fetching.",
        "createdAt" : "2019-04-18T02:19:08Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +1679,1683 @@            Timer timer = time.timer(timeout);\n            do {\n                SubscriptionState.FetchPosition position = this.subscriptions.validPosition(partition);\n                if (position != null)\n                    return position.offset;"
  },
  {
    "id" : "0190d2c8-d905-439d-958d-ce6f827e9d96",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228048411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1501bc97-5f68-4362-bac2-a35f7377d1cb",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Already mentioned, but I think we can be smarter about caching some state to avoid unnecessary work here. Validation is only needed if we do an unprotected seek or a metadata update arrives. Probably this can be left for a follow-up. It's only a concern when the number of partitions and the poll frequency is high.",
        "createdAt" : "2019-04-18T02:20:57Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +2218,2222 @@    private boolean updateFetchPositions(final Timer timer) {\n        // If any partitions have been truncated due to a leader change, we need to validate the offsets\n        fetcher.validateOffsetsIfNeeded();\n\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();"
  },
  {
    "id" : "a3b69087-183c-4773-bd84-ed7a4091e8a1",
    "prId" : 6650,
    "prUrl" : "https://github.com/apache/kafka/pull/6650#pullrequestreview-235889184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think commitAsync cannot throw exception directly: only if you registered a callback, then the callback can expose the exception?",
        "createdAt" : "2019-05-09T23:23:00Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d9d95b79-b080-4f06-9151-537b00056f47",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "@guozhangwang Actually it could, when calling `invokeCompletedOffsetCommitCallbacks` it will potentially throw the fenced instance exception.",
        "createdAt" : "2019-05-09T23:58:02Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "b0831abf-6011-4d3c-9ed4-eb80618f463f",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I see. I thought the trace a bit different though: when you call `commitAsync` -> `coordinator.commitOffsetsAsync` -> `invokeCompletedOffsetCommitCallbacks` note that `invokeCompletedOffsetCommitCallbacks` call is just to clear the previous async commit's callback, if there are any, but not related to this commit --- they will be only sent over after that call returns. Which means, if that exception is thrown from `commitAsync`, it would not be for this offset-to-commit, but for a previous call. \r\n\r\nBut from user's perspective, if it's fenced, it's fenced, no matter if it was triggered by this call or a previous call. So the javadoc looks good.",
        "createdAt" : "2019-05-10T00:05:34Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a7846eef-9a19-4255-a145-db78a3557914",
        "parentId" : "9074fae0-b74c-432e-bbd9-cf288ae89e20",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Yes, great summary here. It is trying to populate exception for previous round, so either from `poll` or `commitAsync` calling `invokeCompletedOffsetCommitCallbacks`",
        "createdAt" : "2019-05-10T01:12:27Z",
        "updatedAt" : "2019-05-18T04:04:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a0c245434329139d931b0cc904704ef8c26a62c",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +1460,1464 @@     * Commit offsets returned on the last {@link #poll(Duration)} for all the subscribed list of topics and partition.\n     * Same as {@link #commitAsync(OffsetCommitCallback) commitAsync(null)}\n     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if this consumer instance gets fenced by broker.\n     */\n    @Override"
  }
]