[
  {
    "id" : "34eec099-b158-4ccb-b1e2-0dd6c683b3f8",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96402531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "`retryBackoffMs` is typically much lower than request timeout. Should `poll(largeValue)`  poll until request timeout to fetch offsets? Perhaps not, just want to make sure I understand.",
        "createdAt" : "2018-02-13T22:07:20Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "82de8225-ee6d-4e50-83c4-3abcfc055b64",
        "parentId" : "554144dd-b77e-4cd4-b818-195a5bc8caf7",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm trying to handle the case in which we are in the middle of a backoff after a failed offset fetch. There wouldn't be any pending IO in the worst case (say if we only had one partition assigned), so `poll()` would just block. We could alternatively do a bit more bookkeeping to keep track of when we are backing off, and when we have offset fetches pending, but it seemed simpler this way.",
        "createdAt" : "2018-02-14T07:21:47Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1166,1170 @@        // We do not want to be stuck blocking in poll if we are missing some positions\n        // since the offset lookup may be backing off after a failure\n        if (!hasAllFetchPositions && pollTimeout > retryBackoffMs)\n            pollTimeout = retryBackoffMs;\n"
  },
  {
    "id" : "51489b38-1d24-47ac-9d27-220a326303e0",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96465977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I thought this was changed because it actually requests something, but it is just setting a flag?",
        "createdAt" : "2018-02-13T22:09:38Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "4e80d391-da8e-417c-b663-f1607e82e94b",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I just didn't like the name. We had both `isOffsetResetNeeded` and `needOffsetReset`, which both sound like boolean flag checks. I wanted the mutation to be obvious in the name and I thought this was analogous with `Metadata.requestUpdate`. For some reason, we frown on names like `setOffsetResetNeeded`, but that would be an alternative which would arguably be less misleading.",
        "createdAt" : "2018-02-14T07:24:07Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ff8d4254-6fca-4c95-9e46-d98438dbc150",
        "parentId" : "595a739f-2453-4a6b-bca7-9c8b01bcbefc",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "OK, since we have `Metadata.requestUpdate`, let's leave as is.",
        "createdAt" : "2018-02-14T11:34:51Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +1366,1370 @@            for (TopicPartition tp : parts) {\n                log.debug(\"Seeking to beginning of partition {}\", tp);\n                subscriptions.requestOffsetReset(tp, OffsetResetStrategy.EARLIEST);\n            }\n        } finally {"
  },
  {
    "id" : "0592813d-e584-4dda-b131-95afd8c9c6ea",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23d00e6d-4e97-4bba-b21e-c8bed8bcd1cc",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note this new exception.",
        "createdAt" : "2018-05-22T18:08:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 181,
    "diffHunk" : "@@ -1,1 +1138,1142 @@     * @throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any\n     *             partitions to consume from\n     * @throws java.lang.ArithmeticException if the timeout is greater than {@link Long#MAX_VALUE} milliseconds.\n     */\n    @Override"
  },
  {
    "id" : "508fb7ce-bb68-444d-b2fa-a9ef1352be5e",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99256ca1-915f-41ac-afdd-b2059992d721",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:14:49Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 391,
    "diffHunk" : "@@ -1,1 +1499,1503 @@                while (!updateFetchPositions(Long.MAX_VALUE)) {\n                    log.warn(\"Still updating fetch positions\");\n                }\n                client.poll(retryBackoffMs);\n                offset = this.subscriptions.position(partition);"
  },
  {
    "id" : "c205486e-802a-4055-8795-710a10532aca",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "837257d9-99de-4442-ab6c-52db440dcb2e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "preserving the old blocking behavior, even though the internal method now takes a timeout.",
        "createdAt" : "2018-05-22T18:15:14Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 406,
    "diffHunk" : "@@ -1,1 +1536,1540 @@                    Long.MAX_VALUE\n                );\n            }\n            return offsets.get(partition);\n        } finally {"
  },
  {
    "id" : "38ee4747-356f-4e27-be79-43bccc546b1b",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d19d9104-0d7e-46ef-abe6-0a6948835138",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This method used to block indefinitely, so we have to add a timeout parameter. Callers need to know whether it timed out or not, and they can easily check directly if all partitions have an assigned position, so we're using the boolean return value to indicate whether the operation completed or timed out.\r\n\r\nWe could throw and catch timeout exceptions instead, but I felt it was cleaner to return instead, and we can also avoid a context switch this way.",
        "createdAt" : "2018-05-22T18:28:22Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "70902e3f-647b-4670-9d9e-8921087235fe",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-122280843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2f13b62-d20c-44eb-9fd5-85e59150007c",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "If this call times out, then `updateFetchPositions` as a whole times out.",
        "createdAt" : "2018-05-22T18:30:45Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 472,
    "diffHunk" : "@@ -1,1 +1865,1869 @@        // a consumer with manually assigned partitions can avoid a coordinator dependence\n        // by always ensuring that assigned partitions have an initial position.\n        if (!coordinator.refreshCommittedOffsetsIfNeeded(timeoutMs)) return false;\n\n        // If there are partitions still needing a position and a reset policy is defined,"
  },
  {
    "id" : "2e270569-883c-413b-9f02-ae586d660999",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123041406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is a bit of a meta comment. We have structured all of these internal APIs to use a timeout. It makes sense in isolation, but when you have a sequence of operations, it's annoying to repeatedly recompute the remaining time. I wonder what it would look like to structure them in terms of deadlines instead. So we just compute a deadline at the start of the call in `KafkaConsumer` and carry it through each operation.\r\n\r\nThe other thing is that we seem to have more calls to system time than we had before. For example, there are three in `internalUpdateAssignmentMetadataIfNeeded` which would hit every call to poll(). It may not seem like a big deal, but we have actually found it to be a performance bottleneck in some cases, which is why we do seemingly silly optimizations like passing around the current time. Consider a case where someone configures `max.poll.records` to 1, then every record return to the user will be accompanied by a bunch of system calls. It would be nice to reduce these calls at least for the common path where we have all our offsets and we are just awaiting fetches.",
        "createdAt" : "2018-05-23T22:22:46Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a4abf3dc-3ca3-43f6-871a-25ea696a6888",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The deadline thing would be more elegant, but I'm concerned that, carelessly applied, it would spider through the clients code base; I think I'd wind up changing much more than I strictly have to. I'm not opposed, and I'll go ahead and give it a crack to see what it looks like, just wanted to point this out.",
        "createdAt" : "2018-05-24T15:09:15Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8bfde804-7f8d-4a81-83f3-b06bc16cb188",
        "parentId" : "d71a5812-9e3f-40b9-9900-7475e76b2772",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "About the extra calls to system time... Yeah, I did that deliberately because it made the code simpler, but I didn't consider that the call itself could become a bottleneck, which is completely plausible. I'll switch it back to the prior strategy, of only checking the time when it really matters.\r\n\r\nApplying the deadline-instead-of-timeout approach would also save one call to system time at the start of every method to get the \"startTime\".",
        "createdAt" : "2018-05-24T15:13:31Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 462,
    "diffHunk" : "@@ -1,1 +1856,1860 @@     * @return true iff the operation completed without timing out\n     */\n    private boolean updateFetchPositions(final long timeoutMs) {\n        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();\n        if (cachedSubscriptionHashAllFetchPositions) return true;"
  },
  {
    "id" : "c0f20e15-fa77-4ada-bf13-cb7db9647d5c",
    "prId" : 4855,
    "prUrl" : "https://github.com/apache/kafka/pull/4855#pullrequestreview-123563710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We might also consider moving this into `SubscriptionState`? We can invalidate the value whenever the assignment changes or an offset is reset. That would also give us a shortcut for `missingFetchPositions()`. ",
        "createdAt" : "2018-05-25T22:15:07Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0452318a-4f56-429f-82ff-f66e00abfc16",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think we'd better defer this for later.",
        "createdAt" : "2018-05-25T23:51:34Z",
        "updatedAt" : "2018-05-26T00:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "246882c1-b17e-4cc9-845e-103cf77def19",
        "parentId" : "3c2e2d93-6e05-449b-b879-51409e951b4f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Sounds good.",
        "createdAt" : "2018-05-26T18:24:09Z",
        "updatedAt" : "2018-05-26T18:24:09Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3fce0f22e8b12e03475212b2bf07e69bc230362",
    "line" : 301,
    "diffHunk" : "@@ -1,1 +1231,1235 @@        // NOTE: the use of cachedSubscriptionHashAllFetchPositions means we MUST call\n        // updateAssignmentMetadataIfNeeded before this method.\n        if (!cachedSubscriptionHashAllFetchPositions && pollTimeout > retryBackoffMs) {\n            pollTimeout = retryBackoffMs;\n        }"
  },
  {
    "id" : "5690df7c-545f-46c5-913b-e7ecc9d2fb8e",
    "prId" : 5084,
    "prUrl" : "https://github.com/apache/kafka/pull/5084#pullrequestreview-124629683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could we update the KIP wiki: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=75974886#KIP-266:AddTimeoutExceptiontoKafkaConsumer#position()-Consumer#committedandConsumer#commitSync\r\n\r\nas well?",
        "createdAt" : "2018-05-30T22:50:57Z",
        "updatedAt" : "2018-05-30T22:50:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "952cdab4-b728-4e24-9f79-c5ed0b4aa0c9",
        "parentId" : "c7c35bd6-3d06-47d9-ba73-ee55428a2efa",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ack, will do. I've had the editor on that wiki open since this morning, but keep getting distracted.",
        "createdAt" : "2018-05-30T23:34:52Z",
        "updatedAt" : "2018-05-30T23:34:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea9fe01ef54c446cfddb36fba41218d989f6e275",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +1323,1327 @@     */\n    @Override\n    public void commitSync(Duration timeout) {\n        acquireAndEnsureOpen();\n        try {"
  },
  {
    "id" : "d7ff8421-2e42-484c-9982-cba719088a87",
    "prId" : 5087,
    "prUrl" : "https://github.com/apache/kafka/pull/5087#pullrequestreview-145406094",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acdef6fc-6c85-48f8-94ca-5273d5013126",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@hachikuji I found this issue overlooked during the review: it should be `timeout` here..",
        "createdAt" : "2018-08-10T21:39:29Z",
        "updatedAt" : "2018-08-10T21:39:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ef469881a5e14aecbaa3dbe890d30335c2c75a8",
    "line" : 227,
    "diffHunk" : "@@ -1,1 +1750,1754 @@                return parts;\n\n            Timer timer = time.timer(requestTimeoutMs);\n            Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                    new MetadataRequest.Builder(Collections.singletonList(topic), true), timer);"
  }
]