[
  {
    "id" : "2ffead69-4cec-4d60-9b76-8b272c629c7e",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-95859553",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bae74676-eb5b-4c79-b180-e234dfc20389",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Is it possible that offsetResetTimestamps is empty ?",
        "createdAt" : "2018-02-12T03:24:42Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "608ab8d6-48c8-4faa-aeae-d7cb002a7099",
        "parentId" : "bae74676-eb5b-4c79-b180-e234dfc20389",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It is possible, but seems fine? We could even get rid of the empty check a couple lines above.",
        "createdAt" : "2018-02-12T16:46:00Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 217,
    "diffHunk" : "@@ -1,1 +375,379 @@        }\n\n        resetOffsetsAsync(offsetResetTimestamps);\n    }\n"
  },
  {
    "id" : "7dee546e-3db7-4fbc-a004-ffc212cd2cc0",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96404008",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd70a793-b531-4e5e-9f47-98478d13a824",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "What do we do if one of the exceptions is not retriable (e.g UNSUPPORTED_FOR_MESSAGE_FORMAT)? It seems to be handled differently from `TOPIC_AUTHORIZATION_FAILED`, but I wasn't sure why.",
        "createdAt" : "2018-02-13T23:06:03Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "c429894e-0e14-4692-af64-9a599d0d0b9a",
        "parentId" : "dd70a793-b531-4e5e-9f47-98478d13a824",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We treat `UNSUPPORTED_FOR_MESSAGE_FORMAT` as equivalent to not finding an offset for the timestamp being searched. It makes sense because timestamps didn't exist in the old format. I can clarify this in the comment.",
        "createdAt" : "2018-02-14T07:31:28Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 614,
    "diffHunk" : "@@ -1,1 +788,792 @@            future.raise(new TopicAuthorizationException(unauthorizedTopics));\n        else\n            future.complete(new ListOffsetResult(fetchedOffsets, partitionsToRetry));\n    }\n"
  },
  {
    "id" : "6f0dcd8e-5a1e-43e6-ade3-998b8def62e0",
    "prId" : 5495,
    "prUrl" : "https://github.com/apache/kafka/pull/5495#pullrequestreview-146008624",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "parentId" : null,
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Wouldn't it be enough to lock on the given instance of the FetchSessionHandler given that's the object that runs into a concurrent modification? This way as I understand we completely evict concurrency from the sendFetches method for a given instance.\r\nAlso I would generally prefer using a lock object instead of locking on `this`. The reason is that this way the synchronized is externalized to the public API (well in this case it is arguable since it's an _internals_ class), + it enables accidental lock stealing, ie. a different class locking on Fetcher.this. I don't know if this is a concern now though.",
        "createdAt" : "2018-08-13T13:41:41Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "17a8ce92-820e-4599-9f52-9222d1eb2e54",
        "parentId" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "@viktorsomogyi Thanks for the review. There is also a `sessionHandlers` HashMap. That would need to become a `ConcurrentHashMap`. I wasn't sure if there was any other state. We do broad locking of the coordinator for thread-safety, I thought the same for `Fetcher` would be the simplest and safest fix. Since this code is generally single-threaded and locking is only to avoid concurrent access in the heartbeat thread, I am not sure it matters so much. Will wait for @hachikuji 's review and then update if required.",
        "createdAt" : "2018-08-14T10:10:02Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "47080302-621e-4678-b1f7-d33361c71070",
        "parentId" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "I see, then it's probably ok. I was missing the detail about the `sessionHandlers` map, but thanks for the heads-up :).",
        "createdAt" : "2018-08-14T10:45:29Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "b379bf19b941c9e97d243f8fc2175147a9fab6e8",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +206,210 @@     * @return number of fetches sent\n     */\n    public synchronized int sendFetches() {\n        Map<Node, FetchSessionHandler.FetchRequestData> fetchRequestMap = prepareFetchRequests();\n        for (Map.Entry<Node, FetchSessionHandler.FetchRequestData> entry : fetchRequestMap.entrySet()) {"
  },
  {
    "id" : "5279ad4b-5c8c-4e68-ad6c-3f03ebd09e67",
    "prId" : 5627,
    "prUrl" : "https://github.com/apache/kafka/pull/5627#pullrequestreview-153980869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6fae6ccd-875e-450c-94b2-53b3ca2cad30",
        "parentId" : null,
        "authorId" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "body" : "I moved the logic for getting the list of partitions that do not have available leader to `groupListOffsetRequests` . I was contemplating whether we should add partition for which we have a failed connection to leader to `partitionsToRetry`. Seems like we should, because we may be able to reconnect before the list offsets timeout. ",
        "createdAt" : "2018-09-10T22:02:42Z",
        "updatedAt" : "2018-09-10T23:39:54Z",
        "lastEditedBy" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f8fbd8a0a66124cffd3a95a15fe8464dd3ae92b",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +695,699 @@                log.debug(\"Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires\",\n                          info.leader(), tp);\n                partitionsToRetry.add(tp);\n            } else {\n                Node node = info.leader();"
  },
  {
    "id" : "9ea10ce5-eaa6-45ea-b071-fa3479cf42a5",
    "prId" : 5991,
    "prUrl" : "https://github.com/apache/kafka/pull/5991#pullrequestreview-182458401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b546855b-aecb-47bc-b2fd-f7d970d6040a",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be nice to add a couple test cases to make sure the expected behavior won't regress.",
        "createdAt" : "2018-12-06T22:00:00Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "54d8dd54100b18957db07485d9ee0c37ad4476c8",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +813,817 @@                       error == Errors.REPLICA_NOT_AVAILABLE ||\n                       error == Errors.KAFKA_STORAGE_ERROR ||\n                       error == Errors.OFFSET_NOT_AVAILABLE ||\n                       error == Errors.LEADER_NOT_AVAILABLE) {\n                log.debug(\"Attempt to fetch offsets for partition {} failed due to {}, retrying.\","
  }
]