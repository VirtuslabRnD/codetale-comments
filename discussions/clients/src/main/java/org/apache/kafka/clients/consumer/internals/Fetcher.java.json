[
  {
    "id" : "2ffead69-4cec-4d60-9b76-8b272c629c7e",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-95859553",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bae74676-eb5b-4c79-b180-e234dfc20389",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Is it possible that offsetResetTimestamps is empty ?",
        "createdAt" : "2018-02-12T03:24:42Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "608ab8d6-48c8-4faa-aeae-d7cb002a7099",
        "parentId" : "bae74676-eb5b-4c79-b180-e234dfc20389",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It is possible, but seems fine? We could even get rid of the empty check a couple lines above.",
        "createdAt" : "2018-02-12T16:46:00Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 217,
    "diffHunk" : "@@ -1,1 +375,379 @@        }\n\n        resetOffsetsAsync(offsetResetTimestamps);\n    }\n"
  },
  {
    "id" : "7dee546e-3db7-4fbc-a004-ffc212cd2cc0",
    "prId" : 4557,
    "prUrl" : "https://github.com/apache/kafka/pull/4557#pullrequestreview-96404008",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd70a793-b531-4e5e-9f47-98478d13a824",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "What do we do if one of the exceptions is not retriable (e.g UNSUPPORTED_FOR_MESSAGE_FORMAT)? It seems to be handled differently from `TOPIC_AUTHORIZATION_FAILED`, but I wasn't sure why.",
        "createdAt" : "2018-02-13T23:06:03Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "c429894e-0e14-4692-af64-9a599d0d0b9a",
        "parentId" : "dd70a793-b531-4e5e-9f47-98478d13a824",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We treat `UNSUPPORTED_FOR_MESSAGE_FORMAT` as equivalent to not finding an offset for the timestamp being searched. It makes sense because timestamps didn't exist in the old format. I can clarify this in the comment.",
        "createdAt" : "2018-02-14T07:31:28Z",
        "updatedAt" : "2018-02-14T15:55:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "76c796ca128c3c97231f3ebda994a07bb06b26aa",
    "line" : 614,
    "diffHunk" : "@@ -1,1 +788,792 @@            future.raise(new TopicAuthorizationException(unauthorizedTopics));\n        else\n            future.complete(new ListOffsetResult(fetchedOffsets, partitionsToRetry));\n    }\n"
  },
  {
    "id" : "6f0dcd8e-5a1e-43e6-ade3-998b8def62e0",
    "prId" : 5495,
    "prUrl" : "https://github.com/apache/kafka/pull/5495#pullrequestreview-146008624",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "parentId" : null,
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Wouldn't it be enough to lock on the given instance of the FetchSessionHandler given that's the object that runs into a concurrent modification? This way as I understand we completely evict concurrency from the sendFetches method for a given instance.\r\nAlso I would generally prefer using a lock object instead of locking on `this`. The reason is that this way the synchronized is externalized to the public API (well in this case it is arguable since it's an _internals_ class), + it enables accidental lock stealing, ie. a different class locking on Fetcher.this. I don't know if this is a concern now though.",
        "createdAt" : "2018-08-13T13:41:41Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      },
      {
        "id" : "17a8ce92-820e-4599-9f52-9222d1eb2e54",
        "parentId" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "@viktorsomogyi Thanks for the review. There is also a `sessionHandlers` HashMap. That would need to become a `ConcurrentHashMap`. I wasn't sure if there was any other state. We do broad locking of the coordinator for thread-safety, I thought the same for `Fetcher` would be the simplest and safest fix. Since this code is generally single-threaded and locking is only to avoid concurrent access in the heartbeat thread, I am not sure it matters so much. Will wait for @hachikuji 's review and then update if required.",
        "createdAt" : "2018-08-14T10:10:02Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "47080302-621e-4678-b1f7-d33361c71070",
        "parentId" : "14d0e4a8-bf79-4bc5-9e88-b53543bf50f5",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "I see, then it's probably ok. I was missing the detail about the `sessionHandlers` map, but thanks for the heads-up :).",
        "createdAt" : "2018-08-14T10:45:29Z",
        "updatedAt" : "2018-09-14T14:43:43Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "b379bf19b941c9e97d243f8fc2175147a9fab6e8",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +206,210 @@     * @return number of fetches sent\n     */\n    public synchronized int sendFetches() {\n        Map<Node, FetchSessionHandler.FetchRequestData> fetchRequestMap = prepareFetchRequests();\n        for (Map.Entry<Node, FetchSessionHandler.FetchRequestData> entry : fetchRequestMap.entrySet()) {"
  },
  {
    "id" : "5279ad4b-5c8c-4e68-ad6c-3f03ebd09e67",
    "prId" : 5627,
    "prUrl" : "https://github.com/apache/kafka/pull/5627#pullrequestreview-153980869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6fae6ccd-875e-450c-94b2-53b3ca2cad30",
        "parentId" : null,
        "authorId" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "body" : "I moved the logic for getting the list of partitions that do not have available leader to `groupListOffsetRequests` . I was contemplating whether we should add partition for which we have a failed connection to leader to `partitionsToRetry`. Seems like we should, because we may be able to reconnect before the list offsets timeout. ",
        "createdAt" : "2018-09-10T22:02:42Z",
        "updatedAt" : "2018-09-10T23:39:54Z",
        "lastEditedBy" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f8fbd8a0a66124cffd3a95a15fe8464dd3ae92b",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +695,699 @@                log.debug(\"Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires\",\n                          info.leader(), tp);\n                partitionsToRetry.add(tp);\n            } else {\n                Node node = info.leader();"
  },
  {
    "id" : "9ea10ce5-eaa6-45ea-b071-fa3479cf42a5",
    "prId" : 5991,
    "prUrl" : "https://github.com/apache/kafka/pull/5991#pullrequestreview-182458401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b546855b-aecb-47bc-b2fd-f7d970d6040a",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be nice to add a couple test cases to make sure the expected behavior won't regress.",
        "createdAt" : "2018-12-06T22:00:00Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "54d8dd54100b18957db07485d9ee0c37ad4476c8",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +813,817 @@                       error == Errors.REPLICA_NOT_AVAILABLE ||\n                       error == Errors.KAFKA_STORAGE_ERROR ||\n                       error == Errors.OFFSET_NOT_AVAILABLE ||\n                       error == Errors.LEADER_NOT_AVAILABLE) {\n                log.debug(\"Attempt to fetch offsets for partition {} failed due to {}, retrying.\","
  },
  {
    "id" : "d3862562-44a7-4276-b1d6-a5fea7becd38",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-214244487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8dcfa3c-78e9-4d92-b843-ba6c13bd9255",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I am sure I am missing something but how can this be true when due to line 560 `if (partitionRecords.nextFetchOffset == position.offset) {`?",
        "createdAt" : "2019-03-12T22:19:20Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "9a3f0246-7007-467d-9d48-a7d53336759b",
        "parentId" : "d8dcfa3c-78e9-4d92-b843-ba6c13bd9255",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "On a side note, unless the local variable and the field are marked as `final`, it is basically impossible for javac to catch this statically because Java's concurrency model. E.g. any thread can modify both `partitionRecords.nextFetchOffset` and `position.offset`",
        "createdAt" : "2019-03-12T22:23:49Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "99e150ef-f7fa-401e-81d1-379446c6cb04",
        "parentId" : "d8dcfa3c-78e9-4d92-b843-ba6c13bd9255",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Good catch. Let me look into this... might be something I missed during the merge from trunk. ",
        "createdAt" : "2019-03-13T13:28:04Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "2affcb55-ce9e-463e-ac5b-2d86cd5dac33",
        "parentId" : "d8dcfa3c-78e9-4d92-b843-ba6c13bd9255",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "I think the code is correct as-is. The call to `partitionRecords.fetchRecords(maxRecords)` updates the nextFetchOffset to the offset of the last record returned plus one.",
        "createdAt" : "2019-03-13T22:31:55Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +604,608 @@                List<ConsumerRecord<K, V>> partRecords = partitionRecords.fetchRecords(maxRecords);\n\n                if (partitionRecords.nextFetchOffset > position.offset) {\n                    SubscriptionState.FetchPosition nextPosition = new SubscriptionState.FetchPosition(\n                            partitionRecords.nextFetchOffset,"
  },
  {
    "id" : "ed8635b8-c3bc-4a90-8e1a-35f75e84d27f",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-217995699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3c431b4-767f-4e7e-8286-25cc33db7adc",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Maybe worth adding a comment here. If `currentPosition.lastFetchEpoch` is equal to `respEndOffset.leaderEpoch`, then the truncation is precise.",
        "createdAt" : "2019-03-22T23:11:21Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +739,743 @@                            }\n\n                            if (respEndOffset.endOffset() < currentPosition.offset) {\n                                if (subscriptions.hasDefaultOffsetResetPolicy()) {\n                                    SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition("
  },
  {
    "id" : "7c0106f5-8888-4e64-a9b3-d981258b1ea1",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-217995699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84461157-7476-475f-9266-061f17b30920",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Maybe the method should be `completeValidation` or something like that?",
        "createdAt" : "2019-03-22T23:12:16Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 241,
    "diffHunk" : "@@ -1,1 +752,756 @@                            } else {\n                                // Offset is fine, clear the validation state\n                                subscriptions.validate(respTopicPartition);\n                            }\n                        }"
  },
  {
    "id" : "c40fbfd6-372b-4b8e-8d41-d6e910956eb6",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-221802445",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "551267ad-1fd6-4420-875f-297092d05a08",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "If the user ignores this exception and calls `poll()`, will we repeat the validation? That may be reasonable, just making sure I understand.",
        "createdAt" : "2019-03-22T23:13:19Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "084a2542-466e-4de5-b99b-ff74432dd91d",
        "parentId" : "551267ad-1fd6-4420-875f-297092d05a08",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "At this point, the subscription state is still in AWAITING_VALIDATION, so yes the next `poll()` call should attempt to revalidate asynchronously and these partitions will be excluded for the time being. ",
        "createdAt" : "2019-04-02T17:34:37Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 247,
    "diffHunk" : "@@ -1,1 +758,762 @@\n                    if (!truncationWithoutResetPolicy.isEmpty()) {\n                        throw new LogTruncationException(truncationWithoutResetPolicy);\n                    }\n                }"
  },
  {
    "id" : "95676a89-2b3a-4790-a6ee-f133ce4c201a",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228385288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05432830-124b-4714-a001-2e58f0255a94",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can we save the second pass over the partitions by doing this collection in the loop above? I'm just thinking about MM-like use cases where the number of partitions could be quite large. A possible optimization is to to cache the metadata update version so that we only bother redoing this check if there has actually been a metadata update.",
        "createdAt" : "2019-04-18T01:59:13Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "95d2d284-4ad3-40a8-931b-c31aa7b3419c",
        "parentId" : "05432830-124b-4714-a001-2e58f0255a94",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "The first pass through all the partitions covers the case of metadata changing, but the second pass through is also used to resubmit the async request with backoff. We could remember the last metadata version seen and avoid unnecessary calls to the first loop.",
        "createdAt" : "2019-04-18T15:34:11Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "b1fa148f-c8ea-4c32-aca9-e2f36919789a",
        "parentId" : "05432830-124b-4714-a001-2e58f0255a94",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "How about we leave this for a follow-up?",
        "createdAt" : "2019-04-18T16:11:18Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "5544c8d2-c9e2-4330-b8c2-a5cc711ced56",
        "parentId" : "05432830-124b-4714-a001-2e58f0255a94",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Works for me 👍 ",
        "createdAt" : "2019-04-18T16:29:07Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +433,437 @@\n        // Collect positions needing validation, with backoff\n        Map<TopicPartition, SubscriptionState.FetchPosition> partitionsToValidate = subscriptions\n                .partitionsNeedingValidation(time.milliseconds())\n                .stream()"
  },
  {
    "id" : "89fc6d0e-83c8-4829-b446-ae53aac502aa",
    "prId" : 6371,
    "prUrl" : "https://github.com/apache/kafka/pull/6371#pullrequestreview-228371955",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f16e3a2-d2ca-4d70-aa66-31ea9f3bd964",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The checks above ensure that we are still in the validating phase and that the current leader epoch hasn't changed. I guess it is still possible that both of these are true, but the user has seeked to a different position. Perhaps we can add position to the cached data above?",
        "createdAt" : "2019-04-18T15:01:54Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "4ef674dd-3576-4fd1-820e-a014c5e12499",
        "parentId" : "6f16e3a2-d2ca-4d70-aa66-31ea9f3bd964",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "I think it's still okay as long as the position's epoch hasn't changed. What's the side effect if you seek to offset 10 (FETCHING), do validation (AWAIT_VALIDATION), seek to offset 30 (FETCHING), do validation again (AWAIT_VALIDATION), and then get back the OffsetsForLeader response from the first async validation? I think as long as the position's epoch is the same, there isn't a problem. When the second response comes back it will get ignored since we won't be in the right state. WDYT?",
        "createdAt" : "2019-04-18T15:57:49Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "432cca33-8112-4e6e-bf8d-0aeed186aed5",
        "parentId" : "6f16e3a2-d2ca-4d70-aa66-31ea9f3bd964",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I agree that the important thing is that the position's epoch hasn't changed. That and the current leader epoch are the only input to the OffsetsForLeaderEpoch API.",
        "createdAt" : "2019-04-18T16:01:11Z",
        "updatedAt" : "2019-04-19T22:50:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0934f5ac0211e742b1c5b77b1b5c067ed5ff9a6e",
    "line" : 224,
    "diffHunk" : "@@ -1,1 +735,739 @@                            SubscriptionState.FetchPosition currentPosition = subscriptions.position(respTopicPartition);\n                            Metadata.LeaderAndEpoch currentLeader = currentPosition.currentLeader;\n                            if (!currentLeader.equals(cachedLeaderAndEpochs.get(respTopicPartition))) {\n                                return;\n                            }"
  }
]