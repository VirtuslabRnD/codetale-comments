[
  {
    "id" : "a358bd30-5e45-4725-b3f9-de0ca821b366",
    "prId" : 2267,
    "prUrl" : "https://github.com/apache/kafka/pull/2267#pullrequestreview-162261031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1df271bb-0be8-42a5-b306-6cfdd5c9b2db",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We should mention that zstd was added in Kafka 2.1 so older versions don't support it.",
        "createdAt" : "2018-10-06T15:44:45Z",
        "updatedAt" : "2018-10-09T21:16:40Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "147c47358b3d9483de633b855ff809f64b9befef",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +160,164 @@    public static final String COMPRESSION_TYPE_CONFIG = \"compression.type\";\n    private static final String COMPRESSION_TYPE_DOC = \"The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid \"\n                                                       + \" values are <code>none</code>, <code>gzip</code>, <code>snappy</code>, <code>lz4</code>, or <code>zstd</code>. \"\n                                                       + \"Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).\";\n"
  },
  {
    "id" : "87e1409c-59cc-4310-8753-c6a2e6052a81",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-132303676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "421eb0b4-2023-4b6a-9cb2-345c0eba8d42",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can you mention this default change in the upgrade notes?",
        "createdAt" : "2018-06-26T20:25:07Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "69b354e6-508b-4048-baad-d8b32229ac6e",
        "parentId" : "421eb0b4-2023-4b6a-9cb2-345c0eba8d42",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "updated the upgrade doc on this. ",
        "createdAt" : "2018-06-27T06:52:51Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +232,236 @@        CONFIG = new ConfigDef().define(BOOTSTRAP_SERVERS_CONFIG, Type.LIST, Collections.emptyList(), new ConfigDef.NonNullValidator(), Importance.HIGH, CommonClientConfigs.BOOTSTRAP_SERVERS_DOC)\n                                .define(BUFFER_MEMORY_CONFIG, Type.LONG, 32 * 1024 * 1024L, atLeast(0L), Importance.HIGH, BUFFER_MEMORY_DOC)\n                                .define(RETRIES_CONFIG, Type.INT, Integer.MAX_VALUE, between(0, Integer.MAX_VALUE), Importance.HIGH, RETRIES_DOC)\n                                .define(ACKS_CONFIG,\n                                        Type.STRING,"
  },
  {
    "id" : "8ed09b1f-cbfa-4507-83cf-b50f0ac6d341",
    "prId" : 5532,
    "prUrl" : "https://github.com/apache/kafka/pull/5532#pullrequestreview-148120015",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do we need a space after \"by\"?",
        "createdAt" : "2018-08-20T21:12:14Z",
        "updatedAt" : "2018-08-21T08:52:01Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ebcd639c-6889-4956-96ab-9f4e97e6785f",
        "parentId" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "There's a leading space on the next line, before `<code>`.",
        "createdAt" : "2018-08-21T09:00:02Z",
        "updatedAt" : "2018-08-21T09:00:02Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "d576df82-e0ec-4152-b7f9-6cb327863df7",
        "parentId" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ah, you're right. Not sure how I missed that.",
        "createdAt" : "2018-08-21T15:32:53Z",
        "updatedAt" : "2018-08-21T15:32:53Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a818764da2787b08b62d7338beaf64ad3b338e3",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +191,195 @@            + \" succeeds, then the records in the second batch may appear first. Note additionall that produce requests will be\"\n            + \" failed before the number of retries has been exhausted if the timeout configured by\"\n            + \" <code>\" + DELIVERY_TIMEOUT_MS_CONFIG + \"</code> expires first before successful acknowledgement. Users should generally\"\n            + \" prefer to leave this config unset and instead use <code>\" + DELIVERY_TIMEOUT_MS_CONFIG + \"</code> to control\"\n            + \" retry behavior.\";"
  },
  {
    "id" : "fd20724d-c500-437e-97db-d2b51f6c97a6",
    "prId" : 9013,
    "prUrl" : "https://github.com/apache/kafka/pull/9013#pullrequestreview-447376033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed802776-0e7f-4c22-a9fc-48dc3d486eb2",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Same here, one parameter per line and align",
        "createdAt" : "2020-07-13T15:48:31Z",
        "updatedAt" : "2020-07-13T20:52:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd9f62bd5587f678f93269ec32011c8f3a0fa71a",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +502,506 @@    }\n\n    static Map<String, Object> appendSerializerToConfig(Map<String, Object> configs,\n            Serializer<?> keySerializer,\n            Serializer<?> valueSerializer) {"
  }
]