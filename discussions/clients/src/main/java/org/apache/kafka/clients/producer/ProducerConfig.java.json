[
  {
    "id" : "a358bd30-5e45-4725-b3f9-de0ca821b366",
    "prId" : 2267,
    "prUrl" : "https://github.com/apache/kafka/pull/2267#pullrequestreview-162261031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1df271bb-0be8-42a5-b306-6cfdd5c9b2db",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We should mention that zstd was added in Kafka 2.1 so older versions don't support it.",
        "createdAt" : "2018-10-06T15:44:45Z",
        "updatedAt" : "2018-10-09T21:16:40Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "147c47358b3d9483de633b855ff809f64b9befef",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +160,164 @@    public static final String COMPRESSION_TYPE_CONFIG = \"compression.type\";\n    private static final String COMPRESSION_TYPE_DOC = \"The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid \"\n                                                       + \" values are <code>none</code>, <code>gzip</code>, <code>snappy</code>, <code>lz4</code>, or <code>zstd</code>. \"\n                                                       + \"Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).\";\n"
  },
  {
    "id" : "87e1409c-59cc-4310-8753-c6a2e6052a81",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-132303676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "421eb0b4-2023-4b6a-9cb2-345c0eba8d42",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can you mention this default change in the upgrade notes?",
        "createdAt" : "2018-06-26T20:25:07Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "69b354e6-508b-4048-baad-d8b32229ac6e",
        "parentId" : "421eb0b4-2023-4b6a-9cb2-345c0eba8d42",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "updated the upgrade doc on this. ",
        "createdAt" : "2018-06-27T06:52:51Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +232,236 @@        CONFIG = new ConfigDef().define(BOOTSTRAP_SERVERS_CONFIG, Type.LIST, Collections.emptyList(), new ConfigDef.NonNullValidator(), Importance.HIGH, CommonClientConfigs.BOOTSTRAP_SERVERS_DOC)\n                                .define(BUFFER_MEMORY_CONFIG, Type.LONG, 32 * 1024 * 1024L, atLeast(0L), Importance.HIGH, BUFFER_MEMORY_DOC)\n                                .define(RETRIES_CONFIG, Type.INT, Integer.MAX_VALUE, between(0, Integer.MAX_VALUE), Importance.HIGH, RETRIES_DOC)\n                                .define(ACKS_CONFIG,\n                                        Type.STRING,"
  },
  {
    "id" : "8ed09b1f-cbfa-4507-83cf-b50f0ac6d341",
    "prId" : 5532,
    "prUrl" : "https://github.com/apache/kafka/pull/5532#pullrequestreview-148120015",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do we need a space after \"by\"?",
        "createdAt" : "2018-08-20T21:12:14Z",
        "updatedAt" : "2018-08-21T08:52:01Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ebcd639c-6889-4956-96ab-9f4e97e6785f",
        "parentId" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "There's a leading space on the next line, before `<code>`.",
        "createdAt" : "2018-08-21T09:00:02Z",
        "updatedAt" : "2018-08-21T09:00:02Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "d576df82-e0ec-4152-b7f9-6cb327863df7",
        "parentId" : "6814c8a1-65cf-44a1-b5c5-56d99c69de74",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ah, you're right. Not sure how I missed that.",
        "createdAt" : "2018-08-21T15:32:53Z",
        "updatedAt" : "2018-08-21T15:32:53Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a818764da2787b08b62d7338beaf64ad3b338e3",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +191,195 @@            + \" succeeds, then the records in the second batch may appear first. Note additionall that produce requests will be\"\n            + \" failed before the number of retries has been exhausted if the timeout configured by\"\n            + \" <code>\" + DELIVERY_TIMEOUT_MS_CONFIG + \"</code> expires first before successful acknowledgement. Users should generally\"\n            + \" prefer to leave this config unset and instead use <code>\" + DELIVERY_TIMEOUT_MS_CONFIG + \"</code> to control\"\n            + \" retry behavior.\";"
  },
  {
    "id" : "fd20724d-c500-437e-97db-d2b51f6c97a6",
    "prId" : 9013,
    "prUrl" : "https://github.com/apache/kafka/pull/9013#pullrequestreview-447376033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed802776-0e7f-4c22-a9fc-48dc3d486eb2",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Same here, one parameter per line and align",
        "createdAt" : "2020-07-13T15:48:31Z",
        "updatedAt" : "2020-07-13T20:52:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd9f62bd5587f678f93269ec32011c8f3a0fa71a",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +502,506 @@    }\n\n    static Map<String, Object> appendSerializerToConfig(Map<String, Object> configs,\n            Serializer<?> keySerializer,\n            Serializer<?> valueSerializer) {"
  },
  {
    "id" : "4ab45980-0a76-4e39-8b58-b67ee4d0c026",
    "prId" : 9497,
    "prUrl" : "https://github.com/apache/kafka/pull/9497#pullrequestreview-697284454",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e218e65-c3f2-4ff4-ae8f-94774e60020f",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "@d8tltanc in your PR with the test adjustments, please reduce the priority of this. Either `LOW` or `MEDIUM`, we can discuss more in the PR.",
        "createdAt" : "2021-07-01T14:02:03Z",
        "updatedAt" : "2021-07-01T14:02:03Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "43f788d0c08c0c81f55b9672e96f1044671a7550",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +303,307 @@                                        \"all\",\n                                        in(\"all\", \"-1\", \"0\", \"1\"),\n                                        Importance.HIGH,\n                                        ACKS_DOC)\n                                .define(COMPRESSION_TYPE_CONFIG, Type.STRING, \"none\", Importance.HIGH, COMPRESSION_TYPE_DOC)"
  },
  {
    "id" : "90c87def-a137-4592-a5b3-35717483efb0",
    "prId" : 10987,
    "prUrl" : "https://github.com/apache/kafka/pull/10987#pullrequestreview-708982846",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "334daa8d-825e-40e5-8bf9-2df74124edb4",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "there is an issue (#8690) which RoundRobinPartitioner can cause uneven distribution when new batch is created. Maybe we should remind the known issue. ",
        "createdAt" : "2021-07-17T08:00:29Z",
        "updatedAt" : "2021-07-17T08:04:54Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "abde650f-a75b-4e7f-bbc5-7b7c4493aa43",
        "parentId" : "334daa8d-825e-40e5-8bf9-2df74124edb4",
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "@chia7712 , thanks for reminding. I didn't know this issue. I added a note in RoundRobinPartitioner description. Thanks.\r\n\r\n> This partitioning strategy is that each record in a series of consecutive records will be sent to a different partition(no matter if the 'key' is provided or not), until we run out of partitions and start over again. Note: There's a known issue that will cause uneven distribution when new batch is created. Please check KAFKA-9965 for more detail.",
        "createdAt" : "2021-07-18T02:37:10Z",
        "updatedAt" : "2021-07-18T02:37:31Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0edcee1d4989b6cccea9364b20bdac8c8fb459b",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +244,248 @@                \"</ul>\" +\n            \"</li>\" +\n            \"<li><code>org.apache.kafka.clients.producer.RoundRobinPartitioner</code>: This partitioning strategy is that \" +\n        \"each record in a series of consecutive records will be sent to a different partition(no matter if the 'key' is provided or not), \" +\n        \"until we run out of partitions and start over again. Note: There's a known issue that will cause uneven distribution when new batch is created. \" +"
  },
  {
    "id" : "9400087e-8a90-42d6-9a98-f27baded8a32",
    "prId" : 11160,
    "prUrl" : "https://github.com/apache/kafka/pull/11160#pullrequestreview-719619873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d785a2c-5160-4a4f-99a2-2648da63aa6e",
        "parentId" : null,
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "add a comma for better readability:\r\nbefore:\r\n`that is, rather than immediately sending out a record the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together.`\r\nafter:\r\n`that is, rather than immediately sending out a record[,] the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together.`",
        "createdAt" : "2021-08-01T03:40:12Z",
        "updatedAt" : "2021-08-01T03:40:12Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cbd8e0bb129612f5ecdc3f74e9aac7271d3542e",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +112,116 @@                                                + \"Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances the client may want to \"\n                                                + \"reduce the number of requests even under moderate load. This setting accomplishes this by adding a small amount \"\n                                                + \"of artificial delay&mdash;that is, rather than immediately sending out a record, the producer will wait for up to \"\n                                                + \"the given delay to allow other records to be sent so that the sends can be batched together. This can be thought \"\n                                                + \"of as analogous to Nagle's algorithm in TCP. This setting gives the upper bound on the delay for batching: once \""
  }
]