[
  {
    "id" : "6b673331-7547-4117-bec5-4875714ff571",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-133335457",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98348165-e7fc-4da7-bb57-ca7019f9d020",
        "parentId" : null,
        "authorId" : "0e2392fc-5c22-4c17-aa96-3025239a3098",
        "body" : "We should add some sort of `accumulator.hasInflightBatches` method, and then check that it returns false here. This would check that expired batches are not reenqueued, which is logic added in this patch.",
        "createdAt" : "2018-06-29T06:00:58Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "0e2392fc-5c22-4c17-aa96-3025239a3098",
        "tags" : [
        ]
      },
      {
        "id" : "5b9fcac8-3703-43ea-ad54-e1b554650fe4",
        "parentId" : "98348165-e7fc-4da7-bb57-ca7019f9d020",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "added the method `public List<ProducerBatch> inFlightBatches(TopicPartition tp)`  in `RecordAccumulator`, and updated the test with two assertions: \r\n\r\n       line 1912: assertEquals(\"Expect one in-flight batch in accumulator\", 1, accumulator.inFlightBatches(tp0).size());\r\n        .....\r\n       line 1920: assertEquals(\"Expect zero in-flight batch in accumulator\", 0, accumulator.inFlightBatches(tp0).size());\r\n",
        "createdAt" : "2018-06-29T18:36:38Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 463,
    "diffHunk" : "@@ -1,1 +1958,1962 @@            fail(\"The expired batch should throw a TimeoutException\");\n        } catch (ExecutionException e) {\n            assertTrue(e.getCause() instanceof TimeoutException);\n        }\n    }"
  },
  {
    "id" : "967f486f-075e-411a-a2c4-597513b51a3a",
    "prId" : 5270,
    "prUrl" : "https://github.com/apache/kafka/pull/5270#pullrequestreview-133388419",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2313699a-f42c-413a-a5c6-2514833a7570",
        "parentId" : null,
        "authorId" : "0e2392fc-5c22-4c17-aa96-3025239a3098",
        "body" : "How is this different from the test `testExpiryOfFirstBatchShouldNotCauseUnresolvedSequencesIfFutureBatchesSucceed`?",
        "createdAt" : "2018-06-29T06:03:16Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "0e2392fc-5c22-4c17-aa96-3025239a3098",
        "tags" : [
        ]
      },
      {
        "id" : "0a42eae0-4864-4400-a121-f400dc802ba4",
        "parentId" : "2313699a-f42c-413a-a5c6-2514833a7570",
        "authorId" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "body" : "`testExpiryOfFirstBatchShouldNotCauseUnresolvedSequencesIfFutureBatchesSucceed` initialize `sender` with `guaranteeMessageOrder = false`, while `testWhenFirstBatchExpireNoSendSecondBatchIfGuaranteeOrder` initialize sender with `guaranteeMessageOrder = true`.  The `inflightBatches` size is different when we set the parameter to true/false. ",
        "createdAt" : "2018-06-29T21:53:35Z",
        "updatedAt" : "2018-07-26T15:53:34Z",
        "lastEditedBy" : "a962e9bb-bf94-4294-b23c-d279e1e69019",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9aa6b1706e2e374c20d710567a64b0328fe3119",
    "line" : 468,
    "diffHunk" : "@@ -1,1 +1963,1967 @@\n    @Test\n    public void testWhenFirstBatchExpireNoSendSecondBatchIfGuaranteeOrder() throws InterruptedException {\n        long deliveryTimeoutMs = 1500L;\n        setupWithTransactionState(null, true, null);"
  },
  {
    "id" : "c8dda5e8-739c-4689-bf18-afe98dda6aef",
    "prId" : 6388,
    "prUrl" : "https://github.com/apache/kafka/pull/6388#pullrequestreview-211964916",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da048431-6559-4376-b7f8-a6bdc57791ca",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could we have a separate test case which covers the `forceClose()` path. We can assert that we do not wait for the producerId and all pending sends are aborted.",
        "createdAt" : "2019-03-07T17:55:46Z",
        "updatedAt" : "2019-03-07T19:34:57Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "01709308-73dd-4d99-84d0-71de1b58e417",
        "parentId" : "da048431-6559-4376-b7f8-a6bdc57791ca",
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "@hachikuji Thanks for the review. Addressed the review comment.",
        "createdAt" : "2019-03-07T19:05:16Z",
        "updatedAt" : "2019-03-07T19:34:57Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      }
    ],
    "commit" : "6130ee8b623e1331cfddd92eb9ce3c7447ccd019",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1199,1203 @@\n    @Test\n    public void testCloseWithProducerIdReset() throws Exception {\n        final long producerId = 343434L;\n        TransactionManager transactionManager = new TransactionManager();"
  },
  {
    "id" : "5508e03b-671c-4a93-b19a-56d32e0e9009",
    "prId" : 6388,
    "prUrl" : "https://github.com/apache/kafka/pull/6388#pullrequestreview-211979149",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6026e049-8aa1-4608-b054-210621e6d821",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can we assert that this future completed below?",
        "createdAt" : "2019-03-07T19:22:31Z",
        "updatedAt" : "2019-03-07T19:34:57Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "bdef0b20-0133-4131-9a7c-05cee89aaaea",
        "parentId" : "6026e049-8aa1-4608-b054-210621e6d821",
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "Done.",
        "createdAt" : "2019-03-07T19:35:37Z",
        "updatedAt" : "2019-03-07T19:35:37Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      }
    ],
    "commit" : "6130ee8b623e1331cfddd92eb9ce3c7447ccd019",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +1252,1256 @@        Future<RecordMetadata> failedResponse = accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(),\n            \"value\".getBytes(), null, null, MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> successfulResponse = accumulator.append(tp1, time.milliseconds(), \"key\".getBytes(),\n            \"value\".getBytes(), null, null, MAX_BLOCK_TIMEOUT).future;\n        sender.run(time.milliseconds());  // connect and send."
  }
]