[
  {
    "id" : "850e9b64-af8b-44e6-b81b-44095a047be4",
    "prId" : 3848,
    "prUrl" : "https://github.com/apache/kafka/pull/3848#pullrequestreview-196402435",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bbe4cfd-d9f6-4f7c-8d1e-2b3cd9f26fc5",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Perhaps we can further assert that calling get on topic1 has no error?",
        "createdAt" : "2019-01-24T23:00:12Z",
        "updatedAt" : "2019-01-25T09:57:17Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "9bea1c79-43bb-4a98-9ea9-5b9271d3f239",
        "parentId" : "8bbe4cfd-d9f6-4f7c-8d1e-2b3cd9f26fc5",
        "authorId" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "body" : "We do that on line 664, unless I misunderstood what you mean?",
        "createdAt" : "2019-01-25T08:38:53Z",
        "updatedAt" : "2019-01-25T09:57:17Z",
        "lastEditedBy" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df18c6b3232f3e8b9bf879b7a8dd762a5968c6c",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +664,668 @@            results.partitionResult(topic1).get();\n            TestUtils.assertFutureError(results.partitionResult(topic2), ClusterAuthorizationException.class);\n            TestUtils.assertFutureError(results.all(), ClusterAuthorizationException.class);\n\n            // Test a call where there are no errors."
  },
  {
    "id" : "f90e6345-acbb-477c-8a80-e0d344981ec7",
    "prId" : 4470,
    "prUrl" : "https://github.com/apache/kafka/pull/4470#pullrequestreview-91954220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4aa110ed-371e-4ac0-9d09-8b4c42979524",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit (open to discussion): I tend to prefer smaller test cases when they are possible since it is easier to narrow down the problem. Any reason not to split this into 3 separate cases: one for each API?",
        "createdAt" : "2018-01-25T19:35:48Z",
        "updatedAt" : "2018-01-26T19:32:31Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "13883e11-d9ad-4e1a-895d-c9ef88d47ea0",
        "parentId" : "4aa110ed-371e-4ac0-9d09-8b4c42979524",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "It's just more boilerplate creating each test.  This particular test actually runs very fast since it's a true unit test (no brokers running), so test time should not be an issue.  I don't feel strongly about it, though.",
        "createdAt" : "2018-01-26T19:23:19Z",
        "updatedAt" : "2018-01-26T19:32:31Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "8d153d46-524d-4dac-a44f-7b16381454d8",
        "parentId" : "4aa110ed-371e-4ac0-9d09-8b4c42979524",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I don't feel too strongly in this case. The advantage generally is that the scope of the test case is clearer which makes failures easier to investigate. ",
        "createdAt" : "2018-01-26T20:03:36Z",
        "updatedAt" : "2018-01-26T20:03:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2861635595d2ea2e0e01282e55837c563c15aa8",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +218,222 @@\n    @Test\n    public void testInvalidTopicNames() throws Exception {\n        try (AdminClientUnitTestEnv env = mockClientEnv()) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());"
  },
  {
    "id" : "7c8e10ad-bcd2-4051-a74a-041d3d93ecd5",
    "prId" : 5578,
    "prUrl" : "https://github.com/apache/kafka/pull/5578#pullrequestreview-151223711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7870e687-32cf-4fb5-ba33-11778f1d6b5a",
        "parentId" : null,
        "authorId" : "96e73e76-849a-48cc-aea2-062b6505864e",
        "body" : "NIT: extra whitespace",
        "createdAt" : "2018-08-31T00:05:24Z",
        "updatedAt" : "2019-05-09T18:36:41Z",
        "lastEditedBy" : "96e73e76-849a-48cc-aea2-062b6505864e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d60ed8b759ca9c141bd47f42bc2eefc9c9629c4",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1085,1089 @@            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            //Retriable  errors should be retried\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\","
  },
  {
    "id" : "5a894181-c5b7-47de-909c-8b9b5d74b7c9",
    "prId" : 5578,
    "prUrl" : "https://github.com/apache/kafka/pull/5578#pullrequestreview-151223773",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "603ff74b-a65f-4f9a-b2ee-0616e6ed6682",
        "parentId" : null,
        "authorId" : "96e73e76-849a-48cc-aea2-062b6505864e",
        "body" : "NIT: same, whitespace",
        "createdAt" : "2018-08-31T00:05:47Z",
        "updatedAt" : "2019-05-09T18:36:41Z",
        "lastEditedBy" : "96e73e76-849a-48cc-aea2-062b6505864e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d60ed8b759ca9c141bd47f42bc2eefc9c9629c4",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +1177,1181 @@            env.kafkaClient().prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, env.cluster().controller()));\n\n            //Retriable  errors should be retried\n            env.kafkaClient().prepareResponse(new OffsetFetchResponse(Errors.COORDINATOR_NOT_AVAILABLE, Collections.emptyMap()));\n            env.kafkaClient().prepareResponse(new OffsetFetchResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS, Collections.emptyMap()));"
  },
  {
    "id" : "d8a65c0f-87c0-4c27-85b1-e124e878ceea",
    "prId" : 7296,
    "prUrl" : "https://github.com/apache/kafka/pull/7296#pullrequestreview-301579638",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "68bd32e2-bfba-4806-b8f0-8ea9857f8b39",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can we have one test case which sends the ListOffset to multiple leaders?",
        "createdAt" : "2019-10-14T23:07:17Z",
        "updatedAt" : "2019-10-19T14:50:21Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "adb3377352be6336d1586a4a160eedbcd5a9a021",
    "line" : 507,
    "diffHunk" : "@@ -1,1 +2625,2629 @@\n    @Test\n    public void testListOffsetsMetadataRetriableErrors() throws Exception {\n\n        Node node0 = new Node(0, \"localhost\", 8120);"
  },
  {
    "id" : "b9ced5b9-abea-4398-955b-48df95056f31",
    "prId" : 7763,
    "prUrl" : "https://github.com/apache/kafka/pull/7763#pullrequestreview-325151365",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a37a7f8b-9808-436a-84a2-9a6d568e344c",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Lots of duplication in these tests. No need to do it in this PR but I'm wondering if wrapping all the\r\n```\r\n final HashMap<Integer, Node> nodes = new HashMap<>();\r\n        nodes.put(0, new Node(0, \"localhost\", 8121));\r\n\r\n        final Cluster cluster =\r\n            new Cluster(\r\n                \"mockClusterId\",\r\n                nodes.values(),\r\n                Collections.<PartitionInfo>emptyList(),\r\n                Collections.<String>emptySet(),\r\n                Collections.<String>emptySet(), nodes.get(0));\r\n\r\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\r\n```\r\nboilerplate into a single method that accepts a callable would look better in this test class",
        "createdAt" : "2019-11-29T20:15:49Z",
        "updatedAt" : "2019-12-02T10:43:06Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "12378682-c73d-40f6-ac46-f2e84ed73112",
        "parentId" : "a37a7f8b-9808-436a-84a2-9a6d568e344c",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Totally. If you don't mind, I will tackle this in a separate PR. I'd like to keep this one focus on the bugfix.",
        "createdAt" : "2019-12-02T10:43:47Z",
        "updatedAt" : "2019-12-02T10:43:47Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ede68327425a9c327d491be0ff73da51da39177",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1515,1519 @@    @Test\n    public void testDescribeNonConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n"
  },
  {
    "id" : "7d87c2b6-af94-4425-a4b8-900a8d29ab16",
    "prId" : 8057,
    "prUrl" : "https://github.com/apache/kafka/pull/8057#pullrequestreview-354853309",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31f90f89-ea16-4e5c-b28c-2771c147f4b9",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could we assert that the map contains the key `myTopicPartition3`?",
        "createdAt" : "2020-02-06T23:51:52Z",
        "updatedAt" : "2020-02-07T00:11:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "9847c4aec837a89172fc9a09f7fefc7de6af9e51",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1516,1520 @@            assertEquals(20, partitionToOffsetAndMetadata.get(myTopicPartition2).offset());\n            assertTrue(partitionToOffsetAndMetadata.containsKey(myTopicPartition3));\n            assertNull(partitionToOffsetAndMetadata.get(myTopicPartition3));\n        }\n    }"
  },
  {
    "id" : "7f02dc39-a931-4974-917f-49b00ac4324e",
    "prId" : 8238,
    "prUrl" : "https://github.com/apache/kafka/pull/8238#pullrequestreview-394485087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Could we add a test case which verifies that `UnsupportedVersionException` is thrown when states are provided but an older API is used? Side question, I haven't seen logic to raise it anywhere. Is it handled implicitly by the serialization layer?",
        "createdAt" : "2020-03-17T08:24:02Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "df41dbb9-9bc3-4983-bcae-352b903e4dcb",
        "parentId" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "Yes, the exception is raised in ListGroupsRequestData. We can't test it here as `MockClient` does not serialize requests. That said, it's a good point, I'll see where we can test this",
        "createdAt" : "2020-03-23T14:40:19Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "795e58dd-3d65-473b-9365-54e35fe34d34",
        "parentId" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "So, it will throw the following exception: `UnsupportedVersionException(\"Attempted to write a non-default states at version \" + _version)`.  The message is a bit weird for an end user. Would it make sense to catch it in `handleFailure` and throw an exception with a better message?\r\n\r\nI wonder how such cases have been handled so far. I don't see any particular handling in the admin client at the moment. ",
        "createdAt" : "2020-03-27T15:56:18Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "28e7412b-fe2e-44b5-bf42-c2818c8bfce8",
        "parentId" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I just stumbled upon this: https://github.com/apache/kafka/blob/169fa0efcc9089bdcf37e6f8b1b9a6f3377f38f8/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchRequest.java#L84\r\n\r\nWe could perhaps do something similar in our case.",
        "createdAt" : "2020-03-29T09:05:41Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "c39a1135-1b8b-4a74-881d-f91220d2cd85",
        "parentId" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "I was sort of avoiding doing this, as I believe we should rely on the underlying Data class instead of having such logic in the Request/Response classes. However, For consistency, let's do it and it will also simplify testing for `UnsupportedVersionException`.",
        "createdAt" : "2020-04-16T09:27:55Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "561d5b0f-3309-46b5-a282-e4b0cfa66e7f",
        "parentId" : "290af110-caa0-4103-b2ea-772b2a393b28",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Thanks. I agree that it is not perfect but it will provide a better error to the end user by explicitly handling it.",
        "createdAt" : "2020-04-16T10:05:38Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "acb64f32f6fc2353dcaec2be44d05c6cd1a77b2d",
    "line" : 95,
    "diffHunk" : "@@ -1,1 +1326,1330 @@\n    @Test\n    public void testListConsumerGroupsWithStates() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());"
  },
  {
    "id" : "935fc26c-9dc8-446d-bed9-2adc07f094b7",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-459264101",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2f0ad1f-d9a7-4c81-903e-61cb8c469754",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Good coverage",
        "createdAt" : "2020-07-31T15:35:35Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 272,
    "diffHunk" : "@@ -1,1 +4099,4103 @@\n    @Test\n    public void testListOffsetsPartialResponse() throws Exception {\n        Node node0 = new Node(0, \"localhost\", 8120);\n        Node node1 = new Node(1, \"localhost\", 8121);"
  },
  {
    "id" : "6156ae0c-e9a1-4795-8536-bb69631f351b",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-490922201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26bda3a6-3fb5-411a-afdb-fd97180f3e6a",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I think we could reduce the change of this PR by reverting the numbering change which seems unnecessary.",
        "createdAt" : "2020-08-11T17:07:50Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "5208f0b0-c8e3-41b9-91dd-8bfd4cd724c6",
        "parentId" : "26bda3a6-3fb5-411a-afdb-fd97180f3e6a",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "I think it's a good cleanup, I changed the numbering because it confused me.",
        "createdAt" : "2020-08-13T09:53:04Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "d50aaeca-b35b-49e7-986d-92986b87fa0a",
        "parentId" : "26bda3a6-3fb5-411a-afdb-fd97180f3e6a",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I will leave it up to you, as long as you ensure the tests itself are mutated correctly, it's not easy to eyeball such a change for no-op.",
        "createdAt" : "2020-09-17T19:29:07Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +3739,3743 @@                node0);\n\n        final TopicPartition tp0 = new TopicPartition(\"foo\", 0);\n        final TopicPartition tp1 = new TopicPartition(\"bar\", 0);\n        final TopicPartition tp2 = new TopicPartition(\"baz\", 0);"
  },
  {
    "id" : "ca91307b-0d5b-4d84-9796-e82ca930e958",
    "prId" : 8589,
    "prUrl" : "https://github.com/apache/kafka/pull/8589#pullrequestreview-417241321",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f015c7f5-32b1-4437-a4a6-49ff69f00b5c",
        "parentId" : null,
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "No existing help method to assert the cause of exception throw by `all()`. Also I think it's more straight forward in this way.",
        "createdAt" : "2020-05-23T02:01:24Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      }
    ],
    "commit" : "5329315b0fba569e0ffd1e3c2d8cbea002a684ba",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +2452,2456 @@                    new RemoveMembersFromConsumerGroupOptions()\n            );\n            ExecutionException exception = assertThrows(ExecutionException.class, () -> partialFailureResults.all().get());\n            assertTrue(exception.getCause() instanceof KafkaException);\n            assertTrue(exception.getCause().getCause() instanceof UnknownMemberIdException);"
  },
  {
    "id" : "b5fe58f3-3926-4d75-b535-9e5bcd1f2943",
    "prId" : 8864,
    "prUrl" : "https://github.com/apache/kafka/pull/8864#pullrequestreview-444946999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e12e0814-8d39-44ba-975a-ca14e279217f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: feels like overkill to deprecate test cases. Since they reference RETRIES directly, I don't think we need to worry about them not getting removed",
        "createdAt" : "2020-07-06T21:39:02Z",
        "updatedAt" : "2020-07-21T00:12:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "26f562cf-7fd1-4b61-891b-fb696bcf5327",
        "parentId" : "e12e0814-8d39-44ba-975a-ca14e279217f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think the deprecation warning was part of a scheme to mark which tests should be rewritten: https://github.com/apache/kafka/pull/8864/files#r439685696",
        "createdAt" : "2020-07-06T23:39:35Z",
        "updatedAt" : "2020-07-21T00:12:06Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a712a400-c4d6-4aa3-9257-38be770afa1f",
        "parentId" : "e12e0814-8d39-44ba-975a-ca14e279217f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Correct. To make the build pass, we either need to add a `Suppress` annotation of just deprecate the test itself. Deprecating the test itself is \"cleaner\" IMHO.",
        "createdAt" : "2020-07-07T19:48:27Z",
        "updatedAt" : "2020-07-21T00:12:06Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fb9129bc-f4ec-4e87-847e-82343f9500da",
        "parentId" : "e12e0814-8d39-44ba-975a-ca14e279217f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Fair enough.",
        "createdAt" : "2020-07-08T16:42:31Z",
        "updatedAt" : "2020-07-21T00:12:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "e6c10d88f9c6fa9d89cc500112255898e2f24845",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +1529,1533 @@    }\n\n    @Deprecated\n    @Test\n    public void testOffsetCommitNumRetries() throws Exception {"
  },
  {
    "id" : "4dacfae4-b136-43dc-a99e-1294216a1321",
    "prId" : 9001,
    "prUrl" : "https://github.com/apache/kafka/pull/9001#pullrequestreview-456880892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "526cb58a-09ed-4dc0-8b56-8e44db2b60c1",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "We should have a matcher checking whether the sent request is pointing at the correct controller id.",
        "createdAt" : "2020-07-23T02:38:39Z",
        "updatedAt" : "2020-10-06T22:58:39Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "c982f718-242f-4630-aae8-ed9d8b312444",
        "parentId" : "526cb58a-09ed-4dc0-8b56-8e44db2b60c1",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "I have improved the matcher now, but how do I check the correct controller id?",
        "createdAt" : "2020-07-25T06:38:13Z",
        "updatedAt" : "2020-10-06T22:58:40Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "e51531a3-4be0-41de-aec6-0771ed2a3cdf",
        "parentId" : "526cb58a-09ed-4dc0-8b56-8e44db2b60c1",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "You are right, it seems not necessary.",
        "createdAt" : "2020-07-29T17:44:02Z",
        "updatedAt" : "2020-10-06T22:58:40Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1c79cee2ab243d95647935d2b3e7abe371bf6ea",
    "line" : 184,
    "diffHunk" : "@@ -1,1 +4032,4036 @@                controllerId,\n                Collections.emptyList()));\n            env.kafkaClient().prepareResponseFrom(\n                request -> request instanceof UpdateFeaturesRequest,\n                UpdateFeaturesResponse.createWithErrors("
  },
  {
    "id" : "b3e78b4f-e537-4235-a3e9-383b9c468cf6",
    "prId" : 9007,
    "prUrl" : "https://github.com/apache/kafka/pull/9007#pullrequestreview-448370078",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aec0c6ab-f454-42a1-85fd-4742b067b9f9",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "nit: In some of the other tests, you have an empty line after calling the method of the admin client. Shall we add one everywhere in order to be consistent? I personally like to have one before and after to separate blocks of code. I leave this up to you.",
        "createdAt" : "2020-07-14T18:58:34Z",
        "updatedAt" : "2020-07-28T07:45:50Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "d17d02f31f30ed64acc8609e0339cb9883a19316",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +1100,1104 @@                    env.cluster().nodeById(0));\n\n            DescribeLogDirsResult result = env.adminClient().describeLogDirs(brokers);\n\n            Map<Integer, KafkaFuture<Map<String, LogDirDescription>>> descriptions = result.descriptions();"
  },
  {
    "id" : "e136d35a-3d99-4980-8aa6-a860156fd2ca",
    "prId" : 9007,
    "prUrl" : "https://github.com/apache/kafka/pull/9007#pullrequestreview-448813870",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d6f21500-718c-4e17-9d3e-92d8456f163b",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "This is not due to your PR but shall we add a unit test which uses multiple brokers? ",
        "createdAt" : "2020-07-14T19:15:56Z",
        "updatedAt" : "2020-07-28T07:45:50Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "447062df-ca95-4f2d-aa3d-a2f7f6a2311c",
        "parentId" : "d6f21500-718c-4e17-9d3e-92d8456f163b",
        "authorId" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "body" : "I added it to the existing test. Due to the new helper methods I felt this didn't really complicate the test very much and is also allows us to cover the case where the RPC returns `STORAGE_ERROR`.",
        "createdAt" : "2020-07-15T10:09:04Z",
        "updatedAt" : "2020-07-28T07:45:50Z",
        "lastEditedBy" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "tags" : [
        ]
      }
    ],
    "commit" : "d17d02f31f30ed64acc8609e0339cb9883a19316",
    "line" : 195,
    "diffHunk" : "@@ -1,1 +1235,1239 @@\n    @Test\n    public void testDescribeReplicaLogDirs() throws ExecutionException, InterruptedException {\n        TopicPartitionReplica tpr1 = new TopicPartitionReplica(\"topic\", 12, 1);\n        TopicPartitionReplica tpr2 = new TopicPartitionReplica(\"topic\", 12, 2);"
  },
  {
    "id" : "905d6d1d-5e28-4035-909a-16d24ca214ca",
    "prId" : 9344,
    "prUrl" : "https://github.com/apache/kafka/pull/9344#pullrequestreview-498164286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9139481-d390-45df-af9b-d266e340268b",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I can see why we return the delta, but this looks odd when it says throttled with a time of zero.",
        "createdAt" : "2020-09-28T19:16:59Z",
        "updatedAt" : "2020-09-29T11:35:04Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "5f333f3c-0321-475d-8821-118f15043251",
        "parentId" : "e9139481-d390-45df-af9b-d266e340268b",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Yeah, I do agree but this could happen even if this should be rare. This test case is a bit stretched to verify that throttle time does not go below zero.\r\n\r\nThe reasoning of doing this is that a client could be throttled for longer than `default.api.timeout.ms`. When this happens, I believe that we should return an adjusted throttle time such that the client does not have to re-wait for the time that it has already waited for.",
        "createdAt" : "2020-09-29T07:23:46Z",
        "updatedAt" : "2020-09-29T11:35:04Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "503e39180f57eb0d2fc71266ee54c3e97ac4b3a9",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +736,740 @@            ThrottlingQuotaExceededException e = TestUtils.assertFutureThrows(result.values().get(\"topic2\"),\n                ThrottlingQuotaExceededException.class);\n            assertEquals(0, e.throttleTimeMs());\n            TestUtils.assertFutureThrows(result.values().get(\"topic3\"), TopicExistsException.class);\n        }"
  },
  {
    "id" : "4184033e-9dc0-4374-a099-a2f41c19d9e2",
    "prId" : 9374,
    "prUrl" : "https://github.com/apache/kafka/pull/9374#pullrequestreview-516576738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01664431-96c7-4d08-97a6-5cc971b943b0",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Would it make sense to extract these into separate unit tests? `testDescribeUserScramCredentials` could receive `users` as a argument such that we could reuse the code logic.",
        "createdAt" : "2020-10-26T07:03:50Z",
        "updatedAt" : "2020-10-26T07:05:29Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "1faad616-226c-42c8-84f5-370bed8dbc42",
        "parentId" : "01664431-96c7-4d08-97a6-5cc971b943b0",
        "authorId" : "8f67d23f-ccb2-42d3-8743-b54be3876b49",
        "body" : "We could but I do not see where we could reuse it, YAGNI?",
        "createdAt" : "2020-10-26T07:57:23Z",
        "updatedAt" : "2020-10-26T07:57:24Z",
        "lastEditedBy" : "8f67d23f-ccb2-42d3-8743-b54be3876b49",
        "tags" : [
        ]
      },
      {
        "id" : "428ac0eb-3922-4ad2-a0df-8a3e2c09b7cd",
        "parentId" : "01664431-96c7-4d08-97a6-5cc971b943b0",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Sorry, I was not clear. It would be great if we could define separate unit tests for the different cases that we want to test. In case of failure, we would know directly which one of the cases has failed. This is why I suggested to pass an argument `users` as an argument to `testDescribeUserScramCredentials`.",
        "createdAt" : "2020-10-26T08:53:03Z",
        "updatedAt" : "2020-10-26T08:53:03Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "19205b3d-8431-4ed1-8bdd-5c58d6d10ef7",
        "parentId" : "01664431-96c7-4d08-97a6-5cc971b943b0",
        "authorId" : "8f67d23f-ccb2-42d3-8743-b54be3876b49",
        "body" : "We can rewrite it to a test factory, this way we can keep it in one function and reuse the initialization logic but will have _n_ different tests being executed so that it is clear which one failed.",
        "createdAt" : "2020-10-26T09:03:12Z",
        "updatedAt" : "2020-10-26T09:03:12Z",
        "lastEditedBy" : "8f67d23f-ccb2-42d3-8743-b54be3876b49",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d769ba80365f6aedef35fe3e5872d1a97389381",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +4527,4531 @@            usersRequestedSet.add(user1Name);\n\n            for (final List<String> users : asList(null, new ArrayList<String>(), asList(user0Name, null, user1Name))) {\n                env.kafkaClient().prepareResponse(response);\n"
  },
  {
    "id" : "f1fd79dd-96ac-4065-ae74-4124ae142db6",
    "prId" : 9874,
    "prUrl" : "https://github.com/apache/kafka/pull/9874#pullrequestreview-567374046",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba19c092-8c5b-42a8-871d-ffc95c26f250",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "ditto",
        "createdAt" : "2021-01-13T16:00:45Z",
        "updatedAt" : "2021-01-13T18:53:57Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "24841495d245873106dc5c4a32af1fa6d2fa8bbd",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +326,330 @@     * an api call completes. If calling {@link Admin#close()} in callback, AdminClient thread hangs\n     */\n    @Test @Timeout(10)\n    public void testCloseAdminClientInCallback() throws InterruptedException {\n        MockTime time = new MockTime();"
  },
  {
    "id" : "daca33f6-a10a-4c01-bfec-3189a8027bcd",
    "prId" : 10281,
    "prUrl" : "https://github.com/apache/kafka/pull/10281#pullrequestreview-616764874",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe82053f-b159-4e85-8f19-2ac6d777fee9",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be simpler to check `isDone`.",
        "createdAt" : "2021-03-17T21:31:02Z",
        "updatedAt" : "2021-03-24T15:49:41Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "3ebb6a78-4305-4c8f-b3eb-a66683be4451",
        "parentId" : "fe82053f-b159-4e85-8f19-2ac6d777fee9",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "In this case, `isDone` is not supposed to be true until we advance the clock (so that a new node can be tried, after the previous one disconnected)",
        "createdAt" : "2021-03-19T20:20:07Z",
        "updatedAt" : "2021-03-24T15:49:41Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a00c1d8f12fcfcc3306d93f86f031d9f596871b",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +5361,5365 @@                time.sleep(1);\n                try {\n                    disconnectFuture.get(1, TimeUnit.MICROSECONDS);\n                    break;\n                } catch (java.util.concurrent.TimeoutException e) {"
  },
  {
    "id" : "0449c1ba-ab96-472a-b002-c3d7fcecdaa7",
    "prId" : 10483,
    "prUrl" : "https://github.com/apache/kafka/pull/10483#pullrequestreview-632351224",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6668d9b-45a4-4487-a8bf-c5ce68fc9e48",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "nit: One empty line could be removed.",
        "createdAt" : "2021-04-09T12:33:04Z",
        "updatedAt" : "2021-04-22T01:32:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "05155a22d065e9e7e6f165d40555269902e6abec",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +5446,5450 @@                coordinator.id(), TransactionState.COMPLETE_COMMIT, 12345L,\n                15, 10000L, OptionalLong.empty(), emptySet());\n\n            env.kafkaClient().prepareResponse(\n                request -> request instanceof FindCoordinatorRequest,"
  }
]