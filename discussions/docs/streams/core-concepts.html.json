[
  {
    "id" : "e16e2337-baeb-410f-a93b-b619d820c87c",
    "prId" : 4519,
    "prUrl" : "https://github.com/apache/kafka/pull/4519#pullrequestreview-102903512",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27e4459b-bcda-494e-97ee-dd14a33dea62",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note users can also explicitly override the default assigned timestamp of the generated results when sending to the downstream processor via <code>#forward()</code>",
        "createdAt" : "2018-03-11T19:16:55Z",
        "updatedAt" : "2018-03-16T00:26:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "184ff9f3-8d88-42c5-ac8c-5a56fc24266b",
        "parentId" : "27e4459b-bcda-494e-97ee-dd14a33dea62",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes. It seems to be covered already in L125.",
        "createdAt" : "2018-03-12T00:34:13Z",
        "updatedAt" : "2018-03-16T00:26:51Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a24643caadd76196cc325e747476f3514af8a381",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +129,133 @@\n    <p>\n\tNote, that the describe default behavior can be changed in the Processor API by assigning timestamps to output records explicitly when calling <code>#forward()</code>.\n    </p>\n"
  },
  {
    "id" : "eaa24db9-d43f-4973-a5ef-4f5c87e412f9",
    "prId" : 4876,
    "prUrl" : "https://github.com/apache/kafka/pull/4876#pullrequestreview-112472683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ea6766e-66da-4ff2-81ff-e93e039da7fd",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We can make it `<a id=\"#streams_processor_node\" href=\"#streams_processor_node\">` as we did for other refs.",
        "createdAt" : "2018-04-16T15:39:47Z",
        "updatedAt" : "2018-04-16T16:49:32Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc8f9de42d1c1d577bf859028b67208a5f33f2ee",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +64,68 @@        <li>A <b>stream</b> is the most important abstraction provided by Kafka Streams: it represents an unbounded, continuously updating data set. A stream is an ordered, replayable, and fault-tolerant sequence of immutable data records, where a <b>data record</b> is defined as a key-value pair.</li>\n        <li>A <b>stream processing application</b> is any program that makes use of the Kafka Streams library. It defines its computational logic through one or more <b>processor topologies</b>, where a processor topology is a graph of stream processors (nodes) that are connected by streams (edges).</li>\n        <li>A <b><a id=\"streams_processor_node\" href=\"#streams_processor_node\">stream processor</a></b> is a node in the processor topology; it represents a processing step to transform data in streams by receiving one input record at a time from its upstream processors in the topology, applying its operation to it, and may subsequently produce one or more output records to its downstream processors. </li>\n    </ul>\n"
  }
]