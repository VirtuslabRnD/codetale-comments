[
  {
    "id" : "6de8d3bd-876e-448b-b157-d2990bd742dd",
    "prId" : 12937,
    "prUrl" : "https://github.com/apache/airflow/pull/12937#pullrequestreview-548023308",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe922fff-fc83-4c3b-9558-bafdf3ef5c3f",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Nice !",
        "createdAt" : "2020-12-09T10:06:31Z",
        "updatedAt" : "2020-12-09T10:06:32Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "552c309d65b905ead1a599e5517e480e3b7e6e1b",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +93,97 @@running on different workers on different nodes on the network is all handled by Airflow.\n\nNow to actually enable this to be run as a DAG, we invoke the python function\n``tutorial_taskflow_api_etl`` set up using the ``@dag`` decorator earlier, as shown below.\n"
  }
]