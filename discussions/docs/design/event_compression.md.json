[
  {
    "id" : "b30bc746-b59b-46c2-9526-a063a31e46a8",
    "prId" : 16798,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd4147ec-5727-4128-a344-70247b654018",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "s/It's/Its/\n",
        "createdAt" : "2015-11-11T20:59:44Z",
        "updatedAt" : "2015-11-11T20:59:44Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "6ad7f1a8cb892b8b881c8a72355b74ed4f4f3078",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +75,79 @@   * The `EventAggregator` runs an aggregation function over each event.  This function buckets each event based on an `aggregateKey`,\n   and identifies the event uniquely with a `localKey` in that bucket.\n   * The default aggregation function groups similar events that differ only by `event.Message`.  It's `localKey` is `event.Message` and its aggregate key is produced by joining:\n     * `event.Source.Component`\n     * `event.Source.Host`"
  },
  {
    "id" : "39408f7a-434d-4058-94a0-a5f29052483d",
    "prId" : 11400,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e91f2822-7a08-4607-98dd-90cc920d4173",
        "parentId" : null,
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "I saw this in another PR. Code links aren't going to work on gh_pages. I think we should punt on that, though. I don't see a good solution.\n",
        "createdAt" : "2015-07-16T23:21:56Z",
        "updatedAt" : "2015-07-16T23:28:28Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "9e1a821b-4822-44f4-9dd2-eae21746ac20",
        "parentId" : "e91f2822-7a08-4607-98dd-90cc920d4173",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Yeah, that's something we'd have to fix in the gh_pages .html generation.\n",
        "createdAt" : "2015-07-16T23:24:08Z",
        "updatedAt" : "2015-07-16T23:28:28Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "98eeadb66e1042ce1ab6c1e75fbb69db00e334a8",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +48,52 @@Each binary that generates events:\n * Maintains a historical record of previously generated events:\n   * Implemented with [\"Least Recently Used Cache\"](https://github.com/golang/groupcache/blob/master/lru/lru.go) in [```pkg/client/record/events_cache.go```](../../pkg/client/record/events_cache.go).\n   * The key in the cache is generated from the event object minus timestamps/count/transient fields, specifically the following events fields are used to construct a unique key for an event:\n     * ```event.Source.Component```"
  },
  {
    "id" : "25b925ac-8b4d-4395-9b02-7272c849e25f",
    "prId" : 4372,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd9694ca-d1c3-4f49-a9df-8cab5fc9a61c",
        "parentId" : null,
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "If we are not careful, people may put ever-changing vaules into the strings of Reason and/or Message.\nWe can wait to see if this is actually a problem, but experience suggests it will.\nSome options then are:\n- if the event creations rate is too high over a time window, begin collapsing events even if they have the differing Reason and Message.  \n- use locality sensitive hashing \n- use structured logging, in the style of https://github.com/Sirupsen/logrus to generate event.Message and event.Reason\n",
        "createdAt" : "2015-02-12T05:18:13Z",
        "updatedAt" : "2015-02-12T05:18:13Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      },
      {
        "id" : "0e21f4b5-8de7-4c14-b42b-e8b3ae849a60",
        "parentId" : "dd9694ca-d1c3-4f49-a9df-8cab5fc9a61c",
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "Actually, this is not hypothetical.  I think it can easily happen today.\nIf a pod is repeatedly terminating and being restarted by an RC, and you have a lot of nodes, then you are going to see this Message:\n`Successfully assigned kibana-logging-controller-$FOO to kubernetes-minion-$BAR.c.saad-dev-vms.internal`\na bunch of times with different values of $FOO and $BAR.\nSo, this needs attention sooner rather than later.\n",
        "createdAt" : "2015-02-12T05:28:54Z",
        "updatedAt" : "2015-02-12T05:28:54Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      },
      {
        "id" : "9d68fe74-d381-4288-91a3-6ee882e342e9",
        "parentId" : "dd9694ca-d1c3-4f49-a9df-8cab5fc9a61c",
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "I have lots more to say about this topic, which might be better said tomorrow in the office, over a tasty beverage.\n",
        "createdAt" : "2015-02-12T05:34:59Z",
        "updatedAt" : "2015-02-12T05:34:59Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2d432005f23f7e7376a70076917b07d71a53deb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +35,39 @@     * ```event.InvolvedObject.UID```\n     * ```event.InvolvedObject.APIVersion```\n     * ```event.Reason```\n     * ```event.Message```\n   * If the key for a new event matches the key for a previously generated events (meaning all of the above fields match between the new event and some previously generated event), then the event is considered to be a duplicate:"
  },
  {
    "id" : "c5cba826-5f46-40c9-b8fe-290a6f7ee4a0",
    "prId" : 4372,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5f3cf3e-b771-4a6f-aacd-edfb825b54d5",
        "parentId" : null,
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "This should be handled now, not in the future.\nThe cache should be fixed size, not a time-based cleanup.\nConsider using an lru cache like https://github.com/hashicorp/golang-lru.\n",
        "createdAt" : "2015-02-12T05:24:35Z",
        "updatedAt" : "2015-02-12T05:24:35Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2d432005f23f7e7376a70076917b07d71a53deb",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +47,51 @@ * Hash table clean up\n   * If the component (e.g. kubelet) runs for a long period of time and generates a ton of unique events, the hash table could grow very large in memory.\n   * *Future consideration:* remove entries from the hash table that are older than some specified time.\n * Event history is not preserved across application restarts\n   * Each component keeps track of event history in memory, a restart causes event history to be cleared."
  }
]