[
  {
    "id" : "d7551aea-fb19-402b-af15-7b9089eb016a",
    "prId" : 33696,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/33696#pullrequestreview-2049266",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e729310-025a-4971-b004-5ce0b66607a1",
        "parentId" : null,
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "Perhaps file an issue to cover this audit as well?\n",
        "createdAt" : "2016-09-28T23:28:01Z",
        "updatedAt" : "2016-09-28T23:28:01Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1aaf79fb48632cc9a2807e9a836bb1049d262c6",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +213,217 @@and the network plugin architecture Kubernetes uses needs to allow returning\nIPv6 addresses too [CNI issue #245](https://github.com/containernetworking/cni/issues/245).\nKubernetes code that deals with IP addresses must then be audited and fixed to\nsupport both IPv4 and IPv6 addresses and not assume IPv4.\nAdditionally, direct ipv6 assignment to instances doesn't appear to be supported"
  },
  {
    "id" : "144a46d4-72b9-4235-80a6-ae95a28118c4",
    "prId" : 7518,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6acb2f16-13b4-4ce9-ba12-57a24b688de1",
        "parentId" : null,
        "authorId" : "9c668715-22fc-4e1d-a673-80ba46f7bd46",
        "body" : "Who will manage the iptables? Can a network-provider be free to not use iptables too, in lieu of its own solution. May not even need any extra work with an ipvlan based solution, e.g.\n",
        "createdAt" : "2015-04-29T19:38:27Z",
        "updatedAt" : "2015-05-11T22:36:09Z",
        "lastEditedBy" : "9c668715-22fc-4e1d-a673-80ba46f7bd46",
        "tags" : [
        ]
      },
      {
        "id" : "3be06d1d-c552-4930-a279-a59a44e5d76a",
        "parentId" : "6acb2f16-13b4-4ce9-ba12-57a24b688de1",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "the iptables is purely for external ip -> internal ip rewriting.  Even if you have ipvlan, I don't think that you can map the external IP to the pod without iptables, unless you somehow make the bridge that the container allocates addresses out of contain external IP addresses, but that seems pretty tricky (and dangerous) you're always going to want something that NATs the packet from external to internal IP.  I suppose you could do that at the edge instead, if you want to...\n",
        "createdAt" : "2015-05-01T00:27:03Z",
        "updatedAt" : "2015-05-11T22:36:09Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      },
      {
        "id" : "b8336cb9-047a-4a14-976a-10db937aec97",
        "parentId" : "6acb2f16-13b4-4ce9-ba12-57a24b688de1",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "I'm a little confused about the future-tense here.   Are you describing host ports (which is what #15 is about) or kube-proxy?  We shouldn't spend too much time on host ports, and we shouldn't be adding features in that space.\n",
        "createdAt" : "2015-05-05T22:57:07Z",
        "updatedAt" : "2015-05-11T22:36:09Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "f163a9b7-eba8-46ac-bcff-bf123e34c8ea",
        "parentId" : "6acb2f16-13b4-4ce9-ba12-57a24b688de1",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "disregard my comment this is fine.\n",
        "createdAt" : "2015-05-06T16:03:27Z",
        "updatedAt" : "2015-05-11T22:36:09Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb8091d4dac0622681d14b9048ed061db726b880",
    "line" : null,
    "diffHunk" : "@@ -1,1 +103,107 @@\n3. Internet -> Container. This also has to go through the primary host IP and has 1 level of NAT, ideally. However, the path currently is a proxy with (External Host IP -> Internal Host IP -> Docker) -> (Docker -> Container IP). Once [issue #15](https://github.com/GoogleCloudPlatform/kubernetes/issues/15) is closed, it should be External Host IP -> Container IP. The way that this will work is that each\ncontainer that wants to be present on the external internet will specify an external ip address.  The IP address will be trapped via IPTables on the host node and re-written to the container IP address.\nIt is the responsibility of the cluster network adminstrator to make sure that these external IP addresses are routed to appropriate host machine.  In cloud provider environments this may involve\nsetting up advanced routing rules, external load balancers, or both.  On physical networks this will envolve configuring a gateway router to receive packets for that IP address and forward them on to"
  },
  {
    "id" : "aeb384f5-4ac8-453f-be63-785d3652ecd0",
    "prId" : 7270,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33ddaddf-4d74-46e8-96d7-fbc5611ddd67",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Should this paragraph be updated to reflect service IPs? Unless I am mis-reading it is saying we don't have that feature yet.\n",
        "createdAt" : "2015-04-23T23:52:44Z",
        "updatedAt" : "2015-04-23T23:52:44Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "e35546f7-9a22-42aa-b1fe-94aac5cc9a93",
        "parentId" : "33ddaddf-4d74-46e8-96d7-fbc5611ddd67",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "I did not edit any docs, just updated the links to the new form - purely\nmechanical.\n\nOn Thu, Apr 23, 2015 at 4:53 PM, David Oppenheimer <notifications@github.com\n\n> wrote:\n> \n> In docs/design/networking.md\n> https://github.com/GoogleCloudPlatform/kubernetes/pull/7270#discussion_r29014353\n> :\n> \n> > @@ -83,7 +83,7 @@ We want to be able to assign IP addresses externally from Docker ([Docker issue\n> > \n> >  In addition to enabling self-registration with 3rd-party discovery mechanisms, we'd like to setup DDNS automatically ([Issue #146](https://github.com/GoogleCloudPlatform/kubernetes/issues/146)). hostname, $HOSTNAME, etc. should return a name for the pod ([Issue #298](https://github.com/GoogleCloudPlatform/kubernetes/issues/298)), and gethostbyname should be able to resolve names of other pods. Probably we need to set up a DNS resolver to do the latter ([Docker issue #2267](https://github.com/dotcloud/docker/issues/2267)), so that we don't need to keep /etc/hosts files up to date dynamically.\n> > \n> > -[Service](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md) endpoints are currently found through environment variables.  Both [Docker-links-compatible](https://docs.docker.com/userguide/dockerlinks/) variables and kubernetes-specific variables ({NAME}_SERVICE_HOST and {NAME}_SERVICE_BAR) are supported, and resolve to ports opened by the service proxy. We don't actually use [the Docker ambassador pattern](https://docs.docker.com/articles/ambassador_pattern_linking/) to link containers because we don't require applications to identify all clients at configuration time, yet.  While services today are managed by the service proxy, this is an implementation detail that applications should not rely on.  Clients should instead use the [service portal IP](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md) (which the above environment variables will resolve to).  However, a flat service namespace doesn't sca\n> >  le and e\n> >  nvironment variables don't permit dynamic updates, which complicates service deployment by imposing implicit ordering constraints.  We intend to register each service portal IP in DNS, and for that to become the preferred resolution protocol.\n> > +[Service](http://docs.k8s.io/services.md) endpoints are currently found through environment variables.  Both [Docker-links-compatible](https://docs.docker.com/userguide/dockerlinks/) variables and kubernetes-specific variables ({NAME}_SERVICE_HOST and {NAME}_SERVICE_BAR) are supported, and resolve to ports opened by the service proxy. We don't actually use [the Docker ambassador pattern](https://docs.docker.com/articles/ambassador_pattern_linking/) to link containers because we don't require applications to identify all clients at configuration time, yet.  While services today are managed by the service proxy, this is an implementation detail that applications should not rely on.  Clients should instead use the [service portal IP](http://docs.k8s.io/services.md) (which the above environment variables will resolve to).  However, a flat service namespace doesn't scale and environment variables don't permit dynamic updates, which complicates service deploym\n> >  ent by i\n> >  mposing implicit ordering constraints.  We intend to register each service portal IP in DNS, and for that to become the preferred resolution protocol.\n> \n> Should this paragraph be updated to reflect service IPs? Unless I am\n> mis-reading it is saying we don't have that feature yet.\n> \n> â€”\n> Reply to this email directly or view it on GitHub\n> https://github.com/GoogleCloudPlatform/kubernetes/pull/7270/files#r29014353\n> .\n",
        "createdAt" : "2015-04-24T00:00:24Z",
        "updatedAt" : "2015-04-24T00:00:24Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "dbd4c90b-6fff-4155-8a24-507c380f4206",
        "parentId" : "33ddaddf-4d74-46e8-96d7-fbc5611ddd67",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Understood, I was just wondering if you wanted to fix this at the same time. Anyway, I'll merge and we can fix it another time.\n",
        "createdAt" : "2015-04-24T00:18:37Z",
        "updatedAt" : "2015-04-24T00:18:37Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "12e4e8f30485a5ef6223e548df3fc0e9f456190c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +84,88 @@In addition to enabling self-registration with 3rd-party discovery mechanisms, we'd like to setup DDNS automatically ([Issue #146](https://github.com/GoogleCloudPlatform/kubernetes/issues/146)). hostname, $HOSTNAME, etc. should return a name for the pod ([Issue #298](https://github.com/GoogleCloudPlatform/kubernetes/issues/298)), and gethostbyname should be able to resolve names of other pods. Probably we need to set up a DNS resolver to do the latter ([Docker issue #2267](https://github.com/dotcloud/docker/issues/2267)), so that we don't need to keep /etc/hosts files up to date dynamically.\n\n[Service](http://docs.k8s.io/services.md) endpoints are currently found through environment variables.  Both [Docker-links-compatible](https://docs.docker.com/userguide/dockerlinks/) variables and kubernetes-specific variables ({NAME}_SERVICE_HOST and {NAME}_SERVICE_BAR) are supported, and resolve to ports opened by the service proxy. We don't actually use [the Docker ambassador pattern](https://docs.docker.com/articles/ambassador_pattern_linking/) to link containers because we don't require applications to identify all clients at configuration time, yet.  While services today are managed by the service proxy, this is an implementation detail that applications should not rely on.  Clients should instead use the [service portal IP](http://docs.k8s.io/services.md) (which the above environment variables will resolve to).  However, a flat service namespace doesn't scale and environment variables don't permit dynamic updates, which complicates service deployment by imposing implicit ordering constraints.  We intend to register each service portal IP in DNS, and for that to become the preferred resolution protocol.\n\nWe'd also like to accommodate other load-balancing solutions (e.g., HAProxy), non-load-balanced services ([Issue #260](https://github.com/GoogleCloudPlatform/kubernetes/issues/260)), and other types of groups (worker pools, etc.). Providing the ability to Watch a label selector applied to pod addresses would enable efficient monitoring of group membership, which could be directly consumed or synced with a discovery mechanism. Event hooks ([Issue #140](https://github.com/GoogleCloudPlatform/kubernetes/issues/140)) for join/leave events would probably make this even easier."
  }
]