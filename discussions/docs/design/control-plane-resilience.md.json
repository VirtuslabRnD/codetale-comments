[
  {
    "id" : "94002bd5-a4ed-46fc-8132-d9ee174b3889",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ec25a44-cf12-4ce9-bed4-ccb15775273f",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "why \"one\" instead of N-1? (i concede that even if you meant N-1, \"one\" is still a true statement. but if you meant N-1, it's better to say N-1.) for example, if I have a cluster that spans 3 zones, why should it behave any differently if 2 zone fails than if 1 zone fails?\n",
        "createdAt" : "2016-01-08T19:53:16Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "a4739f36-2b27-4ba8-b8c0-6a603fc3e6b2",
        "parentId" : "4ec25a44-cf12-4ce9-bed4-ccb15775273f",
        "authorId" : null,
        "body" : "@davidopp Because of quora. A 3-zone cluster where 2 zones are failed, does not have a majority quorum remaining, while with only 1 failed zone it does.  Note that \"N-1\" usually refers to the number of zones that remain (i.e. if we have N zones, and one fails, we have N-1 zones remaining).  If what you're actually asking is whether we want to be resilient to two simultaneous availability zone failures (i.e. \"N-2\"), the answer is that we could be, provided that N>=5  (i.e. we can always be resilient to ceil(N/2)-1 failures.   \n",
        "createdAt" : "2016-01-12T00:49:34Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +80,84 @@1. **Resilience to some correlated failures:** Kubernetes clusters\n   which span multiple availability zones in a region should by\n   default be resilient to complete failure of one entire availability\n   zone (by similarly providing self-healing and high availability in\n   the default cluster creation scripts as above)."
  },
  {
    "id" : "572bd56a-9cbe-4c0f-bc52-cd0e605f7ce3",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b559394-ede1-43c5-9b9c-a4aed78aa8f9",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "It might be good to make these three categories a little more concrete, which would also help the reader understand why they are increasingly good points on a spectrum. Something like\n1. Manual recovery from failure of control plane components, with downtime during the recovery due to un-replicated control plane components\n2. Automatic recovery from failure of control plane components, with downtime during the recovery due to un-replicated control plane components\n3. No-downtime recovery from failure of control plane components, due to replicated control plane components (under certain assumptions about correlated failure)\n",
        "createdAt" : "2016-01-08T19:53:44Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "718174ec-3c2f-4e13-8a72-fe5879b0e460",
        "parentId" : "5b559394-ede1-43c5-9b9c-a4aed78aa8f9",
        "authorId" : null,
        "body" : "@davidopp Actually I think that sort of explanation perhaps makes things more difficult to understand, and confuses a few orthogonal issues, like manual vs automatic recovery, and downtime vs no-downtime failures.  For example, even with replicated control plane components, manual recovery might be necessary (e.g. in cases of data corruption of replicated data).  So in that case down time is due to roll back/data restoration/reconstruction delays, not lack of replicated components.  I'm inclined to leave it as is.\n",
        "createdAt" : "2016-01-12T01:14:24Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +108,112 @@   continuous integration testing, and disaster recovery exercises.\n\n## Relative Priorities\n\n1. **(Possibly manual) recovery from catastrophic failures:** having a Kubernetes cluster, and all"
  },
  {
    "id" : "18682796-8256-4a62-8aaa-cddf4dbdbab4",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Say a little more about under what circumstances users get replicated API server and what circumstances users get single API server? (number of cluster nodes, kube-up flag, start up cluster in a particular way, whatever) Or at least make it clear that some ways of starting kube give you a single API server and some give you replicated, without providing the details.\n",
        "createdAt" : "2016-01-08T19:59:39Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "0c75ecaa-f18c-43b8-b4d8-7d4175ad1bce",
        "parentId" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "authorId" : null,
        "body" : "That's covered explicitly elsewhere in the doc.  By default kube-up will build replicated API server, irrespective of the number of nodes. To disable that, a flag is provided.\n",
        "createdAt" : "2016-01-08T20:52:12Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "385f5d8b-366d-4c35-abc3-d4ae63030cf0",
        "parentId" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : ">  By default kube-up will build replicated API server\n\nCan you point me to the code for that? IIUC `kube-up` in cluster/gce/util.sh calls `create-master-instance` which only creates one master VM and thus only one API server. I thought you had to use the instructions here\nhttps://github.com/kubernetes/kubernetes/blob/master/docs/admin/high-availability.md\nto get multiple API servers.\n",
        "createdAt" : "2016-01-09T01:33:40Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "555f63c7-7e91-490b-99c7-e205898023bb",
        "parentId" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "authorId" : null,
        "body" : "It's probably easiest to read this doc via the \"view\" button at the top, which will give you a formatted view.  You'll notice that this paragraph is in the \"resilience plan\" column of the table.  i.e. this is the plan, as opposed to the current state (which is in the column to the right).  Make sense?\n",
        "createdAt" : "2016-01-09T17:06:39Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "0c0b3bd0-c813-40fd-96d2-46e750ad12c6",
        "parentId" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Right, I know about the view button, I just didn't notice you had formatting in here so wasn't using it. Sorry for the confusion.\n",
        "createdAt" : "2016-01-09T19:45:30Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "3e56b8e8-1fed-4bb8-84ef-1696c7cb9bfb",
        "parentId" : "d257101b-c35f-4f2f-b2bd-b94bcbdbf450",
        "authorId" : null,
        "body" : "OK, done.\n",
        "createdAt" : "2016-01-12T02:02:52Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : null,
    "diffHunk" : "@@ -1,1 +174,178 @@\nMultiple stateless, self-hosted, self-healing API servers behind a HA\nload balancer, built out by the default \"kube-up\" automation on GCE,\nAWS and basic bare metal (BBM).  Note that the single-host approach of\nhving etcd listen only on localhost to ensure that onyl API server can"
  },
  {
    "id" : "90840716-f7e6-4445-aa15-22ad7c16baba",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69d8d9ab-98d9-4e67-bf66-d72f7475b105",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Maybe make this a little more explicit -- even if you have replicated API servers, if you lose a replica nothing re-creates it.\n",
        "createdAt" : "2016-01-08T19:59:41Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "a2486c5e-66ed-40b4-963d-9cc1d8674e6a",
        "parentId" : "69d8d9ab-98d9-4e67-bf66-d72f7475b105",
        "authorId" : null,
        "body" : "\"No scripted self-healing\" was supposed to capture that, but I guess I can repeat that in other words to make it really clear.\n",
        "createdAt" : "2016-01-08T20:37:49Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "6a46a48d-304f-4033-9ca1-224bcb25b98f",
        "parentId" : "69d8d9ab-98d9-4e67-bf66-d72f7475b105",
        "authorId" : null,
        "body" : "@davidopp I've updated the terms section as follows, to hopefully make this clearer.\n\n## Terms\n- **Self-healing:** automatically restarting or replacing failed\n  processes and machines without human intervention\n- **High availability:** continuing to be available and work correctly\n  even if some components are down or uncontactable.  This typically\n  involves multiple replicas of critical services, and a reliable way\n  to find available replicas.  Note that it's possible (but not\n  desirable) to have high\n  availability properties (e.g. multiple replicas) in the absence of\n  self-healing properties (e.g. if a replica fails, nothing replaces\n  it). Fairly obviously, given enough time, such systems typically\n  become unavailable (after enough replicas have failed). \n",
        "createdAt" : "2016-01-12T01:32:58Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : null,
    "diffHunk" : "@@ -1,1 +197,201 @@currently an automated process, and it is not tested as part of\ncontinuous integration.  So it's probably safest to assume that it\ndoesn't actually work in practise.\n\n</td>"
  },
  {
    "id" : "48d42946-6417-4075-aa0a-70ff0af9304b",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Same comment here as at beginning of last section. \"built out by\" is pretty vague.\n",
        "createdAt" : "2016-01-08T20:00:08Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "2a0fe880-d18b-4a23-864a-f042450e2743",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "\"warm standby\" isn't really the right term because that implies data is mirrored to the replicas, which we don't do.\n",
        "createdAt" : "2016-01-08T20:01:48Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "bcd3afc7-1118-49e6-a76f-63a38b01f997",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I didn't realize it was self-healing. If machine running a controller manager replica permanently dies, how does a replacement get started up on another machine?\n",
        "createdAt" : "2016-01-08T20:04:03Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "9091407c-3dea-436e-a2f0-4ad8d6135b55",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : null,
        "body" : "https://cloud.google.com/compute/docs/instance-groups/\n\n\"If an instance in the group stops, crashes, or is deleted by an action other than the instance groups commands, the managed instance group automatically recreates the instance so it can resume its processing tasks. The recreated instance uses the same name and the same instance template as the previous instance\".\n",
        "createdAt" : "2016-01-08T20:45:07Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "6a4ae9e7-ac4b-4bd3-b2ff-2b50b211b590",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : null,
        "body" : "To be clear, this is plan, not the current reality, as reflected by the column it occupies in this table.\n",
        "createdAt" : "2016-01-08T20:53:33Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "5f3d0416-4c26-44f3-b7a3-c0f84ba41d2e",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "oops, I was reading the PR text, not viewing it as an .md file, so I totally missed that there was a table. :-)\n",
        "createdAt" : "2016-01-09T01:25:06Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "73f6f900-09a2-417a-9ac5-3c2f0d5da6ec",
        "parentId" : "9819ae5f-bd11-46a6-b2ac-76e7ab64a8a7",
        "authorId" : null,
        "body" : "Regarding \"warm standby\", I believe I've used the term in the traditional sense.  I think you're thinking of hot standby?  For example:\nhttps://www.ibm.com/developerworks/community/blogs/RohitShetty/entry/high_availability_cold_warm_hot?lang=en\n- *\\* Warm Standby: *\\* The software component is installed and available on the secondary node. The secondary node is up and running. In the case of a failure on the primary node, these software components are started on the secondary node. This process is usually automated using a cluster manager.Data is regularly mirrored to secondary system using disk based replication or shared disk. This generally provides a recovery time of a few minutes.\n- *\\* Hot Standby: *\\* Software components are installed and available on both primary and secondary nodes. The software components on the secondary system are up but will not process data or requests. Data is mirrored in near real time and both systems will have identical data. Data replication is typically done through the softwareâ€™s capabilities. This generally provides a recovery time of a few seconds.\n",
        "createdAt" : "2016-01-12T02:06:18Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : null,
    "diffHunk" : "@@ -1,1 +205,209 @@<td>\n\nMultiple self-hosted, self healing warm standby stateless controller\nmanagers and schedulers with leader election and automatic failover of API server\nclients, automatically installed by default \"kube-up\" automation."
  },
  {
    "id" : "ae72159c-85cd-4f72-8fd5-377f702e572b",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57508ee4-b28e-49bc-8bac-bd249856a154",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "On cloud providers (AWS/GCE) we shouldn't need to care about boot disks at all, as there isn't anything useful stored on the boot disks (which is why we can delete the master VM, including the boot disk, during an [upgrade](https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/upgrade.sh#L71-L89)). For bare metal, this may be different, but if that is the only case where this matters it should be called out explicitly. \n",
        "createdAt" : "2016-01-19T18:18:33Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "22ad9083-0a9b-4177-95bc-a6906c3180cc",
        "parentId" : "57508ee4-b28e-49bc-8bac-bd249856a154",
        "authorId" : null,
        "body" : "Agreed.  That's covered in the second point below, \"reconstructable\".\n",
        "createdAt" : "2016-01-19T20:21:40Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : null,
    "diffHunk" : "@@ -1,1 +146,150 @@           recovery](https://github.com/coreos/etcd/blob/master/Documentation/admin_guide.md#disaster-recovery)).\n\n    1. and boot disks are either:\n        1. truely persistent (i.e. remote persistent disks), or\n        1. reconstructible (e.g. using boot-from-snapshot,"
  },
  {
    "id" : "87609103-caaf-4369-abc9-233880ec734e",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c740bad5-60d1-4a2a-9ac0-7bdced85b163",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "Right now we explicitly disallow access from anything other than the apiserver to etcd by making etcd only listen on localhost. If you put it behind a load balancer without adding any authorization capabilities, then this will make it trivial for anyone to access the \"private store\" for the apiserver directly. \n",
        "createdAt" : "2016-01-19T18:26:04Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "cb89ad0f-9d3e-47a1-9695-1665807e98e4",
        "parentId" : "c740bad5-60d1-4a2a-9ac0-7bdced85b163",
        "authorId" : null,
        "body" : "@robertbailey Good point, we'll need to address that (either using firewall rules, SSL certs, or something else).  I'll add a note here so that we don't forget about it when implementing.\n",
        "createdAt" : "2016-01-19T20:26:23Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "2060a2d8-cb88-496b-8653-6cef4ebeb7c3",
        "parentId" : "c740bad5-60d1-4a2a-9ac0-7bdced85b163",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "We support all the flags for SSL from masters to etcd (that's how openshift runs out of the box) and I _thought_ we had ansible scripts to do it, even if it's not in salt yet.\n",
        "createdAt" : "2016-01-25T02:01:46Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "7419cc9a-0f65-4a6b-9cc8-0f23b1f3122a",
        "parentId" : "c740bad5-60d1-4a2a-9ac0-7bdced85b163",
        "authorId" : null,
        "body" : "Done.\n",
        "createdAt" : "2016-02-26T23:53:44Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : null,
    "diffHunk" : "@@ -1,1 +216,220 @@<td>\n\nMultiple (3-5) etcd quorum members behind a load balancer with session\naffinity (to prevent clients from being bounced from one to another).\n"
  },
  {
    "id" : "7f37bb5b-f8ac-46eb-a824-24b6583e62eb",
    "prId" : 19313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c620c5b-24ac-49cc-8d87-5da96af12926",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "s/or uncontactable/or unavailable\n",
        "createdAt" : "2016-01-19T21:59:55Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "20846ea6-2d3f-4e38-9f83-894b01ccf607",
        "parentId" : "2c620c5b-24ac-49cc-8d87-5da96af12926",
        "authorId" : null,
        "body" : "I was actually trying to draw an explicit distinction between dead software ('down') and healthy software that's simply not visible due to a network partition ('uncontactable'). @timothysc I think I'll leave it as is, unless you have violent objections.\n",
        "createdAt" : "2016-02-26T22:36:01Z",
        "updatedAt" : "2016-03-03T23:50:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "227710d25b044096fc47c104ad8fd9c3e9f999da",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +53,57 @@  processes and machines without human intervention\n* **High availability:** continuing to be available and work correctly\n  even if some components are down or uncontactable.  This typically\n  involves multiple replicas of critical services, and a reliable way\n  to find available replicas.  Note that it's possible (but not"
  }
]