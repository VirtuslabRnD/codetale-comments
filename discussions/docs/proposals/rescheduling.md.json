[
  {
    "id" : "777a45ee-4dde-439f-8e24-30e22f4d440f",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "parentId" : null,
        "authorId" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "body" : "Given that we have a pretty tight container abstraction and live migration has come a long way, should we consider if live container (pod) migration isn't a better way to go?  At the least, it probably deservers an \"alternatives considered\" entry.\n",
        "createdAt" : "2016-03-01T00:14:26Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "tags" : [
        ]
      },
      {
        "id" : "29d723d3-4f53-49c8-8bc2-f5e13b6f0c2b",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : null,
        "body" : "We (and the user) would still need to deal with the node failure case, where live migration is impossible.  So it becomes a matter of how many terminations the client sees, not whether they see them.  Unless the reduction in number of terminations is dramatic and crucial (which I don't think it is), I think that the consistency of termination/failure semantics wins here (i.e. pods always terminate and replacements are created, rather than pods sometimes moving, and sometimes dieing and being replaced). \n",
        "createdAt" : "2016-03-01T16:36:36Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "10f7cd7c-68af-4285-9529-1143943cdba6",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "I would prefer we avoid live container (pod) migration, and I would imagine the rescheduler will continue to respect graceful termination.\n",
        "createdAt" : "2016-03-01T19:06:53Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "62a60314-33ab-481f-96a1-b778b9bc09a8",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "+1 for avoiding live migration. Currently, Pods in k8s are stateless, we save data in PersistentVolume, so live migration is less meaningful.\n",
        "createdAt" : "2016-03-02T02:38:47Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "3f8b35b1-b5a4-4af6-b99a-729f5253a9d9",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "+1 for avoiding live migration.\n",
        "createdAt" : "2016-03-02T02:50:14Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "2878a3fb-b25c-43f8-b3c3-bf2915ab1c58",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "-1 for avoiding live migration. I have a lot stateful applications to take care of:-(\n",
        "createdAt" : "2016-03-03T09:51:15Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "11da2511-79f9-4572-af11-f6bac66d3868",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "This proposal doesn't preclude migration, and this functionality would be required in order to implement migration.\n\nHowever, migration would be a lot more work than what is described here.\n\nMigration is covered by #3949.\n",
        "createdAt" : "2016-03-07T04:09:05Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "6e2a9615-4466-4153-939e-028206808a10",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Right. More generally, this proposal is an attempt to define an initial version and short-term roadmap, not the entire design space or long-term ideas. Once live migration of containers is available (the containerd docs seem to imply it will be soon? https://github.com/docker/containerd ) I would assume Kubernetes will take advantage of it.\n",
        "createdAt" : "2016-03-07T04:24:42Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "2d6ef955-aabc-4bf8-8cb4-33ab40ebae5f",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "@hurf Persisted state can still be \"migrated\" via persistent volume claim or flocker. Presumably the stateful applications have to be able to deal with restart after failure, so migrating the in-memory state shouldn't be strictly necessary.\n",
        "createdAt" : "2016-04-12T07:06:32Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "3164d879-48c0-4245-b8d3-99471ae113a7",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "Yes, that's what we do now.  A problem is dealing with failure sometime may lower performance indicator of a service(doesn't mean not going to deal with the failure, but try to reduce failure). Especially in rescheduler case, failure may not caused by service itself but by an eviction(unless we give it a disruption budget of none). If we can have in-memory migration, the pod can get rescheduled without breaking its ongoing task. It frees more pods and looses the disruption budget restriction. Indeed it's not a necessary feature but an optimized option.\n",
        "createdAt" : "2016-04-12T07:26:58Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "ca29ebb5-bb80-441c-9b78-f731ae3f4419",
        "parentId" : "f5855f1c-aef9-4fe2-9816-534fed963352",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "I'm not asking for live migration. It's a good thing but not urgent.\n",
        "createdAt" : "2016-04-12T07:28:30Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +54,58 @@create a replacement pod that is then scheduled by the pod's scheduler. The terminated\npod and replacement pod are completely separate pods, and no pod migration is\nimplied. However, describing the process as \"moving\" the pod is approximately accurate\nand easier to understand, so we will use this terminology in the document.\n"
  },
  {
    "id" : "82dac014-86f7-4d26-8283-ae1c82d341e0",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0944c0e4-4c2b-46de-abb8-14ab9ed5c5a1",
        "parentId" : null,
        "authorId" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "body" : "\"Evict\" isn't nouny, which made me think maybe it should be called \"eviction\".  At that point I thought, \"why not just DELETE the /binding subresource?\"  The semantics of such a request is clear and it avoids creating another subresource.\n",
        "createdAt" : "2016-03-01T00:27:20Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "tags" : [
        ]
      },
      {
        "id" : "6c76ef5e-3f08-4e6d-a3a2-d7ace919e653",
        "parentId" : "0944c0e4-4c2b-46de-abb8-14ab9ed5c5a1",
        "authorId" : "3c7fea1e-9d61-4b20-8af9-584361c1b59a",
        "body" : "@davidopp I'm confused what /evict subresource will do in resheduler mechanism. IIUC, the re-schedule initiator will delete pod and controller is responsible for creating the replacement pod. Will the /evict subresource delete the pod ? If so, POST or PUT /pod/xxx/evict will lead to deletion of  pod xxx and all subresources of pod xxx including /evict itself(though there's no realistic subresource). It's a little semantically strange.\n",
        "createdAt" : "2016-04-15T06:43:01Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "3c7fea1e-9d61-4b20-8af9-584361c1b59a",
        "tags" : [
        ]
      },
      {
        "id" : "8b4faac7-14fc-4ca9-a35c-3033026a8ea9",
        "parentId" : "0944c0e4-4c2b-46de-abb8-14ab9ed5c5a1",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yes, DELETE of /evict subresource should delete the pod (if the API server allows it, i.e. if DisruptionBudget is satisfied). Other operations (POST, PUT, etc.) on /evict subresource are not supported. Let's continue the discussion in #24321 (I filed that issue just now because the comments on this design doc are getting very cluttered :) )\n",
        "createdAt" : "2016-04-15T07:21:36Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 283,
    "diffHunk" : "@@ -1,1 +281,285 @@Although we could put the responsibility for checking and updating disruption budgets\nsolely on the client, it is safer and more convenient if we implement that functionality\nin the API server. Thus we will introduce a new `/evict` subresource on pod. It is similar to\ntoday's \"delete\" on pod except\n"
  },
  {
    "id" : "47dcce9c-e2ab-4560-939c-20c3e6944e80",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c03f30a-f5ab-4e0a-87e4-2ed7beb9244c",
        "parentId" : null,
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "I think we could use a admission controller to auto-generate a disruption budget. User could enable such an  admission controller so that when they create a Service, a disruption budget will be auto-generated, or they can disable it and create disruption budget manually.\n",
        "createdAt" : "2016-03-01T06:19:12Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "6db496dc-db9d-40bb-98cb-06a8a855b5e6",
        "parentId" : "8c03f30a-f5ab-4e0a-87e4-2ed7beb9244c",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "We can do just like LimitRange,  users can create one, buf if they don't specifiy it, apply a default one.\nQuestion: what's the behavior if this admission controller is disabled. All or none of the pods can be disrupted?\n",
        "createdAt" : "2016-03-03T10:16:21Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 265,
    "diffHunk" : "@@ -1,1 +263,267 @@(podTemplate in controller that managed the pod?)? Do we auto-generate a disruption\nbudget (e.g. when instantiating a Service), or require the user to create it manually\nbefore they create a controller? Which objects should return the disruption budget object\nas part of the output on `kubectl get` other than (obviously) `kubectl get` for the\ndisruption budget itself?"
  },
  {
    "id" : "0c5619a7-d6ab-42ec-a142-fb3592952ae7",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3dedc86d-4de2-4da8-af90-60c5b6d79d76",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Thinking about it more, I'm not convinced we can really get away with having the rescheduler not know at least the required predicate functions, even for the first version of the rescheduler.\n\nTake for example the \"move pods onto under-utilized\" nodes use case. It's important to know if an evicted pod will actually not reschedule onto any of those nodes--for example those nodes might be under-utilized because they're being drained and are marked unschedulable, or maybe they have some kind of taint due to being in a dedicated node group or otherwise restricted to a limited set of pods. In such cases the eviction is pointless, as the evicted pod will not move onto any of those nodes. On the other hand, maybe the nodes were just added by cluster auto-scale-up, in which case they will be feasible for the pod you're considering moving. It seems important to be able to distinguish these two cases.\n\nThis is a slightly different argument than saying rescheduler needs the predicate functions so that it can know whether an evicted pod will go pending. I think the argument that we don't really care whether the pod goes pending is reasonable, certainly for a first version of the rescheduler. The argument here is that rescheduler needs the predicate functions so it can know if the node(s) that seem better for the pod in question are actually feasible for that pod. If they're not, the pod might not end up on a node that is actually better.\n",
        "createdAt" : "2016-03-01T06:37:17Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "abc72e99-14d6-4683-a5f0-fda1e4a76543",
        "parentId" : "3dedc86d-4de2-4da8-af90-60c5b6d79d76",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "+1. Predicate functions are useful for the rescheduler, even in the first version of implementation.\n",
        "createdAt" : "2016-03-02T02:53:12Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "9f5caf6a-5a63-4e45-85f0-4bce47da5aff",
        "parentId" : "3dedc86d-4de2-4da8-af90-60c5b6d79d76",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "What scenarios would you like the MVP to handle?\n\nI don't object to including the fit predicates, since we do have a spec for feasibility, not just an implementation. We should provide an API, though it would admittedly be of significantly lower performance, even once we support protobuf.\n\nI personally think the MVP could be simpler -- for instance don't attempt to fill tainted nodes. Most clusters are likely still homogeneous, especially since we don't yet have a simple mechanism for exporting attributes. Certainly in an auto-scaled cluster, the additional nodes are going to be similar to existing ones. Another approach could be to evict pods from \"similar\" nodes.\n",
        "createdAt" : "2016-03-08T07:30:42Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "d4a87e2b-a738-4502-91f0-35bb3e295f41",
        "parentId" : "3dedc86d-4de2-4da8-af90-60c5b6d79d76",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "Sorry, what does _MVP_ mean here?\n",
        "createdAt" : "2016-03-09T02:02:21Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "a4f6e088-62a8-443c-925d-5120a0c198f1",
        "parentId" : "3dedc86d-4de2-4da8-af90-60c5b6d79d76",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "MVP: https://en.wikipedia.org/wiki/Minimum_viable_product\n\n@bgrant0607 : The plan for the MVP is to move pods onto nodes that were added by cluster auto-scaler (hopefully implemented generically to move pods onto under-utilized nodes) and to move pods to improve affinity. I don't think we need an API; the point of #20204 is to make it possible for a component to link in the required scheduling predicates. \n",
        "createdAt" : "2016-03-09T06:55:50Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 428,
    "diffHunk" : "@@ -1,1 +426,430 @@corresponding shard strength disruption budget by one indefinitely. By using the `/evict`\nsubresource, the rescheduler ensures that an evicted pod has sufficient budget for the\nevicted pod to go and stay pending.  We expect future versions of the rescheduler may be\nlinked with the \"mandatory\" predicate functions (currently, the ones that constitute the\nKubelet admission criteria), and will only evict if the rescheduler determines that the"
  },
  {
    "id" : "000341a7-e098-4bb9-b0c4-3cd6b553d82c",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "parentId" : null,
        "authorId" : null,
        "body" : "Is this really possible? If so, we should presumably fix it in the scheduler, not a rescheduler?  If the scheduler schedules a pod to a node, and then discovers that it had out of date information about the node, and the pod can not in fact be scheduled there, it should automatically reschedule, possibly?\n",
        "createdAt" : "2016-03-01T16:43:02Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "f3ec180c-9297-47cb-9464-4c270120ae02",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "if a pod is scheduled to a kubelet and rejected in admission, isn't the pod immediately moved to a terminal state?  i agree with @quinton-hoole here that this seems like something the scheduler should get right, but from what I can tell thus far in this PR is that the rescheduler does more selective killing of pods on a node, but does not actually take over primary scheduling responsibility so maybe its a no-op here and a solution is needed in both places?\n",
        "createdAt" : "2016-03-01T19:10:43Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "33714f95-2f03-43b7-a8c1-95bdbeeeb353",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "In the model where scheduler has full information about kubelet resources, what you guys are saying is correct (and this is indeed how things are today). However, in the future it's possible that Kubelet will have more information than the scheduler, especially if the resource topology within a node becomes very complicated and it's not scalable for the scheduler to know all of the details. I would like to avoid moving to that world as long as possible, though.\n",
        "createdAt" : "2016-03-09T00:45:32Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "78776fc3-11d2-4ce7-9a5a-60bcd915e3b2",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "+1 @davidopp 's comments. \n",
        "createdAt" : "2016-03-09T02:04:05Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "cb243dd2-1fb5-4175-acad-a875daf9eeb6",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : null,
        "body" : "@davidopp @HaiyangDING In my mind there are two distinct cases where a pod fails to schedule:\n1. The scheduler picks a bad node, due to out of date or incomplete information.  It's not clear to me that fixing this is the responsibility of a rescheduler.\n2. The scheduler picks a non-optimal node, or no suitable node exists (without moving someother pods around).  This seems like the purvue of the rescheduler.\n\nAm I missing something?\n",
        "createdAt" : "2016-03-14T16:10:45Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "4621a2dc-ac32-410f-8d09-8d63549bf329",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : null,
        "body" : "@davidopp @HaiyangDING In my mind there are two distinct cases where a pod fails to schedule:\n1. The scheduler picks a bad node, due to out of date or incomplete information.  It's not clear to me that fixing this is the responsibility of a rescheduler.  It seems like the scheduler should fix it's own mistakes here, e.g by trying again.\n2. The node picked by the scheduler is non-optimal (or becomes non-optimal over time), or no suitable node exists (without moving some other pods around).  This seems like the purview of the rescheduler.\n\nAm I missing something?\n",
        "createdAt" : "2016-03-14T16:19:29Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "88ae5941-fa09-4805-8ea6-bcc3a039ea86",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "I will try to answer with my knowledge, correct me if I am wrong.\n\n> The scheduler picks a bad node, due to out of date or incomplete information. It's not clear to me that fixing this is the responsibility of a rescheduler. It seems like the scheduler should fix it's own mistakes here, e.g by trying again.\n\nCurrently, if the pod is denied by the node proposed by the scheduler, the pod is simply marked 'failed', there is no trying again. I think in future:\n1. It is the responsibility for the scheduler to try to scheduler the pod denied by kubelet again, or several times (<=N).\n2. It is the responsibility for the rescheduler to handle the pod that has been denied by kubelet several times (>= N). However the mechanism needs further consideration. For instance, if the pod is denied by the same kubelet several times, we can add the avoid annotation on the node; but if the pod is denied by different, maybe we could just wait and see. \n\n> The node picked by the scheduler is non-optimal (or becomes non-optimal over time), or no suitable node exists (without moving some other pods around). This seems like the purview of the rescheduler.\n\nYes, it is. FWIW:\n- `The node picked by the scheduler is non-optimal (or becomes non-optimal over time)`, this is in the scope of the first version of rescheduler, but we need to figure out some policy to decide how non-optimal is bad enough (as well as the possibility to improve) to trigger the rescheduling behavior. Actually, by this we are asking the rescheduler to know (at least some of) the priority functions.\n- `suitable node exists (without moving some other pods around)` , this is within the scope of rescheduler but is related to the preemption & priority, so they are not going to be implemented in the first step.\n- Another use case of the rescheduler in the first step is to move some pod to under-utilized node, and both 'some pod' and 'under-utilized' need to be defined.\n\nAnd finally, yeah, I don't think you miss anything :) \n",
        "createdAt" : "2016-03-15T09:52:28Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "01db74cc-7d22-4f63-b15e-0276d178bf14",
        "parentId" : "36559c33-b106-48b5-bae4-dd60fc514566",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yeah, I'd say this falls into the category of things that could go into either the rescheduler or every scheduler. As mentioned somewhere in the doc, we don't actually need a rescheduler component at all--we could just implement all of the rescheduler in every scheduler, creating a virtual/distribute rescheduler. But it's easier for people to write new schedulers (and the system is easier to understand, global policies are easier to configure, etc. etc.) if we have a single rescheduler component rather than putting the responsibility on every scheduler. With that in mind, the reasoning is basically what @HaiyangDING said -- while you could make schedulers responsible for noticing and stopping \"rescheduling loops,\" you can instead make that the responsibility of the rescheduler, which would notice it happening (for any scheduler) and would add an indication to the node that equivalent pods should avoid that node for some period of time. But it is certainly the case that you could put this logic in the scheduler. (And we are not suggesting to address this at all in the first version of the rescheduler, especially since we don't have any scenarios today AFAIK that should cause rescheduling loops, other than stale information, which I don't consider a rescheduling loop because it will quickly stop.)\n",
        "createdAt" : "2016-03-21T07:24:31Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +84,88 @@  * anomalous crashlooping or other mysterious incompatiblity between the pod and the node\n  * repeated out-of-resource killing (see #18724)\n  * repeated attempts by the scheduler to schedule the pod onto some node, but it is\n    rejected by Kubelet admission control due to incomplete scheduler knowledge\n  * poor performance due to interference from other containers on the node (CPU hogs,"
  },
  {
    "id" : "be0c36e0-460e-4138-8f08-84623a62ce49",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42cd603a-5d47-4018-8345-c4aa78f1313d",
        "parentId" : null,
        "authorId" : null,
        "body" : "This verges on a gramatical nit, but it goes a bit deeper than that.  I'd avoid using connotative terms here, inferring that one pod is 'good' and the other is 'bad',  e.g. using as much CPU as is available on the node is a perfectly reasonable strategy for e.g. a CPU-bound batch job. The only thing that makes it not always work out well for everyone is our oversubscription policy and inadequate resource requirement semantics.\n",
        "createdAt" : "2016-03-01T16:47:09Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "b73b0eff-d5cf-429e-8ff8-ca26a5596237",
        "parentId" : "42cd603a-5d47-4018-8345-c4aa78f1313d",
        "authorId" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "body" : "Also, I propose to use latency as a metric to determine \"good\" or \"bad\"\n",
        "createdAt" : "2016-03-04T02:57:53Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 90,
    "diffHunk" : "@@ -1,1 +88,92 @@  * poor performance due to interference from other containers on the node (CPU hogs,\n    cache thrashers, etc.) (note that in this case there is a choice of moving the victim\n    or the aggressor)\n\n## Some axes of the design space"
  },
  {
    "id" : "74da3002-7b15-4fa5-97e5-afb3a0f8219d",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97cff267-3912-4f8c-b489-2e717b537777",
        "parentId" : null,
        "authorId" : null,
        "body" : "Should this tolerance be specified at the pod level, or \"higher up\", e.g. at the replication controller, service etc.  Off the top of my head I'd say there's a use case for both. More below...\n",
        "createdAt" : "2016-03-01T16:50:38Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "5ffea614-8821-4ccd-b9dc-b02838154aa7",
        "parentId" : "97cff267-3912-4f8c-b489-2e717b537777",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "Agree, pod's concern may be \"don't move me too often\", rc and service may think \"don't move too much of my heelers, move others\".\n",
        "createdAt" : "2016-03-03T09:57:32Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "3d090e80-071f-4b43-ae1b-a2de66778d89",
        "parentId" : "97cff267-3912-4f8c-b489-2e717b537777",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "See the discussion later about disruption budgets. The question you're asking is what is the granularity covered by a single disruption budget. Probably for a first cut, we'd want service granularity for long-running services, and Job granularity for run-to-completion. The reason ReplicaSet is not good is because we create a new ReplicaSet when we do rolling update. Of course we can point the new ReplicaSet at the same disruption budget, but in that case you're really saying the granularity is logically something higher-level than the controller.\n",
        "createdAt" : "2016-03-09T00:51:13Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "48588098-168d-4ba8-838b-95a6b3bfea16",
        "parentId" : "97cff267-3912-4f8c-b489-2e717b537777",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "\"service granularity for long-running services, and Job granularity for run-to-completion\" sounds good to me. But how to handle the pods without a matching Service of Job. Just not move them?\n",
        "createdAt" : "2016-03-09T15:00:05Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "f6561b65-ffd6-4472-af52-16b08b8998f1",
        "parentId" : "97cff267-3912-4f8c-b489-2e717b537777",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I think the default would be that if there is no disruption budget associated with a Pod, then it receives no protection (so, the opposite of what you said). If the user wants to protect a Pod by using a disruption budget, then they would need to make the Pod be part of a Service or Job, or manually create a disruption budget and point to it from the Pod.\n",
        "createdAt" : "2016-03-12T21:24:37Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +94,98 @@Among the key design decisions are\n\n* how does a pod specify its tolerance for these system-generated disruptions, and how\n  does the system enforce such disruption limits\n* for each use case, where is the decision made about when and which pods to reschedule"
  },
  {
    "id" : "38fc9c10-d5a9-48f6-9908-dbc9deec0335",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab4882ff-6bb3-48f5-88b3-f4139b2a53fc",
        "parentId" : null,
        "authorId" : null,
        "body" : "Speaking from experience, the term \"priority\" (and even \"scheduling priority\") is easily confused with the more traditional use of the term in the context of on-host CPU scheduling (i.e. which processes receive a larger or smaller share of the available CPU on a node). Would suggest keeping it explicit in this document, with some thing like \"placement priority\". \n",
        "createdAt" : "2016-03-01T16:58:26Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "a7e3604e-1f72-4a96-91d6-c548d48a541a",
        "parentId" : "ab4882ff-6bb3-48f5-88b3-f4139b2a53fc",
        "authorId" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "body" : "+1, CPU scheduling and core assignment is so commonly used. A more explicit explanation is needed at least.\n",
        "createdAt" : "2016-03-04T03:12:26Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +122,126 @@Just as it is useful to overcommit nodes to increase node-level utilization, it is useful\nto overcommit clusters to increase cluster-level utilization.  Scheduling priority (which\nwe abbreviate as *priority*, in combination with disruption budgets (described in the\nnext section), allows Kubernetes to safely overcommit clusters much as QoS levels allow\nit to safely overcommit nodes."
  },
  {
    "id" : "b784c8ee-ece1-4544-9272-50a03383abaa",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "parentId" : null,
        "authorId" : null,
        "body" : "It might be worth clarifying why it's a good idea to preempt pods of the same priority. Superficially it sounds like replacing a pod with another of equal priority does not improve cluster-wide scheduled pod percentages, and is just busy work. I'm sure there's more to it than that though.\n",
        "createdAt" : "2016-03-01T17:03:30Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "af5102e8-e9c4-44bd-8048-8ad16e619811",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : null,
        "body" : "I guess the assumption is that the evicted pod _might_ be schedulable on some other node. In the worst case we break even (modulo rescheduling costs), while in the best case we have an additional pod scheduled.\n",
        "createdAt" : "2016-03-01T17:05:33Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "311edd9f-ad99-4616-908c-7c65ab7d8cec",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : null,
        "body" : "One can imagine a pretty bad situation where the above worst-case behavoir cascades, evicting a large number of equal-priority pods in succession, resulting in high rescheduling costs, and no net benefit.  Would it be worth trying to short-circuit this sort of thing (by e.g. only pre-empting an equal-priority pod if it is immediately schedulable onto another node without evicting anything, or only evicting lower-priority pods?\n",
        "createdAt" : "2016-03-01T17:16:39Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "38606bf6-a212-4e06-9444-d92e8da6cc76",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : null,
        "body" : "Note that this is not a purely theoretical concern.  I have considerable experience with borg taking out an entire serving cluster by precipitating such a \"pre-emption storm\", ultimately rendering the cluster useless in an attempt to schedule one or a small number of higher priority \"pods\".  In those particular cases it would have been way, way better for the rescheduler to have done absolutely nothing (in which case the serving capacity of the cluster in question would have been reduced by a small number of percent due to the unscheduled pods, rather than to zero by the resulting cascading pre-emption storm).\n",
        "createdAt" : "2016-03-01T17:18:36Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "25a6d618-848a-48d7-859f-97c6cf0bf92e",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "@quinton-hoole \n\n> It might be worth clarifying why it's a good idea to preempt pods of the same priority. Superficially it sounds like replacing a pod with another of equal priority does not improve cluster-wide scheduled pod percentages, and is just busy work. I'm sure there's more to it than that though.\n\nI think the reason we allow preempt pods of the same priority is we have \"disruption budget\", as long as \"disruption budget\" allows, it won't increase unavailability of one Service in a further step, but we can get the benefit of allowing Pods or another Service be scheduled.\n",
        "createdAt" : "2016-03-02T02:28:29Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "accec737-64c4-4bb5-b8ea-cf223dd8a89d",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "> I think the reason we allow preempt pods of the same priority is we have \"disruption budget\", as long as \"disruption budget\" allows, it won't increase unavailability of one Service in a further step, but we can get the benefit of allowing Pods or another Service be scheduled.\n\nGood one. I have the same concern of why we could allow equal priority preemption. So pod in the set whose disruption budget is low could be able to preempt that with plenty disruption budget?\nIs there other reasons? \n",
        "createdAt" : "2016-03-02T02:36:44Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "2c3685d8-fac1-4e64-a527-7436090cc8fa",
        "parentId" : "a1156d01-ddb4-412c-a483-2b934370d01e",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "> I guess the assumption is that the evicted pod might be schedulable on some other node. In the worst case we break even (modulo rescheduling costs), while in the best case we have an additional pod scheduled.\n\nCorrect.\n\n> One can imagine a pretty bad situation where the above worst-case behavoir cascades, evicting a large number of equal-priority pods in succession, resulting in high rescheduling costs, and no net benefit.\n\nAs @mqliang says, preemptions are rate-limited by disruption budgets, so you can't get preemption cascades/preemption storms.\n\n> Would it be worth trying to short-circuit this sort of thing (by e.g. only pre-empting an equal-priority pod if it is immediately schedulable onto another node without evicting anything, or only evicting lower-priority pods?\n\nWhat you're describing (only evict if we're pretty sure the victim can reschedule somewhere) is something we might eventually want to do for the other rescheduling use cases, and I agree it could be useful for the same-priority-preemption use case as well. I don't think it's necessary for a first version of the system, though.\n\n>  I have the same concern of why we could allow equal priority preemption.\n\nThe reason to allow equal-priority preemption is to \"repack\" pods to make room for a pending pod. (For example, defragment resources, or move a pod off of a machine with some label that is required by the pending pod but not required by the already-running pod.) Doing this at scheduling time on-demand rather than speculatively in the rescheduler minimizes the amount of unnecessary evictions.\n",
        "createdAt" : "2016-03-09T00:59:39Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 154,
    "diffHunk" : "@@ -1,1 +152,156 @@When a scheduler is scheduling a new pod P and cannot find any node that meets all of P's\nscheduling predicates, it is allowed to evict (\"preempt\") one or more pods that are at\nthe same or lower priority than P (subject to disruption budgets, see next section) from\na node in order to make room for P, i.e. in order to make the scheduling predicates\nsatisfied for P on that node.  (Note that when we add cluster-level resources (#19080),"
  },
  {
    "id" : "c49bc736-f1ad-4982-af61-4a6963c2d25a",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "parentId" : null,
        "authorId" : null,
        "body" : "This is probably not the right place for this comment/question, but here goes.  Have we considered treating scheduling and rescheduling as a _global_ constraint-satisfaction problem (rather than a _local_ one as per the current scheduler implementation and rescheduler design)? What I have in mind is an algorithm that takes as input all of the nodes, all of the pods and their constraints, and current pod placements as input. It's job is to find a new global mapping of pods to nodes that:\n1. results in 'more' scheduled pods (by some definition of 'more').  Ideally the highest possible.\n2. results in 'more' placement constraints (affinities, anti-affinities, ... etc) being satisfied.  Ideally the highest possible.\n3. favors alternative global solutions which are \"closer\" to the current pods placement (i.e the \"diff\" is smaller), in preference to solutions that are \"further\" from it (to reduce rescheduling cost).  A conversion function between rescheduling cost and the cost of pending/unscheduled pods makes it possible to trade off 1 against 3 etc.\n\nThe classic problems with _local_ constraint satisfaction (as we currently design and implement it) as opposed to _global_ constraint satisfaction, is that the former can commonly get stuck in local minima of the function being optimised.   In our case, this is made worse by the relatively high cost of rescheduling (terminating and replacing pods creates a lot of churn in the system, so we'd better be sure that each of these gets us strictly closer to a near-optimal solution).  This is theoretically and practically impossible with a local constraint solver, as evidenced by e.g. the \"pre-emption storm\" example above, and further similar discussion below.\n",
        "createdAt" : "2016-03-01T17:25:13Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "ab2dbb86-b257-4f35-a790-b4597b1ab2b3",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : ">  Have we considered treating scheduling and rescheduling as a global constraint-satisfaction problem \n\nGetting a global optimal solution is challenging IMO. Since we need a good objective functions(take a lot of factors into consideration), and it takes time to calculate. And unfortunately there are schedulers work at the same time, so it's racy. One idea occurs to me is that we can have a distributed lock, if rescheduler get this lock, all schedulers paused, once rescheduler have finished it's work, it free the lock, and schedulers could then start to work again. I have discussed this idea with @HaiyangDING .\n",
        "createdAt" : "2016-03-02T09:13:59Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "2e175a1f-e917-4bb2-9b6e-0b3002152493",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "@mqliang. I have taken a second thought on this. I think locking the schedulers at any time may not be a good idea, because pods that users submitted will get pending for quite a while as long as the rescheduler does not finish its job, which, unfortunately, in many use cases, is not acceptable: new job can not be started due to pod pending, application SLO may be violated due to failure of scaling up pods (newly created pods are scheduled by the scheduler(s)). The rescheduler's goal is to _OPTIMIZE_ the cluster/certain-pod-placement, without harming user experience (or as less as possible). Note that the rescheduler is trying to improve the performance of the cluster/certain-pod: help the cluster/certain-pod to move from a \"worth-improving\" situation to a better one (locally), not from complete failure to \"global optimization\"; while locking the schedulers actually does \"freeze\" the whole cluster for quite some time, which is not worthy at all.\n\nRegarding the global constraint-satisfaction problem brought up by @quinton-hoole , I don't think we could be able to achieve a truly \"global optimized state\", for:\n1. it is too hard, if not impossible, to define the cost function. We need many a-prior knowledge of the system and the input. I believe there are many related research on the field;\n2. in multi-scheduler scenario, it is even harder unless we introduce some cooperative constraints between the schedulers, which is also not easy;\n3. I am very fond of the 3rd point brought by @quinton-hoole , that we can use some heuristics that depends heavily on the current pods placement. We can use such heuristics to see if there is anything we could do to improve the cluster/certain-pod, and the improvement can be measured by some cost function with a considerable punishment on moving the pods. +1 to\n\n> (terminating and replacing pods creates a lot of churn in the system, so we'd better be sure that each of these gets us strictly closer to a near-optimal solution)\n\nAll in all, the above is just some of my thoughts and I believe there is no easy solution if we want the \"global optimization\". We should not consider this in the first step, or even for the next few steps. The rescheduler for the community version should stay simple, easy-to-understand, so let us leave the complexity to the researchers or dedicated commercial distributions.\n\nFWIW, there is a project called [Firmament](www.firmament.io), in which the modeling can be a very good reference for those who are interested in the field. I am not sure if the authors are interested in this discussion. @ms705 @ICGog\n",
        "createdAt" : "2016-03-02T18:21:28Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "8d4460d3-1e29-4e82-a94f-2a3330ddc3d8",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "I agree. But it still racy as long as schedulers work at the same time. My idea is just pause schedulers for a short time. We use pessimistic conflic control with deadline: reschedling algorithm will have a deadline, rescheduler must ensure that rescheduling will finished before the deadline. If it just couldn't, rescheduling algorithm will return a suboptimal(but global) pod placement, if fortunately, it can finished before deadline, we get a optimal solution. Such a implementation could ensure all schedulers will not paused for a long time. Even if we could not get the best cluster layout after one rescheduling, we could get a better and better one.\n\nPseudo code is like:\n\n```\n// take as input all of the nodes, all of the pods and their constraints, and current pod placements as input. \n// return a new global mapping of pods to nodes, if return before deadline, we get a optimal solution, otherwise,\n// we get a suboptimal solution \nfunc Rescheduling(pods []api.Pod, nodes []api.Node, deadline time.Duraion)(result []Binding) {\n    var result []Binding\n    select {\n        case <-time.After(deadline):\n            // calculate can not finish before the deadline, return with a suboptimal global pod placement\n            return\n        default: \n            // calculate the optimal global pod placement\n            return  \n    }\n}\n```\n\nSo, if we design like this, we can solve the race problem, and we could harm user experience as less as possible.\n\nMay be premature, but we could discuss it.\n",
        "createdAt" : "2016-03-03T00:26:40Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "5686fc18-c60b-4e73-8bfc-a17d7c9f4417",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "@mqliang Can we consider rescheduler as a controller, scheduler as a executor? Rescheduler make decisions, and ask kublet to evict a pod, scheduler to schedule a pod(with \"exclude some certain nodes\" constraint). Them we don't need to lock any component.\n",
        "createdAt" : "2016-03-03T10:08:16Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "cfa0ec09-90ac-4f92-a1b9-e5fabf2ee46c",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "So, rescheduler finds out what is bad, and scheduler knows how to suit CURRENT cluster, rescheduler will never make scheduling decisions. Such a design is clean and concise. If we implement like this, does rescheduler really deserve a new component? May be we should implemented it as a \"Controller\", or as a route in scheduler. \n",
        "createdAt" : "2016-03-03T12:47:51Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "2f90330a-e6b6-4cd4-8872-aef1734dceaa",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "To be clear, I don't mean I disagree what you say. Frankly speaking, I also vote the design of \"rescheduler finds out what is bad, and scheduler knows how to suit CURRENT cluster\", such a design is very beautiful. But I think it should be implemented as a kind of \"controller\", not a new component. \n",
        "createdAt" : "2016-03-03T12:53:29Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "1e43471f-f34c-441c-8c01-2fc789f1d81a",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Later in the doc we say\n\n> We expect certain aspects of the design to be \"permanent\" (e.g. the notion and use of priorities, preemption, disruption budgets, and the `/evict` subresource) while others may change over time (e.g. the partitioning of functionality between schedulers, controllers, rescheduler, horizontal pod autoscaler, and cluster autoscaler\"\n\nYou can definitely move the rescheduler logic into the schedulers, but that makes it more complicated for people to build schedulers. As for whether rescheduler is a \"controller\" or a unique type of component -- I think of controllers as \"owning\" pods. The rescheduler doesn't own any pods -- it only evicts pods. So I would not consider it to be a controller. (And even if some day we had rescheduler forcibly schedule evicted pods onto nodes, it still would not own the pods, and wouldn't be a controller.) So I think it is a unique type of component. \n",
        "createdAt" : "2016-03-09T01:06:29Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "ce05b418-dbc8-456d-a1eb-5adb7add022e",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "Agree.\n",
        "createdAt" : "2016-03-09T01:49:55Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "5f4d5b03-5a4f-4295-ab60-b3a86950cf90",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "Does it mean the first version of rescheduler just \"evict\" pods, but we may eventually want rescheduler \"rebind\" pods?\n",
        "createdAt" : "2016-03-09T01:55:32Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "fa267398-f2ce-4c71-8024-b64514abf8b4",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "To evict pod is definitely what we want to implement in the first version of the rescheduler. However, I am not fully convinced that rescheduler should schedule pods, maybe we can discuss this based on concrete use cases or tests.\n",
        "createdAt" : "2016-03-09T02:10:38Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "5f73893f-8564-41dc-a0be-14f506afa293",
        "parentId" : "31967c10-2d7a-4620-8f97-4567c5c713e3",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Right -- only eviction in the first version. I don't think we would ever want rescheduler to directly schedule pods. I think we might want `/evict` subresource to have \"prefer\" in addition to \"avoid,\" but we would still have the regular scheduler(s) do the scheduling for the evicted pods. Of course, since rescheduler is an independent component, people are free to experiment with their own implementations of the rescheduler. If someone could demonstrate a benefit to having rescheduler directly schedule pods, using a real workload, I'm sure I would change my mind. :)\n",
        "createdAt" : "2016-03-09T06:40:28Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 158,
    "diffHunk" : "@@ -1,1 +156,160 @@satisfied for P on that node.  (Note that when we add cluster-level resources (#19080),\nit might be necessary to preempt from multiple nodes, but that scenario is outside the\nscope of this document.)  The preempted pod(s) may or may not be able to reschedule. The\nnet effect of this process is that when demand for cluster resources exceeds supply, the\nhigher-priority pods will be able to run while the lower-priority pods will be forced to"
  },
  {
    "id" : "1a5ae8b6-eeaa-4861-a852-1e45bee54249",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "497eaa30-b3fa-4a65-b312-0c1f08ff3f56",
        "parentId" : null,
        "authorId" : null,
        "body" : "I think that this sort of validation will be crucial for good user experience.\n",
        "createdAt" : "2016-03-01T17:33:00Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 172,
    "diffHunk" : "@@ -1,1 +170,174 @@API, or using ConfigMap to configure the schedulers with the information. The advantage of\nthe former (at least making the names, if not the ordering, constants in the API) is that\nit allows the API server to do validation (e.g. to catch mis-spelling).\n\nIn the future, which priorities are usable for a given namespace and pods with certain"
  },
  {
    "id" : "5933269e-db1c-47d2-9b57-f03d2d5b09e8",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d852c5db-02a3-4e1c-bc16-71c38ad6ab20",
        "parentId" : null,
        "authorId" : null,
        "body" : ".. unless the charges are different.  What about if the charge against quota was proportional to priority.  High priority pods cost more than low priority pods, so people spend their priority wisely, hopefully.\n",
        "createdAt" : "2016-03-01T17:36:51Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "4d2d0ff7-a638-451a-bdd4-1daa5bfa53e1",
        "parentId" : "d852c5db-02a3-4e1c-bc16-71c38ad6ab20",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "That's an interesting idea.\n",
        "createdAt" : "2016-03-09T01:12:35Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 193,
    "diffHunk" : "@@ -1,1 +191,195 @@\nOf course, if the decision of what priority to give a pod is solely up to the user, then\nusers have no incentive to ever request any priority less than the maximum.  Thus\npriority is intimately related to quota, in the sense that resource quotas must be\nallocated on a per-priority-level basis (X amount of RAM at priority A, Y amount of RAM"
  },
  {
    "id" : "9361b69b-9e8e-4a43-9276-cd280e46ef34",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90133634-27cd-4d89-89cb-2be049f648a4",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "Thoughts on `controllerRef` for a pod to \"move\" pods that are backed by a controller versus one-off pods that were created (say by controllers outside of core kubernetes)?\n",
        "createdAt" : "2016-03-01T19:04:26Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "14f70625-4179-4797-ac1e-9e67a11a35bc",
        "parentId" : "90133634-27cd-4d89-89cb-2be049f648a4",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "I can see the usability argument, but am concerned about gaming in multi-tenant clusters.\n",
        "createdAt" : "2016-03-07T04:02:00Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "f84d5337-b04e-4acc-841d-34f52c0d510c",
        "parentId" : "90133634-27cd-4d89-89cb-2be049f648a4",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "@derekwaynecarr I didn't understand your suggestion.\n",
        "createdAt" : "2016-03-07T04:22:31Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "90228331-4c60-4730-b22b-b749296f60f0",
        "parentId" : "90133634-27cd-4d89-89cb-2be049f648a4",
        "authorId" : null,
        "body" : "@derekwaynecarr Neither do I.  Perhaps you're thinking of storing a reference to one or more controllers that might manage a given pod?  What do you plan to do with the reference?\n",
        "createdAt" : "2016-03-14T15:57:42Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +46,50 @@(e.g. the node where it is running dies). Thus in a cluster with long-running pods, the\nassignment of pods to nodes degrades over time, no matter how good an initial scheduling\ndecision the scheduler makes. This observation motivates \"controlled rescheduling,\" a\nmechanism by which Kubernetes will \"move\" already-running pods over time to improve their\nplacement. Controlled rescheduling is the subject of this proposal."
  },
  {
    "id" : "97ab887d-7dd6-4439-aa52-88f1b2f8028c",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "576277b0-e13f-4fab-adfd-d0fe4f082ad5",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "out of resource killing will kill a pod already based on F2F discussion.  is this implying repeated out of resource killing on a specific node or for a specific pod derived from a specific controller?\n",
        "createdAt" : "2016-03-01T19:08:51Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "d1c55528-fa54-4c45-bd03-8d11948b0fda",
        "parentId" : "576277b0-e13f-4fab-adfd-d0fe4f082ad5",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yes, exactly what you said. In this case rescheduler is not responsible for the killing, just for ensuring that after some criteria is met (e.g. pod has been repeatedly OOR killed on the same node some number of times) it reschedules elsewhere.\n",
        "createdAt" : "2016-03-09T00:40:37Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +83,87 @@* moving a running pod off of a node from which it is receiving poor service\n  * anomalous crashlooping or other mysterious incompatiblity between the pod and the node\n  * repeated out-of-resource killing (see #18724)\n  * repeated attempts by the scheduler to schedule the pod onto some node, but it is\n    rejected by Kubelet admission control due to incomplete scheduler knowledge"
  },
  {
    "id" : "be048407-c1b6-4e95-8bef-847cc6131a32",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8075ee6-3ef6-4003-8034-bb3ad8b5098a",
        "parentId" : null,
        "authorId" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "body" : "Thought about this again on my ride in this morning.  We know that exposing a numerical ordering is messy, but with this UI, users will have to think in terms of a named priority (hopefully they remember the semantics/ordering!) and the QoS behavior they get based on the quantitative rules that map to conceptual words documented [here](https://github.com/kubernetes/kubernetes/blob/master/docs/proposals/resource-qos.md).\n\nIt's true that we don't want to expose numbers to users, but what we'd like to expose (IMO) is fully-packaged Service Levels with names.  They _aren't_ ordered themselves because they're multi-axis.  \"Uncheckpointable Batch\", for example, would map to specific priority and QoS settings.\n\nIf we plan on going this direction, we should consider not forcing users to name the priorities and sticking with numbers, because ultimately the numbers should be hidden behind the Service Level facade and naming the objects in the total ordering is actually going to be [hard and error-prone](http://martinfowler.com/bliki/TwoHardThings.html).\n",
        "createdAt" : "2016-03-01T20:22:04Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "d324e241-a7f0-4ace-bda2-4174b07bdb18",
        "tags" : [
        ]
      },
      {
        "id" : "8ee6a1cc-9543-4d10-bf7a-ed566a5dedb7",
        "parentId" : "d8075ee6-3ef6-4003-8034-bb3ad8b5098a",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "Do we want to allow users(I mean system admins) to extend `Priority` levels? I think string helps in this problem.\n",
        "createdAt" : "2016-03-03T10:02:39Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "ea604f50-1c99-4c95-a1eb-02e46e4ebeb1",
        "parentId" : "d8075ee6-3ef6-4003-8034-bb3ad8b5098a",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "Numerical priorities also have the BASIC-line-number problem: one has to leave space for insertion of additional numbers later.\n\nAnother possibility to consider is to just give up on a total order. Think about it as an authorization problem.\n",
        "createdAt" : "2016-04-15T14:32:37Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "f6f0e4b8-3fec-4fb3-aeee-d751cb697ae8",
        "parentId" : "d8075ee6-3ef6-4003-8034-bb3ad8b5098a",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "Maybe we should split \"priority\" into a separate proposal.\n\nPod disruption budget will create a safety mechanism so that rescheduling and other automated processes don't take down whole services. We will need a mechanism to control who/what is allowed to spend that disruption budget, and we will need a mechanism to control who can ask for what kind of disruption budget, but I believe those features to be separable.\n",
        "createdAt" : "2016-06-25T03:19:05Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "3631e005-3304-465e-80dd-d797f261c219",
        "parentId" : "d8075ee6-3ef6-4003-8034-bb3ad8b5098a",
        "authorId" : "11725e10-43c9-4a8c-96d0-5118a3e67a6a",
        "body" : "Whether strings or numbers, there should be a sane default so that\n1. Administrators aren't forced to make unnecessary decisions\n2. It's easier to follow tutorials or reuse other people's configurations\n\nRegarding the type to use, I understand the reluctance to go for magic numbers, but, to give a concrete example, the distinction between \"batch\" and \"best-effort\" was always a bit of a mnemonic struggle to me, as \"left\" vs. \"right\" are to some people (\"batch\" vs. \"free\" was easier; 25 vs 0 even more so). Perhaps it's also because I'm not a native speaker. And, back to the first point, it's shifting an UI decision to cluster administrators, a group that is not generally well-versed in user experience. The pessimist in me imagines clusters from hell with priorities like \"Critical\", \"VeryCritical\", \"VeryVeryCritical\" and \"ReallyCritical\".\n",
        "createdAt" : "2016-07-08T02:56:14Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "11725e10-43c9-4a8c-96d0-5118a3e67a6a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +145,149 @@We propose to add a required `Priority` field to `PodSpec`. Its value type is string, and\nthe cluster administrator defines a total ordering on these strings (for example\n`Critical`, `Normal`, `Preemptible`). We choose string instead of integer so that it is\neasy for an administrator to add new priority levels in between existing levels, to\nencourage thinking about priority in terms of user intent and avoid magic numbers, and to"
  },
  {
    "id" : "610db090-a7e7-43d7-856d-fafe2f15537d",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7828e9a5-e7b2-4c5d-a281-c3c141758bb9",
        "parentId" : null,
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "Regarding use case \"moving a pod onto an under-utilized node\", we need to decide which comes first, a.) an under-utilized node or b.) some pod that we want it to be running on a node with more free resources (under-utilized).\n\nIf a.): when the rescheduler detects/finds a node under-utilized, how to choose which of the many pods in the cluster to be moved onto this under-utilized node\nIf b.): there is pod requiring more resources, then we need a way to define what is \"under-utilized\" for a node, scoring higher in PodFitsResource (in which case we are requiring the rescheduler to know the priority functions)? Certainly we may not care whether the pod eventual goes pending in the fire version, but we need to know when to \"start considering moving the pod\". This is somehow related to your comments above.\n",
        "createdAt" : "2016-03-02T02:10:42Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "0fa8faaf-6235-4f2b-8375-d99ac3601ce0",
        "parentId" : "7828e9a5-e7b2-4c5d-a281-c3c141758bb9",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "> but we need to know when to \"start considering moving the pod\"\n\nI think we only need move pods onto an under-utilized node when CPU/MEM starvation was detected (perhaps using a mechanism similar to horizontal pod autoscaling with custom metrics) .\n\n\"Work Stealing\" algorithm may be helpful to implement this. I describe this idea in https://github.com/kubernetes/kubernetes/issues/22054 \n",
        "createdAt" : "2016-03-02T02:26:06Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "57d76f2d-7e29-47e3-93e8-6f7a0c420669",
        "parentId" : "7828e9a5-e7b2-4c5d-a281-c3c141758bb9",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I don't agree you only want to move pods when you detect starvation (though that is _also_ a scenario when you would want to move pods). For example, you want to move pods onto nodes that were added by cluster auto-scaler. Both of the questions @HaiyangDING mentioned need to be answered in the implementation. How do you choose which pod(s) to move? I guess you would choose pods from nodes that already have high utilization (measured via request or usage), that have not exceeded their disruption budget. How do you define an \"underutilized\" node? I'm not sure. Maybe compare to the average across all nodes? This doc doesn't try to answer all of the design questions, just propose a general approach. :)\n",
        "createdAt" : "2016-03-09T07:00:08Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "0df63800-4f97-4372-b568-d33926e17340",
        "parentId" : "7828e9a5-e7b2-4c5d-a281-c3c141758bb9",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "Ignore me since we don't want rescheduler explicitly schedule pods. \n",
        "createdAt" : "2016-03-09T07:05:06Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +439,443 @@\nThe first version of the rescheduler will only implement two objectives: moving a pod\nonto an under-utilized node, and moving a pod onto a node that meets more of the pod's\naffinity/anti-affinity preferences than wherever it is currently running. (We assume that\nnodes that are intentionally under-utilized, e.g. because they are being drained, are"
  },
  {
    "id" : "dd511265-a0e4-475a-b16f-f660adf38a51",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70dd1e83-eb37-4e9c-bf73-8f6c7ce36206",
        "parentId" : null,
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "I am a little confused here, a node being drained or marked unschedulable should not be considered as candidate host when rescheduling, and IMO this is so called \"not cause the rescheduler to fight a system\". So, should here be `We assume that nodes that are **NOT** intentionally under-utilized`? Or am I misunderstanding something?\n",
        "createdAt" : "2016-03-02T02:14:03Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "3d72f3d3-1ad3-4a56-b515-abb6807e9f56",
        "parentId" : "70dd1e83-eb37-4e9c-bf73-8f6c7ce36206",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "What I was trying to say is that there will be some nodes that are intentionally under-utilized, because they are being drained (for example, in preparation for maintenance). We will assume that these nodes will be marked unschedulable. Thus when looking for under-utilized nodes to move pods onto, we would ignore these nodes.\n",
        "createdAt" : "2016-03-09T07:01:46Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 443,
    "diffHunk" : "@@ -1,1 +441,445 @@onto an under-utilized node, and moving a pod onto a node that meets more of the pod's\naffinity/anti-affinity preferences than wherever it is currently running. (We assume that\nnodes that are intentionally under-utilized, e.g. because they are being drained, are\nmarked unschedulable, thus the first objective will not cause the rescheduler to \"fight\"\na system that is draining nodes.)  We assume that all schedulers sufficiently weight the"
  },
  {
    "id" : "f90ded5b-a3d2-46cf-b1ed-52c1a0e6c2c4",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f15ef0d6-9bcf-45e6-99fb-6cf5eef1dda5",
        "parentId" : null,
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "The alignment of the policies between rescheduler and scheduler is very an important issue. Do we need to design some specific rules to ensure this? A doc that warns the users of custom scheduler and/or the rescheduler is required at the very least.\n",
        "createdAt" : "2016-03-02T02:22:09Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "4e05f96b-11b5-4a4e-b132-e062761a9087",
        "parentId" : "f15ef0d6-9bcf-45e6-99fb-6cf5eef1dda5",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yes, we can put it in the doc described in #17208\n",
        "createdAt" : "2016-03-09T01:22:46Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 460,
    "diffHunk" : "@@ -1,1 +458,462 @@We assume schedulers' priority functions are at least vaguely aligned with the\nrescheduler's policies; otherwise the rescheduler will never accomplish anything useful,\ngiven that it relies on the schedulers to actually reschedule the evicted pods. (Even if\nthe rescheduler acted as a scheduler, explicitly rebinding evicted pods, we'd still want\nthis to be true, to prevent the schedulers and rescheduler from \"fighting\" one another.)"
  },
  {
    "id" : "9c317651-42e2-4071-949e-51338e7942fb",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db909b68-4c19-4e20-bd67-47744f9c5bda",
        "parentId" : null,
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "s/provdes/provides\n",
        "createdAt" : "2016-03-02T02:23:19Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 209,
    "diffHunk" : "@@ -1,1 +207,211 @@sum of the quotas at the top priority level is less than or equal to the total aggregate\ncapacity of the cluster, some pods at the top priority level might still go pending. In\ngeneral, priority provdes a *probabilistic* guarantees of pod schedulability in the face\nof overcommitment, by allowing prioritization of which pods should be allowed to run pods\nwhen demand for cluster resources exceeds supply."
  },
  {
    "id" : "11bcba3a-af2b-4063-98fb-397c6fb63f0f",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "65fd531f-d795-4a73-b572-e2a9491ce57a",
        "parentId" : null,
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "I know what the sentence wants to say here, but should this be 'unavoidable preemptions if......'. Spare me if I am wrong, not native English speaker...\n",
        "createdAt" : "2016-03-02T02:25:18Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      },
      {
        "id" : "3ca9f04f-f354-4b3b-9b56-76cae6bd44ed",
        "parentId" : "65fd531f-d795-4a73-b572-e2a9491ce57a",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I agree it's written a bit confusingly. The idea is that the preemptions could be avoided if you schedule the high-priority pods before the low-priority pods. Hence I called them \"avoidable preemptions\".\n",
        "createdAt" : "2016-03-09T06:52:06Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 184,
    "diffHunk" : "@@ -1,1 +182,186 @@together, since a higher priority genreally indicates that a pod is more urgent to get\nrunning. Also, scheduling low-priority pods before high-priority pods might lead to\navoidable preemptions if the high-priority pods end up preempting the low-priority pods\nthat were just scheduled.\n"
  },
  {
    "id" : "277559ab-a037-4a0f-ba8f-b4a3116d3e63",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e59a62f4-e488-4079-8fe2-480d78bdf90d",
        "parentId" : null,
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "I vote for `explicitly rebinding evicted pods` too. Maybe the initial implementation of rescheduler just evict pods, and we let Controller to create a new one and let Scheduler to schedule it, however unfortunately, scheduler was FIFO and just schedule pod one by one. I think rescheduler could take as input all of the nodes, all of the pods and their constraints, and current pod placements as input. It's job is to find a new global mapping of pods to nodes. So it sounds more reasonable if it can \"rebind\" pods. \n",
        "createdAt" : "2016-03-02T09:25:10Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "87195b82-d6de-4276-b577-3f45c42dcf36",
        "parentId" : "e59a62f4-e488-4079-8fe2-480d78bdf90d",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "Though I still have confusion on `Priority`, if it indicates the order to schedule a pod, We can give the pod to be rescheduled a highest priority, so it can get to the front of the scheduling queue.\nI'm negative to `explicitly rebinding evicted pods`. Two thoughts:\n1. Scheduler knows what is the best pod layout in CURRENT cluster. Just because as the time passes, the cluster condition varies, best choice before will turn to bad choice now. What we need is to make some changes of the pod layout to suit CURRENT cluster again. Rescheduler finds out what is bad, and scheduler knows how to suit CURRENT cluster.\n2. Introducing multiple executor for a same job brings conflicts.\n",
        "createdAt" : "2016-03-03T11:37:43Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "2995fb18-f10a-461a-b946-6708a357c95f",
        "parentId" : "e59a62f4-e488-4079-8fe2-480d78bdf90d",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "Thinking about it more, I agree with you. Introducing multiple executors for a same job is a bad design.\n",
        "createdAt" : "2016-03-03T12:35:56Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "b5a09c15-c511-40a4-ae12-794249e7ea9a",
        "parentId" : "e59a62f4-e488-4079-8fe2-480d78bdf90d",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I agree that we might want some way to force the evicted pod to the front of the scheduler queue, independently of its priority.\n",
        "createdAt" : "2016-03-09T01:21:21Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 463,
    "diffHunk" : "@@ -1,1 +461,465 @@the rescheduler acted as a scheduler, explicitly rebinding evicted pods, we'd still want\nthis to be true, to prevent the schedulers and rescheduler from \"fighting\" one another.)\n\nThe rescheduler will be configured using ConfigMap; the cluster administrator can enable\nor disable policies and can tune the rescheduler's aggressiveness (aggressive means it"
  },
  {
    "id" : "c085e2d4-e2f9-48af-a799-3d1aec817043",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4e58bc0-0daa-4675-b737-ac950c76813b",
        "parentId" : null,
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "Better to use a percentage to represent the value or use the \"down\" description. So we don't need to update the budget when users manually adjust the replicas.\n",
        "createdAt" : "2016-03-03T09:49:29Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "f291ba04-61d9-47c0-ae8d-dcffb0add458",
        "parentId" : "b4e58bc0-0daa-4675-b737-ac950c76813b",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Good point.\n",
        "createdAt" : "2016-03-09T01:13:09Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +226,230 @@* a minimum number of pods that must be up simultaneously (sometimes called \"shard\n  strength\") (of course this can also be expressed as the inverse, i.e. the number of\n  pods of the collection that can be down simultaneously)\n\nThe second item merits a bit more explanation. One use case is to specify a quorum size,"
  },
  {
    "id" : "c3519080-18b2-424e-a3dc-dfb2d55a8a04",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6eb093c5-ff96-4213-ada2-279603eeed80",
        "parentId" : null,
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "In practice, they may have some relations. eg. giving a best-effort pod a high priority doesn't sound reasonable.\n",
        "createdAt" : "2016-03-03T10:10:32Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 178,
    "diffHunk" : "@@ -1,1 +176,180 @@\nPriority and resource QoS are indepedent.\n\nThe priority we have described here might be used to prioritize the scheduling queue\n(i.e. the order in which a scheduler examines pods in its scheduling loop), but the two"
  },
  {
    "id" : "7bef25e6-488a-494a-a7e6-43d7aa278704",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "699f8391-ecb5-4f52-a213-c4f67d326664",
        "parentId" : null,
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "rc and service? Then we need to set up an rule which one would take effect when confliction occurs.\n",
        "createdAt" : "2016-03-03T10:15:51Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +261,265 @@\nTBD: In addition to `PodSpec`, where do we store pointer to disruption budget\n(podTemplate in controller that managed the pod?)? Do we auto-generate a disruption\nbudget (e.g. when instantiating a Service), or require the user to create it manually\nbefore they create a controller? Which objects should return the disruption budget object"
  },
  {
    "id" : "14c39121-7a31-4ce1-8126-188f9259c555",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "parentId" : null,
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "After finish reading the document I get confused about `Priority`, is `Priority` used only for enact preemptions or used to decide which pod get scheduled first? Or both?\n",
        "createdAt" : "2016-03-03T11:27:22Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "414d21af-b841-4b0f-bdee-e97c816ffc01",
        "parentId" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "I think for both. `Priority` is originally used to enact preemption. But if we just have multiple pods in the scheduling queue, we'd better sort them by priority when we decide which pod get scheduled first. Since if we schedule low-priority pods first, it may be preempted soon.\n",
        "createdAt" : "2016-03-03T11:46:14Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "6e575a50-455d-48b1-aa33-b13af087303c",
        "parentId" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "authorId" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "body" : "If for both, it would bring in a problem. As in [this](https://github.com/kubernetes/kubernetes/pull/22217/files#r54868643) situation, a pod is evicted for it has a low priority, and I want it to get scheduled ASAP so I give it a highest priority. But I don't mean to prevent it get evicted next time.\n\nJust got a thought: why not just use QoS class to enact preemption. In practice, I would prefer moving Best-Effort pod to moving Guaranteed pod. And let Priority just to decide the scheduling order?\n",
        "createdAt" : "2016-03-03T12:00:30Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "aa0ae875-2718-4d41-836b-db4cfbf596c8",
        "tags" : [
        ]
      },
      {
        "id" : "6be6bac8-2bfd-4390-b7e2-ad7780f89baf",
        "parentId" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "I think you point out an interesting and important issue here. It deserves further discussion.\n",
        "createdAt" : "2016-03-03T12:30:08Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "4ca77b93-8397-4994-925a-5f73bf8c0e67",
        "parentId" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yes, logically there are three different priorities you might want to specify\n- priority in scheduler queue\n- priority that determines which other pods you can preempt when scheduling\n- priority that determines which other pods can preempt you once you are already running\n\nWhat's being proposed here is just that for an initial version, we use the same value for all three.\n\nWhether priority should be tied to QoS is a separate issue, which we can discuss in the earlier comment @hurf made about it. (I didn't reply to that one yet.)\n",
        "createdAt" : "2016-03-09T01:11:22Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "f5377d58-bd63-493c-9cb5-8757512563f2",
        "parentId" : "63b710d0-b554-4e41-9acc-42dbd1791881",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "Just some thoughts on this, correct me if I am wrong. Priority relates to over-commitment, and there are two \"level\"s of over-commitment: 1.) cluster level and 2.) node level\n\n> priority in scheduler queue\n> priority that determines which other pods you can preempt when scheduling\n\nThere are cluster-level, although some pods are evicted from their running node, at least we made a best effort to let them run somewhere else in the cluster. Quota is also a cluster level mechanism, and this is why some of us may want to link the priority here with Quota.\n\n> priority that determines which other pods can preempt you once you are already running\n\nThis is node-level, QoS currently does the job. I agree that whether QoS should be related to the priority described in this doc is a separated issue, since the motivation of the priority here is a cluster-level concept IMO.\n\nFWIW, I write this because I am afraid that we may get confused when discussing all these \"priority-related\" issues, and I also want to make myself clear about this. I think we should keep in mind which mechanism works at which level, and if they are overlapping on the same level, we need more serious discussion.\n\nJust personal opinions, correct me if there is anything wrong.\n",
        "createdAt" : "2016-03-09T02:38:38Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 182,
    "diffHunk" : "@@ -1,1 +180,184 @@(i.e. the order in which a scheduler examines pods in its scheduling loop), but the two\npriority concepts do not have to be connected. It is somewhat logical to tie them\ntogether, since a higher priority genreally indicates that a pod is more urgent to get\nrunning. Also, scheduling low-priority pods before high-priority pods might lead to\navoidable preemptions if the high-priority pods end up preempting the low-priority pods"
  },
  {
    "id" : "199470aa-717b-4ae6-bd87-ff64a5887abc",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "657a6cec-5281-4ed3-8eb4-9917f0d252ba",
        "parentId" : null,
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "One question: Cold a high-priority pod in namespace A preempt low-priority pod in namespace B?\n",
        "createdAt" : "2016-03-04T01:03:25Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "f5fde9c4-36aa-4df6-bcc7-1e9b1d99770e",
        "parentId" : "657a6cec-5281-4ed3-8eb4-9917f0d252ba",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "It's an interesting question. I think the answer is either \"yes\" or \"we'll make it a configuration parameter of the scheduler.\" Need to think about it more.\n",
        "createdAt" : "2016-03-09T01:18:57Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "40397094-f793-406b-86e0-bfe8f195a152",
        "parentId" : "657a6cec-5281-4ed3-8eb4-9917f0d252ba",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "namespace must be considered in some scenarios. I vote for \"we'll make it a configuration parameter of the scheduler.\"\n",
        "createdAt" : "2016-03-09T02:19:56Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 400,
    "diffHunk" : "@@ -1,1 +398,402 @@Note that there are a lot of details to be figured out here; above is just a very\nhand-wavy sketch of one general approach that might work.\n\nSee #22212 for additional discussion.\n"
  },
  {
    "id" : "415bf5b5-5157-48bd-a1b5-7cbc186f77f4",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d37449a9-3601-4894-9d13-a9f5f6fa12b6",
        "parentId" : null,
        "authorId" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "body" : "what is the `pod's scheduler`?\n",
        "createdAt" : "2016-03-09T06:59:08Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "tags" : [
        ]
      },
      {
        "id" : "e495a460-d619-4edb-a146-fdccffbe2afe",
        "parentId" : "d37449a9-3601-4894-9d13-a9f5f6fa12b6",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "We want support multi-scheduler feature, and it's under active development now. FYI https://github.com/kubernetes/kubernetes/pull/17197\n",
        "createdAt" : "2016-03-09T15:05:09Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "51b9bcce-45f1-4b61-a3aa-5be935a2f36d",
        "parentId" : "d37449a9-3601-4894-9d13-a9f5f6fa12b6",
        "authorId" : null,
        "body" : "@mqliang As far as I can tell from that proposal, each pod still only has one scheduler.  Different schedulers schedule different types of pods, right?\n",
        "createdAt" : "2016-03-14T16:03:04Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +52,56 @@Note that the term \"move\" is not technically accurate -- the mechanism used is that\nKubernetes will terminate a pod that is managed by a controller, and the controller will\ncreate a replacement pod that is then scheduled by the pod's scheduler. The terminated\npod and replacement pod are completely separate pods, and no pod migration is\nimplied. However, describing the process as \"moving\" the pod is approximately accurate"
  },
  {
    "id" : "f8c5e0d2-7449-425c-8051-3455ab938ea7",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "I don't know if this is a good example, as you noted, eviction policies are often better for this scenario.  \n",
        "createdAt" : "2016-03-10T19:30:30Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "1d017837-f432-4b9c-9169-76d442ce987a",
        "parentId" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "@timothysc I didn't understand your comment -- the proposal here is that the rescheduler would notice poor performance due to interference, and do the eviction. So the eviction policy would be implemented in the rescheduler. If you're suggesting that this kind of policy could instead be implemented by kubelet, I agree. I don't have a strong opinion, though I suspect it would be easier to change and configure policies if they are in the rescheduler (though once all the kubelet config is in ConfigMap that may not be true).\n",
        "createdAt" : "2016-03-12T21:18:24Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "49b1be47-9250-4038-a103-eb893953c176",
        "parentId" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "> If you're suggesting that this kind of policy could instead be implemented by kubelet, I agree. \n\nYup, that is what I'm suggesting.  On a fully loaded cluster it may take some time before the metrics are properly gathered in order for the re-scheduler to make an informed decision.  \n",
        "createdAt" : "2016-03-14T14:53:48Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "dab6492a-d7c0-45e5-8293-45845f9f22f7",
        "parentId" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "authorId" : null,
        "body" : "@davidopp @timothysc This is a pretty interesting and important line of thinking, IMO.  Earlier we mentioned that rescheduler's knowledge of what's going on on the node might be incomplete or out of date.  @timothysc mentions something similar here. That motivates for allowing kubelet to evict pods off it's local node. On the other hand, kubelet does not have global information, so can only make locally sensible decisions, which might be globally non-sensible (e.g. evicting pods when the cluster is full and they can't be rescheduled anywhere).  So in many situations it makes more sense for rescheduler to decide what to evict and when.  \n\nMy gut feel says that we probably need both, but we run the risk of having the two evicters (one in the rescheduler, and another on the nodes) fighting against one another.  But we have that problem to solve anyway, given that the scheduler and the rescheduler are also potentially going to fight against each other.\n\nSorry that this does not suggest a very concrete solution - just wanted to make sure that we don't lose track of this problem, and finding a solution to it, as I think it's very important. \n",
        "createdAt" : "2016-03-14T16:37:47Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "caf322a7-c693-4044-b346-d06143441149",
        "parentId" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "So eviction at the kubelet is on the roadmap for 1.3 for other reasons.  /cc @derekwaynecarr @vishh \n",
        "createdAt" : "2016-03-15T18:15:51Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "6237915f-b54e-405c-a238-688b743a9e6a",
        "parentId" : "ac139a3a-a7d8-47ad-9207-ab93ff9f3e8a",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : ">  the scheduler and the rescheduler are also potentially going to fight against each other.\n\nHopefully this shouldn't be the case. The intention is that the rescheduler's policies should be compatible with the schedulers' policies, in the sense that none of the policies are \"opposite\" (if one cares about something that the other doesn't care about, that should be fine). I think this compatibility is likely to happen naturally; for example, you wouldn't write a policy that _tries_ to put a pod on a node where as few as possible of its soft affinity constraints are met. The only place where I can see a potential problem is best-fit vs. worst-fit; there are good rationales for both policies, and it would be bad if scheduler(s) chose one and the rescheduler chose the other. There are various ways to prevent or mitigate this problem, all of which I'm sure you can imagine.\n",
        "createdAt" : "2016-03-21T07:02:36Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +87,91 @@    rejected by Kubelet admission control due to incomplete scheduler knowledge\n  * poor performance due to interference from other containers on the node (CPU hogs,\n    cache thrashers, etc.) (note that in this case there is a choice of moving the victim\n    or the aggressor)\n"
  },
  {
    "id" : "94114907-baaa-4535-a686-502de3fa6548",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9db75446-0eb7-449b-b6fc-c9301f1ab105",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "This is where configurable policy is key.   Without a configurable pre-emption policy there are 2nd order effects that can cause the system to resonate. \n",
        "createdAt" : "2016-03-10T19:33:16Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 108,
    "diffHunk" : "@@ -1,1 +106,110 @@  a preemption when it reschedules, etc.), does the rescheduler execute multi-step plans\n  (e.g. evict two pods at the same time with the intent of moving one into the space\n  vacated by the other, or even more complex plans)\n\nAdditional musings on the rescheduling design space can be found [here](rescheduler.md)."
  },
  {
    "id" : "fd20345d-71df-4a81-abcd-8a4bb9ebc964",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad2be4ae-1976-4a52-afea-07e79ec6bfeb",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "Couldn't those be their own design proposals.  \n",
        "createdAt" : "2016-03-10T19:34:06Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "afbb389e-21ae-42c2-82cb-1df3c3cc6522",
        "parentId" : "ad2be4ae-1976-4a52-afea-07e79ec6bfeb",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I debated whether to split priority/preemption into a separate doc. FWIW the reasons I made this one doc were\n- disruption budget is part of both preemption and rescheduler\n- /evict subresource is part of both preemption and rescheduler\n- preemption can be seen as a form of rescheduling, that is driven by the scheduler (in this proposal) rather than the rescheduler. You could imagine an alternative implementation of preemption that is driven by the rescheduler (it notices a pending pod is blocked, and moves some pod(s) out of the way so that it can schedule). I think the ideas are connected enough to warrant putting them into the same doc. It does make the doc a bit harder to digest overall, though.\n",
        "createdAt" : "2016-03-12T21:28:42Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 114,
    "diffHunk" : "@@ -1,1 +112,116 @@## Design proposal\n\nThe key mechanisms and components of the proposed design are priority, preemption,\ndisruption budgets, the `/evict` subresource, and the rescheduler.\n"
  },
  {
    "id" : "7ac0cb77-2334-4141-8600-5c093aef56bf",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "It might be beneficial to also think in terms of world/namespace(group)/local(user) priority.  B/c in the case of openshift, a user might want to assign their own relative priority but is \"trumped\" by group and world priority. \n",
        "createdAt" : "2016-03-10T19:40:43Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "01da6c28-5ee1-4d1f-adab-5841ac21e810",
        "parentId" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yeah, @bgrant0607 had suggested some kind of user-specified priority relative to namespace. I think this might merit a separate sub-proposal, since it's a somewhat complicated topic. For example, I'm not sure how it interacts with quota, and also I'm not convinced you want to say some namespaces are always higher/lower-priority than some other namespaces. This is related to the question @mqliang asked later about whether preemption should be allowed at all across namespaces (my cop-out was that this should be a scheduler configuration pattern, but I thought most people would want the answer to be \"yes\").\n\nBTW I didn't understand the \"world\" part in your comment. The way I was thinking about this stuff was analogous to: priority is a two-digit base-10 number, high-order digit is determined by namespace (mapping of namespace to digit is configured by cluster admin) and low-order digit is determined by user. Where does the \"world\" part come in?\n",
        "createdAt" : "2016-03-12T21:54:22Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "73ea6743-d2a4-4d33-a1da-2a4c780366df",
        "parentId" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "> had suggested some kind of user-specified priority relative to namespace. I think this might merit a separate sub-proposal, since it's a somewhat complicated topic. For example, I'm not sure how it interacts with quota, and also I'm not convinced you want to say some namespaces are always higher/lower-priority than some other namespaces.\n\nThis is an interesting topic. Question: Should this feature really need to be supported by kubernetes explicitly? Why can't it be built on top of kubernetes? For example: A high-priority namespace(user) could get a ResourceQuota which allow him create more Pods(or more high-priority Pods). \n",
        "createdAt" : "2016-03-14T05:40:04Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "9846df87-1ac0-4e64-b5b5-4dcdc5f0c952",
        "parentId" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "> This is related to the question @mqliang asked later about whether preemption should be allowed at all across namespaces (my cop-out was that this should be a scheduler configuration pattern, but I thought most people would want the answer to be \"yes\").\n\nIf we allow preemption across namespaces, there is a problem about ResourceQuota:\n\n> Generally, there are two viewpoints about this question, both of them sounds reasonable.\n> \n> Viewpoint 1: can not preempt across namespaces\n> Reason : A namespace indicating a user community in k8s. All users are equal, so namespace has no priority, just pod has priority(i.e. Pod of DaemonSet has the highest priority, Pod of Job has the lowest priority). If a user want run more high-priority Pods when he can not preempt his low-priority pod in further step, he should apply for more ResourceQuota(for example, pay more money), instead of preempt low-priority pods of other users.\n> \n> Someone might imagine that it does not decrease availability even if low-priority pods could be preempted by other user's high-priority pods, since we have \"DisruptionBudget\", which could ensure availability, but I feel nervous about it, for example: As a user, I get a ResourceQuota(I may paid some money to get one) which allow me create 5 Pods, so service provider(k8s) must ensure I could always successfully create and run 5 Pods, right(I paid the money)? If unfortunately, my pods could be preempted by others' high-priority Pods, I feel it's hard to accept.\n> \n> Viewpoint 2: can preempt across namespaces\n> Reason : In such a case, as a user, I get a ResourceQuota which allow me create AT MOST 10 Pods, but just ensure 5 pods's availability(DisruptionBudget is 50%). So I could create at most 10 pods, service provider(k8s) will make sure there are 5 pods are always Running. As a bonus, 5 pods I created could be Running if cluster resource is sufficient. But service provider(k8s) doesn't give any promise about the latter 5 pods: they may be preempted by other users' high-priority pods at any time.\n> \n> So, if we want preempt across namespaces, ResourceQuota should take DisruptionBudget into account too. ResourceQuota should not only restrict the number of all kinds of Pods in one namespace, but also restrict the number of \"effective\" Pod. \"effective\" Pods means the Pods protected by DisruptionBudget, those Pods will never become unavailable.\n\nAll my assumption was based on my understanding of ResourceQuota: as a user, I pay some money to get a ResourceQuota which allow me create 5 Pods, then service provider(k8s) should always ensure I could create and run 5 pods. If my understanding was wrong, feel free to correct me.\n\nThis also related to the \"namespace(group)/local(user) priority\" problem. My understanding is: namespace(user) may have priority, but such a priority means how many resource they can get, a high-priority namespace(user) could get a ResourceQuota which allow him create more Pods(or more high-priority Pods). \n\nJust my random thoughts for discussion.\n",
        "createdAt" : "2016-03-14T05:50:37Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "9dc538d8-4853-40f9-aedd-631535891a65",
        "parentId" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "> BTW I didn't understand the \"world\" part in your comment.\n\nworld in this sense could be system policies.  e.g. daemonsets can preempt *.  \nI'm simply channeling the tradition unix permissions model.  \n\n>  Question: Should this feature really need to be supported by kubernetes explicitly? Why can't it be built on top of kubernetes?\n\nI'm all for plug-able policy, but that would also complicate the design.  In general, I think kubernetes should be a more plug-able engine, atop of which folks can implement domain specific policies.  \n",
        "createdAt" : "2016-03-14T15:03:28Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "3d8f9ad1-c6a3-4726-9fd2-19fadc0e849a",
        "parentId" : "18c97501-cdf5-4b87-bf54-d0c1cce09521",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "I think the quota discussion merits a separate doc and a separate discussion, but should wait to have that discussion until we've agreed on the stuff that's in this doc. All this doc is trying to say is that a cluster administrator will probably want to set quota for disruption budget, to prevent users from always says their pods can never be evicted. We are saying how that quota would work. Also the doc suggests that resource quota should probably be per-priority-level, since a cluster administrator may want to \"guarantee\" schedulability of the highest-priority pods by not overcommitting those priority levels, but encourage high utilization by overcommitting lower priority levels. We're not trying to suggest anything more than that here.\n",
        "createdAt" : "2016-03-21T06:40:21Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 150,
    "diffHunk" : "@@ -1,1 +148,152 @@easy for an administrator to add new priority levels in between existing levels, to\nencourage thinking about priority in terms of user intent and avoid magic numbers, and to\nmake the internal implementation more flexible.\n\nWhen a scheduler is scheduling a new pod P and cannot find any node that meets all of P's"
  },
  {
    "id" : "2959ed2a-127d-424f-8717-cf636e041f5a",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "what granularity are we considering here?  \n",
        "createdAt" : "2016-03-10T19:51:06Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "62f69ee7-5d2b-4d2c-a2a7-7c990ac80b13",
        "parentId" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "The feature would be implemented by an (optional) pointer from each Pod to a disruption budget, so in principle users could configure the granularity however they want (by manually creating a disruption budget, and then manually creating Pods that point to it). They can also create the link by specifying it in the podTemplate in any object that stamps out replicas. I think there is a question of what other mechanism(s) we provide to allow users to easily associate a disruption budget with other kinds of objects. I had suggested Service and Job elsewhere, but now I realize Job already has a podTemplate, so really I guess I am just suggesting Service. And maybe that should be Deployment, not Service. This would be simpler if we had #14956.\n",
        "createdAt" : "2016-03-12T22:07:36Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "896ec70f-1e59-4c68-adb0-961509877cb0",
        "parentId" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "Using label/selector to match DisruptionBudget and a collection of Pods allows user manually specify the granularity, which is very flexible. But this introduce the \"overlapping\" problem: a collection of pods is managed by multiple budgets.\n\nMaking DisruptionBudget as a part of Service sounds good. But how about the Pods without a matching Service, they can be always evicted or will never be evicted?\n",
        "createdAt" : "2016-03-14T04:35:57Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "a925836d-6109-41c6-95e5-27825194540b",
        "parentId" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Just to be clear: DisruptionBudget should be a separate API object, with an optional pointer from each pod to its DisruptionBudget. We're just talking about whether there is some way to define it simultaneously with a Service (or Job). I think it's fine to not do this initially.\n",
        "createdAt" : "2016-03-14T04:41:30Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "c4331331-0c14-47cd-ab8c-5a1d9b6fe836",
        "parentId" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "authorId" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "body" : "> DisruptionBudget should be a separate API object \n\nSorry for my misleading comments, I also mean it should be a separate API object.\n\n> with an optional pointer from each pod to its DisruptionBudget\n\nShould we put the pointer pointing to DisruptionBudget in Service/Job/DaemonSet(we also support rolling update of DaemonSet), instead of Pod?\n",
        "createdAt" : "2016-03-14T05:27:16Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "fa03ed6a-9d2a-44b6-8438-e21ee4a2ce4d",
        "tags" : [
        ]
      },
      {
        "id" : "05acaa5b-fe10-457a-8f6c-829f927836ed",
        "parentId" : "53e07c4e-317b-42c7-8dd0-c32d3eefadc8",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "> Should we put the pointer pointing to DisruptionBudget in Service/Job/DaemonSet(we also support rolling update of DaemonSet), instead of Pod?\n\nWhy instead of Pod? Putting it in Pod allows a component that needs to look at the DisruptionBudget, to find it very easily, and also is an easy way to guarantee there is never more than one DisruptionBudget per pod.\n",
        "createdAt" : "2016-03-21T06:30:11Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +222,226 @@(e.g. `DisruptionBudgetSpec`) to consist of\n\n* a rate limit on disruptions (preemption and other evictions) across the corresponding\n  set of pods, e.g. no more than one disruption per hour across the pods of a particular Service\n* a minimum number of pods that must be up simultaneously (sometimes called \"shard"
  },
  {
    "id" : "e3e0749d-d52d-4ab1-9f86-55d476c78f43",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0953fc3-3b70-4034-895d-9c1fa9119f9d",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "Do we have any docs that concretely define how we label pods state as being \"poor\".  \n",
        "createdAt" : "2016-03-10T20:19:45Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "7e6f327d-848e-4f57-bf0f-5f6ce2348276",
        "parentId" : "c0953fc3-3b70-4034-895d-9c1fa9119f9d",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Not yet. I anticipate that the people who implement the rescheduler/experiment with rescheduler policies will write a doc covering that question (for the policies they plan to implement) before implementing. In this doc I've just sketched out some general categories; defining the exact criteria you'd use for triggering an eviction is worthy of (a) separate doc(s), and surely will require experimentation and refinement based on observed behavior in practice.\n",
        "createdAt" : "2016-03-12T22:12:13Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "c771e56c-b93e-4d62-a749-266a0540e730",
        "parentId" : "c0953fc3-3b70-4034-895d-9c1fa9119f9d",
        "authorId" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "body" : "I am going to write a doc focusing on implementing the rescheduler component, in which the policy will be included. We can discuss the policy on that doc then.\n",
        "createdAt" : "2016-03-14T01:15:38Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "367ad63e-2fc8-4db1-949a-10424aaf7469",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 335,
    "diffHunk" : "@@ -1,1 +333,337 @@\n`PreferAvoidPods` is useful for the \"moving a running pod off of a node from which it is\nreceiving poor service\" use case, as it reduces the chance that the replacement pod will\nend up on the same node (keep in mind that most of those cases are situations that the\nscheduler does not have explicit priority functions for, for example it cannot know in"
  },
  {
    "id" : "c79af169-15e0-4e9d-ab82-a00ff82cc9b5",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b0b163d7-0e27-4f30-a8ee-cc6c4a40a21c",
        "parentId" : null,
        "authorId" : "2189757a-ca1a-4186-a1b2-cd6358214fe9",
        "body" : "Does it imply that \"under-utilization of a node\" triggers rescheduling in this case?\n",
        "createdAt" : "2016-03-14T08:18:26Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "2189757a-ca1a-4186-a1b2-cd6358214fe9",
        "tags" : [
        ]
      },
      {
        "id" : "000073a6-88ba-4507-bfce-4d4cc04c3404",
        "parentId" : "b0b163d7-0e27-4f30-a8ee-cc6c4a40a21c",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Yes, see this comment: https://github.com/kubernetes/kubernetes/pull/22217/files#r55478760\n",
        "createdAt" : "2016-03-21T06:42:38Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +72,76 @@\n* moving a running pod onto a node that better satisfies its scheduling criteria\n  * moving a pod onto an under-utilized node\n  * moving a pod onto a node that meets more of the pod's affinity/anti-affinity preferences\n* moving a running pod off of a node in anticipation of a known or speculated future event"
  },
  {
    "id" : "5de91c8a-50c6-4766-844a-cc1722d1283d",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c3bacc9-85a7-4f7e-9593-26ceba9447bf",
        "parentId" : null,
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "Let's move this to a design doc. It's underway already.\n",
        "createdAt" : "2016-06-25T03:20:40Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "664e2a05-79f6-4a78-b132-d97c9ad5dd2f",
        "parentId" : "7c3bacc9-85a7-4f7e-9593-26ceba9447bf",
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "Nevermind. If we move priority out, isn't the rest resolved and underway, and this could be merged?\n",
        "createdAt" : "2016-06-25T03:22:17Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "b63e84ba-a2ed-4c23-8ca1-a3e2cb48714c",
        "parentId" : "7c3bacc9-85a7-4f7e-9593-26ceba9447bf",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "@bgrant0607 Issue/PR? \n",
        "createdAt" : "2016-06-28T03:08:10Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "e07695dd-fb35-43d1-8716-8c4ef8d994c1",
        "parentId" : "7c3bacc9-85a7-4f7e-9593-26ceba9447bf",
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "PodDisruptionBudget API is already merged, see\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/apis/policy/v1alpha1/types.go#L56\n\nThe controller for it is awaiting my review, #25921.\n\nLast step is to implement /evict subresource (no PR for that yet).\n",
        "createdAt" : "2016-06-28T04:36:55Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : 213,
    "diffHunk" : "@@ -1,1 +211,215 @@when demand for cluster resources exceeds supply.\n\n### Disruption budget\n\nWhile priority can protect pods from one source of disruption (preemption by a"
  },
  {
    "id" : "43407741-e284-4ef2-9ca2-b60e92882c2c",
    "prId" : 22217,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5b269c2-18dc-4ef4-a557-4de1fc90d9a5",
        "parentId" : null,
        "authorId" : "11725e10-43c9-4a8c-96d0-5118a3e67a6a",
        "body" : "These nested lists are completely mangled when converted to HTML.  I think you need to have no leading spaces before the asterisks for the outer bullets.\n",
        "createdAt" : "2016-07-08T02:56:28Z",
        "updatedAt" : "2016-07-10T22:00:20Z",
        "lastEditedBy" : "11725e10-43c9-4a8c-96d0-5118a3e67a6a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b77e39298eaf3427bd004402e275dadc3b2e9fbb",
    "line" : null,
    "diffHunk" : "@@ -1,1 +284,288 @@today's \"delete\" on pod except\n\n  * It will be rejected if the deletion would violate disruption budget. (See how\n    Deployment handles failure of /rollback for ideas on how clients could handle failure\n    of `/evict`.) There are two possible ways to implement this:"
  }
]