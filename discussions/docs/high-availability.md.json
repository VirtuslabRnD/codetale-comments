[
  {
    "id" : "8b4c6eb3-d9bd-480b-8ec3-4646fb9f7f4e",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f6a769b-9f32-49d9-b97d-52acf6b6ce81",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Also mention that this should work on bare metal or cloud?\n",
        "createdAt" : "2015-06-03T06:18:35Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "9b875b9b-5b99-4e92-82dc-31eb6cb887cd",
        "parentId" : "0f6a769b-9f32-49d9-b97d-52acf6b6ce81",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "done.\n",
        "createdAt" : "2015-06-03T18:55:11Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : null,
    "diffHunk" : "@@ -1,1 +28,32 @@## Initial set-up\nThe remainder of this guide assumes that you are setting up a 3-node clustered master, where each machine is running some flavor of Linux.\nExamples in the guide are given for Debian distributions, but they should be easily adaptable to other distributions.\nLikewise, this set up should work whether you are running in a public or private cloud provider, or if you are running\non bare metal."
  },
  {
    "id" : "dcb7c5cf-aee4-4f84-8173-012cc7c01a01",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a528649-7811-4a40-9430-29e19092a3b4",
        "parentId" : null,
        "authorId" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "body" : "Maybe redundant, but I would end this section with something like:\n\nNow you will have one scheduler process running and one controller manage process running, and if one of these processes or its nodes fails, another node will launch the corresponding process to take over.\n",
        "createdAt" : "2015-06-03T06:20:03Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "82da2b23-9f40-4abd-8af5-56ba07c1fc0a",
        "tags" : [
        ]
      },
      {
        "id" : "4a093970-cea7-4a72-a7db-3d3a36be3e2e",
        "parentId" : "6a528649-7811-4a40-9430-29e19092a3b4",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "done.\n",
        "createdAt" : "2015-06-03T18:56:11Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : 187,
    "diffHunk" : "@@ -1,1 +185,189 @@Now that the configuration files are in place, copy the [podmaster.manifest](high-availability/podmaster.manifest) config file into ```/etc/kubernetes/manifests/```\n\nAs before, the kubelet on the node monitors this directory, and will start an instance of the podmaster using the pod specification provided in ```podmaster.manifest```.\n\nNow you will have one instance of the scheduler process running on a single master node, and likewise one"
  },
  {
    "id" : "ad96589d-8619-4ef6-8d84-dac872ae2565",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83c3a939-ebfa-42f6-8727-ce8aad713a46",
        "parentId" : null,
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "Not only are they simpler, but they are continuously tested.  I'm sure we'll get to the point where the HA is part of e2e, but until then, best to make it clear which path is best supported.\n",
        "createdAt" : "2015-06-03T22:10:44Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      },
      {
        "id" : "10b63407-c0e6-4801-b4c7-3f2bcae3f856",
        "parentId" : "83c3a939-ebfa-42f6-8727-ce8aad713a46",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "added a note to make this point.\n",
        "createdAt" : "2015-06-04T04:31:53Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : null,
    "diffHunk" : "@@ -1,1 +6,10 @@the simple [Docker based single node cluster instructions](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/docker.md),\nor try [Google Container Engine](https://cloud.google.com/container-engine/) for hosted Kubernetes.\n\nAlso, at this time high availability support for Kubernetes is not continuously tested in our end-to-end (e2e) testing.  We will\nbe working to add this continuous testing, but for now the single-node master installations are more heavily tested."
  },
  {
    "id" : "5f9dce93-6763-416b-a575-6921a248d699",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6daafd80-0aa1-44af-b3cc-d55e511f1d02",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "will you add the scheduler and controller-manager are examples of other client?\n",
        "createdAt" : "2015-06-04T17:19:38Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      },
      {
        "id" : "8d148677-3e06-4a45-844e-6557041d1eae",
        "parentId" : "6daafd80-0aa1-44af-b3cc-d55e511f1d02",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "actually, scheduler and controller-manager just connect to localhost.  There is no world in which they can be successfully running on a master node replica, and there isn't a corresponding api server.\n\neventually we may self-host those containers in the k8s cluster itself, in which case we'd use the load balanced endpoing, but we're not there yet.\n",
        "createdAt" : "2015-06-04T17:52:25Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      },
      {
        "id" : "e283dddd-f71f-4a75-972a-195ee65e18f2",
        "parentId" : "6daafd80-0aa1-44af-b3cc-d55e511f1d02",
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "the sched&cm have a --master arg to talk to a non-localhost apiserver, but it makes sense that it's preferred to run against the local apiserver. i ran into this in #7181.\n",
        "createdAt" : "2015-06-04T20:39:00Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : 159,
    "diffHunk" : "@@ -1,1 +157,161 @@For pods that you deploy into the cluster, the ```kubernetes``` service/dns name should provide a load balanced endpoint for the master automatically.\n\nFor external users of the API (e.g. the ```kubectl``` command line interface, continuous build pipelines, or other clients) you will want to configure\nthem to talk to the external load balancer's IP address.\n"
  },
  {
    "id" : "32babb93-e516-42e8-844b-05c9c97e0dc8",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53ee0a32-b5cf-427b-82d4-99e819715b89",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "this is amusing. i'd say it's more like keeping a spare outfit in your backpack and not having anywhere discrete to change!\n",
        "createdAt" : "2015-06-04T17:43:28Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +12,16 @@## Overview\nSetting up a truly reliable, highly available distributed system requires a number of steps, it is akin to\nwearing underwear, pants, a belt, suspenders, another pair of underwear, and another pair of pants.  We go into each\nof these steps in detail, but a summary is given here to help guide and orient the user.\n"
  },
  {
    "id" : "5b38a420-5fd5-42bb-bdc1-f27d0acf67c7",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3bd5084-ff6f-493a-b7fe-972edc562409",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "suggestion -\n\"\n...first step make these reliable...need a watcher process.\n\nfor debian, we choose monit....\n\nfor systemd-based systems, you can run 'systemctl enable kubelet'. you should also have run 'systemctl enable docker'\n\"\n",
        "createdAt" : "2015-06-04T18:25:57Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      },
      {
        "id" : "42cd4ddc-5fa9-437f-a724-bbea6391afdc",
        "parentId" : "a3bd5084-ff6f-493a-b7fe-972edc562409",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "done.\n",
        "createdAt" : "2015-06-08T04:58:41Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : null,
    "diffHunk" : "@@ -1,1 +51,55 @@\nIf you are using monit, you should also install the monit daemon (```apt-get install monit```) and the [/etc/monit/conf.d/kubelet](high-availability/monit-kubelet) and\n[/etc/monit/conf.d/docker](high-availability/monit-docker) configs.\n\nOn systemd systems you ```systemctl enable kubelet``` and ```systemctl enable docker```."
  },
  {
    "id" : "96405076-2b84-4563-b8b4-30b3c5665396",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9803d1aa-354a-4228-8c8e-39cee02821c6",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "nit, could add kubelet to the worker node boxes\n",
        "createdAt" : "2015-06-08T11:48:16Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : null,
    "diffHunk" : "@@ -1,1 +22,26 @@\nHere's what the system should look like when it's finished:\n![High availability Kubernetes diagram](high-availability/ha.png)\n\nReady? Let's get started."
  },
  {
    "id" : "7d0fa10b-0aba-42c9-ad7b-60871483a8d5",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8aa0c3d0-fcb1-4b88-8fee-33aab32e472a",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "nit, previously used high-availability / highly-available and switched to HA here\n",
        "createdAt" : "2015-06-08T11:50:50Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      },
      {
        "id" : "3f605edc-f8ac-4e1d-be7d-91fe6ba3b38d",
        "parentId" : "8aa0c3d0-fcb1-4b88-8fee-33aab32e472a",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "added parenthetical \"HA\" to make this transition evident.\n",
        "createdAt" : "2015-07-06T14:22:31Z",
        "updatedAt" : "2015-07-06T14:22:31Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +32,36 @@on bare metal.\n\nThe easiest way to implement an HA Kubernetes cluster is to start with an existing single-master cluster.  The\ninstructions at [https://get.k8s.io](https://get.k8s.io)\ndescribe easy installation for single-master clusters on a variety of platforms."
  },
  {
    "id" : "1148b0c0-191e-4494-ad23-8efe137b944e",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bdbea081-1e6b-4c0c-8a5a-3ecbbba1083b",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "nit, this flows better if each of these steps clearly corresponds to a section below. you could use the same text or link them. currently \"installing a health-checking daemon runner\" maps to \"reliable nodes\" while \"setting up a redundant, reliable...\" maps to \"establishing a redundent, ...\"\n",
        "createdAt" : "2015-06-08T11:59:10Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      },
      {
        "id" : "22dcb024-d1f3-4b48-9eaa-d6fd6650819d",
        "parentId" : "bdbea081-1e6b-4c0c-8a5a-3ecbbba1083b",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "links added.\n",
        "createdAt" : "2015-07-06T14:22:13Z",
        "updatedAt" : "2015-07-06T14:22:13Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +15,19 @@of these steps in detail, but a summary is given here to help guide and orient the user.\n\nThe steps involved are as follows:\n   * [Creating the reliable constituent nodes that collectively form our HA master implementation.](#reliable-nodes)\n   * [Setting up a redundant, reliable storage layer with clustered etcd.](#establishing-a-redundant-reliable-data-storage-layer)"
  },
  {
    "id" : "37b07a28-1080-4780-9fb1-2716bf175ad9",
    "prId" : 9136,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae16876d-e757-4d26-96bc-96a9498949c0",
        "parentId" : null,
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "the podmaster.manifest appears to be missing from the commit\n",
        "createdAt" : "2015-06-08T12:12:17Z",
        "updatedAt" : "2015-07-06T14:21:15Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      },
      {
        "id" : "c592f4c6-367e-4ae3-9b92-9579ca152c98",
        "parentId" : "ae16876d-e757-4d26-96bc-96a9498949c0",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "it was mis-named.  fixed.\n",
        "createdAt" : "2015-07-06T14:22:01Z",
        "updatedAt" : "2015-07-06T14:22:01Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "431f1f43842c506ea8e469882d8b7256589ece00",
    "line" : null,
    "diffHunk" : "@@ -1,1 +183,187 @@\n### Running the podmaster\nNow that the configuration files are in place, copy the [podmaster.manifest](high-availability/podmaster.manifest) config file into ```/etc/kubernetes/manifests/```\n\nAs before, the kubelet on the node monitors this directory, and will start an instance of the podmaster using the pod specification provided in ```podmaster.manifest```."
  }
]