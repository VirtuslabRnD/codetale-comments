[
  {
    "id" : "525d581e-dae9-47cc-a8c5-003ed5b898b7",
    "prId" : 1411,
    "prUrl" : "https://github.com/akka/alpakka/pull/1411#pullrequestreview-192501543",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "136feee3-b94e-4de2-8178-a8a276aca6d1",
        "parentId" : null,
        "authorId" : "8173970f-6a3f-4891-8394-179e8251af2d",
        "body" : "Above in the `@@dependency` change `$scalaBinaryVersion$` to `$scala.binary.version$` and `$version$` to `$project.version$`.",
        "createdAt" : "2019-01-15T06:44:03Z",
        "updatedAt" : "2019-01-16T08:27:16Z",
        "lastEditedBy" : "8173970f-6a3f-4891-8394-179e8251af2d",
        "tags" : [
        ]
      }
    ],
    "commit" : "f69ab00d391921b23a3a2b8d7b786516592a8198",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +31,35 @@@@dependencies { projectId=\"couchbase\" }\n\n# Overview\n\nAlpakka Couchbase offers both Akka Streams APIs and a more direct API to access Couchbase:"
  },
  {
    "id" : "3f21ab5b-d804-4828-bec5-1079dab5fcdb",
    "prId" : 1203,
    "prUrl" : "https://github.com/akka/alpakka/pull/1203#pullrequestreview-162210728",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f6a70cd-d7fb-45a2-9b19-6d24a13dda85",
        "parentId" : null,
        "authorId" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "body" : "> Persistance\r\n\r\nPersistence\r\n\r\nAre these realistic defaults? I understand they are good for demos, but I think the defaults should target real scenarios.",
        "createdAt" : "2018-10-05T07:13:01Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "tags" : [
        ]
      },
      {
        "id" : "7042b9a5-dd70-4d92-b1f9-c76fc3b69461",
        "parentId" : "4f6a70cd-d7fb-45a2-9b19-6d24a13dda85",
        "authorId" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "body" : "Fo the Replication - let's change default value to One it means that we observe one replica of data besides the master and we will survive master replica failure. \r\n\r\nFor the persistence - i would like to leave it as is because couchbase bucket divided to memory and disk. only  when bucket memory expands to some value (memory high watermark) it will start persistence to the disk in LRU manner. I would like not to enforce persistence and let couchbase decide when to persist this data. ",
        "createdAt" : "2018-10-05T21:32:17Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c490b57d5e21161af10c9751b3b83a02d272d3f9",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +70,74 @@- Stage Parallelism (default 1)\n- Couchbase Replication Factor (default `ReplicateTo.ONE`) \n- Couchbase Persistance Level for Write Operation (default `PersistTo.NONE`)\n- 2 seconds operation timeout \n"
  },
  {
    "id" : "c67d980a-32a2-4b68-83c6-7cd4710accbf",
    "prId" : 1203,
    "prUrl" : "https://github.com/akka/alpakka/pull/1203#pullrequestreview-162213810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a0a83fd-c208-4724-87ae-1d6ad5a7ce47",
        "parentId" : null,
        "authorId" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "body" : "I find this returning of an exception very surprising. We normally want a stream to fail if anything goes wrong. What kind of errors can we expect here? Why did you decide to do it this way?",
        "createdAt" : "2018-10-05T07:15:39Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "tags" : [
        ]
      },
      {
        "id" : "cb5658b4-f733-426f-8db6-7edf58df18ef",
        "parentId" : "2a0a83fd-c208-4724-87ae-1d6ad5a7ce47",
        "authorId" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "body" : "I did it for the reason of so-called \"Partial failures\" and subjective consistency, as I explained it in long comment below. \r\nPattern is simple: got exception, deal with as next stage of the flow, continue as usual or solve the problem when your system is back to normal. \r\nWould apply this pattern to any strong consistency distributed system. ",
        "createdAt" : "2018-10-05T21:45:30Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c490b57d5e21161af10c9751b3b83a02d272d3f9",
    "line" : 127,
    "diffHunk" : "@@ -1,1 +125,129 @@- For an operation on single object output will be instance of `SingleOperationResult` class which consists of input `T` and optional exception of failed operation \n\n- For an operation on bulk the output will be instance of `BulkOperationResult` class which consists of Collection of input elements and Collection failed documents Id's and its relevant Exception. \n\nThis is vivid if you want to handle partial or single failures and do not want to affect stream materialization.  "
  },
  {
    "id" : "6a43554d-b299-41b9-8483-960b4062a426",
    "prId" : 1203,
    "prUrl" : "https://github.com/akka/alpakka/pull/1203#pullrequestreview-162213783",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4bfac5a0-20ac-497b-beab-ee19fe51a7b9",
        "parentId" : null,
        "authorId" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "body" : "I find this returning of an exception very surprising. We normally want a stream to fail if anything goes wrong. What kind of errors can we expect here? Why did you decide to do it this way?\r\nShould this be something the user opts in to explicitly?",
        "createdAt" : "2018-10-05T07:16:59Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "tags" : [
        ]
      },
      {
        "id" : "e31c1124-7094-4db1-b8c8-e6ce12b77ab6",
        "parentId" : "4bfac5a0-20ac-497b-beab-ee19fe51a7b9",
        "authorId" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "body" : "The same answer as above:\r\n\r\nI did it for the reason of so-called \"Partial failures\" and subjective consistency, as I explained it in long comment below. \r\nPattern is simple: got exception, deal with as next stage of the flow, continue as usual or solve the problem when your system is back to normal. \r\nWould apply this pattern to any strong consistency distributed system. ",
        "createdAt" : "2018-10-05T21:45:21Z",
        "updatedAt" : "2018-11-06T15:14:44Z",
        "lastEditedBy" : "6204914f-856a-4191-be81-95b3ba04dc4f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c490b57d5e21161af10c9751b3b83a02d272d3f9",
    "line" : 129,
    "diffHunk" : "@@ -1,1 +127,131 @@- For an operation on bulk the output will be instance of `BulkOperationResult` class which consists of Collection of input elements and Collection failed documents Id's and its relevant Exception. \n\nThis is vivid if you want to handle partial or single failures and do not want to affect stream materialization.  \n\nCreating flow with single upsert operation"
  }
]