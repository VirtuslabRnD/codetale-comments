[
  {
    "id" : "e46064b0-2f3b-4c29-9b12-4ac086e66f35",
    "prId" : 3848,
    "prUrl" : "https://github.com/apache/kafka/pull/3848#pullrequestreview-191900203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8019499c-cae2-44fe-b6b6-b47d08e405d0",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since this is handled async, we probably want to assert that broker 1 is no longer in ISR before proceeding.",
        "createdAt" : "2019-01-12T18:08:22Z",
        "updatedAt" : "2019-01-25T09:57:17Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df18c6b3232f3e8b9bf879b7a8dd762a5968c6c",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +1338,1342 @@    changePreferredLeader(prefer1)\n    // but shut it down...\n    servers(1).shutdown()\n    waitUntilTrue (\n      () => {"
  },
  {
    "id" : "518ddc08-e6ba-4c04-8e46-f767f8903a6b",
    "prId" : 3848,
    "prUrl" : "https://github.com/apache/kafka/pull/3848#pullrequestreview-191900203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7f05de3-f83d-42e6-b464-729aead916e5",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Great test! Perhaps we should disable auto leader balancing in all brokers to avoid interfering. \r\n\r\nAlso, this is an existing issue. I am wondering if we should disable controlled shutdown to speed up the test since waiting for controlled shutdown when stopping the last broker can be long.",
        "createdAt" : "2019-01-12T18:09:27Z",
        "updatedAt" : "2019-01-25T09:57:17Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df18c6b3232f3e8b9bf879b7a8dd762a5968c6c",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1203,1207 @@\n  @Test\n  def testElectPreferredLeaders(): Unit = {\n    client = AdminClient.create(createConfig)\n"
  },
  {
    "id" : "3830625b-614f-44b2-a85b-e3370dade0f4",
    "prId" : 4980,
    "prUrl" : "https://github.com/apache/kafka/pull/4980#pullrequestreview-121146524",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48bb277a-a41e-4c0c-b0a1-2226e22561b6",
        "parentId" : null,
        "authorId" : "d418e163-e0f8-4dec-9432-7f0eb6df2a1b",
        "body" : "Can you extract the assertions with comments to separate methods? For example:\r\nverifyNewConsumerGroupCanBeListed\r\nverifyNewConsumerGroupCanBeDescribed\r\nverifyFakeConsumerGroupIsListedAsDead\r\nverifyConsumerGroupOffsetsAreListed\r\n\r\nor something",
        "createdAt" : "2018-05-11T09:33:08Z",
        "updatedAt" : "2018-05-18T21:31:06Z",
        "lastEditedBy" : "d418e163-e0f8-4dec-9432-7f0eb6df2a1b",
        "tags" : [
        ]
      },
      {
        "id" : "03f24c3b-060f-4641-8b24-64b16ad0f114",
        "parentId" : "48bb277a-a41e-4c0c-b0a1-2226e22561b6",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "I don't see a lot of value in doing this unless we want to reuse the code, which we're not doing here.",
        "createdAt" : "2018-05-11T21:39:50Z",
        "updatedAt" : "2018-05-18T21:31:06Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "1f5d1796-8240-4143-ab53-eed1997fe51b",
        "parentId" : "48bb277a-a41e-4c0c-b0a1-2226e22561b6",
        "authorId" : "d418e163-e0f8-4dec-9432-7f0eb6df2a1b",
        "body" : "I usually find it easier to read short, focused test methods, but I see your point. You can ignore this comment then.",
        "createdAt" : "2018-05-17T16:07:12Z",
        "updatedAt" : "2018-05-18T21:31:06Z",
        "lastEditedBy" : "d418e163-e0f8-4dec-9432-7f0eb6df2a1b",
        "tags" : [
        ]
      },
      {
        "id" : "cede312b-f021-43c4-a75b-08965c1b50ab",
        "parentId" : "48bb277a-a41e-4c0c-b0a1-2226e22561b6",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I tend to agree with @asasvari for what it's worth. It is easier to understand and debug small test cases. It is not just about code reuse.",
        "createdAt" : "2018-05-17T18:16:49Z",
        "updatedAt" : "2018-05-18T21:31:06Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "47c37faba10b9efd117803ad709047ebd7aa3e55",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +1010,1014 @@        try {\n          consumerThread.start\n          // Test that we can list the new group.\n          TestUtils.waitUntilTrue(() => {\n            val matching = client.listConsumerGroups().all().get().asScala."
  },
  {
    "id" : "5fc2a2db-c59a-4412-b946-8df4d7a9ef7f",
    "prId" : 5133,
    "prUrl" : "https://github.com/apache/kafka/pull/5133#pullrequestreview-127003073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8ae9a77-188c-4a22-90d8-ccea8e4e764e",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "It seems that there is no guarantee that the offset 3 is in the middle of a message set?",
        "createdAt" : "2018-06-07T16:52:31Z",
        "updatedAt" : "2018-06-14T05:35:55Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "6380b7a3-1bb5-49d5-b260-b8ff025c8620",
        "parentId" : "f8ae9a77-188c-4a22-90d8-ccea8e4e764e",
        "authorId" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "body" : "Yes, this is an integration test, but at least those tests are failing without my change. I just moved handling of the `UnexpectedAppendOffsetException` with truncation + append to Partition, so that there is no duplicate code in `ReplicaFetcherThread` and `ReplicaAlterLogDirsThread`. I can do a test that guarantees that log start offset is in the middle of the batch, but unfortunately there is no unit test for Partition class. Will try to create it, but not that simple (lots of mocking). ",
        "createdAt" : "2018-06-08T00:52:34Z",
        "updatedAt" : "2018-06-14T05:35:55Z",
        "lastEditedBy" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "tags" : [
        ]
      }
    ],
    "commit" : "486f83e3422d512e3660225606caeb067a58b41f",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +837,841 @@    sendRecords(producers.head, 100, topicPartition)\n\n    val result = client.deleteRecords(Map(topicPartition -> RecordsToDelete.beforeOffset(3L)).asJava)\n    result.all().get()\n"
  },
  {
    "id" : "3008da48-5b29-4d17-a071-0f3787e411f8",
    "prId" : 6247,
    "prUrl" : "https://github.com/apache/kafka/pull/6247#pullrequestreview-205313067",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49fde534-6142-4bb1-9020-2f8fdda6ed7e",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Should we also add a test case against lost updates? e.g `a=1,b=2,c=3`, incremental config change - `a=4,b=5` and we ensure that `c=3` still",
        "createdAt" : "2019-02-18T14:15:11Z",
        "updatedAt" : "2019-04-13T16:04:28Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "c053a27f-557f-4087-a952-6d904f0a32c5",
        "parentId" : "49fde534-6142-4bb1-9020-2f8fdda6ed7e",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I think this can piggy-back on the `//verify config value substract` check",
        "createdAt" : "2019-02-18T14:17:27Z",
        "updatedAt" : "2019-04-13T16:04:28Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "23c25afb-ee25-408b-a97c-fb0b08aaf841",
        "parentId" : "49fde534-6142-4bb1-9020-2f8fdda6ed7e",
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "added a check to verify previous updates are intact.",
        "createdAt" : "2019-02-19T16:24:37Z",
        "updatedAt" : "2019-04-13T16:04:28Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf81f6c6e266fe058527609c60fb163035b70509",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +1501,1505 @@    assertFutureExceptionTypeEquals(alterResult.values().get(topic1Resource), classOf[InvalidRequestException],\n      Some(\"Invalid config value for resource\"))\n  }\n\n  @Test"
  },
  {
    "id" : "78d253c5-2aec-4adc-a440-57acde8369c3",
    "prId" : 6247,
    "prUrl" : "https://github.com/apache/kafka/pull/6247#pullrequestreview-205313279",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44c952c0-0c8b-45ae-9348-564caacdf6a2",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "So far we've only tested against IncrementalAlterConfig semantics. What do you think about adding a quick assert about an invalid property value to ensure those get validated as well?  This can be equivalent to the \r\n```java\r\n      new ConfigEntry(LogConfig.MinCleanableDirtyRatioProp, \"1.1\"), // this value is invalid as it's above 1.0\r\n```\r\ncheck made in `def checkInvalidAlterConfigs`",
        "createdAt" : "2019-02-18T14:25:14Z",
        "updatedAt" : "2019-04-13T16:04:28Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "70d7c53f-8f57-4d5c-b29d-b8f4bccc3c32",
        "parentId" : "44c952c0-0c8b-45ae-9348-564caacdf6a2",
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "updated the test",
        "createdAt" : "2019-02-19T16:25:01Z",
        "updatedAt" : "2019-04-13T16:04:28Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf81f6c6e266fe058527609c60fb163035b70509",
    "line" : 181,
    "diffHunk" : "@@ -1,1 +1584,1588 @@    assertFutureExceptionTypeEquals(alterResult.values().get(topic1Resource), classOf[InvalidRequestException],\n      Some(\"Invalid config value for resource\"))\n  }\n}\n"
  },
  {
    "id" : "5af9b339-b0b9-4ae0-9a7e-dc81f6e299b0",
    "prId" : 6258,
    "prUrl" : "https://github.com/apache/kafka/pull/6258#pullrequestreview-203427026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83995365-bd70-48b0-b787-9deab093996a",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "@tombentley after I fixed this, the test started failing. `return` was causing everything after this not to run. Can you please check what the issue is and fix it? cc @mjsax in case this is a regression and not a test problem.",
        "createdAt" : "2019-02-12T15:15:38Z",
        "updatedAt" : "2019-02-14T04:07:44Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "01c07d38-56ad-4ad4-a152-035a46536050",
        "parentId" : "83995365-bd70-48b0-b787-9deab093996a",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "@ijuma : Good find. These are indeed existing bugs. There are 4 references of LeaderNotAvailableException in line 1358, 1372, 1380 and 1390. They all need to be changed to PreferredLeaderNotAvailableException. Once I fixed those locally, the test passes.",
        "createdAt" : "2019-02-13T20:06:38Z",
        "updatedAt" : "2019-02-14T04:07:44Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "11832fe6-b52a-4aa5-bf5a-613dbf67ad7a",
        "parentId" : "83995365-bd70-48b0-b787-9deab093996a",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Thanks Jun! Will fix.",
        "createdAt" : "2019-02-13T20:19:19Z",
        "updatedAt" : "2019-02-14T04:07:44Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0d70daf55fabceeb379062c4641749466d771c5",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +1325,1329 @@      val isr = description.asScala.values.flatMap(_.partitions.asScala.flatMap(_.isr.asScala))\n      !isr.exists(_.id == 1)\n    }, \"Expect broker 1 to no longer be in any ISR\")\n\n    // ... now what happens if we try to elect the preferred leader and it's down?"
  }
]