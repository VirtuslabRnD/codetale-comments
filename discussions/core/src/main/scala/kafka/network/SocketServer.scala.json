[
  {
    "id" : "3bf6c771-522a-43cc-81dc-3ce9c958f66c",
    "prId" : 4471,
    "prUrl" : "https://github.com/apache/kafka/pull/4471#pullrequestreview-92406826",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15928730-8780-4925-931d-d199a6109934",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm not really sure it's worth it, but I guess `processors` could be a concurrent map to avoid holding the lock when we just need to access the collection.",
        "createdAt" : "2018-01-29T19:03:26Z",
        "updatedAt" : "2018-01-30T15:24:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "2a6eaf7c-0b6f-448b-a08c-04c2d02ca2ed",
        "parentId" : "15928730-8780-4925-931d-d199a6109934",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I left this synchronization in there since this is only for new connections.",
        "createdAt" : "2018-01-30T00:27:38Z",
        "updatedAt" : "2018-01-30T15:24:51Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c25c58922801e023bc1fe56919dfbab7f4565f5",
    "line" : 196,
    "diffHunk" : "@@ -1,1 +332,336 @@                iter.remove()\n                if (key.isAcceptable) {\n                  val processor = synchronized {\n                    currentProcessor = currentProcessor % processors.size\n                    processors(currentProcessor)"
  },
  {
    "id" : "579b83c8-ed39-4baf-8bca-4e14a731a6fe",
    "prId" : 4471,
    "prUrl" : "https://github.com/apache/kafka/pull/4471#pullrequestreview-92406477",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf95883c-83e7-49ed-853f-beac1083c83f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do we need to reset `nextProcessorId`, or is the intent to always assign new processors with an id which hasn't been used before?",
        "createdAt" : "2018-01-29T19:09:28Z",
        "updatedAt" : "2018-01-30T15:24:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "234976a5-bad0-4871-8495-22795d40451b",
        "parentId" : "cf95883c-83e7-49ed-853f-beac1083c83f",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "Thought it was better not to reuse processor ids, hence the `Map` of processors.",
        "createdAt" : "2018-01-30T00:25:51Z",
        "updatedAt" : "2018-01-30T15:24:51Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c25c58922801e023bc1fe56919dfbab7f4565f5",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +303,307 @@  }\n\n  private[network] def removeProcessors(removeCount: Int, requestChannel: RequestChannel): Unit = synchronized {\n    // Shutdown `removeCount` processors. Remove them from the processor list first so that no more\n    // connections are assigned. Shutdown the removed processors, closing the selector and its connections."
  },
  {
    "id" : "b3472025-9a07-4df0-8ba1-efed625f2c26",
    "prId" : 4488,
    "prUrl" : "https://github.com/apache/kafka/pull/4488#pullrequestreview-93722756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31467e79-bc5a-4bd4-860f-a512385b8353",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Add log line her and in `removeListeners`?",
        "createdAt" : "2018-02-02T22:22:32Z",
        "updatedAt" : "2018-02-04T02:11:57Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0488d78e0ea02c3ddde1a31f6c1e0613a443e3d",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +193,197 @@  }\n\n  def addListeners(listenersAdded: Seq[EndPoint]): Unit = synchronized {\n    info(s\"Adding listeners for endpoints $listenersAdded\")\n    createProcessors(config.numNetworkThreads, listenersAdded)"
  },
  {
    "id" : "98c870ca-fec8-44bf-a787-19b5d66bd494",
    "prId" : 4542,
    "prUrl" : "https://github.com/apache/kafka/pull/4542#pullrequestreview-95213874",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53c8a3a5-d2ed-4e16-89fe-bca0640dbfb1",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Doesn't this change the full metric name?",
        "createdAt" : "2018-02-08T19:42:30Z",
        "updatedAt" : "2018-02-08T19:42:45Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "fdb7d744-3888-488d-ae76-7a5d55cbb6b6",
        "parentId" : "53c8a3a5-d2ed-4e16-89fe-bca0640dbfb1",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, you are right. I forgot about the type attribute. @rajinisivaram Maybe you can fix it in #4539?",
        "createdAt" : "2018-02-08T19:56:52Z",
        "updatedAt" : "2018-02-08T19:56:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a36486a7-ef63-467f-b3f2-80a3f5f76da6",
        "parentId" : "53c8a3a5-d2ed-4e16-89fe-bca0640dbfb1",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "@hachikuji I had forgotten too. Yes, I will update in #4539",
        "createdAt" : "2018-02-08T20:02:28Z",
        "updatedAt" : "2018-02-08T20:02:28Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "e82524c88b3b3e0fb771bcb92f096fe8890b61b7",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +476,480 @@  ).asJava\n\n  newGauge(\"ResponseQueueSize\",\n    new Gauge[Int] {\n      def value = responseQueue.size()"
  },
  {
    "id" : "43b2341e-f19f-4736-987b-9800985bc91b",
    "prId" : 4867,
    "prUrl" : "https://github.com/apache/kafka/pull/4867#pullrequestreview-112329517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a884dc3d-1af4-4f79-98ac-de6002ba0537",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "This is not directly related to this patch. However, it seems that we need some synchronization on processor between the reader and the writer?",
        "createdAt" : "2018-04-13T21:47:58Z",
        "updatedAt" : "2018-04-16T13:58:03Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "274274ac-de66-4767-bc34-9a8f3edf453a",
        "parentId" : "a884dc3d-1af4-4f79-98ac-de6002ba0537",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "@junrao Thanks for the review. We were already synchronizing on all read/write accesses to `processors` apart from `shutdown()`. I think that was safe anyway, but I have added synchronize in shutdown as well to be consistent.",
        "createdAt" : "2018-04-16T08:59:50Z",
        "updatedAt" : "2018-04-16T13:58:03Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "d881674db8abb655be89fd0d126c34c99cf8d2fd",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +334,338 @@\n  private[network] def addProcessors(newProcessors: Buffer[Processor]): Unit = synchronized {\n    processors ++= newProcessors\n    if (processorsStarted.get)\n      startProcessors(newProcessors)"
  },
  {
    "id" : "3de31528-d0f6-47a8-8030-2364de9ac15d",
    "prId" : 5921,
    "prUrl" : "https://github.com/apache/kafka/pull/5921#pullrequestreview-181372959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20516e1c-e222-4911-aae9-bdb76b8f9932",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Could we change the comment above SocketServer and a few other places accordingly?",
        "createdAt" : "2018-11-30T23:15:00Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "b7a563f3-41af-4e02-a9c2-ffd814c8f352",
        "parentId" : "20516e1c-e222-4911-aae9-bdb76b8f9932",
        "authorId" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "body" : "Agreed.",
        "createdAt" : "2018-12-04T17:05:16Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "tags" : [
        ]
      }
    ],
    "commit" : "c40a575b7d984205ae4a8ac4b0584b9731566090",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +71,75 @@class SocketServer(val config: KafkaConfig, val metrics: Metrics, val time: Time, val credentialProvider: CredentialProvider) extends Logging with KafkaMetricsGroup {\n\n  val DataPlanePrefix = \"data-plane\"\n  val ControlPlanePrefix = \"control-plane\"\n"
  },
  {
    "id" : "734e515f-c9a4-4874-9f5c-cd1169ddc93a",
    "prId" : 5921,
    "prUrl" : "https://github.com/apache/kafka/pull/5921#pullrequestreview-181426533",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c56b8f5-7247-40e6-9756-5956719b9070",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Should we include expired connections from the control plane processor too?",
        "createdAt" : "2018-12-04T00:22:38Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "5c10bf20-a1b2-49e1-912d-6f1a5af40f5d",
        "parentId" : "9c56b8f5-7247-40e6-9756-5956719b9070",
        "authorId" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "body" : "Agreed. Will add \"ControlPlaneExpiredConnectionsKilledCount\". I wanted to check if we can change the existing metric to \"DataPlaneExpiredConnectionsKilledCount\". \r\nIf we agree as per the pros and cons listed above for request/response queue size metric naming, I will update the KIP or revert this change, accordingly.",
        "createdAt" : "2018-12-04T19:02:43Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "tags" : [
        ]
      }
    ],
    "commit" : "c40a575b7d984205ae4a8ac4b0584b9731566090",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +160,164 @@\n        def value = SocketServer.this.synchronized {\n          val expiredConnectionsKilledCountMetricNames = dataPlaneProcessors.values.asScala.map { p =>\n            metrics.metricName(\"expired-connections-killed-count\", \"socket-server-metrics\", p.metricTags)\n          }"
  },
  {
    "id" : "e181bf52-ab12-492f-b346-0cee34edab86",
    "prId" : 5921,
    "prUrl" : "https://github.com/apache/kafka/pull/5921#pullrequestreview-185883995",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01899242-ec12-4b87-a80e-0d5c6b99bba0",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "It seems that listenerProcessors can be local to the foreach clause below?",
        "createdAt" : "2018-12-14T18:10:01Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "650b09b6-56a1-43de-b6ed-66a7d3099fa4",
        "parentId" : "01899242-ec12-4b87-a80e-0d5c6b99bba0",
        "authorId" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "body" : "Agreed.",
        "createdAt" : "2018-12-18T02:24:07Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "tags" : [
        ]
      }
    ],
    "commit" : "c40a575b7d984205ae4a8ac4b0584b9731566090",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +229,233 @@      controlPlaneAcceptorOpt = Some(controlPlaneAcceptor)\n      controlPlaneProcessorOpt = Some(controlPlaneProcessor)\n      val listenerProcessors = new ArrayBuffer[Processor]()\n      listenerProcessors += controlPlaneProcessor\n      controlPlaneRequestChannelOpt.foreach(_.addProcessor(controlPlaneProcessor))"
  }
]