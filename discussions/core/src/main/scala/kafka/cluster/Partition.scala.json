[
  {
    "id" : "a547f512-e82e-485d-9b91-0c31e441e23a",
    "prId" : 5436,
    "prUrl" : "https://github.com/apache/kafka/pull/5436#pullrequestreview-144051029",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a44a69a3-475e-411d-9152-a0a8c114cf4a",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I wonder if we can elaborate on this a little bit. I think the main point is that if we have somehow missed a leader epoch, then we have also missed a required truncation.",
        "createdAt" : "2018-08-07T15:32:43Z",
        "updatedAt" : "2018-08-10T19:00:12Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "a96fb4cd18c4eb347abb75ecc132a0558c1addc2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +347,351 @@      zkVersion = partitionStateInfo.basePartitionState.zkVersion\n\n      // If the leader is unchanged and the epochs are no more than one change apart, indicate that no follower changes are required\n      // Otherwise, we missed a leader epoch update, which means the leader's log may have been truncated prior to the current epoch.\n      if (leaderReplicaIdOpt.contains(newLeaderBrokerId) && (leaderEpoch == oldLeaderEpoch || leaderEpoch == oldLeaderEpoch + 1)) {"
  },
  {
    "id" : "99e51044-4d51-4f36-9aff-7d13b6bb8b5d",
    "prId" : 5557,
    "prUrl" : "https://github.com/apache/kafka/pull/5557#pullrequestreview-150236471",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "872535fc-b063-49db-afb0-d4a5a567b269",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Is this fixing a bug in the original code with the use of `getReplica` prior to replica creation? But presumably, that would have actually caused some failure because of the call `get`?",
        "createdAt" : "2018-08-28T15:54:40Z",
        "updatedAt" : "2018-08-28T15:59:19Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b7414d3d-fd24-4c92-b214-890ff8778462",
        "parentId" : "872535fc-b063-49db-afb0-d4a5a567b269",
        "authorId" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "body" : "I moved this up because it seems safer. The code above also calls `getOrCreateReplica` for all replicas in ISR. I am not sure if we can get LeaderAndIsr for new partition where there are no replicas in ISR (in leaderAndIsr request) -- probably not? So, probably there is no bug in the original code, but still seems safer to call `createOrGetReplica` earlier, before trying to use any Replica object.",
        "createdAt" : "2018-08-28T17:35:57Z",
        "updatedAt" : "2018-08-28T17:35:57Z",
        "lastEditedBy" : "e235ea82-83a9-41e5-8e3a-15b2e1b6f350",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc027ec8fc4468d3b552ba45be3b9c1c501cd0d8",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +292,296 @@      (assignedReplicas.map(_.brokerId) -- newAssignedReplicas).foreach(removeReplica)\n      inSyncReplicas = newInSyncReplicas\n      newAssignedReplicas.foreach(id => getOrCreateReplica(id, partitionStateInfo.isNew))\n\n      val leaderReplica = getReplica().get"
  },
  {
    "id" : "2b5b1a50-543d-41d3-a9c2-73749dc1cce6",
    "prId" : 5661,
    "prUrl" : "https://github.com/apache/kafka/pull/5661#pullrequestreview-160516687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bde2abf2-d500-4968-8ad6-a74b58a05ac3",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since currentLeaderEpoch is not present, do we need to hold the leaderIsrUpdateLock here?",
        "createdAt" : "2018-09-28T19:12:12Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "cd4c4509-6bdd-47cd-9a4b-dc7362c0dfaf",
        "parentId" : "bde2abf2-d500-4968-8ad6-a74b58a05ac3",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I had thought we may as well protect `fetchOnlyFromLeader` behavior. Do you think it is not worthwhile?",
        "createdAt" : "2018-10-01T21:58:06Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "70640662-0079-494c-87ef-801c96e32463",
        "parentId" : "bde2abf2-d500-4968-8ad6-a74b58a05ac3",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Ah, ok. Then, we can leave it as it is.",
        "createdAt" : "2018-10-01T22:58:21Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9bc468a7415831841a1203315789e683066dad4",
    "line" : 392,
    "diffHunk" : "@@ -1,1 +846,850 @@                                     maxNumOffsets: Int,\n                                     isFromConsumer: Boolean,\n                                     fetchOnlyFromLeader: Boolean): Seq[Long] = inReadLock(leaderIsrUpdateLock) {\n    val localReplica = localReplicaWithEpochOrException(Optional.empty(), fetchOnlyFromLeader)\n    val allOffsets = logManager.getLog(topicPartition) match {"
  },
  {
    "id" : "febfdd47-adbc-4ff4-8291-3c98771f3254",
    "prId" : 5661,
    "prUrl" : "https://github.com/apache/kafka/pull/5661#pullrequestreview-159982255",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "129922ec-4adf-419a-b17c-d9a2d3e1a3ab",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Could we add the new params to the javadoc?",
        "createdAt" : "2018-09-28T20:42:07Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9bc468a7415831841a1203315789e683066dad4",
    "line" : 482,
    "diffHunk" : "@@ -1,1 +946,950 @@   */\n  def lastOffsetForLeaderEpoch(currentLeaderEpoch: Optional[Integer],\n                               leaderEpoch: Int,\n                               fetchOnlyFromLeader: Boolean): EpochEndOffset = {\n    inReadLock(leaderIsrUpdateLock) {"
  },
  {
    "id" : "164fa80c-02e6-44ad-b37c-9153fb24f4fa",
    "prId" : 5866,
    "prUrl" : "https://github.com/apache/kafka/pull/5866#pullrequestreview-342209506",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bd900f1-e3e0-44cf-8900-13be753bdcbc",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Not a major issue, but since `needsShrinkIsr` is exposed, maybe we can move the lock acquire to it?",
        "createdAt" : "2020-01-13T21:54:18Z",
        "updatedAt" : "2020-01-13T23:27:59Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "e72f6b77-9ea0-4efa-9199-f495d5e8584d",
        "parentId" : "1bd900f1-e3e0-44cf-8900-13be753bdcbc",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "Actually `needsShrinkIsr` can be private, updated. Left the lock in here to be consistent with `needsExpandIsr`.",
        "createdAt" : "2020-01-13T23:31:35Z",
        "updatedAt" : "2020-01-13T23:31:36Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "a6e56086a2eb5d11a1e8eee59d1a7aa88d0af5ce",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +835,839 @@\n  def maybeShrinkIsr(): Unit = {\n    val needsIsrUpdate = inReadLock(leaderIsrUpdateLock) {\n      needsShrinkIsr()\n    }"
  },
  {
    "id" : "79fe17d1-6045-4bb4-8fc0-8dc83b3b2de0",
    "prId" : 6256,
    "prUrl" : "https://github.com/apache/kafka/pull/6256#pullrequestreview-204911168",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f69b05a7-a764-4095-bf1c-e243723fb674",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: unneeded import",
        "createdAt" : "2019-02-18T18:20:06Z",
        "updatedAt" : "2019-02-20T01:22:38Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "69581d42d22c6fd9b5dcfecaefe9d3076b9b15ad",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +21,25 @@\nimport com.yammer.metrics.core.Gauge\nimport kafka.api.{ApiVersion, LeaderAndIsr, Request}\nimport kafka.common.UnexpectedAppendOffsetException\nimport kafka.controller.KafkaController"
  },
  {
    "id" : "40fb409b-5d48-4a41-bd3c-b9cf6cd73c73",
    "prId" : 6705,
    "prUrl" : "https://github.com/apache/kafka/pull/6705#pullrequestreview-235943245",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b27ed6e2-b190-4612-9ce6-6fcddd414b45",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Java doc for `highWatermarkCheckpoints`",
        "createdAt" : "2019-05-10T06:30:16Z",
        "updatedAt" : "2019-05-22T21:10:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "46365108de264bfa9552bc671e6817e1158cab24",
    "line" : 289,
    "diffHunk" : "@@ -1,1 +282,286 @@    * @return true iff the future replica is created\n    */\n  def maybeCreateFutureReplica(logDir: String, highWatermarkCheckpoints: OffsetCheckpoints): Boolean = {\n    // The writeLock is needed to make sure that while the caller checks the log directory of the\n    // current replica and the existence of the future replica, no other thread can update the log directory of the"
  },
  {
    "id" : "81c7b097-78dd-4b26-a8d3-7d6423a17635",
    "prId" : 6814,
    "prUrl" : "https://github.com/apache/kafka/pull/6814#pullrequestreview-244595374",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72e52d2c-c1d7-45b6-b2c3-99b8975a4114",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: no need `()`.",
        "createdAt" : "2019-05-31T22:00:33Z",
        "updatedAt" : "2019-06-01T17:35:35Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "27dca696-449f-4e6f-bc7b-aa36508f38d0",
        "parentId" : "72e52d2c-c1d7-45b6-b2c3-99b8975a4114",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I guess we're inconsistent about this. Does `time.milliseconds()` have a side effect? I guess not because time moves whether or not you invoke `milliseconds()`. But another way to view it is that time doesn't move until you call `milliseconds()`, so the movement of time is the side effect. Viewing it that way accounts for `autoTickMs` in `MockTime`. ",
        "createdAt" : "2019-06-01T17:35:42Z",
        "updatedAt" : "2019-06-01T17:35:43Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fafdae4c452e5581bfa94f675b332da64741d4ac",
    "line" : 213,
    "diffHunk" : "@@ -1,1 +830,834 @@     **/\n    val candidateReplicas = inSyncReplicas - leaderReplica\n    val currentTimeMs = time.milliseconds()\n    val leaderEndOffset = leaderReplica.logEndOffset\n    candidateReplicas.filter(r => isFollowerOutOfSync(r, leaderEndOffset, currentTimeMs, maxLagMs))"
  },
  {
    "id" : "65b8e3dc-f6c8-450e-951c-a51614330d81",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-248434383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e8960ac-91a3-4fe2-9c23-cf1d0b02ba92",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Should this be possible? If this condition happens does it mean a bug in Kafka?",
        "createdAt" : "2019-06-07T21:12:42Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "7c285d05-1c63-4f7b-859a-c3485a62b788",
        "parentId" : "6e8960ac-91a3-4fe2-9c23-cf1d0b02ba92",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Not sure about this. This is original code so don't know the history, but is it possible that this method can get called before \"log\" is initialized?",
        "createdAt" : "2019-06-10T16:32:26Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      },
      {
        "id" : "957720dd-b853-489e-8130-33f0b94b99b7",
        "parentId" : "6e8960ac-91a3-4fe2-9c23-cf1d0b02ba92",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I _think_ it shouldn't be possible to have a `Partition` without a corresponding `Log`. Once this is merged, I think we can look into whether we can replace the optional log field in this class with a concrete instance. ",
        "createdAt" : "2019-06-11T18:52:13Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "4571c179-8d3a-4dbb-9700-2f8c1a7ac9e0",
        "parentId" : "6e8960ac-91a3-4fe2-9c23-cf1d0b02ba92",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Filed https://issues.apache.org/jira/browse/KAFKA-8525 to track this and removal of LocalReplica task.",
        "createdAt" : "2019-06-11T20:58:17Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 255,
    "diffHunk" : "@@ -1,1 +377,381 @@                Right(Errors.NOT_LEADER_FOR_PARTITION)\n              else\n                Right(Errors.REPLICA_NOT_AVAILABLE)\n          }\n        }"
  },
  {
    "id" : "40da0efb-e548-4725-9a50-7e2439a8f9a2",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-247715625",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a96c6819-4881-450b-9a1f-0671126cd469",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "nit: or `log.filter(_ => isLeader)`.",
        "createdAt" : "2019-06-07T21:18:21Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "441238c8-fda4-484f-be7d-11c14f5f868e",
        "parentId" : "a96c6819-4881-450b-9a1f-0671126cd469",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Thanks. I was wondering how I can simplify this. Done.",
        "createdAt" : "2019-06-10T16:37:25Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 286,
    "diffHunk" : "@@ -1,1 +395,399 @@  }\n\n  def leaderLogIfLocal: Option[Log] = {\n    log.filter(_ => isLeader)\n  }"
  },
  {
    "id" : "4e7f26ed-8190-4eba-bddb-ed5996483f36",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-248439619",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1d65ccc-bb1b-434c-b4ab-b62077459adc",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Not from this PR, but the exception message below seems to be missing the word \"log\" after \"Failed to find\".",
        "createdAt" : "2019-06-11T18:59:58Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "1683f282-ce41-44e5-aeb4-d06608979388",
        "parentId" : "a1d65ccc-bb1b-434c-b4ab-b62077459adc",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Done.",
        "createdAt" : "2019-06-11T21:09:32Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 302,
    "diffHunk" : "@@ -1,1 +407,411 @@                                           requireLeader: Boolean): Log = {\n    getLocalLog(currentLeaderEpoch, requireLeader) match {\n      case Left(localLog) => localLog\n      case Right(error) =>\n        throw error.exception(s\"Failed to find ${if (requireLeader) \"leader \" else \"\"} log for \" +"
  },
  {
    "id" : "5aac2a60-51ba-48ff-ae91-1b2c7514e482",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-250083689",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae244411-9e8e-4251-9c4f-147581a32f9e",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Feels like we should be closing the log here. Maybe only if `deleteFromLogDir` is true?",
        "createdAt" : "2019-06-14T02:01:45Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "01afdb33-7118-4fbc-9b04-aa9ada676928",
        "parentId" : "ae244411-9e8e-4251-9c4f-147581a32f9e",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "I think there is a leak. The log is closed for successful alter log dirs case, but I can't find a close for two other cases where this method is invoked. \r\n\r\nLets discuss this as some of this code goes in offline/online partition case. Maybe we don't have to close logs in those cases.",
        "createdAt" : "2019-06-14T17:41:20Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      },
      {
        "id" : "109c5fd5-66f4-4b1d-ad6b-0a761963b012",
        "parentId" : "ae244411-9e8e-4251-9c4f-147581a32f9e",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ok, let's look into this separately since there's no regression in behavior.",
        "createdAt" : "2019-06-14T18:06:42Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "d89f531c-2e42-42ce-b81c-d571dc7f0ed8",
        "parentId" : "ae244411-9e8e-4251-9c4f-147581a32f9e",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "OK, I will create a separate JIRA with follow up comments from this PR.",
        "createdAt" : "2019-06-14T19:28:20Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 359,
    "diffHunk" : "@@ -1,1 +446,450 @@  def removeFutureLocalReplica(deleteFromLogDir: Boolean = true) {\n    inWriteLock(leaderIsrUpdateLock) {\n      futureLog = None\n      if (deleteFromLogDir)\n        logManager.asyncDelete(topicPartition, isFuture = true)"
  },
  {
    "id" : "76fa3201-0927-4729-af7e-1c9284909e9a",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-250083585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80191925-08ed-439e-8baf-0de66c85db6b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Similar to above. Do we need to close?",
        "createdAt" : "2019-06-14T02:06:12Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "3fa8b641-2d5c-469a-8086-5f4b019f5075",
        "parentId" : "80191925-08ed-439e-8baf-0de66c85db6b",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The answer may be no. It looks like `LogManager` is responsible for closing",
        "createdAt" : "2019-06-14T07:33:26Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "40c3f530-6068-4d3d-8416-b3f0828a090f",
        "parentId" : "80191925-08ed-439e-8baf-0de66c85db6b",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "LogManager seems logical place to do it, but can't find where it does that. Log.close() is only invoked by LogManager.shutdown() and alterReplica case. Maybe something I am missing, as this is very basic log lifycycle managment.",
        "createdAt" : "2019-06-14T17:44:18Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      },
      {
        "id" : "90d8536a-181c-4549-8822-dbcd099da1da",
        "parentId" : "80191925-08ed-439e-8baf-0de66c85db6b",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Will create a separate JIRA with follow up comments from this PR.",
        "createdAt" : "2019-06-14T19:28:04Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 407,
    "diffHunk" : "@@ -1,1 +486,490 @@      remoteReplicasMap.clear()\n      allReplicaIds = scala.collection.mutable.Set(localBrokerId)\n      log = None\n      futureLog = None\n      inSyncReplicas = Set.empty[Int]"
  },
  {
    "id" : "0e4874ef-968a-4982-9495-20230cc7b39b",
    "prId" : 6841,
    "prUrl" : "https://github.com/apache/kafka/pull/6841#pullrequestreview-250083258",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3787516f-532f-46d3-9c86-d13c3ac8e332",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Not something for this patch, but I find it puzzling that we include the future replica in the determination of the low watermark. I would think we'd always be able to ensure the log start offset gets updated correctly at the time that we swap it in.",
        "createdAt" : "2019-06-14T06:30:02Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "2be9932e-1065-413a-9a02-05cd3cb32b25",
        "parentId" : "3787516f-532f-46d3-9c86-d13c3ac8e332",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "Agree. Maybe we fix it as part of KAFKA-8001",
        "createdAt" : "2019-06-14T18:04:23Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      },
      {
        "id" : "6d20d4e2-d651-4c82-9229-7536a74d9149",
        "parentId" : "3787516f-532f-46d3-9c86-d13c3ac8e332",
        "authorId" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "body" : "As discussed going to create a JIRA to track all \"future\" work comments from this PR.",
        "createdAt" : "2019-06-14T19:27:16Z",
        "updatedAt" : "2019-06-14T23:20:28Z",
        "lastEditedBy" : "e61d770a-e328-41b4-b8c3-6a769370680c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6524debfbc275fe7f58c41b87c3daeb3f4c0aa6",
    "line" : 626,
    "diffHunk" : "@@ -1,1 +802,806 @@    futureLog match {\n      case Some(partitionFutureLog) =>\n        CoreUtils.min(logStartOffsets + partitionFutureLog.logStartOffset, 0L)\n      case None =>\n        CoreUtils.min(logStartOffsets, 0L)"
  },
  {
    "id" : "59e26307-4ef1-41dd-9852-80c931d2480f",
    "prId" : 7010,
    "prUrl" : "https://github.com/apache/kafka/pull/7010#pullrequestreview-256587520",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6cebb97-78a4-417b-81e1-cb3a7dc021b8",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: we are a little inconsistent with naming. Should we change `inSyncReplicas` to `inSyncReplicaIds`?",
        "createdAt" : "2019-07-01T20:37:33Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "d153b279-eed6-46c0-a7b0-0c4af768c48a",
        "parentId" : "a6cebb97-78a4-417b-81e1-cb3a7dc021b8",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Done.",
        "createdAt" : "2019-07-01T22:18:46Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0525bee8511ea175929ab5de8be76d5d8f24a8c",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +180,184 @@  @volatile var inSyncReplicaIds = Set.empty[Int]\n  // An ordered sequence of all the valid broker ids that were assigned to this topic partition\n  @volatile var allReplicaIds = Seq.empty[Int]\n\n  // Logs belonging to this partition. Majority of time it will be only one log, but if log directory"
  },
  {
    "id" : "f74ae0d8-79c8-433a-b29a-e4826afe5310",
    "prId" : 7010,
    "prUrl" : "https://github.com/apache/kafka/pull/7010#pullrequestreview-257103033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22c07a8a-daa5-449d-a374-5c95c892321f",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Did you mean to remove this `val` as well?",
        "createdAt" : "2019-07-02T17:36:09Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "79c47815-2fd7-4ec0-ae3d-1edce1b87ec0",
        "parentId" : "22c07a8a-daa5-449d-a374-5c95c892321f",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "This one is needed. Having a `val` in the type constructor generates a read-only method: `def topicPartition: TopicPartition`. This property (read-only method) is needed by other clients to this type.",
        "createdAt" : "2019-07-02T19:30:17Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0525bee8511ea175929ab5de8be76d5d8f24a8c",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +156,160 @@ * Data structure that represents a topic partition. The leader maintains the AR, ISR, CUR, RAR\n */\nclass Partition(val topicPartition: TopicPartition,\n                replicaLagTimeMaxMs: Long,\n                interBrokerProtocolVersion: ApiVersion,"
  },
  {
    "id" : "1a222633-5c4b-497a-9960-c5c6c4fb5a4a",
    "prId" : 7010,
    "prUrl" : "https://github.com/apache/kafka/pull/7010#pullrequestreview-257108955",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3531419-5479-4555-8156-794f473a50ce",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "I'm guessing this the crux of the change? Maybe we should include a comment about order preservation here.",
        "createdAt" : "2019-07-02T17:42:07Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "58f931a4-32d2-480e-add2-2c75826059d0",
        "parentId" : "f3531419-5479-4555-8156-794f473a50ce",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yes. I'll update the comment.",
        "createdAt" : "2019-07-02T19:30:41Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "db342501-eb11-4484-91e4-80446ef67f13",
        "parentId" : "f3531419-5479-4555-8156-794f473a50ce",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Done.",
        "createdAt" : "2019-07-02T19:40:44Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0525bee8511ea175929ab5de8be76d5d8f24a8c",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +180,184 @@  @volatile var inSyncReplicaIds = Set.empty[Int]\n  // An ordered sequence of all the valid broker ids that were assigned to this topic partition\n  @volatile var allReplicaIds = Seq.empty[Int]\n\n  // Logs belonging to this partition. Majority of time it will be only one log, but if log directory"
  },
  {
    "id" : "f99c08b6-6f98-420a-bf22-5dc7764ef4b3",
    "prId" : 7010,
    "prUrl" : "https://github.com/apache/kafka/pull/7010#pullrequestreview-257109285",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01836520-8e59-40bd-90f4-47e342be1b79",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Same as above, since it's rather subtle, maybe we should mention that we convert the List from PartitionState to a Seq to preserve the order",
        "createdAt" : "2019-07-02T17:45:41Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "45642d3f-37b2-427a-831f-7d6b8b6ab1f9",
        "parentId" : "01836520-8e59-40bd-90f4-47e342be1b79",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I added a comment to the `updateAssignmentAndIsr` method. Let me know if that address your concern.",
        "createdAt" : "2019-07-02T19:41:24Z",
        "updatedAt" : "2019-07-02T21:26:41Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0525bee8511ea175929ab5de8be76d5d8f24a8c",
    "line" : 159,
    "diffHunk" : "@@ -1,1 +487,491 @@\n      updateAssignmentAndIsr(\n        assignment = partitionStateInfo.basePartitionState.replicas.asScala.iterator.map(_.toInt).toSeq,\n        isr = partitionStateInfo.basePartitionState.isr.asScala.iterator.map(_.toInt).toSet\n      )"
  },
  {
    "id" : "c6c607ee-3ffb-45c7-94ca-99c8b9527458",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/kafka/pull/7324#pullrequestreview-288000023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5500ee7a-e2be-49d0-80ff-a2fbc66975ab",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Should we mention that this method is used in the hot path?",
        "createdAt" : "2019-09-13T13:00:35Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d75d5473b70c633125b47e742de785fa792feacb",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +406,410 @@\n  // remoteReplicas will be called in the hot path, and must be inexpensive\n  def remoteReplicas: Iterable[Replica] =\n    remoteReplicasMap.values\n"
  },
  {
    "id" : "806f941e-2a30-496c-8df0-c369f37831d9",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/kafka/pull/7324#pullrequestreview-288000023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2705ed1-ccb4-44b6-bea7-8c708380a432",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "If you want this code to remain this way, you probably need to add some perf related comment (like you did for the other part).",
        "createdAt" : "2019-09-13T13:03:11Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d75d5473b70c633125b47e742de785fa792feacb",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +802,806 @@        lowWaterMark = replica.logStartOffset\n      }\n    }\n\n    futureLog match {"
  },
  {
    "id" : "ca9a0bf4-4ba5-4503-830c-206f39b09871",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/kafka/pull/7324#pullrequestreview-288259976",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85cd85b0-55bf-493f-9e06-dfc246f68f81",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Leaving this here for lack of an alternative. I think for low-volume topics, we are actually hitting this logic even when the fetch offset hasn't changed. But if the fetch offset hasn't changed, then there should be no need to expand the ISR or to increment the high watermark. So what I was thinking is that `Replica.updateFetchState` could return a flag indicating whether or not the follower's end offset has changed. If it hasn't, we skip the ISR expansion check. What do you think?",
        "createdAt" : "2019-09-13T21:27:51Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "d75d5473b70c633125b47e742de785fa792feacb",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +753,757 @@   * since all callers of this private API acquire that lock\n   */\n  private def maybeIncrementLeaderHW(leaderLog: Log, curTime: Long = time.milliseconds): Boolean = {\n    inReadLock(leaderIsrUpdateLock) {\n      // maybeIncrementLeaderHW is in the hot path, the following code is written to"
  },
  {
    "id" : "bc8b0bb9-3d32-44ab-95f7-5428d05c2fe3",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/kafka/pull/7324#pullrequestreview-288954216",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e38ec22a-1abd-4a5f-aa1e-5d66ae3ae931",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We were previously incrementing the hw atomically with the isr expansion. Have we verified that it's ok to change that?",
        "createdAt" : "2019-09-14T03:09:30Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "8cae9e1f-90be-4dd3-b3df-c56d15352c60",
        "parentId" : "e38ec22a-1abd-4a5f-aa1e-5d66ae3ae931",
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "Hmm, I will look into that. The second problem is that we should probably be taking out a lock in maybeIncrementLeaderHW even if the update does not need to be atomic.",
        "createdAt" : "2019-09-14T05:44:07Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      },
      {
        "id" : "8fc4450e-3968-484b-a522-698860778426",
        "parentId" : "e38ec22a-1abd-4a5f-aa1e-5d66ae3ae931",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I was thinking about this too. We probably need to grab the read side of the `leaderIsrUpdateLock` in `maybeIncrementLeaderHw` to protect from a concurrent ISR change. The second thing is that `Log.maybeIncrementHighWatermark` probably needs to be holding the lock when checking for monotonicity. Currently it only grabs the lock when actually updating the value.",
        "createdAt" : "2019-09-14T10:00:41Z",
        "updatedAt" : "2019-09-16T22:50:37Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0387fa3b-5118-4fdd-8572-a4e837d20197",
        "parentId" : "e38ec22a-1abd-4a5f-aa1e-5d66ae3ae931",
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "@hachikuji the changes you suggested seem good to me. Let me know what you think and whether you think I've implemented the locking at the right granularity.",
        "createdAt" : "2019-09-16T23:37:28Z",
        "updatedAt" : "2019-09-16T23:37:29Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      }
    ],
    "commit" : "d75d5473b70c633125b47e742de785fa792feacb",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +611,615 @@        // since the replica may already be in the ISR and its LEO has just incremented\n        val leaderHWIncremented = if (prevFollowerEndOffset != followerReplica.logEndOffset) {\n          leaderLogIfLocal.exists(leaderLog => maybeIncrementLeaderHW(leaderLog, followerFetchTimeMs))\n        } else {\n          false"
  },
  {
    "id" : "fabf8fcc-8310-4791-98b8-e872276aeda7",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/kafka/pull/7324#pullrequestreview-290160456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1d844f9-b54e-4af5-aa9c-1c59fe540ad7",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "So, it seems that we fixed a bug here? Taking a min with 0 seems wrong. If so, we probably want to reflect that in the jira.",
        "createdAt" : "2019-09-18T18:07:15Z",
        "updatedAt" : "2019-09-18T18:07:38Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "a628c7b1-6a76-4a74-b5ac-6b3fc326ec80",
        "parentId" : "f1d844f9-b54e-4af5-aa9c-1c59fe540ad7",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "@junrao the second parameter for `min` is actually the default if the collection is empty. We should probably rename it to `seqMinOrDefault` to avoid such confusion in the future.",
        "createdAt" : "2019-09-18T19:49:12Z",
        "updatedAt" : "2019-09-18T19:49:12Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d75d5473b70c633125b47e742de785fa792feacb",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +806,810 @@    futureLog match {\n      case Some(partitionFutureLog) =>\n        Math.min(lowWaterMark, partitionFutureLog.logStartOffset)\n      case None =>\n        lowWaterMark"
  },
  {
    "id" : "f1884d8e-6fcf-446f-9f5d-aa9d72f33cdf",
    "prId" : 7361,
    "prUrl" : "https://github.com/apache/kafka/pull/7361#pullrequestreview-298266179",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "492548b9-54cd-4adf-8fe0-a4ac58a8f1d0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This is a non-exhaustive match, no?",
        "createdAt" : "2019-10-07T16:47:09Z",
        "updatedAt" : "2019-10-18T00:16:40Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ade9d03bf3fff7f6fe5665fac8c0c7e622489dfc",
    "line" : 146,
    "diffHunk" : "@@ -1,1 +1236,1240 @@    partitionString.append(\"; Replicas: \" + assignmentState.replicas.mkString(\",\"))\n    partitionString.append(\"; ISR: \" + inSyncReplicaIds.mkString(\",\"))\n    assignmentState match {\n      case OngoingReassignmentState(adding, removing, _) =>\n        partitionString.append(\"; AddingReplicas: \" + adding.mkString(\",\"))"
  },
  {
    "id" : "2971d839-02a1-4f1f-acfa-c72783cd6c62",
    "prId" : 7361,
    "prUrl" : "https://github.com/apache/kafka/pull/7361#pullrequestreview-301236624",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55ae45d6-1ce7-4298-8cb8-124aefab25aa",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "neat `diff` method! I didn't know about this when implementing `PartitionReplicaAssignment`",
        "createdAt" : "2019-10-10T15:32:40Z",
        "updatedAt" : "2019-10-18T00:16:40Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "2cdd3d2f-fae5-4419-be2a-de13bf317369",
        "parentId" : "55ae45d6-1ce7-4298-8cb8-124aefab25aa",
        "authorId" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "body" : "Well, scala is always full of surprises :)",
        "createdAt" : "2019-10-14T11:07:23Z",
        "updatedAt" : "2019-10-18T00:16:40Z",
        "lastEditedBy" : "cb6f8432-d515-4113-87f8-14e555ab8ed1",
        "tags" : [
        ]
      }
    ],
    "commit" : "ade9d03bf3fff7f6fe5665fac8c0c7e622489dfc",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +167,171 @@                                    replicas: Seq[Int]) extends AssignmentState {\n\n  override def replicationFactor: Int = replicas.diff(addingReplicas).size // keep the size of the original replicas\n  override def isAddingReplica(replicaId: Int): Boolean = addingReplicas.contains(replicaId)\n}"
  },
  {
    "id" : "a4d8640c-a588-4ceb-8f80-841c4dbd020b",
    "prId" : 7361,
    "prUrl" : "https://github.com/apache/kafka/pull/7361#pullrequestreview-300814156",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8542020-664d-4e09-97e6-efb6a05580d0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: can you update scaladoc above?",
        "createdAt" : "2019-10-11T17:05:10Z",
        "updatedAt" : "2019-10-18T00:16:40Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ade9d03bf3fff7f6fe5665fac8c0c7e622489dfc",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +683,687 @@    *                         the assignment\n   */\n  def updateAssignmentAndIsr(assignment: Seq[Int],\n                             isr: Set[Int],\n                             addingReplicas: Seq[Int],"
  },
  {
    "id" : "ed89bd4e-311d-498e-9032-315dc55ad480",
    "prId" : 8037,
    "prUrl" : "https://github.com/apache/kafka/pull/8037#pullrequestreview-353160714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3587f262-d23f-4e23-bad3-d84a58224ab4",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "`resetLastCaughtUpTime` takes `curLeaderLogEndOffset`, but we are now passing `leaderEpochStartOffset`. Do we need to update the parameter name of that method?",
        "createdAt" : "2020-02-04T14:48:36Z",
        "updatedAt" : "2020-02-04T14:48:36Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "7f24e79d-67af-4fb9-97e7-f3979d7ab7fd",
        "parentId" : "3587f262-d23f-4e23-bad3-d84a58224ab4",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "They are the same thing. I just got rid of a redundant variable.",
        "createdAt" : "2020-02-04T17:10:38Z",
        "updatedAt" : "2020-02-04T17:10:38Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "005a6ed5-7062-49f5-b659-4cd7f94af784",
        "parentId" : "3587f262-d23f-4e23-bad3-d84a58224ab4",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Ok, I see.",
        "createdAt" : "2020-02-04T17:23:53Z",
        "updatedAt" : "2020-02-04T17:23:54Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c5b977813084661c071ad823e3e7e5555c0ca5a",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +512,516 @@      remoteReplicas.foreach { replica =>\n        val lastCaughtUpTimeMs = if (inSyncReplicaIds.contains(replica.brokerId)) curTimeMs else 0L\n        replica.resetLastCaughtUpTime(leaderEpochStartOffset, curTimeMs, lastCaughtUpTimeMs)\n      }\n"
  },
  {
    "id" : "3f785caa-4873-4a41-9ea6-31b0b917b1dd",
    "prId" : 8320,
    "prUrl" : "https://github.com/apache/kafka/pull/8320#pullrequestreview-378944386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b636b44-c3a0-43ee-9b0a-461d14ca38c7",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I think this made it clearer and easy to separate from the `makeFollower()` log, even though both have a log line indicating that we're handling a `become-leader` or `become-follower` request",
        "createdAt" : "2020-03-21T19:21:42Z",
        "updatedAt" : "2020-03-26T18:05:26Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +500,504 @@      val leaderLog = localLogOrException\n      val leaderEpochStartOffset = leaderLog.logEndOffset\n      stateChangeLogger.info(s\"Leader $topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +\n        s\"offset $leaderEpochStartOffset with high watermark ${leaderLog.highWatermark} \" +\n        s\"ISR ${isr.mkString(\",\")} addingReplicas ${addingReplicas.mkString(\",\")} removingReplicas ${removingReplicas.mkString(\",\")}.\" +"
  },
  {
    "id" : "a089e542-01d8-45d6-ac53-c2670103992c",
    "prId" : 8320,
    "prUrl" : "https://github.com/apache/kafka/pull/8320#pullrequestreview-380171755",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "352ac73a-9c7e-463f-b623-f528daebdfbe",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "It would be useful to log isr, addingReplicas and removingReplicas too.",
        "createdAt" : "2020-03-24T04:12:03Z",
        "updatedAt" : "2020-03-26T18:05:26Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "ddcb0d1d-5f27-4517-a006-e014cd3d2466",
        "parentId" : "352ac73a-9c7e-463f-b623-f528daebdfbe",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I was considering adding a toString method to the `AssignmentState` class to make this easier but went without it for now",
        "createdAt" : "2020-03-24T10:21:25Z",
        "updatedAt" : "2020-03-26T18:05:26Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +500,504 @@      val leaderLog = localLogOrException\n      val leaderEpochStartOffset = leaderLog.logEndOffset\n      stateChangeLogger.info(s\"Leader $topicPartition starts at leader epoch ${partitionState.leaderEpoch} from \" +\n        s\"offset $leaderEpochStartOffset with high watermark ${leaderLog.highWatermark} \" +\n        s\"ISR ${isr.mkString(\",\")} addingReplicas ${addingReplicas.mkString(\",\")} removingReplicas ${removingReplicas.mkString(\",\")}.\" +"
  },
  {
    "id" : "b0ee6a22-1d9d-472e-8210-b7c10741125a",
    "prId" : 8657,
    "prUrl" : "https://github.com/apache/kafka/pull/8657#pullrequestreview-483220574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "608e89ae-b327-4b9e-a07a-24a441f236f9",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "With this change, `DelayedOperations.checkAndCompleteFetch()` is only used in tests. I am wondering if it can be removed. It's fine if we want to do this in a followup PR.\r\n\r\nUnrelated to this PR, `DelayedOperations.checkAndCompleteProduce` and `DelayedOperations.checkAndCompleteDeleteRecords` seem unused. We can probably remove them in a separate PR.",
        "createdAt" : "2020-09-06T17:06:29Z",
        "updatedAt" : "2020-09-08T16:18:13Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "6c4694a3-c37b-4c95-93d0-07560ee1ba7a",
        "parentId" : "608e89ae-b327-4b9e-a07a-24a441f236f9",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "> With this change, DelayedOperations.checkAndCompleteFetch() is only used in tests. I am wondering if it can be removed. It's fine if we want to do this in a followup PR.\r\n\r\nI will file a ticket after this PR is merged.\r\n\r\n> Unrelated to this PR, DelayedOperations.checkAndCompleteProduce and DelayedOperations.checkAndCompleteDeleteRecords seem unused. We can probably remove them in a separate PR.\r\n\r\nthis is small change. I will remove them in this PR",
        "createdAt" : "2020-09-07T03:24:50Z",
        "updatedAt" : "2020-09-08T16:18:13Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbd46565aa5e03f4fd9c857a184b7c2371ca5932",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +999,1003 @@    }\n\n    info.copy(leaderHwChange = if (leaderHWIncremented) LeaderHwChange.Increased else LeaderHwChange.Same)\n  }\n"
  }
]