[
  {
    "id" : "d379f64f-0835-41f3-afe8-1566461deb46",
    "prId" : 6785,
    "prUrl" : "https://github.com/apache/kafka/pull/6785#pullrequestreview-247340535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c239631-105a-4e80-a393-9862f186f09a",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could be simplified as \r\n```\r\nif (batchIterator.hasNext && \r\n!(batch.magic < RecordBatch.MAGIC_VALUE_V2 && sourceCodec == NoCompressionCodec)) {\r\n  throw new InvalidRecordException(\"Compressed outer record has more than one batch\")\r\n} else {\r\n  batch\r\n}\r\n```\r\n",
        "createdAt" : "2019-06-04T18:20:39Z",
        "updatedAt" : "2019-06-21T01:39:59Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "573441ec-db48-429a-b10c-c0dbf87785e3",
        "parentId" : "0c239631-105a-4e80-a393-9862f186f09a",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I feel it is easier to read in this way, though a bit verbose.",
        "createdAt" : "2019-06-07T23:37:21Z",
        "updatedAt" : "2019-06-21T01:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2877059086b62a6a36170174e0d2c924a1a6503",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +85,89 @@\n    // if the format is v2 and beyond, or if the messages are compressed, we should check there's only one batch.\n    if (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 || sourceCodec != NoCompressionCodec) {\n      if (batchIterator.hasNext) {\n        throw new InvalidRecordException(\"Compressed outer record has more than one batch\")"
  },
  {
    "id" : "1e54e266-fa27-4b3a-966e-045e299ebc20",
    "prId" : 6816,
    "prUrl" : "https://github.com/apache/kafka/pull/6816#pullrequestreview-242893943",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3597f92-7ee3-413f-b609-1c0487ee624d",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do you think it's worth calling `hasNext()` first so that we can print a nice exception if the buffer reaches this point empty? I think we have a check for emptiness already in `analyzeAndValidateRecords`, but maybe no harm being a little defensive.",
        "createdAt" : "2019-05-28T20:23:23Z",
        "updatedAt" : "2019-05-29T04:35:12Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7fa8c5522d00b97583dd5d8dd54b1391e209625a",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +83,87 @@    }\n\n    val batch = batchIterator.next()\n\n    if (batchIterator.hasNext) {"
  },
  {
    "id" : "660928be-c84e-49c3-833a-f5ec6e8ba821",
    "prId" : 7142,
    "prUrl" : "https://github.com/apache/kafka/pull/7142#pullrequestreview-283832953",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6699cf86-fde8-4f88-8100-9cb2e418c757",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In line 104,, 112, 119, 124 and 131 137 152 and 461 we should also include the topic-partition information.",
        "createdAt" : "2019-09-04T18:57:48Z",
        "updatedAt" : "2019-09-04T19:21:52Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "31e48845-02df-4b0e-b424-c17dacb64d7e",
        "parentId" : "6699cf86-fde8-4f88-8100-9cb2e418c757",
        "authorId" : "38aea9c5-d7f1-4e61-920e-b35370a0109c",
        "body" : "ack",
        "createdAt" : "2019-09-04T19:08:00Z",
        "updatedAt" : "2019-09-04T19:21:52Z",
        "lastEditedBy" : "38aea9c5-d7f1-4e61-920e-b35370a0109c",
        "tags" : [
        ]
      }
    ],
    "commit" : "09a79610109d36eaca221f0651cc74d53aa26440",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +101,105 @@    // batch magic byte should have the same magic as the first batch\n    if (firstBatch.magic() != batch.magic()) {\n      brokerTopicStats.allTopicsStats.invalidMagicNumberRecordsPerSec.mark()\n      throw new InvalidRecordException(s\"Batch magic ${batch.magic()} is not the same as the first batch'es magic byte ${firstBatch.magic()} in topic partition $topicPartition.\")\n    }"
  },
  {
    "id" : "2f7e4a99-e477-4620-9b0c-956c021e4e8f",
    "prId" : 7167,
    "prUrl" : "https://github.com/apache/kafka/pull/7167#pullrequestreview-297715595",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c7b7706-7cdf-42d8-9108-a5eca8fdae1d",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I am not sure why we don't do this validation for both compressed and non-compressed batches. Seems like we should.",
        "createdAt" : "2019-10-04T21:14:32Z",
        "updatedAt" : "2019-10-09T03:47:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca821c98f7e78ea2dadf8271000d4d084d1be6f5",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +378,382 @@            // inner records offset should always be continuous\n            val expectedOffset = expectedInnerOffset.getAndIncrement()\n            if (record.offset != expectedOffset) {\n              brokerTopicStats.allTopicsStats.invalidOffsetOrSequenceRecordsPerSec.mark()\n              throw new RecordValidationException("
  },
  {
    "id" : "cf474404-a21f-4b03-9e19-69bcfca5478c",
    "prId" : 7167,
    "prUrl" : "https://github.com/apache/kafka/pull/7167#pullrequestreview-299679539",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5e7ad44-75e5-4053-8c38-7ae14f84fe3d",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice catch here.",
        "createdAt" : "2019-10-09T20:32:45Z",
        "updatedAt" : "2019-10-09T21:02:11Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca821c98f7e78ea2dadf8271000d4d084d1be6f5",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +254,258 @@        val expectedOffset = expectedInnerOffset.getAndIncrement()\n\n        // inner records offset should always be continuous\n        if (record.offset != expectedOffset) {\n          brokerTopicStats.allTopicsStats.invalidOffsetOrSequenceRecordsPerSec.mark()"
  },
  {
    "id" : "c9c7b42f-1f24-4a23-90f6-93196a3b7692",
    "prId" : 7687,
    "prUrl" : "https://github.com/apache/kafka/pull/7687#pullrequestreview-337241239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4a76795-10cb-4613-bfdf-f5b6d12b04cf",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Curious any reasons to switch these two conditions?",
        "createdAt" : "2019-12-11T19:12:47Z",
        "updatedAt" : "2020-01-09T19:38:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b972808b-3a37-499b-b5b4-09db246eec31",
        "parentId" : "f4a76795-10cb-4613-bfdf-f5b6d12b04cf",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I think I ran into this by mistake while testing. I had sent a control record with `origin == Client` which resulted in the `Invalid sequence number` error below instead of the more specific error here. So I reversed the order.",
        "createdAt" : "2019-12-30T21:16:46Z",
        "updatedAt" : "2020-01-09T19:38:09Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9a1865479fccd5e7a00c3697248fce38d115d74",
    "line" : 122,
    "diffHunk" : "@@ -1,1 +163,167 @@      if (batch.isControlBatch) {\n        brokerTopicStats.allTopicsStats.invalidOffsetOrSequenceRecordsPerSec.mark()\n        throw new InvalidRecordException(s\"Clients are not allowed to write control records in topic partition $topicPartition.\")\n      }\n"
  },
  {
    "id" : "2d83446c-bfa9-42b3-8aeb-9312c61e5801",
    "prId" : 8422,
    "prUrl" : "https://github.com/apache/kafka/pull/8422#pullrequestreview-387709238",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8112237-881a-4121-80ce-29e0fe33da22",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "why not using ```zipWithIndex```?\r\n```scala\r\n        recordsIterator.asScala.zipWithIndex.foreach {\r\n          case (record, batchIndex) =>\r\n```\r\n\r\nThe ```zipWithIndex``` on scala iterator is a wrap so it should not cause performance regression too much.",
        "createdAt" : "2020-04-04T15:31:50Z",
        "updatedAt" : "2020-04-04T16:50:41Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "921fa1c48f0815f971ce40b7280133150d867c6e",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +416,420 @@        val recordErrors = new ArrayBuffer[ApiRecordError](0)\n        var batchIndex = 0\n        for (record <- recordsIterator.asScala) {\n          val expectedOffset = expectedInnerOffset.getAndIncrement()\n          val recordError = validateRecordCompression(batchIndex, record).orElse {"
  },
  {
    "id" : "07f138a9-d630-4d72-9051-65ac1c631c37",
    "prId" : 8647,
    "prUrl" : "https://github.com/apache/kafka/pull/8647#pullrequestreview-410167956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea26c689-6817-4437-8039-8d725b2bf01f",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "First, I don't fully understand the different between version 0, 1, and 2. I am concern if this check (`if` statement) it still accurate.\r\n\r\n1. Why do we only update the `maxTimestamp` if the version is not v0?\r\n2. Why do we disallow in place assignment of records with invalid offsets if the version is not v0?\r\n\r\nFor 1, is it because we are only allow to update it in v1 and v2? E.g.\r\n```\r\nif (toMagic >= RecordBatch.MAGIC_VALUE_V1)\r\n        batch.setMaxTimestamp(timestampType, maxTimestamp)\r\n```\r\n\r\nFor 2. is it because in place assignment is always false for `v0`? E.g.:\r\n```\r\n    if (firstBatch.magic != toMagic || toMagic == RecordBatch.MAGIC_VALUE_V0)\r\n      inPlaceAssignment = false\r\n```",
        "createdAt" : "2020-05-12T03:42:21Z",
        "updatedAt" : "2020-05-12T16:45:52Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "93abe89f-d2b3-4370-b564-485dab17a374",
        "parentId" : "ea26c689-6817-4437-8039-8d725b2bf01f",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "For 1), it is because the v0 format has no field for the timestamp. For 2), you are right: we never do in place assignment for v0 because it does not support relative internal offsets.",
        "createdAt" : "2020-05-12T15:35:13Z",
        "updatedAt" : "2020-05-12T16:45:52Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "b174f7c272a0cdec396e613507c612ded7f96044",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +411,415 @@            validateRecord(batch, topicPartition, record, batchIndex, now,\n              timestampType, timestampDiffMaxMs, compactedTopic, brokerTopicStats).orElse {\n              if (batch.magic > RecordBatch.MAGIC_VALUE_V0 && toMagic > RecordBatch.MAGIC_VALUE_V0) {\n                if (record.timestamp > maxTimestamp)\n                  maxTimestamp = record.timestamp"
  },
  {
    "id" : "e77ae7e5-13a4-419f-9e37-d6326f3fe749",
    "prId" : 8647,
    "prUrl" : "https://github.com/apache/kafka/pull/8647#pullrequestreview-410217220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "748d953e-b44c-4074-820a-bf0e89e4f7fd",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Can we add a comment here?",
        "createdAt" : "2020-05-12T16:29:07Z",
        "updatedAt" : "2020-05-12T16:45:52Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b174f7c272a0cdec396e613507c612ded7f96044",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +419,423 @@                // than rejecting the request. We must continue this handling here to avoid\n                // breaking these clients.\n                if (record.offset != expectedOffset)\n                  inPlaceAssignment = false\n              }"
  },
  {
    "id" : "2b994286-a34e-4247-9fc0-8b28958c639b",
    "prId" : 9206,
    "prUrl" : "https://github.com/apache/kafka/pull/9206#pullrequestreview-493593070",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d70d5cd-025e-46ef-a37a-06b2201b9dcf",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Worth adding a comment here that this is a hot path and we want to avoid any unnecessary allocations.",
        "createdAt" : "2020-09-22T15:19:34Z",
        "updatedAt" : "2020-09-23T15:06:49Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "6fc86266-778f-48bd-ba08-0ec3294460a7",
        "parentId" : "0d70d5cd-025e-46ef-a37a-06b2201b9dcf",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "copy that",
        "createdAt" : "2020-09-22T15:33:51Z",
        "updatedAt" : "2020-09-23T15:06:49Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "82fbfac1f21a248865f303643fd8fd1836a8d758",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +288,292 @@      val recordErrors = new ArrayBuffer[ApiRecordError](0)\n      // this is a hot path and we want to avoid any unnecessary allocations.\n      var batchIndex = 0\n      batch.forEach { record =>\n        validateRecord(batch, topicPartition, record, batchIndex, now, timestampType,"
  }
]