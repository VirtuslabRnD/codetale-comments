[
  {
    "id" : "d8cfc67d-8b4e-4db1-82ed-4e3addf760dc",
    "prId" : 10280,
    "prUrl" : "https://github.com/apache/kafka/pull/10280#pullrequestreview-679398650",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "105dc630-5a51-456d-87a6-dd7a08a8d586",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "This is unnecessary since during splitting, the old segment is replaced with a new segment with the same base offset. So, result.deletedSegments is always empty.",
        "createdAt" : "2021-05-25T22:16:21Z",
        "updatedAt" : "2021-05-26T00:10:15Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "fec1f45d-4fdc-4fa0-899d-bbbd75878d72",
        "parentId" : "105dc630-5a51-456d-87a6-dd7a08a8d586",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Sounds good. Great catch. It appears straightforward to just skip deleting the snapshot here, I can leave a comment explaining why.",
        "createdAt" : "2021-06-01T20:16:46Z",
        "updatedAt" : "2021-06-01T20:17:11Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "cdcd7210-25eb-4bdb-b84a-b6f176d1ff56",
        "parentId" : "105dc630-5a51-456d-87a6-dd7a08a8d586",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "@junrao I thought about this again. Correct me if I'm wrong, but it appears we may be altering existing behavior if we go down this route. Should we do it in a separate PR to isolate the change?",
        "createdAt" : "2021-06-04T09:46:32Z",
        "updatedAt" : "2021-06-04T09:46:32Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "9ff94d16-e54d-4a30-99fc-fa57e668f5aa",
        "parentId" : "105dc630-5a51-456d-87a6-dd7a08a8d586",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Yes, that's fine.",
        "createdAt" : "2021-06-07T17:45:37Z",
        "updatedAt" : "2021-06-07T17:50:23Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "16fb8507-ee25-4ade-a13c-63f2abf8be11",
        "parentId" : "105dc630-5a51-456d-87a6-dd7a08a8d586",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "I have created a jira to track this improvement. https://issues.apache.org/jira/browse/KAFKA-12923",
        "createdAt" : "2021-06-09T09:04:47Z",
        "updatedAt" : "2021-06-09T09:04:48Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "1752ea8c0b9537d7d66815e7619ba810a1cd141d",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +291,295 @@            params.logDirFailureChannel,\n            params.logIdentifier)\n          deleteProducerSnapshotsAsync(result.deletedSegments, params)\n      }\n    }"
  },
  {
    "id" : "98c8b483-2d62-4a32-a3d8-c64f0dffe155",
    "prId" : 10478,
    "prUrl" : "https://github.com/apache/kafka/pull/10478#pullrequestreview-636323729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3eee61b-f851-47ac-8fd6-286c9c303e99",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Currently, if we hit any IOException during loading, we just kill the broker. So, it seems that there is no need to pass in logDirFailureChannel during log loading.",
        "createdAt" : "2021-04-14T21:08:38Z",
        "updatedAt" : "2021-04-20T07:10:51Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "b91672e6-9c76-4d2a-a554-2424a1ad941f",
        "parentId" : "f3eee61b-f851-47ac-8fd6-286c9c303e99",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "In the recovery path, the `logDirFailureChannel` is used to asynchronously handle `IOException` within the  `Log.deleteSegmentFiles()` calls. This was the existing behavior prior to this refactor as well.  Should we change the existing behavior?https://github.com/apache/kafka/blob/193a9dfc44fa2c0df163a8518a804c4579d37e36/core/src/main/scala/kafka/log/Log.scala#L2377\r\n",
        "createdAt" : "2021-04-15T06:48:36Z",
        "updatedAt" : "2021-04-20T07:10:51Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "eaf8519fa26ecfe6278edadee83e3604ae496be8",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +42,46 @@ * @param scheduler The thread pool scheduler used for background actions\n * @param time The time instance used for checking the clock\n * @param logDirFailureChannel The LogDirFailureChannel instance to asynchronously handle log\n *                             directory failure\n * @param hadCleanShutdown Boolean flag to indicate whether the associated log previously had a"
  },
  {
    "id" : "8eea4c6a-bd84-45dd-b6c8-fe94335fa263",
    "prId" : 10742,
    "prUrl" : "https://github.com/apache/kafka/pull/10742#pullrequestreview-665075092",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11bdc3c1-47cc-4465-bc87-b6114c53d74e",
        "parentId" : null,
        "authorId" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "body" : "is the change (remove blank space here) along with https://github.com/apache/kafka/pull/10742/files#diff-54b3df71b1e0697a211d23a9018a91aef773fca0b9cbd1abafbdca6c79664930L70-R70 (add blank space there) needed? [I am not sure the best practice in Kafka codebase]",
        "createdAt" : "2021-05-21T01:27:18Z",
        "updatedAt" : "2021-05-21T01:27:42Z",
        "lastEditedBy" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "tags" : [
        ]
      },
      {
        "id" : "3977a1ef-194e-460c-8ee6-aa3304f6b737",
        "parentId" : "11bdc3c1-47cc-4465-bc87-b6114c53d74e",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Yes, because the existing identifier in the `Log` class is suffixed with a whitespace, see: https://github.com/apache/kafka/blob/5d4f9f917c8dc356a2d922980ba8101e0f2e7093/core/src/main/scala/kafka/log/Log.scala#L280\r\nI'm adding a whitespace here to be consistent with what we already have in the code.",
        "createdAt" : "2021-05-21T04:16:37Z",
        "updatedAt" : "2021-05-21T04:18:48Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b429dcb5a21580d1b8f5cca7183101c98a6faee",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +174,178 @@\n    def deleteIndicesIfExist(baseFile: File, suffix: String = \"\"): Unit = {\n      info(s\"${params.logIdentifier}Deleting index files with suffix $suffix for baseFile $baseFile\")\n      val offset = offsetFromFile(baseFile)\n      Files.deleteIfExists(Log.offsetIndexFile(params.dir, offset, suffix).toPath)"
  },
  {
    "id" : "ddffcc45-8dc1-4b61-bc89-0ac0db65dc70",
    "prId" : 10742,
    "prUrl" : "https://github.com/apache/kafka/pull/10742#pullrequestreview-665075564",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "730405c5-ef1a-4cfd-8081-3704da850947",
        "parentId" : null,
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "Why do you add a space here, and remove the space in the following log content?",
        "createdAt" : "2021-05-21T02:47:21Z",
        "updatedAt" : "2021-05-21T02:48:20Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      },
      {
        "id" : "d9c3a38d-1757-486f-82c7-b40921bdb676",
        "parentId" : "730405c5-ef1a-4cfd-8081-3704da850947",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "This is required because the existing identifier in the `Log` class is suffixed with a whitespace, see: https://github.com/apache/kafka/blob/5d4f9f917c8dc356a2d922980ba8101e0f2e7093/core/src/main/scala/kafka/log/Log.scala#L280\r\nI'm adding a whitespace here to be consistent with what we already have in the code.",
        "createdAt" : "2021-05-21T04:18:06Z",
        "updatedAt" : "2021-05-21T04:18:34Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b429dcb5a21580d1b8f5cca7183101c98a6faee",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +68,72 @@                         leaderEpochCache: Option[LeaderEpochFileCache],\n                         producerStateManager: ProducerStateManager) {\n  val logIdentifier: String = s\"[LogLoader partition=$topicPartition, dir=${dir.getParent}] \"\n}\n"
  },
  {
    "id" : "cd1370e9-93e7-4e90-9d13-464e16dc4077",
    "prId" : 10763,
    "prUrl" : "https://github.com/apache/kafka/pull/10763#pullrequestreview-691259320",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4be2808f-0361-49a3-b2d4-3e3a4567dd70",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "The PR descriptions says \"as a result, if at least one .swap file exists for a segment, all other files for the segment must exist as .cleaned files or .swap files. Therefore, we rename the .cleaned files to .swap files, then make them normal segment files.\". Are we implementing the renaming of .clean files to .swap files?",
        "createdAt" : "2021-06-23T22:40:29Z",
        "updatedAt" : "2021-06-23T22:41:36Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "6cd39d4f-0fdd-47a1-a3cc-6e7f4f3d1ceb",
        "parentId" : "4be2808f-0361-49a3-b2d4-3e3a4567dd70",
        "authorId" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "body" : "No, we are not renaming .cleaned files to .swap files due to KAFKA-6264. I forgot to update the description of the PR. Just updated it: please see the updated one.",
        "createdAt" : "2021-06-24T01:15:59Z",
        "updatedAt" : "2021-06-24T01:58:49Z",
        "lastEditedBy" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c31418c7bd392e6460fc8a1c2cb333baa6f2134",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +216,220 @@   *\n   * @param params The parameters for the log being loaded from disk\n   * @return Set of .swap files that are valid to be swapped in as segment files and index files\n   */\n  private def removeTempFilesAndCollectSwapFiles(params: LoadLogParams): Set[File] = {"
  },
  {
    "id" : "ddb6efc3-a8d2-4b85-b486-3161e22d2586",
    "prId" : 10763,
    "prUrl" : "https://github.com/apache/kafka/pull/10763#pullrequestreview-695239592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4d36611-4d40-4fdb-8905-ae84a38f20a5",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "It's possible that during renaming, we have only renamed the .log file to .swap, but not the corresponding index files. Should we find those .clean files with the same offset and rename them to .swap?",
        "createdAt" : "2021-06-28T17:11:56Z",
        "updatedAt" : "2021-06-28T17:12:46Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "a8982696-cf1c-42f9-8faa-a559e3375709",
        "parentId" : "c4d36611-4d40-4fdb-8905-ae84a38f20a5",
        "authorId" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "body" : "Due to KAFKA-6264, if there are any .cleaned files (no matter they are .index.cleaned or .log.cleaned), we delete all .cleaned files and .swap files that have larger/equal base offsets. Basically, this reverts ongoing compaction/split operations. Therefore, we don't have any additional .index.cleaned files.\r\n\r\nIs that fair?",
        "createdAt" : "2021-06-28T18:56:24Z",
        "updatedAt" : "2021-06-28T18:59:53Z",
        "lastEditedBy" : "1e1e52a7-6513-46fd-99c3-3d01eee59d17",
        "tags" : [
        ]
      },
      {
        "id" : "519de9b1-3c9f-4b16-954c-4f080c1f58bf",
        "parentId" : "c4d36611-4d40-4fdb-8905-ae84a38f20a5",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Thanks for the explanation. Make sense.",
        "createdAt" : "2021-06-29T16:12:45Z",
        "updatedAt" : "2021-06-29T16:12:45Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c31418c7bd392e6460fc8a1c2cb333baa6f2134",
    "line" : 134,
    "diffHunk" : "@@ -1,1 +235,239 @@        cleanedFiles += file\n      } else if (filename.endsWith(SwapFileSuffix)) {\n        swapFiles += file\n      }\n    }"
  }
]