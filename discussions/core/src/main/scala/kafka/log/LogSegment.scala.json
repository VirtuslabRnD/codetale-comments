[
  {
    "id" : "8d71046c-62ef-44f2-9d6c-1e20dd1646e7",
    "prId" : 5169,
    "prUrl" : "https://github.com/apache/kafka/pull/5169#pullrequestreview-127352873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e5d72f7-5941-4c10-971a-ff32d6ba25a9",
        "parentId" : null,
        "authorId" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "body" : "Hmm, I seem to have missed looking into this call in more detail. Do you think we need to handle a potential offset overflow when `onBecomeInactiveSegment` is called from `roll()`?",
        "createdAt" : "2018-06-08T22:25:17Z",
        "updatedAt" : "2018-06-19T15:58:05Z",
        "lastEditedBy" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "tags" : [
        ]
      },
      {
        "id" : "2ef3625e-8536-41b6-84a8-c6d83783863e",
        "parentId" : "7e5d72f7-5941-4c10-971a-ff32d6ba25a9",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Double check to be sure, but I think we already protect updates to `offsetOfMaxTimestamp`. This field seems is updated in three cases 1) append, 2) recovery, and 3) loading from the index. We do validation in the first two cases and, in the third, the offset should already be in the right range (since it was already appended to the index).",
        "createdAt" : "2018-06-09T05:06:55Z",
        "updatedAt" : "2018-06-19T15:58:05Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "c71b1e5937a33e525f483cd5d2edaa925fa68ccb",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +498,502 @@   */\n  def onBecomeInactiveSegment() {\n    timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp, skipFullCheck = true)\n    offsetIndex.trimToValidSize()\n    timeIndex.trimToValidSize()"
  },
  {
    "id" : "2ff78c19-5482-4f7b-9f1a-46839a0f3f8d",
    "prId" : 5498,
    "prUrl" : "https://github.com/apache/kafka/pull/5498#pullrequestreview-205499964",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87641e20-0100-4911-a264-b93dc9345a00",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Perhaps add a comment why we skip the sanity check just for offsetIndex and timeIndex?",
        "createdAt" : "2019-02-16T02:17:03Z",
        "updatedAt" : "2019-02-19T23:03:15Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "4fde406b-ef21-4b82-9fe0-911401bd55b1",
        "parentId" : "87641e20-0100-4911-a264-b93dc9345a00",
        "authorId" : "e9f2a5b6-a46b-4418-b0e8-3a587ddbbf67",
        "body" : "Done.",
        "createdAt" : "2019-02-19T23:03:12Z",
        "updatedAt" : "2019-02-19T23:03:15Z",
        "lastEditedBy" : "e9f2a5b6-a46b-4418-b0e8-3a587ddbbf67",
        "tags" : [
        ]
      }
    ],
    "commit" : "e818b20e6fd37ece4dbc2d39a0d872a1f523c1d5",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +80,84 @@  def sanityCheck(timeIndexFileNewlyCreated: Boolean): Unit = {\n    if (lazyOffsetIndex.file.exists) {\n      // Resize the time index file to 0 if it is newly created.\n      if (timeIndexFileNewlyCreated)\n        timeIndex.resize(0)"
  }
]