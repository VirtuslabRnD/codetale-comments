[
  {
    "id" : "8d71046c-62ef-44f2-9d6c-1e20dd1646e7",
    "prId" : 5169,
    "prUrl" : "https://github.com/apache/kafka/pull/5169#pullrequestreview-127352873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e5d72f7-5941-4c10-971a-ff32d6ba25a9",
        "parentId" : null,
        "authorId" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "body" : "Hmm, I seem to have missed looking into this call in more detail. Do you think we need to handle a potential offset overflow when `onBecomeInactiveSegment` is called from `roll()`?",
        "createdAt" : "2018-06-08T22:25:17Z",
        "updatedAt" : "2018-06-19T15:58:05Z",
        "lastEditedBy" : "93b1c273-8917-4547-bd53-5101f22161c0",
        "tags" : [
        ]
      },
      {
        "id" : "2ef3625e-8536-41b6-84a8-c6d83783863e",
        "parentId" : "7e5d72f7-5941-4c10-971a-ff32d6ba25a9",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Double check to be sure, but I think we already protect updates to `offsetOfMaxTimestamp`. This field seems is updated in three cases 1) append, 2) recovery, and 3) loading from the index. We do validation in the first two cases and, in the third, the offset should already be in the right range (since it was already appended to the index).",
        "createdAt" : "2018-06-09T05:06:55Z",
        "updatedAt" : "2018-06-19T15:58:05Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "c71b1e5937a33e525f483cd5d2edaa925fa68ccb",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +498,502 @@   */\n  def onBecomeInactiveSegment() {\n    timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp, skipFullCheck = true)\n    offsetIndex.trimToValidSize()\n    timeIndex.trimToValidSize()"
  }
]