[
  {
    "id" : "12fb73fe-0bb7-47c8-9963-4270b3a8a773",
    "prId" : 3610,
    "prUrl" : "https://github.com/apache/kafka/pull/3610#pullrequestreview-108062469",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb4d78ee-cd3a-4ae4-8a7d-68a57725b46e",
        "parentId" : null,
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "Not related to this PR. Can we also update the doc string of MaxConnectionsPerIpOverridesDoc.\r\nCurrently it is not clear about the format of the config string. \r\n\r\nsome thing like this:\r\nA comma separated list of per-ip or hostname overrides to the default maximum number of connections.  Example value is :  `hostName:100,127.0.0.1:200`.",
        "createdAt" : "2018-03-29T14:10:29Z",
        "updatedAt" : "2018-03-29T14:10:29Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      }
    ],
    "commit" : "1409af560c70823ac8b91994560ecbf08e700ce8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +783,787 @@      .define(SocketReceiveBufferBytesProp, INT, Defaults.SocketReceiveBufferBytes, HIGH, SocketReceiveBufferBytesDoc)\n      .define(SocketRequestMaxBytesProp, INT, Defaults.SocketRequestMaxBytes, atLeast(1), HIGH, SocketRequestMaxBytesDoc)\n      .define(MaxConnectionsPerIpProp, INT, Defaults.MaxConnectionsPerIp, atLeast(0), MEDIUM, MaxConnectionsPerIpDoc)\n      .define(MaxConnectionsPerIpOverridesProp, STRING, Defaults.MaxConnectionsPerIpOverrides, MEDIUM, MaxConnectionsPerIpOverridesDoc)\n      .define(ConnectionsMaxIdleMsProp, LONG, Defaults.ConnectionsMaxIdleMs, MEDIUM, ConnectionsMaxIdleMsDoc)"
  },
  {
    "id" : "c5fba628-239b-423f-9c07-08507519e16d",
    "prId" : 4488,
    "prUrl" : "https://github.com/apache/kafka/pull/4488#pullrequestreview-93722756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f1023b4-d737-461b-a3e5-b08566274bce",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "When we update documentation, maybe we can add an additional column to the configuration table which indicates whether the property is dynamically configurable.",
        "createdAt" : "2018-02-02T22:52:53Z",
        "updatedAt" : "2018-02-04T02:11:57Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0488d78e0ea02c3ddde1a31f6c1e0613a443e3d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +231,235 @@}\n\nobject KafkaConfig {\n\n  private val LogConfigPrefix = \"log.\""
  },
  {
    "id" : "c51c476c-1d6f-414a-a94a-861ce847ac96",
    "prId" : 5082,
    "prUrl" : "https://github.com/apache/kafka/pull/5082#pullrequestreview-125262482",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "964fd32f-f9ff-460e-bd3c-7c52b4e05691",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "We perhaps want to validate that `connection.failed.authentication.delay.ms` is less than `connections.max.idle.ms`.",
        "createdAt" : "2018-06-01T18:55:37Z",
        "updatedAt" : "2018-08-29T15:39:41Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "4c882dee7cacc4e09e13dc071804e6a1d8c8aaac",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +284,288 @@  val MaxConnectionsPerIpOverridesProp = \"max.connections.per.ip.overrides\"\n  val ConnectionsMaxIdleMsProp = \"connections.max.idle.ms\"\n  val FailedAuthenticationDelayMsProp = \"connection.failed.authentication.delay.ms\"\n  /***************** rack configuration *************/\n  val RackProp = \"broker.rack\""
  },
  {
    "id" : "caca969c-d46c-4c79-8a22-e12615d50bf8",
    "prId" : 5921,
    "prUrl" : "https://github.com/apache/kafka/pull/5921#pullrequestreview-185887902",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5644043f-212f-44dc-9cdb-43d16953f05e",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Could we adjust the comment for request queue to make it clear that it only controls the data plane queue size?",
        "createdAt" : "2018-12-14T18:43:37Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "ca4a5d21-3cce-4253-8498-5c6ae6a113ba",
        "parentId" : "5644043f-212f-44dc-9cdb-43d16953f05e",
        "authorId" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "body" : "Agreed.",
        "createdAt" : "2018-12-18T02:46:34Z",
        "updatedAt" : "2018-12-21T21:26:18Z",
        "lastEditedBy" : "68c9b940-6e55-49f3-b14b-008ab7e2e635",
        "tags" : [
        ]
      }
    ],
    "commit" : "c40a575b7d984205ae4a8ac4b0584b9731566090",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +548,552 @@    \"INTERNAL listener, a config with name <code>listener.name.internal.ssl.keystore.location</code> would be set. \" +\n    \"If the config for the listener name is not set, the config will fallback to the generic config (i.e. <code>ssl.keystore.location</code>). \"\n  val controlPlaneListenerNameDoc = \"Name of listener used for communication between controller and brokers. \" +\n    s\"Broker will use the $ControlPlaneListenerNameProp to locate the endpoint in $ListenersProp list, to listen for connections from the controller. \" +\n    \"For example, if a broker's config is :\\n\" +"
  },
  {
    "id" : "a1e11576-3268-463e-b933-7ce5d9c27c68",
    "prId" : 6464,
    "prUrl" : "https://github.com/apache/kafka/pull/6464#pullrequestreview-226677045",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0311444-2325-4bc1-8a3e-ce2a6c37c7f7",
        "parentId" : null,
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "Wouldn't \"If set to a negative number, no time limit is applied.\" be a more accurate statement?",
        "createdAt" : "2019-04-14T01:14:34Z",
        "updatedAt" : "2019-04-14T01:14:34Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      },
      {
        "id" : "4d018ec3-f0bb-4dae-bedb-ed704f5ce323",
        "parentId" : "a0311444-2325-4bc1-8a3e-ce2a6c37c7f7",
        "authorId" : "2f3fbc93-2875-4df0-8f43-329c41f891e4",
        "body" : "Hi @vahidhashemian , technically you are indeed completely right, I simply copied over the existing sentence from the documentation, in order to keep them in line with each other.\r\nI thought about changing it, but went with the same reasoning that we applied in a [similar discussion](https://github.com/apache/kafka/pull/6205#discussion_r254739039) we had a little while ago. ",
        "createdAt" : "2019-04-15T07:52:39Z",
        "updatedAt" : "2019-04-15T07:52:39Z",
        "lastEditedBy" : "2f3fbc93-2875-4df0-8f43-329c41f891e4",
        "tags" : [
        ]
      },
      {
        "id" : "b192d5c9-bd8f-48e2-8f09-61b06d69b32b",
        "parentId" : "a0311444-2325-4bc1-8a3e-ce2a6c37c7f7",
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "Thanks for clarifying. I though we already had discussed this but couldn't quickly find it out :)\r\nLGTM.",
        "createdAt" : "2019-04-15T14:22:55Z",
        "updatedAt" : "2019-04-15T14:22:55Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0c4a00459ed5a9f2fdd1f80db9c30f388dce416",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +598,602 @@  val LogRollTimeJitterHoursDoc = \"The maximum jitter to subtract from logRollTimeMillis (in hours), secondary to \" + LogRollTimeJitterMillisProp + \" property\"\n\n  val LogRetentionTimeMillisDoc = \"The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in \" + LogRetentionTimeMinutesProp + \" is used. If set to -1, no time limit is applied.\"\n  val LogRetentionTimeMinsDoc = \"The number of minutes to keep a log file before deleting it (in minutes), secondary to \" + LogRetentionTimeMillisProp + \" property. If not set, the value in \" + LogRetentionTimeHoursProp + \" is used\"\n  val LogRetentionTimeHoursDoc = \"The number of hours to keep a log file before deleting it (in hours), tertiary to \" + LogRetentionTimeMillisProp + \" property\""
  },
  {
    "id" : "e5548f1d-5ad5-45ad-be9d-8a0b61fd17fd",
    "prId" : 8931,
    "prUrl" : "https://github.com/apache/kafka/pull/8931#pullrequestreview-438245997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ecaf8e0c-be3b-43c6-b084-30515088b98b",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "`toBuffer` is more efficient than `toList` and `sorted` returns a copy anyway.",
        "createdAt" : "2020-06-26T12:16:21Z",
        "updatedAt" : "2020-06-26T12:16:21Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "261ab95d14bbc7d88b6d57f5ad291351eed91e0b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1211,1215 @@  }\n\n  def configNames: Seq[String] = configDef.names.asScala.toBuffer.sorted\n  private[server] def defaultValues: Map[String, _] = configDef.defaultValues.asScala\n  private[server] def configKeys: Map[String, ConfigKey] = configDef.configKeys.asScala"
  },
  {
    "id" : "bdfb4591-ca49-4835-9e17-684b7a94b208",
    "prId" : 9934,
    "prUrl" : "https://github.com/apache/kafka/pull/9934#pullrequestreview-573666374",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e233adb-e11b-405d-8f24-5b64ba24716b",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Do we have test coverage for this check?",
        "createdAt" : "2021-01-21T17:28:20Z",
        "updatedAt" : "2021-01-21T19:45:26Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "80031400-b358-46df-bc04-65c965e99771",
        "parentId" : "2e233adb-e11b-405d-8f24-5b64ba24716b",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ack. Will add a test case.",
        "createdAt" : "2021-01-21T19:29:00Z",
        "updatedAt" : "2021-01-21T19:45:26Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "50fa8e955b3f146b624224917374eaf06575a71b",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +1907,1911 @@        s\" authentication responses from timing out\")\n\n    if (requiresZookeeper && zkConnect == null) {\n      throw new ConfigException(s\"Missing required configuration '${KafkaConfig.ZkConnectProp}' which has no default value.\")\n    }"
  },
  {
    "id" : "9097121f-3a9e-4f0e-95b7-98d44a27958f",
    "prId" : 9967,
    "prUrl" : "https://github.com/apache/kafka/pull/9967#pullrequestreview-576989032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4aebfdb-ec4a-4df8-8897-67c2f0de08fa",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Does it cause trouble if we change the order of directories from \"log.dirs\" when restarting server?",
        "createdAt" : "2021-01-26T17:21:00Z",
        "updatedAt" : "2021-01-30T20:56:49Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "86654f88-118e-44dd-8a2d-643e4c742802",
        "parentId" : "c4aebfdb-ec4a-4df8-8897-67c2f0de08fa",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Good question. I think the implementation will have to be smart enough to find the metadata log dir in case we have already created the partition directory. Let me see if it is straightforward to add that here or if we should leave it for a follow-up. I guess the alternative would be to require `metadata.log.dir`, but I think we were trying to avoid that.",
        "createdAt" : "2021-01-27T04:24:51Z",
        "updatedAt" : "2021-01-30T20:56:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "c30e4bf8-9729-484f-a2e9-358ca6c24879",
        "parentId" : "c4aebfdb-ec4a-4df8-8897-67c2f0de08fa",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "What I am thinking for the moment is the following:\r\n\r\n1. Assume a deterministic mapping to the metadata dir from the configuration.\r\n2. Raise an exception on startup if we find the `@metadata` log dir in another directory.\r\n\r\nAs a future improvement, we might relax this in case the metadata log dir has not been explicitly defined and is offline.",
        "createdAt" : "2021-01-27T05:11:19Z",
        "updatedAt" : "2021-01-30T20:56:49Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c316377582d4f84b007a339aa9488af493e8130",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +1522,1526 @@    Option(getString(KafkaConfig.MetadataLogDirProp)) match {\n      case Some(dir) => dir\n      case None => logDirs.head\n    }\n  }"
  }
]