[
  {
    "id" : "25606d95-8bac-4a6b-ac0c-ec8e8b06c102",
    "prId" : 5206,
    "prUrl" : "https://github.com/apache/kafka/pull/5206#pullrequestreview-171309268",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad6ea18d-8ee9-44f8-8cf8-d92894c11ca8",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Should map be foreach?",
        "createdAt" : "2018-11-03T00:41:58Z",
        "updatedAt" : "2018-11-03T00:42:40Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "27c8bdc1dd7272df7db14e886ec2bcdd2f77c75b",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +840,844 @@      val fetchPartitionStatus = new mutable.ArrayBuffer[(TopicPartition, FetchPartitionStatus)]\n      fetchInfos.foreach { case (topicPartition, partitionData) =>\n        logReadResultMap.get(topicPartition).map(logReadResult => {\n          val logOffsetMetadata = logReadResult.info.fetchOffsetMetadata\n          fetchPartitionStatus += (topicPartition -> FetchPartitionStatus(logOffsetMetadata, partitionData))"
  },
  {
    "id" : "a8e052e2-5b14-42c0-a3fc-9a31b92b93d5",
    "prId" : 5576,
    "prUrl" : "https://github.com/apache/kafka/pull/5576#pullrequestreview-149903578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "368c4a79-2e9a-439b-8c8b-05768037e675",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "If we do this, we can remove the unused import in line 38.",
        "createdAt" : "2018-08-27T22:09:16Z",
        "updatedAt" : "2018-08-27T22:24:59Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "210976e679533309f961e74a781124ff4e7ec6fd",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1481,1485 @@        case Some(partition) =>\n          if (partition eq ReplicaManager.OfflinePartition)\n            new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n          else\n            partition.lastOffsetForLeaderEpoch(leaderEpoch)"
  },
  {
    "id" : "a005cbb5-564f-4212-87b0-abe78ac184d5",
    "prId" : 5661,
    "prUrl" : "https://github.com/apache/kafka/pull/5661#pullrequestreview-161859700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc0ac912-e63d-432c-948e-d3b3b3000c21",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "The issue of not calling replicaFetcherManager.removeFetcherForPartitions() in line 1278 is that in the case of controlled shutdown, we avoid adding the partitions to the fetcher. This means that existing partitions won't be removed from the fetcher. This may cause replicas removed from ISR during controlled shutdown to be added back to ISR again.\r\n\r\nAlso, if we do this, the state-change logging after replicaFetcherManager.removeFetcherForPartitions()  probably needs to be moved too.",
        "createdAt" : "2018-10-04T23:16:59Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "bed238d1-adaa-4654-ae96-3a96f1ecd3c5",
        "parentId" : "fc0ac912-e63d-432c-948e-d3b3b3000c21",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Ok, let's revert this change. I think it was not strictly needed and I was not too happy about the additional bookkeeping in `AbstractFetcherManager`.",
        "createdAt" : "2018-10-05T00:48:21Z",
        "updatedAt" : "2018-10-05T16:40:27Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9bc468a7415831841a1203315789e683066dad4",
    "line" : 581,
    "diffHunk" : "@@ -1,1 +1301,1305 @@      else {\n        // we do not need to check if the leader exists again since this has been done at the beginning of this process\n        val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map { partition =>\n          val leader = metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get\n            .brokerEndPoint(config.interBrokerListenerName)"
  }
]