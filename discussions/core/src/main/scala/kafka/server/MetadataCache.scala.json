[
  {
    "id" : "bb887540-a477-434d-be1a-50d2caede3ca",
    "prId" : 6397,
    "prUrl" : "https://github.com/apache/kafka/pull/6397#pullrequestreview-212147517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffe70a44-318f-4b0d-b2fd-9ecf1802dd7c",
        "parentId" : null,
        "authorId" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "body" : "Actually, do you think we can switch this to be a plain `j.u.List`? See next comment as well.",
        "createdAt" : "2019-03-08T05:46:37Z",
        "updatedAt" : "2019-03-22T08:30:39Z",
        "lastEditedBy" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "tags" : [
        ]
      }
    ],
    "commit" : "aabb6735a0168c4b04ec92cd1a9d4ac50173df8a",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +55,59 @@  // `Iterable[Integer]` instead of `Iterable[Int]` to avoid a collection copy.\n  // filterUnavailableEndpoints exists to support v0 MetadataResponses\n  private def getEndpoints(snapshot: MetadataSnapshot, brokers: Iterable[java.lang.Integer], listenerName: ListenerName, filterUnavailableEndpoints: Boolean): Seq[Node] = {\n    val result = new mutable.ArrayBuffer[Node](math.min(snapshot.aliveBrokers.size, brokers.size))\n    brokers.foreach { brokerId =>"
  },
  {
    "id" : "a94b63b9-a16b-4d8a-a985-d7bfb0eb3da4",
    "prId" : 6397,
    "prUrl" : "https://github.com/apache/kafka/pull/6397#pullrequestreview-212150932",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfcaaacf-a0e6-4fed-b849-ee177dbe45f8",
        "parentId" : null,
        "authorId" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "body" : "basically, these fields are all originally `j.u.List`s. There seems to be an unnecessary conversion to Scala collections and then back to Java (https://github.com/apache/kafka/pull/6397/files#diff-bfeebf48d90e86c1ffb850fbbe019dd6R112). I think we can avoid these altogether. Although there are Scala-collection-specific filters applied for debug logging (https://github.com/apache/kafka/pull/6397/files#diff-bfeebf48d90e86c1ffb850fbbe019dd6R107 for example), you can just use `JavaConverters.collectionAsScalaIterable` which IIUC does not do any copying.",
        "createdAt" : "2019-03-08T05:52:44Z",
        "updatedAt" : "2019-03-22T08:30:39Z",
        "lastEditedBy" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "tags" : [
        ]
      },
      {
        "id" : "8361049e-8af3-45b7-8f08-fdaf4c7e7505",
        "parentId" : "dfcaaacf-a0e6-4fed-b849-ee177dbe45f8",
        "authorId" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "body" : "actually, nm - these aren't copying conversions except for the type conversion which your patch eliminates. So I think we are good.",
        "createdAt" : "2019-03-08T06:05:09Z",
        "updatedAt" : "2019-03-22T08:30:39Z",
        "lastEditedBy" : "aa2f3d2f-93f8-421b-a14a-37805d03ea87",
        "tags" : [
        ]
      },
      {
        "id" : "82670b22-f012-47c2-b514-ab639a48b21b",
        "parentId" : "dfcaaacf-a0e6-4fed-b849-ee177dbe45f8",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Yeah, none of the converters do copying. It's just unfortunate that there's no way to have `Int` as a collection parameter without copying. We can live with `Integer` here.",
        "createdAt" : "2019-03-08T06:06:25Z",
        "updatedAt" : "2019-03-22T08:30:39Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aabb6735a0168c4b04ec92cd1a9d4ac50173df8a",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +78,82 @@        val leaderEpoch = partitionState.basePartitionState.leaderEpoch\n        val maybeLeader = getAliveEndpoint(snapshot, leaderBrokerId, listenerName)\n        val replicas = partitionState.basePartitionState.replicas.asScala\n        val replicaInfo = getEndpoints(snapshot, replicas, listenerName, errorUnavailableEndpoints)\n        val offlineReplicaInfo = getEndpoints(snapshot, partitionState.offlineReplicas.asScala, listenerName, errorUnavailableEndpoints)"
  },
  {
    "id" : "51791f01-6830-41ff-b89e-9576a27f405a",
    "prId" : 6832,
    "prUrl" : "https://github.com/apache/kafka/pull/6832#pullrequestreview-257164748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "654f2799-dc99-4c3f-8cbf-43aa720034e4",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We could make this a `flatMap` and skip the `filter` below.",
        "createdAt" : "2019-07-02T21:52:07Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "4649c14a969cd8c88d06cad68f65d39a0cfdd905",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +202,206 @@      val replicaIds = partitionInfo.basePartitionState.replicas\n      replicaIds.asScala\n        .map(replicaId => replicaId.intValue() -> {\n          snapshot.aliveBrokers.get(replicaId.longValue()) match {\n            case Some(broker) =>"
  },
  {
    "id" : "c3e966c2-0fa2-4500-905a-f123029686b0",
    "prId" : 6836,
    "prUrl" : "https://github.com/apache/kafka/pull/6836#pullrequestreview-264104952",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8cf4279-4c92-474d-90da-cb94333fe1a3",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can we have a test case for this change?",
        "createdAt" : "2019-07-01T22:00:43Z",
        "updatedAt" : "2019-07-01T22:00:51Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "83e9047a-459b-4a01-af6c-6b60b2c785a2",
        "parentId" : "b8cf4279-4c92-474d-90da-cb94333fe1a3",
        "authorId" : "2b8ddac3-3f74-403c-9e9d-62dc37cb6655",
        "body" : "Do you think MetadataCacheTest#getTopicMetadataPartitionLeaderNotAvailable cover this?",
        "createdAt" : "2019-07-19T09:24:38Z",
        "updatedAt" : "2019-07-19T09:24:38Z",
        "lastEditedBy" : "2b8ddac3-3f74-403c-9e9d-62dc37cb6655",
        "tags" : [
        ]
      }
    ],
    "commit" : "654949d269673ccb612261f3e635d3fc0a1b6621",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +94,98 @@            }\n            new MetadataResponse.PartitionMetadata(error, partitionId.toInt, Node.noNode(),\n              Optional.empty(), replicaInfo.asJava, isrInfo.asJava,\n              offlineReplicaInfo.asJava)\n"
  },
  {
    "id" : "5e859c43-12de-4944-8f69-8d5670aaa166",
    "prId" : 7770,
    "prUrl" : "https://github.com/apache/kafka/pull/7770#pullrequestreview-350858924",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d483d2e7-218f-425e-a693-2033332413ba",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Part of this comment doesn't seem accurate anymore. For example, `brokers` is now a `List`?",
        "createdAt" : "2020-01-30T15:00:50Z",
        "updatedAt" : "2020-02-05T00:33:47Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb5a99fe09a3a7caca8a71256d2810115bfe47e1",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +58,62 @@  // we should be careful about adding additional logic here. Relatedly, `brokers` is\n  // `List[Integer]` instead of `List[Int]` to avoid a collection copy.\n  // filterUnavailableEndpoints exists to support v0 MetadataResponses\n  private def maybeFilterAliveReplicas(snapshot: MetadataSnapshot,\n                                       brokers: java.util.List[Integer],"
  },
  {
    "id" : "94b383a0-d15b-4f4c-a0f3-ce6135b7ef26",
    "prId" : 7770,
    "prUrl" : "https://github.com/apache/kafka/pull/7770#pullrequestreview-352720720",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "511abd2b-5b26-4995-bbc2-7b33862f9bb5",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "May be worth mentioning that we added this method for perf reasons and it has the same semantics as `getAliveEndpoint` (which has a comment explaining how it works). Otherwise, I can see someone removing this method in a refactoring.",
        "createdAt" : "2020-02-04T14:25:13Z",
        "updatedAt" : "2020-02-05T00:33:47Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb5a99fe09a3a7caca8a71256d2810115bfe47e1",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +134,138 @@   */\n  private def hasAliveEndpoint(snapshot: MetadataSnapshot, brokerId: Int, listenerName: ListenerName): Boolean = {\n    snapshot.aliveNodes.get(brokerId).exists(_.contains(listenerName))\n  }\n"
  },
  {
    "id" : "35c1255f-f39d-4977-a756-34041fbd9fed",
    "prId" : 8320,
    "prUrl" : "https://github.com/apache/kafka/pull/8320#pullrequestreview-382210318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "923f9607-0c08-416c-ace2-29ff019f0b1d",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Should we add a comment that these trace logs are expensive?",
        "createdAt" : "2020-03-26T13:11:48Z",
        "updatedAt" : "2020-03-26T18:05:26Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "a3b1a395-a14b-49ee-b725-39368a485a74",
        "parentId" : "923f9607-0c08-416c-ace2-29ff019f0b1d",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Yes, we can add a comment.",
        "createdAt" : "2020-03-26T16:57:15Z",
        "updatedAt" : "2020-03-26T18:05:26Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fc7ca7de7ffd00ed32fcd3ced1cc4774ad503c0",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +332,336 @@          if (state.leader == LeaderAndIsr.LeaderDuringDelete) {\n            removePartitionInfo(partitionStates, tp.topic, tp.partition)\n            if (traceEnabled)\n              stateChangeLogger.trace(s\"Deleted partition $tp from metadata cache in response to UpdateMetadata \" +\n                s\"request sent by controller $controllerId epoch $controllerEpoch with correlation id $correlationId\")"
  }
]