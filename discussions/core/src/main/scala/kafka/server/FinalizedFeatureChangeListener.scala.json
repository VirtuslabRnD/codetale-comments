[
  {
    "id" : "969f026d-46f8-4cd1-b8f3-4e3e88130e88",
    "prId" : 8680,
    "prUrl" : "https://github.com/apache/kafka/pull/8680#pullrequestreview-417207312",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ec49341-caa0-444b-b333-6d80a8d01415",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Do we need the comment to be on info level?",
        "createdAt" : "2020-05-21T03:11:58Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "52341769-40cc-4e63-83c3-5f9490650056",
        "parentId" : "1ec49341-caa0-444b-b333-6d80a8d01415",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "I didn't understand the question. Are you saying the logging severity should be lower or higher?\r\nThis is a rare case anyway as the feature node doesn't get created often, so, `info` logging seems fine to me.",
        "createdAt" : "2020-05-22T08:23:51Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "e4a2d43d-8ee6-48e8-b162-2df55f28a995",
        "parentId" : "1ec49341-caa0-444b-b333-6d80a8d01415",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "My feeling is that this could be on debug level, but no strong perference.",
        "createdAt" : "2020-05-22T22:38:14Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e3ef56c552da13226c1fcc472c8d339fb98c7a8",
    "line" : 163,
    "diffHunk" : "@@ -1,1 +161,165 @@\n    override def handleCreation(): Unit = {\n      info(s\"Feature ZK node created at path: $path\")\n      queue.add(new FeatureCacheUpdater(path))\n    }"
  },
  {
    "id" : "adc70d2a-1cc2-4d9a-8555-9c9e22bd9be7",
    "prId" : 8680,
    "prUrl" : "https://github.com/apache/kafka/pull/8680#pullrequestreview-416042080",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4c649c5-5c44-4ed1-9cde-4226b69ff676",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Does the version field existence guarantee there is a valid feature data node or not? In fact, `getDataAndVersion` returns an optional data. I checked the getDataAndVersion caller `ProducerIdManager`, there is a handling for empty data which I feel we should have as well. \r\nAdditionally, I think since we haven't implemented the write path yet, could we get a ticket to write down a short description on how the write path shall look like, by defining the different cases like:\r\n```\r\nempty dataBytes, valid version \r\nvalid dataBytes, valid version \r\nempty dataBytes, unknown version \r\nvalid dataBytes, unknown version \r\n```\r\nif that makes sense, so that we could keep track of the design decisions we made in the read path PR when implementing the write path.",
        "createdAt" : "2020-05-21T03:31:57Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "6253568f-2a23-46b7-a4f5-306a71344a13",
        "parentId" : "b4c649c5-5c44-4ed1-9cde-4226b69ff676",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "I have added documentation here in this method describing all the cases.\r\nThe empty data case should never happen and can indicate a corruption. The reason is that we always return non-empty data in `FeatureZNode.encode`, so the ZK node content should never empty.\r\n\r\nYes, I can add some more info to KAFKA-10028 or in the write path PR summary.",
        "createdAt" : "2020-05-22T08:50:49Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e3ef56c552da13226c1fcc472c8d339fb98c7a8",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +85,89 @@      //                                           ZK node is absent. Therefore dataBytes should be empty in such\n      //                                           a case.\n      if (version == ZkVersion.UnknownVersion) {\n        info(s\"Feature ZK node at path: $featureZkNodePath does not exist\")\n        FinalizedFeatureCache.clear()"
  },
  {
    "id" : "b49502db-4a76-4890-bbf9-24381ac48fa9",
    "prId" : 8680,
    "prUrl" : "https://github.com/apache/kafka/pull/8680#pullrequestreview-416042080",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "487a1694-112a-4749-934a-ee98818d34f1",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we summary the possible thrown error code in the comment as well? For example, does a JSON deserialization error should be treated as fatal?",
        "createdAt" : "2020-05-21T03:33:03Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "6147e577-6ca8-4a85-bef0-fd3681380c82",
        "parentId" : "487a1694-112a-4749-934a-ee98818d34f1",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Done. Yes, I feel JSON deserialization should be treated as fatal. It should never happen, and, can indicate corruption.",
        "createdAt" : "2020-05-22T08:01:36Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e3ef56c552da13226c1fcc472c8d339fb98c7a8",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +62,66 @@     *           FinalizedFeatureCache.\n     */\n    def updateLatestOrThrow(): Unit = {\n      maybeNotifyOnce.foreach(notifier => {\n        if (notifier.getCount != 1) {"
  },
  {
    "id" : "aafe5195-e742-4071-8e80-0ac7c6c29bb9",
    "prId" : 8680,
    "prUrl" : "https://github.com/apache/kafka/pull/8680#pullrequestreview-416042080",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf865bad-0f6c-449a-90db-c8e52883a25f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "For an educational question, does the zkClient have a separate thread to do the node change monitoring?",
        "createdAt" : "2020-05-21T03:47:38Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "3d7313d2-91dc-47f2-a316-1d1e514b1cbe",
        "parentId" : "bf865bad-0f6c-449a-90db-c8e52883a25f",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Yes. Here is the documentation explaining the same: https://zookeeper.apache.org/doc/r3.5.7/zookeeperProgrammers.html#Java+Binding.\r\n\r\n> When a ZooKeeper object is created, two threads are created as well: an IO thread and an event thread. All IO happens on the IO thread (using Java NIO). All event callbacks happen on the event thread. Session maintenance such as reconnecting to ZooKeeper servers and maintaining heartbeat is done on the IO thread. Responses for synchronous methods are also processed in the IO thread. All responses to asynchronous methods and watch events are processed on the event thread.",
        "createdAt" : "2020-05-22T08:36:30Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e3ef56c552da13226c1fcc472c8d339fb98c7a8",
    "line" : 216,
    "diffHunk" : "@@ -1,1 +214,218 @@    thread.start()\n    zkClient.registerStateChangeHandler(ZkStateChangeHandler)\n    zkClient.registerZNodeChangeHandlerAndCheckExistence(FeatureZNodeChangeHandler)\n    val ensureCacheUpdateOnce = new FeatureCacheUpdater(\n      FeatureZNodeChangeHandler.path, Some(new CountDownLatch(1)))"
  },
  {
    "id" : "a808b183-3fe6-4427-a1f6-b3c734c1f3c8",
    "prId" : 8680,
    "prUrl" : "https://github.com/apache/kafka/pull/8680#pullrequestreview-416042080",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8300621-0b4c-409e-ac11-1d56f43fc5c6",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Does the order matter here? I was wondering if there is any concurrent issue if we unregister before the queue and thread get cleaned up.",
        "createdAt" : "2020-05-21T03:49:45Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "a7b1c8a0-9b7c-43b9-a9a3-66148b5865ad",
        "parentId" : "b8300621-0b4c-409e-ac11-1d56f43fc5c6",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "The order probably doesn't matter in this case. But logically I decided to follow the below order since I could reason about it better:\r\n1. Stop the inflow of new events\r\n2. Clear pending events\r\n3. Stop the processing of all events",
        "createdAt" : "2020-05-22T08:43:40Z",
        "updatedAt" : "2020-06-11T05:59:01Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e3ef56c552da13226c1fcc472c8d339fb98c7a8",
    "line" : 236,
    "diffHunk" : "@@ -1,1 +234,238 @@  def close(): Unit = {\n    zkClient.unregisterStateChangeHandler(ZkStateChangeHandler.name)\n    zkClient.unregisterZNodeChangeHandler(FeatureZNodeChangeHandler.path)\n    queue.clear()\n    thread.shutdown()"
  }
]