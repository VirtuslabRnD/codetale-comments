[
  {
    "id" : "71e811f3-078b-440b-a6bf-d3e003e015ba",
    "prId" : 3960,
    "prUrl" : "https://github.com/apache/kafka/pull/3960#pullrequestreview-140809034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "parentId" : null,
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "We also need to update DeleteTopicsRequest/DeleteTopicsResponse request/response classes to V3.",
        "createdAt" : "2018-07-26T15:58:08Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      },
      {
        "id" : "3fd11012-77a3-408a-8136-cada4c730828",
        "parentId" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "authorId" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "body" : "Done!",
        "createdAt" : "2018-07-26T16:29:48Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc67c0df33ed26af6c5af45f32d139b7dbe87738",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1541,1545 @@      sendResponseCallback(results)\n    } else if (!config.deleteTopicEnable) {\n      val error = if (request.context.apiVersion < 3) Errors.INVALID_REQUEST else Errors.TOPIC_DELETION_DISABLED\n      val results = deleteTopicRequest.topics.asScala.map { topic =>\n        (topic, error)"
  },
  {
    "id" : "7a02ce24-97db-4c45-bb6f-60e548ac6dbd",
    "prId" : 5074,
    "prUrl" : "https://github.com/apache/kafka/pull/5074#pullrequestreview-123536379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We don't guarantee this, do we? It seems like we only guarantee that we won't exceed the quota if ISR traffic is below the quota.",
        "createdAt" : "2018-05-25T23:24:48Z",
        "updatedAt" : "2018-05-25T23:25:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "f06aeb1d-d791-4816-a754-3ebff5163e30",
        "parentId" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Right, we guarantee that if the quota is set high enough.",
        "createdAt" : "2018-05-25T23:30:18Z",
        "updatedAt" : "2018-05-25T23:30:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f2fc60cfd9188a3a530d5ae8f6ad2ca305a89add",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +668,672 @@\n  // Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication\n  // traffic doesn't exceed quota.\n  private def sizeOfThrottledPartitions(versionId: Short,\n                                        unconvertedResponse: FetchResponse,"
  },
  {
    "id" : "1afefefa-5c98-4e0f-8212-72c7871069f9",
    "prId" : 5972,
    "prUrl" : "https://github.com/apache/kafka/pull/5972#pullrequestreview-196171710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since results is a set, is that check still needed?",
        "createdAt" : "2019-01-23T18:35:03Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "8b2f2193-08d7-4418-ade9-2a268367f61a",
        "parentId" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Just to be clear, it's a multiset.  This was done specifically to preserve the existing behavior where duplicate entries caused us to return an error code, rather than triggering a deserialization error (which would show up as a disconnection)",
        "createdAt" : "2019-01-24T18:00:56Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "83e42e5fc686792f41bd087a5b4b2270871bfcb7",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +1423,1427 @@      val hasClusterAuthorization = authorize(request.session, Create, Resource.ClusterResource)\n      results.asScala.foreach(topic => {\n        if (results.findAll(topic.name()).size() > 1) {\n          topic.setErrorCode(Errors.INVALID_REQUEST.code())\n          topic.setErrorMessage(\"Found multiple entries for this topic.\")"
  },
  {
    "id" : "2a97d99a-8002-49e6-beef-05c218a15007",
    "prId" : 5991,
    "prUrl" : "https://github.com/apache/kafka/pull/5991#pullrequestreview-182902344",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just thinking about this a little, do you think there's much advantage to having a separate error code? Whether it is `OFFSET_NOT_AVAILABLE` or `LEADER_NOT_AVAILABLE`, the client will just retry.\r\n\r\nAlso, it might be a good idea to update `Fetcher.handleListOffsetResponse` to explicitly check the expected error codes. We can probably skip the log warning in these cases and print a debug message since this is an expected scenario.",
        "createdAt" : "2018-12-04T18:14:01Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b21c7285-5752-4ad6-b4a3-9a96ff301a01",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "The motivation of a new exception was to give a more precise reason for not returning the offsets. Sticking with `LEADER_NOT_AVAILABLE` would eliminate any change required to the protocol, which is nice, but maybe runs the risk of overloading the error code. Looking at usages of `LEADER_NOT_AVAILABLE` in the code, it doesn't actually look all that widely used, so maybe adding another usage of it for this case isn't so bad. \r\n\r\n@hachikuji @cmccabe WDYT?",
        "createdAt" : "2018-12-04T19:12:28Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "13ab09a8-d622-47f6-a676-1e16981a1ff9",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "> Fetcher.handleListOffsetResponse to explicitly check the expected error codes\r\n\r\nSounds good. Would handling `LEADER_NOT_AVAILABLE` and retrying have any unintended consequences with other uses of this error code?",
        "createdAt" : "2018-12-04T19:13:14Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "c3edb389-b1d4-497a-8f27-1ba1f59296f2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I'm not sure. We have tended to regret when we didn't provide more explicit error codes, so perhaps we should just stick with what's in the KIP. \r\n\r\n> Sounds good. Would handling LEADER_NOT_AVAILABLE and retrying have any unintended consequences with other uses of this error code?\r\n\r\nI didn't see any explicit logic to handle it in `Fetcher`, so I think we'd be hitting this case:\r\n```java\r\nlog.warn(\"Attempt to fetch offsets for partition {} failed due to: {}\", topicPartition, error.message());\r\npartitionsToRetry.add(topicPartition);\r\n```\r\nDo we have any current scenarios in the ListOffset handler where we could raise `LEADER_NOT_AVAILABLE`?",
        "createdAt" : "2018-12-06T02:58:49Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "e8b074b1-6eb7-4014-9467-ebc286aa24e2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "As far as I can tell, `LEADER_NOT_AVAILABLE` is only returned when creating a topic, fetching metadata, and deleting records. I'll continue with the new error as indicated in the KIP and rev the IBP",
        "createdAt" : "2018-12-06T14:42:31Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "48fa917c-4ffd-453e-8938-8e0fab2c2b85",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Yes, we discussed this in the KIP.  It is good to be specific with error codes.  +1.",
        "createdAt" : "2018-12-07T22:48:08Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "54d8dd54100b18957db07485d9ee0c37ad4476c8",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +875,879 @@          case e: OffsetNotAvailableException =>\n            if(request.header.apiVersion >= 5) {\n              buildErrorResponse(Errors.forException(e))\n            } else {\n              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)"
  },
  {
    "id" : "5536b0e1-1f68-44ff-a356-ec35b42d7b70",
    "prId" : 6172,
    "prUrl" : "https://github.com/apache/kafka/pull/6172#pullrequestreview-194375653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "What's the intended behaviour if `transactionalId == null && produceRequest.hasTransactionalRecords`?",
        "createdAt" : "2019-01-19T04:14:34Z",
        "updatedAt" : "2019-01-19T04:14:35Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "827717ae-cc3a-4cdb-b107-7e03ec768026",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Returning `TRANSACTIONAL_ID_AUTHORIZATION_FAILED` seemed like the best bet. `INVALID_REQUEST` might be another option. Currently, without this check, the authorizer raises an NPE which causes the connection to terminate. We could push the null checks into the authorizor as well.",
        "createdAt" : "2019-01-20T01:09:15Z",
        "updatedAt" : "2019-01-20T01:35:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "8ba7773b-756b-4e8c-9d65-b124ddd2e11e",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Makes sense. I guess one can say that the `null` transaction id is never authorized.",
        "createdAt" : "2019-01-20T01:20:19Z",
        "updatedAt" : "2019-01-20T01:20:19Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b9945c7fe740373681b8b96a15c00e699b6a4fc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +390,394 @@\n    if (produceRequest.hasTransactionalRecords) {\n      val isAuthorizedTransactional = produceRequest.transactionalId != null &&\n        authorize(request.session, Write, Resource(TransactionalId, produceRequest.transactionalId, LITERAL))\n      if (!isAuthorizedTransactional) {"
  },
  {
    "id" : "de13e4d1-248a-407d-a156-3faccc0a8372",
    "prId" : 6408,
    "prUrl" : "https://github.com/apache/kafka/pull/6408#pullrequestreview-232427016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could probably modify `prepareResponse` to take the throttle time and remove this.",
        "createdAt" : "2019-04-27T23:24:58Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a9ae8e81-b4ba-4ea7-aeba-fe23130916fb",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "The throttle time is only used in 2 places so I kept it this way. I'm happy to change it if you think that's really better",
        "createdAt" : "2019-04-30T19:47:34Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "7bd9c359-85db-4e74-95cb-6eb45bf4abe6",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "No strong preference. Just a suggestion",
        "createdAt" : "2019-04-30T21:58:19Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "25f2ac3741e53e4e7fc1b4da0e3cd3523cf2209d",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1197,1201 @@\n      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n          new FindCoordinatorResponse(\n              new FindCoordinatorResponseData()"
  },
  {
    "id" : "e6ac4908-4e4a-4a94-9cae-9f026387c89f",
    "prId" : 6686,
    "prUrl" : "https://github.com/apache/kafka/pull/6686#pullrequestreview-240919946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60346547-c70c-4c6d-8fe7-23a6699c341b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be worth a comment explaining this filtering.",
        "createdAt" : "2019-05-23T02:17:16Z",
        "updatedAt" : "2019-05-29T01:18:29Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d53f267c91cc93478d817214f47a6fd2ec20691",
    "line" : 222,
    "diffHunk" : "@@ -1,1 +2461,2465 @@    ): Unit = {\n      sendResponseMaybeThrottle(request, requestThrottleMs => {\n        val adjustedResults = if (electionRequest.data().topicPartitions() == null) {\n          /* When performing elections across all of the partitions we should only return\n           * partitions for which there was an eleciton or resulted in an error. In other"
  },
  {
    "id" : "8c2939cc-c475-4a7c-991b-3ed94886a784",
    "prId" : 6714,
    "prUrl" : "https://github.com/apache/kafka/pull/6714#pullrequestreview-266889526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just want to be clear that the top-level error code isn't giving us much benefit other than easing compatibility since we are always setting the member-level error codes. This sort of goes back to the question I had about allowing empty list of members. If we removed some of the validations, then we could just provide the top level error code in the response.",
        "createdAt" : "2019-07-25T20:42:18Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a38f3050-69ab-4c0c-a553-55c0d13d00ba",
        "parentId" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I see your point, makes sense.",
        "createdAt" : "2019-07-25T21:15:04Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab085e9764aa35dece48891a8d707b743b5bf711",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +1557,1561 @@        new LeaveGroupResponse(new LeaveGroupResponseData()\n          .setThrottleTimeMs(requestThrottleMs)\n          .setErrorCode(Errors.GROUP_AUTHORIZATION_FAILED.code)\n        )\n      })"
  },
  {
    "id" : "a68988ca-95e3-4f0e-a20c-68e1c9326653",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-268909360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I've opted out of having the INVALID_REASSIGNMENT error. Mainly because it's tricky to know when a replica is intermittently offline, as the znode and controller memory cache store only the online brokers. ",
        "createdAt" : "2019-07-30T18:00:18Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "d1ec0f37-61b7-4225-895a-96817b788d7a",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We could have some preliminary checks here for an empty list or negative IDs though",
        "createdAt" : "2019-07-30T18:00:56Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "484d6e14-365e-4502-918d-f316eaaa8911",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We discussed here and I changed my mind that it's a goo idea to have - https://github.com/apache/kafka/pull/7120#discussion_r308861346",
        "createdAt" : "2019-07-31T10:05:06Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +2342,2346 @@          if (reassignablePartition.replicas() == null)\n            tp -> None // revert call\n          else\n            tp -> Some(reassignablePartition.replicas().asScala.map(_.toInt))\n      }"
  },
  {
    "id" : "d43d0394-6b6e-44bf-b9e3-b209c5322152",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-283907403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "is flatMap really needed here, or should it be map?",
        "createdAt" : "2019-08-19T23:53:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "8f9ac6e8-af60-4231-b29a-15a6de8ccda9",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Should be `flatMap` since we do another map inside on the partitions indices to convert to TopicPartition and we want a big list of TopicPartitions, rather than one for each topic",
        "createdAt" : "2019-08-29T08:17:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "e817e4eb-7981-46e8-9193-4f7fa399a5e2",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "thanks for the explanation",
        "createdAt" : "2019-09-04T21:29:59Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +2384,2388 @@    val partitionsOpt = listPartitionReassignmentsRequest.data().topics() match {\n      case topics: Any =>\n        Some(topics.iterator().asScala.flatMap { topic =>\n          topic.partitionIndexes().iterator().asScala\n            .map { tp => new TopicPartition(topic.name(), tp) }"
  },
  {
    "id" : "872685f9-63d9-4bb5-801e-ef4380bff247",
    "prId" : 7381,
    "prUrl" : "https://github.com/apache/kafka/pull/7381#pullrequestreview-297149707",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "WDYT about adding a new error code here? If I understand correctly, the client will get this error code when sending a valid ApiVersionsRequest with an invalid client name/version. Something more indicative of the actual problem might be nice.",
        "createdAt" : "2019-10-01T20:56:12Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "8807771e-7ff5-4a0c-abd4-b197fef071b6",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "You have a fair point. Would you go with something like `INVALID_NAME_OR_VERSION` for instance? I have thought about this when I wrote the KIP and went with this error. My reasoning was that we may add new fields in the future (e.g. hostname?) so I wanted to have a generic error which is not tight to the client/version cases. `INVALID_REQUEST` sounds quite appropriate for this.\r\n\r\nFurthermore, as the client name and version are set by the developer of a client, it should rarely happen when end users use the client library. ",
        "createdAt" : "2019-10-02T07:00:36Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "ae149f6b-8f6b-412f-8353-160cd55765fa",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "This should be pretty rare, so it's probably not worth its own error code.  I do wonder if there should be some kind of log message, since otherwise this would be hard for a broker operator to see.",
        "createdAt" : "2019-10-03T17:59:10Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "b1246dc2-838e-4bcf-9cc2-60ceadad6cc1",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I thought about adding a log message as well and I decided to not do it for two reasons:\r\n1) This should be pretty rare and should mainly happen during the development of the client. In this case, the request log could be used; and\r\n2) If a buggy client would be released with an invalid ApiVersionsRequest, I wanted to avoid flooding the logs with something which is not really actionable for a broker operator. What would he do with this information?",
        "createdAt" : "2019-10-03T18:52:40Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "701ae98a-0110-49ab-8644-8edbe023d69f",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Those are fair points.  Let's leave it as-is for now.  As you say, the request log will give some hints in this scenario.",
        "createdAt" : "2019-10-03T21:02:39Z",
        "updatedAt" : "2019-10-03T21:02:39Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc07639d6db7c5712730e5130ad67fb21504f5e8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1618,1622 @@        apiVersionRequest.getErrorResponse(requestThrottleMs, Errors.UNSUPPORTED_VERSION.exception)\n      else if (!apiVersionRequest.isValid)\n        apiVersionRequest.getErrorResponse(requestThrottleMs, Errors.INVALID_REQUEST.exception)\n      else\n        ApiVersionsResponse.apiVersionsResponse(requestThrottleMs,"
  },
  {
    "id" : "ead5ceb9-28b1-4072-b646-0b2978343299",
    "prId" : 7813,
    "prUrl" : "https://github.com/apache/kafka/pull/7813#pullrequestreview-349864022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This actually seems like an intuitive time to set the local complete time. I guess the reason we set it in `RequestChannel.Response` also is that we are trying to set it consistently with `responseCompleteTimeNanos`. I can't really think of a better solution than what you have here, but it might at least be helpful to add a comment of explanation?",
        "createdAt" : "2020-01-18T20:31:59Z",
        "updatedAt" : "2020-01-21T21:45:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0402e129-26c6-49f4-ac55-c4fbb112967b",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "I was looking at this code and the way it works today is super confusing. :) I think this change makes sense. However, I was curious how you noticed this. Was there a delay in getting to this point somehow? In theory, the value at this point should be very similar to the value we set during processing.",
        "createdAt" : "2020-01-23T16:07:01Z",
        "updatedAt" : "2020-01-23T16:07:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "3b99c5bd-417b-4843-8709-1f1ef8d20e5d",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "98b12f1a-2624-4608-85a1-ec49503fd316",
        "body" : "From what I remember, the value was close enough that I didn't consider it worth looking into. I encountered it when I added debug metrics to further subdivide the local time, and there appeared to be lost time, i.e. the sum wasn't adding to the whole.",
        "createdAt" : "2020-01-23T19:04:14Z",
        "updatedAt" : "2020-01-23T19:04:15Z",
        "lastEditedBy" : "98b12f1a-2624-4608-85a1-ec49503fd316",
        "tags" : [
        ]
      },
      {
        "id" : "280c2a05-1c72-4c3d-94fc-7fd850e49467",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Makes sense, thanks.",
        "createdAt" : "2020-01-29T05:09:50Z",
        "updatedAt" : "2020-01-29T05:09:50Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aeda982db0838fcce7ca8a1fdad6d995a60c269e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +181,185 @@      // The local completion time may be set while processing the request. Only record it if it's unset.\n      if (request.apiLocalCompleteTimeNanos < 0)\n        request.apiLocalCompleteTimeNanos = time.nanoseconds\n    }\n  }"
  },
  {
    "id" : "ca15088b-27ce-4c70-b835-ee3a659a86bf",
    "prId" : 7897,
    "prUrl" : "https://github.com/apache/kafka/pull/7897#pullrequestreview-340730014",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0b5b4be-f184-4b78-9f0a-730930267736",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: why UNKNOWN_GENERATION_ID and UNKNOWN_PROTOCOL belongs to response while UNKNOWN_MEMBER_ID belongs to request? If there's no real good reason let's put them in a single class.",
        "createdAt" : "2020-01-08T22:07:23Z",
        "updatedAt" : "2020-01-14T20:20:27Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a7f3953f-2638-482b-930c-b4730dcc21cb",
        "parentId" : "e0b5b4be-f184-4b78-9f0a-730930267736",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I think it makes sense to move all the constant to request class.",
        "createdAt" : "2020-01-09T18:36:32Z",
        "updatedAt" : "2020-01-14T20:20:27Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "943bdf3604b662dfd20e7cfd586ada10e3412bc8",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1412,1416 @@      sendResponseCallback(JoinGroupResult(\n        List.empty,\n        JoinGroupRequest.UNKNOWN_MEMBER_ID,\n        JoinGroupRequest.UNKNOWN_GENERATION_ID,\n        JoinGroupRequest.UNKNOWN_PROTOCOL,"
  },
  {
    "id" : "b2e9217d-1d25-4d14-bb35-204395572c53",
    "prId" : 8238,
    "prUrl" : "https://github.com/apache/kafka/pull/8238#pullrequestreview-375429585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f34b7728-9b3c-4b6f-9eea-10fd63d2a8c5",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Could we add tests in `KafkaApisTest` to cover this one?",
        "createdAt" : "2020-03-16T17:45:14Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "acb64f32f6fc2353dcaec2be44d05c6cd1a77b2d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1398,1402 @@  }\n\n  def handleListGroupsRequest(request: RequestChannel.Request): Unit = {\n    val listGroupsRequest = request.body[ListGroupsRequest]\n    val states = if (listGroupsRequest.data.statesFilter == null)"
  },
  {
    "id" : "5f2a8ca5-96b2-42e2-a639-ffd3cb5700f4",
    "prId" : 8253,
    "prUrl" : "https://github.com/apache/kafka/pull/8253#pullrequestreview-376246615",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27ba51fc-27f8-4a6f-b207-c738ec52bd72",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just doublechecking, but does this cover any client version prior to 2.0? I think it would be good to mention this in the comment.",
        "createdAt" : "2020-03-17T17:24:05Z",
        "updatedAt" : "2020-03-18T06:02:55Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a213332e3d2cd8412e3ce81e81d7348d17f86f9",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +2217,2221 @@        // txn commit protocol >= 2 (version 2.3 and onwards) are guaranteed to have\n        // the fix to check for the loading error.\n        if (txnOffsetCommitRequest.version < 2) {\n          combinedCommitStatus.foreach { case (topicPartition, error) =>\n            if (error == Errors.COORDINATOR_LOAD_IN_PROGRESS) {"
  },
  {
    "id" : "63854b5d-a000-4997-baec-2fc1fabe56b7",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-445516197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1afcca4-2181-4381-a115-b8f1bded4966",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "nit: The indentation looks weird.",
        "createdAt" : "2020-07-03T14:58:06Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "f0f04b98-995f-48c9-875f-e0bc9e97d886",
        "parentId" : "b1afcca4-2181-4381-a115-b8f1bded4966",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "It looks weird but it's 2 to the right which should be \"correct\"",
        "createdAt" : "2020-07-09T11:09:53Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +960,964 @@        .setName(topic.name)\n        .setPartitions(topic.partitions.asScala.map(partition =>\n          new ListOffsetPartitionResponse()\n            .setPartitionIndex(partition.partitionIndex)\n            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)"
  },
  {
    "id" : "c1bf59aa-3a3b-41e7-8918-8d87bfcc0150",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-466839774",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "We could use a scala `Option` now.",
        "createdAt" : "2020-07-03T15:09:24Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "722d39be-7ce6-4f4e-bc4c-05fc5300fec5",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "What do you mean here? @dajac ",
        "createdAt" : "2020-07-31T16:00:51Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "464c3d38-bdde-41a9-b561-9c48de48d77b",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I was asking if we could use a Scala Option instead of the Java Optional. Keeping the Optional as-is is the way to go as we will likely add support for it in the auto-generated protocol to avoid having to manually handle sentinel values.",
        "createdAt" : "2020-08-04T09:10:46Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "fdce84ac-ab3a-4d8c-b5e9-ab204a8ad660",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "@mimaison WDYT? I'm neutral.",
        "createdAt" : "2020-08-11T17:55:45Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "07457d52-d02c-4459-ad95-561779b02700",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "Yes let's keep Optional here",
        "createdAt" : "2020-08-13T14:52:24Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +1045,1049 @@              partition.timestamp,\n              isolationLevelOpt,\n              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),\n              fetchOnlyFromLeader)\n"
  },
  {
    "id" : "3ee0a6c8-d0f4-45c3-b2b9-af1bd0cddfa9",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-459264101",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6010eafb-fa14-4e64-8fdb-844c5fe49ca9",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Redundant braces.",
        "createdAt" : "2020-07-31T15:59:36Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 231,
    "diffHunk" : "@@ -1,1 +1048,1052 @@              fetchOnlyFromLeader)\n\n            val response = foundOpt match {\n              case Some(found) =>\n                val partitionResponse = new ListOffsetPartitionResponse()"
  },
  {
    "id" : "23f70fd5-7b5c-4f76-9613-ec4a4cc8e85f",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-491452490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2aed618f-4158-4589-8416-7fda3d5b2c2f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Are we missing storage exception here?",
        "createdAt" : "2020-09-17T19:36:41Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "2e3ba70f-f64d-4704-94fa-8613becfea34",
        "parentId" : "2aed618f-4158-4589-8416-7fda3d5b2c2f",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "This message has not changed. The way Github shows the diff here is confusing. If you look at https://github.com/apache/kafka/pull/8295/files#diff-d45970e44e2636ec847b63ac71827b71L944 on the right (which is the matching logic) you'll see it's already there.",
        "createdAt" : "2020-09-18T13:14:29Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +981,985 @@            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n        } catch {\n          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cases since these error messages\n          // are typically transient and there is no value in logging the entire stack trace for the same\n          case e @ (_ : UnknownTopicOrPartitionException |"
  },
  {
    "id" : "911fef65-4e7a-449c-9a10-947470c79fbd",
    "prId" : 8311,
    "prUrl" : "https://github.com/apache/kafka/pull/8311#pullrequestreview-390824016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2157be9e-78f1-4128-a2d8-accc10ad5950",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "While we are refactoring this, could we add a unit test in `KafkaApisTest`?",
        "createdAt" : "2020-04-09T14:52:57Z",
        "updatedAt" : "2020-06-04T13:26:20Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "2af415b22d9671ee7aff320f104d975b084ea450",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +2589,2593 @@  }\n\n  def handleAlterReplicaLogDirsRequest(request: RequestChannel.Request): Unit = {\n    val alterReplicaDirsRequest = request.body[AlterReplicaLogDirsRequest]\n    if (authorize(request.context, ALTER, CLUSTER, CLUSTER_NAME)) {"
  },
  {
    "id" : "da16e72b-845d-4192-9e9c-2538d3f06e94",
    "prId" : 8432,
    "prUrl" : "https://github.com/apache/kafka/pull/8432#pullrequestreview-388432910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70070e24-be5f-470f-aa9a-dbf1c090dbd5",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We can replace the next line by `uniqueResourceNames.toSet`? Doesn't change the behavior, but slightly better performance if there were indeed duplicates.",
        "createdAt" : "2020-04-06T16:11:51Z",
        "updatedAt" : "2020-04-06T16:52:14Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "e2a8fad4-d3da-4520-a255-7dceb77b9815",
        "parentId" : "70070e24-be5f-470f-aa9a-dbf1c090dbd5",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Yes.",
        "createdAt" : "2020-04-06T16:46:05Z",
        "updatedAt" : "2020-04-06T16:52:14Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f71ff568868ce87a89590d7b903b9f30e280c3e",
    "line" : 505,
    "diffHunk" : "@@ -1,1 +2913,2917 @@          .filter { case (authzResult, _) => authzResult == AuthorizationResult.ALLOWED }\n          .map { case (_, resourceName) => resourceName }.toSet\n      case None =>\n        uniqueResourceNames.toSet\n    }"
  },
  {
    "id" : "a0d5ffea-6b44-4fa5-8d23-760aeadc5cd4",
    "prId" : 8509,
    "prUrl" : "https://github.com/apache/kafka/pull/8509#pullrequestreview-398790772",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "64c12ed2-a11a-4b93-acf0-ccb94b45a40f",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "nit: Alignment of the comment looks a bit weird. I would align it with the if/else.",
        "createdAt" : "2020-04-23T06:24:16Z",
        "updatedAt" : "2020-04-23T21:15:47Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "d952854018b2862f48d23dcce9db682a16923ab0",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +3087,3091 @@    else {\n      // brokerEpochInRequest > controller.brokerEpoch is possible in rare scenarios where the controller gets notified\n      // about the new broker epoch and sends a control request with this epoch before the broker learns about it\n      brokerEpochInRequest < controller.brokerEpoch\n    }"
  },
  {
    "id" : "7e8f4c45-1777-4ec6-8652-6e1ec7aa51f9",
    "prId" : 9032,
    "prUrl" : "https://github.com/apache/kafka/pull/9032#pullrequestreview-461842401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dbefcb08-7092-4c77-bc15-176a7672199d",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "I think we should also not allow users who authenticated using delegation tokens to create or update users. We don't allow these users to create new tokens, it would be odd if they could create a new user or the password of the user of the token.",
        "createdAt" : "2020-08-05T19:44:12Z",
        "updatedAt" : "2020-09-02T17:54:03Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      }
    ],
    "commit" : "04a882b1794f90bbe002f460803cda9a2beebccc",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +3031,3035 @@      sendResponseMaybeThrottle(request, requestThrottleMs =>\n        alterUserScramCredentialsRequest.getErrorResponse(requestThrottleMs, Errors.NOT_CONTROLLER.exception))\n    } else if (authorize(request.context, ALTER, CLUSTER, CLUSTER_NAME)) {\n      val result = adminManager.alterUserScramCredentials(\n        alterUserScramCredentialsRequest.data.upsertions().asScala, alterUserScramCredentialsRequest.data.deletions().asScala)"
  },
  {
    "id" : "617a9ff2-4b7c-4022-ad45-5ed677c97d16",
    "prId" : 9103,
    "prUrl" : "https://github.com/apache/kafka/pull/9103#pullrequestreview-518891546",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bbfbfec-6e04-487a-ae1b-bf21ea06c598",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We should have a check at the beginning of `handle` to restrict the \"forwardable\" APIs. ",
        "createdAt" : "2020-10-21T18:24:02Z",
        "updatedAt" : "2020-11-04T19:19:59Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "1f4a8fe1-d967-4822-aa64-3b36d177be22",
        "parentId" : "5bbfbfec-6e04-487a-ae1b-bf21ea06c598",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Not sure why this was resolved. I don't see the check. Basically the first thing we should do in `handle` is check whether we have an envelope request and if it is authorized.",
        "createdAt" : "2020-10-28T18:14:32Z",
        "updatedAt" : "2020-11-04T19:19:59Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9844c4dc13337a68b89d6e1acf772af9246e221",
    "line" : 119,
    "diffHunk" : "@@ -1,1 +209,213 @@        case ApiKeys.SASL_HANDSHAKE => handleSaslHandshakeRequest(request)\n        case ApiKeys.API_VERSIONS => handleApiVersionsRequest(request)\n        case ApiKeys.CREATE_TOPICS => maybeForward(request, handleCreateTopicsRequest)\n        case ApiKeys.DELETE_TOPICS => handleDeleteTopicsRequest(request)\n        case ApiKeys.DELETE_RECORDS => handleDeleteRecordsRequest(request)"
  },
  {
    "id" : "87ccac11-6d76-434d-b629-9fe0600f0507",
    "prId" : 9130,
    "prUrl" : "https://github.com/apache/kafka/pull/9130#pullrequestreview-492810813",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03faebf0-3f4f-44d9-bef5-c189671c6d70",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I feel this is not necessary since we would throw in `processCompletedReceives` at SocketServer already as `processChannelException`, but no harm guarding them as well.",
        "createdAt" : "2020-09-20T23:12:16Z",
        "updatedAt" : "2020-09-22T15:59:30Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4e3d9962-66a5-4c3c-87b7-0920304a2ba0",
        "parentId" : "03faebf0-3f4f-44d9-bef5-c189671c6d70",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Right. We should never reach here, but I thought we should make the `match` complete to avoid warnings.",
        "createdAt" : "2020-09-21T17:00:01Z",
        "updatedAt" : "2020-09-22T15:59:30Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "385f3780cd4e3bfbe43741206e705500e78783a6",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +187,191 @@        // Until we are ready to integrate the Raft layer, these APIs are treated as\n        // unexpected and we just close the connection.\n        case ApiKeys.VOTE => closeConnection(request, util.Collections.emptyMap())\n        case ApiKeys.BEGIN_QUORUM_EPOCH => closeConnection(request, util.Collections.emptyMap())\n        case ApiKeys.END_QUORUM_EPOCH => closeConnection(request, util.Collections.emptyMap())"
  },
  {
    "id" : "8a0e39eb-957b-41d3-9d17-b5622fe9fb35",
    "prId" : 9579,
    "prUrl" : "https://github.com/apache/kafka/pull/9579#pullrequestreview-581940829",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a258e097-fbf8-4796-87d5-267ea3633489",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Pre-existing issue. `CoordinatorType.forId` returns `IllegalArgumentException` if the key type is unknown. That will get translated to UNKNOWN_SERVER_ERROR. It would be better to return INVALID_REQUEST.",
        "createdAt" : "2021-02-03T04:43:21Z",
        "updatedAt" : "2021-02-06T18:07:13Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d21fc4693b289caeb92dbcfcb9d19d8455d7c0e",
    "line" : 288,
    "diffHunk" : "@@ -1,1 +1320,1324 @@      requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n    else {\n      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n        case CoordinatorType.GROUP =>\n          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)"
  },
  {
    "id" : "9492b724-ee14-44da-a357-f5d2ae77abc0",
    "prId" : 9630,
    "prUrl" : "https://github.com/apache/kafka/pull/9630#pullrequestreview-536267540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3e3bc5a-be90-4f32-947d-f43ecd3e24fc",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "ditto",
        "createdAt" : "2020-11-23T08:52:56Z",
        "updatedAt" : "2020-12-03T11:58:01Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a9f87a118c051bfc6e6a944ef21db79db9b5068",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +2608,2612 @@    val endOffsetsForAuthorizedPartitions = replicaManager.lastOffsetForLeaderEpoch(authorizedTopics)\n    val endOffsetsForUnauthorizedPartitions = unauthorizedTopics.map { offsetForLeaderTopic =>\n      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>\n        new EpochEndOffset()\n          .setPartition(offsetForLeaderPartition.partition)"
  },
  {
    "id" : "90551e97-b2f7-4f8c-a55a-5c2292068fe9",
    "prId" : 9758,
    "prUrl" : "https://github.com/apache/kafka/pull/9758#pullrequestreview-555923158",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44822130-ca7b-4e84-bb21-f8d97315f006",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "@ijuma This is the only case that we create ```LazyDownConversionRecords``` in production. Through this PR, this case can get rid of generic ```FetchResponse.PartitionData```. Hence, we can remove generic from ```FetchResponse.PartitionData``` after this PR goes in trunk.",
        "createdAt" : "2020-12-19T07:08:26Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae25551171fd4e3b889ca94d494e3207545320e5",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +725,729 @@    }\n\n    def maybeConvertFetchedData(tp: TopicPartition,\n                                partitionData: FetchResponseData.PartitionData): FetchResponseData.PartitionData = {\n      val logConfig = replicaManager.getLogConfig(tp)"
  },
  {
    "id" : "a1995d02-7b8e-49ec-8fbd-54c6f8b08206",
    "prId" : 9758,
    "prUrl" : "https://github.com/apache/kafka/pull/9758#pullrequestreview-600213558",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28e3e355-be6a-459c-983b-34d513464866",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Do we have to copy like this or can we mutate the response?",
        "createdAt" : "2021-02-27T20:31:14Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "80697efa-ed8e-4697-96af-1caa0199749f",
        "parentId" : "28e3e355-be6a-459c-983b-34d513464866",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "It created copy before so I don't change the behavior in this PR. We can investigate it in separate PR :)",
        "createdAt" : "2021-02-28T03:28:41Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "b4f2541a-a49f-4358-bd94-660c47aca59e",
        "parentId" : "28e3e355-be6a-459c-983b-34d513464866",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "https://issues.apache.org/jira/browse/KAFKA-12387",
        "createdAt" : "2021-02-28T03:33:21Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae25551171fd4e3b889ca94d494e3207545320e5",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +772,776 @@                  .setAbortedTransactions(partitionData.abortedTransactions)\n                  .setRecords(new LazyDownConversionRecords(tp, unconvertedRecords, magic, fetchContext.getFetchOffset(tp).get, time))\n                  .setPreferredReadReplica(partitionData.preferredReadReplica())\n              } catch {\n                case e: UnsupportedCompressionTypeException =>"
  },
  {
    "id" : "b2db6922-5111-43d0-bff6-0ca22f85a87f",
    "prId" : 9758,
    "prUrl" : "https://github.com/apache/kafka/pull/9758#pullrequestreview-600213435",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72de96c9-c26d-4e38-a7da-742ad928f825",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Similar question, is the copy required?",
        "createdAt" : "2021-02-27T20:31:38Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "47c87e12-6394-4739-af9d-cac28695b97d",
        "parentId" : "72de96c9-c26d-4e38-a7da-742ad928f825",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "same to https://github.com/apache/kafka/pull/9758#discussion_r584224693",
        "createdAt" : "2021-02-28T03:29:35Z",
        "updatedAt" : "2021-03-04T07:33:22Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae25551171fd4e3b889ca94d494e3207545320e5",
    "line" : 175,
    "diffHunk" : "@@ -1,1 +789,793 @@              .setRecords(unconvertedRecords)\n              .setPreferredReadReplica(partitionData.preferredReadReplica)\n              .setDivergingEpoch(partitionData.divergingEpoch)\n        }\n      }"
  },
  {
    "id" : "8b926ad0-40c6-457c-817b-0c5f91992bd8",
    "prId" : 9850,
    "prUrl" : "https://github.com/apache/kafka/pull/9850#pullrequestreview-564835404",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54e224da-0ed5-4d18-adfd-d905a0b4514d",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "ditto",
        "createdAt" : "2021-01-10T07:36:29Z",
        "updatedAt" : "2021-01-12T18:31:37Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b57ece0c28e6d35dfbf2cc3a9c9d1018902fe8d",
    "line" : 304,
    "diffHunk" : "@@ -1,1 +3304,3308 @@      RequestHeader.parse(buffer)\n    } catch {\n      case e: InvalidRequestException =>\n        // We use UNSUPPORTED_VERSION if the embedded request cannot be parsed.\n        // The purpose is to disambiguate structural errors in the envelope request"
  },
  {
    "id" : "29ffd285-f7bf-4774-9f49-a673fe61513d",
    "prId" : 9850,
    "prUrl" : "https://github.com/apache/kafka/pull/9850#pullrequestreview-564835404",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8904ab8e-cc73-4dda-96ef-5cd4f3ceb4af",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "ditto",
        "createdAt" : "2021-01-10T07:38:06Z",
        "updatedAt" : "2021-01-12T18:31:37Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b57ece0c28e6d35dfbf2cc3a9c9d1018902fe8d",
    "line" : 289,
    "diffHunk" : "@@ -1,1 +3289,3293 @@      )\n    } catch {\n      case e: InvalidRequestException =>\n        // We use UNSUPPORTED_VERSION if the embedded request cannot be parsed.\n        // The purpose is to disambiguate structural errors in the envelope request"
  },
  {
    "id" : "b5cebf34-b2d9-4f2b-a93f-d9baa9e05751",
    "prId" : 9850,
    "prUrl" : "https://github.com/apache/kafka/pull/9850#pullrequestreview-566010326",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb5db97c-3712-4742-93bc-b882e3e8cd9a",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "How about passing root cause to this new exception?",
        "createdAt" : "2021-01-12T07:55:27Z",
        "updatedAt" : "2021-01-12T18:31:37Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b57ece0c28e6d35dfbf2cc3a9c9d1018902fe8d",
    "line" : 293,
    "diffHunk" : "@@ -1,1 +3293,3297 @@        // The purpose is to disambiguate structural errors in the envelope request\n        // itself, such as an invalid client address.\n        throw new UnsupportedVersionException(s\"Failed to parse forwarded request \" +\n          s\"with header ${forwardedContext.header}\", e)\n    }"
  },
  {
    "id" : "1a9b7162-59a0-4e06-a695-c7fb82d9f176",
    "prId" : 9944,
    "prUrl" : "https://github.com/apache/kafka/pull/9944#pullrequestreview-652553397",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab9ce13f-4cbb-4ba3-809c-9fe8ada23f81",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "not sure whether this idea is valid. Could we resolve all ids to names and then keep using previous code to handle fetch requests?  for example: the code of deleting topic resolve ids to names first and then process the deletion by names. That is a good pattern to me as we don't need to trace id/name everywhere.",
        "createdAt" : "2021-03-13T11:29:33Z",
        "updatedAt" : "2021-05-05T20:29:40Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "b35789fa-5847-4651-a112-a2d298120d0f",
        "parentId" : "ab9ce13f-4cbb-4ba3-809c-9fe8ada23f81",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "For the most part, this is what we do. But we also have to keep track of unresolved names right?  FetchSession makes this more complicated. We may get a topic ID that we can't resolve, but with a subsequent update we can. I'm not 100% sure of the logistics of fetch sessions, but it doesn't seem like a good practice to leave unresolved IDs out of the session.",
        "createdAt" : "2021-03-13T16:35:08Z",
        "updatedAt" : "2021-05-05T20:29:40Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      },
      {
        "id" : "c2da9a39-04d5-4850-85b4-760a89b85f2a",
        "parentId" : "ab9ce13f-4cbb-4ba3-809c-9fe8ada23f81",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "I ended up deciding to end the session and throw a top level error when we have an unknown topic ID.",
        "createdAt" : "2021-05-05T17:09:36Z",
        "updatedAt" : "2021-05-05T20:29:40Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a47290d9a46db70b9ed3273ddafedbc8827e8da",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +690,694 @@    }\n\n    val fetchContext = fetchManager.newContext(\n      fetchRequest.version,\n      fetchRequest.metadata,"
  },
  {
    "id" : "9a8b81b1-c474-4012-b428-24b94218d9c4",
    "prId" : 9944,
    "prUrl" : "https://github.com/apache/kafka/pull/9944#pullrequestreview-641598151",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00fa56c0-a3d5-4bca-92a6-bd8019f638cf",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "extra newline.",
        "createdAt" : "2021-04-21T22:26:04Z",
        "updatedAt" : "2021-05-05T20:29:40Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a47290d9a46db70b9ed3273ddafedbc8827e8da",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +697,701 @@      forgottenTopics,\n      topicIds)\n\n    val clientMetadata: Option[ClientMetadata] = if (versionId >= 11) {\n      // Fetch API version 11 added preferred replica logic"
  },
  {
    "id" : "e30fdf38-5ad7-46fd-b3c2-c4a5fbd66545",
    "prId" : 10045,
    "prUrl" : "https://github.com/apache/kafka/pull/10045#pullrequestreview-584609850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12085dbb-ba89-4053-83e1-934901800203",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Why move these and not `unsupported`/`notYetSupported`?",
        "createdAt" : "2021-02-05T18:41:46Z",
        "updatedAt" : "2021-02-05T18:52:16Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "3caeccd1-df52-421b-8f2b-fae12889e7dd",
        "parentId" : "12085dbb-ba89-4053-83e1-934901800203",
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "Ah, I hadn't tested for those, and I moved based on rewriting tests.  Will move.",
        "createdAt" : "2021-02-05T18:43:05Z",
        "updatedAt" : "2021-02-05T18:52:16Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab497f241d01dff1cb78b8d52c94848d39b127cc",
    "line" : 567,
    "diffHunk" : "@@ -1,1 +3489,3493 @@\n  // visible for testing\n  private[server] def shouldNeverReceive(request: RequestChannel.Request): Exception = {\n    new UnsupportedVersionException(s\"Should never receive when using a Raft-based metadata quorum: ${request.header.apiKey()}\")\n  }"
  },
  {
    "id" : "d2a63618-9278-49ef-a2f1-7d8c437f6cac",
    "prId" : 10084,
    "prUrl" : "https://github.com/apache/kafka/pull/10084#pullrequestreview-586995628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "df2bbca2-388a-4c6a-b406-30525ae55b0d",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "The other APIs from KIP-500 is just closed. Maybe this API could follow same pattern?",
        "createdAt" : "2021-02-09T03:10:34Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "61b7a1a9-bc89-4ff3-9ebb-2cfedf4f9e1c",
        "parentId" : "df2bbca2-388a-4c6a-b406-30525ae55b0d",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "This call needs to be forwarded to the KIP-500 controller.  That is different from the other KIP-500 RPCs which are controller RPCs, and are not expected to be received on the broker at all.",
        "createdAt" : "2021-02-09T06:37:20Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "671d8859-fc0c-430d-9052-71c22ee9c62c",
        "parentId" : "df2bbca2-388a-4c6a-b406-30525ae55b0d",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "@cmccabe Thanks for explanation. It seems the [comment](https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaApis.scala#L221) gets invalid now.\r\n```\r\nHandle requests that should have been sent to the KIP-500 controlle\r\n```\r\n\r\nCould you revise the comment as well?",
        "createdAt" : "2021-02-09T06:53:56Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "9a5cfd43-e6c0-4053-b73d-be035be66543",
        "parentId" : "df2bbca2-388a-4c6a-b406-30525ae55b0d",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "The comment is not invalid.  It just doesn't apply to UNREGISTER_BROKER.  It does apply to VOTE, BEGIN_QUORUM_EPOCH, etc. etc.  I moved UNREGISTER_BROKER so it no longer appears underneath the comment.",
        "createdAt" : "2021-02-09T20:47:57Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd46b9d998090be1231df99a768a258ec449877c",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +218,222 @@        case ApiKeys.DESCRIBE_CLUSTER => handleDescribeCluster(request)\n        case ApiKeys.DESCRIBE_PRODUCERS => handleDescribeProducersRequest(request)\n        case ApiKeys.UNREGISTER_BROKER => maybeForwardToController(request, handleUnregisterBrokerRequest)\n\n        // Handle requests that should have been sent to the KIP-500 controller."
  },
  {
    "id" : "1629f34a-c586-4c04-8faf-603131ac2fc4",
    "prId" : 10084,
    "prUrl" : "https://github.com/apache/kafka/pull/10084#pullrequestreview-588033121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc3deab4-bfa4-4a0e-bff9-75e0f494f4f7",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "This is a bit confusing since this method can be called when the built-in quorum mode is used too. Or am I missing something?",
        "createdAt" : "2021-02-10T15:31:28Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "82c37bbb-1aed-483c-9b6d-72634968ad41",
        "parentId" : "dc3deab4-bfa4-4a0e-bff9-75e0f494f4f7",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "This method can't be called in built-in quorum mode since the API is forwardable and we will always have a forwarding manager",
        "createdAt" : "2021-02-10T19:18:03Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "a22f0841-f903-40dc-ba8a-ffdf780f1909",
        "parentId" : "dc3deab4-bfa4-4a0e-bff9-75e0f494f4f7",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Can we add a comment explaining that?",
        "createdAt" : "2021-02-10T20:19:34Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "d7a4ac8f-18ed-4289-b64b-d9355c17117c",
        "parentId" : "dc3deab4-bfa4-4a0e-bff9-75e0f494f4f7",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "will do",
        "createdAt" : "2021-02-10T20:39:30Z",
        "updatedAt" : "2021-02-10T20:44:04Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd46b9d998090be1231df99a768a258ec449877c",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +3396,3400 @@    // manager.\n    throw new UnsupportedVersionException(\"The broker unregistration API is not available when using \" +\n      \"Apache ZooKeeper mode.\")\n  }\n"
  },
  {
    "id" : "fce52c35-68e1-431b-b6d1-15a6ad381532",
    "prId" : 10183,
    "prUrl" : "https://github.com/apache/kafka/pull/10183#pullrequestreview-596598125",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b35b530-e504-47cf-880e-b261362436f2",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Why not converting to `TOPIC_AUTHORIZATION_FAILED`? Also, the data excluding non-authorized topics is a bit weird as it is in-completed result to callers.",
        "createdAt" : "2021-02-23T05:56:31Z",
        "updatedAt" : "2021-02-24T18:56:23Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "5b19b2a1-5f09-45fe-a6ba-a99abb623645",
        "parentId" : "3b35b530-e504-47cf-880e-b261362436f2",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The idea is to avoid exposing topic existence to unauthorized principals. We do the same thing in `Metadata` for example. I agree it is a little weird and I debated it for a little while. Should describe authorization on a transactionalId automatically imply describe authorization on all of the topics that it is writing to? A similar case is `OffsetFetch`: should describe authorization on the groupId imply describe authorization for all topics? We said \"no\" in that case, so I decided to be consistent.",
        "createdAt" : "2021-02-23T17:24:11Z",
        "updatedAt" : "2021-02-24T18:56:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "f8a1e12c-90cd-46e7-a82e-3cb2d8c101ee",
        "parentId" : "3b35b530-e504-47cf-880e-b261362436f2",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Got it. Thanks for this nice explanation.",
        "createdAt" : "2021-02-23T17:29:01Z",
        "updatedAt" : "2021-02-24T18:56:23Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dca9e47b22d9dd7ce6bc7878dbf5a7e223c5467",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +3289,3293 @@      }\n\n      // Include only partitions which the principal is authorized to describe\n      val topicIter = transactionState.topics.iterator()\n      while (topicIter.hasNext) {"
  },
  {
    "id" : "8ee6142d-8104-41ff-a798-77289e889ffb",
    "prId" : 10223,
    "prUrl" : "https://github.com/apache/kafka/pull/10223#pullrequestreview-601149479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa7756fb-084c-4c8c-8ace-28006f1a1e75",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I just noticed that the `Name` in the schema [1] used `mapKey: true`. I wonder if we should remove it now that `Name` is nullable. Usually, when we use `mapKey`, we expect to be able to query with the name and this is not always the case now. It seems that we don't rely on it in the admin client but we do in tests. What do you think?\r\n\r\n[1] https://github.com/apache/kafka/blob/trunk/clients/src/main/resources/common/message/DeleteTopicsResponse.json#L41",
        "createdAt" : "2021-02-27T08:56:48Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "fea7a85c-f678-4452-8258-991b5551da8b",
        "parentId" : "aa7756fb-084c-4c8c-8ace-28006f1a1e75",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "That's a good question. I agree using `mapKey` makes less sense now. Let me try it out. If the diff is not too bad, we can do it here. Otherwise, we can do it separately.",
        "createdAt" : "2021-02-27T15:40:53Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "d472b75a-dcd4-48c0-ae50-d4d0b53a297a",
        "parentId" : "aa7756fb-084c-4c8c-8ace-28006f1a1e75",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "We have one dependence here which makes this a little more work than I wanted to do here: https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaApis.scala#L1909. I filed a separate JIRA so that we don't forget about it: https://issues.apache.org/jira/browse/KAFKA-12395.",
        "createdAt" : "2021-03-01T20:45:02Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dffa6ddb400a627154d49561138adfb9a510a93",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +1897,1901 @@          // the topicId itself to be sensitive, so there is no reason to obscure\n          // this case with `UNKNOWN_TOPIC_ID`.\n          topic.setName(null)\n          topic.setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n        } else if (!authorizedDeleteTopics.contains(topic.name)) {"
  },
  {
    "id" : "9d156c77-db96-42fd-ad40-f6d3cce91020",
    "prId" : 10223,
    "prUrl" : "https://github.com/apache/kafka/pull/10223#pullrequestreview-601124997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03c8524b-c712-41b0-9d94-3d2d5d4cc226",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Do you want to narrow the access of `topicNames`? If so, we should change the modifier of `topicNames` from public to private",
        "createdAt" : "2021-02-27T13:43:56Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "7ed40035-91b1-4256-aabb-2c4995de6a9d",
        "parentId" : "03c8524b-c712-41b0-9d94-3d2d5d4cc226",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I mainly did this for easier mocking. I would like to see reduced access for `topicNames`, but that feels like something to address separately.",
        "createdAt" : "2021-03-01T20:13:08Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dffa6ddb400a627154d49561138adfb9a510a93",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1875,1879 @@          throw new InvalidRequestException(\"Topic name and topic ID can not both be specified.\")\n        val name = if (topic.topicId() == Uuid.ZERO_UUID) topic.name()\n        else zkSupport.controller.controllerContext.topicName(topic.topicId).orNull\n        results.add(new DeletableTopicResult()\n          .setName(name)"
  },
  {
    "id" : "50fd0a83-7f81-44df-8ff8-896d38064369",
    "prId" : 10223,
    "prUrl" : "https://github.com/apache/kafka/pull/10223#pullrequestreview-601899868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a425775e-ee73-4d49-99ef-922417a22441",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "according to https://github.com/apache/kafka/pull/10184#discussion_r585086425, should it handle the case `name provided, topic missing, describable => UNKNOWN_TOPIC_OR_PARTITION`?",
        "createdAt" : "2021-03-02T07:33:28Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "6cdf8edc-b96d-4214-944e-102ae97a2fba",
        "parentId" : "a425775e-ee73-4d49-99ef-922417a22441",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I guess there are really two sub-cases. Here's how they are currently handled:\r\n```\r\nname provided, topic missing, describable, deletable => UNKNOWN_TOPIC_OR_PARTITION\r\nname provided, topic missing, describable, undeletable => TOPIC_AUTHORIZATION_FAILED\r\n```\r\nThis seems defensible to me. The `UNKNOWN_TOPIC_OR_PARTITION` error will cause the client to retry because of the possibility of stale metadata, but it can't delete the topic anyway because of the authorization failure. It seems better to fail fast?",
        "createdAt" : "2021-03-02T14:19:15Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "5792528b-5cfd-43b4-a1e6-05b018eed725",
        "parentId" : "a425775e-ee73-4d49-99ef-922417a22441",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "> This seems defensible to me. The UNKNOWN_TOPIC_OR_PARTITION error will cause the client to retry because of the possibility of stale metadata, but it can't delete the topic anyway because of the authorization failure. It seems better to fail fast?\r\n\r\nThat makes sense to me. We have to make sure this rule is applied to #10184 :)",
        "createdAt" : "2021-03-02T14:49:37Z",
        "updatedAt" : "2021-03-02T15:32:23Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dffa6ddb400a627154d49561138adfb9a510a93",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +1899,1903 @@          topic.setName(null)\n          topic.setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n        } else if (!authorizedDeleteTopics.contains(topic.name)) {\n          topic.setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)\n        } else if (!metadataCache.contains(topic.name)) {"
  },
  {
    "id" : "2e940e21-7988-4225-850a-e7eb19802bb2",
    "prId" : 10584,
    "prUrl" : "https://github.com/apache/kafka/pull/10584#pullrequestreview-680790300",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5dee411e-1046-4b2a-81dc-aae36bafdf7c",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Can we not do such validation in the request class?",
        "createdAt" : "2021-05-19T12:49:12Z",
        "updatedAt" : "2021-05-19T12:49:12Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "717eb276-91a2-476e-b7b7-2f800b7d7d99",
        "parentId" : "5dee411e-1046-4b2a-81dc-aae36bafdf7c",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "We can do some there. But would we still need this since the protocol also allows for nulls/topic Ids?",
        "createdAt" : "2021-05-19T16:21:55Z",
        "updatedAt" : "2021-05-19T16:21:56Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      },
      {
        "id" : "9c2fd560-4cf8-4310-9f89-9b472d6db873",
        "parentId" : "5dee411e-1046-4b2a-81dc-aae36bafdf7c",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "What I mean is that this logic could exist in the request class and you can then call the method from here. That way it's much easier to test.",
        "createdAt" : "2021-06-10T13:35:47Z",
        "updatedAt" : "2021-06-10T13:37:07Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d8959457160ecc2614ac5c6b04e2eb323c08690b",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1152,1156 @@        }\n      }\n    }\n\n    val topics = if (metadataRequest.isAllTopics)"
  },
  {
    "id" : "fb1da962-b6ed-45eb-90a8-54e98a4380d4",
    "prId" : 10743,
    "prUrl" : "https://github.com/apache/kafka/pull/10743#pullrequestreview-679956274",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b7ae6a0-a31b-46b9-a729-bb890d68c3ae",
        "parentId" : null,
        "authorId" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "body" : "Do we really need these separate methods? I would have thought we could just wrap the `findCoordinatorRequest.data.key` in a singleton List for the `version < 4` and otherwise they'd be handled the same. If there is a reason I think it deserves a comment.",
        "createdAt" : "2021-06-07T15:13:51Z",
        "updatedAt" : "2021-06-07T15:14:18Z",
        "lastEditedBy" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "tags" : [
        ]
      },
      {
        "id" : "59c13496-1480-4d4b-859e-e80244c1bb0b",
        "parentId" : "2b7ae6a0-a31b-46b9-a729-bb890d68c3ae",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "We need a different `createResponse()` for each version. Both methods call `getCoordinator()` and have no logic.",
        "createdAt" : "2021-06-09T17:28:19Z",
        "updatedAt" : "2021-06-09T17:28:19Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "b4927960-74a7-43bd-8dba-1c66ac6f36ff",
        "parentId" : "2b7ae6a0-a31b-46b9-a729-bb890d68c3ae",
        "authorId" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "body" : "Yes, obvious now you point it out! I guess I can't see a better way of abstracting over that. ",
        "createdAt" : "2021-06-09T17:40:13Z",
        "updatedAt" : "2021-06-09T17:40:13Z",
        "lastEditedBy" : "491bcd91-bc8d-4f54-b5fd-d6c7be5e8693",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae09d742171c8a3a7d60587ce0502dce35945f73",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1336,1340 @@      handleFindCoordinatorRequestLessThanV4(request)\n    } else {\n      handleFindCoordinatorRequestV4AndAbove(request)\n    }\n  }"
  },
  {
    "id" : "42881dc6-0820-447a-b79d-314c273b2184",
    "prId" : 10900,
    "prUrl" : "https://github.com/apache/kafka/pull/10900#pullrequestreview-691280706",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57db2d8a-6393-42f9-beb8-e057d2b57040",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Hm, so we are _only_ allowing forwarding with this `forwardToControllerOrFail` since this RPC did not exist before? Are there other recently added controller-only RPCs that need this treatment?",
        "createdAt" : "2021-06-23T15:48:46Z",
        "updatedAt" : "2021-06-23T15:49:37Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "ad72a617-3f8b-4e27-a8df-5e207b43c413",
        "parentId" : "57db2d8a-6393-42f9-beb8-e057d2b57040",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, because DescribeQuorum does not make sense for zk clusters. As far as I know, this is the only case of a client api which is only exposed under kraft. However, we do have some internal controller apis that are only used by kraft (e.g. for broker registration and heartbeating).",
        "createdAt" : "2021-06-24T02:17:42Z",
        "updatedAt" : "2021-06-24T02:17:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "600f81a469ea0d7beeb293b17f35924418efd29b",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +228,232 @@        case ApiKeys.LIST_TRANSACTIONS => handleListTransactionsRequest(request)\n        case ApiKeys.ALLOCATE_PRODUCER_IDS => maybeForwardToController(request, handleAllocateProducerIdsRequest)\n        case ApiKeys.DESCRIBE_QUORUM => forwardToControllerOrFail(request)\n        case _ => throw new IllegalStateException(s\"No handler for request api key ${request.header.apiKey}\")\n      }"
  }
]