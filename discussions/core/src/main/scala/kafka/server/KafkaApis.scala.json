[
  {
    "id" : "71e811f3-078b-440b-a6bf-d3e003e015ba",
    "prId" : 3960,
    "prUrl" : "https://github.com/apache/kafka/pull/3960#pullrequestreview-140809034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "parentId" : null,
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "We also need to update DeleteTopicsRequest/DeleteTopicsResponse request/response classes to V3.",
        "createdAt" : "2018-07-26T15:58:08Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      },
      {
        "id" : "3fd11012-77a3-408a-8136-cada4c730828",
        "parentId" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "authorId" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "body" : "Done!",
        "createdAt" : "2018-07-26T16:29:48Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc67c0df33ed26af6c5af45f32d139b7dbe87738",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1541,1545 @@      sendResponseCallback(results)\n    } else if (!config.deleteTopicEnable) {\n      val error = if (request.context.apiVersion < 3) Errors.INVALID_REQUEST else Errors.TOPIC_DELETION_DISABLED\n      val results = deleteTopicRequest.topics.asScala.map { topic =>\n        (topic, error)"
  },
  {
    "id" : "7a02ce24-97db-4c45-bb6f-60e548ac6dbd",
    "prId" : 5074,
    "prUrl" : "https://github.com/apache/kafka/pull/5074#pullrequestreview-123536379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We don't guarantee this, do we? It seems like we only guarantee that we won't exceed the quota if ISR traffic is below the quota.",
        "createdAt" : "2018-05-25T23:24:48Z",
        "updatedAt" : "2018-05-25T23:25:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "f06aeb1d-d791-4816-a754-3ebff5163e30",
        "parentId" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Right, we guarantee that if the quota is set high enough.",
        "createdAt" : "2018-05-25T23:30:18Z",
        "updatedAt" : "2018-05-25T23:30:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f2fc60cfd9188a3a530d5ae8f6ad2ca305a89add",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +668,672 @@\n  // Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication\n  // traffic doesn't exceed quota.\n  private def sizeOfThrottledPartitions(versionId: Short,\n                                        unconvertedResponse: FetchResponse,"
  },
  {
    "id" : "1afefefa-5c98-4e0f-8212-72c7871069f9",
    "prId" : 5972,
    "prUrl" : "https://github.com/apache/kafka/pull/5972#pullrequestreview-196171710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since results is a set, is that check still needed?",
        "createdAt" : "2019-01-23T18:35:03Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "8b2f2193-08d7-4418-ade9-2a268367f61a",
        "parentId" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Just to be clear, it's a multiset.  This was done specifically to preserve the existing behavior where duplicate entries caused us to return an error code, rather than triggering a deserialization error (which would show up as a disconnection)",
        "createdAt" : "2019-01-24T18:00:56Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "83e42e5fc686792f41bd087a5b4b2270871bfcb7",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +1423,1427 @@      val hasClusterAuthorization = authorize(request.session, Create, Resource.ClusterResource)\n      results.asScala.foreach(topic => {\n        if (results.findAll(topic.name()).size() > 1) {\n          topic.setErrorCode(Errors.INVALID_REQUEST.code())\n          topic.setErrorMessage(\"Found multiple entries for this topic.\")"
  },
  {
    "id" : "2a97d99a-8002-49e6-beef-05c218a15007",
    "prId" : 5991,
    "prUrl" : "https://github.com/apache/kafka/pull/5991#pullrequestreview-182902344",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just thinking about this a little, do you think there's much advantage to having a separate error code? Whether it is `OFFSET_NOT_AVAILABLE` or `LEADER_NOT_AVAILABLE`, the client will just retry.\r\n\r\nAlso, it might be a good idea to update `Fetcher.handleListOffsetResponse` to explicitly check the expected error codes. We can probably skip the log warning in these cases and print a debug message since this is an expected scenario.",
        "createdAt" : "2018-12-04T18:14:01Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b21c7285-5752-4ad6-b4a3-9a96ff301a01",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "The motivation of a new exception was to give a more precise reason for not returning the offsets. Sticking with `LEADER_NOT_AVAILABLE` would eliminate any change required to the protocol, which is nice, but maybe runs the risk of overloading the error code. Looking at usages of `LEADER_NOT_AVAILABLE` in the code, it doesn't actually look all that widely used, so maybe adding another usage of it for this case isn't so bad. \r\n\r\n@hachikuji @cmccabe WDYT?",
        "createdAt" : "2018-12-04T19:12:28Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "13ab09a8-d622-47f6-a676-1e16981a1ff9",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "> Fetcher.handleListOffsetResponse to explicitly check the expected error codes\r\n\r\nSounds good. Would handling `LEADER_NOT_AVAILABLE` and retrying have any unintended consequences with other uses of this error code?",
        "createdAt" : "2018-12-04T19:13:14Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "c3edb389-b1d4-497a-8f27-1ba1f59296f2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I'm not sure. We have tended to regret when we didn't provide more explicit error codes, so perhaps we should just stick with what's in the KIP. \r\n\r\n> Sounds good. Would handling LEADER_NOT_AVAILABLE and retrying have any unintended consequences with other uses of this error code?\r\n\r\nI didn't see any explicit logic to handle it in `Fetcher`, so I think we'd be hitting this case:\r\n```java\r\nlog.warn(\"Attempt to fetch offsets for partition {} failed due to: {}\", topicPartition, error.message());\r\npartitionsToRetry.add(topicPartition);\r\n```\r\nDo we have any current scenarios in the ListOffset handler where we could raise `LEADER_NOT_AVAILABLE`?",
        "createdAt" : "2018-12-06T02:58:49Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "e8b074b1-6eb7-4014-9467-ebc286aa24e2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "As far as I can tell, `LEADER_NOT_AVAILABLE` is only returned when creating a topic, fetching metadata, and deleting records. I'll continue with the new error as indicated in the KIP and rev the IBP",
        "createdAt" : "2018-12-06T14:42:31Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "48fa917c-4ffd-453e-8938-8e0fab2c2b85",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Yes, we discussed this in the KIP.  It is good to be specific with error codes.  +1.",
        "createdAt" : "2018-12-07T22:48:08Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "54d8dd54100b18957db07485d9ee0c37ad4476c8",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +875,879 @@          case e: OffsetNotAvailableException =>\n            if(request.header.apiVersion >= 5) {\n              buildErrorResponse(Errors.forException(e))\n            } else {\n              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)"
  },
  {
    "id" : "5536b0e1-1f68-44ff-a356-ec35b42d7b70",
    "prId" : 6172,
    "prUrl" : "https://github.com/apache/kafka/pull/6172#pullrequestreview-194375653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "What's the intended behaviour if `transactionalId == null && produceRequest.hasTransactionalRecords`?",
        "createdAt" : "2019-01-19T04:14:34Z",
        "updatedAt" : "2019-01-19T04:14:35Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "827717ae-cc3a-4cdb-b107-7e03ec768026",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Returning `TRANSACTIONAL_ID_AUTHORIZATION_FAILED` seemed like the best bet. `INVALID_REQUEST` might be another option. Currently, without this check, the authorizer raises an NPE which causes the connection to terminate. We could push the null checks into the authorizor as well.",
        "createdAt" : "2019-01-20T01:09:15Z",
        "updatedAt" : "2019-01-20T01:35:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "8ba7773b-756b-4e8c-9d65-b124ddd2e11e",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Makes sense. I guess one can say that the `null` transaction id is never authorized.",
        "createdAt" : "2019-01-20T01:20:19Z",
        "updatedAt" : "2019-01-20T01:20:19Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b9945c7fe740373681b8b96a15c00e699b6a4fc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +390,394 @@\n    if (produceRequest.hasTransactionalRecords) {\n      val isAuthorizedTransactional = produceRequest.transactionalId != null &&\n        authorize(request.session, Write, Resource(TransactionalId, produceRequest.transactionalId, LITERAL))\n      if (!isAuthorizedTransactional) {"
  },
  {
    "id" : "de13e4d1-248a-407d-a156-3faccc0a8372",
    "prId" : 6408,
    "prUrl" : "https://github.com/apache/kafka/pull/6408#pullrequestreview-232427016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could probably modify `prepareResponse` to take the throttle time and remove this.",
        "createdAt" : "2019-04-27T23:24:58Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a9ae8e81-b4ba-4ea7-aeba-fe23130916fb",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "The throttle time is only used in 2 places so I kept it this way. I'm happy to change it if you think that's really better",
        "createdAt" : "2019-04-30T19:47:34Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "7bd9c359-85db-4e74-95cb-6eb45bf4abe6",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "No strong preference. Just a suggestion",
        "createdAt" : "2019-04-30T21:58:19Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "25f2ac3741e53e4e7fc1b4da0e3cd3523cf2209d",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1197,1201 @@\n      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n          new FindCoordinatorResponse(\n              new FindCoordinatorResponseData()"
  },
  {
    "id" : "e6ac4908-4e4a-4a94-9cae-9f026387c89f",
    "prId" : 6686,
    "prUrl" : "https://github.com/apache/kafka/pull/6686#pullrequestreview-240919946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60346547-c70c-4c6d-8fe7-23a6699c341b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be worth a comment explaining this filtering.",
        "createdAt" : "2019-05-23T02:17:16Z",
        "updatedAt" : "2019-05-29T01:18:29Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d53f267c91cc93478d817214f47a6fd2ec20691",
    "line" : 222,
    "diffHunk" : "@@ -1,1 +2461,2465 @@    ): Unit = {\n      sendResponseMaybeThrottle(request, requestThrottleMs => {\n        val adjustedResults = if (electionRequest.data().topicPartitions() == null) {\n          /* When performing elections across all of the partitions we should only return\n           * partitions for which there was an eleciton or resulted in an error. In other"
  },
  {
    "id" : "8c2939cc-c475-4a7c-991b-3ed94886a784",
    "prId" : 6714,
    "prUrl" : "https://github.com/apache/kafka/pull/6714#pullrequestreview-266889526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just want to be clear that the top-level error code isn't giving us much benefit other than easing compatibility since we are always setting the member-level error codes. This sort of goes back to the question I had about allowing empty list of members. If we removed some of the validations, then we could just provide the top level error code in the response.",
        "createdAt" : "2019-07-25T20:42:18Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a38f3050-69ab-4c0c-a553-55c0d13d00ba",
        "parentId" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I see your point, makes sense.",
        "createdAt" : "2019-07-25T21:15:04Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab085e9764aa35dece48891a8d707b743b5bf711",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +1557,1561 @@        new LeaveGroupResponse(new LeaveGroupResponseData()\n          .setThrottleTimeMs(requestThrottleMs)\n          .setErrorCode(Errors.GROUP_AUTHORIZATION_FAILED.code)\n        )\n      })"
  },
  {
    "id" : "a68988ca-95e3-4f0e-a20c-68e1c9326653",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-268909360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I've opted out of having the INVALID_REASSIGNMENT error. Mainly because it's tricky to know when a replica is intermittently offline, as the znode and controller memory cache store only the online brokers. ",
        "createdAt" : "2019-07-30T18:00:18Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "d1ec0f37-61b7-4225-895a-96817b788d7a",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We could have some preliminary checks here for an empty list or negative IDs though",
        "createdAt" : "2019-07-30T18:00:56Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "484d6e14-365e-4502-918d-f316eaaa8911",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We discussed here and I changed my mind that it's a goo idea to have - https://github.com/apache/kafka/pull/7120#discussion_r308861346",
        "createdAt" : "2019-07-31T10:05:06Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +2342,2346 @@          if (reassignablePartition.replicas() == null)\n            tp -> None // revert call\n          else\n            tp -> Some(reassignablePartition.replicas().asScala.map(_.toInt))\n      }"
  },
  {
    "id" : "d43d0394-6b6e-44bf-b9e3-b209c5322152",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-283907403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "is flatMap really needed here, or should it be map?",
        "createdAt" : "2019-08-19T23:53:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "8f9ac6e8-af60-4231-b29a-15a6de8ccda9",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Should be `flatMap` since we do another map inside on the partitions indices to convert to TopicPartition and we want a big list of TopicPartitions, rather than one for each topic",
        "createdAt" : "2019-08-29T08:17:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "e817e4eb-7981-46e8-9193-4f7fa399a5e2",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "thanks for the explanation",
        "createdAt" : "2019-09-04T21:29:59Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +2384,2388 @@    val partitionsOpt = listPartitionReassignmentsRequest.data().topics() match {\n      case topics: Any =>\n        Some(topics.iterator().asScala.flatMap { topic =>\n          topic.partitionIndexes().iterator().asScala\n            .map { tp => new TopicPartition(topic.name(), tp) }"
  }
]