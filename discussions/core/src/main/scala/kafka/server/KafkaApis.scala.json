[
  {
    "id" : "71e811f3-078b-440b-a6bf-d3e003e015ba",
    "prId" : 3960,
    "prUrl" : "https://github.com/apache/kafka/pull/3960#pullrequestreview-140809034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "parentId" : null,
        "authorId" : "915b2f67-05e6-4824-939a-398e7be58870",
        "body" : "We also need to update DeleteTopicsRequest/DeleteTopicsResponse request/response classes to V3.",
        "createdAt" : "2018-07-26T15:58:08Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "915b2f67-05e6-4824-939a-398e7be58870",
        "tags" : [
        ]
      },
      {
        "id" : "3fd11012-77a3-408a-8136-cada4c730828",
        "parentId" : "7ecb8060-edfb-40a7-ad1c-d689613cca10",
        "authorId" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "body" : "Done!",
        "createdAt" : "2018-07-26T16:29:48Z",
        "updatedAt" : "2018-08-24T04:15:03Z",
        "lastEditedBy" : "e010e546-b6d6-4bd1-8a04-3b3160805fc9",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc67c0df33ed26af6c5af45f32d139b7dbe87738",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1541,1545 @@      sendResponseCallback(results)\n    } else if (!config.deleteTopicEnable) {\n      val error = if (request.context.apiVersion < 3) Errors.INVALID_REQUEST else Errors.TOPIC_DELETION_DISABLED\n      val results = deleteTopicRequest.topics.asScala.map { topic =>\n        (topic, error)"
  },
  {
    "id" : "7a02ce24-97db-4c45-bb6f-60e548ac6dbd",
    "prId" : 5074,
    "prUrl" : "https://github.com/apache/kafka/pull/5074#pullrequestreview-123536379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "We don't guarantee this, do we? It seems like we only guarantee that we won't exceed the quota if ISR traffic is below the quota.",
        "createdAt" : "2018-05-25T23:24:48Z",
        "updatedAt" : "2018-05-25T23:25:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "f06aeb1d-d791-4816-a754-3ebff5163e30",
        "parentId" : "b556fb5b-8369-45fc-a182-53c46e52add8",
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Right, we guarantee that if the quota is set high enough.",
        "createdAt" : "2018-05-25T23:30:18Z",
        "updatedAt" : "2018-05-25T23:30:18Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f2fc60cfd9188a3a530d5ae8f6ad2ca305a89add",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +668,672 @@\n  // Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication\n  // traffic doesn't exceed quota.\n  private def sizeOfThrottledPartitions(versionId: Short,\n                                        unconvertedResponse: FetchResponse,"
  },
  {
    "id" : "1afefefa-5c98-4e0f-8212-72c7871069f9",
    "prId" : 5972,
    "prUrl" : "https://github.com/apache/kafka/pull/5972#pullrequestreview-196171710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Since results is a set, is that check still needed?",
        "createdAt" : "2019-01-23T18:35:03Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "8b2f2193-08d7-4418-ade9-2a268367f61a",
        "parentId" : "a45a77b5-3f16-4301-842f-defd788c1431",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Just to be clear, it's a multiset.  This was done specifically to preserve the existing behavior where duplicate entries caused us to return an error code, rather than triggering a deserialization error (which would show up as a disconnection)",
        "createdAt" : "2019-01-24T18:00:56Z",
        "updatedAt" : "2019-02-01T23:53:39Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "83e42e5fc686792f41bd087a5b4b2270871bfcb7",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +1423,1427 @@      val hasClusterAuthorization = authorize(request.session, Create, Resource.ClusterResource)\n      results.asScala.foreach(topic => {\n        if (results.findAll(topic.name()).size() > 1) {\n          topic.setErrorCode(Errors.INVALID_REQUEST.code())\n          topic.setErrorMessage(\"Found multiple entries for this topic.\")"
  },
  {
    "id" : "2a97d99a-8002-49e6-beef-05c218a15007",
    "prId" : 5991,
    "prUrl" : "https://github.com/apache/kafka/pull/5991#pullrequestreview-182902344",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just thinking about this a little, do you think there's much advantage to having a separate error code? Whether it is `OFFSET_NOT_AVAILABLE` or `LEADER_NOT_AVAILABLE`, the client will just retry.\r\n\r\nAlso, it might be a good idea to update `Fetcher.handleListOffsetResponse` to explicitly check the expected error codes. We can probably skip the log warning in these cases and print a debug message since this is an expected scenario.",
        "createdAt" : "2018-12-04T18:14:01Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b21c7285-5752-4ad6-b4a3-9a96ff301a01",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "The motivation of a new exception was to give a more precise reason for not returning the offsets. Sticking with `LEADER_NOT_AVAILABLE` would eliminate any change required to the protocol, which is nice, but maybe runs the risk of overloading the error code. Looking at usages of `LEADER_NOT_AVAILABLE` in the code, it doesn't actually look all that widely used, so maybe adding another usage of it for this case isn't so bad. \r\n\r\n@hachikuji @cmccabe WDYT?",
        "createdAt" : "2018-12-04T19:12:28Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "13ab09a8-d622-47f6-a676-1e16981a1ff9",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "> Fetcher.handleListOffsetResponse to explicitly check the expected error codes\r\n\r\nSounds good. Would handling `LEADER_NOT_AVAILABLE` and retrying have any unintended consequences with other uses of this error code?",
        "createdAt" : "2018-12-04T19:13:14Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "c3edb389-b1d4-497a-8f27-1ba1f59296f2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I'm not sure. We have tended to regret when we didn't provide more explicit error codes, so perhaps we should just stick with what's in the KIP. \r\n\r\n> Sounds good. Would handling LEADER_NOT_AVAILABLE and retrying have any unintended consequences with other uses of this error code?\r\n\r\nI didn't see any explicit logic to handle it in `Fetcher`, so I think we'd be hitting this case:\r\n```java\r\nlog.warn(\"Attempt to fetch offsets for partition {} failed due to: {}\", topicPartition, error.message());\r\npartitionsToRetry.add(topicPartition);\r\n```\r\nDo we have any current scenarios in the ListOffset handler where we could raise `LEADER_NOT_AVAILABLE`?",
        "createdAt" : "2018-12-06T02:58:49Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "e8b074b1-6eb7-4014-9467-ebc286aa24e2",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "As far as I can tell, `LEADER_NOT_AVAILABLE` is only returned when creating a topic, fetching metadata, and deleting records. I'll continue with the new error as indicated in the KIP and rev the IBP",
        "createdAt" : "2018-12-06T14:42:31Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "48fa917c-4ffd-453e-8938-8e0fab2c2b85",
        "parentId" : "08dc0976-4b20-41ca-bcd9-0b6923699991",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Yes, we discussed this in the KIP.  It is good to be specific with error codes.  +1.",
        "createdAt" : "2018-12-07T22:48:08Z",
        "updatedAt" : "2018-12-14T16:34:23Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "54d8dd54100b18957db07485d9ee0c37ad4476c8",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +875,879 @@          case e: OffsetNotAvailableException =>\n            if(request.header.apiVersion >= 5) {\n              buildErrorResponse(Errors.forException(e))\n            } else {\n              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)"
  },
  {
    "id" : "5536b0e1-1f68-44ff-a356-ec35b42d7b70",
    "prId" : 6172,
    "prUrl" : "https://github.com/apache/kafka/pull/6172#pullrequestreview-194375653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "What's the intended behaviour if `transactionalId == null && produceRequest.hasTransactionalRecords`?",
        "createdAt" : "2019-01-19T04:14:34Z",
        "updatedAt" : "2019-01-19T04:14:35Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "827717ae-cc3a-4cdb-b107-7e03ec768026",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Returning `TRANSACTIONAL_ID_AUTHORIZATION_FAILED` seemed like the best bet. `INVALID_REQUEST` might be another option. Currently, without this check, the authorizer raises an NPE which causes the connection to terminate. We could push the null checks into the authorizor as well.",
        "createdAt" : "2019-01-20T01:09:15Z",
        "updatedAt" : "2019-01-20T01:35:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "8ba7773b-756b-4e8c-9d65-b124ddd2e11e",
        "parentId" : "f5892c6b-d5c3-458b-bdc3-845f6f4dd413",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Makes sense. I guess one can say that the `null` transaction id is never authorized.",
        "createdAt" : "2019-01-20T01:20:19Z",
        "updatedAt" : "2019-01-20T01:20:19Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b9945c7fe740373681b8b96a15c00e699b6a4fc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +390,394 @@\n    if (produceRequest.hasTransactionalRecords) {\n      val isAuthorizedTransactional = produceRequest.transactionalId != null &&\n        authorize(request.session, Write, Resource(TransactionalId, produceRequest.transactionalId, LITERAL))\n      if (!isAuthorizedTransactional) {"
  },
  {
    "id" : "de13e4d1-248a-407d-a156-3faccc0a8372",
    "prId" : 6408,
    "prUrl" : "https://github.com/apache/kafka/pull/6408#pullrequestreview-232427016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could probably modify `prepareResponse` to take the throttle time and remove this.",
        "createdAt" : "2019-04-27T23:24:58Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a9ae8e81-b4ba-4ea7-aeba-fe23130916fb",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "The throttle time is only used in 2 places so I kept it this way. I'm happy to change it if you think that's really better",
        "createdAt" : "2019-04-30T19:47:34Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      },
      {
        "id" : "7bd9c359-85db-4e74-95cb-6eb45bf4abe6",
        "parentId" : "44bcbc4b-6c83-449e-b12d-bffbffe985f0",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "No strong preference. Just a suggestion",
        "createdAt" : "2019-04-30T21:58:19Z",
        "updatedAt" : "2019-05-06T19:03:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "25f2ac3741e53e4e7fc1b4da0e3cd3523cf2209d",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1197,1201 @@\n      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n          new FindCoordinatorResponse(\n              new FindCoordinatorResponseData()"
  },
  {
    "id" : "e6ac4908-4e4a-4a94-9cae-9f026387c89f",
    "prId" : 6686,
    "prUrl" : "https://github.com/apache/kafka/pull/6686#pullrequestreview-240919946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60346547-c70c-4c6d-8fe7-23a6699c341b",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Might be worth a comment explaining this filtering.",
        "createdAt" : "2019-05-23T02:17:16Z",
        "updatedAt" : "2019-05-29T01:18:29Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d53f267c91cc93478d817214f47a6fd2ec20691",
    "line" : 222,
    "diffHunk" : "@@ -1,1 +2461,2465 @@    ): Unit = {\n      sendResponseMaybeThrottle(request, requestThrottleMs => {\n        val adjustedResults = if (electionRequest.data().topicPartitions() == null) {\n          /* When performing elections across all of the partitions we should only return\n           * partitions for which there was an eleciton or resulted in an error. In other"
  },
  {
    "id" : "8c2939cc-c475-4a7c-991b-3ed94886a784",
    "prId" : 6714,
    "prUrl" : "https://github.com/apache/kafka/pull/6714#pullrequestreview-266889526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just want to be clear that the top-level error code isn't giving us much benefit other than easing compatibility since we are always setting the member-level error codes. This sort of goes back to the question I had about allowing empty list of members. If we removed some of the validations, then we could just provide the top level error code in the response.",
        "createdAt" : "2019-07-25T20:42:18Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a38f3050-69ab-4c0c-a553-55c0d13d00ba",
        "parentId" : "fef74e08-0774-432f-a4ea-51ea8b6848b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I see your point, makes sense.",
        "createdAt" : "2019-07-25T21:15:04Z",
        "updatedAt" : "2019-07-26T04:38:45Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab085e9764aa35dece48891a8d707b743b5bf711",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +1557,1561 @@        new LeaveGroupResponse(new LeaveGroupResponseData()\n          .setThrottleTimeMs(requestThrottleMs)\n          .setErrorCode(Errors.GROUP_AUTHORIZATION_FAILED.code)\n        )\n      })"
  },
  {
    "id" : "a68988ca-95e3-4f0e-a20c-68e1c9326653",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-268909360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "parentId" : null,
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "I've opted out of having the INVALID_REASSIGNMENT error. Mainly because it's tricky to know when a replica is intermittently offline, as the znode and controller memory cache store only the online brokers. ",
        "createdAt" : "2019-07-30T18:00:18Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "d1ec0f37-61b7-4225-895a-96817b788d7a",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We could have some preliminary checks here for an empty list or negative IDs though",
        "createdAt" : "2019-07-30T18:00:56Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "484d6e14-365e-4502-918d-f316eaaa8911",
        "parentId" : "e422d74d-3175-4b66-98fa-4d7aaa94b11a",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "We discussed here and I changed my mind that it's a goo idea to have - https://github.com/apache/kafka/pull/7120#discussion_r308861346",
        "createdAt" : "2019-07-31T10:05:06Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +2342,2346 @@          if (reassignablePartition.replicas() == null)\n            tp -> None // revert call\n          else\n            tp -> Some(reassignablePartition.replicas().asScala.map(_.toInt))\n      }"
  },
  {
    "id" : "d43d0394-6b6e-44bf-b9e3-b209c5322152",
    "prId" : 7128,
    "prUrl" : "https://github.com/apache/kafka/pull/7128#pullrequestreview-283907403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "is flatMap really needed here, or should it be map?",
        "createdAt" : "2019-08-19T23:53:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "8f9ac6e8-af60-4231-b29a-15a6de8ccda9",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "body" : "Should be `flatMap` since we do another map inside on the partitions indices to convert to TopicPartition and we want a big list of TopicPartitions, rather than one for each topic",
        "createdAt" : "2019-08-29T08:17:07Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "df911192-d6c6-4af9-8568-f67bf2dcf926",
        "tags" : [
        ]
      },
      {
        "id" : "e817e4eb-7981-46e8-9193-4f7fa399a5e2",
        "parentId" : "2bc32acf-73f1-43c8-b733-6cc00dbbd70d",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "thanks for the explanation",
        "createdAt" : "2019-09-04T21:29:59Z",
        "updatedAt" : "2019-09-09T17:48:38Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "8538961c460c50be1828a050793f45d8558ea9b9",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +2384,2388 @@    val partitionsOpt = listPartitionReassignmentsRequest.data().topics() match {\n      case topics: Any =>\n        Some(topics.iterator().asScala.flatMap { topic =>\n          topic.partitionIndexes().iterator().asScala\n            .map { tp => new TopicPartition(topic.name(), tp) }"
  },
  {
    "id" : "872685f9-63d9-4bb5-801e-ef4380bff247",
    "prId" : 7381,
    "prUrl" : "https://github.com/apache/kafka/pull/7381#pullrequestreview-297149707",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "WDYT about adding a new error code here? If I understand correctly, the client will get this error code when sending a valid ApiVersionsRequest with an invalid client name/version. Something more indicative of the actual problem might be nice.",
        "createdAt" : "2019-10-01T20:56:12Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "8807771e-7ff5-4a0c-abd4-b197fef071b6",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "You have a fair point. Would you go with something like `INVALID_NAME_OR_VERSION` for instance? I have thought about this when I wrote the KIP and went with this error. My reasoning was that we may add new fields in the future (e.g. hostname?) so I wanted to have a generic error which is not tight to the client/version cases. `INVALID_REQUEST` sounds quite appropriate for this.\r\n\r\nFurthermore, as the client name and version are set by the developer of a client, it should rarely happen when end users use the client library. ",
        "createdAt" : "2019-10-02T07:00:36Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "ae149f6b-8f6b-412f-8353-160cd55765fa",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "This should be pretty rare, so it's probably not worth its own error code.  I do wonder if there should be some kind of log message, since otherwise this would be hard for a broker operator to see.",
        "createdAt" : "2019-10-03T17:59:10Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "b1246dc2-838e-4bcf-9cc2-60ceadad6cc1",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I thought about adding a log message as well and I decided to not do it for two reasons:\r\n1) This should be pretty rare and should mainly happen during the development of the client. In this case, the request log could be used; and\r\n2) If a buggy client would be released with an invalid ApiVersionsRequest, I wanted to avoid flooding the logs with something which is not really actionable for a broker operator. What would he do with this information?",
        "createdAt" : "2019-10-03T18:52:40Z",
        "updatedAt" : "2019-10-03T19:34:23Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "701ae98a-0110-49ab-8644-8edbe023d69f",
        "parentId" : "5e92d50f-c15b-4fe1-a87c-40d6d27bcff5",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Those are fair points.  Let's leave it as-is for now.  As you say, the request log will give some hints in this scenario.",
        "createdAt" : "2019-10-03T21:02:39Z",
        "updatedAt" : "2019-10-03T21:02:39Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc07639d6db7c5712730e5130ad67fb21504f5e8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1618,1622 @@        apiVersionRequest.getErrorResponse(requestThrottleMs, Errors.UNSUPPORTED_VERSION.exception)\n      else if (!apiVersionRequest.isValid)\n        apiVersionRequest.getErrorResponse(requestThrottleMs, Errors.INVALID_REQUEST.exception)\n      else\n        ApiVersionsResponse.apiVersionsResponse(requestThrottleMs,"
  },
  {
    "id" : "ead5ceb9-28b1-4072-b646-0b2978343299",
    "prId" : 7813,
    "prUrl" : "https://github.com/apache/kafka/pull/7813#pullrequestreview-349864022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This actually seems like an intuitive time to set the local complete time. I guess the reason we set it in `RequestChannel.Response` also is that we are trying to set it consistently with `responseCompleteTimeNanos`. I can't really think of a better solution than what you have here, but it might at least be helpful to add a comment of explanation?",
        "createdAt" : "2020-01-18T20:31:59Z",
        "updatedAt" : "2020-01-21T21:45:15Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0402e129-26c6-49f4-ac55-c4fbb112967b",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "I was looking at this code and the way it works today is super confusing. :) I think this change makes sense. However, I was curious how you noticed this. Was there a delay in getting to this point somehow? In theory, the value at this point should be very similar to the value we set during processing.",
        "createdAt" : "2020-01-23T16:07:01Z",
        "updatedAt" : "2020-01-23T16:07:02Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "3b99c5bd-417b-4843-8709-1f1ef8d20e5d",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "98b12f1a-2624-4608-85a1-ec49503fd316",
        "body" : "From what I remember, the value was close enough that I didn't consider it worth looking into. I encountered it when I added debug metrics to further subdivide the local time, and there appeared to be lost time, i.e. the sum wasn't adding to the whole.",
        "createdAt" : "2020-01-23T19:04:14Z",
        "updatedAt" : "2020-01-23T19:04:15Z",
        "lastEditedBy" : "98b12f1a-2624-4608-85a1-ec49503fd316",
        "tags" : [
        ]
      },
      {
        "id" : "280c2a05-1c72-4c3d-94fc-7fd850e49467",
        "parentId" : "cf11efc5-c6c5-4401-8ffd-b7b8eb8e80a2",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Makes sense, thanks.",
        "createdAt" : "2020-01-29T05:09:50Z",
        "updatedAt" : "2020-01-29T05:09:50Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aeda982db0838fcce7ca8a1fdad6d995a60c269e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +181,185 @@      // The local completion time may be set while processing the request. Only record it if it's unset.\n      if (request.apiLocalCompleteTimeNanos < 0)\n        request.apiLocalCompleteTimeNanos = time.nanoseconds\n    }\n  }"
  },
  {
    "id" : "ca15088b-27ce-4c70-b835-ee3a659a86bf",
    "prId" : 7897,
    "prUrl" : "https://github.com/apache/kafka/pull/7897#pullrequestreview-340730014",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0b5b4be-f184-4b78-9f0a-730930267736",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: why UNKNOWN_GENERATION_ID and UNKNOWN_PROTOCOL belongs to response while UNKNOWN_MEMBER_ID belongs to request? If there's no real good reason let's put them in a single class.",
        "createdAt" : "2020-01-08T22:07:23Z",
        "updatedAt" : "2020-01-14T20:20:27Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a7f3953f-2638-482b-930c-b4730dcc21cb",
        "parentId" : "e0b5b4be-f184-4b78-9f0a-730930267736",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I think it makes sense to move all the constant to request class.",
        "createdAt" : "2020-01-09T18:36:32Z",
        "updatedAt" : "2020-01-14T20:20:27Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "943bdf3604b662dfd20e7cfd586ada10e3412bc8",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1412,1416 @@      sendResponseCallback(JoinGroupResult(\n        List.empty,\n        JoinGroupRequest.UNKNOWN_MEMBER_ID,\n        JoinGroupRequest.UNKNOWN_GENERATION_ID,\n        JoinGroupRequest.UNKNOWN_PROTOCOL,"
  },
  {
    "id" : "b2e9217d-1d25-4d14-bb35-204395572c53",
    "prId" : 8238,
    "prUrl" : "https://github.com/apache/kafka/pull/8238#pullrequestreview-375429585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f34b7728-9b3c-4b6f-9eea-10fd63d2a8c5",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "Could we add tests in `KafkaApisTest` to cover this one?",
        "createdAt" : "2020-03-16T17:45:14Z",
        "updatedAt" : "2020-05-29T09:30:58Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "acb64f32f6fc2353dcaec2be44d05c6cd1a77b2d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1398,1402 @@  }\n\n  def handleListGroupsRequest(request: RequestChannel.Request): Unit = {\n    val listGroupsRequest = request.body[ListGroupsRequest]\n    val states = if (listGroupsRequest.data.statesFilter == null)"
  },
  {
    "id" : "5f2a8ca5-96b2-42e2-a639-ffd3cb5700f4",
    "prId" : 8253,
    "prUrl" : "https://github.com/apache/kafka/pull/8253#pullrequestreview-376246615",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27ba51fc-27f8-4a6f-b207-c738ec52bd72",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Just doublechecking, but does this cover any client version prior to 2.0? I think it would be good to mention this in the comment.",
        "createdAt" : "2020-03-17T17:24:05Z",
        "updatedAt" : "2020-03-18T06:02:55Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a213332e3d2cd8412e3ce81e81d7348d17f86f9",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +2217,2221 @@        // txn commit protocol >= 2 (version 2.3 and onwards) are guaranteed to have\n        // the fix to check for the loading error.\n        if (txnOffsetCommitRequest.version < 2) {\n          combinedCommitStatus.foreach { case (topicPartition, error) =>\n            if (error == Errors.COORDINATOR_LOAD_IN_PROGRESS) {"
  },
  {
    "id" : "63854b5d-a000-4997-baec-2fc1fabe56b7",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-445516197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1afcca4-2181-4381-a115-b8f1bded4966",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "nit: The indentation looks weird.",
        "createdAt" : "2020-07-03T14:58:06Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "f0f04b98-995f-48c9-875f-e0bc9e97d886",
        "parentId" : "b1afcca4-2181-4381-a115-b8f1bded4966",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "It looks weird but it's 2 to the right which should be \"correct\"",
        "createdAt" : "2020-07-09T11:09:53Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +960,964 @@        .setName(topic.name)\n        .setPartitions(topic.partitions.asScala.map(partition =>\n          new ListOffsetPartitionResponse()\n            .setPartitionIndex(partition.partitionIndex)\n            .setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)).asJava)"
  },
  {
    "id" : "c1bf59aa-3a3b-41e7-8918-8d87bfcc0150",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-466839774",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "We could use a scala `Option` now.",
        "createdAt" : "2020-07-03T15:09:24Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "722d39be-7ce6-4f4e-bc4c-05fc5300fec5",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "What do you mean here? @dajac ",
        "createdAt" : "2020-07-31T16:00:51Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "464c3d38-bdde-41a9-b561-9c48de48d77b",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "I was asking if we could use a Scala Option instead of the Java Optional. Keeping the Optional as-is is the way to go as we will likely add support for it in the auto-generated protocol to avoid having to manually handle sentinel values.",
        "createdAt" : "2020-08-04T09:10:46Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      },
      {
        "id" : "fdce84ac-ab3a-4d8c-b5e9-ab204a8ad660",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "@mimaison WDYT? I'm neutral.",
        "createdAt" : "2020-08-11T17:55:45Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "07457d52-d02c-4459-ad95-561779b02700",
        "parentId" : "ee65d2cc-781f-402e-9125-929d08f57612",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "Yes let's keep Optional here",
        "createdAt" : "2020-08-13T14:52:24Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +1045,1049 @@              partition.timestamp,\n              isolationLevelOpt,\n              if (partition.currentLeaderEpoch == ListOffsetResponse.UNKNOWN_EPOCH) Optional.empty() else Optional.of(partition.currentLeaderEpoch),\n              fetchOnlyFromLeader)\n"
  },
  {
    "id" : "3ee0a6c8-d0f4-45c3-b2b9-af1bd0cddfa9",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-459264101",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6010eafb-fa14-4e64-8fdb-844c5fe49ca9",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Redundant braces.",
        "createdAt" : "2020-07-31T15:59:36Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 231,
    "diffHunk" : "@@ -1,1 +1048,1052 @@              fetchOnlyFromLeader)\n\n            val response = foundOpt match {\n              case Some(found) =>\n                val partitionResponse = new ListOffsetPartitionResponse()"
  },
  {
    "id" : "23f70fd5-7b5c-4f76-9613-ec4a4cc8e85f",
    "prId" : 8295,
    "prUrl" : "https://github.com/apache/kafka/pull/8295#pullrequestreview-491452490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2aed618f-4158-4589-8416-7fda3d5b2c2f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Are we missing storage exception here?",
        "createdAt" : "2020-09-17T19:36:41Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "2e3ba70f-f64d-4704-94fa-8613becfea34",
        "parentId" : "2aed618f-4158-4589-8416-7fda3d5b2c2f",
        "authorId" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "body" : "This message has not changed. The way Github shows the diff here is confusing. If you look at https://github.com/apache/kafka/pull/8295/files#diff-d45970e44e2636ec847b63ac71827b71L944 on the right (which is the matching logic) you'll see it's already there.",
        "createdAt" : "2020-09-18T13:14:29Z",
        "updatedAt" : "2020-09-24T09:26:37Z",
        "lastEditedBy" : "d31db46e-de6d-4fea-8dc5-6f7b17b636be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78cb96fc13e5c337372b24b5ea50d7ade30485fc",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +981,985 @@            .setOldStyleOffsets(offsets.map(JLong.valueOf).asJava)\n        } catch {\n          // NOTE: UnknownTopicOrPartitionException and NotLeaderOrFollowerException are special cases since these error messages\n          // are typically transient and there is no value in logging the entire stack trace for the same\n          case e @ (_ : UnknownTopicOrPartitionException |"
  },
  {
    "id" : "911fef65-4e7a-449c-9a10-947470c79fbd",
    "prId" : 8311,
    "prUrl" : "https://github.com/apache/kafka/pull/8311#pullrequestreview-390824016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2157be9e-78f1-4128-a2d8-accc10ad5950",
        "parentId" : null,
        "authorId" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "body" : "While we are refactoring this, could we add a unit test in `KafkaApisTest`?",
        "createdAt" : "2020-04-09T14:52:57Z",
        "updatedAt" : "2020-06-04T13:26:20Z",
        "lastEditedBy" : "59ca7821-b29c-4f24-a9d5-cbd394145686",
        "tags" : [
        ]
      }
    ],
    "commit" : "2af415b22d9671ee7aff320f104d975b084ea450",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +2589,2593 @@  }\n\n  def handleAlterReplicaLogDirsRequest(request: RequestChannel.Request): Unit = {\n    val alterReplicaDirsRequest = request.body[AlterReplicaLogDirsRequest]\n    if (authorize(request.context, ALTER, CLUSTER, CLUSTER_NAME)) {"
  }
]