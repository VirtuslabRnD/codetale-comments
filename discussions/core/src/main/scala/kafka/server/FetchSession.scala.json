[
  {
    "id" : "6cbcf9f8-8852-499c-8bb2-572ed7952f0f",
    "prId" : 6832,
    "prUrl" : "https://github.com/apache/kafka/pull/6832#pullrequestreview-255347220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a084b53-7e10-403b-a876-a261987c7c56",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "If the preferred read replica is the leader, do we need to respond immediately?",
        "createdAt" : "2019-06-24T17:46:06Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "d79ee42a-4253-49ae-ac63-9abe1289714e",
        "parentId" : "3a084b53-7e10-403b-a876-a261987c7c56",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Is that what this does? I thought `mustRespond` just made sure to include that partition in the response.",
        "createdAt" : "2019-06-25T17:10:25Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "6eb1d489-48ac-4499-9dda-522c25d6ab89",
        "parentId" : "3a084b53-7e10-403b-a876-a261987c7c56",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I think you're right, but that just changes the question. If the preferred read replica is the leader, do we need to include it in the response? Wouldn't that imply that we always have to include the partition in the response?",
        "createdAt" : "2019-06-25T19:55:05Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "a478e5dc-c58e-49f6-bb2a-1140c980e89f",
        "parentId" : "3a084b53-7e10-403b-a876-a261987c7c56",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "If the leader picks itself as the preferred read replica, we could exclude it from the response (return none from ReplicaSelector). This actually makes sense b/c we are treating the presence of a preferred read replica ID as a signal to \"go somewhere else\" to the client and parts of the broker response logic. WDYT?",
        "createdAt" : "2019-06-27T15:35:15Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "454079eb-24dc-4ad1-ad85-f6e3f0a7d7a2",
        "parentId" : "3a084b53-7e10-403b-a876-a261987c7c56",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yes, that makes sense. So the preferred read replica is only set in the fetch response if it is a node other than the leader.",
        "createdAt" : "2019-06-27T16:38:57Z",
        "updatedAt" : "2019-07-04T02:59:14Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "4649c14a969cd8c88d06cad68f65d39a0cfdd905",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +145,149 @@        localLogStartOffset = respData.logStartOffset\n    }\n    if (respData.preferredReadReplica.isPresent) {\n      // If the broker computed a preferred read replica, we need to include it in the response\n      mustRespond = true"
  },
  {
    "id" : "e613b7db-e1ce-4715-8adb-57f4c3e568ea",
    "prId" : 7970,
    "prUrl" : "https://github.com/apache/kafka/pull/7970#pullrequestreview-344807079",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39a28c70-4d3d-4524-bddf-9ee184a69f33",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "It seems like rather than use None for older fetch requests, we could just initialize the leaderEpoch to the current leader epoch.  That way, we could at least detect epoch changes.  Although we'd have to figure out how to handle the error-- probably just by dropping the session.",
        "createdAt" : "2020-01-16T16:40:11Z",
        "updatedAt" : "2020-01-16T18:31:42Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "545a61d0-97e7-40a9-9dea-b067094fe9fc",
        "parentId" : "39a28c70-4d3d-4524-bddf-9ee184a69f33",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Can you elaborate a little bit? I think the validation only has value if it comes from the client making the request.",
        "createdAt" : "2020-01-16T17:23:05Z",
        "updatedAt" : "2020-01-16T18:31:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0e2f4756-67bc-4e73-bda2-20ae3d6d0d95",
        "parentId" : "39a28c70-4d3d-4524-bddf-9ee184a69f33",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Discussed offline. It's an interesting thought. The problem is we don't have an error that would force a follower to go through the truncation phase. We could force a retry and we could drop the session, but the follower would still be able to continue.",
        "createdAt" : "2020-01-16T17:37:36Z",
        "updatedAt" : "2020-01-16T18:31:42Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "05685fa7-c01b-4899-81c9-7e8d896d10de",
        "parentId" : "39a28c70-4d3d-4524-bddf-9ee184a69f33",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Can we file a separate JIRA for this idea?",
        "createdAt" : "2020-01-17T19:30:05Z",
        "updatedAt" : "2020-01-17T19:30:06Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "ddd34ffc-b9a6-41ee-8e73-0fbf9de975fb",
        "parentId" : "39a28c70-4d3d-4524-bddf-9ee184a69f33",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "Thinking about this more, I'm not sure it's worth it.  Without true leader epoch awareness in the client, we don't have a way to force the client to refresh metadata and use a different leader, which is what we would need here.  So maybe my initial idea was a bit half-baked-- sorry. ",
        "createdAt" : "2020-01-17T19:53:31Z",
        "updatedAt" : "2020-01-17T19:53:31Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "accca8208544725928f00dda822d160c1f4be048",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +77,81 @@                      var fetchOffset: Long,\n                      var highWatermark: Long,\n                      var leaderEpoch: Optional[Integer],\n                      var fetcherLogStartOffset: Long,\n                      var localLogStartOffset: Long)"
  },
  {
    "id" : "68b6f775-e1ad-48fa-9ba3-5fb3aa9ecf87",
    "prId" : 9944,
    "prUrl" : "https://github.com/apache/kafka/pull/9944#pullrequestreview-653843087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05ec1685-424e-4a2e-bb73-cd7a385a00a9",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Hmm, it seems that we can't pass in an empty topicIds since partition iterator is not empty?",
        "createdAt" : "2021-05-03T23:43:56Z",
        "updatedAt" : "2021-05-06T01:32:07Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "5f1cbd93-b8a8-44e2-88eb-98fa68dc2d73",
        "parentId" : "05ec1685-424e-4a2e-bb73-cd7a385a00a9",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "ah good catch on this.",
        "createdAt" : "2021-05-06T02:01:20Z",
        "updatedAt" : "2021-05-06T02:01:20Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      },
      {
        "id" : "b1dfc600-c8d6-42da-9d32-849a43e30c9c",
        "parentId" : "05ec1685-424e-4a2e-bb73-cd7a385a00a9",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "Ah wait. The iterator is empty here. We create a new one `(new FetchSession.RESP_MAP).entrySet.iterator` and do not use `updates`. This is because the session is an error one.",
        "createdAt" : "2021-05-06T19:58:26Z",
        "updatedAt" : "2021-05-06T19:58:27Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a47290d9a46db70b9ed3273ddafedbc8827e8da",
    "line" : 217,
    "diffHunk" : "@@ -1,1 +336,340 @@\n  override def getResponseSize(updates: FetchSession.RESP_MAP, versionId: Short): Int = {\n    FetchResponse.sizeOf(versionId, (new FetchSession.RESP_MAP).entrySet.iterator, Collections.emptyMap())\n  }\n"
  },
  {
    "id" : "6c89acaf-5105-4d04-ac56-4f29d0f29f1c",
    "prId" : 9944,
    "prUrl" : "https://github.com/apache/kafka/pull/9944#pullrequestreview-686913535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28e38256-6e91-48ba-a11b-b3ba0ecdf1b7",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Should we include topicId in hashCode() and equals()?",
        "createdAt" : "2021-06-11T00:09:33Z",
        "updatedAt" : "2021-06-14T22:25:42Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "00c4d4ba-dad0-4ccc-9dbd-39cce37420cd",
        "parentId" : "28e38256-6e91-48ba-a11b-b3ba0ecdf1b7",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "I thought about this, and originally we compared the topic IDs in the session by grabbing cached partitions and comparing to the IDs in the request. Since we have a new mechanism (the topic ID map) we may no longer need to do this and I can add the ID to the hashcode and equals methods.",
        "createdAt" : "2021-06-15T17:03:49Z",
        "updatedAt" : "2021-06-15T17:03:50Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      },
      {
        "id" : "3d1fa7c0-56da-4fc0-98d7-ee26b002fcfd",
        "parentId" : "28e38256-6e91-48ba-a11b-b3ba0ecdf1b7",
        "authorId" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "body" : "Ah, I found another use -- we lookup partitions toForget using the hashCode. Right now, toForget is a list of topic partitions and we don't directly use the ID provided in the request. We could look up the topic ID from the topic ID map and use it (we could also remove from the session map if we do remove the topic)",
        "createdAt" : "2021-06-17T23:06:25Z",
        "updatedAt" : "2021-06-17T23:06:25Z",
        "lastEditedBy" : "a31dcef8-b459-4b48-bb49-44e910fa9f34",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a47290d9a46db70b9ed3273ddafedbc8827e8da",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +72,76 @@  */\nclass CachedPartition(val topic: String,\n                      val topicId: Uuid,\n                      val partition: Int,\n                      var maxBytes: Int,"
  },
  {
    "id" : "c5c993a2-db2e-4361-9ee9-0ddfc0afc3d0",
    "prId" : 10318,
    "prUrl" : "https://github.com/apache/kafka/pull/10318#pullrequestreview-613563772",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a63812ae-a87a-465c-b75f-46df28f3ff3a",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Does it result in the side effect that we always fetch the no-data partitions?",
        "createdAt" : "2021-03-16T09:40:15Z",
        "updatedAt" : "2021-03-16T09:40:15Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "1fb113e4-3694-4c9d-917b-b24e6ccfd985",
        "parentId" : "a63812ae-a87a-465c-b75f-46df28f3ff3a",
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "@chia7712 I believe it only affects the order of the fetching on the following fetch. Previously those partitions would be penalized in fetch order if their hwm or log start offset updated and there was no data to be returned.\r\n\r\nAll of the partitions where the fetch metadata had been updated without any data to be returned will end up behind the partitions ordered prior to them that were part of the full fetch response. ",
        "createdAt" : "2021-03-16T10:38:19Z",
        "updatedAt" : "2021-03-16T10:38:19Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      },
      {
        "id" : "a4926a40-c2fc-4fde-a920-16fccd9e1a5f",
        "parentId" : "a63812ae-a87a-465c-b75f-46df28f3ff3a",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "Thanks for nice explanation!",
        "createdAt" : "2021-03-16T17:58:18Z",
        "updatedAt" : "2021-03-16T17:58:19Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "c5b2f8da8cc65f797c1517d4f8b8ca7c7e797a45",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +429,433 @@        if (mustRespond) {\n          nextElement = element\n          if (updateFetchContextAndRemoveUnselected && FetchResponse.recordsSize(respData) > 0) {\n            session.partitionMap.remove(cachedPart)\n            session.partitionMap.mustAdd(cachedPart)"
  }
]