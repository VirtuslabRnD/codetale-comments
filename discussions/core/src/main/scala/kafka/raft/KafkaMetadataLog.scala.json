[
  {
    "id" : "dd189997-392f-49a3-9620-335c307255c2",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-565778020",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d55d72f3-19b6-4da4-8d83-297a411ef60e",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Does the log recovery logic need to be updated at all for the presence of snapshots?",
        "createdAt" : "2021-01-07T20:22:16Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "ca3a75f2-f755-45f0-9058-6dcded4c510e",
        "parentId" : "d55d72f3-19b6-4da4-8d83-297a411ef60e",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "This PR changes the recovery logic so that the log is `truncateFullyToLatestSnapshot()` (https://github.com/apache/kafka/pull/9816/files#diff-b332f85b04775c821226b6f704e91d51f9647f29ba73dace65b99cf36f6b9ceaR298) if the `latestSnapshotId` is greater than `new OffsetAndEpoch(endOffset().offset, log.lastFetchedEpoch)`.\r\n\r\nThis can happen when a follower crashed after downloading a snapshot from the leader but before calling `truncateFullyToLatestSnapshot()`. Or https://github.com/apache/kafka/pull/9816/files#diff-b332f85b04775c821226b6f704e91d51f9647f29ba73dace65b99cf36f6b9ceaR155\r\n\r\nI think this is correct because `KafkaRaftClient` guarantees that any offset less then high watermark has been flushed and after https://issues.apache.org/jira/browse/KAFKA-10800 any snapshot generated by the state machine will be less than or equal to the high-watermark.",
        "createdAt" : "2021-01-11T22:07:41Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +43,47 @@import scala.compat.java8.OptionConverters._\n\nfinal class KafkaMetadataLog private (\n  log: Log,\n  // This object needs to be thread-safe because it is used by the snapshotting thread to notify the"
  },
  {
    "id" : "f33484bd-90e6-4a98-a08c-af498d017c57",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-568421679",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69674b23-9c1c-40b7-938b-884bbc483261",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do we need to delete older snapshots?",
        "createdAt" : "2021-01-13T02:50:24Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "e18cadae-2c22-4b5d-9271-3dd4b3be31cf",
        "parentId" : "69674b23-9c1c-40b7-938b-884bbc483261",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yes. Up to this point we don't delete any snapshot. I was thinking of doing this in a future PR.\r\n\r\nhttps://issues.apache.org/jira/browse/KAFKA-12205",
        "createdAt" : "2021-01-14T16:44:35Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 162,
    "diffHunk" : "@@ -1,1 +179,183 @@        // Truncate the log fully if the latest snapshot is greater than the log end offset\n\n        log.truncateFullyAndStartAt(snapshotId.offset)\n        oldestSnapshotId = latestSnapshotId\n"
  },
  {
    "id" : "e34dee6f-a83d-4ea3-b872-29e5dda71183",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-568449564",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d77c808-5629-4d88-933e-27319531109e",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Man, this is annoying. There is also a `pollLast` which returns null if the set is empty.",
        "createdAt" : "2021-01-13T02:57:31Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "321fea21-b767-40fe-9d97-d41ba34e4f6c",
        "parentId" : "8d77c808-5629-4d88-933e-27319531109e",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I agree. Unfortunately, `pollLast` removes the element from the set. I don't think we have a choice but to do this. ",
        "createdAt" : "2021-01-14T17:14:00Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 232,
    "diffHunk" : "@@ -1,1 +263,267 @@      Optional.of(snapshotIds.last)\n    } catch {\n      case _: NoSuchElementException =>\n        Optional.empty()\n    }"
  },
  {
    "id" : "df1993ee-2314-4238-a159-d7e55f3f90aa",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-566845278",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "542e86ed-ad43-480d-be69-204614aa803d",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Kind of a general note, but I think there are some logging gaps in here. I think we should tend toward the verbose side initially since snapshot events will be relatively infrequent.",
        "createdAt" : "2021-01-13T03:12:23Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 266,
    "diffHunk" : "@@ -1,1 +297,301 @@}\n\nobject KafkaMetadataLog {\n  def apply(\n    log: Log,"
  },
  {
    "id" : "5a4efc22-ea4d-428a-a3d8-4bfa16be6383",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-576636032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18d29206-a1ac-4637-974d-c40421843b62",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I guess it's probably better to throw here. I was trying to think how we could end up here, but the only way I came up with is an invalid state transition which left the start or end offset inconsistent with the segment data. Sadly we have had a number of those bugs in the past. I debated whether we should just delete the snapshot, but I'm not sure that helps if we are left with inconsistent start/end offsets.",
        "createdAt" : "2021-01-15T01:54:08Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "39c34e04-cadf-47f8-8992-cf96ef9c1245",
        "parentId" : "18d29206-a1ac-4637-974d-c40421843b62",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I don't think we can delete the snapshot if `startOffset` is greater than 0.\r\n\r\nI think we need multiple bugs to throw this exception. Like you said the leader epoch cache would need to be inconsistent with respect to the log itself. Or we don't have a snapshot at the log start offset.\r\n\r\nI think at this point the best we can do is throw an exception. I think that deleting the snapshots and/or log could result in data loss. Maybe in the future we can do a `truncateFullyAtLastestSnapshot` but I would like to have a concrete reason for doing this.",
        "createdAt" : "2021-01-26T18:23:05Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 108,
    "diffHunk" : "@@ -1,1 +126,130 @@        } else {\n          throw new KafkaException(\n            s\"Log doesn't have a last fetch epoch and there is a snapshot ($snapshotId). \" +\n            s\"Expected the snapshot's end offset to match the log's end offset ($logEndOffset) \" +\n            s\"and the log start offset ($startOffset)\""
  },
  {
    "id" : "5862de13-fb69-46f1-83b7-f4263dd48843",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-576674479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80990245-c9b1-4fd8-9528-2bea8973b31f",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Is it useful here to ensure that `snapshotId` is indeed lower than the high watermark?",
        "createdAt" : "2021-01-15T02:12:19Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "22f26789-45ac-4e26-a634-ffd61e137d66",
        "parentId" : "80990245-c9b1-4fd8-9528-2bea8973b31f",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yes but only when it is the state machine that is creating the snapshot. When the raft client is creating the snapshot because it is downloading it from the leader we don't want to validate this.\r\n\r\nWe'll add this check to the `RaftClient::createSnapshot` API when we implement https://issues.apache.org/jira/browse/KAFKA-10800",
        "createdAt" : "2021-01-26T19:15:29Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 202,
    "diffHunk" : "@@ -1,1 +236,240 @@    latestSnapshotId().ifPresent { latest =>\n      if (latest.epoch > snapshotId.epoch || latest.offset > snapshotId.offset) {\n        // Since snapshots are less than the high-watermark absolute offset comparison is okay.\n        throw new IllegalArgumentException(\n          s\"Attemting to create a snapshot ($snapshotId) that is not greater than the latest snapshot ($latest)\""
  },
  {
    "id" : "ae222e9f-b5f0-4213-9c85-b13b90e7534f",
    "prId" : 9816,
    "prUrl" : "https://github.com/apache/kafka/pull/9816#pullrequestreview-576925096",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c64d79ee-0df0-44fb-bdbf-377e24619df2",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Do we need to keep this as a var or could we access it from `snapshotIds` when needed (as we do for `latestSnapshotId`)?",
        "createdAt" : "2021-01-15T02:24:14Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "b075083f-bd7e-40ce-be91-b15c37edd7bd",
        "parentId" : "c64d79ee-0df0-44fb-bdbf-377e24619df2",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Sorry for the delay reply. I missed this comment for some reason.\r\n\r\nAt the moment we need to keep this variable/reference. In this PR, the `oldestSnapshotId` can be anywhere in the `snapshotIds` set. I think that when we implement https://issues.apache.org/jira/browse/KAFKA-12205 can remove this variable.\r\n\r\nhttps://issues.apache.org/jira/browse/KAFKA-12205 tracks the work needed to delete any snapshot that is less than the log start offset.",
        "createdAt" : "2021-01-26T17:46:18Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "958babe5-7377-403f-b873-9660bbd31112",
        "parentId" : "c64d79ee-0df0-44fb-bdbf-377e24619df2",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Hmm... It might be helpful to document this fact somewhere since it seems non-obvious. It surprised me anyway.",
        "createdAt" : "2021-01-27T02:18:22Z",
        "updatedAt" : "2021-01-29T19:24:36Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d7d4d25e92681ccdea18c2a388a367ac0993ab7",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +56,60 @@   * snapshot id in the snapshotIds set.\n   */\n  private[this] var oldestSnapshotId = snapshotIds\n    .stream()\n    .filter(_.offset == startOffset)"
  },
  {
    "id" : "ca1eae25-6717-46de-b2b4-2031666616cb",
    "prId" : 10021,
    "prUrl" : "https://github.com/apache/kafka/pull/10021#pullrequestreview-599231367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "050cfbfa-efe5-420e-aa9e-5640e451e281",
        "parentId" : null,
        "authorId" : "51186e61-891a-464c-8c1d-9cf13522da98",
        "body" : "why we needs `false` here, it seems the default value of calling `headSet`?",
        "createdAt" : "2021-02-26T02:27:23Z",
        "updatedAt" : "2021-03-11T01:24:32Z",
        "lastEditedBy" : "51186e61-891a-464c-8c1d-9cf13522da98",
        "tags" : [
        ]
      },
      {
        "id" : "c5279077-c53c-4afc-8360-836e4ead5dcb",
        "parentId" : "050cfbfa-efe5-420e-aa9e-5640e451e281",
        "authorId" : "12f98c82-b9ef-4668-aa6f-5a62bf3439bb",
        "body" : "I add `false` to remind us that this headSet is not inclusive, I think it doesn't matter whether add or not, both are OK.",
        "createdAt" : "2021-02-26T02:36:58Z",
        "updatedAt" : "2021-03-11T01:24:32Z",
        "lastEditedBy" : "12f98c82-b9ef-4668-aa6f-5a62bf3439bb",
        "tags" : [
        ]
      },
      {
        "id" : "8ad2a5ce-9f59-4ada-90d6-6826f4e9e1d0",
        "parentId" : "050cfbfa-efe5-420e-aa9e-5640e451e281",
        "authorId" : "51186e61-891a-464c-8c1d-9cf13522da98",
        "body" : "makes sense, ty!",
        "createdAt" : "2021-02-26T03:44:59Z",
        "updatedAt" : "2021-03-11T01:24:32Z",
        "lastEditedBy" : "51186e61-891a-464c-8c1d-9cf13522da98",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce539fa117584682bd25c719e93ed5f371772b34",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +287,291 @@   */\n  private def removeSnapshotFilesBefore(logStartSnapshotId: OffsetAndEpoch): Unit = {\n    val expiredSnapshotIdsIter = snapshotIds.headSet(logStartSnapshotId, false).iterator()\n    while (expiredSnapshotIdsIter.hasNext) {\n      val snapshotId = expiredSnapshotIdsIter.next()"
  },
  {
    "id" : "cbb836b4-e7dc-40d3-8ae5-91f6ad3d87ec",
    "prId" : 10256,
    "prUrl" : "https://github.com/apache/kafka/pull/10256#pullrequestreview-604483374",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45575fe7-9b00-4ce8-be6f-48b032800d20",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "üëç  Makes sense to move this here since KafkaMetadataLog fully owns the Log's lifecycle",
        "createdAt" : "2021-03-04T19:41:55Z",
        "updatedAt" : "2021-03-04T20:36:43Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "fad668873765974413cef49f63688665702983c6",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +305,309 @@    val defaultLogConfig = LogConfig(props)\n\n    val log = Log(\n      dir = dataDir,\n      config = defaultLogConfig,"
  }
]