[
  {
    "id" : "b6990de4-9f31-4f12-bf51-9a449776d85e",
    "prId" : 4479,
    "prUrl" : "https://github.com/apache/kafka/pull/4479#pullrequestreview-92814289",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "864242f1-c7d2-4ce6-b7d1-1e82f2c730c8",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "This still feels a bit hacky. As an alternative, maybe we can let the offset selector be provided as a function. Something like this:\r\n\r\n```scala\r\ndef cleanupGroupMetadata(\r\n groups: Iterable[GroupMetadata], \r\n collectOffsetsToRemove: Group => Map[TopicPartition, OffsetAndMetadata])\r\n```\r\n\r\nWhat do you think?",
        "createdAt" : "2018-01-30T22:20:49Z",
        "updatedAt" : "2018-01-31T19:11:21Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "580caacb-72a1-46b4-a3e5-e98b6213c967",
        "parentId" : "864242f1-c7d2-4ce6-b7d1-1e82f2c730c8",
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "I'm not sure which part you consider hacky, and am trying to understand your suggestion.\r\n\r\nFor the sake of `deleteGroups` functionality, we can use `group.allOffsets` that conforms to the function signature above. But how about the existing functionality, where we want to delete specific topic partitions from a group: `groupManager.cleanupGroupMetadata(Some(topicPartitions), groupManager.currentGroups, time.milliseconds())` and populate the corresponding `OffsetAndMetadata` values? I'm assuming we want to reuse the same `cleanupGroupMetadata` method for both cases.\r\n\r\nOn the same assumption, we also need to factor in the concept of current time so we can determine the expired offsets for the existing functionality.\r\n\r\nOn the other hand if you are proposing to create A new `cleanupGroupMetadata` method that calls on the existing method, we should make this call once per group (since topic partitions are group-specific).\r\n\r\nOr maybe I'm missing the point :)",
        "createdAt" : "2018-01-31T03:40:55Z",
        "updatedAt" : "2018-01-31T19:11:21Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      },
      {
        "id" : "57e4e53d-bfb3-4c49-807d-d506de269e23",
        "parentId" : "864242f1-c7d2-4ce6-b7d1-1e82f2c730c8",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It's not that big of a deal. I just thought it was a mild abuse to reuse the expiration logic to delete all offsets. Alternatively, what I was suggesting is to let the caller choose the offsets to delete.",
        "createdAt" : "2018-01-31T06:09:39Z",
        "updatedAt" : "2018-01-31T19:11:21Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca60b651ee8c2c38a6122b0300504aad8d2972b9",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +376,380 @@\n      if (eligibleGroups.nonEmpty) {\n        groupManager.cleanupGroupMetadata(None, eligibleGroups, Long.MaxValue)\n        groupErrors ++= eligibleGroups.map(_.groupId -> Errors.NONE).toMap\n        info(s\"The following groups were deleted: ${eligibleGroups.map(_.groupId).mkString(\", \")}\")"
  },
  {
    "id" : "4aef60da-fd15-476b-9a0b-5a0ac737d789",
    "prId" : 4504,
    "prUrl" : "https://github.com/apache/kafka/pull/4504#pullrequestreview-98375530",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa5117ad-8727-4f3e-afee-fb1ecb1e0efe",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm debating whether we should grab the group lock in these functions. I know the caller is holding the lock already when it invokes them, but I'm wondering if we should be more defensive in case we change the logic. At a minimum, we can document the fact that the function is invoked while holding the lock.",
        "createdAt" : "2018-02-21T19:48:15Z",
        "updatedAt" : "2018-02-22T00:13:13Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "195d8b5c-d438-4b92-aae7-1b482eb00779",
        "parentId" : "fa5117ad-8727-4f3e-afee-fb1ecb1e0efe",
        "authorId" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "body" : "Thanks for the quick feedback. Seems fair. I added some comments to clarify this matter. Please let me know if you think they're not adequate. Thanks.",
        "createdAt" : "2018-02-21T21:55:12Z",
        "updatedAt" : "2018-02-22T00:13:13Z",
        "lastEditedBy" : "2a5e5a4d-e0e2-4e26-b139-0930dd63f949",
        "tags" : [
        ]
      }
    ],
    "commit" : "05a6eb50b5de80647cd6a8cae72551f5e94ccb70",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +376,380 @@\n      if (eligibleGroups.nonEmpty) {\n        val offsetsRemoved = groupManager.cleanupGroupMetadata(eligibleGroups, group => {\n          group.removeAllOffsets()\n        })"
  },
  {
    "id" : "ad5f89db-775b-4516-8ed0-dc72ff8d06ff",
    "prId" : 4788,
    "prUrl" : "https://github.com/apache/kafka/pull/4788#pullrequestreview-108229349",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3b3e556-eb66-4147-aa29-d8533ee2ab1d",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The indention below seems not aligned?",
        "createdAt" : "2018-03-29T22:59:34Z",
        "updatedAt" : "2018-03-30T01:01:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ccc3e85feaf510a8730f6dddb63fb9fc8c592124",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +249,253 @@\n      case None =>\n        groupManager.getGroup(groupId) match {\n          case None => responseCallback(Array.empty, Errors.UNKNOWN_MEMBER_ID)\n          case Some(group) => doSyncGroup(group, generation, memberId, groupAssignment, responseCallback)"
  },
  {
    "id" : "d0b3d0ca-5474-4e78-b608-a9b292eeec69",
    "prId" : 5962,
    "prUrl" : "https://github.com/apache/kafka/pull/5962#pullrequestreview-189504164",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a038565b-0342-4349-b055-b7215cd346a5",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Why do we define a new `NewMemberJoinTimeoutMs` instead of using the member's brought-in session timeout?",
        "createdAt" : "2018-12-28T23:23:24Z",
        "updatedAt" : "2018-12-28T23:23:24Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "4597285d-31b4-4e67-ab91-5f50ddcb0c10",
        "parentId" : "a038565b-0342-4349-b055-b7215cd346a5",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "As stated above, for new members they do not have member ids and cannot start sending heartbeats, so session timeout would not matter here. Thus we need a separate value just for this purpose.",
        "createdAt" : "2019-01-04T19:47:03Z",
        "updatedAt" : "2019-01-04T19:47:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "259f70653f00eaeec3377abc30580ca801974b78",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +722,726 @@    // members in the rebalance. To prevent this going on indefinitely, we timeout JoinGroup requests\n    // for new members. If the new member is still there, we expect it to retry.\n    completeAndScheduleNextExpiration(group, member, NewMemberJoinTimeoutMs)\n\n    maybePrepareRebalance(group, s\"Adding new member $memberId\")"
  },
  {
    "id" : "e8792bbe-1ebe-4b00-af40-bc9210f37875",
    "prId" : 6058,
    "prUrl" : "https://github.com/apache/kafka/pull/6058#pullrequestreview-188880567",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70c1c09c-e589-4067-94b6-72519ac91008",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "With the changes here, I think the `Empty` case shouldn't be possible. We know we have one member at least. ",
        "createdAt" : "2019-01-03T16:40:09Z",
        "updatedAt" : "2019-01-15T03:26:21Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "29f668ef1a9b2ee5939791b9bd5b89bf1a1660bb",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +231,235 @@\n          case Stable =>\n            val member = group.get(memberId)\n            if (group.isLeader(memberId) || !member.matches(protocols)) {\n              // force a rebalance if a member has changed metadata or if the leader sends JoinGroup."
  }
]