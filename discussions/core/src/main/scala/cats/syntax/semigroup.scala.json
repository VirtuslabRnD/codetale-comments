[
  {
    "id" : "53c15383-d391-45e1-ab34-88a2de3fc960",
    "prId" : 368,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "784e22fe-0d15-403f-a44b-1ead8b781956",
        "parentId" : null,
        "authorId" : "b714495a-5740-47d4-aaaa-98f354f5c0a7",
        "body" : "Sorry, I still don't have a good picture of what Cats is doing with Simulacrum and/or Machinist. What's the advantage of using `macro Ops.binop[A, A]` instead of the obvious `A.combine(lhs, rhs)`?\n",
        "createdAt" : "2015-06-24T12:27:26Z",
        "updatedAt" : "2015-07-07T15:11:57Z",
        "lastEditedBy" : "b714495a-5740-47d4-aaaa-98f354f5c0a7",
        "tags" : [
        ]
      },
      {
        "id" : "74985af9-d18b-4dc1-bea1-fcb9539fe8f7",
        "parentId" : "784e22fe-0d15-403f-a44b-1ead8b781956",
        "authorId" : "89a3e0e3-e301-4aa8-b150-74070eb5a619",
        "body" : "Consider the following generic code using semigroup:\n\n```\ndef sum[A: Semigroup](as: Iteratable[A]): A =\n  as.foldLeft(0)(_ |+| _)\n```\n\nSay I pass it a `Vector[Int]` with 100,000 items. With the old code, I would instantiate 100k instances of `SemigroupOps`, one for each step in the `foldLeft`. With the new code, I would instantiate 0 instances of `SemigroupOps`; the code would be equivalent to:\n\n```\ndef sum[A](as: Iteratable[A])(implicit ev: Semigroup[A]): A =\n  as.foldLeft(0)((x, y) => ev.combine(x, y))\n```\n\nSo it is an efficiency improvement that removes the penalty of using Ops implicits rather than explicitly threading and using the type class instances.\n",
        "createdAt" : "2015-06-24T17:09:38Z",
        "updatedAt" : "2015-07-07T15:11:57Z",
        "lastEditedBy" : "89a3e0e3-e301-4aa8-b150-74070eb5a619",
        "tags" : [
        ]
      },
      {
        "id" : "b05e9196-1da1-4f39-99fb-39da35d87ae9",
        "parentId" : "784e22fe-0d15-403f-a44b-1ead8b781956",
        "authorId" : "b714495a-5740-47d4-aaaa-98f354f5c0a7",
        "body" : "@non thanks. That makes sense. What's to prevent us from doing this in other places, such as in `FlatMapOps`?\n",
        "createdAt" : "2015-06-25T00:47:27Z",
        "updatedAt" : "2015-07-07T15:11:57Z",
        "lastEditedBy" : "b714495a-5740-47d4-aaaa-98f354f5c0a7",
        "tags" : [
        ]
      },
      {
        "id" : "68446f12-8a37-41fe-8a05-6b526ea074c1",
        "parentId" : "784e22fe-0d15-403f-a44b-1ead8b781956",
        "authorId" : "89a3e0e3-e301-4aa8-b150-74070eb5a619",
        "body" : "Nothing -- I'd be happy to add this everywhere. I wanted to add it here since these are the places where the cost of the actual work (e.g. integer addition) is so small that the overhead would be particularly unfortunate (although we will still do better than Scalaz where we would be allocating a by-name parameter every time).\n",
        "createdAt" : "2015-06-25T01:17:35Z",
        "updatedAt" : "2015-07-07T15:11:57Z",
        "lastEditedBy" : "89a3e0e3-e301-4aa8-b150-74070eb5a619",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e0453fabfbf0c73efb82bafed9348d4e2c85f9b",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +11,15 @@\nclass SemigroupOps[A: Semigroup](lhs: A) {\n  def |+|(rhs: A): A = macro Ops.binop[A, A]\n  def combine(rhs: A): A = macro Ops.binop[A, A]\n  def combineN(rhs: Int): A = macro Ops.binop[A, A]"
  }
]