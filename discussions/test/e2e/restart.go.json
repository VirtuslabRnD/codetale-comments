[
  {
    "id" : "ee0f4eab-379b-4a28-9da1-39304d97e2b2",
    "prId" : 33144,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/33144#pullrequestreview-1849245",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "438c1fac-5831-4c91-a9f2-5d4522778a5d",
        "parentId" : null,
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "this is a hard reset - is this the same effect as we had before?\n",
        "createdAt" : "2016-09-27T23:42:28Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "b673af8c-d9c9-4ca3-81f4-d5ba44ea9031",
        "parentId" : "438c1fac-5831-4c91-a9f2-5d4522778a5d",
        "authorId" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "body" : "Not quite. Before they were doing a mig rolling update, which implicitly deleted and recreated the VM.\n",
        "createdAt" : "2016-09-28T00:03:12Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc79cc82ced892e47b5aa5ea7a8edebf1f553877",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +141,145 @@\t\tfmt.Sprintf(\"--project=%s\", framework.TestContext.CloudConfig.ProjectID),\n\t\t\"instances\",\n\t\t\"reset\",\n\t}\n\targs = append(args, nodeNames...)"
  },
  {
    "id" : "06453ebc-9b02-4376-91df-9bf5d7770a17",
    "prId" : 33144,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/33144#pullrequestreview-1976484",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "10e7a334-b792-4a3d-89ee-d97b5ce88595",
        "parentId" : null,
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "will this call fail immediately after the node is reset?\n",
        "createdAt" : "2016-09-27T23:43:51Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "5d5d4904-bf25-415a-9c52-187a0867e12b",
        "parentId" : "10e7a334-b792-4a3d-89ee-d97b5ce88595",
        "authorId" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "body" : "No, it will report the node as healthy until it misses a heartbeat, then it will disappear, then reappear as NotReady.\n",
        "createdAt" : "2016-09-28T00:03:53Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "tags" : [
        ]
      },
      {
        "id" : "fe322577-94ad-496f-a5c1-79ab5ec13007",
        "parentId" : "10e7a334-b792-4a3d-89ee-d97b5ce88595",
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "will any of those result in this call returning an error?\n",
        "createdAt" : "2016-09-28T00:08:24Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "8697f07f-721f-462a-a473-69f8bea68b1a",
        "parentId" : "10e7a334-b792-4a3d-89ee-d97b5ce88595",
        "authorId" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "body" : "Nope. My previous explanation wasn't quite precise. It will report as healthy until it misses a heartbeat, the immediately it will show as NodeNotReady. It won't disappear, and it won't cause an error.\n",
        "createdAt" : "2016-09-28T16:31:27Z",
        "updatedAt" : "2016-09-28T16:36:39Z",
        "lastEditedBy" : "c532215f-ed76-4a19-b066-8676d269eaf1",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc79cc82ced892e47b5aa5ea7a8edebf1f553877",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +152,156 @@\tfor _, name := range nodeNames {\n\t\tif err := wait.Poll(30*time.Second, 5*time.Minute, func() (bool, error) {\n\t\t\tnode, err := f.Client.Nodes().Get(name)\n\t\t\tif err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"error getting node info after reboot: %s\", err)"
  },
  {
    "id" : "293b5a2a-5855-4a29-91dc-bc8eec87951a",
    "prId" : 26711,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a5a8b7b-72aa-4764-90d9-6e03e32308a3",
        "parentId" : null,
        "authorId" : "edc2bb46-795f-4aea-9ce4-1822d9e81d73",
        "body" : "total nit: comment could be updated to match condition check. \n",
        "createdAt" : "2016-06-02T14:46:59Z",
        "updatedAt" : "2016-06-02T14:46:59Z",
        "lastEditedBy" : "edc2bb46-795f-4aea-9ce4-1822d9e81d73",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b082ce57db14bec42d82036a69fe71ca52433d0",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +94,98 @@\t\tremaining := framework.RestartPodReadyAgainTimeout - time.Since(podCheckStart)\n\t\tif !framework.CheckPodsRunningReadyOrSucceeded(f.Client, ns, podNamesAfter, remaining) {\n\t\t\tframework.Failf(\"At least one pod wasn't running and ready after the restart.\")\n\t\t}\n\t})"
  },
  {
    "id" : "b0e37d76-9ba9-45d7-984d-fa134bd52649",
    "prId" : 19297,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f3ff936-8a56-4dca-9b9b-632b32335f04",
        "parentId" : null,
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "do you have an issue to track this?\n",
        "createdAt" : "2016-01-06T20:07:53Z",
        "updatedAt" : "2016-01-06T20:16:35Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "673a745c-bef9-4ba1-8f46-b0b5a7ba0faf",
        "parentId" : "7f3ff936-8a56-4dca-9b9b-632b32335f04",
        "authorId" : "d513ff43-94d3-4f43-8358-1fb8132b6aae",
        "body" : "Not yet, but that's what my next task is, going through all the `[Skipped]` tests and filing issues for them.\n",
        "createdAt" : "2016-01-06T20:09:50Z",
        "updatedAt" : "2016-01-06T20:16:35Z",
        "lastEditedBy" : "d513ff43-94d3-4f43-8358-1fb8132b6aae",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3cbe341061dc313e02602191629096e5a0ddc49",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +49,53 @@)\n\n// TODO(ihmccreery): This is skipped because it was previously in\n// REBOOT_SKIP_TESTS, dates back before version control (#10078)\nvar _ = Describe(\"Restart [Skipped]\", func() {"
  },
  {
    "id" : "b0da98d3-0c84-4895-9e35-63f9acde3d45",
    "prId" : 8837,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "parentId" : null,
        "authorId" : null,
        "body" : "This is unfortunately way too long, e.g. we have 100-node scalability test clusters.\nCan we perhaps pipeline/parallelise a few reboots at a time?  At least 2 so that we can make progress if one gets delayed.\n",
        "createdAt" : "2015-05-27T04:23:53Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "0b1ddd4d-539a-474f-96d1-949f68cf2ac2",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : null,
        "body" : "In retrospect I see that you're using a MIG rolling update, which is probably serial by definintion.  In which case you might need to limit the number of nodes that you reboot or something.  Taking 100 x 5 min = 8.3 hours to fail is clearly not tenable.  I'm out of ideas as to how to get this down to a few minutes, but we'll need to think of something.\n",
        "createdAt" : "2015-05-27T04:39:06Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "4270d117-28b8-4e2f-ba05-2852a18ebc5b",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "Check out this line and the comment I wrote above it:\nhttps://github.com/GoogleCloudPlatform/kubernetes/pull/8837/files#diff-bbc40d90a96515627afa5efea9599dbeR292\n\nWe can just set this to the cluster size if we want it to run in parallel. Then, the whole thing should take roughly a single node's time.\n\nI originally wrote it this way because during node upgrades, we expect to do it serially, so that if something fails, we destroy the minimum number of nodes we can :-)\n\nHowever, for testing, we could either have a flag to do it serially for \"normal\" e2es and in parallel for scalability runs, or just always do it in parallel as it's probably going to be roughly the same test.\n\nAnother thought: for \"soak\" tests, should we be disabling all reboot / restart / recreate tests? So that we see how long the system really lasts?\n",
        "createdAt" : "2015-05-28T17:37:15Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "9124c173-61e8-4a40-a65f-2d7ea9c59a31",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : null,
        "body" : "Yes, I agree.   I think the best we can do is:\n1. By default, only restart two nodes, in serial (i.e. devs do this by default, as do standard Jenkins runs)\n2. In addition, we can try restarting all nodes in parallel, but I'm guessing that this is unlikely to be successful, and it's fairly unrepresentative of reality anyway.  Make it possible to do this via appropriate environment variables, and we can dedicate a Jenkins job to this.\n3. Make it possible to run this test completely (i.e. restart every node, and in serial) using environment variables, and dedicate a Jenkins test run to this. This is the most realistic test, but unfortunately it takes too long to have it delay the standard e2e test runs.\n",
        "createdAt" : "2015-06-01T20:33:23Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "ac345f5f-ba02-48f7-ba57-66e53bedf662",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : null,
        "body" : "Oh, and regarding soak tests, yes, I think that all node restarts should be disabled there.\n",
        "createdAt" : "2015-06-01T20:34:46Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "6bc616c8-bc38-40f8-a204-9985dee12266",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "1. By default, devs and jenkins launch clusters with only two nodes (a la [`cluster/gce/config-test.sh`](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/cluster/gce/config-test.sh#L23)), so this will happen. Furthermore, configuring to only rolling-update to some of the nodes would involve passing an `--auto-pause-after-instances` flag, which would change the test: we would need to look for \"PAUSED\" state instead of \"ROLLED_OUT\", but it's unclear how \"PAUSED\" is different than \"CANCELLED\", and which one will be applied if the rolling update fails. (I can't easily tell because I haven't gotten one to fail yet.) Anyway, tl;dr is we have two-node clusters, so this should only apply to two nodes.\n2. I vote we punt on parallel right now. We can parameterize this and set up a dedicated Jenkins job if we decide to investigate this later. (I'm curious: why is it unlikely to be successful? If I understand correctly, all necessary state to reschedule all pods is on the master, so blowing away all nodes at once shouldn't cause any problems, right?)\n3. Shouldn't be necessary (a la 1).\n\nRe: soak tests, the only one I saw that disabled other tests (like reboot) was \"kubernetes-soak-continuous-e2e\", so I disabled this test on that already. Are there other Jenkins jobs I should do this to?\n\nRe: large clusters, are there any Jenkins jobs that run > 2 size clusters for which I should also disable this test?\n",
        "createdAt" : "2015-06-04T00:03:30Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "9c75c1b8-6cc5-46cc-8f1d-ea991c4f023d",
        "parentId" : "36b23fd5-f00d-4b34-8a01-2b934b863d7d",
        "authorId" : null,
        "body" : "1. That's only the default, which anyone can override.  I guess what we're saying is that anyone who overrides that default should also disable this test, or suffer horribly-long test run times.  I guess that's OK, although it's guaranteed to trip some people up.\n2. Ack\n3. OK, as per 1.\n\nRe disabling on Jenkins jobs, yes, you'll want to disable it on all of the parallel runs, and the scalability runs.\n",
        "createdAt" : "2015-06-08T23:14:48Z",
        "updatedAt" : "2015-06-08T23:14:48Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "a6c47a07de5c63d0f34591f2cb327222a15f3650",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +37,41 @@\t// before the test is considered failed. (Note that the total time to\n\t// restart all nodes will be this number times the nubmer of nodes.)\n\trestartPerNodeTimeout = 5 * time.Minute\n\n\t// How often to poll the statues of a restart."
  },
  {
    "id" : "83859d86-8d0e-4a92-8d32-78efaafc853f",
    "prId" : 8837,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1034e0dd-8c01-45c6-873f-251f62828ba8",
        "parentId" : null,
        "authorId" : null,
        "body" : "It seems that this needs to be shorter than restartPerNodeTimeout to be useful?\n",
        "createdAt" : "2015-05-27T04:25:04Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "0eddbe44-c2bf-4c69-ab13-022279eff0f2",
        "parentId" : "1034e0dd-8c01-45c6-873f-251f62828ba8",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "All of these timeouts come serially—this allows for 5 minutes AFTER the node is restarted (from an infrastructure point of view) before it is ready (from kubernetes' point of view).\n",
        "createdAt" : "2015-06-03T20:59:02Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "d8d98e9f-633d-47fd-9840-7ef124c93bfc",
        "parentId" : "1034e0dd-8c01-45c6-873f-251f62828ba8",
        "authorId" : null,
        "body" : "10 minutes is too long to wait for a failure in general.  But I can shrink it down in a separate PR once we know how long it usually takes in the successful case.  \n",
        "createdAt" : "2015-06-08T23:02:29Z",
        "updatedAt" : "2015-06-08T23:02:29Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "a6c47a07de5c63d0f34591f2cb327222a15f3650",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +44,48 @@\t// How long a node is allowed to become \"Ready\" after it is restarted before\n\t// the test is considered failed.\n\trestartNodeReadyAgainTimeout = 5 * time.Minute\n\n\t// How long a pod is allowed to become \"running\" and \"ready\" after a node"
  },
  {
    "id" : "61565aa0-7b8d-4379-9122-bc9b1918a928",
    "prId" : 8837,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b96296b-22aa-43e1-a099-ee47194a3a83",
        "parentId" : null,
        "authorId" : null,
        "body" : "As above.\n",
        "createdAt" : "2015-05-27T04:25:11Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "77fb6eda-6aa2-45d5-b203-8d514b55e83c",
        "parentId" : "7b96296b-22aa-43e1-a099-ee47194a3a83",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "As above—this is AFTER the above timeout.\n",
        "createdAt" : "2015-06-03T20:59:16Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "38583203-6f9b-4b3c-bfd1-f079c336b030",
        "parentId" : "7b96296b-22aa-43e1-a099-ee47194a3a83",
        "authorId" : null,
        "body" : "ack.\n",
        "createdAt" : "2015-06-08T23:02:40Z",
        "updatedAt" : "2015-06-08T23:02:40Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "a6c47a07de5c63d0f34591f2cb327222a15f3650",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +48,52 @@\t// How long a pod is allowed to become \"running\" and \"ready\" after a node\n\t// restart before test is considered failed.\n\trestartPodReadyAgainTimeout = 5 * time.Minute\n)\n"
  },
  {
    "id" : "ddf62fb7-7631-45bd-be02-fe6d04d06a91",
    "prId" : 8837,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fccc9b07-4a4c-4513-a436-5bde0c7c38d7",
        "parentId" : null,
        "authorId" : null,
        "body" : "@justinsb FYI . It would be good to extend this for AWS also.\n",
        "createdAt" : "2015-05-27T04:26:38Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      }
    ],
    "commit" : "a6c47a07de5c63d0f34591f2cb327222a15f3650",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +71,75 @@\t\tprovider := testContext.Provider\n\t\tnn := testContext.CloudConfig.NumNodes\n\t\tif !providerIs(\"gce\") {\n\t\t\tBy(fmt.Sprintf(\"Skipping reboot test, which is not implemented for %s\", provider))\n\t\t\treturn"
  },
  {
    "id" : "0aae7f75-a6f6-407d-b0a8-764fb4621891",
    "prId" : 8837,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c84898ca-32c7-4775-9910-4e82eadd1fb7",
        "parentId" : null,
        "authorId" : null,
        "body" : "I think this warrants it's own function.  This one is getting a bit long.\n",
        "createdAt" : "2015-05-27T04:34:35Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "6c7db0db-cb2a-4565-b20c-aacc98d8b721",
        "parentId" : "c84898ca-32c7-4775-9910-4e82eadd1fb7",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "Ugh, yeah, I spent a while trying to figure out the best way for this to be factored... all this really does is run _n_ `waitForNodeToBeReady(...)` in parallel and check their result. However, because of our Go 1.3 support and my extra-safe \"waiting until all nodes are done before failing,\" this a handful extra lines of code. I din't factor it out more because I wouldn't reuse the function if I did.\n\nPlease let me know your final decision after my whining above :-)\n",
        "createdAt" : "2015-05-28T17:41:16Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "07099372-55ca-45c4-816f-026468aed619",
        "parentId" : "c84898ca-32c7-4775-9910-4e82eadd1fb7",
        "authorId" : null,
        "body" : "Whining accepted :-)  But I think it's worth factoring out, even if the resulting function is never re-used.  It makes the code more readable.\n",
        "createdAt" : "2015-06-01T20:37:02Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : null,
        "tags" : [
        ]
      },
      {
        "id" : "debde11a-64d6-4a41-84a4-bb9bc9d133d8",
        "parentId" : "c84898ca-32c7-4775-9910-4e82eadd1fb7",
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "Ack.\n",
        "createdAt" : "2015-06-03T22:22:44Z",
        "updatedAt" : "2015-06-04T00:06:01Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a6c47a07de5c63d0f34591f2cb327222a15f3650",
    "line" : null,
    "diffHunk" : "@@ -1,1 +182,186 @@\t}\n\n\t// Next, ensure in parallel that all the nodes are ready. We subtract the\n\t// time we spent waiting above.\n\ttimeout := nt - time.Since(start)"
  }
]