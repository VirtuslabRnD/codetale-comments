[
  {
    "id" : "c7d9054e-c74c-4f3a-87da-2938e10d8362",
    "prId" : 92954,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92954#pullrequestreview-459314723",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "34cda117-618c-4950-bb0f-3861a32bd042",
        "parentId" : null,
        "authorId" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "body" : "100ms seems aggressively short to me, but I see there are other tests in apimachinery that use this interval",
        "createdAt" : "2020-07-31T16:10:00Z",
        "updatedAt" : "2020-07-31T16:10:18Z",
        "lastEditedBy" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "tags" : [
        ]
      },
      {
        "id" : "da4e5da5-fe91-4193-85b6-0d8a854fce3d",
        "parentId" : "34cda117-618c-4950-bb0f-3861a32bd042",
        "authorId" : "4d29f8cc-3047-4ae4-a324-ef139bab5663",
        "body" : "I think I just copy &pasted it from somewhere around here ðŸ˜€",
        "createdAt" : "2020-07-31T16:45:21Z",
        "updatedAt" : "2020-07-31T16:45:21Z",
        "lastEditedBy" : "4d29f8cc-3047-4ae4-a324-ef139bab5663",
        "tags" : [
        ]
      }
    ],
    "commit" : "06e878081853ea0e6257e8966edf766c506f5bb0",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +595,599 @@\n\t\tdesiredGeneration := replicaset.Generation\n\t\tif err := wait.PollImmediate(100*time.Millisecond, 60*time.Second, func() (bool, error) {\n\t\t\tnewRS, err := clientSet.AppsV1().ReplicaSets(replicaset.Namespace).Get(context.TODO(), replicaset.Name, metav1.GetOptions{})\n\t\t\tif err != nil {"
  },
  {
    "id" : "73699a31-0c9f-45eb-b165-de210fd2fef8",
    "prId" : 76066,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/76066#pullrequestreview-226914249",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5e7e28a-6ebd-4287-b153-5ba357dc84c7",
        "parentId" : null,
        "authorId" : "185604f6-2915-4313-8d6b-1d55757d0d22",
        "body" : "Please ensure your PR removes https://github.com/kubernetes/kubernetes/blob/8045a99a701fcba612eab9168963113ebcfd3bf9/hack/.golint_failures#L635",
        "createdAt" : "2019-04-15T22:42:45Z",
        "updatedAt" : "2019-04-16T03:07:48Z",
        "lastEditedBy" : "185604f6-2915-4313-8d6b-1d55757d0d22",
        "tags" : [
        ]
      }
    ],
    "commit" : "91bd1ac1eae56ac7620da97324f71a003815e8f8",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +41,45 @@\t\"k8s.io/kubernetes/test/e2e/framework/metrics\"\n\n\t\"github.com/onsi/ginkgo\"\n\t\"github.com/onsi/gomega\"\n\timageutils \"k8s.io/kubernetes/test/utils/image\""
  },
  {
    "id" : "b7181cfe-a62f-4e15-85e3-e57d8b1083aa",
    "prId" : 63386,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/63386#pullrequestreview-129753737",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I'm surprised this passes, I thought the GC only worked on namespace scoped resources?",
        "createdAt" : "2018-06-05T23:57:58Z",
        "updatedAt" : "2018-06-05T23:57:58Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "a4a5e075-8991-4d37-ae79-89b12607eb99",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "owner references don't have a namespace field, so they don't allow \r\n* cross-namespace references\r\n* cluster-scoped -> namespaced references\r\n\r\nThey do allow:\r\n* same namespace references\r\n* namespaced -> cluster scoped references",
        "createdAt" : "2018-06-06T00:10:09Z",
        "updatedAt" : "2018-06-06T00:10:10Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "7b948f67-7453-4330-8dc4-85ecb4e71afb",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "695b6860-569c-4e63-a215-7342e2279a94",
        "body" : "Owner reference was designed to not have namespace field, but there was use case / bug where dependent refers cluster-scoped owner. Fixed in: https://github.com/kubernetes/kubernetes/pull/57211",
        "createdAt" : "2018-06-06T00:35:24Z",
        "updatedAt" : "2018-06-06T00:35:24Z",
        "lastEditedBy" : "695b6860-569c-4e63-a215-7342e2279a94",
        "tags" : [
        ]
      },
      {
        "id" : "c7be0114-6593-4666-b438-5827683056a8",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Though it's not by design, I know GC at least supports cluster-scoped owner with namespaced dependents (see https://github.com/kubernetes/kubernetes/pull/57211). This test sets up cluster-scoped owner with cluster-scoped dependents, so it seems GC works in this case as well.\r\n\r\nMaybe GC works for namespaced owner and cluster-scoped dependents in most cases. After all, GC's internal graph records the namespace, and indexed the graph nodes by UID.",
        "createdAt" : "2018-06-06T00:39:37Z",
        "updatedAt" : "2018-06-06T00:39:37Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "b31ee4c4-158d-48ca-be52-ef2882d6f198",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "> Maybe GC works for namespaced owner and cluster-scoped dependents in most cases.\r\n\r\nSpecifying incorrect ownerref data and racing the uid index is definitely not safe, reliable, or supported. In cases where GC falls back to a live lookup of the owner before deleting, I think it would get a 404 from the incorrect (no namespace) reference, properly conclude the pod with namespace \"\" and name \"foo\" did not exist (because it doesn't), and delete the cluster scoped object. ",
        "createdAt" : "2018-06-06T00:52:12Z",
        "updatedAt" : "2018-06-06T00:52:53Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "ef22f356-aa81-4bcc-928b-62edb104c417",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Yes, I should have thought another minute before my first comment.\r\n\r\nIt's definitely a bug if cluster scoped resources can consider namespace scoped objects in namespace \"\" a parent--that namespace should never exist anywhere, and GET of individual objects across all namespaces should always fail.",
        "createdAt" : "2018-06-06T16:42:54Z",
        "updatedAt" : "2018-06-06T16:42:54Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "93e0ccc6-e5a2-485a-9a68-a623eb5b1813",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "> In cases where GC falls back to a live lookup of the owner before deleting, I think it would get a 404 from the incorrect (no namespace) reference\r\n\r\nSure, in general it's not safe and not supported to have namespaced owner and cluster scoped dependents.\r\n\r\nFWIW, the live lookup actually might work, because GC gets the namespace of the owner from the its internal graph, which is generated by the reflector in most cases, so the correct namespace will be there. I think the \"virtual node\" scenario is what is broken, where as liggitt described, the cluster-scoped child will be wrongly deleted.\r\n",
        "createdAt" : "2018-06-06T18:37:12Z",
        "updatedAt" : "2018-06-06T18:37:12Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "6b2b8149-f303-45ff-951c-cb50e2842890",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "> FWIW, the live lookup actually might work, because GC gets the namespace of the owner from the its internal graph\r\n\r\nI guess the graph must be by UID?\r\n\r\nThis is a bug. Please file an issue. We need extra checks that references don't cross namespace boundaries, or go from cluster scoped to namespaced.",
        "createdAt" : "2018-06-06T18:43:59Z",
        "updatedAt" : "2018-06-06T18:43:59Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "a6ebce6c-1468-4e33-ac1b-71a0965eec24",
        "parentId" : "402bace6-6d0c-445a-866f-9a0fedd9f1ef",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "@lavalamp see https://github.com/kubernetes/kubernetes/issues/65200",
        "createdAt" : "2018-06-18T21:54:48Z",
        "updatedAt" : "2018-06-18T21:54:48Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "29d72a71345d535e270cee59e31e8b5788910bb9",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1012,1016 @@\t\t// Create a random custom resource definition and ensure it's available for\n\t\t// use.\n\t\tdefinition := apiextensionstestserver.NewRandomNameCustomResourceDefinition(apiextensionsv1beta1.ClusterScoped)\n\t\tdefer func() {\n\t\t\terr = apiextensionstestserver.DeleteCustomResourceDefinition(definition, apiExtensionClient)"
  },
  {
    "id" : "8af413be-5823-49de-bac9-fab3a3aecc03",
    "prId" : 60671,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60671#pullrequestreview-101749644",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c449bd4-80dc-42b4-96dd-7d9cd977ee3c",
        "parentId" : null,
        "authorId" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "body" : "Fix for error swallowing missed by https://github.com/kubernetes/kubernetes/pull/48068/commits/f08f504a7ec5bc3f3f85b8cb372254d2b8766a1b",
        "createdAt" : "2018-03-06T22:54:27Z",
        "updatedAt" : "2018-03-14T17:29:18Z",
        "lastEditedBy" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f518e6d4cb2b68be05bafac2963aceb39ea90b7",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +546,550 @@\t\t\treturn verifyRemainingDeploymentsReplicaSetsPods(f, clientSet, deployment, 0, 0, 0)\n\t\t})\n\t\tif err != nil {\n\t\t\terrList := make([]error, 0)\n\t\t\terrList = append(errList, err)"
  },
  {
    "id" : "a38e63c9-1a1b-4a6f-b4a8-d7c7314844f4",
    "prId" : 60671,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60671#pullrequestreview-125321289",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1990a9ac-40fc-4f96-8b59-09843676c99d",
        "parentId" : null,
        "authorId" : "695b6860-569c-4e63-a215-7342e2279a94",
        "body" : "nit: polling helps us fail earlier in case of error. but in reality we expect these tests to pass consistently, so there is no difference",
        "createdAt" : "2018-06-01T21:00:41Z",
        "updatedAt" : "2018-06-01T21:00:41Z",
        "lastEditedBy" : "695b6860-569c-4e63-a215-7342e2279a94",
        "tags" : [
        ]
      },
      {
        "id" : "5495d5bc-236d-4c02-ae1b-a0aad4f5da9c",
        "parentId" : "1990a9ac-40fc-4f96-8b59-09843676c99d",
        "authorId" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "body" : "This was a while ago, but I think the reason for that change was to keep consistency with the change I made to https://github.com/kubernetes/kubernetes/pull/60671/files#diff-4a7d8678f8505e86c1c6cc626cdc5eeeL608\r\nIn that case the way the polling was set up was completely broken, and it would always succeed within the first 0-5 seconds, even if the garbage collector mistakenly deleted the replica set.\r\n\r\nDiscussion about it here: https://github.com/kubernetes/kubernetes/pull/60671#discussion_r172980606",
        "createdAt" : "2018-06-01T21:24:25Z",
        "updatedAt" : "2018-06-01T21:24:25Z",
        "lastEditedBy" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f518e6d4cb2b68be05bafac2963aceb39ea90b7",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +447,451 @@\t\t}\n\t\tBy(\"wait for 30 seconds to see if the garbage collector mistakenly deletes the pods\")\n\t\ttime.Sleep(30 * time.Second)\n\t\tpods, err := podClient.List(metav1.ListOptions{})\n\t\tif err != nil {"
  },
  {
    "id" : "a24df94b-606e-4c41-b12a-02aa65fc6690",
    "prId" : 49428,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/49428#pullrequestreview-51612823",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d78b6114-109b-49ec-a61f-717cc06d0fb0",
        "parentId" : null,
        "authorId" : "26bd3fa6-ac8d-4cb0-b746-a30dc1dc2931",
        "body" : "We used to set `rc2.Spec.Selector = nil`, is that still needed?",
        "createdAt" : "2017-07-22T02:08:36Z",
        "updatedAt" : "2017-07-22T02:08:36Z",
        "lastEditedBy" : "26bd3fa6-ac8d-4cb0-b746-a30dc1dc2931",
        "tags" : [
        ]
      },
      {
        "id" : "6e31a385-4e3c-4981-952a-fde9714f0dae",
        "parentId" : "d78b6114-109b-49ec-a61f-717cc06d0fb0",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "No, nil selector will be default to match the podTemplate labels by the server.",
        "createdAt" : "2017-07-22T02:12:22Z",
        "updatedAt" : "2017-07-22T02:12:22Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "200eb19dc2085f63d8f9dc6e518aeebab7592bc4",
    "line" : 159,
    "diffHunk" : "@@ -1,1 +598,602 @@\t\t// TODO: find better way to keep this label unique in the test\n\t\tuniqLabels = map[string]string{\"another.key\": \"another.value\"}\n\t\trc2 := newOwnerRC(f, rc2Name, 0, uniqLabels)\n\t\tBy(\"create the rc2\")\n\t\trc2, err = rcClient.Create(rc2)"
  }
]