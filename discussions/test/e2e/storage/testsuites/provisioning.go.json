[
  {
    "id" : "488d15bd-235b-42d1-9c6f-050e70f65140",
    "prId" : 102538,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102538#pullrequestreview-678877654",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "038711c6-a008-4cfb-9e4f-47d5cd0dcd9b",
        "parentId" : null,
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "oh nice, I didn't know about `ResourceVersion`, so this ensures that the object is not the spec to create the PVC but it's instead a PVC object that was returned by the API server",
        "createdAt" : "2021-06-08T18:33:51Z",
        "updatedAt" : "2021-06-08T18:33:51Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "28511e82ad96cd0fdc54a8dfcf99b8a9c16f6ca9",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +839,843 @@\n\tif initClaim.ResourceVersion != \"\" {\n\t\tginkgo.By(\"Skipping creation of PVC, it already exists\")\n\t} else {\n\t\tginkgo.By(\"[Initialize dataSource]creating a initClaim\")"
  },
  {
    "id" : "90e3c3ae-489f-46a7-9bcf-7ac7e4a41a1a",
    "prId" : 102538,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102538#pullrequestreview-678878540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a65cdca-6245-4dc8-9c9e-4c0db7b9dfaf",
        "parentId" : null,
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "thanks for the cleanup, `initClaim` looks better than `updatedClaim`",
        "createdAt" : "2021-06-08T18:34:56Z",
        "updatedAt" : "2021-06-08T18:34:56Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "28511e82ad96cd0fdc54a8dfcf99b8a9c16f6ca9",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +871,875 @@\n\tcleanupFunc := func() {\n\t\tframework.Logf(\"deleting initClaim %q/%q\", initClaim.Namespace, initClaim.Name)\n\t\terr := client.CoreV1().PersistentVolumeClaims(initClaim.Namespace).Delete(context.TODO(), initClaim.Name, metav1.DeleteOptions{})\n\t\tif err != nil && !apierrors.IsNotFound(err) {"
  },
  {
    "id" : "c6affed9-b06e-499a-8c96-b6870a9a0828",
    "prId" : 100537,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/100537#pullrequestreview-620105355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a4f58d6-2e8b-4ffd-8933-557b57b63875",
        "parentId" : null,
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "This change was necessary because the new capacity test calls the function twice, once as part of the test and then through `defer`. I think ignoring \"NotFound\" errors is a common pattern when deleting.",
        "createdAt" : "2021-03-24T17:21:18Z",
        "updatedAt" : "2021-03-24T21:33:32Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "37ee7439-f93c-4908-aefc-9012fdf6fd31",
        "parentId" : "7a4f58d6-2e8b-4ffd-8933-557b57b63875",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "I understand this is making the cleanup idempotent, good idea",
        "createdAt" : "2021-03-24T18:28:13Z",
        "updatedAt" : "2021-03-24T21:33:32Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "d7a086ddd82d7d1b287ac4da4c35c5c96b98da0d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +341,345 @@\t\t\t\tif err != nil && !apierrors.IsNotFound(err) {\n\t\t\t\t\tframework.ExpectNoError(err, \"delete storage class\")\n\t\t\t\t}\n\t\t\t}\n\t\t}"
  },
  {
    "id" : "ed3e1129-3a42-4b35-aef3-372661d4ad76",
    "prId" : 99346,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99346#pullrequestreview-596990261",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "251f20b8-6dd4-4fbc-a98c-3255f122024b",
        "parentId" : null,
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "I'll remove these comments",
        "createdAt" : "2021-02-24T01:48:43Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "432928b673056562f475392863495bb0a6a8439b",
    "line" : 203,
    "diffHunk" : "@@ -1,1 +909,913 @@\t\t\tframework.Failf(\"Error deleting source PVC %q. Error: %v\", sourcePVC.Name, err)\n\t\t}\n\n\t\tclearComputedStorageClass()\n\t}"
  },
  {
    "id" : "59ede493-cd9a-42ce-a470-a49fbb6abc37",
    "prId" : 99346,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99346#pullrequestreview-597832330",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d79880e1-f99b-4458-af9e-5bd5224683e9",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Can you add a comment here that this method expects the StorageClass to already exist.",
        "createdAt" : "2021-02-24T17:23:23Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "029cb4a1-7aaf-40d0-bbea-7faf124b99fe",
        "parentId" : "d79880e1-f99b-4458-af9e-5bd5224683e9",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "Got it",
        "createdAt" : "2021-02-24T19:11:21Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "432928b673056562f475392863495bb0a6a8439b",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +353,357 @@}\n\n// TestDynamicProvisioning tests dynamic provisioning with specified StorageClassTest\n// it's assumed that the StorageClass `t.Class` is already provisioned,\n// see #ProvisionStorageClass"
  },
  {
    "id" : "08a1ae1b-5753-4777-8b22-0ba9b0f456f8",
    "prId" : 99346,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99346#pullrequestreview-600086618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c83a345e-883b-47c8-a61e-c564e23d8cb8",
        "parentId" : null,
        "authorId" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "body" : "Want to verify: Is there some case that different test share the same storageClass name, but the spec of the storageclass might be different. Need to verify this behavior.",
        "createdAt" : "2021-02-24T19:27:40Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "tags" : [
        ]
      },
      {
        "id" : "884485ff-3f77-474d-b59f-090484cb9fa1",
        "parentId" : "c83a345e-883b-47c8-a61e-c564e23d8cb8",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "I did a search and all of the test cases inside testsuites create a StorageClass here https://github.com/kubernetes/kubernetes/blob/89d1e37ff116fbd5f41e7afee06af601ae611e66/test/e2e/storage/testsuites/provisioning.go#L144, this method is implemented by multiple drivers and all of them call https://github.com/kubernetes/kubernetes/blob/66fa2c49e28b9dcf478a87636971bc7d241b2849/test/e2e/storage/framework/driver_operations.go#L65 which creates a unique StorageClass name\r\n\r\nTestDynamicProvisioning was always creating the StorageClass this way, what would we verify in this case?",
        "createdAt" : "2021-02-24T19:57:21Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      },
      {
        "id" : "24331e9c-f9ae-435f-a6f6-ec3bfa72d92a",
        "parentId" : "c83a345e-883b-47c8-a61e-c564e23d8cb8",
        "authorId" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "body" : "I thought we were saying the storageClass name is the same to different tests that is why storageClass might already exist when test tries to create it. If each storage class is unique for each test, it normally should not exist already?",
        "createdAt" : "2021-02-27T06:02:40Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "tags" : [
        ]
      },
      {
        "id" : "cd958e13-56b8-48b8-b532-65ebb5c73fc5",
        "parentId" : "c83a345e-883b-47c8-a61e-c564e23d8cb8",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "that's correct, if the storageclass already exists then the test could fail, I can change this to throw an exception instead",
        "createdAt" : "2021-02-27T06:06:26Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      },
      {
        "id" : "aa840a05-5d63-404c-821b-9b720e5be478",
        "parentId" : "c83a345e-883b-47c8-a61e-c564e23d8cb8",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "One of the cases where the storage class already exists when it enters this method is in the v1beta1 case, the storage class is created outside this method and when this method is called then it's fetched from the cluster but as a v1 object, do you think that in the beta case I shouldn't use this method?",
        "createdAt" : "2021-02-27T06:18:24Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "432928b673056562f475392863495bb0a6a8439b",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +332,336 @@\t\t} else {\n\t\t\tginkgo.By(\"Creating a StorageClass \" + class.Name)\n\t\t\t_, err = client.StorageV1().StorageClasses().Create(context.TODO(), class, metav1.CreateOptions{})\n\t\t\tframework.ExpectNoError(err)\n\t\t\tcomputedStorageClass, err = client.StorageV1().StorageClasses().Get(context.TODO(), class.Name, metav1.GetOptions{})"
  },
  {
    "id" : "cb658a63-6fab-4ed9-9c4e-cd341bf466c0",
    "prId" : 99346,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99346#pullrequestreview-601170336",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32c47ebd-ca29-4772-903e-4601579fee4a",
        "parentId" : null,
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "@msau42 the conversation was dropped after I did the rebase fix, sorry about that.\r\n\r\nAfter debugging the test I saw that the Pod created in this if statement was failing with the following error:\r\n\r\n```\r\n Warning  FailedMount  7s    kubelet, e2e-test-mauriciopoppe-minion-group-pnq9  Unable to attach or mount volumes: unmounted volumes=[volume1], unattached volumes=[volume1 default-token-b9jmr[]: volume volume1 has volumeMode Block, but is specified in volumeMounts\r\n```\r\n\r\nAfter some debugging I found out that the test is failing because the claim dynamically provisions a PV with volumeMode = Block and this pod is created with `volumeMounts` instead of `volumeDevices` for all the cases, if the objective of this test is to also make it work with a BlockDevice then I can create either `volumeMounts` (the default) or `volumeDevices` inside `e2e.CreatePod`, we could also skip this test for block devices, what do you think?",
        "createdAt" : "2021-02-27T06:37:56Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      },
      {
        "id" : "7d979f1d-7862-4d81-9fd4-59c10d1e2981",
        "parentId" : "32c47ebd-ca29-4772-903e-4601579fee4a",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "I opted for adding support to create volumeDevices in the e2e pod creation method",
        "createdAt" : "2021-02-27T07:17:27Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      },
      {
        "id" : "c140928d-5f24-453b-a316-852dde98ab83",
        "parentId" : "32c47ebd-ca29-4772-903e-4601579fee4a",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "Changed to use `e2epod.CreateSecPod`",
        "createdAt" : "2021-03-01T21:12:45Z",
        "updatedAt" : "2021-03-01T21:12:45Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "432928b673056562f475392863495bb0a6a8439b",
    "line" : 135,
    "diffHunk" : "@@ -1,1 +385,389 @@\n\t// if late binding is configured, create and delete a pod to provision the volume\n\tif *class.VolumeBindingMode == storagev1.VolumeBindingWaitForFirstConsumer {\n\t\tginkgo.By(fmt.Sprintf(\"creating a pod referring to the class=%+v claim=%+v\", class, claim))\n\t\tvar podConfig *e2epod.Config = &e2epod.Config{"
  },
  {
    "id" : "bfbc7cee-3b1a-4a5b-a026-d7d2ed5837d2",
    "prId" : 99346,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99346#pullrequestreview-601081036",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "parentId" : null,
        "authorId" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "body" : "why remove Claim.DeepCopy()?",
        "createdAt" : "2021-02-27T06:39:48Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "tags" : [
        ]
      },
      {
        "id" : "a081a93e-8107-4ffe-ae37-bb496896428e",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "body" : "Also I don't know why class was set to nil before. The author @jsafrane https://github.com/kubernetes/kubernetes/commit/1f9f2390cb57832f5fbd02e53d39023b81500cc2 specifically made a comment about storageclass already exist? Is it trying to test default storage class behavior?",
        "createdAt" : "2021-02-27T06:46:04Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "tags" : [
        ]
      },
      {
        "id" : "ba482686-8017-4bcc-815d-6b1ccb46e19c",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "t.Claim is just a spec without a name, `TestDynamicProvisioning` will create the actual object, from what I understand this will happen as long as the object created is unique and it is because it doesn't have a name\r\n\r\nfor `t.Class = nil` it might have been a mistake because the test wasn't using the class setup before the goroutines (it was instead using the default storageclass if it existed), @msau42 clarified that inside testsuites we don't have tests for the default storageclass",
        "createdAt" : "2021-02-28T05:16:12Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      },
      {
        "id" : "a26130af-671d-4260-b563-a97a4d1f19dc",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "body" : "I see. The claim is using a GenerateName which provides the prefix and when creating PVC, it will generate a unique dynamically. ",
        "createdAt" : "2021-02-28T06:57:12Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "44594ff0-8fbc-44a7-84f9-654ffd54270f",
        "tags" : [
        ]
      },
      {
        "id" : "606e6065-f6a5-4c79-8836-ab14eac3dc26",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "Ack to the storage class changes in this PR - it's better to create a new one for each test inside the testsuites.",
        "createdAt" : "2021-03-01T10:48:02Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "8752e36e-45ac-4a93-935b-0171a6a4e8ab",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Regarding `t.Claim`, does every caller use GenerateName? If we want to make that assumption, then it may be better to assert on it so we catch any future changes.",
        "createdAt" : "2021-03-01T17:31:28Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "895d0549-a25a-421b-be88-76d87921702f",
        "parentId" : "80f8d958-d2db-4205-aff7-761b02226da0",
        "authorId" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "body" : "yes, all of the callers use `e2epv.MakePersistentVolumeClaim` with an empty `Name` but with a `NamePrefix`, I added an assertion in `TestDynamicProvisioning` to ensure that `NamePrefix` is set (although it could be overriden by setting Name but no test does this at this moment)",
        "createdAt" : "2021-03-01T19:17:59Z",
        "updatedAt" : "2021-03-01T20:16:16Z",
        "lastEditedBy" : "87fae8a2-4751-4356-ba8a-ce265708b853",
        "tags" : [
        ]
      }
    ],
    "commit" : "432928b673056562f475392863495bb0a6a8439b",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +294,298 @@\n\t\t\t\tt := *l.testCase\n\t\t\t\tt.PvCheck = func(claim *v1.PersistentVolumeClaim) {\n\t\t\t\t\tginkgo.By(fmt.Sprintf(\"checking whether the created volume %d has the pre-populated data\", i))\n\t\t\t\t\ttests := []e2evolume.Test{"
  },
  {
    "id" : "8572190b-d88d-40e7-b2f4-440682958c43",
    "prId" : 96042,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/96042#pullrequestreview-541857618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d358e4be-8e14-43af-804b-b64d32675bdd",
        "parentId" : null,
        "authorId" : "70e0dd56-8907-46d7-8381-c173d3c02d47",
        "body" : "https://github.com/kubernetes/kubernetes/blob/master/test/e2e/storage/testsuites/provisioning.go#L388,\r\n```framework.ExpectNoError(e2epv.WaitForPersistentVolumeDeleted(client, pv.Name, 5*time.Second, 20*time.Minute))```\r\nthere is a wait for pv delete step that has 20 mins timeout not sure why. This needs to be revisited, perhaps in a different PR.\r\n",
        "createdAt" : "2020-11-24T20:15:37Z",
        "updatedAt" : "2020-12-02T19:15:54Z",
        "lastEditedBy" : "70e0dd56-8907-46d7-8381-c173d3c02d47",
        "tags" : [
        ]
      },
      {
        "id" : "e36bc049-da86-481a-b2e3-b0a2a98105bc",
        "parentId" : "d358e4be-8e14-43af-804b-b64d32675bdd",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "According to the comment in that section, the 20 min timeouts is \"to recover from random cloud hiccups\".\r\n\r\n@msau42: since you added that comment, do you remember any details as to why the timeout is that long?",
        "createdAt" : "2020-11-25T14:36:58Z",
        "updatedAt" : "2020-12-02T19:15:54Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      },
      {
        "id" : "7d8c1716-b5d3-43a2-8c88-853f4a22d361",
        "parentId" : "d358e4be-8e14-43af-804b-b64d32675bdd",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I didn't add the comment, I just moved it to a new place :-)\r\n\r\nI had to trace back quite a bit to where this comment was originally added: https://github.com/kubernetes/kubernetes/commit/46fb4172999bebcf822a2953e1783ed0428adc70\r\n\r\nI think the 20 mins is to also account for the time period that it may take to unmount and detach the volume. 20 minutes seems quite long and could probably be part of the customizable timeouts?",
        "createdAt" : "2020-12-01T00:14:06Z",
        "updatedAt" : "2020-12-02T19:15:54Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "5c7eef41-7bfa-4b7c-8515-3da6e27a2233",
        "parentId" : "d358e4be-8e14-43af-804b-b64d32675bdd",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "Thanks. Moved the 20 minutes values to a new `PVDeleteSlow` custom timeout.",
        "createdAt" : "2020-12-01T12:43:23Z",
        "updatedAt" : "2020-12-02T19:15:54Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee082985c2d8568989400d214f56c020ec8b20f9",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +43,47 @@\n// StorageClassTest represents parameters to be used by provisioning tests.\n// Not all parameters are used by all tests.\ntype StorageClassTest struct {\n\tClient               clientset.Interface"
  },
  {
    "id" : "86d06308-ec54-4403-8fe1-e377082371e2",
    "prId" : 94647,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/94647#pullrequestreview-485601302",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2aad62ad-8020-48db-bfd4-f9df47ca1911",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "How do we know these PVs are generic ephemeral volumes and not just normal PVs?",
        "createdAt" : "2020-09-10T02:46:31Z",
        "updatedAt" : "2020-09-10T02:47:31Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "cec68fe0-04a9-4ef0-a852-3cf3ab4c5778",
        "parentId" : "2aad62ad-8020-48db-bfd4-f9df47ca1911",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I guess either way, we want all PVs to be cleaned up regardless.",
        "createdAt" : "2020-09-10T02:48:06Z",
        "updatedAt" : "2020-09-10T02:48:07Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "4a006b08-e101-4b0c-b7a7-a6258d39354c",
        "parentId" : "2aad62ad-8020-48db-bfd4-f9df47ca1911",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "> How do we know these PVs are generic ephemeral volumes and not just normal PVs?\r\n\r\nBecause they are bound to the PVCs which are owned by the pod that is being deleted.\r\n",
        "createdAt" : "2020-09-10T05:53:08Z",
        "updatedAt" : "2020-09-10T05:53:08Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      }
    ],
    "commit" : "16635f5902e73183846f1d9a85cdf0546144123d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +734,738 @@\tfor _, pv := range pvs.Items {\n\t\tif pv.Spec.ClaimRef == nil ||\n\t\t\tpv.Spec.ClaimRef.Namespace != pod.Namespace {\n\t\t\tcontinue\n\t\t}"
  },
  {
    "id" : "735f538d-9959-4a3a-a790-6ef0721b4adf",
    "prId" : 93332,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/93332#pullrequestreview-453535657",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8609c18b-d367-43fa-9f3a-fafa2d2fec88",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "A better place for this may be https://github.com/kubernetes/kubernetes/tree/f5c7ce96ce2644fc229e6d5479a3ca976ecb1b83/test/e2e/storage/utils. (In general, these files could use some reorganization)",
        "createdAt" : "2020-07-22T17:01:21Z",
        "updatedAt" : "2020-07-22T22:52:42Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "a4c0cd60-851d-41c6-acce-66a4f189933c",
        "parentId" : "8609c18b-d367-43fa-9f3a-fafa2d2fec88",
        "authorId" : "36d7f8b5-3497-43b0-96eb-612a05dccdf8",
        "body" : "@msau42 agreed. I plan on circling back for cleanup but would like to get these tests working again ASAP. I'll open a tracking issue and assign myself ðŸ™‚",
        "createdAt" : "2020-07-22T17:03:28Z",
        "updatedAt" : "2020-07-22T22:52:42Z",
        "lastEditedBy" : "36d7f8b5-3497-43b0-96eb-612a05dccdf8",
        "tags" : [
        ]
      },
      {
        "id" : "92a37d36-1c8a-473e-abed-10ceff794181",
        "parentId" : "8609c18b-d367-43fa-9f3a-fafa2d2fec88",
        "authorId" : "36d7f8b5-3497-43b0-96eb-612a05dccdf8",
        "body" : "Opened issue #93347 ",
        "createdAt" : "2020-07-22T17:31:09Z",
        "updatedAt" : "2020-07-22T22:52:42Z",
        "lastEditedBy" : "36d7f8b5-3497-43b0-96eb-612a05dccdf8",
        "tags" : [
        ]
      }
    ],
    "commit" : "efe3747c22c132c7e20eb0090d688e8853053915",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +716,720 @@// then deletes the pod and waits for that to succeed. Also waits for all owned\n// resources to be deleted.\nfunc StopPodAndDependents(c clientset.Interface, pod *v1.Pod) {\n\tif pod == nil {\n\t\treturn"
  },
  {
    "id" : "59645091-4c8a-4f14-9d27-eb1da4b5a21b",
    "prId" : 88242,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/88242#pullrequestreview-366274508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3cab2e51-8bf0-48da-a6d7-23059e696455",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "For any go routine that could call ginkgo.Fail(), we need to also add a `defer ginkgo.GinkgoRecover()` so that it will still run the AfterEach() handlers.",
        "createdAt" : "2020-02-28T00:22:28Z",
        "updatedAt" : "2020-02-28T09:53:13Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "80342fe7-2ccc-4596-8d1c-16e2a7ef55f9",
        "parentId" : "3cab2e51-8bf0-48da-a6d7-23059e696455",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "fixed",
        "createdAt" : "2020-02-28T09:51:35Z",
        "updatedAt" : "2020-02-28T09:53:13Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      }
    ],
    "commit" : "347d8419488c3bc9f5e4e63ea774c0f8dcf41eee",
    "line" : 119,
    "diffHunk" : "@@ -1,1 +277,281 @@\t\t\tgo func(i int) {\n\t\t\t\tdefer ginkgo.GinkgoRecover()\n\t\t\t\tdefer wg.Done()\n\t\t\t\tginkgo.By(fmt.Sprintf(\"Cloning volume nr. %d\", i))\n\t\t\t\t// Each go routine must have its own pod prefix"
  },
  {
    "id" : "ea3a210d-efd9-41d1-a17e-7de0e5172d10",
    "prId" : 80117,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/80117#pullrequestreview-275670972",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82e0a789-77ff-4ea4-b0e6-e1b9fdfbbccb",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Have you tried running this test manually against hostpath driver?  I'm not sure if reusing `l.pvc` works here because we already used it to provision the source volume.",
        "createdAt" : "2019-07-23T00:15:26Z",
        "updatedAt" : "2019-08-15T19:25:28Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "109d1233-c6c2-472e-b4c6-3658b30391ea",
        "parentId" : "82e0a789-77ff-4ea4-b0e6-e1b9fdfbbccb",
        "authorId" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "body" : "This won't work without:  https://github.com/kubernetes-csi/external-provisioner/pull/309 and https://github.com/kubernetes-csi/csi-driver-host-path/pull/82.\r\n\r\nWe'll need to get those merged and backported or update the image in the e2e tests for this to pass.",
        "createdAt" : "2019-07-31T16:55:53Z",
        "updatedAt" : "2019-08-15T19:25:28Z",
        "lastEditedBy" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "tags" : [
        ]
      },
      {
        "id" : "c2e24131-ade9-480c-9143-440602be7b19",
        "parentId" : "82e0a789-77ff-4ea4-b0e6-e1b9fdfbbccb",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I'm still not sure this works. `l.pvc` is used to create the source pvc.  We need a new PVC for the target clone.",
        "createdAt" : "2019-08-15T01:51:14Z",
        "updatedAt" : "2019-08-15T19:25:28Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "73767161-dd8c-4b48-87ea-f23490bff53e",
        "parentId" : "82e0a789-77ff-4ea4-b0e6-e1b9fdfbbccb",
        "authorId" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "body" : "I'll clean it up, it's poorly written as is even if it did work.",
        "createdAt" : "2019-08-15T12:27:48Z",
        "updatedAt" : "2019-08-15T19:25:28Z",
        "lastEditedBy" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "tags" : [
        ]
      },
      {
        "id" : "89db07b6-e8fa-4be7-a9d3-c51ee17a77aa",
        "parentId" : "82e0a789-77ff-4ea4-b0e6-e1b9fdfbbccb",
        "authorId" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "body" : "@msau42 I added a new source PVC to the init, instrumented some thing and ran though it with the new images to confirm it's working as expected.",
        "createdAt" : "2019-08-15T21:08:02Z",
        "updatedAt" : "2019-08-15T21:08:02Z",
        "lastEditedBy" : "464046a5-36cb-4f77-ae2a-07c568c4c1b6",
        "tags" : [
        ]
      }
    ],
    "commit" : "47facf91b95427b2a2b61ba5ee6146b180e7c2ca",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +214,218 @@\t\tdefer dataSourceCleanup()\n\n\t\tl.pvc.Spec.DataSource = dataSource\n\t\tl.testCase.PvCheck = func(claim *v1.PersistentVolumeClaim) {\n\t\t\tginkgo.By(\"checking whether the created volume has the pre-populated data\")"
  },
  {
    "id" : "16780a07-daa8-463c-916e-169aa2a30444",
    "prId" : 78697,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/78697#pullrequestreview-257393380",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ea9f0f7-9bc3-42bd-9d40-f1d472d35968",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "I think you should still drop a warning that it landed on the same node.  \r\n\r\n/assign @timothysc ",
        "createdAt" : "2019-07-01T19:55:31Z",
        "updatedAt" : "2019-07-04T15:16:01Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "a6f9a9ba-aa2a-4d35-89c5-0b31f1cad4db",
        "parentId" : "2ea9f0f7-9bc3-42bd-9d40-f1d472d35968",
        "authorId" : "d0f794d1-a9d4-4c31-aacc-fb35543cf586",
        "body" : "OK. Will do.",
        "createdAt" : "2019-07-03T10:18:33Z",
        "updatedAt" : "2019-07-04T15:16:01Z",
        "lastEditedBy" : "d0f794d1-a9d4-4c31-aacc-fb35543cf586",
        "tags" : [
        ]
      }
    ],
    "commit" : "d4f43e8e19c2efd4d457996904fb5af05201a1a3",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +439,443 @@\tStopPod(client, pod)\n\tpod = nil\n\t// The second pod got scheduled on the same node as the first one: skip the test.\n\tif runningPod.Spec.NodeName == actualNodeName {\n\t\te2elog.Logf(\"Warning: The reader pod got scheduled on the same node as the writer pod: skipping test\")"
  },
  {
    "id" : "1ff565fe-33d3-4484-b6ac-223f3e7eae2a",
    "prId" : 75796,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/75796#pullrequestreview-220721646",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5509f5a4-6ff2-4766-91d0-0ea8f9ebb397",
        "parentId" : null,
        "authorId" : "34f61776-88da-4b26-aa20-3c4f92530d05",
        "body" : "nit: break?",
        "createdAt" : "2019-03-29T19:36:10Z",
        "updatedAt" : "2019-03-29T22:00:37Z",
        "lastEditedBy" : "34f61776-88da-4b26-aa20-3c4f92530d05",
        "tags" : [
        ]
      }
    ],
    "commit" : "634be030a82a20c5e7d273e92d5ea397366035df",
    "line" : 135,
    "diffHunk" : "@@ -1,1 +308,312 @@\t\tfor _, pvcMode := range claim.Spec.AccessModes {\n\t\t\tif pvMode == pvcMode {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}"
  },
  {
    "id" : "b4e76971-e0f8-4215-b44c-38b7796e0129",
    "prId" : 75796,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/75796#pullrequestreview-220761373",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "361d2b5d-478f-4551-8c70-17d383a9a876",
        "parentId" : null,
        "authorId" : "34f61776-88da-4b26-aa20-3c4f92530d05",
        "body" : "nit: Add comment for the return parameter",
        "createdAt" : "2019-03-29T21:17:24Z",
        "updatedAt" : "2019-03-29T22:00:37Z",
        "lastEditedBy" : "34f61776-88da-4b26-aa20-3c4f92530d05",
        "tags" : [
        ]
      }
    ],
    "commit" : "634be030a82a20c5e7d273e92d5ea397366035df",
    "line" : 191,
    "diffHunk" : "@@ -1,1 +344,348 @@//\n// This is a common test that can be called from a StorageClassTest.PvCheck.\nfunc PVWriteReadSingleNodeCheck(client clientset.Interface, claim *v1.PersistentVolumeClaim, node framework.NodeSelection) *v1.PersistentVolume {\n\tBy(fmt.Sprintf(\"checking the created volume is writable on node %+v\", node))\n\tcommand := \"echo 'hello world' > /mnt/test/data\""
  },
  {
    "id" : "fba8cc8c-ca47-430d-afe9-2463abb62611",
    "prId" : 72434,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72434#pullrequestreview-203967868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "831260f8-7c60-4d40-a6b1-88b6a8ef976f",
        "parentId" : null,
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "these Skip messages should specify that the sc is not defined because the fstype %s is not supported. there is no other reason (currently?) for a driver to implement DynamicPVTestDriver but return nil",
        "createdAt" : "2019-02-14T19:51:09Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "649b1668-c97c-44e7-b052-6993a48e55b0",
        "parentId" : "831260f8-7c60-4d40-a6b1-88b6a8ef976f",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Can this code here know why the driver didn't return a storage class? I don't think it should make assumptions based on the current implementation.\r\n\r\n\r\n",
        "createdAt" : "2019-02-14T20:55:14Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "cb58d906-30d6-493d-ba2d-27fc919b9a41",
        "parentId" : "831260f8-7c60-4d40-a6b1-88b6a8ef976f",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "yeah I guess it's fine as-is. I guess it is the driver author's responsibility to make sense of why their GetDynamicProvisionStorageClass would return nil. Maybe it could return an error in the future, seems pointless now though",
        "createdAt" : "2019-02-14T21:00:29Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      }
    ],
    "commit" : "ec3655a1d40ced6b1873e627b736aae1cf242477",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +123,127 @@\t\tl.sc = dDriver.GetDynamicProvisionStorageClass(l.config, \"\")\n\t\tif l.sc == nil {\n\t\t\tframework.Skipf(\"Driver %q does not define Dynamic Provision StorageClass - skipping\", dInfo.Name)\n\t\t}\n\t\tl.pvc = getClaim(claimSize, l.config.Framework.Namespace.Name)"
  },
  {
    "id" : "a44f0246-35b1-47ee-8420-82b2ebdda1da",
    "prId" : 72434,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72434#pullrequestreview-204120202",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38a3129a-4a88-4975-b4e3-8dd41dedabef",
        "parentId" : null,
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "could fail w/ nice error if this is nil",
        "createdAt" : "2019-02-14T19:56:32Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "fabd635c-5ca4-4982-8137-1679fdbca208",
        "parentId" : "38a3129a-4a88-4975-b4e3-8dd41dedabef",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Not sure if Github is showing me the right context. What can be nil here? `t.Client` and/or `t.Claim`?\r\n\r\nAre you worried that they might be accidentally passed as nil because they are now struct members instead of separate function parameters? I agree, this isn't caught explicitly. If this is the only requested change, then I'd prefer to add assertions in a separate PR.\r\n\r\n",
        "createdAt" : "2019-02-14T21:00:36Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "8eb1eff1-ad90-4b6d-af50-430432f1a38e",
        "parentId" : "38a3129a-4a88-4975-b4e3-8dd41dedabef",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "I meant t.Claim, though client could be nil as well. either way, the nil error will be caught a few lines below, so yeah these assertions can be added in a separate PR as \"nice-to-haves\" :+1:",
        "createdAt" : "2019-02-14T21:03:12Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "7847ecf1-25e5-4ec9-8f72-062575d689f1",
        "parentId" : "38a3129a-4a88-4975-b4e3-8dd41dedabef",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "As I was rebasing anyway, I added the asserts.",
        "createdAt" : "2019-02-15T08:14:18Z",
        "updatedAt" : "2019-02-15T10:06:24Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      }
    ],
    "commit" : "ec3655a1d40ced6b1873e627b736aae1cf242477",
    "line" : 334,
    "diffHunk" : "@@ -1,1 +280,284 @@\tclient := t.Client\n\tExpect(client).NotTo(BeNil(), \"StorageClassTest.Client is required\")\n\tclaim := t.Claim\n\tExpect(claim).NotTo(BeNil(), \"StorageClassTest.Claim is required\")\n\tclass := t.Class"
  },
  {
    "id" : "2a1bb083-cc3a-4e0a-869d-021c49d34cf4",
    "prId" : 72002,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72002#pullrequestreview-191861367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4c5f0cf-a9c3-43eb-a51e-11fafc60c4d9",
        "parentId" : null,
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "I don't think the test belongs in the provisioning suite. volumes might be a better fit? I guess it will need more boilerplate though since we can't piggyback on TestDynamicProvisioning.",
        "createdAt" : "2019-01-10T16:27:48Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "ceeccaa6-d256-4a74-ae16-626c72e3e3f8",
        "parentId" : "a4c5f0cf-a9c3-43eb-a51e-11fafc60c4d9",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "it might be okay if we make CapMultiPODs non-default though, then I would have to explicitly sign up my driver for this test anyway. Up to you..",
        "createdAt" : "2019-01-10T17:57:06Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "174dd8ab-7e6c-4cf0-9de4-b02d4bb6f18c",
        "parentId" : "a4c5f0cf-a9c3-43eb-a51e-11fafc60c4d9",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Yes, let's do that. My original reasoning was that all drivers must pass the test and therefore nothing special should be needed to run it, but as that's not the case, let's make it opt-in.\r\n",
        "createdAt" : "2019-01-10T19:08:57Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "84897472-78c0-4fdb-85e2-9035315cd8a0",
        "parentId" : "a4c5f0cf-a9c3-43eb-a51e-11fafc60c4d9",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Regarding where to put the test: I agree that this might belong into its own test suite, but it is not clear to me which one (\"volume-features\"?) and now is a bad time to introduce one because of the concurrent work on PR #72434. Let's keep it here, okay?\r\n\r\n\r\n",
        "createdAt" : "2019-01-11T07:05:14Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "9cef92de-33f9-445b-827c-62a949aa2239",
        "parentId" : "a4c5f0cf-a9c3-43eb-a51e-11fafc60c4d9",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "agree",
        "createdAt" : "2019-01-11T20:53:52Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      }
    ],
    "commit" : "ecc0c4e4b4730e01874feb324ff01b1ce6b15343",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +248,252 @@\t})\n\n\tIt(\"should allow concurrent writes on the same node\", func() {\n\t\tif !input.dInfo.Capabilities[CapMultiPODs] {\n\t\t\tframework.Skipf(\"Driver %q does not support multiple concurrent pods - skipping\", input.dInfo.Name)"
  },
  {
    "id" : "52896c8b-08ba-48c1-a56d-3751172c6434",
    "prId" : 72002,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72002#pullrequestreview-193202548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I know this function does a lot of common setup, but I think it's going to get harder to understand/read as we add more functionality that only pertains to one test case.\r\n\r\nInstead, can we move the setup into a common function, and keep each test-case specific logic in its own function?",
        "createdAt" : "2019-01-16T05:17:00Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "5cf75cf4-400f-4edb-a72f-9fb61d1b09cf",
        "parentId" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "I'll have a look at that.",
        "createdAt" : "2019-01-16T08:44:33Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "3ec1684d-e2fa-4ddb-9721-96a893efe262",
        "parentId" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Splitting `TestDynamicProvisioning` into a `SetupDynamicPrivisioning` plus cleanup function is a major API change that would affect a lot of call sites.\r\n\r\nWhat's a bit more doable is having a hook mechanism that executes additional tests inside `TestDynamicProvisioning`.",
        "createdAt" : "2019-01-16T09:13:56Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "316239c1-ff91-44c9-9e40-5063361b6f29",
        "parentId" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Why do I always end up cleaning up tests written by others?! :tired_face:\r\n\r\n`StorageClassTest.ExpectUnschedulable` was added very recently and now I need to move that logic to the one test case that actually uses it. Just saying.\r\n\r\n",
        "createdAt" : "2019-01-16T09:37:24Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "992fcd56-302a-422b-9283-b55044028317",
        "parentId" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "I ended up not touching `StorageClassTest.ExpectUnschedulable`. IMHO it would be better to have that as a separate parameter for those functions which actually use it, but that would have led to even more code churn. It was false in all cases for `TestDynamicProvisioning` and that function now ignores it. Having it at `true` wouldn't make sense, because why run that function in a configuration where the two test pods cannot be scheduled?\r\n\r\nWhat I have done is move the write/read check out of `TestDynamicProvisioning`. Callers of `TestDynamicProvisioning` now decide which additional checks they want to run on the PV, which makes it a bit easier to understand what each testcase really covers. The \"run two pods concurrently\" check then hooks into `TestDynamicProvisioning` the same way.\r\n\r\nThe first three commits in this PR are now generic cleanup commits. If you want, I can submit them separately.\r\n",
        "createdAt" : "2019-01-16T13:49:10Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "a2393c29-90ca-40b6-b78c-ec3b7da029e5",
        "parentId" : "e6ba2ede-8666-4974-af78-31bfa84e283b",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Thanks for finding a way to do this. I wasn't expecting you to clean up other tests.  I was thinking to wrap setup in a function, change TestDynamicProvisioning to use the function, and then write a new function for your test case.  But this works too.",
        "createdAt" : "2019-01-16T15:48:24Z",
        "updatedAt" : "2019-02-12T08:22:39Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      }
    ],
    "commit" : "ecc0c4e4b4730e01874feb324ff01b1ce6b15343",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +289,293 @@\t\t\twg.Wait()\n\t\t}\n\t\tTestDynamicProvisioning(input.testCase, input.cs, input.pvc, input.sc)\n\t})\n}"
  },
  {
    "id" : "c11d6476-dda4-473e-8e54-3c54255ddda5",
    "prId" : 70941,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/70941#pullrequestreview-176032160",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "02aa7ca3-778c-4ac6-89f3-d95001a7710f",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "these two cases are the same (?) `t.NodeSelector` will be either set or empty right? We can pass it in in both cases. Its unclear to me what difference there is between `CreateUnschedulablePod` and `CreatePod`. Shouldn't they both just be creating a `Pod`, and it is the properties of the pod itself that makes it unschedulable, not any difference in the creation process itself?",
        "createdAt" : "2018-11-17T00:37:19Z",
        "updatedAt" : "2019-01-12T02:36:54Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "f0328bd3-806c-4c2d-9376-5fc989c8f8d1",
        "parentId" : "02aa7ca3-778c-4ac6-89f3-d95001a7710f",
        "authorId" : "98986d5f-c846-4478-8363-8a016e3d6b89",
        "body" : "`framework.CreatePod` calls `WaitForPodNameRunningInNamespace` and checks the pod is up and running. `framework. CreateUnschedulablePod` calls `WaitForPodNameUnschedulableInNamespace` and checks pod is in an unschedulable state. So that extra wait+verification in both functions goes beyond just basic creation of the pod and thus they are different.",
        "createdAt" : "2018-11-17T01:12:26Z",
        "updatedAt" : "2019-01-12T02:36:54Z",
        "lastEditedBy" : "98986d5f-c846-4478-8363-8a016e3d6b89",
        "tags" : [
        ]
      }
    ],
    "commit" : "12ece9dacbbe8b3f9727c5136912de9089b54b27",
    "line" : 109,
    "diffHunk" : "@@ -1,1 +358,362 @@\t// Create a pod referring to the claim and wait for it to get to running\n\tvar pod *v1.Pod\n\tif t.ExpectUnschedulable {\n\t\tpod, err = framework.CreateUnschedulablePod(client, namespace, t.NodeSelector, createdClaims, true /* isPrivileged */, \"\" /* command */)\n\t} else {"
  },
  {
    "id" : "010afe73-5dfd-4736-abfd-e61b43e0b1d4",
    "prId" : 70941,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/70941#pullrequestreview-176031316",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a44ce51e-427e-40d2-a4b8-bdeec6205cc7",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "do we ever want to check whether this pod actually succeeded in coming up or not?",
        "createdAt" : "2018-11-17T00:38:49Z",
        "updatedAt" : "2019-01-12T02:36:54Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "10f06b40-c87b-4670-a85c-d42e6b01b9cb",
        "parentId" : "a44ce51e-427e-40d2-a4b8-bdeec6205cc7",
        "authorId" : "98986d5f-c846-4478-8363-8a016e3d6b89",
        "body" : "`CreatePod` already does the waiting through `WaitForPodNameRunningInNamespace` : https://github.com/kubernetes/kubernetes/blob/master/test/e2e/framework/pv_util.go#L844",
        "createdAt" : "2018-11-17T01:03:17Z",
        "updatedAt" : "2019-01-12T02:36:54Z",
        "lastEditedBy" : "98986d5f-c846-4478-8363-8a016e3d6b89",
        "tags" : [
        ]
      }
    ],
    "commit" : "12ece9dacbbe8b3f9727c5136912de9089b54b27",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +361,365 @@\t\tpod, err = framework.CreateUnschedulablePod(client, namespace, t.NodeSelector, createdClaims, true /* isPrivileged */, \"\" /* command */)\n\t} else {\n\t\tpod, err = framework.CreatePod(client, namespace, nil /* nodeSelector */, createdClaims, true /* isPrivileged */, \"\" /* command */)\n\t}\n\tExpect(err).NotTo(HaveOccurred())"
  },
  {
    "id" : "3dd58520-4dfb-40a1-b68e-770c10b81cab",
    "prId" : 69441,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69441#pullrequestreview-163506121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccc2c12a-189e-4e72-b4d4-030b25faf4ac",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "@davidz627 did you find some race condition issue with this, or was it something else?",
        "createdAt" : "2018-10-10T00:23:11Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "96758127-f46c-4332-bd05-f2d862878079",
        "parentId" : "ccc2c12a-189e-4e72-b4d4-030b25faf4ac",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "what are you referring to by \"this\"? If you mean the `needsCleanup` variable I don't think we ever got to the bottom of it, the problem we ended up solving was with per-test resource cleanup racing as well as a sneaky variable shadowing issue. Those both seemed to mitigate the issue.\r\n\r\nIn terms of variable scoping for `needsCleanup` I have neither figured it out nor found anything online that specifies the behavior ",
        "createdAt" : "2018-10-10T18:10:59Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "8ff05c46-21f0-4599-a3f3-8b74519bc058",
        "parentId" : "ccc2c12a-189e-4e72-b4d4-030b25faf4ac",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "ok I remember you thought this variable may have been the cause of resource leaking issues",
        "createdAt" : "2018-10-10T18:23:25Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "61f68f24-f1e8-4f33-aad0-89095976889a",
        "parentId" : "ccc2c12a-189e-4e72-b4d4-030b25faf4ac",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "yep, that was the original hunch but it hasn't proven to be true so far. Especially after we found and fixed the other issues",
        "createdAt" : "2018-10-10T18:44:08Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fcb36e205b0a589806debf9ea20d873d8657f7d",
    "line" : 114,
    "diffHunk" : "@@ -1,1 +112,116 @@\t\t\t// Skip unsupported tests to avoid unnecessary resource initialization\n\t\t\tskipUnsupportedTest(p, driver, pattern)\n\t\t\tneedsCleanup = true\n\n\t\t\t// Create test input"
  },
  {
    "id" : "3f01ac5b-abf0-410f-a970-dc8fca3b7134",
    "prId" : 69441,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69441#pullrequestreview-165865946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "393daed5-41d9-4955-9f32-b47a2443392d",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "this claim size should be coming from the storage class test",
        "createdAt" : "2018-10-10T18:18:34Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "9956886b-84cd-4a11-9cfc-21b56471b427",
        "parentId" : "393daed5-41d9-4955-9f32-b47a2443392d",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "this may not be an issue right now, but different plugins may have different minimum sizes. We may want to consider making this a plugin parameter.",
        "createdAt" : "2018-10-10T18:22:13Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "150c6c4b-eea7-42aa-ab92-68de4fcb6b15",
        "parentId" : "393daed5-41d9-4955-9f32-b47a2443392d",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "xref: https://github.com/kubernetes/kubernetes/pull/69441#discussion_r224190545",
        "createdAt" : "2018-10-10T18:50:36Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "e9c30755-4b40-4d8a-835d-5b5b2c4cd41f",
        "parentId" : "393daed5-41d9-4955-9f32-b47a2443392d",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "still want this to be the claim size specified in the test struct if possible",
        "createdAt" : "2018-10-17T22:44:09Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fcb36e205b0a589806debf9ea20d873d8657f7d",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +151,155 @@\t\t\t}\n\t\t\tp.driver = driver\n\t\t\tp.claimSize = \"2Gi\"\n\t\t\tp.pvc = getClaim(p.claimSize, driver.GetDriverInfo().Framework.Namespace.Name)\n\t\t\tp.pvc.Spec.StorageClassName = &p.sc.Name"
  },
  {
    "id" : "88a15a6d-37be-47e9-bbe4-f5c69dd26d19",
    "prId" : 69441,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69441#pullrequestreview-163914633",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db69e8a5-b638-4966-905c-cf479eeeb081",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "do the CSI Drivers have this implemented",
        "createdAt" : "2018-10-10T18:20:27Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "7bb6bd0d-5d34-4632-871e-6d9ef6e5e7f0",
        "parentId" : "db69e8a5-b638-4966-905c-cf479eeeb081",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "Not yet. And, it is exactly what we aim to do it in https://github.com/kubernetes/kubernetes/pull/68025 .\r\n\r\n",
        "createdAt" : "2018-10-11T16:52:36Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fcb36e205b0a589806debf9ea20d873d8657f7d",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +146,150 @@\tcase testpatterns.DynamicPV:\n\t\tif dDriver, ok := driver.(drivers.DynamicPVTestDriver); ok {\n\t\t\tp.sc = dDriver.GetDynamicProvisionStorageClass(\"\")\n\t\t\tif p.sc == nil {\n\t\t\t\tframework.Skipf(\"Driver %q does not define Dynamic Provision StorageClass - skipping\", driver.GetDriverInfo().Name)"
  },
  {
    "id" : "a69c03e2-619c-43e1-badb-7237b32ce888",
    "prId" : 69441,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69441#pullrequestreview-163945992",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "530ee52f-75dc-4703-99d7-36fcc2bce74a",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "why is this a pointer?",
        "createdAt" : "2018-10-10T18:27:19Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "b8c6ca53-1896-4e12-9aa8-3737e591f5c3",
        "parentId" : "530ee52f-75dc-4703-99d7-36fcc2bce74a",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "This is related to  https://github.com/kubernetes/kubernetes/pull/66577#discussion_r210006095 , although implementation has been changed so much since then.\r\n\r\nIn summary, we are using pattern 2 of \"Global Shared Behaviors\" described in https://onsi.github.io/ginkgo/#global-shared-behaviors, and it requires all the inputs for It() to be in one struct and the struct is required to be passed as a pointer.\r\n\r\nAnd you are right that it should be commented in somewhere, because it is a bit tricky part and is not obvious.\r\n",
        "createdAt" : "2018-10-11T16:48:42Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      },
      {
        "id" : "06c61f9e-6361-46e6-8765-61399740de55",
        "parentId" : "530ee52f-75dc-4703-99d7-36fcc2bce74a",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "cool, thanks for the explaination! can we just add a comment above this line then",
        "createdAt" : "2018-10-11T18:09:27Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fcb36e205b0a589806debf9ea20d873d8657f7d",
    "line" : 129,
    "diffHunk" : "@@ -1,1 +127,131 @@\t\t// to be a single struct and to be passed as a pointer.\n\t\t// Please see https://onsi.github.io/ginkgo/#global-shared-behaviors for details.\n\t\ttestProvisioning(&input)\n\t})\n}"
  },
  {
    "id" : "dd56c4e8-5e0a-4722-b00d-fa2a87603b94",
    "prId" : 69441,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69441#pullrequestreview-166651125",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6166237-970d-4ffe-89cc-1e061362dab8",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "just to confirm, this no longer needs to set up generic resource? why is that?",
        "createdAt" : "2018-10-17T22:48:40Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "5b579a33-0f06-4244-b418-c792b9529188",
        "parentId" : "f6166237-970d-4ffe-89cc-1e061362dab8",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@davidz627\r\n\r\n```genericVolumeTestResource```'s ```setupResource``` will create storage class and pvc, which are the scope of provisioning test. To avoid ```setupResource``` doing too much and make test do it, ```provisioningTestResource```'s ```setupResource``` is defined here and it just creates storage class object.",
        "createdAt" : "2018-10-19T18:47:23Z",
        "updatedAt" : "2018-10-22T16:13:43Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fcb36e205b0a589806debf9ea20d873d8657f7d",
    "line" : 143,
    "diffHunk" : "@@ -1,1 +141,145 @@var _ TestResource = &provisioningTestResource{}\n\nfunc (p *provisioningTestResource) setupResource(driver drivers.TestDriver, pattern testpatterns.TestPattern) {\n\t// Setup provisioningTest resource\n\tswitch pattern.VolType {"
  },
  {
    "id" : "064b370c-7184-47ed-9927-02def35bb1a5",
    "prId" : 69036,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69036#pullrequestreview-193170679",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4277b8c4-fd2c-4b12-9d6a-3b9b90ebf074",
        "parentId" : null,
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Please don't extend `TestDynamicProvisioning` with test-case specific code. Instead set `input.testCase.CheckPV` and implement your custom check there. Does your test need the write/read check? Probably not. You can make it run faster by setting `input.testCase.SkipWriteReadCheck = true`.\r\n\r\n@msau42 pointed out that `TestDynamicProvisioning` is getting overloaded with different checks in https://github.com/kubernetes/kubernetes/pull/72002#discussion_r248153684 and now I am trying to clean that up in that PR.",
        "createdAt" : "2019-01-16T14:45:36Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280fcef5cf6a210016e70beeb198aa273e63970",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +221,225 @@\t\tinput.pvc.Spec.DataSource = dataSource\n\t\tTestDynamicProvisioning(input.testCase, input.cs, input.pvc, input.sc)\n\t})\n}\n"
  },
  {
    "id" : "d5c89962-27ad-4321-a735-44e4388fdbaf",
    "prId" : 69036,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69036#pullrequestreview-198482748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c087246-5e70-4439-81cc-e7936727fd90",
        "parentId" : null,
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "If the class already exists, how do you know that it is the right one? Under which circumstances is it normal to have the class already?\r\n",
        "createdAt" : "2019-01-30T14:57:27Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "ea0cd7ba-db77-45eb-87a1-7074457f3ce8",
        "parentId" : "0c087246-5e70-4439-81cc-e7936727fd90",
        "authorId" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "body" : "only in the test case \"should provision storage with snapshot data source\", in this case, we have create the storage class in the `prepareDataSourceForProvisioning` func.",
        "createdAt" : "2019-01-31T01:41:31Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "tags" : [
        ]
      },
      {
        "id" : "a92341df-8f81-4c02-a363-c81d19f6b31e",
        "parentId" : "0c087246-5e70-4439-81cc-e7936727fd90",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Please add a TODO remark here:\r\n```\r\n// The \"should provision storage with snapshot data source\" test already has created the class.\r\n// TODO: make class creation optional and remove the IsAlreadyExists exception\r\n```\r\n\r\nI'll clean that up later.",
        "createdAt" : "2019-01-31T07:12:17Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "d2e6c8ca-c88d-4c7f-a210-2854a8323133",
        "parentId" : "0c087246-5e70-4439-81cc-e7936727fd90",
        "authorId" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "body" : "Done",
        "createdAt" : "2019-01-31T09:04:50Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280fcef5cf6a210016e70beeb198aa273e63970",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +233,237 @@\t\t// TODO: make class creation optional and remove the IsAlreadyExists exception\n\t\tExpect(err == nil || apierrs.IsAlreadyExists(err)).To(Equal(true))\n\t\tclass, err = client.StorageV1().StorageClasses().Get(class.Name, metav1.GetOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tdefer func() {"
  },
  {
    "id" : "76948d55-65f5-48c2-9cc8-1215ca54ae9c",
    "prId" : 69036,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69036#pullrequestreview-198448181",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "530037eb-9680-406b-aede-fc935c8ae545",
        "parentId" : null,
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Please put this check into a local function of your \"should provision storage with snapshot data source\" and then assign that function to `input.testCase.PvCheck`. That way it is obvious that the check belongs to that test case, and only that testcase.\r\n",
        "createdAt" : "2019-01-30T15:01:09Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "fcfc396a-4015-46a2-a7bb-727ef0d5f41b",
        "parentId" : "530037eb-9680-406b-aede-fc935c8ae545",
        "authorId" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "body" : "now the PvCheck only one argument `v1.PersistentVolume`, this check need also `v1.PersistentVolumeClaim` argument. So we need  refactor the `PvCheck` func first, and I have saw your do this work in PR https://github.com/kubernetes/kubernetes/pull/72002, can we merge this first and fix it after your pr get merged.",
        "createdAt" : "2019-01-31T01:49:57Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "tags" : [
        ]
      },
      {
        "id" : "9e4fd296-bd33-4588-990c-f38f0310d1df",
        "parentId" : "530037eb-9680-406b-aede-fc935c8ae545",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Okay.\r\n",
        "createdAt" : "2019-01-31T07:08:01Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280fcef5cf6a210016e70beeb198aa273e63970",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +301,305 @@\t\trunInPodWithVolume(client, claim.Namespace, claim.Name, t.NodeName, command, t.NodeSelector, t.ExpectUnschedulable)\n\t}\n\n\tif !t.SkipWriteReadCheck {\n\t\t// We start two pods:"
  },
  {
    "id" : "2771d03d-5202-485f-b933-220bbb7cfa5c",
    "prId" : 69036,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69036#pullrequestreview-198987481",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63d823ff-355b-4ca7-815b-769f86cb6472",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I think it would be valuable to do read/write validation with snapshots.  Actually, a good test case could be to:\r\n1. Write some data\r\n2. Take a snapshot\r\n3. Write more data\r\n4. Create a new volume from snapshot\r\n5. Validate data is the old data",
        "createdAt" : "2019-01-31T17:42:02Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "b65ff2ee-5e63-4263-a016-5a1fd02988d5",
        "parentId" : "63d823ff-355b-4ca7-815b-769f86cb6472",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "Can we cover that by a new issue and merge this PR after addressing your other concern?\r\n",
        "createdAt" : "2019-01-31T20:41:22Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "1324418f-d6ca-4813-9966-ba6d43669b77",
        "parentId" : "63d823ff-355b-4ca7-815b-769f86cb6472",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "sure that's fine",
        "createdAt" : "2019-01-31T22:05:21Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "76ce3829-fac7-44c6-8350-91965e4b7132",
        "parentId" : "63d823ff-355b-4ca7-815b-769f86cb6472",
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "https://github.com/kubernetes/kubernetes/issues/73625",
        "createdAt" : "2019-02-01T09:28:11Z",
        "updatedAt" : "2019-02-01T09:28:11Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280fcef5cf6a210016e70beeb198aa273e63970",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +215,219 @@\t\t}\n\n\t\tinput.testCase.SkipWriteReadCheck = true\n\t\tdataSource, cleanupFunc := prepareDataSourceForProvisioning(input.testCase, input.cs, input.dc, input.pvc, input.sc, input.vsc)\n\t\tdefer cleanupFunc()"
  },
  {
    "id" : "94d03753-ef62-4891-ac60-9af572f3b2d5",
    "prId" : 69036,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/69036#pullrequestreview-198910719",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "506b6079-f638-4cc6-bd4b-559eb5e7233c",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Can you also add the feature tag to the alpha suite whitelist [here](https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/sig-gcp/sig-gcp-gce-config.yaml#L250) and [here](https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/sig-gcp/sig-gcp-gce-config.yaml#L334)",
        "createdAt" : "2019-02-01T02:05:11Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "b7d1adc5-c141-4059-b228-0aaffa3a1deb",
        "parentId" : "506b6079-f638-4cc6-bd4b-559eb5e7233c",
        "authorId" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "body" : "Thanks for this information, commit a PR https://github.com/kubernetes/test-infra/pull/11078",
        "createdAt" : "2019-02-01T03:00:32Z",
        "updatedAt" : "2019-02-01T08:34:55Z",
        "lastEditedBy" : "f71497cc-dd85-47eb-bbed-996bde0d13a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280fcef5cf6a210016e70beeb198aa273e63970",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +210,214 @@\t})\n\n\tIt(\"should provision storage with snapshot data source [Feature:VolumeSnapshotDataSource]\", func() {\n\t\tif !input.dInfo.Capabilities[CapDataSource] {\n\t\t\tframework.Skipf(\"Driver %q does not support populate data from snapshot - skipping\", input.dInfo.Name)"
  },
  {
    "id" : "49569858-58a3-49b3-bda8-48893176d34e",
    "prId" : 68025,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68025#pullrequestreview-173145522",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2881a84e-5d92-4ded-ad10-6ed74e861be8",
        "parentId" : null,
        "authorId" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "body" : "@mkimuram This hard-coded size doesn't work for me: my test setup provisions in RAM and can't support such large volumes. This needs to be configurable.\r\n\r\nI can work on a PR for this, but let's clarify first what the role of `framework.VolumeTestConfig` is in `testsuites`.\r\n\r\nSpeaking of volume size, the subpath tests fail for the same reason. But I haven't figured out yet where that PVC gets created. Can you point me in the right direction?\r\n",
        "createdAt" : "2018-11-08T17:37:00Z",
        "updatedAt" : "2018-11-08T17:37:00Z",
        "lastEditedBy" : "ba0b9c6e-ec4c-4d1b-832e-751e6109bf38",
        "tags" : [
        ]
      },
      {
        "id" : "c059f162-d26d-46e8-bb9e-c7999dc02a19",
        "parentId" : "2881a84e-5d92-4ded-ad10-6ed74e861be8",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@pohly \r\n\r\nThis value was changed to 5Gi due to the restriction of current version of csi gce driver.\r\nOnce @davidz627 push the latest version of csi gce driver, then we will be able to change it to smaller value.\r\n\r\nAlso, we will be able to tune it by defining something like minimum volume size in each driver and set the size here.\r\n\r\n> But I haven't figured out yet where that PVC gets created. Can you point me in the right direction?\r\n\r\nIt depends on the testsuites but it should be created either in\r\n1. Each tests ([Inside ```It()```](https://github.com/kubernetes/kubernetes/blob/master/test/e2e/storage/testsuites/provisioning.go#L215)) (ex. provisioning, volumeMode testsuites)\r\n2. [setupResource](https://github.com/kubernetes/kubernetes/blob/master/test/e2e/storage/testsuites/base.go#L137) (ex. subPath, volumes, volumeIO testsuites)\r\n\r\nIt is different because \r\n - if the scope of the test includes the creation of a resource, it should be inside ```It()```,\r\n - if the scope of the test doesn't include the creation of a resource, it should be in ```setupResource``` to avoid duplicated logic in all tests. (Most of tests will be able to use genericVolumeTestResource as is.)\r\n\r\n",
        "createdAt" : "2018-11-08T19:53:02Z",
        "updatedAt" : "2018-11-08T19:53:02Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      },
      {
        "id" : "878cd8e6-b008-4bb2-bd63-54d0c9613b16",
        "parentId" : "2881a84e-5d92-4ded-ad10-6ed74e861be8",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I agree on making PVC size configurable.  For example, Google Filestore volumes have a min size of 1TB",
        "createdAt" : "2018-11-08T19:56:49Z",
        "updatedAt" : "2018-11-08T19:56:50Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b89b367247039f4a46a1ca2f0e4e906d723d79d2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +152,156 @@\t\t\t}\n\t\t\tp.driver = driver\n\t\t\tp.claimSize = \"5Gi\"\n\t\t\tp.pvc = getClaim(p.claimSize, driver.GetDriverInfo().Framework.Namespace.Name)\n\t\t\tp.pvc.Spec.StorageClassName = &p.sc.Name"
  }
]