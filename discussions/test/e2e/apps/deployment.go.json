[
  {
    "id" : "29907eec-bf33-4ad4-a1c6-7ac2181f89ea",
    "prId" : 102260,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102260#pullrequestreview-677963088",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db6928fa-1fbe-479e-bcf1-3eb646e6dfc9",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "nit: Same as the comment I mentioned at https://github.com/kubernetes/kubernetes/pull/102256#discussion_r646206878",
        "createdAt" : "2021-06-07T00:09:11Z",
        "updatedAt" : "2021-06-07T00:10:08Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      },
      {
        "id" : "fbeffc3a-557a-4438-af42-64842f332f8e",
        "parentId" : "db6928fa-1fbe-479e-bcf1-3eb646e6dfc9",
        "authorId" : "23d83a23-a06a-4542-a52f-6096ea5648ef",
        "body" : "@ravisantoshgudimetla If the test was to flake at some point the idea was to have a clear reference point to help debug the test. For some context refer to this [comment](https://github.com/kubernetes/kubernetes/pull/96485#issuecomment-732335344).",
        "createdAt" : "2021-06-07T21:19:29Z",
        "updatedAt" : "2021-06-07T21:19:29Z",
        "lastEditedBy" : "23d83a23-a06a-4542-a52f-6096ea5648ef",
        "tags" : [
        ]
      },
      {
        "id" : "ddb53d07-4ba3-4e07-be71-8d0acc638fe8",
        "parentId" : "db6928fa-1fbe-479e-bcf1-3eb646e6dfc9",
        "authorId" : "53d7f6d1-52e4-4b09-bbe9-0301c7d86286",
        "body" : "The same pattern is followed in other merged conformance tests. We would like to keep it consistent. Thank you for the review.",
        "createdAt" : "2021-06-07T23:24:51Z",
        "updatedAt" : "2021-06-07T23:24:51Z",
        "lastEditedBy" : "53d7f6d1-52e4-4b09-bbe9-0301c7d86286",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c1576ae5732189ef150ad2f3b393f469943e8ed",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +562,566 @@\n\t\t\t\tif !found {\n\t\t\t\t\tframework.Logf(\"Observed Deployment %v in namespace %v with annotations: %v & Conditions: %v\\n\", d.ObjectMeta.Name, d.ObjectMeta.Namespace, d.Annotations, d.Status.Conditions)\n\t\t\t\t\treturn false, nil\n\t\t\t\t}"
  },
  {
    "id" : "51d6dc59-8933-44bf-8813-61701ea259d7",
    "prId" : 93458,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/93458#pullrequestreview-467911518",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ec23bb7-2d58-4630-9bca-2f830aed1cc7",
        "parentId" : null,
        "authorId" : "c2df03b8-26df-4018-9f8f-4ddea7f8f6cc",
        "body" : "Can we separate this into multiple tests?\r\nCurrent test is one of big tests by comparing the other tests in this test package and that would make it difficult to investigate issues if they happen.",
        "createdAt" : "2020-08-14T22:30:07Z",
        "updatedAt" : "2020-11-02T22:21:35Z",
        "lastEditedBy" : "c2df03b8-26df-4018-9f8f-4ddea7f8f6cc",
        "tags" : [
        ]
      },
      {
        "id" : "9a8506a0-03be-4330-bd2c-e49221d9ca35",
        "parentId" : "5ec23bb7-2d58-4630-9bca-2f830aed1cc7",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "every individual test has setup/tear down cost, and our e2e jobs already trend long. A single coherent test that walks an object through its paces seems better to me. ",
        "createdAt" : "2020-08-14T22:49:47Z",
        "updatedAt" : "2020-11-02T22:21:35Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c4117dc733df1b094b9aff27efa08d502c6e4ee",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +144,148 @@\t// See https://github.com/kubernetes/kubernetes/issues/29229\n\n\tginkgo.It(\"should run the lifecycle of a Deployment\", func() {\n\t\tzero := int64(0)\n\t\tdeploymentResource := schema.GroupVersionResource{Group: \"apps\", Version: \"v1\", Resource: \"deployments\"}"
  },
  {
    "id" : "497669f4-78e9-4a80-8726-eb6aa10a8c35",
    "prId" : 92589,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92589#pullrequestreview-452820764",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e0e3013-8d13-4337-90ff-1eee0938c35e",
        "parentId" : null,
        "authorId" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "body" : "Why is `dc.Resource` being used instead of `f.ClientSet.AppsV1().Deployments`?",
        "createdAt" : "2020-07-20T19:00:02Z",
        "updatedAt" : "2020-07-23T02:07:26Z",
        "lastEditedBy" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "tags" : [
        ]
      },
      {
        "id" : "e4aa7cb5-9208-4455-b6c9-49c048700352",
        "parentId" : "8e0e3013-8d13-4337-90ff-1eee0938c35e",
        "authorId" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "body" : "I'm also curious why `Update` is being used here instead of the usual marshal-json-to-bytes-then-`Patch` approach I've seen in other tests from you?",
        "createdAt" : "2020-07-20T19:05:52Z",
        "updatedAt" : "2020-07-23T02:07:26Z",
        "lastEditedBy" : "5de211e4-9744-455e-9548-1a8e70ed1b2e",
        "tags" : [
        ]
      },
      {
        "id" : "c73b1661-f370-4319-ba48-be54b9c77611",
        "parentId" : "8e0e3013-8d13-4337-90ff-1eee0938c35e",
        "authorId" : "97f5510f-d2e4-4cef-b8eb-c4184feaff72",
        "body" : "> Why is `dc.Resource` being used instead of `f.ClientSet.AppsV1().Deployments`?\r\n\r\nThis was meant to hit _replaceAppsV1NamespacedDeploymentStatus_, which to my research requires the DynamicClient - also why it's still remaining like this. Should I replace it with the default ClientSet, or should I leave it around for when the Endpoint could be added at a later date as a reminder?",
        "createdAt" : "2020-07-21T20:53:06Z",
        "updatedAt" : "2020-07-23T02:07:26Z",
        "lastEditedBy" : "97f5510f-d2e4-4cef-b8eb-c4184feaff72",
        "tags" : [
        ]
      },
      {
        "id" : "4e33b19d-e1a1-4247-a7b9-e43db48c3f14",
        "parentId" : "8e0e3013-8d13-4337-90ff-1eee0938c35e",
        "authorId" : "97f5510f-d2e4-4cef-b8eb-c4184feaff72",
        "body" : "> I'm also curious why `Update` is being used here instead of the usual marshal-json-to-bytes-then-`Patch` approach I've seen in other tests from you?\r\n\r\nAlso because it's trying to hit the endpoint _replaceAppsV1NamespacedDeploymentStatus_.",
        "createdAt" : "2020-07-21T20:53:34Z",
        "updatedAt" : "2020-07-23T02:07:26Z",
        "lastEditedBy" : "97f5510f-d2e4-4cef-b8eb-c4184feaff72",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee29022ac8a28fef9839a70e0be3c0f2b082364f",
    "line" : 215,
    "diffHunk" : "@@ -1,1 +306,310 @@\t\t}\n\t\t// currently this hasn't been able to hit the endpoint replaceAppsV1NamespacedDeploymentStatus\n\t\t_, err = dc.Resource(deploymentResource).Namespace(testNamespaceName).Update(context.TODO(), &testDeploymentUpdateUnstructured, metav1.UpdateOptions{}) //, \"status\")\n\t\tframework.ExpectNoError(err, \"failed to update the DeploymentStatus\")\n\t\tctx, cancel = context.WithTimeout(context.Background(), 30*time.Second)"
  },
  {
    "id" : "f359ce01-13fe-4658-b6b8-eefd1124a769",
    "prId" : 80004,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/80004#pullrequestreview-297769976",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2427a7a9-7d69-4cd7-b567-ba15b73513f6",
        "parentId" : null,
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "You need to defer closing a channel here, and then wait after your for loop for this. to exit",
        "createdAt" : "2019-10-05T01:57:44Z",
        "updatedAt" : "2019-10-17T15:53:09Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "12f81227-8361-4780-a73d-b66b7f9cbd4e",
        "parentId" : "2427a7a9-7d69-4cd7-b567-ba15b73513f6",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "See my other comment, supercedes this.",
        "createdAt" : "2019-10-05T01:58:59Z",
        "updatedAt" : "2019-10-17T15:53:09Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      }
    ],
    "commit" : "980b6406b24b41bc0ef061624385f1f420708819",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +921,925 @@\tdefer close(done)\n\tgo func() {\n\t\tdefer ginkgo.GinkgoRecover()\n\t\texpectedNodes := jig.GetEndpointNodeNames(service)\n\t\t// The affinity policy should ensure that before an old pod is"
  },
  {
    "id" : "87bd68f9-cf33-416d-887b-6a91a8d8ef90",
    "prId" : 80004,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/80004#pullrequestreview-307128944",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4df4e012-b319-4d62-9aa2-df38ccc346ff",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "This test is failing when run in 5k-node tests.\r\nThe reason is that scheduler has a feature that in large clusters it doesn't look at all nodes - as soon as it finds a certain percentage of feasible node, it stops looking for more and scores only those nodes.\r\nAnd given the affinity you're using is \"Preferred\" (it's priority function not predicate), there is no guarantee that the set of nodes we're scoring will contain any of those 3 nodes that will work for this test.\r\n\r\nI guess the solution will be to change PodAffinity from soft to hard, i.e. to RequiredDuringSchedulingIgnoredDuringExecution\r\n\r\n@kubernetes/sig-scalability-bugs @smarterclayton @ahg-g  - FYI",
        "createdAt" : "2019-10-24T20:58:09Z",
        "updatedAt" : "2019-10-24T20:58:10Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "1a4e313e-4172-4475-905d-16d68bb718e2",
        "parentId" : "4df4e012-b319-4d62-9aa2-df38ccc346ff",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I opened https://github.com/kubernetes/kubernetes/pull/84339 with the fix",
        "createdAt" : "2019-10-25T10:56:33Z",
        "updatedAt" : "2019-10-25T10:56:33Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "980b6406b24b41bc0ef061624385f1f420708819",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +926,930 @@\t\t// deleted, a new pod will have been created on the same node.\n\t\t// Thus the set of nodes with local endpoints for the service\n\t\t// should remain unchanged.\n\t\twait.Until(func() {\n\t\t\tactualNodes := jig.GetEndpointNodeNames(service)"
  },
  {
    "id" : "60d1319d-3690-45fc-a28c-4222ba91592d",
    "prId" : 55032,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/55032#pullrequestreview-92752670",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b79eafd0-7696-46ba-b9e9-ea619b937102",
        "parentId" : null,
        "authorId" : "a3d6d690-2601-4c58-a5bc-a3eaa025f8e0",
        "body" : "For error messages, we start with lower case. For logging messages, will it be fine to start them with capital case? Other tests have capital case for the logging messages.",
        "createdAt" : "2017-11-03T21:05:42Z",
        "updatedAt" : "2018-02-21T00:56:49Z",
        "lastEditedBy" : "a3d6d690-2601-4c58-a5bc-a3eaa025f8e0",
        "tags" : [
        ]
      },
      {
        "id" : "dd22a725-2b66-42b8-aa44-6a5b36babd6c",
        "parentId" : "b79eafd0-7696-46ba-b9e9-ea619b937102",
        "authorId" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "body" : "https://github.com/golang/go/wiki/CodeReviewComments#error-strings\r\n\r\nError strings aren't capitalized because they're often prefixed before printing (you've probably seen `fmt.Errorf(\"xxx: %v\", err)` a lot). This is not the case for logs. Logs should be capitalized. ",
        "createdAt" : "2018-01-30T23:25:16Z",
        "updatedAt" : "2018-02-21T00:56:49Z",
        "lastEditedBy" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1df84ba0db38ab0f8418f22e84b5d5b05b37b473",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +820,824 @@\td.Spec.Strategy.RollingUpdate.MaxUnavailable = intOrStrP(2)\n\n\tframework.Logf(\"Creating deployment %q\", deploymentName)\n\tdeployment, err := c.ExtensionsV1beta1().Deployments(ns).Create(d)\n\tExpect(err).NotTo(HaveOccurred())"
  },
  {
    "id" : "793af8ed-34e6-40d2-813f-f029529d3ca7",
    "prId" : 55032,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/55032#pullrequestreview-96612788",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e616353-67bf-415f-ba91-074907cd19d6",
        "parentId" : null,
        "authorId" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "body" : "We can use scale subresource to avoid conflict. But let's leave it for now and revisit it later. ",
        "createdAt" : "2018-02-08T01:06:31Z",
        "updatedAt" : "2018-02-21T00:56:49Z",
        "lastEditedBy" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "tags" : [
        ]
      },
      {
        "id" : "7778c378-1406-4fca-892d-e78e0a8079a9",
        "parentId" : "9e616353-67bf-415f-ba91-074907cd19d6",
        "authorId" : "a3d6d690-2601-4c58-a5bc-a3eaa025f8e0",
        "body" : "Do you mind to explain why will there be a conflict?",
        "createdAt" : "2018-02-08T05:08:21Z",
        "updatedAt" : "2018-02-21T00:56:49Z",
        "lastEditedBy" : "a3d6d690-2601-4c58-a5bc-a3eaa025f8e0",
        "tags" : [
        ]
      },
      {
        "id" : "1ccb9637-1032-4be2-817d-f16e24950634",
        "parentId" : "9e616353-67bf-415f-ba91-074907cd19d6",
        "authorId" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "body" : "I meant the update conflict, which is why we update deployment with retries. ",
        "createdAt" : "2018-02-14T18:46:09Z",
        "updatedAt" : "2018-02-21T00:56:49Z",
        "lastEditedBy" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1df84ba0db38ab0f8418f22e84b5d5b05b37b473",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +904,908 @@\t\tupdate.Spec.Replicas = &newReplicas\n\t})\n\tExpect(err).NotTo(HaveOccurred())\n\n\tframework.Logf(\"Waiting for the replicasets of deployment %q to have desired number of replicas\", deploymentName)"
  },
  {
    "id" : "c40bbcf9-e75d-4796-aec8-365a2a2c1dfb",
    "prId" : 49289,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/49289#pullrequestreview-51315957",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e73a2ac6-c365-4212-885f-0d3b08aba9e0",
        "parentId" : null,
        "authorId" : "a5ac91f3-1cbc-4fd9-af85-741ee28dd9c8",
        "body" : "Golint comments: should have a package comment, unless it's in another file for this package. [More info](https://golang.org/wiki/CodeReviewComments#package-comments). <!-- golint -->",
        "createdAt" : "2017-07-20T20:09:05Z",
        "updatedAt" : "2017-07-22T10:43:51Z",
        "lastEditedBy" : "a5ac91f3-1cbc-4fd9-af85-741ee28dd9c8",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e93ed27bd90728dc840b9bfd67b5c4c35affe48",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +15,19 @@*/\n\npackage apps\n\nimport ("
  }
]