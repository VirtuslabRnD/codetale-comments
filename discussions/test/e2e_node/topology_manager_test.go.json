[
  {
    "id" : "48c33e80-2a23-4aa9-a2d9-0ae53eba16c4",
    "prId" : 95734,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95734#pullrequestreview-539449132",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22abda5e-20c4-46b9-afc5-a161d95e9dab",
        "parentId" : null,
        "authorId" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "body" : "Nit on commit message:\r\n\r\n```\r\ndocument why teardowbnSRIOVPod was to wait for all the containers\r\nto be gone before to end, and why is important.\r\n```\r\n\r\nshould be:\r\n```\r\ndocument why teardownSRIOVPod has to wait for all the containers\r\nto be gone before to end, and why is important.\r\n```",
        "createdAt" : "2020-11-25T06:17:19Z",
        "updatedAt" : "2021-03-09T15:40:18Z",
        "lastEditedBy" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "tags" : [
        ]
      },
      {
        "id" : "1f49edea-2991-4737-bfc4-3d1824410cd9",
        "parentId" : "22abda5e-20c4-46b9-afc5-a161d95e9dab",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "ack, will fix since I want to address the last pending comment",
        "createdAt" : "2020-11-26T16:16:32Z",
        "updatedAt" : "2021-03-09T15:40:18Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "aafe8b45-3af0-4eab-8351-1d92c315e418",
        "parentId" : "22abda5e-20c4-46b9-afc5-a161d95e9dab",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "actually not sure because I don't want to lose the LGTM if I can help it :\\",
        "createdAt" : "2020-11-26T16:29:04Z",
        "updatedAt" : "2021-03-09T15:40:18Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "1e7bb20c52e452a7ca061ca1dda1936e9df1f266",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +392,396 @@}\n\n// waitForAllContainerRemoval waits until all the containers on a given pod are really gone.\n// This is needed by the e2e tests which involve exclusive resource allocation (cpu, topology manager; podresources; etc.)\n// In these cases, we need to make sure the tests clean up after themselves to make sure each test runs in"
  },
  {
    "id" : "06989e2a-34e9-4f83-ac01-ea3c9faa3a9a",
    "prId" : 95609,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95609#pullrequestreview-638842529",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba763ae4-bcb5-4281-b64b-ddbc25ae3f40",
        "parentId" : null,
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "some stupid question, why do you get under arguments `map[string]*v1.Pod` instead of `[]*v1.Pod`, when you do not really use the key?",
        "createdAt" : "2021-04-19T12:36:11Z",
        "updatedAt" : "2021-04-19T12:39:07Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "9860e82e-494e-4947-958c-708c836de8a0",
        "parentId" : "ba763ae4-bcb5-4281-b64b-ddbc25ae3f40",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "It's not stupid: I want to use this helper from two different test suites.\r\nOne of them (podresources) already keeps a map, while here the most natural representation would be a `[]*v1.Pod`. So I need to refactor at least one between the two calling sites and the code :)\r\nNow: the code originates from `podresources_test.go`, and I want to use here; to minimize the changes the path of least resistance is to use a map here in `topology_manager_test.go`.\r\nI'm open to other approaches though.",
        "createdAt" : "2021-04-19T12:44:52Z",
        "updatedAt" : "2021-04-19T12:44:52Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "64673ddd-7e99-450c-8606-a21d7ae0e2a5",
        "parentId" : "ba763ae4-bcb5-4281-b64b-ddbc25ae3f40",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "good enough for me.",
        "createdAt" : "2021-04-19T13:05:18Z",
        "updatedAt" : "2021-04-19T13:05:19Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc0955c26acbaecdd256443076843cbc7507d02f",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +446,450 @@func deletePodsAsync(f *framework.Framework, podMap map[string]*v1.Pod) {\n\tvar wg sync.WaitGroup\n\tfor _, pod := range podMap {\n\t\twg.Add(1)\n\t\tgo func(podNS, podName string) {"
  },
  {
    "id" : "8fe968d8-8aa7-46ce-a194-10c293ac0c9e",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-519599579",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11bf897d-ef09-4374-90ed-e0ab23468a2e",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Have you verified that these actually run? I know you have to send a specific command in the PR comments to trigger them (they are not automatic as far as I know).",
        "createdAt" : "2020-10-28T19:07:22Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "aac4bd36-1726-4f79-9aff-d7756b582f56",
        "parentId" : "11bf897d-ef09-4374-90ed-e0ab23468a2e",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "/cc @vpickard for more information",
        "createdAt" : "2020-10-28T19:07:58Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "8eb281b8-28b1-4c5e-85ab-7631d01a504f",
        "parentId" : "11bf897d-ef09-4374-90ed-e0ab23468a2e",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "/test pull-kubernetes-node-kubelet-serial-topology-manager\r\n",
        "createdAt" : "2020-10-28T19:41:02Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "2552bb27-3499-4a3a-96db-7c5618f7526a",
        "parentId" : "11bf897d-ef09-4374-90ed-e0ab23468a2e",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "@klueska Yes, the jobs still have to be manuall triggered, as above. ",
        "createdAt" : "2020-10-28T19:41:59Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "649d857a-4a8c-41a2-9120-6a392ae21393",
        "parentId" : "11bf897d-ef09-4374-90ed-e0ab23468a2e",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "We were verifying tests in our test environment. As I see tests are passing here too. Thanks for the command Victor!",
        "createdAt" : "2020-10-29T12:12:06Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +330,334 @@\n// validatePodAligmentWithPodScope validates whether all pod's CPUs are affined to the same NUMA node.\nfunc validatePodAlignmentWithPodScope(f *framework.Framework, pod *v1.Pod, envInfo *testEnvInfo) error {\n\t// Mapping between CPU IDs and NUMA node IDs.\n\tpodsNUMA := make(map[int]int)"
  },
  {
    "id" : "008a9c62-ac67-4ca0-a908-59293c369529",
    "prId" : 88773,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/88773#pullrequestreview-368748158",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f7afc19-9a00-4a5f-b52a-ac87b6a1a1c6",
        "parentId" : null,
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Yes, checking Allocatable instead of Capacity should be the fix",
        "createdAt" : "2020-03-04T07:25:29Z",
        "updatedAt" : "2020-03-04T15:08:02Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "5dc8de8c-e96e-475b-b732-24bfc3897efd",
        "parentId" : "2f7afc19-9a00-4a5f-b52a-ac87b6a1a1c6",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "Yes, in my local testing, this worked great. The test ran all the way with no failures, and I could definitely see in the logs, that the SRIOV devices took 3-5 seconds before they were \"allocatable\", whereas before it was almost immediate when checking capacity.",
        "createdAt" : "2020-03-04T12:47:54Z",
        "updatedAt" : "2020-03-04T15:08:02Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      }
    ],
    "commit" : "61565b3f6c7d1fbf0180254f544e23a8d2e2a73e",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +681,685 @@\t\tnode := getLocalNode(f)\n\t\tsriovResourceName, sriovResourceAmount = findSRIOVResource(node)\n\t\treturn sriovResourceAmount > minSriovResource\n\t}, 2*time.Minute, framework.Poll).Should(gomega.BeTrue())\n\tframework.Logf(\"Successfully created device plugin pod, detected %d SRIOV allocatable devices %q\", sriovResourceAmount, sriovResourceName)"
  },
  {
    "id" : "97989a0c-f23b-4972-b2cf-534a419ce039",
    "prId" : 88773,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/88773#pullrequestreview-368750662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17298a9f-ba85-4331-82d2-3aea3b290e07",
        "parentId" : null,
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "I didn't add because on my env the sriovdp was fast enough in like 95% of cases, but this is something we better have, yes.",
        "createdAt" : "2020-03-04T07:28:41Z",
        "updatedAt" : "2020-03-04T15:08:02Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "9d0cfad5-baa4-4517-8275-03b05df30080",
        "parentId" : "17298a9f-ba85-4331-82d2-3aea3b290e07",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "Agree, just another check to make sure we are ready.",
        "createdAt" : "2020-03-04T12:51:55Z",
        "updatedAt" : "2020-03-04T15:08:02Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      }
    ],
    "commit" : "61565b3f6c7d1fbf0180254f544e23a8d2e2a73e",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +673,677 @@\t\tframework.Logf(\"SRIOV Pod %v took too long to enter running/ready: %v\", dp.Name, err)\n\t}\n\tframework.ExpectNoError(err)\n\n\tsriovResourceName := \"\""
  },
  {
    "id" : "deae66a3-7b62-4218-91cc-5cff371dd1ac",
    "prId" : 88234,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/88234#pullrequestreview-361826567",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0690bbd2-b0fa-4edf-9468-f3b66decd8d1",
        "parentId" : null,
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "Just curious, does CPU manager returns correct topology hints when you do not specify integer CPU's, I was sure it works only for static policy.",
        "createdAt" : "2020-02-20T08:35:27Z",
        "updatedAt" : "2020-02-20T17:23:01Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "504d7d66-59b2-481c-934b-8f3b82409eb6",
        "parentId" : "0690bbd2-b0fa-4edf-9468-f3b66decd8d1",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "In the `configureTopologyManagerInKubelet` helper we always set the CPUManager policy to `static` indeed. Edit: for reference https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/cpumanager/policy_static.go#L265",
        "createdAt" : "2020-02-20T08:43:40Z",
        "updatedAt" : "2020-02-20T17:23:01Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "a44a1339-b0d9-41ad-851b-ea7a946771c2",
        "parentId" : "0690bbd2-b0fa-4edf-9468-f3b66decd8d1",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "Thanks for the clarification.",
        "createdAt" : "2020-02-20T11:26:46Z",
        "updatedAt" : "2020-02-20T17:23:01Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      }
    ],
    "commit" : "64904d0ab8b880172dbe6630194f5abd070530be",
    "line" : 336,
    "diffHunk" : "@@ -1,1 +777,781 @@\t\t\t{\n\t\t\t\tctnName:       \"gu-container\",\n\t\t\t\tcpuRequest:    \"1000m\",\n\t\t\t\tcpuLimit:      \"1000m\",\n\t\t\t\tdeviceName:    sd.resourceName,"
  },
  {
    "id" : "c56d070c-8d5f-4582-9962-378601c39342",
    "prId" : 87645,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87645#pullrequestreview-356117045",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b39489f1-e8af-4199-9dbb-ce93d05578ab",
        "parentId" : null,
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "It may be a good idea to document, perhaps with a comment here, and in test doc code, that VFs should already be configure on the system under test. On my setup, I did not have any VFs configured (wiped out from doing other stuff), and the test spun here for 5 mins. \r\n\r\nPerhaps some example config/commands would be helpful. For example:\r\n\r\ncat /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.1/sriov_numvfs\r\necho 7 > /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.1/sriov_numvfs\r\n",
        "createdAt" : "2020-02-10T15:04:25Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "978417d2-83e1-400c-acf5-17e172d58178",
        "parentId" : "b39489f1-e8af-4199-9dbb-ce93d05578ab",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Will post a PR against https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md - but will also add a comment here.",
        "createdAt" : "2020-02-10T17:17:16Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "70cce5e3f13961bbc78eed9f3869b433cfd846d2",
    "line" : 388,
    "diffHunk" : "@@ -1,1 +624,628 @@\tsriovResourceName := \"\"\n\tvar sriovResourceAmount int64\n\tginkgo.By(\"Waiting for devices to become available on the local node\")\n\tgomega.Eventually(func() bool {\n\t\tnode := getLocalNode(f)"
  },
  {
    "id" : "405793b2-eb7c-4810-9ba0-9197b721ccee",
    "prId" : 87645,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87645#pullrequestreview-356116622",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03fea64a-f566-47d2-a437-27568aeffad7",
        "parentId" : null,
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "SR-IOV device plugin also supports Mellanox devices. I think it would be a good idea if this could be expanded to work with either Intel or Mellanox.",
        "createdAt" : "2020-02-10T15:07:45Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "e827e0a9-836c-4bfc-b8f6-a41019b2ed9e",
        "parentId" : "03fea64a-f566-47d2-a437-27568aeffad7",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Yup, already improved here: https://github.com/kubernetes/kubernetes/pull/87645/commits/0fad14ffe1c3daadf2a6d47c3ed68e8fd8e80bfb",
        "createdAt" : "2020-02-10T17:16:38Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "70cce5e3f13961bbc78eed9f3869b433cfd846d2",
    "line" : 225,
    "diffHunk" : "@@ -1,1 +243,247 @@\nfunc findSRIOVResource(node *v1.Node) (string, int64) {\n\tre := regexp.MustCompile(`^intel.com/.*sriov.*`)\n\tfor key, val := range node.Status.Capacity {\n\t\tresource := string(key)"
  },
  {
    "id" : "396d4bf9-cb96-4f13-9a19-dca174e1e672",
    "prId" : 87645,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87645#pullrequestreview-356143341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef06146f-ea39-4984-8d01-20bef39fae83",
        "parentId" : null,
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "Perhaps consider moving the SRIOV setup to separate function (setupSRIOVConf()... or something like that). \r\n\r\nEventually, we will have support for other devices (memory manager, GPU). It seems a little cleaner to have the device setup separately from the actual tests. ",
        "createdAt" : "2020-02-10T15:11:04Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "e3427f9e-16cd-4624-a3d3-13f1b4ff4008",
        "parentId" : "ef06146f-ea39-4984-8d01-20bef39fae83",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Done",
        "createdAt" : "2020-02-10T17:57:09Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "70cce5e3f13961bbc78eed9f3869b433cfd846d2",
    "line" : 366,
    "diffHunk" : "@@ -1,1 +602,606 @@\tvar err error\n\n\tginkgo.By(fmt.Sprintf(\"Creating configMap %v/%v\", metav1.NamespaceSystem, configMap.Name))\n\tif _, err = f.ClientSet.CoreV1().ConfigMaps(metav1.NamespaceSystem).Create(context.TODO(), configMap, metav1.CreateOptions{}); err != nil {\n\t\tframework.Failf(\"unable to create test configMap %s: %v\", configMap.Name, err)"
  },
  {
    "id" : "1e37b150-7bf4-4fb0-8f3e-344fbef23cec",
    "prId" : 87645,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87645#pullrequestreview-356539657",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbce3949-4d07-4492-b620-ac172faa0c8a",
        "parentId" : null,
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "The negative test was failing in my setup. Debugged it, and could see from older version where it was failing. Code was checking for Topology Affinity Error, from below const definition. I see you have fixed this in latest update. Nice!\r\n\r\ntopologyError = \"Topology Affinity Error\" // XXX do we have a proper constant?\r\n\r\nI also looked around to see if this error string was defined somewhere, but no luck so far...\r\n",
        "createdAt" : "2020-02-10T22:37:48Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "8736ed9c-34dc-444d-b9a3-2927063a492f",
        "parentId" : "cbce3949-4d07-4492-b620-ac172faa0c8a",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Sorry for causing you troubles. I'm not very happy with the current test but it's the best I could think of, lacking constants or symbols I could depend on :\\",
        "createdAt" : "2020-02-11T08:14:27Z",
        "updatedAt" : "2020-02-11T08:14:28Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "a47ccd52-c72a-468d-a470-4103b3e91970",
        "parentId" : "cbce3949-4d07-4492-b620-ac172faa0c8a",
        "authorId" : "9b4e4d81-187d-4943-a9be-08f439915f8f",
        "body" : "Not sure if this is relevant, but just FYI: Changes introduced in https://github.com/kubernetes/kubernetes/pull/87758 mean the error is now \"TopologyAffinityError\" as opposed to previous \"Topology Affinity Error\".",
        "createdAt" : "2020-02-11T09:58:47Z",
        "updatedAt" : "2020-02-11T09:58:47Z",
        "lastEditedBy" : "9b4e4d81-187d-4943-a9be-08f439915f8f",
        "tags" : [
        ]
      },
      {
        "id" : "21cb01f9-46c7-470f-b7cd-f261ce0b9219",
        "parentId" : "cbce3949-4d07-4492-b620-ac172faa0c8a",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Ack, I missed this, thanks for pointing it out. This is the reason why it worked before and then failed. Anyway I'd keep the regexp match - lacking better alternatives - because its' a little less fragile than the string matching I had before.",
        "createdAt" : "2020-02-11T10:16:24Z",
        "updatedAt" : "2020-02-11T10:16:24Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "70cce5e3f13961bbc78eed9f3869b433cfd846d2",
    "line" : 341,
    "diffHunk" : "@@ -1,1 +577,581 @@\nfunc isTopologyAffinityError(pod *v1.Pod) bool {\n\tre := regexp.MustCompile(`Topology.*Affinity.*Error`)\n\treturn re.MatchString(pod.Status.Reason)\n}"
  },
  {
    "id" : "0d9a3ea7-a9fe-4103-bfeb-49f7e226d47b",
    "prId" : 87645,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87645#pullrequestreview-356887568",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a56ea0c7-b16d-4c3e-8088-ac928f3ac784",
        "parentId" : null,
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "I'm seeing this failure in my setup when I run the test. Looks like 2 min timeout waiting to remove container...\r\n\r\nI don't have your last 2 commits, but I don't think this part of the code changed.... I will update and retest, may be tomorrow morning...\r\n\r\nFeb 10 23:39:53.117: INFO: Pod \"gu-pod\" satisfied condition \"Failed\"\r\nFeb 10 23:39:53.125: INFO: Waiting for pod gu-pod to disappear\r\nFeb 10 23:39:53.127: INFO: Pod gu-pod no longer exists\r\nFeb 10 23:39:53.127: INFO: deleting the SRIOV device plugin pod kube-system/sriov-device-plugin and waiting for container kube-sriovdp removal\r\n\r\nâ€¢ Failure [498.096 seconds]\r\n[sig-node] Topology Manager [Serial] [Feature:TopologyManager][NodeAlphaFeature:TopologyManager]\r\n_output/local/go/src/k8s.io/kubernetes/test/e2e_node/framework.go:23\r\n  With kubeconfig updated to static CPU Manager policy run the Topology Manager tests\r\n  _output/local/go/src/k8s.io/kubernetes/test/e2e_node/topology_manager_test.go:739\r\n    run Topology Manager node alignment test suite [It]\r\n    _output/local/go/src/k8s.io/kubernetes/test/e2e_node/topology_manager_test.go:695\r\n\r\n    Timed out after 120.000s.\r\n    Expected                                                                                                                                                            \r\n        <bool>: false                                                                                                                                                   \r\n    to be true                        \r\n",
        "createdAt" : "2020-02-10T22:46:53Z",
        "updatedAt" : "2020-02-10T23:50:13Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "21d65ace-ee2e-4ed0-a31d-a2ea08580b3a",
        "parentId" : "a56ea0c7-b16d-4c3e-8088-ac928f3ac784",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "We investigated on Victor's testing machine, and it seems a local glitch. We'll check again in the near future.",
        "createdAt" : "2020-02-11T17:34:56Z",
        "updatedAt" : "2020-02-11T17:34:57Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "519e5a7b-aee2-4c2a-b7f5-08efa8152a00",
        "parentId" : "a56ea0c7-b16d-4c3e-8088-ac928f3ac784",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "Yes, it was a docker issue on my setup. I have it working now.",
        "createdAt" : "2020-02-11T18:23:03Z",
        "updatedAt" : "2020-02-11T18:23:03Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      }
    ],
    "commit" : "70cce5e3f13961bbc78eed9f3869b433cfd846d2",
    "line" : 404,
    "diffHunk" : "@@ -1,1 +640,644 @@\t\tdpPod.Namespace, dpPod.Name, dpPod.Spec.Containers[0].Name)\n\tdeletePodInNamespace(f, dpPod.Namespace, dpPod.Name)\n\twaitForContainerRemoval(dpPod.Spec.Containers[0].Name, dpPod.Name, dpPod.Namespace)\n}\n"
  },
  {
    "id" : "ea58c5a9-d4c3-4bc8-8913-7cabdec57f50",
    "prId" : 86184,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86184#pullrequestreview-345945542",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ac3407b-01e2-4e74-b792-b8b78425c97d",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "nit: makeTopologyManagerPod",
        "createdAt" : "2020-01-21T15:03:23Z",
        "updatedAt" : "2020-01-21T15:18:43Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e644c874936c7b0ade5c150b3371859c6588992",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +43,47 @@}\n\n// makeTopologyMangerPod returns a pod with the provided tmCtnAttributes.\nfunc makeTopologyManagerPod(podName string, tmCtnAttributes []tmCtnAttribute) *v1.Pod {\n\tvar containers []v1.Container"
  },
  {
    "id" : "b9948f20-e4a6-42ba-b56d-e10e92205112",
    "prId" : 86184,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86184#pullrequestreview-345945542",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9c4f717-3a73-45ab-8204-d5e27bce6256",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "nit: i think its fine that we have separate structs from cpu_manager_test, but maybe leave a TODO to see if we should just care a common helper struct rather than copy as this appears to do now?",
        "createdAt" : "2020-01-21T15:09:51Z",
        "updatedAt" : "2020-01-21T15:18:43Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e644c874936c7b0ade5c150b3371859c6588992",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +37,41 @@\n// Helper for makeTopologyManagerPod().\ntype tmCtnAttribute struct {\n\tctnName    string\n\tcpuRequest string"
  },
  {
    "id" : "01bd60d8-cb7b-483d-8dc5-8ce7faa9d93e",
    "prId" : 86184,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86184#pullrequestreview-345945542",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2cb9998c-5b50-4b82-aafc-883813aa3834",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "this is basically the same as the makeCPUManagerPod, i am assuming we will grow this in the future to take device requirement?",
        "createdAt" : "2020-01-21T15:10:55Z",
        "updatedAt" : "2020-01-21T15:18:43Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e644c874936c7b0ade5c150b3371859c6588992",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +44,48 @@\n// makeTopologyMangerPod returns a pod with the provided tmCtnAttributes.\nfunc makeTopologyManagerPod(podName string, tmCtnAttributes []tmCtnAttribute) *v1.Pod {\n\tvar containers []v1.Container\n\tfor _, ctnAttr := range tmCtnAttributes {"
  },
  {
    "id" : "a6bca9b9-745b-4814-8b2c-c36e33380d55",
    "prId" : 86184,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86184#pullrequestreview-345945542",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dca6a204-f2b4-4a8e-b666-c4aeb760ed3f",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "nit: simpler to just say \"1\"",
        "createdAt" : "2020-01-21T15:12:29Z",
        "updatedAt" : "2020-01-21T15:18:43Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e644c874936c7b0ade5c150b3371859c6588992",
    "line" : 164,
    "diffHunk" : "@@ -1,1 +162,166 @@\t\t{\n\t\t\tctnName:    \"gu-container\",\n\t\t\tcpuRequest: \"1000m\",\n\t\t\tcpuLimit:   \"1000m\",\n\t\t},"
  },
  {
    "id" : "ab1280fe-a18d-4f35-ada4-bbc7c8cc7087",
    "prId" : 86184,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86184#pullrequestreview-355039012",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "150f17c3-0455-4fa7-908c-3e04cf259947",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "I see now what this is doing, so we basically configure topology manager policies, and then run the same basic tests as we cover in cpu manager test suite with a corresponding topology manager.  this makes sense as a first starting point, but i assume we will have a follow-on PR to actually validate topology policy applied if/when we add a device?",
        "createdAt" : "2020-01-21T15:16:54Z",
        "updatedAt" : "2020-01-21T15:18:43Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "9fd19cbb-e795-4bbd-83c3-d400b684f437",
        "parentId" : "150f17c3-0455-4fa7-908c-3e04cf259947",
        "authorId" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "body" : "Yes, here is the PR to add checking for alignment of CPU and SR-IOV devices:\r\nhttps://github.com/kubernetes/kubernetes/pull/87645",
        "createdAt" : "2020-02-06T19:04:07Z",
        "updatedAt" : "2020-02-06T19:04:08Z",
        "lastEditedBy" : "02dff94e-daf4-4f4a-bdf2-966dc2196371",
        "tags" : [
        ]
      },
      {
        "id" : "67c6a1c7-7431-46e0-86f3-e7dfdd6d3c96",
        "parentId" : "150f17c3-0455-4fa7-908c-3e04cf259947",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "Hi, I updated my PR with more positive test and negative test. I'm more than open about suggestions about adding more positive and negative tests, please review and suggest!",
        "createdAt" : "2020-02-07T09:48:02Z",
        "updatedAt" : "2020-02-07T09:48:03Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e644c874936c7b0ade5c150b3371859c6588992",
    "line" : 367,
    "diffHunk" : "@@ -1,1 +365,369 @@\t\t\tconfigureTopologyManagerInKubelet(f, policy)\n\t\t\t// Run the tests\n\t\t\trunTopologyManagerSuiteTests(f)\n\t\t}\n\t\t// restore kubelet config"
  }
]