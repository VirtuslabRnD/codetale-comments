[
  {
    "id" : "3d8172fe-e8df-46a7-817b-ae54e51f3b65",
    "prId" : 18458,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "973cf0f7-eaf7-42b2-b45b-b8911e7b8bd4",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "This can potentially significantly affect performance of scheduler, since List() is done under mutex. So running List() frequently may impact scheduler (note that listing 10000 pods is an expensive operation).\n\nWe should try to use watch here, although it may not be that easy... but at least a TODO is necessary.\n",
        "createdAt" : "2015-12-14T13:57:19Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "d12cccb5-bc90-464d-8d41-86d4068b2112",
        "parentId" : "973cf0f7-eaf7-42b2-b45b-b8911e7b8bd4",
        "authorId" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "body" : "TBH, that's also one of my pain.\nIn order to test larger scale cases like 10k, 20k pods, we manually craft the sleep time. It would be great if we can take this chance and push back on client team for async watch-based operation.\n",
        "createdAt" : "2015-12-14T21:42:29Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "tags" : [
        ]
      },
      {
        "id" : "ff30167e-9bb3-44c6-ac54-ec1d310eb8a6",
        "parentId" : "973cf0f7-eaf7-42b2-b45b-b8911e7b8bd4",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I think the solution here should be to setup watch on the apiserver (using the existing client infrastructure).\nIt won't be exactly what scheduler is observing, but since we are waiting until all pods are scheduler, it is definitely enough. (it's exactly what density test is doing).\n",
        "createdAt" : "2015-12-15T08:50:08Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "c4283a9f-fc6a-4f0c-8636-ad3d3820ea48",
        "parentId" : "973cf0f7-eaf7-42b2-b45b-b8911e7b8bd4",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "Of course - a TODO is fine for now.\n",
        "createdAt" : "2015-12-15T08:50:21Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9704222cf30cc9d0e6a5ea52ebaf9fea89865705",
    "line" : null,
    "diffHunk" : "@@ -1,1 +69,73 @@\t\t// This can potentially affect performance of scheduler, since List() is done under mutex.\n\t\t// TODO: Setup watch on apiserver and wait until all pods scheduled.\n\t\tscheduled := schedulerConfigFactory.ScheduledPodLister.Store.List()\n\t\tif len(scheduled) >= numScheduledPods+b.N {\n\t\t\tbreak"
  },
  {
    "id" : "f0fab037-cd3b-4825-93b8-ed7bab9ad418",
    "prId" : 18458,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24fbc5c6-2f34-4c56-a992-d00e7e751523",
        "parentId" : null,
        "authorId" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "body" : "I think we need to add a todo here. MakePods actually goes through the scheduling path and it can be slow. So it might take a long time to prepare the benchmark. Ideally, we should just setup a case that all the pods evenly scheduled to nodes really quickly. (We can mock other setups in the future too)\n",
        "createdAt" : "2015-12-14T18:10:40Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "tags" : [
        ]
      },
      {
        "id" : "024f975b-5c01-4025-aae4-9b4e86663672",
        "parentId" : "24fbc5c6-2f34-4c56-a992-d00e7e751523",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "+1\n@hongchaodeng - can you please add a TODO for it\n",
        "createdAt" : "2015-12-15T08:48:03Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9704222cf30cc9d0e6a5ea52ebaf9fea89865705",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +55,59 @@\n\tmakeNodes(c, numNodes)\n\tmakePods(c, numScheduledPods)\n\tfor {\n\t\tscheduled := schedulerConfigFactory.ScheduledPodLister.Store.List()"
  },
  {
    "id" : "5605e218-7b89-46e4-9f7c-0f007af07986",
    "prId" : 18458,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72b221f2-2b3c-478f-8b3b-ab07e994517d",
        "parentId" : null,
        "authorId" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "body" : "Hi @wojtek-t ,\nSetting up 10k pods with client takes a lot of time. I would like to see any improvement to do set up in a quicker way. Unfortunately I don't know how to do it.\n\nBenchmarkXXX is used to find the bottleneck. The quicker the better :)\n/cc @xiang90 \n",
        "createdAt" : "2015-12-14T18:18:52Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "tags" : [
        ]
      },
      {
        "id" : "b06466df-99d9-4e79-8f42-41467f5c3d49",
        "parentId" : "72b221f2-2b3c-478f-8b3b-ab07e994517d",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "Sure - that's fine.\nWe can always add another one.\n",
        "createdAt" : "2015-12-15T08:47:14Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9704222cf30cc9d0e6a5ea52ebaf9fea89865705",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +42,46 @@// BenchmarkScheduling1000Nodes1000Pods benchmarks the scheduling rate\n// when the cluster has 1000 nodes and 1000 scheduled pods\nfunc BenchmarkScheduling1000Nodes1000Pods(b *testing.B) {\n\tbenchmarkScheduling(1000, 1000, b)\n}"
  },
  {
    "id" : "7a0e354d-216b-408e-8cfa-1c2617295eed",
    "prId" : 18458,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "parentId" : null,
        "authorId" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "body" : "List sleep time changed to 100 ms\n@wojtek-t \n",
        "createdAt" : "2015-12-14T21:51:37Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "tags" : [
        ]
      },
      {
        "id" : "b1384a84-7a9a-42e6-b8e9-eb64246518d6",
        "parentId" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "authorId" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "body" : "this is going to affect the accuracy of benchmark. Assume the benchmark finishes within 100ms, we will introduce a 100% deviation between true value and the observed value.\n",
        "createdAt" : "2015-12-14T21:54:22Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "tags" : [
        ]
      },
      {
        "id" : "d50264c4-029f-4e2e-9bfd-600623606420",
        "parentId" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "authorId" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "body" : "go bench will generally try to finish the benchmark around second level by trying different Ns. We probably will introduce 10% if we change to 100ms.\n",
        "createdAt" : "2015-12-14T21:55:34Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "55c0e4a8-86f8-4426-a163-752ee421c57e",
        "tags" : [
        ]
      },
      {
        "id" : "09bc2a88-cd3e-44b9-8ba5-42fc25444fd4",
        "parentId" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "authorId" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "body" : "My point is that any amount of sleep time is fine to me. Exact accuracy on benchmark results isn't the highest goal in my mind. Go profiling tool still tells me where the time is spent no matter what.\n\nI'm trying to raise a discussion here. Here the tradeoff is about accuracy on bench results and potential effects of mutex. What do you think?\n\n@wojtek-t @xiang90 \n",
        "createdAt" : "2015-12-15T04:46:30Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "tags" : [
        ]
      },
      {
        "id" : "b9fb2e6a-d3fa-4463-aedc-7a9736c1bfab",
        "parentId" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I think we should proceed with what we have now (100ms is good enough in my opinion), and change to watch as soon as possible (as a next step?).\nWDYT?\n",
        "createdAt" : "2015-12-15T08:51:41Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "59a86b60-0624-4a38-8672-c3787f1aefd6",
        "parentId" : "ae160953-a36d-4a7e-bfc8-c197b210e751",
        "authorId" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "body" : "SGTM. \n\n/cc @xiang90 \n",
        "createdAt" : "2015-12-15T18:45:20Z",
        "updatedAt" : "2015-12-18T17:41:17Z",
        "lastEditedBy" : "bb4cf218-381a-40ad-ac0c-0c2c66685cd4",
        "tags" : [
        ]
      }
    ],
    "commit" : "9704222cf30cc9d0e6a5ea52ebaf9fea89865705",
    "line" : null,
    "diffHunk" : "@@ -1,1 +75,79 @@\t\t// Note: This might introduce slight deviation in accuracy of benchmark results.\n\t\t// Since the total amount of time is relatively large, it might not be a concern.\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n}"
  }
]