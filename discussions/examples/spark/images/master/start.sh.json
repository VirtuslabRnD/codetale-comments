[
  {
    "id" : "a88a32a4-59b2-4197-8002-6a7a60365455",
    "prId" : 16607,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "Did you verify the output works.. (docker logs = spark output) I tried building your images but they ubuntu based :-( \n| used apt-get. \n",
        "createdAt" : "2015-11-05T22:15:09Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "58b7796e-ef03-49af-8140-aacd7bd4083e",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "Yup. There's a pile of private iterations hidden behind that one tag bump.\n",
        "createdAt" : "2015-11-05T22:17:06Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "0ba03ba3-a2db-4f79-bf66-569fb0d4dc22",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "What failed? Blech, I thought this was supposed to be agnostic.\n",
        "createdAt" : "2015-11-05T22:25:07Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "69eda009-1482-4506-a50b-eef89a31bc78",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "apt-get failed on the base image. \n\nStep 1 : RUN apt-get update -y\n ---> Running in 6d09b8abfdef\nunexpected EOF\nMakefile:10: recipe for target 'containers' failed\n",
        "createdAt" : "2015-11-05T22:32:45Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "d5cd4eb2-a13b-486d-993d-a359b9df21df",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "Come to think of it why are you installing scala?  \n\nYou should only need the jvm for compiled binaries. \n",
        "createdAt" : "2015-11-05T22:47:58Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "b6934ec8-b328-4542-95fd-3147b04cb537",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "That's a bit of legacy I haven't even touched. I can try to take it out, gimme a bit.\n",
        "createdAt" : "2015-11-05T22:53:31Z",
        "updatedAt" : "2015-11-05T23:15:42Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "81221728-6892-4b1e-8027-504d3c1f745b",
        "parentId" : "f1c1484a-0fbd-4477-a849-01808bb99d33",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "Done. I took out `setup_client.sh` as well, because it's no longer how we get to the master. (It used to shim in the address for the driver, if I'm understanding it, now DNS just works.)\n",
        "createdAt" : "2015-11-05T23:17:03Z",
        "updatedAt" : "2015-11-05T23:17:03Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "de92fb698edf8fe56d35632443d849f39dea7831",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +20,24 @@\n# Run spark-class directly so that when it exits (or crashes), the pod restarts.\n/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip spark-master --port 7077 --webui-port 8080"
  },
  {
    "id" : "3dc3078f-406b-4bf4-8258-2a5d4b1d0b6e",
    "prId" : 16320,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47c81d24-19c9-4c9f-93d8-455f1d3c572a",
        "parentId" : null,
        "authorId" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "body" : "Can't we set the log4 properties just to stdout, and eliminate the tail? \n",
        "createdAt" : "2015-10-30T14:07:33Z",
        "updatedAt" : "2015-10-30T14:07:33Z",
        "lastEditedBy" : "f81960f6-a033-4403-bebf-c8ebb484e444",
        "tags" : [
        ]
      },
      {
        "id" : "812f3534-0aee-47a0-bc0f-7b64e0e12f5b",
        "parentId" : "47c81d24-19c9-4c9f-93d8-455f1d3c572a",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "https://github.com/kubernetes/kubernetes/pull/16607\n",
        "createdAt" : "2015-10-30T18:59:23Z",
        "updatedAt" : "2015-10-30T18:59:23Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "50bae3a6-c8da-4040-8a84-cf228af6466a",
        "parentId" : "47c81d24-19c9-4c9f-93d8-455f1d3c572a",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "It turns out, we're logging to stderr already. This actually let me kill the liveness checks I added, since all I was doing was probing the daemon running anyways.\n",
        "createdAt" : "2015-10-30T19:00:50Z",
        "updatedAt" : "2015-10-30T19:00:50Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "12b11208-40be-4333-b724-cfa602b90145",
        "parentId" : "47c81d24-19c9-4c9f-93d8-455f1d3c572a",
        "authorId" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "body" : "+1 linking the pod lifecycle to the spark-master's, instead of to tail's\n\nin fact, i thought there was a TODO comment about that in the original pr. the only downside i could think of for linking by executing the main class was that the spark upstream folks might change the wrapper to do more setup. revving the spark version will just require some care in inspecting start-master.sh changes.\n",
        "createdAt" : "2015-11-03T00:43:34Z",
        "updatedAt" : "2015-11-03T00:43:34Z",
        "lastEditedBy" : "03b61a2c-385a-4e3a-9c84-96fa464c31a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "777d3a6ec0acfbf6a517d5b3fb62ff64d8222e15",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +22,26 @@\n/opt/spark/sbin/start-master.sh\ntail -F /opt/spark/logs/*"
  }
]