[
  {
    "id" : "92e5c22c-74b9-4964-9cb5-386bed9bf457",
    "prId" : 3028,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3028#pullrequestreview-454673475",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9eb27340-87fe-42d7-a027-f78853bdf0f6",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "The notebook is great! Some questions/comments:\r\n* Why is the output-helper necessary for displaying the output of `mlflow models serve`? I guess IPython won't display server output anywhere otherwise? For simplicity, could we instead encourage the user to run `mlflow models serve` via the CLI in a separate terminal window after they've trained their model in the notebook?\r\n* Similar to the other example, I wonder if we can actually log to a local sqlite file in order to use model registry features (as usage of SQL-backed storage and model registry is the encouraged best-practice), rather than working around it",
        "createdAt" : "2020-07-14T18:51:13Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "a7dc46f3-0d27-44a6-bd2b-3b347a8ef07d",
        "parentId" : "9eb27340-87fe-42d7-a027-f78853bdf0f6",
        "authorId" : "317cbbe8-c982-494c-a5e8-241f35a05c3d",
        "body" : "We could direct the user to run the model serve call in a separate terminal; however, I think they already get that workflow by following the CLI instructions. This just provides a more self-contained example, fully self-contained after migrating to the sqlite storage solution, since it lets us look up the artifact uri.\r\n\r\nAll examples will use sqllite in the next PR update.",
        "createdAt" : "2020-07-16T19:18:21Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "317cbbe8-c982-494c-a5e8-241f35a05c3d",
        "tags" : [
        ]
      },
      {
        "id" : "9b987f33-3ff8-4748-9641-89130329ba19",
        "parentId" : "9eb27340-87fe-42d7-a027-f78853bdf0f6",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "@drobison00 got it, I see where you're coming from re striving for a self-contained example. However, IMO it'd still be better to recommend using the CLI to serve models - in our examples, we want to encourage best practices for using RAPIDS and MLflow, and currently, the recommended & well-supported way to serve models is to invoke the `mlflow models serve` CLI via terminal, rather than attempt to run it as a subprocess and process the output via a helper thread etc. It'd also make the notebook shorter, which is always nice to have in an example :)",
        "createdAt" : "2020-07-24T07:08:47Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "13b6f3b5-d8d2-47f2-9c57-f87cd6b07d15",
        "parentId" : "9eb27340-87fe-42d7-a027-f78853bdf0f6",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Let me know if that makes sense btw, happy to discuss further!",
        "createdAt" : "2020-07-24T07:09:05Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f29c26a17a91c21d0912d82d5a8b5dd9510d4cc",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +-1,3 @@{\n \"cells\": [\n  {"
  },
  {
    "id" : "4a62e087-2716-4a68-ba02-28f0f9749efc",
    "prId" : 3028,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3028#pullrequestreview-451857726",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db147c6c-2241-4be7-9be3-df956efc8c94",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Can we run this notebook on Google Colab?",
        "createdAt" : "2020-07-17T23:57:04Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "348049c7-d9a9-4d9f-8da1-77cbec829479",
        "parentId" : "db147c6c-2241-4be7-9be3-df956efc8c94",
        "authorId" : "317cbbe8-c982-494c-a5e8-241f35a05c3d",
        "body" : "You can run in colab, and install rapids using the csp helpers (https://github.com/rapidsai/rapidsai-csp-utils); however, it does require at least a Pascal level GPU, which may not be satisfied if colab gives you a k80.",
        "createdAt" : "2020-07-20T18:31:34Z",
        "updatedAt" : "2020-08-21T00:53:45Z",
        "lastEditedBy" : "317cbbe8-c982-494c-a5e8-241f35a05c3d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f29c26a17a91c21d0912d82d5a8b5dd9510d4cc",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +0,4 @@{\n \"cells\": [\n  {\n   \"cell_type\": \"code\","
  }
]