[
  {
    "id" : "d329b253-e2e0-45e5-b677-d5b65593f8e0",
    "prId" : 8000,
    "prUrl" : "https://github.com/apache/kafka/pull/8000#pullrequestreview-356995238",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53d1df76-e28b-4e7e-9edb-bb743ec20a17",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Add a reminder in EOS example to people",
        "createdAt" : "2020-02-11T21:07:58Z",
        "updatedAt" : "2020-02-11T21:07:58Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "17b1ebb275d0bef7744a0215fc2392c4c97285cc",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +79,83 @@        // If we are using the group mode, it is recommended to have a relatively short txn timeout\n        // in order to clear pending offsets faster.\n        final int transactionTimeoutMs = this.mode.equals(\"groupMode\") ? 10000 : -1;\n        // A unique transactional.id must be provided in order to properly use EOS.\n        producer = new Producer(outputTopic, true, transactionalId, true, -1, transactionTimeoutMs, null).get();"
  },
  {
    "id" : "d9dc3c4a-ea36-4017-b2be-60957f411b19",
    "prId" : 8031,
    "prUrl" : "https://github.com/apache/kafka/pull/8031#pullrequestreview-353375315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9947a401-212e-47a9-ba43-89f602a6c8c6",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Just to refresh my memory: are we going to eventually deprecate this API, or are we going to keep both, and let users apply this one with manual assignment (like you did here)? I thought we are going to deprecate, but maybe I remembered it wrong.",
        "createdAt" : "2020-02-04T21:39:42Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "8f53f62c-fd78-4c69-8dd9-bb9425c9249c",
        "parentId" : "9947a401-212e-47a9-ba43-89f602a6c8c6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "No, we are intended to keep both",
        "createdAt" : "2020-02-04T23:27:02Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a748240c100014e86e831f614bf4219974fbd32",
    "line" : 152,
    "diffHunk" : "@@ -1,1 +150,154 @@                        producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n                    } else {\n                        producer.sendOffsetsToTransaction(positions, consumerGroupId);\n                    }\n"
  },
  {
    "id" : "c9a7c78f-a671-48f4-b41c-c902640b50b4",
    "prId" : 8031,
    "prUrl" : "https://github.com/apache/kafka/pull/8031#pullrequestreview-353374498",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35f74dcd-e3f7-4da2-b567-462074cd401d",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why we need an atomic long here? Seems there's no concurrency.",
        "createdAt" : "2020-02-04T21:41:24Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "cd1d97c2-39fd-467b-9b2a-3330ed4b8b75",
        "parentId" : "35f74dcd-e3f7-4da2-b567-462074cd401d",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "The tricky thing here is that if we define a primitive long outside of the rebalance callback, it won't compile.",
        "createdAt" : "2020-02-04T23:24:53Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a748240c100014e86e831f614bf4219974fbd32",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +163,167 @@                }\n            }\n            messageRemaining.set(messagesRemaining(consumer));\n            printWithTxnId(\"Message remaining: \" + messageRemaining);\n        }"
  },
  {
    "id" : "7219abbf-3a3c-4697-8c66-d7bbe2a0ddaa",
    "prId" : 8031,
    "prUrl" : "https://github.com/apache/kafka/pull/8031#pullrequestreview-353374765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3fb5d54b-2786-4944-b730-8299a3ac10b5",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why divide the key by two?",
        "createdAt" : "2020-02-04T21:42:21Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "67858327-c0a5-48ef-9e73-69c6d7321fd2",
        "parentId" : "3fb5d54b-2786-4944-b730-8299a3ac10b5",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "It's just a way of showing the key gets processed by message copier, all the produced message key are even keys.",
        "createdAt" : "2020-02-04T23:25:33Z",
        "updatedAt" : "2020-02-05T20:48:26Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a748240c100014e86e831f614bf4219974fbd32",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +177,181 @@    private ProducerRecord<Integer, String> transform(final ConsumerRecord<Integer, String> record) {\n        printWithTxnId(\"Transformed record (\" + record.key() + \",\" + record.value() + \")\");\n        return new ProducerRecord<>(outputTopic, record.key() / 2, \"Transformed_\" + record.value());\n    }\n"
  },
  {
    "id" : "444a310f-dac8-4950-a189-e6ca38163979",
    "prId" : 8031,
    "prUrl" : "https://github.com/apache/kafka/pull/8031#pullrequestreview-354664932",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d81a9eb1-3010-45c5-9789-6a3698aa85eb",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It's a bit unconventional to have abort logic at the start of the loop. I think what users would expect is something like this:\r\n```java\r\ntry {\r\n  producer.beginTransaction()\r\n  producer.send(...)\r\n  producer.sendOffsetsToTransaction(...)\r\n  producer.commitTransaction()\r\n} catch (Exception ) {\r\n  producer.abortTransaction()\r\n}\r\n```\r\n\r\n\r\n",
        "createdAt" : "2020-02-06T18:13:33Z",
        "updatedAt" : "2020-02-06T18:13:34Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a748240c100014e86e831f614bf4219974fbd32",
    "line" : 131,
    "diffHunk" : "@@ -1,1 +129,133 @@                    // Abort previous transaction if instructed.\n                    if (abortPreviousTransaction) {\n                        producer.abortTransaction();\n                        // The consumer fetch position also needs to be reset.\n                        resetToLastCommittedPositions(consumer);"
  },
  {
    "id" : "b3eff666-b883-43d8-bb4f-9a3ee6e22f7c",
    "prId" : 8052,
    "prUrl" : "https://github.com/apache/kafka/pull/8052#pullrequestreview-360702611",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "008b06c0-708b-40d2-ac70-0e407f64e947",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I had a question before about the \"groupMode.\" Do we need to include this in the example? I think it would be fine to let this example use the latest recommended pattern and include a comment about it.\r\n\r\nAlso, could we have a helper for the boilerplate conversion to `Map<TopicPartition, OffsetAndMetadata`>` since it clutters up the core logic?",
        "createdAt" : "2020-02-18T22:03:10Z",
        "updatedAt" : "2020-02-19T17:28:23Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1905ec71d61b8134284881f706306d1f14c122b",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +117,121 @@                    // Finish the transaction. All sent records should be visible for consumption now.\n                    producer.commitTransaction();\n                    messageProcessed += records.count();\n                }\n            } catch (ProducerFencedException e) {"
  }
]