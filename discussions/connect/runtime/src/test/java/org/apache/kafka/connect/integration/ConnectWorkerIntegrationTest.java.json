[
  {
    "id" : "76c43726-1777-4006-8a60-24196b485031",
    "prId" : 7771,
    "prUrl" : "https://github.com/apache/kafka/pull/7771#pullrequestreview-327049764",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc742392-b2f5-4598-b62c-f188ce47d212",
        "parentId" : null,
        "authorId" : "12b658fc-2aaf-48e9-ad8b-15fd33dc8321",
        "body" : "Shouldn't the workers discover that the coordinator is unavailable while it is down?\r\nI'm imagining this test going like this:\r\n\r\n1. steady-state workers are running\r\n2. brokers stop\r\n3. workers discover the coordinator is unavailable \r\n4. workers stop their tasks\r\n5. brokers start\r\n6. workers discover the next coordinator \r\n7. workers start their tasks\r\n8. workers are running unaffected",
        "createdAt" : "2019-12-04T17:26:30Z",
        "updatedAt" : "2019-12-04T18:07:06Z",
        "lastEditedBy" : "12b658fc-2aaf-48e9-ad8b-15fd33dc8321",
        "tags" : [
        ]
      },
      {
        "id" : "0e9835b6-cea8-4f81-9783-b56db77978c7",
        "parentId" : "fc742392-b2f5-4598-b62c-f188ce47d212",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "That was a bit misplaced, because I actually need 3 explicit delays (due to current lack of appropriate handles from the kafka and connect embedded clusters). \r\n1. Bring kafka down, allow workers to discover it's down (heartbeat * 2 + 4 sec)\r\n2. Allow for Kafka to come back up\r\n3. Allow for worker cluster to stabilize after the very last rebalance (delay = 5sec) \r\n\r\nAdded another commit. ",
        "createdAt" : "2019-12-04T18:12:06Z",
        "updatedAt" : "2019-12-04T18:12:06Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "a031894a59ce13839b6e5d54bf22152fc5640f88",
    "line" : 113,
    "diffHunk" : "@@ -1,1 +232,236 @@\n        // Allow for the kafka brokers to come back online\n        Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),"
  },
  {
    "id" : "df7abf61-87cf-4c8f-b2fd-cdf2ee66061f",
    "prId" : 8118,
    "prUrl" : "https://github.com/apache/kafka/pull/8118#pullrequestreview-367616883",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "36d061e9-2f65-4993-8116-7309f9405963",
        "parentId" : null,
        "authorId" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "body" : "Will the DESTROYED tasks show up in REST so that we can add an assertion to make sure they are not UNASSIGNED?",
        "createdAt" : "2020-03-02T23:02:13Z",
        "updatedAt" : "2020-05-21T20:31:11Z",
        "lastEditedBy" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "tags" : [
        ]
      },
      {
        "id" : "c59bc12f-b4a5-4921-b25a-91b4d5f526e2",
        "parentId" : "36d061e9-2f65-4993-8116-7309f9405963",
        "authorId" : "f1480a85-4082-46f9-89c6-fe7231733b83",
        "body" : "The framework doesn't actually explicitly write the `DESTROYED` state to the status backing store, it just writes a null-valued record: https://github.com/apache/kafka/blob/d3f9cb5cd37486e33cb90a6ec7eb382044ba1e51/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaStatusBackingStore.java#L285\r\n\r\nThat information is surfaced via the REST API by the lack of the presence of that task in the status info for the connector. So verifying exactly the number of tasks should also verify that the expected number of deleted tasks were removed from the status backing store.",
        "createdAt" : "2020-03-02T23:13:13Z",
        "updatedAt" : "2020-05-21T20:31:11Z",
        "lastEditedBy" : "f1480a85-4082-46f9-89c6-fe7231733b83",
        "tags" : [
        ]
      },
      {
        "id" : "eff02495-5e90-46d4-bf84-f93341297c49",
        "parentId" : "36d061e9-2f65-4993-8116-7309f9405963",
        "authorId" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "body" : "Makes sense. And I kind of figured that is likely the reason for lack of explicit assertion there.",
        "createdAt" : "2020-03-03T00:00:15Z",
        "updatedAt" : "2020-05-21T20:31:11Z",
        "lastEditedBy" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bd4bc32249c50608039b95ffe8ab338a9c2126b",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +270,274 @@        connectorProps.put(TASKS_MAX_CONFIG, String.valueOf(decreasedNumTasks));\n        connect.configureConnector(CONNECTOR_NAME, connectorProps);\n        connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME, decreasedNumTasks, \"Connector task statuses did not update in time.\");\n    }\n}"
  }
]