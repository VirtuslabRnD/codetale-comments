[
  {
    "id" : "aca21115-1e70-4b1f-9895-663ad7c09764",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-237585225",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33b9969c-d1ce-4c67-adde-133f31130179",
        "parentId" : null,
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "Did you consider having a single log message that output all of these in one message? Would that make it easier to follow what is being decided, especially if there are lots of interjected messages from currently-running connectors and tasks?",
        "createdAt" : "2019-03-25T21:53:33Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "47dab166-a133-4e9d-8d3a-bfa97bf3ec6b",
        "parentId" : "33b9969c-d1ce-4c67-adde-133f31130179",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "The sets are many. I'd still like to take a final look on what is printed before we merge. But seems not printing as soon as possible, might hide issues, even during integration tests. But I see your point. Let's get back to that. ",
        "createdAt" : "2019-04-04T00:36:45Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "e5e04e08-39d2-4a84-8fe2-ce500f181dfb",
        "parentId" : "33b9969c-d1ce-4c67-adde-133f31130179",
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "Thoughts on this now that you've been running this a while in tests and in soak?",
        "createdAt" : "2019-05-14T23:25:06Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "f7d1e3de-4634-4dfe-b54a-a428d531a71d",
        "parentId" : "33b9969c-d1ce-4c67-adde-133f31130179",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "Actually, the current form, that prints each assignment set separately has been working out nicely in the logs even with lots of connectors. What I think is key, is to use `assignments: ` suffix (or similar) in the end. This way you can grep/collect these lines all together focusing on the logger of this class as well (either via log4j or again by grepping). The fact that these assignments (every set) are printed in a separate line makes the lineage of the assignment process easy to follow. I'll review their final message but again, I'm inclined to retain a common substring and have each one in their own line. Rebalancing is happening in certain moments, so there's no significant issue with verbosity here. ",
        "createdAt" : "2019-05-15T02:35:47Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 200,
    "diffHunk" : "@@ -1,1 +198,202 @@        // difference of configured - previous\n        ConnectorsAndTasks newSubmissions = diff(configured, previousAssignment);\n        log.debug(\"New assignments: {}\", newSubmissions);\n\n        // A collection of the complete assignment"
  },
  {
    "id" : "4b873ef8-df55-4ce2-86c6-404b5ffd5b16",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-237585225",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2fb537da-a7a0-4167-8645-f86ea65a1347",
        "parentId" : null,
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "The logic of these methods is not trivial, and while ConnectAssignorTest has unit tests that exercise some of these methods, what do you think about writing unit tests for these. They really don't use state, so they would seem straightforward to test and it would help any future work by preventing regressions.",
        "createdAt" : "2019-03-26T01:06:41Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "98abeb4d-4e04-4611-b5e5-637fa4ac77e6",
        "parentId" : "2fb537da-a7a0-4167-8645-f86ea65a1347",
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "Ping",
        "createdAt" : "2019-05-02T06:11:51Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "3cf92cd6-b0f8-45c1-82e0-bcd1afb9d976",
        "parentId" : "2fb537da-a7a0-4167-8645-f86ea65a1347",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "These are now specifically tested in `IncrementalCooperativeAssignorTest` alone and as part of the tests cases for `performTaskAssignment`. Also tested in `WorkerCoordinatorIncrementalTest`",
        "createdAt" : "2019-05-15T03:06:58Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 574,
    "diffHunk" : "@@ -1,1 +572,576 @@     * @param connectors the connectors to be assigned\n     */\n    protected void assignConnectors(List<WorkerLoad> workerAssignment, Collection<String> connectors) {\n        workerAssignment.sort(WorkerLoad.connectorComparator());\n        WorkerLoad first = workerAssignment.get(0);"
  },
  {
    "id" : "01981e25-da28-4587-8def-7c483f4ddf1f",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-222511189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "444778f9-8242-43fb-8fe4-a7f5a67cfd4c",
        "parentId" : null,
        "authorId" : "f5ac54e5-ad95-49b9-b49a-3fd091e917ae",
        "body" : "Do we need an `assert` that `allMemberMetadata` is not empty?  Otherwise an NPE would result here I think",
        "createdAt" : "2019-04-03T21:01:10Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "f5ac54e5-ad95-49b9-b49a-3fd091e917ae",
        "tags" : [
        ]
      },
      {
        "id" : "5177ad5f-7ded-4193-82b7-e9b50d671713",
        "parentId" : "444778f9-8242-43fb-8fe4-a7f5a67cfd4c",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "With Api generator has become a bit harder to argue about, but both current and new code depend on members this list (`allMemberMetadata`) not being `null`. Any gaps of api generator with `final` member fields and when arrays are allowed to be set to `null` instead of an empty array should not be addressed as part of this PR IMO. \r\n\r\nI think it's safe to depend on the previous assumption, that `allMemberMetadata` can not be `null`. ",
        "createdAt" : "2019-04-15T23:02:18Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +96,100 @@        // even if some members have fallen behind. The config offset used to generate the assignment is included in\n        // the response so members that have fallen behind will not use the assignment until they have caught up.\n        long maxOffset = memberConfigs.values().stream().map(ExtendedWorkerState::offset).max(Long::compare).get();\n        log.debug(\"Max config offset root: {}, local snapshot config offsets root: {}\",\n                  maxOffset, coordinator.configSnapshot().offset());"
  },
  {
    "id" : "6a163620-efc7-4e2a-b52f-2f4287c23a9d",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-237583371",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e377f627-ea24-4d3f-9d53-77291b201f46",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Why iterator here instead of stream?",
        "createdAt" : "2019-04-16T17:32:06Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "3574e42a-b1ed-4f0b-82b3-2e5f9dfa5461",
        "parentId" : "e377f627-ea24-4d3f-9d53-77291b201f46",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "The `numToRevoke` that is used to exit the `for` loops (potentially early) is not effectively final. I could work around it, but I'm not sure the result would be more readable. ",
        "createdAt" : "2019-04-16T19:25:52Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "2d0a5b40-65fb-4cb4-a682-7bc935ef35c7",
        "parentId" : "e377f627-ea24-4d3f-9d53-77291b201f46",
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "These assign methods are pretty boilerplate, with I think just 2 lines in each that is distinct (the log line and the worker.assign call). Did you consider pulling into a method and supplying a bi-function that takes the ConnectorTaskId and the Worker?",
        "createdAt" : "2019-05-15T02:45:59Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 578,
    "diffHunk" : "@@ -1,1 +576,580 @@        WorkerLoad first = workerAssignment.get(0);\n\n        Iterator<String> load = connectors.iterator();\n        while (load.hasNext()) {\n            int firstLoad = first.connectorsSize();"
  },
  {
    "id" : "5d86110c-c7a5-414e-82ed-33b1b3a16688",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-237962594",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe6a5af0-2d9d-46b5-a434-0a5dc28dffcb",
        "parentId" : null,
        "authorId" : "f4cc0a00-0225-4972-8b58-0b97edf58337",
        "body" : "seems like copy paste? and a bunch of the utilities would be. aside from the diff to make protected, did you consider having this inherit from Eager and override the key functionality but reuse the rest (which perhaps is better structured as utilities elsewhere, but your inclination to not change the existing implementation too much seems reasonable to me at least for awhile for maintenance reasons, although even there that code hasn't changed in a long time)?",
        "createdAt" : "2019-04-25T01:54:11Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "f4cc0a00-0225-4972-8b58-0b97edf58337",
        "tags" : [
        ]
      },
      {
        "id" : "5b73562b-7109-47b1-8f69-5f6afe3d9cda",
        "parentId" : "fe6a5af0-2d9d-46b5-a434-0a5dc28dffcb",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "True. I'd like as part of this PR to apply minimal or no changes to V0 (now eager) protocol. \r\nAlso, as opposed to `ConnectProtocol` the overlap between the two assignor implementations is quite small, so I think subclassing is not worth it here. I suggest we consider a refactoring (including any helper methods in utils classes) in a subsequent iteration/cleanup. ",
        "createdAt" : "2019-05-15T17:25:18Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 113,
    "diffHunk" : "@@ -1,1 +111,115 @@    }\n\n    private Long ensureLeaderConfig(long maxOffset, WorkerCoordinator coordinator) {\n        // If this leader is behind some other members, we can't do assignment\n        if (coordinator.configSnapshot().offset() < maxOffset) {"
  },
  {
    "id" : "3f72d014-cfb7-499c-98be-3b1171377699",
    "prId" : 6363,
    "prUrl" : "https://github.com/apache/kafka/pull/6363#pullrequestreview-237585225",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a62e8543-f19c-4e0f-b062-06607516ab3f",
        "parentId" : null,
        "authorId" : "f4cc0a00-0225-4972-8b58-0b97edf58337",
        "body" : "This is getting a bit confusing -- this seems the same as `currentWorkerAssignment`. What mutates that causes this to be different?",
        "createdAt" : "2019-04-25T22:18:41Z",
        "updatedAt" : "2019-05-17T01:31:30Z",
        "lastEditedBy" : "f4cc0a00-0225-4972-8b58-0b97edf58337",
        "tags" : [
        ]
      },
      {
        "id" : "9473cadd-eea4-4a7e-a7d9-65911d6f8fa1",
        "parentId" : "a62e8543-f19c-4e0f-b062-06607516ab3f",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "It's mutated by: \r\n```\r\nassignConnectors(completeWorkerAssignment, newSubmissions.connectors());\r\nassignTasks(completeWorkerAssignment, newSubmissions.tasks());\r\n```\r\n\r\nI see your point and we might be able to consolidate. But I feel that this is higher risk low value optimization at this point. I'm more inclined to leave a comment for a future refactoring. ",
        "createdAt" : "2019-05-15T02:49:38Z",
        "updatedAt" : "2019-05-17T01:31:31Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb1853d8040f29948c1b9e54f95c0c2400d5b66e",
    "line" : 223,
    "diffHunk" : "@@ -1,1 +221,225 @@\n        // Recompute the complete assignment excluding the deleted connectors-and-tasks\n        completeWorkerAssignment = workerAssignment(memberConfigs, deleted);\n        connectorAssignments =\n                completeWorkerAssignment.stream().collect(Collectors.toMap(WorkerLoad::worker, WorkerLoad::connectors));"
  },
  {
    "id" : "463dfc18-3981-406a-97c7-3b2107f6c94d",
    "prId" : 9319,
    "prUrl" : "https://github.com/apache/kafka/pull/9319#pullrequestreview-518035580",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66db97f7-1be4-490b-9bdd-a4b5fb7b1a11",
        "parentId" : null,
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "Isn't it possible that `numToRevoke` might be negative?",
        "createdAt" : "2020-09-29T00:04:15Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "327cd971-aa6e-4b05-a597-b68b4fb8ffc1",
        "parentId" : "66db97f7-1be4-490b-9bdd-a4b5fb7b1a11",
        "authorId" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "body" : "yes it can be and it is captured under the next for loop condition.",
        "createdAt" : "2020-10-17T05:18:43Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "tags" : [
        ]
      },
      {
        "id" : "743b7411-c123-40a2-b534-7125050e2de5",
        "parentId" : "66db97f7-1be4-490b-9bdd-a4b5fb7b1a11",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "Can you explain a bit what you aim to achieve with this change here? ",
        "createdAt" : "2020-10-27T08:29:37Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "3ad58429-1a9d-4e65-861f-9682c7ed8e77",
        "parentId" : "66db97f7-1be4-490b-9bdd-a4b5fb7b1a11",
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "Also, we apply this logic in tasks only. But why not in the connectors too, if it helps?",
        "createdAt" : "2020-10-27T08:34:26Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "be0083e4-dbcb-4090-ad99-06384540fbc2",
        "parentId" : "66db97f7-1be4-490b-9bdd-a4b5fb7b1a11",
        "authorId" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "body" : "@kkonstantine  we are trying to revoke the additional tasks assigned [if any] to a worker so that in the next stage the revoked tasks can be re assigned to the new workers that get added to the group.  Yes we need to apply this to connectors as well, I will update the PR for the changes .",
        "createdAt" : "2020-10-27T18:49:29Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3f74e29a11e7746da23e6c917270644c15c1d83",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +595,599 @@        for (WorkerLoad existing : existingWorkers) {\n            Iterator<ConnectorTaskId> tasks = existing.tasks().iterator();\n            numToRevoke = existing.tasksSize() - ceilTasks;\n            log.debug(\"Tasks on worker {} is higher than ceiling, so revoking {} tasks\", existing, numToRevoke);\n            for (int i = existing.tasksSize(); i > floorTasks && numToRevoke > 0; --i, --numToRevoke) {"
  },
  {
    "id" : "5811a0b9-81bf-44e9-8104-0ddd09e7fa81",
    "prId" : 9319,
    "prUrl" : "https://github.com/apache/kafka/pull/9319#pullrequestreview-518026787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c324162-08df-4944-b804-3092324118ca",
        "parentId" : null,
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "So we balance the lost tasks among the new workers now. That balances the tasks but only among the new workers. Have you checked how this works with task revocation called right after?",
        "createdAt" : "2020-10-27T08:21:52Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "9467b0e0-92df-4c59-843c-085a95864ee5",
        "parentId" : "9c324162-08df-4944-b804-3092324118ca",
        "authorId" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "body" : "It not only balances the tasks for new workers it also does revocation if there is any overloaded worker. ",
        "createdAt" : "2020-10-27T18:38:12Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3f74e29a11e7746da23e6c917270644c15c1d83",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +456,460 @@                Iterator<WorkerLoad> candidateWorkerIterator = candidateWorkerLoad.iterator();\n                for (String connector : lostAssignments.connectors()) {\n                    // Loop over the the candidate workers as many times as it takes\n                    if (!candidateWorkerIterator.hasNext()) {\n                        candidateWorkerIterator = candidateWorkerLoad.iterator();"
  },
  {
    "id" : "56008b01-7c0f-431d-ae96-95a66368e2a5",
    "prId" : 9319,
    "prUrl" : "https://github.com/apache/kafka/pull/9319#pullrequestreview-581018012",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0afdacdc-7a02-4e3c-8207-fe4622dcbeb6",
        "parentId" : null,
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "we should remove the `if` branch on the `numToRevoke` here too, right?",
        "createdAt" : "2021-02-02T06:13:55Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      },
      {
        "id" : "c2af0ea5-ec79-4bac-9aa2-493ecb6ad3d3",
        "parentId" : "0afdacdc-7a02-4e3c-8207-fe4622dcbeb6",
        "authorId" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "body" : "removed the if block , thanks for pointing out. ",
        "createdAt" : "2021-02-02T06:25:11Z",
        "updatedAt" : "2021-02-02T06:26:52Z",
        "lastEditedBy" : "421d85ec-b84b-4195-b16c-eaf0aed0444f",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3f74e29a11e7746da23e6c917270644c15c1d83",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +584,588 @@        for (WorkerLoad existing : existingWorkers) {\n            Iterator<String> connectors = existing.connectors().iterator();\n            numToRevoke = existing.connectorsSize() - ceilConnectors;\n            for (int i = existing.connectorsSize(); i > floorConnectors && numToRevoke > 0; --i, --numToRevoke) {\n                ConnectorsAndTasks resources = revoking.computeIfAbsent("
  }
]