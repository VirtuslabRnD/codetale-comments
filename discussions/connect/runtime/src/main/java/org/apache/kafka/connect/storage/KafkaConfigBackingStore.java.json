[
  {
    "id" : "bbaa3c96-218e-488c-bfdd-942616347bfa",
    "prId" : 5425,
    "prUrl" : "https://github.com/apache/kafka/pull/5425#pullrequestreview-141125953",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19723e7c-d1f1-48c7-a70d-9a781be1895b",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "@rhauch do we need to update Connect documentation?",
        "createdAt" : "2018-07-27T14:24:53Z",
        "updatedAt" : "2018-08-01T00:34:42Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "eae84c1396d2828a0a2a4aa9fb571d5f7d39a652",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +416,420 @@        producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n        producerProps.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, Integer.MAX_VALUE);\n        Map<String, Object> consumerProps = new HashMap<>(originals);\n        consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());"
  },
  {
    "id" : "57a30157-7441-4912-93d8-b116fe8a440d",
    "prId" : 5868,
    "prUrl" : "https://github.com/apache/kafka/pull/5868#pullrequestreview-172739462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5db2ff2-c509-4c8f-90cf-2a08f8dc8552",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I wonder if it would be worth wrapping the config in another object with a custom `toString` so that we are not tempted to reintroduce this bug in the future.",
        "createdAt" : "2018-11-07T19:25:32Z",
        "updatedAt" : "2018-11-13T17:41:11Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "58f8bec8-e952-4d3e-8a6f-f614625e5620",
        "parentId" : "f5db2ff2-c509-4c8f-90cf-2a08f8dc8552",
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "Yeah, it would be possible to do that, and that object would have to:\r\n1. Look in the configuration for the `connector.class` property\r\n2. Use the plugins mechanism to load the specified connector class\r\n3. Get the ConfigDef from the connector instance\r\n4. Create a `ConnectorConfig` instance using the ConfigDef\r\n5. Use the `ConnectorConfig.toString()` method to mask any PASSWORD fields.\r\n\r\nThe problem is that some connectors may include secrets in configs that are not of type PASSWORD, and this approach would still not mask those secrets. For example, JDBC URLs can contain the username and password, but it's not likely that any connector that has a JDBC URL as a config treats this as a PASSWORD field.",
        "createdAt" : "2018-11-07T19:34:49Z",
        "updatedAt" : "2018-11-13T17:41:11Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "a50b225d-fcb6-45ff-ad2a-8620b7355cf2",
        "parentId" : "f5db2ff2-c509-4c8f-90cf-2a08f8dc8552",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Yeah, I was thinking something simpler. Like having an `UnvalidatedConnectorConfig` which just wrapped the map we have here. We could override `toString` and document the potential sensitivity of the configs. Anyway, up to you if you think it would be helpful or not.",
        "createdAt" : "2018-11-07T22:15:43Z",
        "updatedAt" : "2018-11-13T17:41:11Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "32829250-298f-470e-b1f3-151c6a306eba",
        "parentId" : "f5db2ff2-c509-4c8f-90cf-2a08f8dc8552",
        "authorId" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "body" : "I'm not sure it adds much value. I'm not sure we can print any of the connector configuration properties if we don't know which connector-specific properties are sensitive.",
        "createdAt" : "2018-11-07T22:36:42Z",
        "updatedAt" : "2018-11-13T17:41:11Z",
        "lastEditedBy" : "145db0de-7396-4643-9a2c-9977e1c6219b",
        "tags" : [
        ]
      },
      {
        "id" : "28cb9fe1-27f4-407d-97aa-ada2a3b31f45",
        "parentId" : "f5db2ff2-c509-4c8f-90cf-2a08f8dc8552",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Fair enough.",
        "createdAt" : "2018-11-07T22:56:08Z",
        "updatedAt" : "2018-11-13T17:41:11Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "534d523b36b595857124f06cdd1d288ab3aeeab8",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +296,300 @@     */\n    @Override\n    public void putConnectorConfig(String connector, Map<String, String> properties) {\n        log.debug(\"Writing connector configuration for connector '{}'\", connector);\n        Struct connectConfig = new Struct(CONNECTOR_CONFIGURATION_V0);"
  },
  {
    "id" : "7c95d4f5-1f9e-46a9-8ce0-afda50e610da",
    "prId" : 8444,
    "prUrl" : "https://github.com/apache/kafka/pull/8444#pullrequestreview-390327457",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ecf843c-009c-46c5-82e6-0a2fe1082bc0",
        "parentId" : null,
        "authorId" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "body" : "Do you think it is worth also updating `connectorTaskCounts` to keep these in sync?",
        "createdAt" : "2020-04-08T08:19:53Z",
        "updatedAt" : "2020-04-08T20:59:13Z",
        "lastEditedBy" : "4873aa72-3842-44ba-91a8-a59ea9830460",
        "tags" : [
        ]
      },
      {
        "id" : "6e8b45ef-f66f-4db0-981f-78a9bda6074f",
        "parentId" : "3ecf843c-009c-46c5-82e6-0a2fe1082bc0",
        "authorId" : "f1480a85-4082-46f9-89c6-fe7231733b83",
        "body" : "No kidding! Good catch. I've added logic in this class to do that, and expanded the test to verify this logic.",
        "createdAt" : "2020-04-08T20:59:13Z",
        "updatedAt" : "2020-04-08T20:59:13Z",
        "lastEditedBy" : "f1480a85-4082-46f9-89c6-fe7231733b83",
        "tags" : [
        ]
      }
    ],
    "commit" : "8225b29541689adfd465c92649228786831d655d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +550,554 @@                        connectorConfigs.remove(connectorName);\n                        connectorTaskCounts.remove(connectorName);\n                        taskConfigs.keySet().removeIf(taskId -> taskId.connector().equals(connectorName));\n                        removed = true;\n                    } else {"
  },
  {
    "id" : "f25b6db7-6ee5-4902-979f-952e2fbd692e",
    "prId" : 8828,
    "prUrl" : "https://github.com/apache/kafka/pull/8828#pullrequestreview-425865699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e49b23fc-2538-4ef0-85e4-ec38a8e87798",
        "parentId" : null,
        "authorId" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "body" : "Vararg gives some unintended consequences in naming. Should we stick to singular given that we expect at most a single topic to be created?",
        "createdAt" : "2020-06-08T01:14:28Z",
        "updatedAt" : "2020-06-11T03:38:21Z",
        "lastEditedBy" : "e77724e7-3db9-47d6-b4d8-a865b1d06edc",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef4c994e57a321ccd562d31ad5fb32ff813e9fb9",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +495,499 @@                try (TopicAdmin admin = new TopicAdmin(adminProps)) {\n                    // Create the topic if it doesn't exist\n                    Set<String> newTopics = admin.createTopics(topicDescription);\n                    if (!newTopics.contains(topic)) {\n                        // It already existed, so check that the topic cleanup policy is compact only and not delete"
  }
]