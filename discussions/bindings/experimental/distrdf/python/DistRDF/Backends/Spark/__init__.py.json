[
  {
    "id" : "66835f4f-54b2-4cca-bd9d-1ad138acf98b",
    "prId" : 7139,
    "prUrl" : "https://github.com/root-project/root/pull/7139#pullrequestreview-585538100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be395e15-a819-4ceb-b7cd-a40703eb1082",
        "parentId" : null,
        "authorId" : "4c541c6e-f658-422b-9f5a-7ae0b2a9a1f5",
        "body" : "Here there are several possibilities:\r\n1. We leave the `RDataFrame` factory function here, and we make this module (`Spark`) inject itself in `ROOT.RDF.Distributed`.\r\n2. We create a new module `ROOT.RDF.Distributed.Spark` that we inject in `ROOT.RDF.Distributed`, plus we inject the `RDataFrame` function in this new module.\r\n\r\nThe advantage of 1 is simplicity, but the module would inherit the name it has in `DistRDF`, thus making that detail visible to the user.",
        "createdAt" : "2021-02-08T14:13:07Z",
        "updatedAt" : "2021-02-17T11:18:35Z",
        "lastEditedBy" : "4c541c6e-f658-422b-9f5a-7ae0b2a9a1f5",
        "tags" : [
        ]
      }
    ],
    "commit" : "6b42fc3cd075722522c7c71de9abcda1fb9c8a10",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +11,15 @@################################################################################\n\ndef RDataFrame(*args, **kwargs):\n    \"\"\"\n    Create an RDataFrame object that can run computations on a Spark cluster."
  }
]