[
  {
    "id" : "7c301d33-fba7-412f-ab95-c1f14b9f7750",
    "prId" : 2422,
    "prUrl" : "https://github.com/akka/alpakka/pull/2422#pullrequestreview-493581412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bacb01b1-eac5-4ad9-849a-9d0c2e4b07b5",
        "parentId" : null,
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "Should this method be deprecated like its javadsl counterpart?",
        "createdAt" : "2020-09-22T14:26:12Z",
        "updatedAt" : "2020-09-22T15:23:42Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "7deadcb1-9d99-47fc-8fb9-2ca8de5190a1",
        "parentId" : "bacb01b1-eac5-4ad9-849a-9d0c2e4b07b5",
        "authorId" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "body" : "That was in the non-gRPC version.",
        "createdAt" : "2020-09-22T15:22:35Z",
        "updatedAt" : "2020-09-22T15:23:42Z",
        "lastEditedBy" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "tags" : [
        ]
      }
    ],
    "commit" : "da725e8a39b3fefbaa9105d6baecfd927051b033",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +118,122 @@   * @param parallelism controls how many acknowledgements can be in-flight at any given time\n   */\n  def acknowledge(parallelism: Int): Sink[AcknowledgeRequest, Future[Done]] = {\n    Sink\n      .setup { (mat, attr) =>"
  },
  {
    "id" : "0d0408db-2ea6-45c3-9b0f-9d531d52c279",
    "prId" : 2422,
    "prUrl" : "https://github.com/akka/alpakka/pull/2422#pullrequestreview-493576484",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1821159-1c19-42bc-a4af-334e734a28d7",
        "parentId" : null,
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "Maybe there's an opportunity here to compose all the acknowledge sink/flow and java/scala DSL methods from this to DRY up the impls. It could be refactored into a private method that takes `parallelism` to support the deprecated overloads.",
        "createdAt" : "2020-09-22T14:28:37Z",
        "updatedAt" : "2020-09-22T15:23:42Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "9fa7d320-e7d7-40b2-bdc1-7705a2ba00cb",
        "parentId" : "f1821159-1c19-42bc-a4af-334e734a28d7",
        "authorId" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "body" : "The gRPC generated types are different for the Java DSL and the Scala DSL. That's not easy to see.",
        "createdAt" : "2020-09-22T15:17:46Z",
        "updatedAt" : "2020-09-22T15:23:42Z",
        "lastEditedBy" : "9500ec63-4ee5-4a4b-820c-121a3523fbda",
        "tags" : [
        ]
      }
    ],
    "commit" : "da725e8a39b3fefbaa9105d6baecfd927051b033",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +109,113 @@          )\n      }\n      .mapMaterializedValue(_ => NotUsed)\n\n  /**"
  },
  {
    "id" : "17568a3e-5adb-42c2-a1d3-c55620ea3454",
    "prId" : 2166,
    "prUrl" : "https://github.com/akka/alpakka/pull/2166#pullrequestreview-368688271",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d88a2b6-6879-4559-b538-337602bff608",
        "parentId" : null,
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "It seems that this is the only reason this would be \"blocking\" (process one request/response at a time). Could this value be greater than 1?  Maybe this could be a user parameter as well.",
        "createdAt" : "2020-02-24T21:39:04Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "5412e9fa-e4fe-4f99-901a-87e1be749207",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "Hmm, in case the interval between pulls is less than the amount of time it takes to receive the messages (which is unlikely I would say), this can be blocking yes.\r\n\r\nJust to be sure and flexible we can make this a user parameter with a default of 1.",
        "createdAt" : "2020-02-25T10:53:37Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      },
      {
        "id" : "d97838e9-e25f-4c91-9647-d063fff78361",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "f671ad62-946e-4691-83e4-79ee05b8b109",
        "body" : "Couldn't you just increase the number of `max_messages` instead? And maybe add a `buffer(1)` afterwards so you always already fetch the next batch while the previous batch is still processed by the `mapConcat`.",
        "createdAt" : "2020-02-25T11:11:47Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "f671ad62-946e-4691-83e4-79ee05b8b109",
        "tags" : [
        ]
      },
      {
        "id" : "a21721a7-37d9-48af-9060-c025e5e4fb9a",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "@jrudolph right, I'm not sure if there is any case that parallelism would help. If you need more messages, increase maxMessages, if you need more time between messages, increase interval, etc.\r\n\r\nDo you think I should revert this last piece then?",
        "createdAt" : "2020-02-25T12:24:26Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      },
      {
        "id" : "051ebd9d-a9d9-447c-a861-3a6e053427e6",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "Yes, I think @jrudolph's idea is better :).  Do you want to revert the parallelism param and implement that instead?",
        "createdAt" : "2020-02-28T14:24:46Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "9f7f53b2-f5c2-4b6c-b51f-3767256a52b3",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "@seglo @jrudolph  Now that I think about it, if we have a `buffer(1)`, and someone sets an interval to N, and their ack deadline is N or close to N, then they will continuously miss their ack deadlines because the buffered message is passing its lifetime in the buffer.\r\n\r\nPubSub is tricky because of the ack deadline, so holding onto messages is not free, it can be costly and problematic, that's why if we want to have a buffer, I think it must be configurable and not a constant. One might not want to buffer anything to avoid a message's ack deadline being passed by.\r\n\r\nThis might be an edge case but still I think it's worth avoiding it. cc",
        "createdAt" : "2020-03-02T12:24:36Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      },
      {
        "id" : "3c0d7701-078c-4c5e-b79e-91992af3169a",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "Can't users just add a buffer on top of the source themselves? Wouldn't that work? :thinking: \r\n\r\n```\r\nGooglePubSub.subscribe(request, 100.millis).buffer(10)\r\n```",
        "createdAt" : "2020-03-02T12:25:36Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      },
      {
        "id" : "8e812228-ef57-4cd2-b71c-8e72b6c705d0",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "> someone sets an interval to N, and their ack deadline is N or close to N, then they will continuously miss their ack deadlines because the buffered message is passing its lifetime in the buffer.\r\n\r\nWouldn't that be the case regardless of the buffer?\r\n\r\nAs long as there's demand downstream then elements will continue to move through the buffer to downstream stages.",
        "createdAt" : "2020-03-02T22:09:04Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "06e5c11c-ff2f-441e-b97e-32263518f279",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "To explain the difference I see in the case of a buffer and the case without the buffer better, consider this example:\r\n\r\nI want to pull messages in intervals of N seconds and processing time for a batch is is P. Imagine there is no parallelism in my stream, I can only process one item at a time.\r\n\r\n_When I use the word \"lifetime\" I mean the message has been received from PubSub, so there is a \"lease\" on it, and unless it is acknowledged in time it will be retried._\r\n\r\nIn the case without buffer, this is what the timeline looks like:\r\nFirst batch comes at T = 0, it takes P seconds to process it.\r\nSecond batch comes at T = N, it takes P seconds to process it. If P > N, then batch 2 will not be processed for P - N seconds because it's waiting for the first batch to be processed. So it will spend P - N of its lifetime waiting to be processed. As new batches come in continuously this time can grow if there is no backpressure, but if backpressure works correctly at some point we should skip a few intervals to make sure we can process more.\r\n\r\nIn case of with buffer:\r\nFirst batch comes at T = 0 it takes P seconds to process it.\r\nSecond batch comes at T = 0 (almost, there is a small latency of receiving the first batch) and is saved in buffer. This batch will start being processed at T = P. That means this batch will be waiting and spending its \"lifetime\" of P seconds before being processed.\r\nThird batch comes at T = N. It will be processed at 2P, it will spend 2P - N of its lifetime waiting to be processed.\r\n\r\nIn this case P > (P - N) and (2P - N) > (P - N), so it's more likely for the case with buffer to have messages exceeding their deadline.\r\n\r\nThis is an edge case but it's possible anyhow and given our experience with buffers causing issues with acknowledge deadlines, I would prefer to have the ability to manage buffers myself to avoid surprises.",
        "createdAt" : "2020-03-03T11:59:41Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      },
      {
        "id" : "e8960538-62d2-4418-aaa2-655f98ed9c55",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "body" : "Got it. Thanks for the excellent analysis to describe the problem! I agree, let the buffer be a user concern. If you're willing you may want to add a small section to the docs describing the consequences of buffering.",
        "createdAt" : "2020-03-03T16:24:51Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "daac5cb5-ce57-4037-a06c-7adf6a3f10e6",
        "tags" : [
        ]
      },
      {
        "id" : "c7e72728-d0ab-4349-b337-3c9709a730f9",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "f671ad62-946e-4691-83e4-79ee05b8b109",
        "body" : "That's the usual trade-off. \r\n\r\nOn one hand, you want some buffer to hide some latency in the critical path.\r\n`max_messages` is already such a kind of buffer that amortizes the pull latency to the pubsub over `max_messages` (one pull per `max_messages`). But that still leaves you with that one pull latency. If you add another buffer on top that you even hide that remaining latency. I.e. for `n` messages\r\n\r\n * without any buffer and `max_messages = 1` you have `n * pull latency` (O(n) high constant factor)\r\n * with `max_messages`, you have `n / max_messages * pull latency` (O(n) with low constant factor, or practically ~ O(1) if `max_messages` is high enough)\r\n * with the extra buffer, you only have the very first initial latency, `pull_latency` (O(1))\r\n\r\nOn the other hand, you want to have buffers as small as possible because as you say you want to minimize the time spent uselessly in buffers.\r\n\r\nIt's a bit harder for users to add that buffer because it will be after `mapConcat` so the size of the buffer must be manually adopted to scale with `max_messages` you chose.",
        "createdAt" : "2020-03-04T10:57:17Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "f671ad62-946e-4691-83e4-79ee05b8b109",
        "tags" : [
        ]
      },
      {
        "id" : "5571d673-4c5e-43a7-9f00-fb70b44d5a0b",
        "parentId" : "3d88a2b6-6879-4559-b538-337602bff608",
        "authorId" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "body" : "@jrudolph That's right, do you think by documenting this we will be able to help users decide whether they need a buffer or not, and if they do, how to add it? (i.e. set the buffer size to be the same as max_messages if you usually receive max messages and not less).",
        "createdAt" : "2020-03-04T11:06:27Z",
        "updatedAt" : "2020-03-19T15:45:16Z",
        "lastEditedBy" : "8f3c287f-b393-498d-81ba-28694eee6023",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a727a7c1f7aba159aec120a201bf4a9df22369e",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +89,93 @@          .tick(0.seconds, pollInterval, request)\n          .mapMaterializedValue(cancellable.success)\n          .mapAsync(1)(client.pull(_))\n          .mapConcat(_.receivedMessages.toVector)\n          .mapMaterializedValue(_ => cancellable.future)"
  }
]