[
  {
    "id" : "119bec84-4c1b-40ca-8995-88a5ffb1ebfc",
    "prId" : 4464,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4464#pullrequestreview-684971766",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3aacb36-a185-4245-9000-6af99b064dee",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "This script doesn't have to run tests under `tests/spark_autologging/ml` since `dev/run-python-flavor-tests.sh` runs them.",
        "createdAt" : "2021-06-16T10:02:08Z",
        "updatedAt" : "2021-06-16T10:02:08Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "a366208da3d3dd732e8172ef6d13d4d8495f5b98",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +22,26 @@\nexport SPARK_HOME=$TEMPDIR/spark-3.0.0-preview-bin-hadoop2.7\nfind tests/spark_autologging/datasource -name 'test*.py' | xargs -L 1 pytest --large\n\nrm -rf $TEMPDIR"
  },
  {
    "id" : "6abd40a1-9da0-4a7a-9661-d73b0d3cb0bd",
    "prId" : 3265,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3265#pullrequestreview-466418203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "109b36b4-8b5f-420b-8f97-a195b06d33aa",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "\r\nhttps://www.gnu.org/software/wget/manual/wget.html\r\n\r\n```\r\n‘--no-verbose’\r\nTurn off verbose without being completely quiet (use ‘-q’ for that),\r\nwhich means that error messages and basic information still get printed.\r\n```",
        "createdAt" : "2020-08-13T03:22:01Z",
        "updatedAt" : "2020-08-13T03:22:01Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe42ea4aa8d5989c198287f995d3c2640283f92a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +16,20 @@TEMPDIR=$(mktemp -d)\npushd $TEMPDIR\nwget --no-verbose https://archive.apache.org/dist/spark/spark-3.0.0-preview/spark-3.0.0-preview-bin-hadoop2.7.tgz -O /tmp/spark.tgz\ntar -xf /tmp/spark.tgz\npip install -e spark-3.0.0-preview-bin-hadoop2.7/python"
  }
]