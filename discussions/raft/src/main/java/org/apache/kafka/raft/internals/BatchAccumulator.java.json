[
  {
    "id" : "f033b806-4152-42b4-81ca-fcd92fb49e6c",
    "prId" : 9418,
    "prUrl" : "https://github.com/apache/kafka/pull/9418#pullrequestreview-514207123",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ee63066-8d05-4ba3-b423-b1ab6446e5bc",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.",
        "createdAt" : "2020-10-21T00:49:26Z",
        "updatedAt" : "2020-10-27T03:04:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "8ecec46a-4194-4608-a693-6888638fd93a",
        "parentId" : "6ee63066-8d05-4ba3-b423-b1ab6446e5bc",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I am not sure. We don't have a metric yet, so I thought we might as well start with a thread-safe implementation. If we add a metric in the future, we can probably use an `AtomicInteger` or something and eliminate the locking.",
        "createdAt" : "2020-10-21T21:40:59Z",
        "updatedAt" : "2020-10-27T03:04:10Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fac5c0a9507f9f40f99dac017242d12500a97d5d",
    "line" : 278,
    "diffHunk" : "@@ -1,1 +276,280 @@     * written to (if it exists).\n     */\n    public int count() {\n        appendLock.lock();\n        try {"
  },
  {
    "id" : "67005db1-7f46-421d-9921-ce107ae9c1f4",
    "prId" : 9418,
    "prUrl" : "https://github.com/apache/kafka/pull/9418#pullrequestreview-516114788",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a73e9441-1f87-4400-8270-58d9de304ae9",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "What are you trying to protect with this check? For example, the signature could be `public long append(List<T> records)` with the accumulator writing the correct epoch.\r\n\r\nIn https://github.com/apache/kafka/pull/9482 you implemented `handleClaim` in to only fire when the `Listener`'s \"acknowledged\" offset + 1 is >= to the leader's epoch start offset.\r\n\r\nThinking through the code's behaviour, I see this check catching the case the the raft replica lost leadership and won leadership before the `Listener` was able to asynchronously process `handleResign` and `handleClaim`.",
        "createdAt" : "2020-10-23T19:22:25Z",
        "updatedAt" : "2020-10-27T03:04:10Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "98a9ec7f-5c41-49e1-831d-f71a0222bc06",
        "parentId" : "a73e9441-1f87-4400-8270-58d9de304ae9",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Right. It is important to ensure that the state machine has observed the latest leader epoch. Otherwise there may be committed data inflight which the state machine has yet to see.",
        "createdAt" : "2020-10-23T23:50:34Z",
        "updatedAt" : "2020-10-27T03:04:10Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "fac5c0a9507f9f40f99dac017242d12500a97d5d",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +97,101 @@            // has not gotten the notification about the latest epoch change.\n            // In this case, ignore the append and return a large offset value\n            // which will never be committed.\n            return Long.MAX_VALUE;\n        }"
  },
  {
    "id" : "1d2039ae-a156-4aa9-96e7-0d82f1f912c8",
    "prId" : 9716,
    "prUrl" : "https://github.com/apache/kafka/pull/9716#pullrequestreview-547827063",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86b58d0c-e5b7-4131-9b1b-dc46cf369d63",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice one.",
        "createdAt" : "2020-12-09T04:30:09Z",
        "updatedAt" : "2020-12-09T18:25:35Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "306c956f53dce5b98acbf881b90216385878b57e",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +275,279 @@    public boolean isEmpty() {\n        // The linger timer begins running when we have pending batches.\n        // We use this to infer when the accumulator is empty to avoid the\n        // need to acquire the append lock.\n        return !lingerTimer.isRunning();"
  },
  {
    "id" : "e13fda66-1483-4d59-8048-ac9d69539adf",
    "prId" : 9716,
    "prUrl" : "https://github.com/apache/kafka/pull/9716#pullrequestreview-547827063",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa034a10-7729-403e-ae30-e25734707b57",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Does the javadoc above need updates?",
        "createdAt" : "2020-12-09T04:36:49Z",
        "updatedAt" : "2020-12-09T18:25:35Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "306c956f53dce5b98acbf881b90216385878b57e",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +284,288 @@     * This does not include the batch that is currently being filled.\n     */\n    public int numCompletedBatches() {\n        return completed.size();\n    }"
  },
  {
    "id" : "4ee22b97-341b-4ba1-a78b-24d2bf533633",
    "prId" : 9739,
    "prUrl" : "https://github.com/apache/kafka/pull/9739#pullrequestreview-572966273",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7ea4309-1285-4a0a-879b-990ba03acf18",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Good catch. Do we have any test cases in `BatchAccumulatorTest` which can be modified to catch this case?",
        "createdAt" : "2021-01-20T00:57:12Z",
        "updatedAt" : "2021-02-01T15:22:53Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "54e0e0d8-65dd-459d-935e-305a1cff4e83",
        "parentId" : "b7ea4309-1285-4a0a-879b-990ba03acf18",
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "Let me check",
        "createdAt" : "2021-01-21T03:59:18Z",
        "updatedAt" : "2021-02-01T15:22:53Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      }
    ],
    "commit" : "89afaf3d8f72af4b5770bef9ae27989ad1a29860",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +180,184 @@                time.milliseconds(),\n                false,\n                epoch,\n                maxBatchSize\n            );"
  },
  {
    "id" : "7e189774-5dfe-4e57-8b0e-f9738a06be72",
    "prId" : 10063,
    "prUrl" : "https://github.com/apache/kafka/pull/10063#pullrequestreview-590723257",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b615af0a-bf75-40cf-994e-1da8264f510e",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Since these two `append` methods are mostly identical, can we use a single private method with `isAtomic` as an argument? Otherwise seems we will need to update both methods in most cases as we add features and fix bugs.",
        "createdAt" : "2021-02-09T14:59:13Z",
        "updatedAt" : "2021-02-19T02:45:44Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "4754b4d3-f18f-4afd-9afe-7e6dcd8ddcba",
        "parentId" : "b615af0a-bf75-40cf-994e-1da8264f510e",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yeah. I thought about doing this but I felt that the implementation was very subtle and hard to read. I use this strategy for `private Long append(int epoch, List<T> records, boolean isAtomic)` in `KafkaRaftClient` since the difference is obvious.\r\n\r\nIn the `BatchAccumulator` for the \"atomic\" version we need to calculate the total size and allocate a buffer/batch if needed that fits that total size. For the non-atomic version we need to allocate a buffer/batch for every record if it doesn't fit the current batch.\r\n\r\nI'll create a commit for this so you can see the two side by side.",
        "createdAt" : "2021-02-10T21:04:19Z",
        "updatedAt" : "2021-02-19T02:45:44Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "82f69d3b-a85e-4151-9b48-1cbf16dcb340",
        "parentId" : "b615af0a-bf75-40cf-994e-1da8264f510e",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "@mumrah This one way to merge these two methods. Let me know which one you prefer.\r\n\r\nhttps://gist.github.com/jsancio/06bdffc9f25450127b1dc730ebbd55f7",
        "createdAt" : "2021-02-11T02:19:21Z",
        "updatedAt" : "2021-02-19T02:45:44Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "bd695666-b8fa-4dac-a03c-b4f699a06be0",
        "parentId" : "b615af0a-bf75-40cf-994e-1da8264f510e",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "The gist looks pretty reasonable üëç ",
        "createdAt" : "2021-02-11T16:03:20Z",
        "updatedAt" : "2021-02-19T02:45:44Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "b528b5d9-8701-47e4-b276-71a2655fd3c6",
        "parentId" : "b615af0a-bf75-40cf-994e-1da8264f510e",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Done. Implemented the Gist.",
        "createdAt" : "2021-02-15T19:49:15Z",
        "updatedAt" : "2021-02-19T02:45:44Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "83501090957a4f1d861a1d8de25882273095168e",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +99,103 @@     *         been committed\n     */\n    public Long append(int epoch, List<T> records) {\n        return append(epoch, records, false);\n    }"
  },
  {
    "id" : "77a49738-d200-44c1-9ca0-1257992c8d83",
    "prId" : 10480,
    "prUrl" : "https://github.com/apache/kafka/pull/10480#pullrequestreview-645182934",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "36df67a0-0dd4-4e8b-b719-70bcd9a70539",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "It would be useful to factor out a `flush()` API. We may have additional use cases in the future.\r\n```java\r\n    public void flush() {\r\n        appendLock.lock();\r\n        try {\r\n            drainStatus = DrainStatus.STARTED;\r\n            maybeCompleteDrain();\r\n        } finally {\r\n            appendLock.unlock();\r\n        }\r\n    }\r\n```",
        "createdAt" : "2021-04-09T00:39:54Z",
        "updatedAt" : "2021-04-28T19:54:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "58ece905-70f3-48e6-85d5-4a39111abf26",
        "parentId" : "36df67a0-0dd4-4e8b-b719-70bcd9a70539",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Okay. This is an internal API so I say we add this when needed. If we still want to refactor then, this is similar to `maybeCompleteDrain` but it cannot assume that the lock is held. How about naming this method `completeDrain`?",
        "createdAt" : "2021-04-12T21:12:40Z",
        "updatedAt" : "2021-04-28T19:54:04Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "bc4c9b2e-b7f3-4b49-9094-12ca18e81d2f",
        "parentId" : "36df67a0-0dd4-4e8b-b719-70bcd9a70539",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "How about `forceDrain`?",
        "createdAt" : "2021-04-26T23:07:14Z",
        "updatedAt" : "2021-04-28T19:54:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "d043ff6bcf43648ef34031594a8620e64761618a",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +237,241 @@        appendLock.lock();\n        try {\n            drainStatus = DrainStatus.STARTED;\n            maybeCompleteDrain();\n        } finally {"
  },
  {
    "id" : "b3517886-75c6-491d-90cb-204848b17f92",
    "prId" : 10480,
    "prUrl" : "https://github.com/apache/kafka/pull/10480#pullrequestreview-633748999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0383853c-0efd-42f4-9602-d7c248f4cdc4",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "This method is not safe. I think you need to hold a lock before falling `maybeCompleteDrain` and updating `nextOffset`.",
        "createdAt" : "2021-04-12T16:35:51Z",
        "updatedAt" : "2021-04-28T19:54:04Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "d043ff6bcf43648ef34031594a8620e64761618a",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +205,209 @@    }\n\n    public void appendLeaderChangeMessage(LeaderChangeMessage leaderChangeMessage, long currentTimeMs) {\n        appendLock.lock();\n        try {"
  },
  {
    "id" : "870f35c1-fe07-49b6-a767-e6d6dc8d73bf",
    "prId" : 10480,
    "prUrl" : "https://github.com/apache/kafka/pull/10480#pullrequestreview-645175062",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f79efaee-18cd-45d3-9106-fb1b7d5718b8",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "How about in the `else` case? Probably we need to raise an exception?",
        "createdAt" : "2021-04-26T22:49:00Z",
        "updatedAt" : "2021-04-28T19:54:04Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "d043ff6bcf43648ef34031594a8620e64761618a",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +210,214 @@            forceDrain();\n            ByteBuffer buffer = memoryPool.tryAllocate(256);\n            if (buffer != null) {\n                MemoryRecords data = MemoryRecords.withLeaderChangeMessage(\n                    this.nextOffset, "
  },
  {
    "id" : "be3a4f1c-e6fa-406d-81b6-7468cbb75213",
    "prId" : 10899,
    "prUrl" : "https://github.com/apache/kafka/pull/10899#pullrequestreview-688613555",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb91823c-f3a3-4644-90b4-ff8122716f71",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "There is code duplication between these 3 methods. Let's figure out a way to remove this duplicate code.",
        "createdAt" : "2021-06-18T23:00:00Z",
        "updatedAt" : "2021-06-18T23:12:38Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "3992b138-924f-452c-8a5b-42ee932eefb7",
        "parentId" : "eb91823c-f3a3-4644-90b4-ff8122716f71",
        "authorId" : "a4dbaf80-7a7c-4314-af6e-b4cf858a6ce2",
        "body" : "I agree. Let me fix that.",
        "createdAt" : "2021-06-21T15:59:25Z",
        "updatedAt" : "2021-06-21T15:59:25Z",
        "lastEditedBy" : "a4dbaf80-7a7c-4314-af6e-b4cf858a6ce2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a924cbd5919c5a7faf3f57cfc5d054575305e10",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +302,306 @@            );\n        });\n    }\n\n    public void forceDrain() {"
  },
  {
    "id" : "a1eee24a-8002-4e7e-8418-063c8cc6aec6",
    "prId" : 10909,
    "prUrl" : "https://github.com/apache/kafka/pull/10909#pullrequestreview-719641372",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "faa1e91e-ee6d-4770-93d9-5ab34a8f28e4",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "@dengziming @hachikuji What do you both think about making this consistent with `RaftClient::resign`? `RaftClient::resign` throws `IllegalArgumentException` when the passed epoch is greater than the current epoch. With this change `KafkaRaftClient::schedule*Append` throws `NotLeaderException` when the passed epoch is greater than the current epoch.\r\n\r\nMaybe something like:\r\n```\r\nif (epoch > this.epoch) {\r\n    throw new IllegalArgumentExcpetion(\"...\");\r\n} else if (epoch < this.epoch) {\r\n    throw new NotLeaderException(\"...\");\r\n}\r\n```",
        "createdAt" : "2021-07-31T17:39:23Z",
        "updatedAt" : "2021-07-31T17:41:33Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "6dca9cc2-a86b-4c58-b0e5-411873b0c56d",
        "parentId" : "faa1e91e-ee6d-4770-93d9-5ab34a8f28e4",
        "authorId" : "12f98c82-b9ef-4668-aa6f-5a62bf3439bb",
        "body" : "I think this is a good suggestion, only an epoch smaller than the current leader epoch should be treated as `NotLeaderException`.",
        "createdAt" : "2021-08-01T09:11:44Z",
        "updatedAt" : "2021-08-01T09:11:44Z",
        "lastEditedBy" : "12f98c82-b9ef-4668-aa6f-5a62bf3439bb",
        "tags" : [
        ]
      }
    ],
    "commit" : "7426fc014915feaeaabaaf5099cceae9dd6756f7",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +133,137 @@    private long append(int epoch, List<T> records, boolean isAtomic) {\n        if (epoch < this.epoch) {\n            throw new NotLeaderException(\"Append failed because the epoch doesn't match\");\n        } else if (epoch > this.epoch) {\n            throw new IllegalArgumentException(\"Attempt to append from epoch \" + epoch +"
  },
  {
    "id" : "13fe4fc6-94c9-4aee-95bd-a8c983e14228",
    "prId" : 10946,
    "prUrl" : "https://github.com/apache/kafka/pull/10946#pullrequestreview-697682803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "adaa68dc-9649-4048-9714-960404f06537",
        "parentId" : null,
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "This will be the timestamp of the first batch in the MemoryRecords. Do we assume that only a single batch is included in any given MemoryRecords?",
        "createdAt" : "2021-06-30T18:18:46Z",
        "updatedAt" : "2021-06-30T18:19:57Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "a1290acb-09cb-4c2b-8d87-5cd65e1351ef",
        "parentId" : "adaa68dc-9649-4048-9714-960404f06537",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yes. I added this check and message to the PR: https://github.com/apache/kafka/pull/10946/files/1964e026b783235e2d9af9c0b116f15ed31e0a5b#diff-b7a2129b03764fbafab69c81e985d8ac6006d55f95307f0e21c70fb4750f61b5R475",
        "createdAt" : "2021-06-30T20:32:02Z",
        "updatedAt" : "2021-06-30T20:32:02Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "3e0a24cd-9ff7-4611-91c4-e15863640fd3",
        "parentId" : "adaa68dc-9649-4048-9714-960404f06537",
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "I think we should document that \"we only use the append time of the first batch\" here, and append a `to-do` with KAFKA-13020 to make it clear.",
        "createdAt" : "2021-07-01T08:19:47Z",
        "updatedAt" : "2021-07-01T08:24:28Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      },
      {
        "id" : "856fe591-3147-4334-b1c9-349b8a9301ed",
        "parentId" : "adaa68dc-9649-4048-9714-960404f06537",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Thanks @showuon . I added a comment. I didn't add the Jira issue. Apache Kafka tends not link to Jira from the code.",
        "createdAt" : "2021-07-01T21:11:11Z",
        "updatedAt" : "2021-07-01T21:11:39Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "72335638-d422-49a4-bc76-35cb291c4e42",
        "parentId" : "adaa68dc-9649-4048-9714-960404f06537",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "@jsancio : for future rerference, it's OK to put Apache JIRA numbers in the code. :)",
        "createdAt" : "2021-07-01T21:55:25Z",
        "updatedAt" : "2021-07-01T21:55:25Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca411125119c47b3ed22fe86e1af1bec6371d06d",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +515,519 @@            // 2. maxTimestamp is the append time of the batch. This needs to be changed\n            //    to return the LastContainedLogTimestamp of the SnapshotHeaderRecord\n            return data.firstBatch().maxTimestamp();\n        }\n    }"
  },
  {
    "id" : "6b78926e-3726-4881-b077-63bf7c3c926b",
    "prId" : 10946,
    "prUrl" : "https://github.com/apache/kafka/pull/10946#pullrequestreview-697675370",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06e8f281-a002-441e-b615-23dbcea8fde6",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "can you document `valueCreator` here?",
        "createdAt" : "2021-07-01T21:27:28Z",
        "updatedAt" : "2021-07-01T21:27:28Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "41496c9d-f338-4f01-9a03-cc76789c156a",
        "parentId" : "06e8f281-a002-441e-b615-23dbcea8fde6",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yep. Fixed.",
        "createdAt" : "2021-07-01T21:41:16Z",
        "updatedAt" : "2021-07-01T21:41:16Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca411125119c47b3ed22fe86e1af1bec6371d06d",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +217,221 @@     *        batch that will be appended. The memory records returned must contain one\n     *        control batch and that control batch have one record.\n     */\n    private void appendControlMessage(Function<ByteBuffer, MemoryRecords> valueCreator) {\n        appendLock.lock();"
  }
]