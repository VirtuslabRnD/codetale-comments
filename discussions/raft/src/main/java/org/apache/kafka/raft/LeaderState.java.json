[
  {
    "id" : "1d9313d5-a4fc-458d-9144-78e9de415cf0",
    "prId" : 9539,
    "prUrl" : "https://github.com/apache/kafka/pull/9539#pullrequestreview-538723641",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aafae846-532e-413c-8709-c78cf164b6aa",
        "parentId" : null,
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I think we have two options here. This class can contain either:\r\n```java\r\nprivate final Map<Integer, VoterState> voterReplicaStates = new HashMap<>(); \r\n```\r\nwhere we change this expression to `boolean hasEndorsedLeader = grantingVoters.contains(voterId);`\r\nand remove the field `private final Set<Integer> grantingVoters = new HashSet<>();`\r\n\r\nor:\r\n\r\n```java\r\nprivate final Set<Integer> voters = new HashSet<>(); \r\nprivate final Set<Integer> grantingVoters = new HashSet<>(); \r\n```\r\nand change a few of the methods here use these two sets instead of `voterReplicaStates`.\r\n\r\nI like the first option but it is up to you.",
        "createdAt" : "2020-11-24T14:36:21Z",
        "updatedAt" : "2020-12-08T02:56:30Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      },
      {
        "id" : "3878074d-343f-418e-8531-095891b0918a",
        "parentId" : "aafae846-532e-413c-8709-c78cf164b6aa",
        "authorId" : "dec739d0-c763-471c-b738-6b6f5b82e58e",
        "body" : "@jsancio , even I would prefer option 1 but slightly confused on it. You suggest to check for endorsement using `boolean hasEndorsedLeader = grantingVoters.contains(voterId);` and then asking to remove the field `grantingVoters `. Am I missing something ?\r\n",
        "createdAt" : "2020-11-25T14:04:46Z",
        "updatedAt" : "2020-12-08T02:56:30Z",
        "lastEditedBy" : "dec739d0-c763-471c-b738-6b6f5b82e58e",
        "tags" : [
        ]
      },
      {
        "id" : "4ed37e6b-5dad-4c48-afef-a1ae0b8df86c",
        "parentId" : "aafae846-532e-413c-8709-c78cf164b6aa",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "Yes, that's correct. You will have to change the implementation of `grantingVoters()` to something like:\r\n\r\n```java\r\npublic Set<Integer> endorsingVoters() { \r\n    return voterReplicaStates\r\n        .values()\r\n        .stream()\r\n        .filter(voter -> voter.hasEndorsedLeader)\r\n        .map(voter -> voter.stateId)\r\n        .collect(Collectors.toSet()); \r\n}\r\n```\r\n\r\nNotice the change in the method name. We can also change `nonEndorsingFollowers` to `nonEndorsingVoters` for consistency.",
        "createdAt" : "2020-11-25T17:37:11Z",
        "updatedAt" : "2020-12-08T02:56:30Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "16432f8e9a89a11ffd862efe67f9ddc27a85642a",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +51,55 @@\n        for (int voterId : voters) {\n            boolean hasEndorsedLeader = voterId == localId;\n            this.voterReplicaStates.put(voterId, new VoterState(voterId, hasEndorsedLeader));\n        }"
  },
  {
    "id" : "d054b6cd-e331-40bc-a5a2-4f614ed2ad9a",
    "prId" : 9553,
    "prUrl" : "https://github.com/apache/kafka/pull/9553#pullrequestreview-557337017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e40a2fce-37d8-4baa-bf18-1089e1004e41",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Maybe we could add a default no-op implementation to EpochState?",
        "createdAt" : "2020-12-22T17:01:29Z",
        "updatedAt" : "2020-12-23T18:10:34Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "0556f0fb-28e2-49d1-a8db-daf18409ad29",
        "parentId" : "e40a2fce-37d8-4baa-bf18-1089e1004e41",
        "authorId" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "body" : "I prefer to have each of the epoch states explicitly opt out of this `close` method. This makes it clear that this state doesn't have any resource that it wishes to clean/close during a transition. Instead of future code changes forgetting to override this method. What do you think?",
        "createdAt" : "2020-12-22T20:05:20Z",
        "updatedAt" : "2020-12-23T18:10:34Z",
        "lastEditedBy" : "4a7c311c-0954-4671-a0d2-266cb67437ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "22133d1166394ea4ffbf111aeb8eb063c2182cd8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +303,307 @@\n    @Override\n    public void close() {}\n\n}"
  },
  {
    "id" : "71e8bb5f-4517-4274-8937-61854de8858d",
    "prId" : 9737,
    "prUrl" : "https://github.com/apache/kafka/pull/9737#pullrequestreview-553563185",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5add6b64-491a-4d20-a05d-ab275a5b0b88",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Could we add a brief comment in the class javadoc about what we mean by \"acknowledged\"? It would be helpful to mention specifically that the set of unacknowledged voters are targets for `BeginQuorumEpoch` requests from the leader.",
        "createdAt" : "2020-12-16T01:46:23Z",
        "updatedAt" : "2020-12-22T18:04:33Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "c9ef6315-393e-4d00-87aa-c3a8e8cffa79",
        "parentId" : "5add6b64-491a-4d20-a05d-ab275a5b0b88",
        "authorId" : "dec739d0-c763-471c-b738-6b6f5b82e58e",
        "body" : "done",
        "createdAt" : "2020-12-16T10:45:31Z",
        "updatedAt" : "2020-12-22T18:04:33Z",
        "lastEditedBy" : "dec739d0-c763-471c-b738-6b6f5b82e58e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5078bbfcb7b16fe3443e3119bd7d47e25fd59ed9",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +57,61 @@\n        for (int voterId : voters) {\n            boolean hasAcknowledgedLeader = voterId == localId;\n            this.voterReplicaStates.put(voterId, new VoterState(voterId, hasAcknowledgedLeader));\n        }"
  },
  {
    "id" : "0d35eb92-e0db-4f4d-8890-a2e71fb8e52c",
    "prId" : 10309,
    "prUrl" : "https://github.com/apache/kafka/pull/10309#pullrequestreview-617863237",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "901c7046-6e9f-4ae7-b689-719cee95f811",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Just for my own education, when is it preferable to use upper class log context vs creating own log context?",
        "createdAt" : "2021-03-20T16:59:03Z",
        "updatedAt" : "2021-03-22T18:47:30Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "a6345e0e-fc88-4457-81b6-7c3c23eb001a",
        "parentId" : "901c7046-6e9f-4ae7-b689-719cee95f811",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The log context is useful because it carries with it a logging prefix which can be used to distinguish log messages. For example, in a streams application, the fact that we have multiple producers can make debugging difficult. Or in the context of integration/system/simulation testing, we often get logs from multiple nodes mixed together. With a common prefix, it is easy to grep messages for a particular instance so long as the `LogContext` is carried through to all the dependencies. Sometimes it is a little annoying to add the extra parameter, but it is worthwhile for improved debugging whenever the parent object already has a log context.",
        "createdAt" : "2021-03-22T18:37:23Z",
        "updatedAt" : "2021-03-22T18:47:30Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fc7bf96b2722317ac418a1d6ff0dedbc01a9ea8",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +55,59 @@        Set<Integer> voters,\n        Set<Integer> grantingVoters,\n        LogContext logContext\n    ) {\n        this.localId = localId;"
  },
  {
    "id" : "657a091f-2a30-444e-8f48-fa9a28df0011",
    "prId" : 10309,
    "prUrl" : "https://github.com/apache/kafka/pull/10309#pullrequestreview-617870900",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f7d96e8a-76f7-4991-adb1-5a66b99ab580",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I wonder whether the current approach is too loose. Maybe this is already done, but do we want to inform failed replica to cleanup or truncate in the FetchResponse?",
        "createdAt" : "2021-03-21T03:52:02Z",
        "updatedAt" : "2021-03-22T18:47:30Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "0ff7aa12-37e1-4bd4-860e-307de605c9ca",
        "parentId" : "f7d96e8a-76f7-4991-adb1-5a66b99ab580",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "The situation we are trying to handle is when a follower loses its disk. Basically the damage is already done by the time we receive the Fetch and the only thing we can do is let the follower try to catch back up. The problem with the old logic is that it prevented this even in situations which would not violate guarantees. I am planning to file a follow-up jira to think of some ways to handle disk loss situations more generally. We would like to at least detect the situation and see if we can prevent it from causing too much damage.",
        "createdAt" : "2021-03-22T18:46:05Z",
        "updatedAt" : "2021-03-22T18:47:30Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fc7bf96b2722317ac418a1d6ff0dedbc01a9ea8",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +198,202 @@                        \"end offset: \" + currentEndOffset.offset + \" -> \" + endOffsetMetadata.offset);\n                } else {\n                    log.warn(\"Detected non-monotonic update of fetch offset from nodeId {}: {} -> {}\",\n                        state.nodeId, currentEndOffset.offset, endOffsetMetadata.offset);\n                }"
  }
]