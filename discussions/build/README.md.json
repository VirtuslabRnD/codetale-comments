[
  {
    "id" : "d7209556-bafc-4f47-816a-d301552a2832",
    "prId" : 30787,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/30787#pullrequestreview-1437876",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c08598c5-6980-42d3-9fdd-a7350897c1d9",
        "parentId" : null,
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "maybe describe the build-data and rsync containers, too?\n",
        "createdAt" : "2016-09-22T21:57:33Z",
        "updatedAt" : "2016-10-04T02:42:31Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "a0e3accc-006f-4d12-b280-2d7b3edd65e9",
        "parentId" : "c08598c5-6980-42d3-9fdd-a7350897c1d9",
        "authorId" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "body" : "Adding a lot more description here.  Also describing the hash and versioning.\n",
        "createdAt" : "2016-09-24T16:40:35Z",
        "updatedAt" : "2016-10-04T02:42:31Z",
        "lastEditedBy" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "tags" : [
        ]
      }
    ],
    "commit" : "d955f54918159630a331611672e3f226ce7bd5af",
    "line" : null,
    "diffHunk" : "@@ -1,1 +36,40 @@The scripts directly under `build/` are used to build and test.  They will ensure that the `kube-build` Docker image is built (based on `build/build-image/Dockerfile`) and then execute the appropriate command in that container.  These scripts will both ensure that the right data is cached from run to run for incremental builds and will copy the results back out of the container.\n\nThe `kube-build` container image is built by first creating a \"context\" directory in `_output/images/build-image`.  It is done there instead of at the root of the Kubernetes repo to minimize the amount of data we need to package up when building the image.\n\nThere are 3 different containers instances that are run from this image.  The first is a \"data\" container to store all data that needs to persist across to support incremental builds. Next there is an \"rsync\" container that is used to transfer data in and out to the data container.  Lastly there is a \"build\" container that is used for actually doing build actions.  The data container persists across runs while the rsync and build containers are deleted after each use."
  },
  {
    "id" : "59acb6e7-4110-47f6-9922-33f0fde64f04",
    "prId" : 30787,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/30787#pullrequestreview-2036695",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b963962f-19ae-467e-a45b-b2552063887f",
        "parentId" : null,
        "authorId" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "body" : "should this be removing the generated stuff that's copied out by copy-output?\n",
        "createdAt" : "2016-09-28T00:22:08Z",
        "updatedAt" : "2016-10-04T02:42:31Z",
        "lastEditedBy" : "719d0e19-fcef-4b47-afac-404318b9514f",
        "tags" : [
        ]
      },
      {
        "id" : "94b42037-848b-46ca-8817-d2129d853879",
        "parentId" : "b963962f-19ae-467e-a45b-b2552063887f",
        "authorId" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "body" : "Right now we are checking in a lot of this stuff.  \n\nIt used to be necessary to have the dockerized stuff clean out `_output` as we were running as root in the container with a bind mount. But we don't do that any more so we could make `make-clean.sh` just clean up docker stuff and not touch _output or other files.\n\nI'll clean this up and slim down `build/make-clean.sh` in a different PR.\n",
        "createdAt" : "2016-09-28T21:49:55Z",
        "updatedAt" : "2016-10-04T02:42:31Z",
        "lastEditedBy" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "tags" : [
        ]
      }
    ],
    "commit" : "d955f54918159630a331611672e3f226ce7bd5af",
    "line" : null,
    "diffHunk" : "@@ -1,1 +29,33 @@  *  `build/run.sh make test-cmd`: Run CLI tests\n* `build/copy-output.sh`: This will copy the contents of `_output/dockerized/bin` from the Docker container to the local `_output/dockerized/bin`. It will also copy out specific file patterns that are generated as part of the build process. This is run automatically as part of `build/run.sh`.\n* `build/make-clean.sh`: Clean out the contents of `_output`, remove any locally built container images and remove the data container.\n* `/build/shell.sh`: Drop into a `bash` shell in a build container with a snapshot of the current repo code.\n"
  },
  {
    "id" : "047cc45f-853f-42b1-83e7-c21563486445",
    "prId" : 25978,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49ed9591-f59c-4a00-b3fc-3d90e2fea556",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "make test-cmd?\n",
        "createdAt" : "2016-07-12T00:30:32Z",
        "updatedAt" : "2016-07-13T04:53:03Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "fef16dd541356b9de3df1d180d0d96daebb874d2",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +28,32 @@  *  `run.sh make cross`: Build all binaries for all platforms\n  *  `run.sh make test`: Run all unit tests\n  *  `run.sh make test-integration`: Run integration test\n  *  `run.sh make test-cmd`: Run CLI tests\n* `copy-output.sh`: This will copy the contents of `_output/dockerized/bin` from any remote Docker container to the local `_output/dockerized/bin`.  Right now this is only necessary on Mac OS X with `boot2docker` when your git repo isn't under `/Users`."
  },
  {
    "id" : "08045de2-5688-4d1a-acbc-43848347c607",
    "prId" : 1532,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "210ba6ae-2907-4ed8-8fd0-5f4f297ea0ef",
        "parentId" : null,
        "authorId" : "27dc1d5f-333e-4abe-b37b-f5e273a43302",
        "body" : "Do you imagine a set of env vars for every cloud to enable storage upload in build/release.sh?\n",
        "createdAt" : "2014-10-02T06:02:29Z",
        "updatedAt" : "2014-10-10T19:37:07Z",
        "lastEditedBy" : "27dc1d5f-333e-4abe-b37b-f5e273a43302",
        "tags" : [
        ]
      },
      {
        "id" : "c09c635d-d73e-40dd-84c3-a978b4907e7f",
        "parentId" : "210ba6ae-2907-4ed8-8fd0-5f4f297ea0ef",
        "authorId" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "body" : "Yes -- there are really two things here that were conflated in the old system:\n1. Uploading a release so that users can download it.  This is basically making it more automatic so that we can build/upload nightlies and such.  Not need for every cloud to do this and most users won't need it during development (that is why it defaults off).\n2. Staging a server config and binaries so that they can be downloaded by VMs/instances/etc at cluster start time. This is different for every cloud.  Some clouds (GCE and Azure) have an object store we can bounce off of while other situations (vagrant, VSphere) can support sharing/uploading to the master via other means.  You can see the upload for _staging_ in `cluster/gce/util.sh`.  \n\nThe end result is that the user ends up downloading a release to their local machine and then re-uploading it to the object store when deploying.  At some point we can short circuit this and have the deploy refer to the release directly but I'm leaving that for later.\n",
        "createdAt" : "2014-10-03T17:25:49Z",
        "updatedAt" : "2014-10-10T19:37:07Z",
        "lastEditedBy" : "e19009d8-ed5c-45bb-b5ce-4f8d956c6c45",
        "tags" : [
        ]
      }
    ],
    "commit" : "272b9306c45c18effa5d92ef2e5bfa6263c88430",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +57,61 @@`KUBE_BUILD_RUN_IMAGES` | `n` | *Experimental* Build Docker images for running most server components.\n`KUBE_GCS_DOCKER_REG_PREFIX` | `docker-reg/` | *Experimental* When uploading docker images, the bucket that backs the registry.\n\n## Basic Flow\n"
  },
  {
    "id" : "053fa571-1cf4-4733-8f17-3c52c5ca6ac5",
    "prId" : 520,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d33ec7e6-fe38-4b60-84ef-61b3afd543c4",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I think markdown automagically corrects the numbers. Looks a little weird in plain text, but it means you don't have to renumber if you move stuff around.\n",
        "createdAt" : "2014-07-18T19:55:33Z",
        "updatedAt" : "2014-07-18T20:03:03Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "b718fbae-69f3-4f50-b183-6cb4cf0aec66",
        "parentId" : "d33ec7e6-fe38-4b60-84ef-61b3afd543c4",
        "authorId" : "4c30e665-5e6c-4a02-81a0-563b610a6d75",
        "body" : "It does, but I read the plain text much more often so prefer to order them explicitly. I can revert if you prefer.\n",
        "createdAt" : "2014-07-18T20:02:45Z",
        "updatedAt" : "2014-07-18T20:03:03Z",
        "lastEditedBy" : "4c30e665-5e6c-4a02-81a0-563b610a6d75",
        "tags" : [
        ]
      },
      {
        "id" : "e6221a21-8eaa-4ae3-b844-cdf8c278e4b6",
        "parentId" : "d33ec7e6-fe38-4b60-84ef-61b3afd543c4",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Nope, I'm OK with that.\n",
        "createdAt" : "2014-07-19T00:15:43Z",
        "updatedAt" : "2014-07-19T00:15:43Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e63c3a633d51445a29432ce1c8647915b9f390f",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +9,13 @@  2. **Linux with local Docker**  Install Docker according to the [instructions](https://docs.docker.com/installation/#installation) for your OS.  The scripts here assume that they are using a local Docker server and that they can \"reach around\" docker and grab results directly from the file system.\n2. Have python installed.  Pretty much it is installed everywhere at this point so you can probably ignore this.\n3. For releasing, have the [Google Cloud SDK](https://developers.google.com/cloud/sdk/) installed and configured.  The default release mechanism will upload Docker images to a private registry backed by Google Cloud Storage.  Non-image release artifacts will be uploaded to Google Cloud Storage also.\n\n## Key scripts"
  }
]