[
  {
    "id" : "54f81554-3f9b-4b09-a119-0b29e0ca7b1d",
    "prId" : 6707,
    "prUrl" : "https://github.com/root-project/root/pull/6707#pullrequestreview-584136372",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d56fd74d-8473-4bac-b244-7dd1d64d6280",
        "parentId" : null,
        "authorId" : "09b7e073-cbeb-42e8-aa22-8b1468de56ae",
        "body" : "Where is `config.environment['CUDA_VISIBLE_DEVICES']` used?",
        "createdAt" : "2021-02-05T08:23:47Z",
        "updatedAt" : "2021-02-05T15:49:21Z",
        "lastEditedBy" : "09b7e073-cbeb-42e8-aa22-8b1468de56ae",
        "tags" : [
        ]
      },
      {
        "id" : "5d60b7f9-2c6c-4484-8f7f-4998fc3cee16",
        "parentId" : "d56fd74d-8473-4bac-b244-7dd1d64d6280",
        "authorId" : "284066c8-7400-4d13-9dd5-d405b84b6ddb",
        "body" : "Inside the tests. If you do not manually select the GPU in your source code, CUDA runtime will choose the GPU with id 0 by default. In our workstation system, where we have two completely different GPUs, this can cause problems. With `CUDA_VISIBLE_DEVICES` you can limit the GPUs that the application can see and thus indirectly select the correct GPU.",
        "createdAt" : "2021-02-05T08:57:33Z",
        "updatedAt" : "2021-02-05T15:49:21Z",
        "lastEditedBy" : "284066c8-7400-4d13-9dd5-d405b84b6ddb",
        "tags" : [
        ]
      }
    ],
    "commit" : "02cfe2581b9f960c3ab846eeed3cd40acaa55cf3",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +344,348 @@  # https://developer.nvidia.com/blog/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/\n  if 'CUDA_VISIBLE_DEVICES' in os.environ:\n      config.environment['CUDA_VISIBLE_DEVICES'] = os.environ['CUDA_VISIBLE_DEVICES']\n\n# Loadable module"
  }
]