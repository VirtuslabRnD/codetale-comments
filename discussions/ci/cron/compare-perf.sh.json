[
  {
    "id" : "474faea2-7cc4-4a77-a41c-59aad563a753",
    "prId" : 5843,
    "prUrl" : "https://github.com/digital-asset/daml/pull/5843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0f360f6-cf88-40b0-868f-a2548c55d232",
        "parentId" : null,
        "authorId" : "7ddbf119-9fd4-4e95-b47a-aa60f2648372",
        "body" : "Looks like we are never deleting this directory?",
        "createdAt" : "2020-05-06T06:31:54Z",
        "updatedAt" : "2020-05-06T11:05:40Z",
        "lastEditedBy" : "7ddbf119-9fd4-4e95-b47a-aa60f2648372",
        "tags" : [
        ]
      },
      {
        "id" : "3d594f14-79ee-4804-a0e3-29911f843d64",
        "parentId" : "a0f360f6-cf88-40b0-868f-a2548c55d232",
        "authorId" : "8afc1e61-17e0-4309-b9ea-f0690fd56c47",
        "body" : "Indeed. The job runs once a day and the one file that function writes is about 8.8kb, so I don't think it's an issue. Even taking into account the fact that the script invokes that function twice, and FS padding (on HFS+ at least), this is still consuming only 24kb in total (as machines get cleared every day, there should never be more than one set of files).",
        "createdAt" : "2020-05-06T11:01:26Z",
        "updatedAt" : "2020-05-06T11:05:40Z",
        "lastEditedBy" : "8afc1e61-17e0-4309-b9ea-f0690fd56c47",
        "tags" : [
        ]
      }
    ],
    "commit" : "e81d3082bdb9619d997db4439b42a683b7d6838c",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +10,14 @@measure() {\n    local treeish=$1\n    local out=$(mktemp -d)/out.json\n    git checkout $treeish >&2\n    bazel run daml-lf/scenario-interpreter:scenario-perf -- -rf json -rff $out >&2"
  }
]