[
  {
    "id" : "21c4aad6-30fb-422a-b611-97acae34b195",
    "prId" : 18775,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/18775#pullrequestreview-120678692",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bfb5b9e-0826-4a96-8781-e28ab2dc0326",
        "parentId" : null,
        "authorId" : "9e7dc62f-3c1b-4617-b948-2f2fe615cbe5",
        "body" : "I'm not sure if this is the right way to do it.\r\n\r\nOn Ubuntu 16.04, I indeed had a file `/usr/lib/x86_64-linux-gnu/libgomp.so`, but on 14.04 and 18.04, I only have `/usr/lib/x86_64-linux-gnu/libgomp.so.1`, which is not found by the linker. There are several `libgomp.so`s in subdirectories for each installed gcc version, e.g. `/usr/lib/gcc/x86_64-linux-gnu/6/libgomp.so`. These subdirectories are not however on the linker path, so linking a dependent project fails.\r\n\r\nWhat works for me (and IMHO is the correct way) is `find_package(OpenMP)` and then exporting `OpenMP_CXX_FLAGS` to dependent projects (using an extras file?). With gcc, it adds `-fopenmp` to both compile and link steps. \r\n\r\nIn https://github.com/tensorflow/tensorflow/commit/9e197152c04ebb81f055067534bd93322d182f0e there was some alteration of the CXX flags done (just for the current project, not for dependent ones), but as stated in the discussion to https://github.com/tensorflow/tensorflow/pull/18973 , it'd be better to find the flags using the `find_package` call. This is just a reminder that the work should be coordinated.",
        "createdAt" : "2018-05-05T23:52:51Z",
        "updatedAt" : "2018-05-05T23:52:52Z",
        "lastEditedBy" : "9e7dc62f-3c1b-4617-b948-2f2fe615cbe5",
        "tags" : [
        ]
      },
      {
        "id" : "82a6cd90-e123-4e67-a8c6-6ffad1c7b520",
        "parentId" : "9bfb5b9e-0826-4a96-8781-e28ab2dc0326",
        "authorId" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "body" : "@peci1 I only tested on Ubuntu 16.04 as it was the version Nvidia support for CUDA (Nvidia supports ubuntu 16.04 and 17.04 at that time, I couldn't find 14.04 or 18.04), but let me take a look at Ubuntu 18.04 and see if it is possible to address the issue you mentioned.",
        "createdAt" : "2018-05-07T16:39:23Z",
        "updatedAt" : "2018-05-07T16:39:23Z",
        "lastEditedBy" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "tags" : [
        ]
      },
      {
        "id" : "cf70d9f7-dad6-40cb-b9e5-1522282e55ab",
        "parentId" : "9bfb5b9e-0826-4a96-8781-e28ab2dc0326",
        "authorId" : "2409d0a4-e7fe-4dd6-b31c-a597890e2a13",
        "body" : "Can't seem to find much documentation on support for cmake on Ubuntu 18.04. ",
        "createdAt" : "2018-05-16T14:06:01Z",
        "updatedAt" : "2018-05-16T14:06:01Z",
        "lastEditedBy" : "2409d0a4-e7fe-4dd6-b31c-a597890e2a13",
        "tags" : [
        ]
      },
      {
        "id" : "1c96bf1d-643a-47ea-ac9f-156a845ce18e",
        "parentId" : "9bfb5b9e-0826-4a96-8781-e28ab2dc0326",
        "authorId" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "body" : "@aceveggie I haven't been able to find the cuda install on ubuntu 18.04, or the cuda docker images based on Ubuntu 18.04: https://hub.docker.com/r/nvidia/cuda/\r\n\r\nI can look into fixing any potential issues of CMAKE+CUDA once Nvidia supports 18.04.",
        "createdAt" : "2018-05-16T14:46:43Z",
        "updatedAt" : "2018-05-16T14:46:43Z",
        "lastEditedBy" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "tags" : [
        ]
      },
      {
        "id" : "f16d8574-aebc-46d1-afe6-5075f2359184",
        "parentId" : "9bfb5b9e-0826-4a96-8781-e28ab2dc0326",
        "authorId" : "9e7dc62f-3c1b-4617-b948-2f2fe615cbe5",
        "body" : "Installing the 17.04 or 17.10 binary packages works on 18.04 without a problem (I've built TF both with bazel and CMake on 18.04 with CUDA 9.0 and 9.1). But I understand it still lacks official support.",
        "createdAt" : "2018-05-16T14:53:58Z",
        "updatedAt" : "2018-05-16T14:53:58Z",
        "lastEditedBy" : "9e7dc62f-3c1b-4617-b948-2f2fe615cbe5",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9766a574e0793d7aa2c970763535785be12abef",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +470,474 @@  if(NOT WIN32)\n    # add gomp to tensorflow_EXTERNAL_LIBRARIES, needed by libcusolver.so\n    list(APPEND tensorflow_EXTERNAL_LIBRARIES gomp)\n  endif()\n"
  },
  {
    "id" : "3a07b58e-047c-4901-989b-8e74128a315e",
    "prId" : 16936,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/16936#pullrequestreview-96718459",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d140006c-ac4d-4234-8f15-3aada8710239",
        "parentId" : null,
        "authorId" : "f8fdffda-0f78-4047-80eb-39d50943d149",
        "body" : "I think the result of this is: \r\n\r\n- MKL is off by default\r\n- adding tensorflow_ENABLE_MKL_SUPPORT will enable MKL-ML support (not open source)\r\n- adding tensorflow_ENABLE_MKLDNN_SUPPORT will enable MKL-DNN support (using open source solution)\r\n\r\nMKL_DNN is now the default MKL implementation on Linux/bazel (e.g. adding --config=mkl turns on MKL_DNN). I guess it's fine for now to have Windows default to MKL-ML. At some point (i.e. when we done better testing) we should flip that.",
        "createdAt" : "2018-02-13T22:28:24Z",
        "updatedAt" : "2018-04-13T03:19:32Z",
        "lastEditedBy" : "f8fdffda-0f78-4047-80eb-39d50943d149",
        "tags" : [
        ]
      },
      {
        "id" : "994ee0ee-abec-46de-bf06-b365496df288",
        "parentId" : "d140006c-ac4d-4234-8f15-3aada8710239",
        "authorId" : "c556f901-4423-40e8-901f-55474b2047a1",
        "body" : "Yes you are right. Since MKL download site is not public (just like cuDnn), I can't autoconfig MKL installation.",
        "createdAt" : "2018-02-14T05:17:06Z",
        "updatedAt" : "2018-04-13T03:19:32Z",
        "lastEditedBy" : "c556f901-4423-40e8-901f-55474b2047a1",
        "tags" : [
        ]
      },
      {
        "id" : "8edbb784-892b-4cc4-a14d-38e9b11b4839",
        "parentId" : "d140006c-ac4d-4234-8f15-3aada8710239",
        "authorId" : "f8fdffda-0f78-4047-80eb-39d50943d149",
        "body" : "Is this not what you are looking for? https://github.com/intel/mkl-dnn",
        "createdAt" : "2018-02-14T16:19:57Z",
        "updatedAt" : "2018-04-13T03:19:32Z",
        "lastEditedBy" : "f8fdffda-0f78-4047-80eb-39d50943d149",
        "tags" : [
        ]
      },
      {
        "id" : "78a59828-da9d-41f7-8007-3e1c7753a0e5",
        "parentId" : "d140006c-ac4d-4234-8f15-3aada8710239",
        "authorId" : "c556f901-4423-40e8-901f-55474b2047a1",
        "body" : "Nope. That is mkl dnn, an open source library encapulating dnn calculation by mkl. It still requires mkl to be installed on your machine.\r\nTf also supports mkldnn and I have already add related cmake script.",
        "createdAt" : "2018-02-15T01:44:19Z",
        "updatedAt" : "2018-04-13T03:19:32Z",
        "lastEditedBy" : "c556f901-4423-40e8-901f-55474b2047a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a62f35b07444d084b738e320ed2983b6a1af420",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +171,175 @@    add_definitions(-DINTEL_MKL -DEIGEN_USE_VML)\n    if (NOT tensorflow_ENABLE_MKLDNN_SUPPORT)\n      add_definitions(-DINTEL_MKL_ML)\n    endif()\n  endif()"
  },
  {
    "id" : "e16123ac-d0ea-4449-b367-1c5b72070df9",
    "prId" : 15382,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/15382#pullrequestreview-91126168",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8eae14a1-b182-4987-9f07-95813807e583",
        "parentId" : null,
        "authorId" : "28fabc34-a1ac-4aba-988b-9c9e03232122",
        "body" : "Should these be protected like:\r\n```\r\nif len(ADD_CLAGS) > 0\r\n  add_definitions...\r\n```\r\nI cannot see how add_definitions or link_directories will behave if these are unset.\r\n\r\n",
        "createdAt" : "2018-01-23T07:31:57Z",
        "updatedAt" : "2018-02-11T06:45:06Z",
        "lastEditedBy" : "28fabc34-a1ac-4aba-988b-9c9e03232122",
        "tags" : [
        ]
      },
      {
        "id" : "d94e7d00-089a-44e1-ab54-86c666d9d29e",
        "parentId" : "8eae14a1-b182-4987-9f07-95813807e583",
        "authorId" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "body" : "I thought ```add_definitions``` with null strings or unset strings behaves ok (no effect on runtime); however, I'll recheck this issue.",
        "createdAt" : "2018-01-24T10:22:18Z",
        "updatedAt" : "2018-02-11T06:45:06Z",
        "lastEditedBy" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e7e652d0b09cab1b426af856fe41a5b77542c64",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +198,202 @@endif()\n\nadd_definitions(${ADD_CFLAGS})\nlink_directories(${ADD_LINK_DIRECTORY})\n"
  },
  {
    "id" : "68c9b6d3-6625-43f5-8683-84ca49da5d07",
    "prId" : 14016,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/14016#pullrequestreview-83225446",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "291abd53-3367-4ed7-b799-819d0df7e5d7",
        "parentId" : null,
        "authorId" : "5f311952-9020-4294-a943-21cbd17dde41",
        "body" : "Do we need this option? For example, is there an underlying option that will cause `find_package(CUDA 8.0 REQUIRED)` to surface these same paths?",
        "createdAt" : "2017-11-01T16:11:31Z",
        "updatedAt" : "2017-11-07T11:14:14Z",
        "lastEditedBy" : "5f311952-9020-4294-a943-21cbd17dde41",
        "tags" : [
        ]
      },
      {
        "id" : "a640262e-f18f-42cb-9821-41a0783c846a",
        "parentId" : "291abd53-3367-4ed7-b799-819d0df7e5d7",
        "authorId" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "body" : "Cudnn and nccl may be installed at a different path. (separated from Cuda)\r\n\r\nSuch issues get worse if users do not use popular Linux distro.",
        "createdAt" : "2017-11-03T14:59:58Z",
        "updatedAt" : "2017-11-07T11:14:14Z",
        "lastEditedBy" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "tags" : [
        ]
      },
      {
        "id" : "02017533-dbce-4f40-a26d-fc3a1e70e4fa",
        "parentId" : "291abd53-3367-4ed7-b799-819d0df7e5d7",
        "authorId" : "5f311952-9020-4294-a943-21cbd17dde41",
        "body" : "Perhaps we should have two options, `tensorflow_PATH_CUDNN_STATIC_LIB` and `tensorflow_PATH_NCCL_STATIC_LIB`, with some common default?",
        "createdAt" : "2017-11-07T00:05:35Z",
        "updatedAt" : "2017-11-07T11:14:14Z",
        "lastEditedBy" : "5f311952-9020-4294-a943-21cbd17dde41",
        "tags" : [
        ]
      },
      {
        "id" : "868a3ee9-7a80-4c22-9375-120c7ef3842c",
        "parentId" : "291abd53-3367-4ed7-b799-819d0df7e5d7",
        "authorId" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "body" : "Ok. I'll add these two to override the value of ```tensorflow_PATH_STATIC_LIB```:\r\n```\r\n  option(tensorflow_PATH_CUDNN_STATIC_LIB \"Override PATH_STATIC_LIB for libcudnn_static.a\" ${tensorflow_PATH_STATIC_LIB})              \r\n  option(tensorflow_PATH_NCCL_STATIC_LIB \"Override PATH_STATIC_LIB for libnccl_static.a\" ${tensorflow_PATH_STATIC_LIB}) \r\n```",
        "createdAt" : "2017-11-07T10:09:34Z",
        "updatedAt" : "2017-11-07T11:14:14Z",
        "lastEditedBy" : "4aac6b37-b72f-4038-aab7-2c15d7d955bb",
        "tags" : [
        ]
      },
      {
        "id" : "7d9672ee-4532-41cb-a3f1-ba110be8b720",
        "parentId" : "291abd53-3367-4ed7-b799-819d0df7e5d7",
        "authorId" : "0d33c4f5-d351-4192-896b-8a711aa7ffb4",
        "body" : "@mrry : I'm trying to extend this update to finish CMake + OSX testing w/ (NVIDIA) GPU.   I had started with CUDA 8.0 and cuDNN 6.0, but given recent activity here, it seems better to target master w/ CUDA 9.0 + cuDNN 7.0.  Since this is closely related, It seemed better to keep related discussion in this thread, but I can create a new issue if preferred.   The OS X CUDA installation does not come with `nccl` (see `find` output below for contents).  NVIDIA has a (login based) `nccl` download for v2.0, but it only has Linux libraries.  I see three other options to support OS X + GPU Builds:\r\n\r\n1. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/nccl (build from bundled source v1.3.5)\r\n2. https://github.com/nvidia/nccl (build from source v1.?)\r\n3. add `option(tensroflow_USE_NCCL \"Use NCCL lib\" ON)` and update code\r\n\r\nShall I add the bundled `nccl` (v1.3.5?) files to the CMake build?.  I see notes about migrating to v2.0 in commit comments, which seems to be closed source.  If that's the case, then it may be best to try to make any internal tensorflow `nccl` operations optional in order to support single GPU configurations to start with. \r\n\r\n`find /Developer/NVIDIA/CUDA-9.0/lib -name \"*.a\"`\r\n```\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcublas_device.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcublas_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcudadevrt.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcudart_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcufft_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcufftw_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libculibos.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcurand_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcusolver_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libcusparse_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppc_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppial_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppicc_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppicom_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppidei_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppif_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppig_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppim_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppist_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppisu_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnppitc_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnpps_static.a\r\n/Developer/NVIDIA/CUDA-9.0/lib/libnvgraph_static.a\r\n```\r\n\r\n[UPDATE: I will repost this as a separate issue for tracking.]",
        "createdAt" : "2017-12-13T16:11:15Z",
        "updatedAt" : "2017-12-15T12:16:19Z",
        "lastEditedBy" : "0d33c4f5-d351-4192-896b-8a711aa7ffb4",
        "tags" : [
        ]
      }
    ],
    "commit" : "486ad315f70d1a17769fdc4cf89634e7db9a4ebd",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +41,45 @@  find_package (Threads)\n\n  option(tensorflow_PATH_STATIC_LIB \"Additional library search path for libcudnn_static.a, libnccl_static.a, libculibos.a\" /usr/local/cuda/lib64/)\n  option(tensorflow_CUDNN_INCLUDE \"cudnn.h header install path\" /usr/include/)\n  if (NOT tensorflow_CUDNN_INCLUDE)"
  },
  {
    "id" : "74149f4c-d616-4400-915c-9ae3d26b035d",
    "prId" : 8737,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/8737#pullrequestreview-29510838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71003790-4784-4300-9df6-28ae26438b33",
        "parentId" : null,
        "authorId" : "aff1f283-ceb1-4130-abd7-0adce56ac0e9",
        "body" : "Do you rather add it in an `else()` in the same closure of the `arch=native` or leave it separate like it is?",
        "createdAt" : "2017-03-28T03:37:14Z",
        "updatedAt" : "2017-03-28T18:09:28Z",
        "lastEditedBy" : "aff1f283-ceb1-4130-abd7-0adce56ac0e9",
        "tags" : [
        ]
      },
      {
        "id" : "7c9436f8-f4fc-4edf-8a82-2169e53afe9b",
        "parentId" : "71003790-4784-4300-9df6-28ae26438b33",
        "authorId" : "5f311952-9020-4294-a943-21cbd17dde41",
        "body" : "This looks fine to me.",
        "createdAt" : "2017-03-28T16:59:54Z",
        "updatedAt" : "2017-03-28T18:09:28Z",
        "lastEditedBy" : "5f311952-9020-4294-a943-21cbd17dde41",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1b4a7a274ce05a68f8640476ff7b47b7075a40f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +83,87 @@endif()\n\n# MSVC SIMD instructions\nif (tensorflow_WIN_CPU_SIMD_OPTIONS)\n  if (WIN32)"
  },
  {
    "id" : "4e80d3f1-b18c-49a4-8061-2153d1bf9aed",
    "prId" : 1738,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa5e7e90-139e-4091-a520-aba7b9af5c3c",
        "parentId" : null,
        "authorId" : "5e8e4e4f-c91f-4d0d-a21a-404f7d555b7d",
        "body" : "Does it need 3.1? Would 3.0 work? That is what is in stable debian.\n",
        "createdAt" : "2016-04-11T18:02:48Z",
        "updatedAt" : "2016-04-11T18:02:48Z",
        "lastEditedBy" : "5e8e4e4f-c91f-4d0d-a21a-404f7d555b7d",
        "tags" : [
        ]
      },
      {
        "id" : "1145fa97-eb4a-4983-8d33-12d4744e4be5",
        "parentId" : "fa5e7e90-139e-4091-a520-aba7b9af5c3c",
        "authorId" : "a81922ca-0d8d-47ac-8356-3df488232492",
        "body" : "According to https://cmake.org/cmake/help/v3.1/release/3.1.0.html\n\n> New target_compile_features() command allows populating the COMPILE_FEATURES target property, just like any other build variable.\n\nSo it should only works from 3.1\n",
        "createdAt" : "2016-04-12T03:43:31Z",
        "updatedAt" : "2016-04-12T03:43:31Z",
        "lastEditedBy" : "a81922ca-0d8d-47ac-8356-3df488232492",
        "tags" : [
        ]
      }
    ],
    "commit" : "c1bde26f462c94b76c7c93e5510bb5b7b8e732a9",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +0,4 @@# Minimum CMake required\ncmake_minimum_required(VERSION 3.1)\n\n# Project"
  }
]