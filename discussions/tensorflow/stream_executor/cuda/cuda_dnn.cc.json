[
  {
    "id" : "d598b894-ed30-4062-919d-3939295fc9ff",
    "prId" : 50570,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/50570#pullrequestreview-698426267",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c810a088-845e-44ab-8fa3-2958ef12ab95",
        "parentId" : null,
        "authorId" : "9a96df0c-194f-4775-82a5-c8d2c6b88fd1",
        "body" : "I don't see anything specific to int8x4 in the recent cuDNN Frontend changes; is the lack of support actually in the backend API inside the cuDNN binary release?  The documentation of `CUDNN_BACKEND_TENSOR_DESCRIPTOR` does say it works with vector size 32.",
        "createdAt" : "2021-07-02T22:10:29Z",
        "updatedAt" : "2021-07-03T02:19:48Z",
        "lastEditedBy" : "9a96df0c-194f-4775-82a5-c8d2c6b88fd1",
        "tags" : [
        ]
      }
    ],
    "commit" : "b954a503ff5bdcfa589e4c18f64e60c1075d0949",
    "line" : 263,
    "diffHunk" : "@@ -1,1 +3483,3487 @@      dnn::DataLayout::kBatchDepthYX, vector_size, vector_dim);\n\n  if (vector_size == 32) {\n    return port::InternalError(\"cuDNN frontend doesn't support int8x32 at the \"\n                               \"moment.\");"
  },
  {
    "id" : "e8a3617d-fa78-4a3d-bf28-710d303e4c7f",
    "prId" : 49277,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/49277#pullrequestreview-680277085",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e181115-fc7c-4cfa-8ca2-e1b137584aea",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "If I understand this section correctly, it provides more knobs to the cuDNN API from SE. Is it possible to factor it out in a separate PR?",
        "createdAt" : "2021-06-10T01:49:37Z",
        "updatedAt" : "2021-06-10T02:06:26Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      }
    ],
    "commit" : "290070fba0521d1cf8aad2cf491d7f5a58390f79",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +1804,1808 @@}\n\nport::StatusOr<DeviceMemory<uint8>> CreateBatchNormBackwardWorkspace(\n    Stream* stream, const CudnnHandle& cudnn, const cudnnBatchNormMode_t& mode,\n    const cudnnBatchNormOps_t& bn_ops,"
  },
  {
    "id" : "2db5b914-cd3f-442d-977b-f4658c742424",
    "prId" : 46965,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/46965#pullrequestreview-598027492",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab44fcb8-01ae-4a82-9624-a7a934ea576b",
        "parentId" : null,
        "authorId" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "body" : "Overall comment: this PR is too large. Can you split it into multiple PRs, or at least multiple commits? I can see clear layering here, e.g. stream_executor doesn't depending on core/kernels.",
        "createdAt" : "2021-02-24T23:28:19Z",
        "updatedAt" : "2021-03-17T02:37:34Z",
        "lastEditedBy" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "tags" : [
        ]
      }
    ],
    "commit" : "6838420da8ce4672d23d497c28932528d022fe2a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +48,52 @@#include \"third_party/gpus/cudnn/cudnn.h\"\n#if CUDNN_VERSION >= 8100\n#include \"third_party/cudnn_frontend/include/cudnn_frontend.h\"\n#endif // CUDNN_VERSION >= 8100\n#include \"absl/strings/string_view.h\""
  },
  {
    "id" : "3863e0a8-be95-4e0c-b737-1c55d3e3ed53",
    "prId" : 39764,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39764#pullrequestreview-427519222",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a67d9b8-6426-4e79-8c49-41206e8a1086",
        "parentId" : null,
        "authorId" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "body" : "Why not call IsTensorMathAllowed?",
        "createdAt" : "2020-06-08T19:02:35Z",
        "updatedAt" : "2020-06-12T00:16:29Z",
        "lastEditedBy" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "tags" : [
        ]
      },
      {
        "id" : "b0463652-8870-4c12-8b63-2db5e2063bf8",
        "parentId" : "8a67d9b8-6426-4e79-8c49-41206e8a1086",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "Because Stream is not currently plumbed into CudnnRnnDescriptor::Create.",
        "createdAt" : "2020-06-09T20:33:44Z",
        "updatedAt" : "2020-06-12T00:16:29Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bd42cdd0e68cebe8b280b323cde4d01a9d2bf3a",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +1164,1168 @@    // GetRnnAlgorithms() (which are non-default and explicitly set whether to\n    // use tensor ops). CuDNN 7.2.1 fixed this issue\n    bool allow_tensor_ops =\n        data_type != CUDNN_DATA_FLOAT || tensorflow::tf32_execution_allowed();\n    bool use_tensor_ops;"
  },
  {
    "id" : "992af5a3-58df-4405-aa5b-3b8fadf17253",
    "prId" : 39764,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39764#pullrequestreview-426520199",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "16153e3b-bb4b-410a-b0b1-60e6eb666f4b",
        "parentId" : null,
        "authorId" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "body" : "Thanks for fixing the TODO!",
        "createdAt" : "2020-06-08T19:03:15Z",
        "updatedAt" : "2020-06-12T00:16:29Z",
        "lastEditedBy" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bd42cdd0e68cebe8b280b323cde4d01a9d2bf3a",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +2492,2496 @@    const dnn::AlgorithmDesc& algorithm_desc,\n    ScratchAllocator* scratch_allocator) {\n  if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {\n    return port::Status(\n        port::error::INTERNAL,"
  },
  {
    "id" : "3dbcebde-f2b9-43de-85b7-8683536893c9",
    "prId" : 30762,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/30762#pullrequestreview-275777862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c13d9f0d-91e7-41b3-8bbc-907c80c39c15",
        "parentId" : null,
        "authorId" : "eca90909-340c-4f15-9af5-58905c41473a",
        "body" : "int8-to-float convolution with CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM clamps out at [-128,127], but shouldn't.  We need to check against it.  CUDNN 8.0 is an estimation.  Once the fix is scheduled, we may need to adjust this condition.",
        "createdAt" : "2019-08-16T05:17:10Z",
        "updatedAt" : "2019-08-16T05:17:11Z",
        "lastEditedBy" : "eca90909-340c-4f15-9af5-58905c41473a",
        "tags" : [
        ]
      }
    ],
    "commit" : "e009644f034fa0ca4df910a812432cab3458d440",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +2935,2939 @@          \"cuDNNv5 and cuDNNv6. See b/68264959.\");\n    }\n    if (CUDNN_VERSION < 8000) {\n      if (algorithm_desc.algo_id() ==\n              CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM &&"
  },
  {
    "id" : "489b448c-a499-4ecd-9c34-f9d2e4da4774",
    "prId" : 29147,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29147#pullrequestreview-243571188",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b21e069-8ee0-4f0b-ad2c-9c9acb6a2356",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Just to double check: if tensor core is not available it'll still fallback to non-tensorcore operations right?",
        "createdAt" : "2019-05-29T22:19:44Z",
        "updatedAt" : "2019-05-29T22:19:44Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "532658e5-113a-44f6-929b-e7dbaedcc004",
        "parentId" : "1b21e069-8ee0-4f0b-ad2c-9c9acb6a2356",
        "authorId" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "body" : "Yes, after 7.2.1 the tensor_core_op_math is only a hint.",
        "createdAt" : "2019-05-29T22:44:00Z",
        "updatedAt" : "2019-05-29T22:44:00Z",
        "lastEditedBy" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "tags" : [
        ]
      },
      {
        "id" : "70686e24-edfe-49ac-b106-a9087ecc80b6",
        "parentId" : "1b21e069-8ee0-4f0b-ad2c-9c9acb6a2356",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "In that case please document the behavior.",
        "createdAt" : "2019-05-29T23:19:49Z",
        "updatedAt" : "2019-05-29T23:19:53Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "533a2dda-91fc-4448-ba61-aa4cc45da853",
        "parentId" : "1b21e069-8ee0-4f0b-ad2c-9c9acb6a2356",
        "authorId" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "body" : "This has already been doc'ed above. Someone has already mentioned why they didn't use the tensor core op as default one. And I added that  `CuDNN 7.2.1 fixed this issue`.",
        "createdAt" : "2019-05-29T23:28:24Z",
        "updatedAt" : "2019-05-29T23:28:24Z",
        "lastEditedBy" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "tags" : [
        ]
      },
      {
        "id" : "67b757a8-b561-4195-b478-efacc411653f",
        "parentId" : "1b21e069-8ee0-4f0b-ad2c-9c9acb6a2356",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "I see, sorry I missed that.",
        "createdAt" : "2019-05-29T23:55:49Z",
        "updatedAt" : "2019-05-29T23:55:52Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "660925846c09988ca99c09761727590284c70203",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1097,1101 @@      } else {\n#if CUDNN_VERSION >= 7201\n        math_type = CUDNN_TENSOR_OP_MATH;\n#else\n        math_type = CUDNN_DEFAULT_MATH;"
  },
  {
    "id" : "30814d27-34ff-4d4b-8d3e-7922e2047abd",
    "prId" : 27756,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27756#pullrequestreview-242958570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11b68947-69e7-4b73-8b8c-681b5459d5fb",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add a comment on why it doesn't require equality here.",
        "createdAt" : "2019-05-28T22:50:26Z",
        "updatedAt" : "2019-06-07T17:16:15Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0ea11b15886b62ce7184bf9ab4a5e2502afe985",
    "line" : 198,
    "diffHunk" : "@@ -1,1 +1534,1538 @@  if (!(input_h_desc.num_layers() == input_c_desc.num_layers() &&\n        input_h_desc.batch_size() == input_c_desc.batch_size() &&\n        input_h_desc.data_size() <= input_c_desc.data_size())) {\n    return port::Status(port::error::INVALID_ARGUMENT, \"Invalid input_c shape\");\n  }"
  },
  {
    "id" : "57e2c644-4aee-4365-abf2-7772c3b27f47",
    "prId" : 27756,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27756#pullrequestreview-242958570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c02a1d63-3a2d-4c0b-8ab2-dc0cea0dfc39",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add some description on what this function does.",
        "createdAt" : "2019-05-28T22:51:46Z",
        "updatedAt" : "2019-06-07T17:16:15Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0ea11b15886b62ce7184bf9ab4a5e2502afe985",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +1178,1182 @@// (projection matrix) will be fetched to the 'weights'. Otherwise, nothing will\n// be done.\nport::Status CheckAndFetchProjectionWeights(\n    const CudnnHandle& cudnn, cudnnRNNDescriptor_t rnn_desc, const int layer,\n    const TensorDescriptor& input_desc, const FilterDescriptor& filter_desc,"
  },
  {
    "id" : "693b5f86-8a97-43db-995f-1325e2f8d0ab",
    "prId" : 27756,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27756#pullrequestreview-242958570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5b58be4-dc4c-4338-b707-ed12e65edf78",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Move this check to line 1050 so it happens earlier?",
        "createdAt" : "2019-05-28T23:05:27Z",
        "updatedAt" : "2019-06-07T17:16:15Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0ea11b15886b62ce7184bf9ab4a5e2502afe985",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1058,1062 @@        /*dataType=*/compute_type));\n    if (use_projection) {\n#if CUDNN_VERSION >= 7101\n      RETURN_IF_CUDNN_ERROR(cudnnSetRNNProjectionLayers(\n          cudnn.handle(), /*rnnDesc=*/rnn_desc.get(),"
  },
  {
    "id" : "e6e749de-be1b-45b8-82da-d0af3596df08",
    "prId" : 27756,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27756#pullrequestreview-244089189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b57007fb-7010-4ac9-8d11-551d795807c3",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "`cudnnSetRNNProjectionLayers is not supported when ...`",
        "createdAt" : "2019-05-28T23:07:16Z",
        "updatedAt" : "2019-06-07T17:16:15Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "83ce0b5f-3c31-487f-bb7c-cf6861848e65",
        "parentId" : "b57007fb-7010-4ac9-8d11-551d795807c3",
        "authorId" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "body" : "The remaining part is in the next line.",
        "createdAt" : "2019-05-31T00:26:41Z",
        "updatedAt" : "2019-06-07T17:16:15Z",
        "lastEditedBy" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0ea11b15886b62ce7184bf9ab4a5e2502afe985",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +1064,1068 @@#else\n      return port::Status(port::error::INVALID_ARGUMENT,\n                          \"No supported cudnnSetRNNProjectionLayers when \"\n                          \"CUDNN_VERSION < 7.1.1\");\n#endif"
  },
  {
    "id" : "b881e27d-103c-4ea8-b381-de64d21616ad",
    "prId" : 25269,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25269#pullrequestreview-198380965",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfd783af-8871-4c26-801d-d4ca2bb9d772",
        "parentId" : null,
        "authorId" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "body" : "perhaps ```const auto```?",
        "createdAt" : "2019-01-30T03:24:21Z",
        "updatedAt" : "2019-01-30T03:24:29Z",
        "lastEditedBy" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "tags" : [
        ]
      },
      {
        "id" : "b1f44cc7-1c2d-4a87-8f02-986c820ff6e4",
        "parentId" : "dfd783af-8871-4c26-801d-d4ca2bb9d772",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "Sorry I didn't get a chance to address this before the merge. I agree that adding the const would have been preferable.",
        "createdAt" : "2019-01-31T00:18:33Z",
        "updatedAt" : "2019-01-31T00:18:33Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      },
      {
        "id" : "c4f47b62-63d5-43e5-9900-0461db80a835",
        "parentId" : "dfd783af-8871-4c26-801d-d4ca2bb9d772",
        "authorId" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "body" : "I'm fine with either way. Not having const is shorter, and happens to be consistent with other places. The variable is used only once, and it's immediately below, so const doesn't actually help much.",
        "createdAt" : "2019-01-31T00:22:17Z",
        "updatedAt" : "2019-01-31T00:22:18Z",
        "lastEditedBy" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "tags" : [
        ]
      },
      {
        "id" : "c6110e43-fee3-46d5-a995-ff4575d7e0d2",
        "parentId" : "dfd783af-8871-4c26-801d-d4ca2bb9d772",
        "authorId" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "body" : "It is better code to have const. I can fix all of them if you can guide me to them.",
        "createdAt" : "2019-01-31T00:51:19Z",
        "updatedAt" : "2019-01-31T00:51:19Z",
        "lastEditedBy" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e78e8aa87eadeb7abb676be9ff3926a6a3865c5",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +887,891 @@                   &CheckedNarrowing<int64, int>);\n    bool propagate_nans = pooling_descriptor.propagate_nans();\n    auto cudnn_max_pooling_mode = RequireDeterminism()\n                                      ? CUDNN_POOLING_MAX_DETERMINISTIC\n                                      : CUDNN_POOLING_MAX;"
  },
  {
    "id" : "f29ddc66-76ad-4c2a-af03-2234d922294d",
    "prId" : 23588,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/23588#pullrequestreview-175988711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "038812b0-219a-4c92-89c0-dd1fe2f1bdab",
        "parentId" : null,
        "authorId" : "ed1418d4-e022-4541-929d-990e12851735",
        "body" : "This should become an constructor argument (and TF-op attribute) as unpacked layout supports both time and batch majored.",
        "createdAt" : "2018-11-15T20:12:28Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "ed1418d4-e022-4541-929d-990e12851735",
        "tags" : [
        ]
      },
      {
        "id" : "9fb01e06-b45c-4b74-8e17-c3e77d23263b",
        "parentId" : "038812b0-219a-4c92-89c0-dd1fe2f1bdab",
        "authorId" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "body" : "We planned to submit another PR to expose the data layout options.",
        "createdAt" : "2018-11-16T21:12:49Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "tags" : [
        ]
      },
      {
        "id" : "dcaa5abc-463e-4b22-a514-093b13629841",
        "parentId" : "038812b0-219a-4c92-89c0-dd1fe2f1bdab",
        "authorId" : "ed1418d4-e022-4541-929d-990e12851735",
        "body" : "Ok. I don't have strong opinion.",
        "createdAt" : "2018-11-16T21:31:46Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "ed1418d4-e022-4541-929d-990e12851735",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf46fa4c5225e853e602b0e18951884b08729163",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +1282,1286 @@    RETURN_IF_CUDNN_ERROR(cudnnSetRNNDataDescriptor(\n        /*RNNDataDesc=*/data_desc.get(), /*dataType*/ data_type,\n        /*layout=*/CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED,\n        /*maxSeqLength=*/max_seq_length,\n        /*batchSize=*/batch_size, /*vectorSize=*/data_size,"
  },
  {
    "id" : "9abcb5c2-5089-4ad3-899a-4859a8e184a0",
    "prId" : 23588,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/23588#pullrequestreview-181007038",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05ad9be9-4c8b-4924-87de-1014ff0664a5",
        "parentId" : null,
        "authorId" : "ed1418d4-e022-4541-929d-990e12851735",
        "body" : "When using CudnnRnn v1 and v2, we probably still don't want to set rnn padding mode since that mode only works with the standard algorithm. This probably need to be a constructor argument. And should raise compile time error if `enable_padded_io` is set to true and CUDNN_VERSION is < 7201.",
        "createdAt" : "2018-11-23T05:50:41Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "ed1418d4-e022-4541-929d-990e12851735",
        "tags" : [
        ]
      },
      {
        "id" : "8bd5850c-0822-41dc-b7ba-f03ec876e4a3",
        "parentId" : "05ad9be9-4c8b-4924-87de-1014ff0664a5",
        "authorId" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "body" : "The cudnnSetRNNPaddingMode will only allocate slightly more space. So, I think setting it when CUDNN_VERSION > 7.2.1 should be safe. But if using `enable_padded_io` parameter, many functions and header files need to be changed (e.g., CudnnRnnDescriptor::Create(), CudnnSupport::createRnnDescriptor(), ExtractCudnnRNNParamsInfo(),  CreateRnnDescriptor(), etc). Especially, createRnnDescriptor() and CreateRnnDescriptor() confuse me a lot.  I am not sure it is worth to do that.",
        "createdAt" : "2018-11-28T23:50:27Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "8df6b2a7-a5b8-4771-8241-49fd7ff5a2aa",
        "tags" : [
        ]
      },
      {
        "id" : "ba549d9f-410e-4ce5-835b-4682678bd183",
        "parentId" : "05ad9be9-4c8b-4924-87de-1014ff0664a5",
        "authorId" : "ed1418d4-e022-4541-929d-990e12851735",
        "body" : "The concern is, if setting padded io, non-standard algorithms wouldn't be supported.\r\nMaybe you could put a \"TODO\" here.",
        "createdAt" : "2018-12-03T22:24:33Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "ed1418d4-e022-4541-929d-990e12851735",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf46fa4c5225e853e602b0e18951884b08729163",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +1034,1038 @@    // But in the future if these APIs are used to process full length arrays, \n    // we need to distinguish when to set it.\n#if CUDNN_VERSION >= 7201\n    RETURN_IF_CUDNN_ERROR(\n        cudnnSetRNNPaddingMode(rnn_desc.get(), CUDNN_RNN_PADDED_IO_ENABLED));"
  },
  {
    "id" : "4e039c7d-9143-4244-b441-7c79a57bb192",
    "prId" : 23588,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/23588#pullrequestreview-181007038",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "563c4e42-a83e-422d-9ff8-825fad0f7638",
        "parentId" : null,
        "authorId" : "ed1418d4-e022-4541-929d-990e12851735",
        "body" : "We need a separate `CudnnSupport::createRnnSequenceTensorDescriptor()` for the extra `seq_lengths` param. It would be reflected in various layer wrappers, and in the end CudnnV3 will call the new create() function.",
        "createdAt" : "2018-12-03T23:02:55Z",
        "updatedAt" : "2018-12-18T03:44:04Z",
        "lastEditedBy" : "ed1418d4-e022-4541-929d-990e12851735",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf46fa4c5225e853e602b0e18951884b08729163",
    "line" : 458,
    "diffHunk" : "@@ -1,1 +1800,1804 @@\nport::StatusOr<std::unique_ptr<dnn::RnnSequenceTensorDescriptor>>\nCudnnSupport::createRnnSequenceTensorDescriptor(int max_seq_length, int batch_size,\n                                                int data_size,\n                                                dnn::DataType data_type) {"
  },
  {
    "id" : "351200c9-8805-4e8f-8da7-6615a5dcd650",
    "prId" : 2555,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4210f6dc-48dc-4419-b543-625fdb77f595",
        "parentId" : null,
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "Why is this needed?  We build with cudnnv4 right now and nothing was failing...\n",
        "createdAt" : "2016-05-28T15:54:57Z",
        "updatedAt" : "2016-05-28T18:03:44Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      },
      {
        "id" : "da66e06b-b61b-4310-997a-975fe0abad1f",
        "parentId" : "4210f6dc-48dc-4419-b543-625fdb77f595",
        "authorId" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "body" : "otherwise for CUDNNv4 and less  the `format` variable will be defined but not used (see the other block below:\n\n``` c++\n    status = dynload::cudnnSetFilterNdDescriptor(parent_, handle_, elem_type,\n#if CUDNN_VERSION >= 5000\n                                                 format,\n#endif\n                                                 dims.size(), dims.data());\n```\n",
        "createdAt" : "2016-05-28T17:35:47Z",
        "updatedAt" : "2016-05-28T18:03:44Z",
        "lastEditedBy" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "tags" : [
        ]
      }
    ],
    "commit" : "089c33eeb4742081c53f5bcee3eec0ccc59cc528",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +458,462 @@    }\n\n#if CUDNN_VERSION >= 5000\n    // TODO(b/23032134): Even if the filter layout is not supported,\n    // cudnnSetFilter4DDescriptor_v4 will return CUDNN_STATUS_SUCCESS because it"
  },
  {
    "id" : "57084452-6532-4bb2-aeb7-eb8e3001ccb5",
    "prId" : 2555,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbd65ecb-9c21-4df7-a07c-30bb9a35db65",
        "parentId" : null,
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "Let's revert this -- we don't want to crash the program -- we'd prefer to return a bad status message.\n",
        "createdAt" : "2016-05-28T15:55:25Z",
        "updatedAt" : "2016-05-28T18:03:44Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      },
      {
        "id" : "ebb4424e-6c3c-48c8-af7a-688057579373",
        "parentId" : "bbd65ecb-9c21-4df7-a07c-30bb9a35db65",
        "authorId" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "body" : "if the mode is unknown the fatal will be triggered anyway at the line 681 with a more generic message or be accepted with an undefined state. Is most likely an API programming error, isn't it better to just terminate the program ? \n",
        "createdAt" : "2016-05-28T17:36:05Z",
        "updatedAt" : "2016-05-28T18:03:44Z",
        "lastEditedBy" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "tags" : [
        ]
      },
      {
        "id" : "e54c8545-a1a2-40e3-90f6-d2722c4adc4b",
        "parentId" : "bbd65ecb-9c21-4df7-a07c-30bb9a35db65",
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "Good point, this class is not written very well.  One day we should probably refactor this so that we can check the status rather than just kill the program.\n",
        "createdAt" : "2016-05-28T20:29:01Z",
        "updatedAt" : "2016-05-28T20:29:01Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      }
    ],
    "commit" : "089c33eeb4742081c53f5bcee3eec0ccc59cc528",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +669,673 @@        break;\n      default:\n        LOG(FATAL) << \"unrecognized activation mode: \"\n                   << static_cast<int>(activation_mode);\n    }"
  },
  {
    "id" : "2981e4d6-105d-4c18-b0e9-51806bd0b272",
    "prId" : 664,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d209665e-e015-4485-a586-1f426241521f",
        "parentId" : null,
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "same here -- is there a similar check for the OS X side of things?\n",
        "createdAt" : "2016-04-25T02:38:08Z",
        "updatedAt" : "2016-04-27T06:43:33Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      },
      {
        "id" : "028c1883-76a1-49bc-a954-484f6b8fc859",
        "parentId" : "d209665e-e015-4485-a586-1f426241521f",
        "authorId" : "e314083e-794a-4ff7-b4a5-a00d72b0e046",
        "body" : "Agreed.  I haven't been able to find a public API for getting the kernel driver version that is reported by OSX CUDA preferences panel :(\n",
        "createdAt" : "2016-04-25T03:56:51Z",
        "updatedAt" : "2016-04-27T06:43:33Z",
        "lastEditedBy" : "e314083e-794a-4ff7-b4a5-a00d72b0e046",
        "tags" : [
        ]
      }
    ],
    "commit" : "e11c8b3dbd6ee4f3f4b3030916ec8efe356b34b3",
    "line" : null,
    "diffHunk" : "@@ -1,1 +316,320 @@      LOG(INFO) << \"running driver version: \" << DriverVersionToString(version);\n      // OS X kernel driver does not report version accurately\n#if !defined(__APPLE__)\n      if (std::get<0>(version) < 340) {\n        LOG(ERROR)"
  }
]