[
  {
    "id" : "5966f7e3-a9ad-4f7d-aeb2-bb90b6f7afd4",
    "prId" : 44175,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/44175#pullrequestreview-512830390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f67215c0-f024-450b-bbcf-5eae0d49efb4",
        "parentId" : null,
        "authorId" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "body" : "Is there any Nvidia documentation / bug we can refer to here, and add a comment / TODO?",
        "createdAt" : "2020-10-20T15:10:24Z",
        "updatedAt" : "2020-10-20T15:14:09Z",
        "lastEditedBy" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "tags" : [
        ]
      }
    ],
    "commit" : "aae59c53f4fb698e34d640c0ec6e90ddd826ff88",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +3337,3341 @@\n private:\n  // In some cases cublasLt does not support large batch sizes, so we need to\n  // split up such cases into multiple calls.\n  static constexpr const int kMaxBatchCount = 65535;"
  },
  {
    "id" : "3a87b46d-171a-40ee-99f6-dce626c6b0b3",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-78214504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6318c3c3-bcb4-4081-a703-a4c8c55ed564",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "Why do we need this? With RAII, can we do this in the constructor?",
        "createdAt" : "2017-11-10T00:53:57Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "b0e4b8c8-7732-4cea-b635-644b1b61e395",
        "parentId" : "6318c3c3-bcb4-4081-a703-a4c8c55ed564",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "The separate init function is used to better handle errors. This follows the existing approach used for ScopedCublasPointerMode.",
        "createdAt" : "2017-11-21T18:32:00Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +404,408 @@  // Note that when false is returned, an appropriate error has already been\n  // logged.\n  bool Init(cublasMath_t new_mode) {\n    cublasStatus_t ret = wrap::cublasGetMathMode(parent_, handle_, &old_mode_);\n    if (ret != CUBLAS_STATUS_SUCCESS) {"
  },
  {
    "id" : "6837f430-567a-4576-b343-03e3506b75e2",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-78214514",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3db2036c-f97c-4127-b38b-a31fef03ebf0",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "Add a TODO to propagate this error back to callers. TensorFlow wants to fail graceful when this happens. ",
        "createdAt" : "2017-11-10T00:54:42Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "0cc23e80-7543-49a7-8590-c211a375d14d",
        "parentId" : "3db2036c-f97c-4127-b38b-a31fef03ebf0",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "Propagation is already in place as the callers check for a false return value.",
        "createdAt" : "2017-11-21T18:32:02Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +413,417 @@    ret = wrap::cublasSetMathMode(parent_, handle_, new_mode);\n    if (ret != CUBLAS_STATUS_SUCCESS) {\n      LOG(ERROR) << \"failed to set new cublas math mode: \" << ToString(ret);\n      return ok_ = false;\n    }"
  },
  {
    "id" : "fde27eb5-c12b-4ef4-a03f-b6ca80808a21",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-78214534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f66c7e2-72cd-4909-aee3-38280e488e90",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "If the functions who will be affected by this is small, I'd rather not to call it at all by most of them.\r\n",
        "createdAt" : "2017-11-10T00:57:28Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "aaf06a6b-6b69-467a-b77b-9589705624ba",
        "parentId" : "3f66c7e2-72cd-4909-aee3-38280e488e90",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "OK. We'll only call init when tensor-ops are needed.",
        "createdAt" : "2017-11-21T18:32:07Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +625,629 @@  }\n#if CUDA_VERSION >= 9000\n  ScopedCublasMathMode math_mode{parent_, blas_};\n  if (use_tensor_op_math) {\n    if (!math_mode.Init(CUBLAS_TENSOR_OP_MATH)) {"
  },
  {
    "id" : "bbfaf200-d035-4f90-9695-a206351737c8",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-78278929",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d31c5426-9c5b-49ec-b85b-dc1206fa3bdb",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "I'm not a big fan of parsing env-var on every matmul-calls. Either cache this globally, or have the caller cache it and pass it in. \r\n\r\nThe problem with a global setting is that you will have to test it separately. Since there is no way to unset it to not affect other tests. \r\n\r\nWith TF, this can be cached at the op construction time, and therefore save the trouble.",
        "createdAt" : "2017-11-10T01:01:14Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "8107e139-0804-4ddb-95a6-9890fd478838",
        "parentId" : "d31c5426-9c5b-49ec-b85b-dc1206fa3bdb",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "The env-var is only checked on first access. TensorOpMathEnabled() caches the return value in a static variable.",
        "createdAt" : "2017-11-21T18:32:14Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      },
      {
        "id" : "70136530-d413-4c0e-b44a-382da6164e5e",
        "parentId" : "d31c5426-9c5b-49ec-b85b-dc1206fa3bdb",
        "authorId" : "7cf62659-8336-47b5-841a-36e5ae153b44",
        "body" : "I think you'd have to also add this code to DoBlasGemmWithProfiling() and DoBlasGemmWithAlgorithm() for fp16, so that it can also be used when turning on autotune.",
        "createdAt" : "2017-11-21T22:41:51Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "7cf62659-8336-47b5-841a-36e5ae153b44",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +1856,1860 @@\n  // GPUs < sm_70 don't support tensor cores\n  if (cc_major >= 7 && TensorOpMathEnabled()) {\n    use_tensor_ops = true;\n  }"
  },
  {
    "id" : "d4495fce-3e92-4674-9b04-313b6b9498b3",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-82655882",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f1cffc9-f2d3-4cbe-8b56-3083c4887660",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "What's the point of having a lambda and evaluate it right away?",
        "createdAt" : "2017-12-05T23:03:18Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "20be77e0-eacc-4bbf-bb51-7cb327d3389a",
        "parentId" : "6f1cffc9-f2d3-4cbe-8b56-3083c4887660",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "This allows the static is_enabled to be set inline.",
        "createdAt" : "2017-12-11T22:08:34Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +308,312 @@// Decide whether to enable TENSOR_OP_MATH\nstatic bool TensorOpMathEnabled() {\n  static bool is_enabled = [] {\n    bool is_disabled;\n    TF_CHECK_OK("
  },
  {
    "id" : "71374e8a-9306-4d8f-b2bd-74682b5003d0",
    "prId" : 13451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13451#pullrequestreview-82656058",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e10d706-fb33-4079-a24b-05203978fa5c",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "Could you split the list into its own function? So we know to update them, or even auto-gen them from the header file.",
        "createdAt" : "2017-12-05T23:12:03Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "f62828f1-70fd-4b98-932f-0ba9bad251fb",
        "parentId" : "9e10d706-fb33-4079-a24b-05203978fa5c",
        "authorId" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "body" : "I'm not sure what is being suggested here. The current function seems pretty clean to me. Do you envision separate functions for CUBLAS 8 vs. 9 algos, or separate function for tensor op vs. non tensor op algos. Either of these would make the API higher up the stack more complicated.",
        "createdAt" : "2017-12-11T22:09:13Z",
        "updatedAt" : "2017-12-13T19:25:08Z",
        "lastEditedBy" : "8ff4e099-8cf6-4348-9db7-45b9bc9150c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "80d3e858255e1d829b927b5996b5cce091b390ec",
    "line" : 212,
    "diffHunk" : "@@ -1,1 +2221,2225 @@#if CUDA_VERSION >= 8000\n  for (cublasGemmAlgo_t algo : {\n         CUBLAS_GEMM_DFALT, CUBLAS_GEMM_ALGO0, CUBLAS_GEMM_ALGO1,\n             CUBLAS_GEMM_ALGO2, CUBLAS_GEMM_ALGO3, CUBLAS_GEMM_ALGO4,\n             CUBLAS_GEMM_ALGO5, CUBLAS_GEMM_ALGO6, CUBLAS_GEMM_ALGO7,"
  },
  {
    "id" : "a03e6687-5a00-4c88-abf2-cb68e73f713d",
    "prId" : 2556,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0767f2f-cc96-4182-8215-3889d619af74",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "This seems fine with me too. \n\nThe downside is that it introduces an outdated symbol back into CUBLAS space, which might interact with other code when we move it around. I would second vrv@'s suggestion that it is better to have our own symbol that is conditionally defined.\n\nI will leave it up to you whether you want to follow through in this CL. \n",
        "createdAt" : "2016-05-31T17:38:22Z",
        "updatedAt" : "2016-06-02T09:12:28Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "14b68ee9-5c0a-4e65-b831-044bbd9b13af",
        "parentId" : "c0767f2f-cc96-4182-8215-3889d619af74",
        "authorId" : "3c1b6f5d-3c0c-478d-a373-96d915903ba4",
        "body" : "I will make the change in another pull request if that is ok?\n",
        "createdAt" : "2016-06-01T05:21:47Z",
        "updatedAt" : "2016-06-02T09:12:28Z",
        "lastEditedBy" : "3c1b6f5d-3c0c-478d-a373-96d915903ba4",
        "tags" : [
        ]
      }
    ],
    "commit" : "f488a4902bafe0f5ad266ea3f52603d6507467f9",
    "line" : null,
    "diffHunk" : "@@ -1,1 +31,35 @@#define SE_CUDA_DATA_HALF CUBLAS_DATA_HALF\n#endif\n\n#include \"tensorflow/stream_executor/cuda/cuda_blas.h\"\n"
  }
]