[
  {
    "id" : "c2899b45-0bdb-4710-9037-f4e9ef663c05",
    "prId" : 46399,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/46399#pullrequestreview-567526118",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56f8727d-2bef-4990-8dc1-6ec30e12a5de",
        "parentId" : null,
        "authorId" : "5729d906-4981-47d8-8a16-0c5af0b868d2",
        "body" : "I'd recommend adding comment to turn off an internal mdformat tool:\r\nhttps://github.com/tensorflow/tensorflow/blob/78fdd635abb65422c5a4b72750e9fafccf8bee61/tensorflow/lite/micro/docs/memory_management.md#L1\r\n\r\nto avoid being surprised by some auto-formatting.",
        "createdAt" : "2021-01-13T18:55:40Z",
        "updatedAt" : "2021-01-18T15:58:48Z",
        "lastEditedBy" : "5729d906-4981-47d8-8a16-0c5af0b868d2",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a3b0fbfda0f1ef47a58ce31d8eba338c513fe6a",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +16,20 @@<!--te-->\n\n# Pre-allocated tensors\n## Background\nTensors are allocated differently depending on the type of tensor. Weight tensors are located in the flatbuffer, which is allocated by the application that calls TensorFlow Lite Micro. EvalTensors are allocated in the tensor arena, either offline planned as specified in the flatbuffers metadata (described in this [RFC](https://docs.google.com/document/d/16aTSHL5wxsq99t6adVbBz1U3K8Y5tBDAvs16iroZDEU)), or allocated during runtime by the [memory planner](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/memory_planner) (online planned), see [RFC](https://docs.google.com/document/d/1akpqu0uiPQshmCrnV6dOEFgYM4tCCnI8Zce85PnjHMI)."
  }
]