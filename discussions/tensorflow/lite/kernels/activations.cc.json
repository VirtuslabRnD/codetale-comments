[
  {
    "id" : "c0bb230e-32e4-4500-b4e7-47b6b4e33e19",
    "prId" : 43148,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/43148#pullrequestreview-496154437",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f134473-48d5-49ae-80f2-e26ec189a816",
        "parentId" : null,
        "authorId" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "body" : "Could you please keep this Int16 support? I think this is added to support some use case.",
        "createdAt" : "2020-09-24T15:41:08Z",
        "updatedAt" : "2020-09-24T15:41:35Z",
        "lastEditedBy" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "tags" : [
        ]
      },
      {
        "id" : "782b15a7-5b47-4b30-82c8-15053486efb1",
        "parentId" : "7f134473-48d5-49ae-80f2-e26ec189a816",
        "authorId" : "5449a69d-7f99-4886-9908-47affbac272a",
        "body" : "It seems that `PreluEval` only supports outputs of type `float`, `uint8_t` and `int8_t`. Do you know in which cases we could have a Prelu with an int16 output?",
        "createdAt" : "2020-09-24T15:48:25Z",
        "updatedAt" : "2020-09-24T15:59:48Z",
        "lastEditedBy" : "5449a69d-7f99-4886-9908-47affbac272a",
        "tags" : [
        ]
      },
      {
        "id" : "19638e7a-3e4e-4e81-aa2e-ca41035b984d",
        "parentId" : "7f134473-48d5-49ae-80f2-e26ec189a816",
        "authorId" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "body" : "Ah, you are right, the eval function does not handle int16. Thanks for the change.",
        "createdAt" : "2020-09-25T06:55:12Z",
        "updatedAt" : "2020-09-25T06:56:38Z",
        "lastEditedBy" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d9820e8f00a0332471ba37eea148fde4d885a57",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +686,690 @@  output->type = input->type;\n\n  if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {\n    // prelu(x) = x if x >= 0 else x * alpha.\n    // So if we translate that for quantized computation:"
  },
  {
    "id" : "dfeb91af-fbc3-4bac-87c2-4291f822135e",
    "prId" : 42671,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/42671#pullrequestreview-491977247",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d87b8ca-2085-4e14-bf45-c8ca0bc6ceba",
        "parentId" : null,
        "authorId" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "body" : "can you explain more about how the math works here in the comments?\r\n\r\nthanks",
        "createdAt" : "2020-08-31T23:29:48Z",
        "updatedAt" : "2020-10-28T16:48:46Z",
        "lastEditedBy" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "tags" : [
        ]
      },
      {
        "id" : "67403e1d-f810-4fd7-b994-3746b1540549",
        "parentId" : "0d87b8ca-2085-4e14-bf45-c8ca0bc6ceba",
        "authorId" : "44d28fc5-28b1-4fbb-b2f4-273674b18507",
        "body" : "Hi @renjie-liu Sorry for the delay with the reply. I missed the comment.\r\n\r\nThe initial implementation has been updated to have a general input scale, so we introduced this scaling factor 1/4096 (from 16-bit to [-8, 8]), but the change allows only integer multipliers of the 1/4096 scaling factor. Here we do:\r\ndata->input_multiplier = static_cast<int32_t>(input->params.scale * 4096);\r\nand then\r\nint32_t input_data_mul = (input_multiplier > 0) ? input_multiplier : 1;\r\nSo, the scaling should be multiple of 1/4096.\r\n\r\nThis fix is to handle general case.\r\nThe number 3.0 in the multiplier comes from here, because the interval is [-10.7, 10.7] instead of [-8, 8]\r\nhttps://github.com/tensorflow/tensorflow/pull/42671/files#diff-7ae159b53f418105dff8194481058709R66\r\nThe numbers are activations_test.cc are identical to values from the calculator with this change.\r\n\r\n",
        "createdAt" : "2020-09-14T10:47:59Z",
        "updatedAt" : "2020-10-28T16:48:46Z",
        "lastEditedBy" : "44d28fc5-28b1-4fbb-b2f4-273674b18507",
        "tags" : [
        ]
      },
      {
        "id" : "a15db5c6-8b8e-447d-bfd8-4f1ccbfe1b7d",
        "parentId" : "0d87b8ca-2085-4e14-bf45-c8ca0bc6ceba",
        "authorId" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "body" : "thanks, it would be great to add to the comments",
        "createdAt" : "2020-09-19T07:02:22Z",
        "updatedAt" : "2020-10-28T16:48:46Z",
        "lastEditedBy" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "tags" : [
        ]
      }
    ],
    "commit" : "595c3e3d1348d43e7aad994bddd68ee6b735f068",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +436,440 @@\n    if (!param_scale_pot) {\n      // Calculate multiplier to change input scale to 1/(3*4096)\n      // as required by the table lookup.\n      // The number 3.0 in the multiplier comes from here, "
  },
  {
    "id" : "546e6cd1-9b0b-4e0f-b8b8-c2a7cb8b4b64",
    "prId" : 42671,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/42671#pullrequestreview-567330459",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1542c3e4-8060-4c7c-a304-728849b8ee40",
        "parentId" : null,
        "authorId" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "body" : "looks like this can be replaced with a std::frexp.",
        "createdAt" : "2020-09-19T07:04:38Z",
        "updatedAt" : "2020-10-28T16:48:46Z",
        "lastEditedBy" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "tags" : [
        ]
      },
      {
        "id" : "305b61b6-73d1-4a09-abde-3ae95a13e3cf",
        "parentId" : "1542c3e4-8060-4c7c-a304-728849b8ee40",
        "authorId" : "5b3a04f9-28e3-44da-80c1-3636e911cd91",
        "body" : "As @renjie-liu suggested, could this be replaced by `std::frexp` ?\r\n(something like `multiplier =  std::frexp(multiplier, &data->input_left_shift)` ?)\r\n\r\nThis also applies to same logic at line 550",
        "createdAt" : "2020-12-15T14:46:02Z",
        "updatedAt" : "2020-12-15T14:48:09Z",
        "lastEditedBy" : "5b3a04f9-28e3-44da-80c1-3636e911cd91",
        "tags" : [
        ]
      },
      {
        "id" : "8eea895f-e3a7-44b8-9e9a-418e8a75c6ac",
        "parentId" : "1542c3e4-8060-4c7c-a304-728849b8ee40",
        "authorId" : "44d28fc5-28b1-4fbb-b2f4-273674b18507",
        "body" : "Hi @fredrec Sorry for the late reply.\r\nThis block can't be replaced with this function, because frexp breaks in double significant and exponent, but we need int16 here.\r\nfor example,\r\n4.125 should be \r\nmultiplier: 16896\r\ninput left shift: 12\r\nbut if I apply frexp, then the result is 0.515625 and 3.\r\n\r\nThanks for the review!",
        "createdAt" : "2021-01-13T15:22:35Z",
        "updatedAt" : "2021-01-13T15:22:36Z",
        "lastEditedBy" : "44d28fc5-28b1-4fbb-b2f4-273674b18507",
        "tags" : [
        ]
      }
    ],
    "commit" : "595c3e3d1348d43e7aad994bddd68ee6b735f068",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +445,449 @@      data->input_left_shift = 0;\n\n      while (multiplier <= 32767.0 / 2.0 && data->input_left_shift <= 30) {\n         data->input_left_shift++;\n         multiplier = multiplier * 2.0;"
  },
  {
    "id" : "c3d4648c-1e60-476f-a3d0-bc1379da6a0c",
    "prId" : 37279,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37279#pullrequestreview-369334035",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c83eb93-73fe-4b26-ba8c-cd2a81fc2357",
        "parentId" : null,
        "authorId" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "body" : "can you either use int or int32_t for consistency? thanks",
        "createdAt" : "2020-03-05T06:23:44Z",
        "updatedAt" : "2020-03-05T08:47:25Z",
        "lastEditedBy" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "tags" : [
        ]
      },
      {
        "id" : "c52fbe21-abd5-4d52-bb03-b7f0074a43cc",
        "parentId" : "6c83eb93-73fe-4b26-ba8c-cd2a81fc2357",
        "authorId" : "3ecac61d-84a1-4b2b-aa0b-281ca74e397b",
        "body" : "No problem. All switched to int32_t. Just a note, `MultiplyByQuantizedMultiplier` and `QuantizeMultiplier` use mixture of int and int32(_t), not sure if it is intended.",
        "createdAt" : "2020-03-05T07:04:13Z",
        "updatedAt" : "2020-03-05T08:47:25Z",
        "lastEditedBy" : "3ecac61d-84a1-4b2b-aa0b-281ca74e397b",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a9afb8b2726324244a143362622660cd8a070c",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +77,81 @@\nstruct LeakyReluOpData : public OpData {\n  int32_t output_multiplier_alpha = 0;\n  int32_t output_shift_alpha = 0;\n  int32_t output_multiplier_identity = 0;"
  },
  {
    "id" : "464506ff-3600-4e62-a9ea-57faf22c20fb",
    "prId" : 27131,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27131#pullrequestreview-218982353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22900c1e-cfdc-40b4-952d-9139cc359e4f",
        "parentId" : null,
        "authorId" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "body" : "return kTfLiteOk?",
        "createdAt" : "2019-03-26T14:54:54Z",
        "updatedAt" : "2019-03-27T15:31:43Z",
        "lastEditedBy" : "0a35de17-09bf-47a1-9bfa-84c0a8c63acb",
        "tags" : [
        ]
      },
      {
        "id" : "ee243bf2-8fbf-42a6-8a80-bc35fd4e0ca0",
        "parentId" : "22900c1e-cfdc-40b4-952d-9139cc359e4f",
        "authorId" : "71aa83b5-0dc7-445e-852e-6207307652b2",
        "body" : "@renjie-liu , thanks for pointing this out, i have updated the code as per the comments, Kindly check and approve.\r\n\r\nRegards\r\nAmit",
        "createdAt" : "2019-03-26T15:43:02Z",
        "updatedAt" : "2019-03-27T15:31:43Z",
        "lastEditedBy" : "71aa83b5-0dc7-445e-852e-6207307652b2",
        "tags" : [
        ]
      }
    ],
    "commit" : "52d1af8c2920f7be17bd3d094f4e64deb4d7647c",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +335,339 @@    case kTfLiteFloat32: {\n      optimized_ops::Relu(GetTensorShape(input), GetTensorData<float>(input),\n                          GetTensorShape(output), GetTensorData<float>(output));\n      return kTfLiteOk;\n    } break;"
  },
  {
    "id" : "05d71bd7-87ca-446d-9059-390030fb36c5",
    "prId" : 27061,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27061#pullrequestreview-223107242",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21ee813e-a950-4879-bc8b-efdc6f02c136",
        "parentId" : null,
        "authorId" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "body" : "Sorry but I am a bit confused about this logic, why are there two input->params.scale?\r\n\r\nAlso, I think you can merge the logic of q_alpha here as well so in the kernel you can change\r\nparams.output_offset + MultiplyByQuantizedMultiplierSmallerThanOneExp(\r\n                                     input_value * alpha_value,\r\n                                     params.output_multiplier,\r\n                                     params.output_shift)\r\nto \r\nparams.output_offset + MultiplyByQuantizedMultiplierSmallerThanOneExp(\r\n                                     input_value,\r\n                                     params.output_multiplier,\r\n                                     params.output_shift)",
        "createdAt" : "2019-04-05T03:55:30Z",
        "updatedAt" : "2019-04-28T10:44:18Z",
        "lastEditedBy" : "c14be44a-1748-4d93-a075-2bb17587c151",
        "tags" : [
        ]
      },
      {
        "id" : "91d5bae0-a23b-4913-a8e2-020531e2c2a0",
        "parentId" : "21ee813e-a950-4879-bc8b-efdc6f02c136",
        "authorId" : "71aa83b5-0dc7-445e-852e-6207307652b2",
        "body" : "@jianlijianli thanks for the review, the logic of two input->params.scale is in sync with the formula as i have quantized the alpha using the same scale as of input, so real multipler will be \r\n((input A scale * input B scale) / output scale). I hope this is ok.\r\n\r\nAbout your last part of the comment i could not understand. Can you be more specific as i have to multiply the updated alpha value to input for Leaky relu to produce a correct output.\r\n\r\nRegdrs\r\nAmit\r\n",
        "createdAt" : "2019-04-05T05:54:58Z",
        "updatedAt" : "2019-04-28T10:44:18Z",
        "lastEditedBy" : "71aa83b5-0dc7-445e-852e-6207307652b2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d08f26fea6e43c51f17fb671feafe2bfd36a78a",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +147,151 @@\n    double real_multiplier =\n        input->params.scale * input->params.scale / output->params.scale;\n    QuantizeMultiplierSmallerThanOneExp(\n        real_multiplier, &data->output_multiplier, &data->output_shift);"
  },
  {
    "id" : "01ac44e3-e3f8-4676-b34d-b6bb7909bd59",
    "prId" : 26008,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/26008#pullrequestreview-239173897",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be837ed9-e33d-4d2c-8919-b7806aafa189",
        "parentId" : null,
        "authorId" : "7366ec07-24db-4972-bd02-7729e5975f20",
        "body" : "nit: Please replace Int8_t with int8_t.",
        "createdAt" : "2019-05-18T00:14:24Z",
        "updatedAt" : "2019-05-18T00:14:24Z",
        "lastEditedBy" : "7366ec07-24db-4972-bd02-7729e5975f20",
        "tags" : [
        ]
      }
    ],
    "commit" : "717c6cf5d68a4a6fa3b62ff081ec0581364e2afe",
    "line" : 341,
    "diffHunk" : "@@ -1,1 +644,648 @@      context->ReportError(\n          context,\n          \"Only float32, uint8_t and Int8_t are supported currently, got %s.\",\n          TfLiteTypeGetName(input->type));\n      return kTfLiteError;"
  }
]