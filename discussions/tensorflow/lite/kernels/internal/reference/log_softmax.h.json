[
  {
    "id" : "9c800e98-74d6-4d22-94e6-0582a2658c18",
    "prId" : 47482,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47482#pullrequestreview-630602019",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb87ab76-e235-47e1-8cc5-e1f427e5ebfe",
        "parentId" : null,
        "authorId" : "dc2d2e0c-b690-4812-96e8-4d9e58f7d2e1",
        "body" : "How about creating this change separately? It would be better to split this big change into two, one for refactoring and one for quantization addition in order to make the overall code review procedure easier and faster.",
        "createdAt" : "2021-03-01T21:12:26Z",
        "updatedAt" : "2021-04-07T21:04:58Z",
        "lastEditedBy" : "dc2d2e0c-b690-4812-96e8-4d9e58f7d2e1",
        "tags" : [
        ]
      },
      {
        "id" : "e452c68c-1071-4d13-897b-b8540eb7f953",
        "parentId" : "eb87ab76-e235-47e1-8cc5-e1f427e5ebfe",
        "authorId" : "ee0a2af8-6b35-454a-8a96-7865a54e572d",
        "body" : "After discussion with Pete Warden, we have decided it is OK to continue with the PRs as currently submitted.",
        "createdAt" : "2021-04-07T21:07:38Z",
        "updatedAt" : "2021-04-07T21:07:39Z",
        "lastEditedBy" : "ee0a2af8-6b35-454a-8a96-7865a54e572d",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0bf1d9a1e343f609d60e15d638c157f1a584512",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +151,155 @@                                T* output_data) {\n  const int32_t input_multiplier = params.input_multiplier;\n  const int32_t input_left_shift = params.input_left_shift;\n  const int32_t reverse_scaling_divisor = params.reverse_scaling_divisor;\n  const int32_t reverse_scaling_right_shift ="
  },
  {
    "id" : "08528c97-3f77-4df7-b8c7-4d1562597d15",
    "prId" : 47477,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47477#pullrequestreview-635066745",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae122bef-a28a-4a29-bc96-264d0479c270",
        "parentId" : null,
        "authorId" : "2424ca1f-2171-47cc-b401-ceb61b6f3fde",
        "body" : "This is a slightly surprising change - I just wanted to check that it was deliberate?",
        "createdAt" : "2021-04-13T16:19:28Z",
        "updatedAt" : "2021-04-13T22:13:03Z",
        "lastEditedBy" : "2424ca1f-2171-47cc-b401-ceb61b6f3fde",
        "tags" : [
        ]
      },
      {
        "id" : "ee686dd0-77ee-4f7d-a9b7-bb7564367099",
        "parentId" : "ae122bef-a28a-4a29-bc96-264d0479c270",
        "authorId" : "ee0a2af8-6b35-454a-8a96-7865a54e572d",
        "body" : "Yes that is intentional.  I saved 4 bytes during Init phase by not storing the zero point.  The correct zero point for output is checked during the Prepare phase.  So the zero point will always match kMaxT8 when calling this template.",
        "createdAt" : "2021-04-13T22:11:03Z",
        "updatedAt" : "2021-04-13T22:13:03Z",
        "lastEditedBy" : "ee0a2af8-6b35-454a-8a96-7865a54e572d",
        "tags" : [
        ]
      }
    ],
    "commit" : "ad5fa40cb51f133847096acb58a615867ebfe98c",
    "line" : 182,
    "diffHunk" : "@@ -1,1 +229,233 @@                (input_diff_in_q5 - log_sum_of_exps_in_q5),\n                31 - kInputIntegerBits - kOutputIntegerBits) +\n            kMaxT8;\n\n        output_in_q27 ="
  }
]