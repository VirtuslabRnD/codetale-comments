[
  {
    "id" : "02c24917-c847-4389-9d18-5be63a1f54d8",
    "prId" : 43617,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/43617#pullrequestreview-520487685",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42d7667b-4049-4b77-920b-9d729ea87f33",
        "parentId" : null,
        "authorId" : "5b3a04f9-28e3-44da-80c1-3636e911cd91",
        "body" : "Why are the int16 quatization test excluded ?",
        "createdAt" : "2020-10-30T09:00:38Z",
        "updatedAt" : "2020-10-30T09:01:15Z",
        "lastEditedBy" : "5b3a04f9-28e3-44da-80c1-3636e911cd91",
        "tags" : [
        ]
      },
      {
        "id" : "e57df688-01bf-49b2-962d-c1dffc4aaebd",
        "parentId" : "42d7667b-4049-4b77-920b-9d729ea87f33",
        "authorId" : "5449a69d-7f99-4886-9908-47affbac272a",
        "body" : "From what I understand 16-bit tests are not supported by the tested accelerators (see other int16 exclusions in [acceleration_test_list.cc](https://github.com/tensorflow/tensorflow/blob/3581a0db862931065353e4285a1c6810ea70743e/tensorflow/lite/delegates/nnapi/acceleration_test_list.cc#L284) or https://github.com/tensorflow/tensorflow/pull/35997#issuecomment-611223883).",
        "createdAt" : "2020-10-30T09:14:08Z",
        "updatedAt" : "2020-10-30T09:14:22Z",
        "lastEditedBy" : "5449a69d-7f99-4886-9908-47affbac272a",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d7f963f7b570944212082ab97c135aed887e060",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +60,64 @@QuantizedActivationsOpTest/HardSwish\nQuantizedActivationsOpTest/HardSwishBias\nQuantizedActivationsOpTest/Relu.+nt8\nQuantizedActivationsOpTest/PRelu,29\nQuantizedActivationsOpTest/PReluSameShapes,29"
  }
]