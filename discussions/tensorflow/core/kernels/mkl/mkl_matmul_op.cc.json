[
  {
    "id" : "dd5afe43-9cd3-4718-a4b6-e48016655829",
    "prId" : 47577,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47577#pullrequestreview-616853515",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2f0e960-f8fb-4e58-aeb9-017f598b622a",
        "parentId" : null,
        "authorId" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "body" : "Nit: `based on` appears twice.\r\n```suggestion\r\n    // the kernel single threaded. Here we are coming up with a cost model based\r\n    // on L1 sizes. If we find that matrices are small enough, we will\r\n```",
        "createdAt" : "2021-03-19T23:56:00Z",
        "updatedAt" : "2021-03-20T00:12:36Z",
        "lastEditedBy" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "tags" : [
        ]
      }
    ],
    "commit" : "96930b5ea3ecbe514e9c40974259d82c7554415f",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +161,165 @@    // execution for small kernel sizes. For such sizes, it may be better to run\n    // the kernel single threaded. Here we are coming up with a cost model based\n    // on based on L1 sizes. If we find that matrices are small enough, we will\n    // execute single threaded. This may need tuning.\n    bool single_threaded = ExecuteSingleThreadedGemm(m, n, k);"
  },
  {
    "id" : "6842656b-60d5-4690-8b27-a82149e59104",
    "prId" : 47577,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47577#pullrequestreview-616853515",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b405dba7-a444-437a-a6a1-e77df3050f8e",
        "parentId" : null,
        "authorId" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "body" : "Nit: The call is short enough and the result is only used once. I don't think we need a variable for it.",
        "createdAt" : "2021-03-19T23:57:57Z",
        "updatedAt" : "2021-03-20T00:12:36Z",
        "lastEditedBy" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "tags" : [
        ]
      }
    ],
    "commit" : "96930b5ea3ecbe514e9c40974259d82c7554415f",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +163,167 @@    // on based on L1 sizes. If we find that matrices are small enough, we will\n    // execute single threaded. This may need tuning.\n    bool single_threaded = ExecuteSingleThreadedGemm(m, n, k);\n    if (!single_threaded) {\n      dnnl::threadpool_interop::sgemm(char_transa, char_transb, m, n, k, alpha,"
  },
  {
    "id" : "4141bdcc-2a90-44f6-be59-99699fc927f3",
    "prId" : 47577,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47577#pullrequestreview-616853515",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe2f8176-b6a5-4fc8-8b22-343d595109d6",
        "parentId" : null,
        "authorId" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "body" : "Nit: Can we swap the logic? E.g., start with single-threaded first so we don't have to negate the condition?\r\n```c++\r\nif (ExecuteSingleThreadedGemm(m, n, k)) {\r\n  ...  // nullptr for thread pool\r\n} else {\r\n  ...  // &eigen_tp\r\n}\r\n```",
        "createdAt" : "2021-03-19T23:59:15Z",
        "updatedAt" : "2021-03-20T00:12:36Z",
        "lastEditedBy" : "72acf7f0-6473-4b57-a71f-2a44410818c5",
        "tags" : [
        ]
      }
    ],
    "commit" : "96930b5ea3ecbe514e9c40974259d82c7554415f",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +171,175 @@      dnnl::threadpool_interop::sgemm(char_transa, char_transb, m, n, k, alpha,\n                                      a, lda, b, ldb, beta, c, ldc, nullptr);\n    }\n#else\n    dnnl_sgemm(char_transa, char_transb, m, n, k, alpha, a, lda, b, ldb, beta,"
  }
]