[
  {
    "id" : "fb5c8164-555c-438e-9db1-2d4dce65c3c5",
    "prId" : 16784,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/16784#pullrequestreview-106686643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f420fe6-1df1-47fa-8091-d2a297e1ee0f",
        "parentId" : null,
        "authorId" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "body" : "Could you please verify that the presence of the extra broadcast expression does not affect performance in the trivial case? If it does, perhaps we should have a separate code path for that. This is a pretty performance critical op for many models.",
        "createdAt" : "2018-02-07T18:05:19Z",
        "updatedAt" : "2018-03-24T01:22:01Z",
        "lastEditedBy" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "tags" : [
        ]
      },
      {
        "id" : "4027f618-0a7d-4da4-af7d-246216b40863",
        "parentId" : "2f420fe6-1df1-47fa-8091-d2a297e1ee0f",
        "authorId" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "body" : "Thanks @rmlarsen. I added zero dimensions and single classes for benchmark. No significant performance changes so far:\r\n\r\nBefore:\r\n```\r\nBenchmark: zero_dimension_m_128_n_100000_k_100000_use_gpu_False \t wall_time: 0.000133 s \t Throughput: 96.2 GB/s\r\n\r\nBenchmark: single_class_m_128_n_100000_k_100000_use_gpu_False \t wall_time: 0.000131 s \t Throughput: 97.6 GB/s\r\n\r\n```\r\n\r\nAfter:\r\n```\r\nBenchmark: zero_dimension_m_128_n_100000_k_100000_use_gpu_False \t wall_time: 0.000135 s \t Throughput: 94.7 GB/s\r\n\r\nBenchmark: single_class_m_128_n_100000_k_100000_use_gpu_False \t wall_time: 0.000133 s \t Throughput: 96.4 GB/s\r\n```",
        "createdAt" : "2018-03-24T02:22:25Z",
        "updatedAt" : "2018-03-24T02:22:25Z",
        "lastEditedBy" : "04d6768a-662f-42f5-9152-0bb9c7d64855",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f37ebe74529bba07954eade1d51862c7887123a",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +94,98 @@\n    // max_logits along classes.\n    scratch.reshape(batch_only).device(d) =\n        logits.broadcast(logits_bcast).maximum(along_class);\n"
  }
]