[
  {
    "id" : "ee5020f5-45da-4be4-a217-060bd3319901",
    "prId" : 13905,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13905#pullrequestreview-71285997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "068f1ae1-0c02-4589-874d-3b15b51a893e",
        "parentId" : null,
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "Everything that doesn't need to publicly exposed should be in anonymous namespace.",
        "createdAt" : "2017-10-23T18:35:21Z",
        "updatedAt" : "2017-11-02T22:03:25Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      }
    ],
    "commit" : "1ec44ca2fe337eccc043fe41171316e8b05a8c8a",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +49,53 @@\ntypedef Eigen::GpuDevice GPUDevice;\n\nnamespace {\n"
  },
  {
    "id" : "87a2e19f-ee30-4908-8a88-bc413b88fdb3",
    "prId" : 13905,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13905#pullrequestreview-71285997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a10950c-e96a-4402-989a-ac0d3add57e3",
        "parentId" : null,
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "Please use GetCudaStream to get the stream instead; there are some edge cases with async ops that it handles better.  We ran into these problems with the GPU version of the where op.",
        "createdAt" : "2017-10-23T18:55:46Z",
        "updatedAt" : "2017-11-02T22:03:25Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      }
    ],
    "commit" : "1ec44ca2fe337eccc043fe41171316e8b05a8c8a",
    "line" : 230,
    "diffHunk" : "@@ -1,1 +228,232 @@    // In order to allocate the output tensor we have to move partition_count\n    // to CPU.\n    auto* stream = c->op_device_context()->stream();\n    OP_REQUIRES_ASYNC(c, stream, errors::Internal(\"No GPU stream available.\"),\n                      done);"
  },
  {
    "id" : "8bd14425-61c2-4342-a8cc-a1ea300435a8",
    "prId" : 13905,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13905#pullrequestreview-71285997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e564c29-6d52-4987-ad74-65be24c39882",
        "parentId" : null,
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "Could you also write a note at the top explaining the general approach that is going to be used.",
        "createdAt" : "2017-10-23T18:57:37Z",
        "updatedAt" : "2017-11-02T22:03:25Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      }
    ],
    "commit" : "1ec44ca2fe337eccc043fe41171316e8b05a8c8a",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +45,49 @@#include \"tensorflow/core/kernels/gather_functor_gpu.cu.h\"\n#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n\nnamespace tensorflow {\n"
  },
  {
    "id" : "0aec9244-fbd6-4acb-a1bc-cac38ec28488",
    "prId" : 13905,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/13905#pullrequestreview-75852968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c25951f-9c94-4486-a400-984a47973244",
        "parentId" : null,
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "Just looking at this again and realized there is a faster / less custom code way of determining the partition counts:  use reduce_by_key from cub: http://nvlabs.github.io/cub/structcub_1_1_device_reduce.html#a303ae673ac32825f95912b4bfff8bef1\r\n\r\nThe sorted partitions would be the keys and a constant_iterator of 1 would be the values.  It should do less passes over the memory than the current implementation.  Not critical though, so do it if you find it interesting.",
        "createdAt" : "2017-11-04T00:30:14Z",
        "updatedAt" : "2017-11-04T00:30:15Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      },
      {
        "id" : "76d72deb-7c21-4510-b993-8ee83adc5400",
        "parentId" : "2c25951f-9c94-4486-a400-984a47973244",
        "authorId" : "ea2f4d83-2f06-4ca2-a151-402c4480fa46",
        "body" : "You are right, that's a better way of doing things. I will create a separate PR for this.",
        "createdAt" : "2017-11-05T16:19:32Z",
        "updatedAt" : "2017-11-05T16:19:32Z",
        "lastEditedBy" : "ea2f4d83-2f06-4ca2-a151-402c4480fa46",
        "tags" : [
        ]
      },
      {
        "id" : "381f5fa4-3a5d-4023-9d91-d938a4bf0b77",
        "parentId" : "2c25951f-9c94-4486-a400-984a47973244",
        "authorId" : "ea2f4d83-2f06-4ca2-a151-402c4480fa46",
        "body" : "Actually, I think it's not that easy. The problem is that there could be wrong indices in partitions, which are larger than num_partitions. cub::ReduceByKey does not check the input for correctness and assumes the output array d_unique_out is large enough to contain all the distinct keys. But this need not be the case if the input is wrong. This would result in a seg fault or some other memory corruption. On the other hand, my custom kernel simply ignores out-of-bounds indices.\r\n It would be possible to do a check first, but then I would have to wait for the check to complete, bring the result to the CPU, and decide whether I should continue the computation. I think it's easier to keep the version which just ignores the out-of-bound indices.",
        "createdAt" : "2017-11-10T18:47:06Z",
        "updatedAt" : "2017-11-10T18:47:06Z",
        "lastEditedBy" : "ea2f4d83-2f06-4ca2-a151-402c4480fa46",
        "tags" : [
        ]
      },
      {
        "id" : "3a8ed1e6-5fff-4de6-b303-07eb6d5bfcad",
        "parentId" : "2c25951f-9c94-4486-a400-984a47973244",
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "Maybe you could use custom iterators (instead of pointers).  The output iterators could do a check for the position being in bounds and only then doing the write.  This wouldn't involve any extra kernel launches or host communication.",
        "createdAt" : "2017-11-10T19:06:43Z",
        "updatedAt" : "2017-11-10T19:06:43Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      },
      {
        "id" : "40768dc1-593c-4dd8-baae-6a2aa75557e7",
        "parentId" : "2c25951f-9c94-4486-a400-984a47973244",
        "authorId" : "e0c73848-497b-4162-afc3-88791d085557",
        "body" : "You can find an example of a custom output iterator here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/transform_output_iterator.h",
        "createdAt" : "2017-11-10T19:07:42Z",
        "updatedAt" : "2017-11-10T19:07:43Z",
        "lastEditedBy" : "e0c73848-497b-4162-afc3-88791d085557",
        "tags" : [
        ]
      }
    ],
    "commit" : "1ec44ca2fe337eccc043fe41171316e8b05a8c8a",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +24,28 @@//    - compute the starting and ending point of each interval,\n//    - subtract the starting and ending points to find the length.\n//    The result is placed in partition_count.\n// 4. Because partition_count is on the GPU, we bring it asynchronously to\n//    the CPU. Then we can allocate the output tensors."
  }
]