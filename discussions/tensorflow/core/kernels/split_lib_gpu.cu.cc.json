[
  {
    "id" : "c767a6dd-0dfd-49c2-9085-94906bf8128d",
    "prId" : 28451,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28451#pullrequestreview-241415584",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a7e0d7b-5cd8-492f-a183-9c479da803df",
        "parentId" : null,
        "authorId" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "body" : "Have you considered introducing a wrapper for this?",
        "createdAt" : "2019-05-21T06:15:00Z",
        "updatedAt" : "2019-05-21T18:56:05Z",
        "lastEditedBy" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "tags" : [
        ]
      },
      {
        "id" : "9e13685d-90f8-492d-9ce4-125e007da926",
        "parentId" : "6a7e0d7b-5cd8-492f-a183-9c479da803df",
        "authorId" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "body" : "I had not until now.\r\n\r\nwould something along the following lines work\r\n\r\n```\r\n<in tensorflow/core/gpu_kernel_helper.h>\r\n\r\n#if GOOGLE_CUDA\r\n  #define GPU_DYNAMIC_SHARED_MEM_DECL(ALIGN, TYPE, NAME)     extern __shared__ __align__(ALIGN) TYPE NAME[]\r\n#elif TENSORFLOW_USE_ROCM\r\n  #define GPU_DYNAMIC_SHARED_MEM_DECL(ALIGN, TYPE, NAME)     HIP_DYNAMIC_SHARED(TYPE, NAME)\r\n#endif \r\n\r\n\r\n<and then in the file where we need the shared memory decl, like right here>\r\n\r\nGPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);\r\n\r\n```\r\n\r\nThere are 8 instances of HIP_DYNAMIC_SHARED in our fork...so this should not be a major change.\r\n\r\nAssuming the above change is the route we want to go, can we track it in a different PR, and leave the change here as is?\r\n\r\nthanks",
        "createdAt" : "2019-05-21T15:32:40Z",
        "updatedAt" : "2019-05-21T18:56:05Z",
        "lastEditedBy" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "tags" : [
        ]
      },
      {
        "id" : "8f876b89-dd39-4848-864f-44966d0863b2",
        "parentId" : "6a7e0d7b-5cd8-492f-a183-9c479da803df",
        "authorId" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "body" : "@chsigg , gentle ping ... let me know if you are okay with the proposal above, and whether we can address it in a separate PR.",
        "createdAt" : "2019-05-23T18:25:42Z",
        "updatedAt" : "2019-05-23T18:25:43Z",
        "lastEditedBy" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "tags" : [
        ]
      },
      {
        "id" : "941699cf-6564-43ff-b74c-c3086a91b67c",
        "parentId" : "6a7e0d7b-5cd8-492f-a183-9c479da803df",
        "authorId" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "body" : "cool. expect a PR for it sometime next week.\r\n\r\nalso this PR should be good to go now.\r\n\r\nthanks again ",
        "createdAt" : "2019-05-23T19:50:08Z",
        "updatedAt" : "2019-05-23T19:50:08Z",
        "lastEditedBy" : "80b3505d-f76d-48ab-b8fe-fe7925204b98",
        "tags" : [
        ]
      }
    ],
    "commit" : "a62758b88c7fe842e77550335d7c2cbb6a13beb9",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +125,129 @@\n  // verbose declaration needed due to template\n#if GOOGLE_CUDA\n  extern __shared__ __align__(sizeof(T)) unsigned char smem[];\n#elif TENSORFLOW_USE_ROCM"
  }
]