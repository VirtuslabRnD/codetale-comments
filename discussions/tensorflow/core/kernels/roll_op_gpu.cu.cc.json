[
  {
    "id" : "4c0d0d49-a996-4c01-9bc3-e1ad4358d243",
    "prId" : 27389,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27389#pullrequestreview-254006630",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5443300-7e1d-449e-bd6b-6fd10267e4a3",
        "parentId" : null,
        "authorId" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "body" : "I'm pretty sure this would be faster if you allocated and copied them in one go. You would need to merge the arrays first and make sure the underlying storage (preferably page-locked) remains allocated.\r\n\r\nActually, I think the lifetime is not guaranteed in the current code either. Feel free to ignore the optimization, but please check correctness.",
        "createdAt" : "2019-06-18T08:46:43Z",
        "updatedAt" : "2019-06-24T11:15:32Z",
        "lastEditedBy" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "tags" : [
        ]
      },
      {
        "id" : "d7daf1b0-e817-428e-bed2-57d75b7d5ddc",
        "parentId" : "e5443300-7e1d-449e-bd6b-6fd10267e4a3",
        "authorId" : "c9ec34d5-7154-44a3-bc4d-aa51540645d9",
        "body" : "Here, I follow the example of transpose_functor_gpu.cu.cc for memory allocation\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/transpose_functor_gpu.cu.cc\r\n\r\nI run some unit tests, which are correct.",
        "createdAt" : "2019-06-24T11:28:35Z",
        "updatedAt" : "2019-06-24T11:28:35Z",
        "lastEditedBy" : "c9ec34d5-7154-44a3-bc4d-aa51540645d9",
        "tags" : [
        ]
      },
      {
        "id" : "a05c2b06-db41-4e99-8afb-6786c06e9bb2",
        "parentId" : "e5443300-7e1d-449e-bd6b-6fd10267e4a3",
        "authorId" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "body" : "Indeed, allocate+memcpy+deallocate is a valid and correct pattern. The deallocation is inserted into the stream and not carried out immediately.",
        "createdAt" : "2019-06-25T13:33:27Z",
        "updatedAt" : "2019-06-25T13:33:28Z",
        "lastEditedBy" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a8a68695339e5ff191a81f04ff4f179e357711d",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +75,79 @@    d.memcpyHostToDevice(dim_buf, dim_size.data(), dim_bytes);\n    d.memcpyHostToDevice(thres_buf, threshold.data(), thres_bytes);\n    d.memcpyHostToDevice(range_buf, dim_range.data(), range_bytes);\n\n    CudaLaunchConfig cfg = GetCudaLaunchConfig(num_elements, d);"
  },
  {
    "id" : "be706b79-9022-4387-8413-15862cc7e65f",
    "prId" : 27389,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27389#pullrequestreview-250933881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ba81cd8-1bd1-49cb-ae8c-eb4fcfc98422",
        "parentId" : null,
        "authorId" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "body" : "That's a lot of index computation to move a single element. I'm pretty sure we can do better, but let's keep it simple for now.",
        "createdAt" : "2019-06-18T08:49:02Z",
        "updatedAt" : "2019-06-24T11:15:32Z",
        "lastEditedBy" : "1223b96d-efd5-4254-9e4f-f359308f8df2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a8a68695339e5ff191a81f04ff4f179e357711d",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +38,42 @@    int64 offset = 0;\n    for (int i = 0; i < num_dims; i++) {\n        const int64 stride = dim_range[i] / dim_size[i];\n        const int shift = dim_size[i] - threshold[i];\n        const int indx = (out_idx / stride) % dim_size[i];"
  }
]