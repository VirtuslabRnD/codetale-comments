[
  {
    "id" : "f6ac9297-cd8f-4b67-9485-4e68cc80c3ef",
    "prId" : 40545,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/40545#pullrequestreview-605925086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff9104ba-6527-4a3e-91f6-522140c805e8",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "We introduced the case ctx==nullptr and input_vec!=nullptr a while back, and it is only use for the test, this part of code looks very difficult to understand.  I think we should replace these two parameters with one parameter, which is a vector the Tensor* as shown here https://github.com/tensorflow/tensorflow/blob/befea92a3d74a010791eb845267f03c54315d660/tensorflow/core/framework/op_kernel.h#L670.",
        "createdAt" : "2020-11-14T04:16:26Z",
        "updatedAt" : "2021-03-09T22:29:02Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "aa0a26f7-6438-474f-9fbc-f4be484a98af",
        "parentId" : "ff9104ba-6527-4a3e-91f6-522140c805e8",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "This is possible, but we need actually two inputs: the vector of Tensor* and a vector of input names. I had such an implementation earlier, which I rejected to keep `TRTEngineOp::ExecuteTrtEngine` shorter. I can bring this back.",
        "createdAt" : "2020-12-09T09:38:24Z",
        "updatedAt" : "2021-03-09T22:29:02Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      },
      {
        "id" : "6e5c075e-9ff0-4fd3-a078-329c2abc4d5d",
        "parentId" : "ff9104ba-6527-4a3e-91f6-522140c805e8",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I was thinking about the proposed change. I am not convinced if it simplifies things. Let me know if I should go forward with this:\r\n\r\n1. For the inputs it could work the following way: \r\n- we need a helper to construct the vector of tensors from `OpKernelContext` (since the `params_` field is private),\r\n- another helper to map the unit test `DataVec -> gtl::InlinedVector<TensorValue,4>`.\r\n\r\n2. The outputs need either to be allocated using `OpKernelContext`, or just reshaped in case of the unit tests. One would need two more helpers that return the vector of tensors: \r\n- create a helper functions doing the allocations for `OpKernelContext`\r\n- another one for the reshape operations during unit test with `DataVec`.\r\n\r\nMy preferred solution would be to make the converter tests a subclass of OpTestBase, and run the tests as a TF op test. But that would be outside the scope of this PR.",
        "createdAt" : "2021-02-08T18:46:19Z",
        "updatedAt" : "2021-03-09T22:29:02Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      },
      {
        "id" : "6a3febe1-756d-46ad-8c58-25d78bbbc934",
        "parentId" : "ff9104ba-6527-4a3e-91f6-522140c805e8",
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "I think making the converter tests run as OpTestBase is a good idea.",
        "createdAt" : "2021-03-08T02:19:32Z",
        "updatedAt" : "2021-03-09T22:29:03Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "47ef8f0dc44b84032bb2cc5401c84a3afe3dd6f2",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +138,142 @@                          int num_batch,\n                          const TrtShapeOptimizationProfile& profiles,\n                          OpKernelContext* ctx, const DataVec* input_vec) {\n  int n_inputs = ctx ? ctx->num_inputs() : (input_vec ? input_vec->size() : 0);\n  // Setup engine inputs."
  }
]