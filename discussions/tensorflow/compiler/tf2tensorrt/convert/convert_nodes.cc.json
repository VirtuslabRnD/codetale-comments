[
  {
    "id" : "294b5c8a-c09f-44ee-8beb-c893233589bc",
    "prId" : 48917,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48917#pullrequestreview-687676368",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bab323fa-c7a4-4a9f-af43-a663b7b90bc3",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "In the class definition, batch_size_ comes before tensor_proxy_ptr_, you need to initialize the fields in the same order they are declared. Similar problems in a few constructors below. You might want to remove tensor_proxy_ptr_ ahead of batch_size_ in the class definition to minimize the needed changes.",
        "createdAt" : "2021-06-18T17:53:14Z",
        "updatedAt" : "2021-06-18T17:57:12Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "7496d71d-2137-4ac8-9529-09eba9cfed54",
        "parentId" : "bab323fa-c7a4-4a9f-af43-a663b7b90bc3",
        "authorId" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "body" : "Thanks for the recommendation, moved the tensor_proxy_ptr_ as suggested, and the rest of TRT_TensorOrWeights's members are in order",
        "createdAt" : "2021-06-18T19:20:56Z",
        "updatedAt" : "2021-06-18T19:20:56Z",
        "lastEditedBy" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b3a98336d0dea159ea292206f9d254f04581759b",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +871,875 @@TRT_TensorOrWeights::TRT_TensorOrWeights(ITensorProxyPtr tensor, int batch_size)\n    : tensor_proxy_ptr_(tensor),\n      batch_size_(batch_size),\n      initialized_(true),\n      is_tensor_(true) {}"
  },
  {
    "id" : "a7a82150-8327-4b0c-a37c-d690402fff1a",
    "prId" : 48917,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48917#pullrequestreview-690944981",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4735e6d4-e497-4aed-b49a-ce62a8af97b2",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Need to add this to the end of the list:\r\n#if IS_TRT_VERSION_GE(8, 0, 0, 0)\r\n    ADD_LAYER(QUANTIZE)\r\n    ADD_LAYER(DEQUANTIZE)\r\n#endif",
        "createdAt" : "2021-06-21T17:27:50Z",
        "updatedAt" : "2021-06-21T17:53:40Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "a30576e8-b748-46aa-b28c-5845279c3df5",
        "parentId" : "4735e6d4-e497-4aed-b49a-ce62a8af97b2",
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "I see code change for this. In the future, please response to the comment so I know you already addressed it.",
        "createdAt" : "2021-06-23T15:48:22Z",
        "updatedAt" : "2021-06-23T15:54:51Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "60934656-4f1f-4267-bcd5-d3a0bde754b4",
        "parentId" : "4735e6d4-e497-4aed-b49a-ce62a8af97b2",
        "authorId" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "body" : "Added the quantize conversions and moved the TRT8 check to the bottom to keep things slightly cleaner, thanks",
        "createdAt" : "2021-06-23T17:23:36Z",
        "updatedAt" : "2021-06-23T17:23:36Z",
        "lastEditedBy" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b3a98336d0dea159ea292206f9d254f04581759b",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +112,116 @@    ADD_LAYER(UNARY)\n    ADD_LAYER(PADDING)\n    ADD_LAYER(SHUFFLE)\n    ADD_LAYER(REDUCE)\n    ADD_LAYER(TOPK)"
  },
  {
    "id" : "6f40b97e-f646-4e7f-a303-dd9b59915f8e",
    "prId" : 48049,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48049#pullrequestreview-621519234",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc86d304-6b74-43a5-a44b-6649a3fac9ba",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "I should remove this for these reasons:\r\n     The SqueezeTensor converter can handle validataion_only mode.\r\n      The SqueezeTensor converter may return error, in that case, we should not convert and returning Status::OK() here premature and wrong.",
        "createdAt" : "2021-03-24T23:44:09Z",
        "updatedAt" : "2021-03-25T19:31:43Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "caa4249d-6cf7-4f78-97dc-c7f63e1b9f14",
        "parentId" : "fc86d304-6b74-43a5-a44b-6649a3fac9ba",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "`SqueezeTensor` seems to handle `validation_only` mode, but in practice we do not use it for validation in any other converter. I believe we cannot use it here either:\r\n- The first arg (`params->outputs->at(i)`) is not created by `ConvertStridedSliceHelper` during validation.\r\n- I am not sure if `params->converter` exists in `validation_mode`.",
        "createdAt" : "2021-03-25T19:47:47Z",
        "updatedAt" : "2021-03-25T19:47:47Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d612d87e2b99ce2ae1cddff96fef5423515f316",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +5147,5151 @@        /*op_instance=*/i));\n  }\n  if (params->validation_only) return Status::OK();\n\n  // Squeeze for dynamic shapes"
  },
  {
    "id" : "907f897e-add1-4e06-8684-4c41bdf2ee20",
    "prId" : 47988,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47988#pullrequestreview-619160960",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e7436d3-da75-4128-9afc-d52736b3cbcf",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "We can replace this with:\r\n using EinsumHelper::DimensionType::kBatch;\r\n and so on",
        "createdAt" : "2021-03-23T16:19:57Z",
        "updatedAt" : "2021-03-25T00:10:03Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "f26e0b85-927b-451f-a728-b4e2db127e75",
        "parentId" : "9e7436d3-da75-4128-9afc-d52736b3cbcf",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "That does not work unfortunately: ` error: ‘tensorflow::EinsumHelper’ is not a namespace or unscoped enum`.\r\nhttps://stackoverflow.com/questions/24212921/is-it-possible-to-alias-an-enum-class-enumerator",
        "createdAt" : "2021-03-23T23:19:48Z",
        "updatedAt" : "2021-03-25T00:10:03Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9af3727e13235ff7191854792eb2d5a1c31411d",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +5879,5883 @@        EinsumHelper::DimensionType::kFree;\n    const EinsumHelper::DimensionType kContract =\n        EinsumHelper::DimensionType::kContract;\n\n    // Map label indices to label types."
  },
  {
    "id" : "b01fffdb-df55-4ba3-b6de-7fdef3efbadc",
    "prId" : 47988,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47988#pullrequestreview-619160960",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a93ee99-8482-4353-abd8-883dccfd8a26",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Why can't we just \"return permute\" to implement the copy?",
        "createdAt" : "2021-03-23T16:47:50Z",
        "updatedAt" : "2021-03-25T00:10:03Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "c9dbd0d0-11e8-4582-843e-9f565128738b",
        "parentId" : "2a93ee99-8482-4353-abd8-883dccfd8a26",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "```c++\r\nerror: could not convert ‘((tensorflow::tensorrt::convert::EinsumDescriptor*)this)->tensorflow::tensorrt::convert::EinsumDescriptor::permute’ from ‘std::vector<int>’ to ‘nvinfer1::Permutation’\r\n```",
        "createdAt" : "2021-03-24T00:57:09Z",
        "updatedAt" : "2021-03-25T00:10:03Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9af3727e13235ff7191854792eb2d5a1c31411d",
    "line" : 330,
    "diffHunk" : "@@ -1,1 +6032,6036 @@    std::copy(permute.begin(), permute.end(), p.order);\n    return p;\n  }\n\n  Status SetDynamicSize(OpConverterParams* params,"
  },
  {
    "id" : "eaa09b02-47c3-4ec4-bf9e-6c74c6cfa77e",
    "prId" : 47698,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47698#pullrequestreview-609001573",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1df53946-dc34-4413-b545-daba08116262",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Not sure if you agree, but I think making the env for user to over the top_k value is more flexible. If that is what we will do, this code will look like this:\r\n```\r\nstd::optional<int64> user_request_top_k = read from env\r\nif (user_request_top_k) {\r\n    if (top_k <= user_request_top_k.value()) {\r\n           issue a VLOG message saying the user request is not used because it is bigger than the natural top_k.\r\n    } else {\r\n          issue a VLOG to tell the \"natural top_k\" and user requested top_k values, and the use requested one is use\r\n          top_k = user_requested_top_k.value();\r\n          keep_top_k = min(top_k, keep_top_k)\r\n    }\r\n}\r\nif (top_k > 4096)\r\n   return errors::InvalidaArgument(...)\r\n```\r\n",
        "createdAt" : "2021-03-10T16:41:12Z",
        "updatedAt" : "2021-03-10T16:51:24Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "465019d0-c2a2-4226-9ef5-56dde4b37666",
        "parentId" : "1df53946-dc34-4413-b545-daba08116262",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I believe what we need here is a way for the user to opt-in for a conversion in case the TRT converted op is not strictly equivalent with the TF op. While your suggestion can be used to reach the same goal, I do not see the need for flexibly overriding top_k, and therefore I would choose the current simpler solution.\r\n\r\nWhy would the user want to override top_k with a concrete value? More importantly, how would he/she decide what value to use? The TF-TRT converter does this job: it sets a value for top_k based on the input parameters. If that value is not compatible with TRT, then we either skip conversion, or not (this case only with the users consent). If we do not skip conversion, then the next best thing (in terms of correctness of the results) is to set the max value allowed by the plugin.\r\n",
        "createdAt" : "2021-03-10T17:34:55Z",
        "updatedAt" : "2021-03-10T17:34:55Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      },
      {
        "id" : "06694e52-cc58-42de-881b-6561b437959e",
        "parentId" : "1df53946-dc34-4413-b545-daba08116262",
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "See [this comment](https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-774227477).\r\nCan this value affect performance? That is the only reason I can think of to allow users change the value.\r\n",
        "createdAt" : "2021-03-10T17:51:56Z",
        "updatedAt" : "2021-03-10T17:51:56Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "398ecd5381432ba72d2e4c79a656177fc32beb98",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +6290,6294 @@          \"result in a loss of accuracy.\");\n    }\n  }\n\n  if (params->validation_only) return Status::OK();"
  },
  {
    "id" : "c23f2274-cd62-4790-be7e-e3be461c6a7c",
    "prId" : 47590,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47590#pullrequestreview-616919472",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66fa2aad-9087-4014-baec-4ec1a0b963ef",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Shall we change line 6260 } else if (node_def.op() == \"SpaceToDepth\") {\r\nto:\r\n\r\nelse {\r\n if (node_def.op() != \"SpaceToDepth\") \r\n return errors::InvalidArgument(...)\r\n\r\n?",
        "createdAt" : "2021-03-18T21:38:12Z",
        "updatedAt" : "2021-03-22T22:42:16Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "f38bce81-e975-4684-86d9-7fd609e670b6",
        "parentId" : "66fa2aad-9087-4014-baec-4ec1a0b963ef",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "We can.",
        "createdAt" : "2021-03-20T15:17:34Z",
        "updatedAt" : "2021-03-22T22:42:16Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b283d83141aabd6befe64fec9cb1579d8e14baf",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +6117,6121 @@  // afterwards with an initial transpose op. TODO(tfeher): Get rid of the\n  // layout_transpose ops by defining shuffle shape specifically for NCHW and\n  // NHCW.\n  if (node_def.op() == \"DepthToSpace\") {\n    if (num_channels != -1 && num_channels % (block_size * block_size) != 0) {"
  },
  {
    "id" : "1cb1bc65-25d0-45d8-831c-f3ec920c7e5e",
    "prId" : 47215,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47215#pullrequestreview-595314663",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7f0a5e0-2a2e-47c3-971f-e093e492bf3b",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "The comment in the old file line 5601-5602 is not relevant, as we only care about input_l and we only make two calls the routine to make sure both operands are checked. Shall we remove that? Let's add a comment to the lambda:\r\n// Check whether input_l is weight batched.",
        "createdAt" : "2021-02-18T17:13:57Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "28538276-86c9-4b81-8a48-80934f8fd8a7",
        "parentId" : "c7f0a5e0-2a2e-47c3-971f-e093e492bf3b",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I have deleted the irrelevant comment, moved the explanation inside the lambda, and added the comment that you propose. ",
        "createdAt" : "2021-02-22T19:31:24Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "5136ce11428211bb1e3571de51c8a655e6600556",
    "line" : 451,
    "diffHunk" : "@@ -1,1 +5751,5755 @@  if (params->use_implicit_batch) {\n    TF_RETURN_IF_ERROR(check_weight_is_not_batched(inputs.at(0), inputs.at(1)));\n    TF_RETURN_IF_ERROR(check_weight_is_not_batched(inputs.at(1), inputs.at(0)));\n  }\n"
  },
  {
    "id" : "69744dba-2b7f-48ed-84ca-2a5313ad9dd0",
    "prId" : 47215,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47215#pullrequestreview-595314663",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "007d6ac2-3130-4a38-9fda-fcf66ccbdd7a",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "I think this code path should also check params->validation_only and return without applying the transformation as other code paths do.",
        "createdAt" : "2021-02-18T17:51:43Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "de8b7e6a-d7b1-477a-b4de-bf01185b236a",
        "parentId" : "007d6ac2-3130-4a38-9fda-fcf66ccbdd7a",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I consider applying the broadcast op as a conversion step. Instead of checking validation mode here, I have added\r\n```c++\r\nif (params->validation_only) return Status::OK();\r\n```\r\nto `BroadcastTensors`, so that in validation mode we return even before calling `ApplyBroadcast`.",
        "createdAt" : "2021-02-22T19:16:19Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "5136ce11428211bb1e3571de51c8a655e6600556",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +500,504 @@                      OpConverterParams* params) {\n  if (operand->is_weights()) {\n    TF_RETURN_IF_ERROR(BroadcastWeights(operand, broadcasted_dims));\n  } else {\n    nvinfer1::ITensor* tensor = nullptr;"
  },
  {
    "id" : "1e6f32cc-7f98-40ad-8978-510731b53e8b",
    "prId" : 47215,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47215#pullrequestreview-595314663",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "049120f6-35ee-4afa-ae07-ef7480dee70f",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Let's simplify this and not repeat what is obvious from the code:\r\n In implicit batch mode, we can only implement limited cases of 2D MatMul, through treating A as a batch of vectors.",
        "createdAt" : "2021-02-18T22:09:04Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "2a1f6e49-ec71-46ff-b96a-5945901d21fd",
        "parentId" : "049120f6-35ee-4afa-ae07-ef7480dee70f",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I prefer to be verbose here, and explain why do we have this condition. I have the following arguments for verbosity:\r\n- Explaining that 2D tensors are represented as tensors with nbDims==1 is helpful for developers who are not so familiar with implicit batch mode of TRT. \r\n- It is not trivial why we can do matmul with 1D input, the comment adds information that it is treated as a batch of vectors.\r\n- The error message below states that conversion is not done under certain the conditions. The comment here conveys a stronger message, it describes \"the only possibility to implement MatMul with 2D input in implicit batch mode\".",
        "createdAt" : "2021-02-22T15:25:57Z",
        "updatedAt" : "2021-02-24T17:39:55Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "5136ce11428211bb1e3571de51c8a655e6600556",
    "line" : 288,
    "diffHunk" : "@@ -1,1 +5622,5626 @@    // not counted). If A is not transposed and B is weight, then we can convert\n    // this treating A as a batch of vectors. This is the only possibility\n    // to implement MatMul with 2D input in implicit batch mode.\n    if ((input_a.GetTrtDims().nbDims < 2 &&\n         (transpose_a || !input_b.is_weights())) ||"
  },
  {
    "id" : "a14b9091-f829-4ce5-9fb1-57bfb2e86c9e",
    "prId" : 40545,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/40545#pullrequestreview-595797585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d37f7c2c-65e1-426f-b12c-5160275d7756",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Is it possible that dims.nbDims coming into this constructor has a value of 0 and it will miss the special handling you add (dims.d[0] =0)?  We should either DCHECK this situation is not possible or do similar special handling.",
        "createdAt" : "2021-02-12T17:38:02Z",
        "updatedAt" : "2021-03-09T22:29:02Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "80bf3ae5-758a-49fc-a5a8-ae670b30b6d4",
        "parentId" : "d37f7c2c-65e1-426f-b12c-5160275d7756",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I have added a DCHECK.",
        "createdAt" : "2021-02-22T23:26:00Z",
        "updatedAt" : "2021-03-09T22:29:02Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "47ef8f0dc44b84032bb2cc5401c84a3afe3dd6f2",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +755,759 @@}\n\nTRT_ShapedWeights::TRT_ShapedWeights(nvinfer1::DataType type,\n                                     nvinfer1::Dims dims, Tensor tensor)\n    : shape_(dims), type_(type), tensor_(tensor) {"
  },
  {
    "id" : "361fa571-c4dc-4d09-af13-58a4fcc3b72c",
    "prId" : 40483,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/40483#pullrequestreview-432692277",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89c3564d-95b4-44d4-afcb-67791ee8261a",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "We have a plan to provide a way to get the supported data types for all op converters. The code here is fine for this reason.",
        "createdAt" : "2020-06-17T19:03:08Z",
        "updatedAt" : "2020-06-17T19:58:36Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "cb61c42938010f3ff33b55ef4b41651c22fb7652",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +4425,4429 @@  const auto& node_def = params->node_def;\n  TF_RETURN_IF_ERROR(CheckInputsWeights(*params, {{\"x\", false}}));\n#if IS_TRT_VERSION_GE(6, 0, 1, 0)\n  TF_RETURN_IF_ERROR(AllowDataTypes(\n      *params, {DataType::DT_FLOAT, DataType::DT_HALF, DataType::DT_INT32}));"
  },
  {
    "id" : "eb26272a-f513-4bc0-a4b7-ea5e3fcb6598",
    "prId" : 40179,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/40179#pullrequestreview-451690257",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e2649edc-2bd6-4ebc-befb-ef89e03118ce",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "One might wonder, why it is ok to have d[1]==-1 when use_implicit_batch==true? The true is when use_implicit_batch==true, it is expected that we will never have d[1]==-1. How can we avoid this confusion here? Will it be better if we change the if condition to:\r\nif (tensor->getDimensions().d[1] == -1) {",
        "createdAt" : "2020-07-07T18:13:55Z",
        "updatedAt" : "2020-07-20T14:58:19Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "96f95284-655c-465e-b250-a3b89cc44088",
        "parentId" : "e2649edc-2bd6-4ebc-befb-ef89e03118ce",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Added a comment to explain this. \r\n\r\nOne need to consider that the converter is called in two phases: during segmentation and conversion. During segmentation the dimensions can be unknown both in implicit/explicit batch modes. During conversion the converter is [called using known shapes](https://github.com/tensorflow/tensorflow/blob/a1cae5e5acf90572f56e8f00fa8dad5008747fe0/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L742-L748) in implicit batch mode. Therefore it is not  a problem if we have -1 in implicit batch mode, that will be replaced with the actual value during conversion. In explicit batch mode we keep the same (possibly unknown) value that we saw during segmentation, which is not TRT compatible. Therefore we have to return an error in explicit batch mode. ",
        "createdAt" : "2020-07-08T08:45:58Z",
        "updatedAt" : "2020-07-20T14:58:19Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      },
      {
        "id" : "d96e0b77-5cbc-410b-8dd7-474998b51a69",
        "parentId" : "e2649edc-2bd6-4ebc-befb-ef89e03118ce",
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Thanks for clarifying this. I would suggest a comment like this:\r\n    // This check is to make sure that channel dimension is known during\r\n    // conversion.\r\n    //\r\n    // We check this only in explicit batch mode and reject an op with unknown\r\n    // channel dimension during segmentation. In implicit batch mode we have\r\n    // known shapes during conversion even though the shapes may not be known\r\n    // during segmentation (see the actual argument for input_shapes when\r\n    // ConvertGraphDefToEngine is called from TRTEngineOp::BuildEngine).",
        "createdAt" : "2020-07-13T16:42:33Z",
        "updatedAt" : "2020-07-20T14:58:19Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "b82586b7-f2ab-4f95-9f0c-46c240b92afd",
        "parentId" : "e2649edc-2bd6-4ebc-befb-ef89e03118ce",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I have updated the comment as you have suggested. ",
        "createdAt" : "2020-07-20T14:59:49Z",
        "updatedAt" : "2020-07-20T14:59:50Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "45591fac1d5a9042e205832e60c2fc4bfaeadfdc",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +4943,4947 @@  }\n  nvinfer1::ITensor* tensor = inputs.at(0).tensor();\n  if (!params->use_implicit_batch && tensor->getDimensions().d[1] == -1) {\n    // This check is to make sure that channel dimension is known during\n    // conversion."
  },
  {
    "id" : "f2c6525b-fdb0-4816-9ec9-de463468a7e1",
    "prId" : 39990,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39990#pullrequestreview-461453399",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bcd7bf4f-e2e0-403d-8ef8-d25227bfcff0",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Can we return Status::OK() here and move the else-branch below outside the if?",
        "createdAt" : "2020-08-04T23:59:45Z",
        "updatedAt" : "2020-08-05T08:58:17Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "0d427c40-0981-4006-898f-16a252100c1b",
        "parentId" : "bcd7bf4f-e2e0-403d-8ef8-d25227bfcff0",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Good catch, I have corrected it!",
        "createdAt" : "2020-08-05T08:39:42Z",
        "updatedAt" : "2020-08-05T08:58:17Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "1033515e9ede0996f0213da293d0a7cff6dc094c",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +2429,2433 @@    std::copy(input_dims.d, input_dims.d + input_dims.nbDims, values_ptr);\n    auto output = params->converter->CreateConstantLayer(weight, output_dims);\n    params->outputs->push_back(TRT_TensorOrWeights(output));\n    return Status::OK();\n  }"
  },
  {
    "id" : "e84ce1d9-5880-410c-9d32-74580b723f32",
    "prId" : 39859,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39859#pullrequestreview-440250836",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93487178-7681-4dc3-afcc-b8d415e87a78",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Can you add a comment to explain why we don't want to handle weights for implicit mode?",
        "createdAt" : "2020-06-22T19:14:39Z",
        "updatedAt" : "2020-06-30T18:32:18Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "90393a2c-9362-41fc-89c5-960facf8ced1",
        "parentId" : "93487178-7681-4dc3-afcc-b8d415e87a78",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Added.",
        "createdAt" : "2020-06-30T17:47:28Z",
        "updatedAt" : "2020-06-30T18:32:35Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "bfe43303794b8ec092bb7d555d0c5e47d1aab03b",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +4534,4538 @@  // case the input tensors are also represented with full dims that include the\n  // batch size.\n  TrtInputArg expected_arg =\n      params->use_implicit_batch ? TrtInputArg::kTensor : TrtInputArg::kBoth;\n"
  },
  {
    "id" : "018857d8-a699-4397-b134-a0c76d236d28",
    "prId" : 39785,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39785#pullrequestreview-423492903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "830d66b7-cbae-43da-9d72-da51d52dd94e",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "A better way is to use a static array to hold the data types and only this array value is conditional on TRT version.",
        "createdAt" : "2020-06-01T16:15:26Z",
        "updatedAt" : "2020-06-04T14:38:22Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "687e4327-cb20-4c80-b85a-2c3037c8ac3b",
        "parentId" : "830d66b7-cbae-43da-9d72-da51d52dd94e",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Changed it.",
        "createdAt" : "2020-06-03T16:04:27Z",
        "updatedAt" : "2020-06-04T14:38:22Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "b19e03cb754079466e52a464d0e100420d9a9d69",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +4236,4240 @@                                   node_def.name());\n  }\n#if IS_TRT_VERSION_GE(6, 0, 0, 0)\n  std::set<DataType> allowed_types{DataType::DT_FLOAT, DataType::DT_HALF,\n                                   DataType::DT_INT32};"
  },
  {
    "id" : "06163a48-fef3-4c7e-b52b-5550554cc8f1",
    "prId" : 39282,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39282#pullrequestreview-420128852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23f3510b-fb46-43a3-810b-b86806f58bd4",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "It would be nice if we can refactor this to share code with Converter::SqueezeTensor:\r\n(1) a common routine to decide whether input_dims has a dynamic value\r\n(2) a routine for ConcatenateAndReshape(absl::span<nvinfer1::ITensor const*> values, nvinfer1::ITensor* new_shape)",
        "createdAt" : "2020-05-08T16:33:00Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "08fcd33f-adb8-42c0-9737-47ee20b2cfe8",
        "parentId" : "23f3510b-fb46-43a3-810b-b86806f58bd4",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Yes, it is a good idea. There are other ops which might need similar functionalities: many ops that change shape need special methods in dynamic shape mode. I will review a few other cases, and I will improve this.",
        "createdAt" : "2020-05-08T19:19:01Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      },
      {
        "id" : "d339bf03-1f56-4bda-a83d-077c8d39f33a",
        "parentId" : "23f3510b-fb46-43a3-810b-b86806f58bd4",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "(1) Using common HasStaticShape routine to decide on whether the tensor has static or dynamic shapes.\r\n(2) Added SliceShape routine to take slices of a tensor's shape and combine it into a new shape tensor.\r\n(3) Added separate DynamicExpandDims routine which will also be used by the Pack converter.",
        "createdAt" : "2020-05-28T13:52:19Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "177625f9e8f489af9be3c26a8bda5cccc522fe4f",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +2505,2509 @@  // DynamicReshape relies on INetworkDefinition::addShape that was introduced\n  // in TensorRT 6.\n#if IS_TRT_VERSION_GE(6, 0, 0, 0)\n  if (params->validation_only) {\n    return errors::Internal("
  },
  {
    "id" : "aac31a77-8f6f-41e3-b9a9-5721b5bcb6d3",
    "prId" : 39282,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39282#pullrequestreview-420128852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3686a2a9-53dd-42e4-94a7-ef9dd97e779f",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Do we really need to protect this code block with #if IS_TRT_VERSION_GE? If the code inside the block can be compiled with the older versions of TRT, I think we should remove #if here because we should have a common logic elsewhere to make sure we won't see dynamic dimensions here for the older versions of TRT.",
        "createdAt" : "2020-05-08T16:35:40Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "3ae0006e-efa6-4c90-83c4-069360be7037",
        "parentId" : "3686a2a9-53dd-42e4-94a7-ef9dd97e779f",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "The block that needs to be protected is moved into SliceShape. The ifdef is needed there because the addShape() method of INetworkDefinition requires TRT 6.",
        "createdAt" : "2020-05-28T13:54:59Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "177625f9e8f489af9be3c26a8bda5cccc522fe4f",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +2505,2509 @@  // DynamicReshape relies on INetworkDefinition::addShape that was introduced\n  // in TensorRT 6.\n#if IS_TRT_VERSION_GE(6, 0, 0, 0)\n  if (params->validation_only) {\n    return errors::Internal("
  },
  {
    "id" : "cb2f1548-67d2-456b-b580-2cbb6b089b84",
    "prId" : 39282,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39282#pullrequestreview-423094731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbe35482-19da-4fda-be2e-985665fd01e8",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "It is not obvious why this code is protected via IS_TRT_VERSION_GE. Can you add a comment to say addShape is only available in recent TRT versions?",
        "createdAt" : "2020-05-29T18:23:13Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "f917b341-1764-4391-9300-4a153593a9b5",
        "parentId" : "cbe35482-19da-4fda-be2e-985665fd01e8",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "Added. ",
        "createdAt" : "2020-06-03T00:22:30Z",
        "updatedAt" : "2020-06-03T20:59:30Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "177625f9e8f489af9be3c26a8bda5cccc522fe4f",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +2505,2509 @@  // DynamicReshape relies on INetworkDefinition::addShape that was introduced\n  // in TensorRT 6.\n#if IS_TRT_VERSION_GE(6, 0, 0, 0)\n  if (params->validation_only) {\n    return errors::Internal("
  },
  {
    "id" : "4b0baf0f-7e49-467d-95ed-544be079221c",
    "prId" : 39183,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39183#pullrequestreview-407005092",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "40245024-c34b-4d09-8098-6e8f7f1ed683",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "What is the reason that we can't/don't-want-to do this for implicit batch mode, for all the non-batch dimensions?",
        "createdAt" : "2020-05-06T00:06:44Z",
        "updatedAt" : "2020-05-06T21:54:51Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "f7a53dd9-cfa2-44fa-b296-0b5546d60e69",
        "parentId" : "40245024-c34b-4d09-8098-6e8f7f1ed683",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "We do not know what the batch size will be during conversion time. If we just omit squeezing batch dim, and squeeze the others that would be an incorrect op conversion for an input that has batch size 1. I have updated the PR description with this info. ",
        "createdAt" : "2020-05-06T21:36:01Z",
        "updatedAt" : "2020-05-06T21:55:22Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "4756483d5cc8a9ec3ff5057e60fc73f1c4f38e6d",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +2475,2479 @@          node_def.name());\n    } else {\n      // explicit batch mode with static input shape we squeeze all singleton\n      // dimensions\n      for (int& dim : input_dims) {"
  },
  {
    "id" : "9d1de5c8-136e-41db-97c7-96a893da4376",
    "prId" : 39156,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/39156#pullrequestreview-418221828",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e278e32-5976-4942-b23d-1aa1767c1bb5",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Can we add comment here to explain the decision here? In particular, why we allow cases like these:\r\n   (output_l[i], output_r[i]) = (-1, -1), (40, -1)\r\nWith implicit mode, we don't have (-1, -1), we only support (-1, 1) or (1, -1).",
        "createdAt" : "2020-05-21T17:14:14Z",
        "updatedAt" : "2020-05-26T21:02:54Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "6dfb92e2-ce38-4739-b166-e743a596bd6f",
        "parentId" : "4e278e32-5976-4942-b23d-1aa1767c1bb5",
        "authorId" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "body" : "I have added comments. I do not understand your question: why wouldn't we allow (-1,-1), (40,-1) in dynamic shape mode? In dynamic shape the following are all possible input shapes:\r\n1. output_l = {-1, -1}, output_r = {-1, -1}\r\n2. output_l = {-1, 16}, output_r = {-1, 16}\r\n3. output_l = {40, 8}, output_r = {40, -1}\r\n4. output_l = {-1,-1}, output_r = {40, -1}\r\n\r\nDepending on the actual input shapes that we see during inference time, the broadcast operation might or might not be feasible. For example, the third case has only two feasible actual shape:\r\noutput_r = {40,1} or output_r = {40,8}.",
        "createdAt" : "2020-05-26T11:52:28Z",
        "updatedAt" : "2020-05-26T21:05:18Z",
        "lastEditedBy" : "c5cb8841-0e3d-4435-b088-7d6beb78afd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "d847948f59a89ffab2182511944869fe996d715d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +405,409 @@  if (check_feasibility) {\n    for (int i = 0; i < broadcast_num_dims; ++i) {\n      if (!use_implicit_batch && (output_l[i] == -1 || output_r[i] == -1)) {\n        // If the condition is true then we are in explicit batch mode and (at\n        // least) one of the input dimensions are unknown. In other words we"
  },
  {
    "id" : "347820b0-1846-4082-a827-7b880b54a47b",
    "prId" : 36439,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/36439#pullrequestreview-356792931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d13d62f4-f99a-4d9f-a8b1-87a62d949752",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Add \"a\" between \"of\" and \"squeeze operation\"",
        "createdAt" : "2020-02-11T16:15:49Z",
        "updatedAt" : "2020-02-11T17:31:52Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b75a6222b82bb556f63f7a5a04cab45212ed30c6",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +2404,2408 @@\n#if IS_TRT_VERSION_GE(6, 0, 0, 0)\n  // If the remaining dimensions of squeeze operation have dynamic sizes, we\n  // need to use TRT ops to build the result shape for the squeeze operation.\n  // This is because IShuffleLayer::setReshapeDimensions treats -1 as a special"
  },
  {
    "id" : "e5170b23-6827-4236-8b20-950c05028c3e",
    "prId" : 36439,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/36439#pullrequestreview-356792931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5935b841-135f-4292-9dc9-3426368f6c6c",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : ">Following checks are only used during TRT engine creation time. \r\nDo you mean this routine itself is called to validate tensors during TRT engine creation time? Can you move this sentence and make it a document for the routine?",
        "createdAt" : "2020-02-11T16:31:50Z",
        "updatedAt" : "2020-02-11T17:31:52Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b75a6222b82bb556f63f7a5a04cab45212ed30c6",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +294,298 @@  if (validation_only) return Status::OK();\n\n  // Following checks are only used during TRT engine creation time. In implicit\n  // batch mode we check that all inputs for the network has static shape (as\n  // required by the TensorRT). The only exception is the batch size, which"
  },
  {
    "id" : "279ee6e1-8d50-48fb-9739-42d231ec2065",
    "prId" : 35207,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/35207#pullrequestreview-334830042",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86c6c720-7e94-4f6e-84b7-56ee3bb9083d",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "I think this should be `backprop_output_size.weights().GetValues()`, but I'm fixing it. Just FYI.",
        "createdAt" : "2019-12-19T18:35:21Z",
        "updatedAt" : "2019-12-19T18:37:28Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "28d8d155-61bf-460f-bbf4-b16083336984",
        "parentId" : "86c6c720-7e94-4f6e-84b7-56ee3bb9083d",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "hmmm, I am wondering how the test worked?",
        "createdAt" : "2019-12-19T18:40:16Z",
        "updatedAt" : "2019-12-19T18:40:16Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280366b36da3da1f64c104d4e9ee0b2b27f3050",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +2235,2239 @@  // in case of strides>1.\n  if (is_conv2d_backprop_input) {\n    auto tf_output_shape = backprop_output_size.GetTrtDims();\n    nvinfer1::Dims trt_output_shape = output_tensor->getDimensions();\n    // What determines the padding size is the difference between the given"
  },
  {
    "id" : "10dd4f6e-249e-4746-bb4f-cd85a457c642",
    "prId" : 35207,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/35207#pullrequestreview-334831593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f79db62a-15ff-4f53-a05e-b7b68f16dbc6",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Accordingly this should be tf_output_shape[h_index]? Similar below.",
        "createdAt" : "2019-12-19T18:36:11Z",
        "updatedAt" : "2019-12-19T18:37:28Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "027e8e5a-e875-41c1-9f7f-ddd24f20a95e",
        "parentId" : "f79db62a-15ff-4f53-a05e-b7b68f16dbc6",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "Since `tf_output_shape = backprop_output_size.GetTrtDims()`, `tf_output_shape` is in TRT format which means it doesn't have  the batch dimension. That's why need `h_index - 1`.",
        "createdAt" : "2019-12-19T18:42:44Z",
        "updatedAt" : "2019-12-19T18:42:44Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280366b36da3da1f64c104d4e9ee0b2b27f3050",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2239,2243 @@    // What determines the padding size is the difference between the given\n    // input_sizes (tf_output_shape) and TRT computed size.\n    const int height_diff = tf_output_shape.d[h_index - 1] - trt_output_shape.d[1];\n    const int width_diff = tf_output_shape.d[w_index - 1] - trt_output_shape.d[2];\n    if ((height_diff < 0) || (width_diff < 0)) {"
  },
  {
    "id" : "09311a5e-fc82-4fee-8eb7-67154c8f2198",
    "prId" : 35207,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/35207#pullrequestreview-334831888",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72000dbf-74b4-4e16-91ab-d6f9666fb03d",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Do we need to consider NHWC vs NCHW to determine whether to use trt_output_shape.d[1] or d[2]? Same below.",
        "createdAt" : "2019-12-19T18:37:15Z",
        "updatedAt" : "2019-12-19T18:37:28Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "6894db68-abd4-4948-a3b8-b54d52ab9cd7",
        "parentId" : "72000dbf-74b4-4e16-91ab-d6f9666fb03d",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "It seems the output is always NCHW? Then should it be d[2] instead?",
        "createdAt" : "2019-12-19T18:42:53Z",
        "updatedAt" : "2019-12-19T18:42:54Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "027e18a1-874e-48da-a5a3-92dd701e8f51",
        "parentId" : "72000dbf-74b4-4e16-91ab-d6f9666fb03d",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "`trt_output_shape` is the output of TRT which is always NCHW.",
        "createdAt" : "2019-12-19T18:43:15Z",
        "updatedAt" : "2019-12-19T18:43:15Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      }
    ],
    "commit" : "7280366b36da3da1f64c104d4e9ee0b2b27f3050",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2239,2243 @@    // What determines the padding size is the difference between the given\n    // input_sizes (tf_output_shape) and TRT computed size.\n    const int height_diff = tf_output_shape.d[h_index - 1] - trt_output_shape.d[1];\n    const int width_diff = tf_output_shape.d[w_index - 1] - trt_output_shape.d[2];\n    if ((height_diff < 0) || (width_diff < 0)) {"
  },
  {
    "id" : "743bc4dc-e63f-4a19-863d-0281a15bd4ab",
    "prId" : 34973,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/34973#pullrequestreview-330748969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26f4c337-1b71-478e-9cd0-44bc499d912b",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Do you know what the semantic is when sorted is false? TF API doc doesn't say anything about that, that means it can be in any order? If that's the case, sorted order is also a valid order for sorted=false?",
        "createdAt" : "2019-12-11T16:50:13Z",
        "updatedAt" : "2019-12-16T19:53:13Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "de27029d-518a-40d4-a201-ceec940f0765",
        "parentId" : "26f4c337-1b71-478e-9cd0-44bc499d912b",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "My guess is that the `k` returned values are sorted by index in case of `sorted=False`.\r\nLet me see if I can find that quickly in the op definition.",
        "createdAt" : "2019-12-11T17:39:09Z",
        "updatedAt" : "2019-12-16T19:53:13Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      },
      {
        "id" : "05d2e68a-be1c-493a-8b9c-f640a57516da",
        "parentId" : "26f4c337-1b71-478e-9cd0-44bc499d912b",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "Yeah, I think they are sorted by index according to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/topk_op.cc#L190-L207\r\n",
        "createdAt" : "2019-12-11T17:50:35Z",
        "updatedAt" : "2019-12-16T19:53:13Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      },
      {
        "id" : "8c8505d7-850a-4aee-ba63-124ed2ed6ad9",
        "parentId" : "26f4c337-1b71-478e-9cd0-44bc499d912b",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Thanks, but is that part of the API semantic? I could not find anything in https://www.tensorflow.org/api_docs/python/tf/math/top_k saying that. If that's not an API guarantee, it means any order is fine?\r\n\r\nFor example, did you see not fixing this causing any problem for any models?",
        "createdAt" : "2019-12-11T18:16:24Z",
        "updatedAt" : "2019-12-16T19:53:13Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "bbd2f786-d1c9-4be3-8be4-9b12f6cb55bd",
        "parentId" : "26f4c337-1b71-478e-9cd0-44bc499d912b",
        "authorId" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "body" : "You are right, looks like there is no guarantee in the API in case of `sorted=False`.\r\n\r\nI didn't find any model failing. I just see that TensorRT only supports `sorted=True`, and I thought we should check for that.",
        "createdAt" : "2019-12-11T18:27:00Z",
        "updatedAt" : "2019-12-16T19:53:13Z",
        "lastEditedBy" : "d8ccd123-f416-49e8-8333-df30e2a1eb20",
        "tags" : [
        ]
      }
    ],
    "commit" : "b8a619c68eae95a4bfb1fb968f774c0e5b6e04f8",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +5089,5093 @@    // but it's safer to not convert because the output of TensorRT might\n    // be different with TensorFlow which can cause confusion.\n    return errors::InvalidArgument(\"Only sorted=True is supported, at\",\n                                   node_def.name());\n  }"
  },
  {
    "id" : "1cdbbe9c-9fa0-4564-b248-722bb024729e",
    "prId" : 32843,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/32843#pullrequestreview-297631786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a233549-2eb7-46fe-a749-11b31047ed30",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Thanks for the improvement! Could you help to add a test for this?",
        "createdAt" : "2019-10-04T14:39:35Z",
        "updatedAt" : "2019-10-07T16:05:28Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "e0900c9e-3844-45cf-bc32-578fa8fa7d3e",
        "parentId" : "3a233549-2eb7-46fe-a749-11b31047ed30",
        "authorId" : "fe09a2fe-5247-4919-9104-9de60f2bd4a3",
        "body" : "Added tests as requested.",
        "createdAt" : "2019-10-04T18:00:12Z",
        "updatedAt" : "2019-10-07T16:05:28Z",
        "lastEditedBy" : "fe09a2fe-5247-4919-9104-9de60f2bd4a3",
        "tags" : [
        ]
      },
      {
        "id" : "604f9f57-6b5c-421f-907a-fb51bc39462d",
        "parentId" : "3a233549-2eb7-46fe-a749-11b31047ed30",
        "authorId" : "fe09a2fe-5247-4919-9104-9de60f2bd4a3",
        "body" : "Added tests as requested.",
        "createdAt" : "2019-10-04T18:01:10Z",
        "updatedAt" : "2019-10-07T16:05:28Z",
        "lastEditedBy" : "fe09a2fe-5247-4919-9104-9de60f2bd4a3",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c8afe88694ac40d6c64f3d999dc29e8d7a23da7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2908,2912 @@}\n\nStatus ConvertPool3D(OpConverterParams* params) {\n  const int kNumDims = 5;\n  const auto& inputs = params->inputs;"
  },
  {
    "id" : "0935c5d3-e39c-4674-9b1f-07575a7d2da8",
    "prId" : 31461,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/31461#pullrequestreview-274949471",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c3d559a-fd46-4fa1-a058-b6a6f1145b9c",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add some comment about what this function does.",
        "createdAt" : "2019-08-14T15:00:58Z",
        "updatedAt" : "2019-08-15T01:43:05Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "372517407a9b82bab8140bb3cb75344f56b6abe2",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +851,855 @@// Example: reorder NDHWC (Tensorflow) -> NCDHW (TensorRT)\ntemplate <typename T>\nvoid Reorder5(const nvinfer1::Dims& shape, const T* idata,\n              const nvinfer1::Dims& istrides, T* odata,\n              const nvinfer1::Dims& ostrides) {"
  },
  {
    "id" : "19d04396-dbfc-4ca9-9e4b-8bf4eb51da95",
    "prId" : 30789,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/30789#pullrequestreview-266847762",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45449d1d-c23b-4b02-aa0b-186eafa096e4",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Is this for backward compatibility? Please comment.",
        "createdAt" : "2019-07-18T17:35:02Z",
        "updatedAt" : "2019-07-30T16:06:06Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "edc758f1-eb95-4da8-8736-bd7b2bfe5d96",
        "parentId" : "45449d1d-c23b-4b02-aa0b-186eafa096e4",
        "authorId" : "95b3f429-07e9-432d-a88d-974769318396",
        "body" : "In the static case, CreateTRTNode uses the original segment graphdef, not the one recreated from the function, so I believe the graph at that point has those nodes, not _Arg/_Retval.",
        "createdAt" : "2019-07-25T19:50:46Z",
        "updatedAt" : "2019-07-30T16:06:06Z",
        "lastEditedBy" : "95b3f429-07e9-432d-a88d-974769318396",
        "tags" : [
        ]
      }
    ],
    "commit" : "f98cde6ddcad49f435d86e5c49a3f3347e707b7f",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +5202,5206 @@      int32 slot_number = -1;\n      string type_key;\n      if (node_def.op() == \"Placeholder\") {\n        if (!strings::safe_strto32(  // non-absl ok\n                node_name.c_str() + strlen(IONamePrefixes::kInputPHName),"
  },
  {
    "id" : "8083ef52-9c41-460f-bece-c0da1a0809a2",
    "prId" : 30789,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/30789#pullrequestreview-263802808",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "360592ec-b107-43bf-9be7-43024a9c7f97",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Same here.",
        "createdAt" : "2019-07-18T17:35:41Z",
        "updatedAt" : "2019-07-30T16:06:06Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "f98cde6ddcad49f435d86e5c49a3f3347e707b7f",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +5243,5247 @@    } else if (IsEngineOutput(node_name)) {\n      int32 slot_number = -1;\n      if (node_def.op() == \"Identity\") {\n        if (!strings::safe_strto32(  // non-absl ok\n                node_name.c_str() + strlen(IONamePrefixes::kOutputPHName),"
  },
  {
    "id" : "c57752ec-af48-469d-b7dd-caa1da5dc389",
    "prId" : 29544,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29544#pullrequestreview-247285790",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d98eeef-13d0-4e99-8680-a4e3be276200",
        "parentId" : null,
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Add `if (params->validation_only) return Status::OK();` after PrepareTensorForShape.",
        "createdAt" : "2019-06-07T20:17:12Z",
        "updatedAt" : "2019-06-19T19:55:03Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "4afb83b4acda52fae413b6960da7a639e7d98070",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +2839,2843 @@  TF_RETURN_IF_ERROR(params->converter->PrepareTensorForShape(\n      inputs.at(1), bias_shape, params->validation_only, &bias_tensor));\n  VLOG(2) << \"Bias shape adjusted to \" << DebugString(bias_shape);\n\n  if (params->validation_only) return Status::OK();"
  },
  {
    "id" : "79e31358-1e8d-451b-b946-b213b1be1685",
    "prId" : 29192,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29192#pullrequestreview-251813852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f440be4-a08d-49dd-ba42-c85a1a87f8c3",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Is it possible to add a test for this fix?",
        "createdAt" : "2019-06-19T16:14:47Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9f9a1189cec92c42ba7e807682daadbdcc236da",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +4210,4214 @@  // does not support int8 at this time.\n  if (should_use_fc ||\n      (can_use_fc &&\n       params->converter->precision_mode() == TrtPrecisionMode::INT8)) {\n    return ConvertFullyConnectedHelper("
  },
  {
    "id" : "ae55a78c-e765-49a7-bf06-93fd98d1daf6",
    "prId" : 29192,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29192#pullrequestreview-251899120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1678f4f7-83ae-498a-b887-d75157b1f871",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Why not checking the feasibility in this case? Please comment.",
        "createdAt" : "2019-06-19T16:21:41Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "5276a1b0-3aa0-4cb8-af0d-ef93a03c4c11",
        "parentId" : "1678f4f7-83ae-498a-b887-d75157b1f871",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "For typically uses of broadcast, we checked that the input dimensions either matched exactly or one of them was 1.\r\nBut for a batch matrix multiply, the dimensions don't line up exactly:\r\n```\r\ninput 0: [N, T, C]\r\ninput 1: [1, C, K]\r\noutput: [N, T, K]\r\n```\r\nSince `C != K` and `T != C`, checkfeasiblity would fail",
        "createdAt" : "2019-06-19T18:38:55Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9f9a1189cec92c42ba7e807682daadbdcc236da",
    "line" : 144,
    "diffHunk" : "@@ -1,1 +4334,4338 @@  nvinfer1::Dims broadcasted_dims_l, broadcasted_dims_r;\n  TF_RETURN_IF_ERROR(GetTrtBroadcastShape(\n      inputs.at(0), inputs.at(1), /*check_feasibility=*/false,\n      &broadcasted_dims_l, &broadcasted_dims_r));\n  nvinfer1::ITensor* tensor_l = nullptr;"
  },
  {
    "id" : "8d92db80-b230-4f25-9ce4-c9c862a11688",
    "prId" : 29192,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29192#pullrequestreview-251813852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a75492ec-1ebf-4a56-b805-8181dfbee22e",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add a note, here if input_l is weights then input_r must be tensor (otherwise should be handled by Grappler).",
        "createdAt" : "2019-06-19T16:24:25Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9f9a1189cec92c42ba7e807682daadbdcc236da",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +4316,4320 @@    // the op would be handled by Grappler.\n    if (input_l.is_weights() &&\n        input_l.GetTrtDims().nbDims > input_r.GetTrtDims().nbDims &&\n        input_l.GetTrtDims().d[0] != 1) {\n      return errors::Unimplemented("
  },
  {
    "id" : "0068ba66-e542-4631-bd6d-8d4b1901541e",
    "prId" : 29192,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29192#pullrequestreview-251813852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3305275-d775-4d9c-b72a-8101c03a1da5",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Also I think the tensor*tensor with broadcast case (i.e. lhs.nbDims != rhs.nbDims) should fail the conversion, which doesn't seem to be covered here? Once covered, can you add a corresponding c++ test?",
        "createdAt" : "2019-06-19T17:05:36Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9f9a1189cec92c42ba7e807682daadbdcc236da",
    "line" : 144,
    "diffHunk" : "@@ -1,1 +4334,4338 @@  nvinfer1::Dims broadcasted_dims_l, broadcasted_dims_r;\n  TF_RETURN_IF_ERROR(GetTrtBroadcastShape(\n      inputs.at(0), inputs.at(1), /*check_feasibility=*/false,\n      &broadcasted_dims_l, &broadcasted_dims_r));\n  nvinfer1::ITensor* tensor_l = nullptr;"
  },
  {
    "id" : "fac67857-2e0b-4903-9a31-411a23ffb4f1",
    "prId" : 29192,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/29192#pullrequestreview-254763209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e6a9126-4161-44f7-aedb-69d64594986a",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "I think this is not sufficient. For example, if both are tensors and one with shape [-1, T, C] and the other with shape [-1, C, K], the converter will accept it. But when user provides [N, T, C] and [1, C, K] at runtime the execution will fail. I'm not sure how to fix this, just FYI. May be good to add a note though.",
        "createdAt" : "2019-06-26T14:37:52Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "e6140494-2afb-443a-b816-3a0f22c2e95a",
        "parentId" : "2e6a9126-4161-44f7-aedb-69d64594986a",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Those inputs are valid and will work",
        "createdAt" : "2019-06-26T14:49:24Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      },
      {
        "id" : "c01ee4e4-7d01-4440-84f5-a6b12963c277",
        "parentId" : "2e6a9126-4161-44f7-aedb-69d64594986a",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Does a TRT engine accept inputs with different batch size? I vaguely remember that it will fail enqueue() but I could be wrong.",
        "createdAt" : "2019-06-26T15:15:24Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "0a14d540-9edd-4c80-ae9e-55685ea3f0ab",
        "parentId" : "2e6a9126-4161-44f7-aedb-69d64594986a",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Yes, there is no way to enqueue two inputs with different batch sizes. But you can still have a tensor in the network with TRT dims of [C, K] which is broadcasted over the batch dimension.",
        "createdAt" : "2019-06-26T17:25:35Z",
        "updatedAt" : "2019-07-03T15:44:03Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9f9a1189cec92c42ba7e807682daadbdcc236da",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +4300,4304 @@      inputs.at(0).GetTrtDims().nbDims != inputs.at(1).GetTrtDims().nbDims) {\n    return errors::Unimplemented(\n        \"Inputs must have the same rank if they are both tensors.\");\n  }\n"
  },
  {
    "id" : "b38ddd8c-9a11-4c42-a99c-4a69d111868a",
    "prId" : 28349,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28349#pullrequestreview-234198731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e9c917a-c052-4251-a534-9d608b5d0d44",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add a fast-path: `if (!std::is_same<int32, CType>::value) { ...do the check; }`",
        "createdAt" : "2019-05-03T05:07:54Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "8c221362-eea9-4d50-a031-09315086d234",
        "parentId" : "8e9c917a-c052-4251-a534-9d608b5d0d44",
        "authorId" : "6609cf87-e91c-4a1b-bb94-950733cde505",
        "body" : "I think the condition in `isIntegerInBounds`:\r\n```\r\nif (std::numeric_limits<Input>::lowest() >= std::numeric_limits<Bounds>::lowest()\r\n      && std::numeric_limits<Input>::max() <= std::numeric_limits<Bounds>::max())\r\n```\r\nwould be evaluated at compile-time, so the compiler can completely optimize away the check in cases where it's unnecessary.",
        "createdAt" : "2019-05-03T16:43:11Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "6609cf87-e91c-4a1b-bb94-950733cde505",
        "tags" : [
        ]
      },
      {
        "id" : "352b2380-7e9b-4450-a425-24b454703db2",
        "parentId" : "8e9c917a-c052-4251-a534-9d608b5d0d44",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Even in that case, it still need to do the copy below `dst[i] = static_cast<int32>(src[i]);`. Can we get rid of that?\r\n\r\nAlso, to make the compiler's life easier please move the bound check outside the function and the for loop.",
        "createdAt" : "2019-05-06T16:31:27Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "9fee21d8-8a1c-4f04-aa5d-1ebe601b0901",
        "parentId" : "8e9c917a-c052-4251-a534-9d608b5d0d44",
        "authorId" : "6609cf87-e91c-4a1b-bb94-950733cde505",
        "body" : "Removed the redundant copy. We still need the check to be inside the loop, since we need to check each individual value in the tensor to make sure it's in bounds. ",
        "createdAt" : "2019-05-06T20:58:26Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "6609cf87-e91c-4a1b-bb94-950733cde505",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bce937dcd6cdf67ca994ff58847b70b40cc9052",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +3158,3162 @@  typedef typename EnumToDataType<dtype>::Type CType;\n  const CType* src = tensor.flat<CType>().data();\n  for (int i = 0; i < tensor.NumElements(); ++i) {\n    // This becomes a no-op if CType is within bounds of int32\n    if (!IsIntegerInInt32Bounds(src[i])) {"
  },
  {
    "id" : "4daeb3cd-762c-4842-80cb-370864d205be",
    "prId" : 28349,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28349#pullrequestreview-234615069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b81240b-8e88-4a6f-b198-acb614ae0b96",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please extend the test to cover newly added types: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc#L1473",
        "createdAt" : "2019-05-07T16:07:49Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bce937dcd6cdf67ca994ff58847b70b40cc9052",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +3218,3222 @@      status = CopyToTrtInt32Array<DT_UINT16>(tensor, dst);\n      break;\n    case DT_UINT32:\n      status = CopyToTrtInt32Array<DT_UINT32>(tensor, dst);\n      break;"
  },
  {
    "id" : "93de3080-a073-4ad5-a989-df23db88202f",
    "prId" : 28349,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28349#pullrequestreview-234615069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5deba20-457c-403b-90d8-faab768b321f",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Please add a test to cover this case.",
        "createdAt" : "2019-05-07T16:08:22Z",
        "updatedAt" : "2019-06-05T23:55:55Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bce937dcd6cdf67ca994ff58847b70b40cc9052",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +3161,3165 @@    // This becomes a no-op if CType is within bounds of int32\n    if (!IsIntegerInInt32Bounds(src[i])) {\n      return errors::InvalidArgument(\"Value at index \", i,\n                                     \" is outside the range of int32\");\n    }"
  },
  {
    "id" : "7d94e046-2aaf-4bad-8fdb-506afe168144",
    "prId" : 27393,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27393#pullrequestreview-221923191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc8f2dea-d8cc-4055-9561-1c80dae04068",
        "parentId" : null,
        "authorId" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "body" : "Need to add `return Status::OK();` here.",
        "createdAt" : "2019-04-02T21:12:22Z",
        "updatedAt" : "2019-04-02T21:48:40Z",
        "lastEditedBy" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "tags" : [
        ]
      },
      {
        "id" : "13ff78b8-5dd8-4fb7-8eae-7bb10abbe539",
        "parentId" : "fc8f2dea-d8cc-4055-9561-1c80dae04068",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Thanks",
        "createdAt" : "2019-04-02T21:58:36Z",
        "updatedAt" : "2019-04-02T21:58:36Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbcf153668b7aa4e0acc354a6bfc438867bf482d",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +4197,4201 @@      /*validation_only=*/false, &output_tensor));\n\n  params->outputs->push_back(TRT_TensorOrWeights(output_tensor));\n  return Status::OK();\n}"
  },
  {
    "id" : "45904694-ac50-44b5-b5bf-07553935ecf6",
    "prId" : 27299,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27299#pullrequestreview-220778977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ddb1832-e797-40f8-a525-d748b1106e36",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Thanks for the fix, could you please add a unit test in the PrepareTensorForShape test suite to cover this use case?",
        "createdAt" : "2019-03-29T22:19:56Z",
        "updatedAt" : "2019-04-01T18:24:55Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "3c8e6bb0-3bfa-4f20-81bd-ec27c0730d08",
        "parentId" : "4ddb1832-e797-40f8-a525-d748b1106e36",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Yes!",
        "createdAt" : "2019-03-29T22:23:47Z",
        "updatedAt" : "2019-04-01T18:24:55Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "274f5dd3769aacbe67e2da9aa8a672b94010b6ab",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1354,1358 @@  // CreateConstantLayer. So we can treat it as a tensor for\n  // AreDimsStaticWithDifferentSize(). This really only matters for 0-D tensors.\n  if (AreDimsStaticWithDifferentSize(input_dims, dims, /*is_tensor=*/true)) {\n    return errors::InvalidArgument(\"Incompatible shapes: \",\n                                   DebugString(input_dims), \" vs. \","
  },
  {
    "id" : "e657b3a4-d0f3-4402-a66e-9d9e528aeaff",
    "prId" : 26850,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/26850#pullrequestreview-216312756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "335d262a-a9ff-47d0-ac73-33b5b9851f0c",
        "parentId" : null,
        "authorId" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "body" : "could this be const auto ? or is this modified?",
        "createdAt" : "2019-03-19T17:19:58Z",
        "updatedAt" : "2019-03-19T17:20:02Z",
        "lastEditedBy" : "c02b6806-c89c-4249-b10e-ef3335355570",
        "tags" : [
        ]
      },
      {
        "id" : "ed2a235f-c797-423c-99f7-75eb64e2c387",
        "parentId" : "335d262a-a9ff-47d0-ac73-33b5b9851f0c",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "`GetSpan<T>` returns a `Span<const T>`, I think that already means it can’t be modified? \r\n\r\nThis variable is not modified so it should be const",
        "createdAt" : "2019-03-19T17:32:04Z",
        "updatedAt" : "2019-03-19T17:34:34Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d61644ad6017b0b958587a04054eaf62984c27f",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +2187,2191 @@  std::vector<int> input_dims(dims.d, dims.d + dims.nbDims);\n  // Get axis to expand on.\n  auto axis = inputs.at(1).weights().GetSpan<int>();\n  if (axis.size() != 1) {\n    return errors::InvalidArgument(\"ExpandDims axis must be a scalar, at \","
  },
  {
    "id" : "8073a604-ee57-40b5-b225-1ec3ed6c737c",
    "prId" : 25763,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25763#pullrequestreview-204356064",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c46d8f3-4619-4581-88d1-953de54d899b",
        "parentId" : null,
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "@smit-hinsu clang-format wanted this weird indention. Not sure why.",
        "createdAt" : "2019-02-15T17:34:36Z",
        "updatedAt" : "2019-02-20T06:50:35Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "f368730b5d0f6c2fa727af9e91020aca39e1ae26",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +3126,3130 @@        {\"Neg\", nvinfer1::UnaryOperation::kNEG},\n            {\"Exp\", nvinfer1::UnaryOperation::kEXP},\n            {\"Log\", nvinfer1::UnaryOperation::kLOG},\n            {\"Sqrt\", nvinfer1::UnaryOperation::kSQRT},\n            {\"Abs\", nvinfer1::UnaryOperation::kABS},"
  },
  {
    "id" : "cecd255f-8935-4bf5-ac60-0752e266cd25",
    "prId" : 25763,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25763#pullrequestreview-205572424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41636d65-69d1-4e82-abdb-182b9ecbcd4e",
        "parentId" : null,
        "authorId" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "body" : "const here as well.",
        "createdAt" : "2019-02-20T04:30:29Z",
        "updatedAt" : "2019-02-20T06:50:35Z",
        "lastEditedBy" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "tags" : [
        ]
      }
    ],
    "commit" : "f368730b5d0f6c2fa727af9e91020aca39e1ae26",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +3122,3126 @@\nconst std::unordered_map<string, nvinfer1::UnaryOperation>* UnaryOperationMap() {\n  static auto* const m =\n      new std::unordered_map<string, nvinfer1::UnaryOperation>({\n        {\"Neg\", nvinfer1::UnaryOperation::kNEG},"
  },
  {
    "id" : "d837c3ef-9eee-4dc3-84b5-c3ada3e85e7d",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-201889170",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0527510-9ffc-46be-9b05-fc83917bf788",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "`begin` and `size` are `const`. Remove the `const &`?",
        "createdAt" : "2019-02-10T05:42:21Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 178,
    "diffHunk" : "@@ -1,1 +2262,2266 @@      input_dims.insert(input_dims.begin() + 1, 1);\n      begin.insert(begin.begin() + 1, 0);\n      size.insert(size.begin() + 1, 1);\n      reshape_dims_added++;\n    }"
  },
  {
    "id" : "6dd4ca5d-46c2-4d48-b1cb-426f6daea56b",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-202281270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8a172a2-6b89-4c76-ab26-3c80a4cc1795",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Don't we need to restore the reshape after restoring transpose?",
        "createdAt" : "2019-02-10T06:07:12Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "1deb5210-56eb-49f4-b7a3-9c3e0aeda70e",
        "parentId" : "f8a172a2-6b89-4c76-ab26-3c80a4cc1795",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Yeah, that is what we are doing.",
        "createdAt" : "2019-02-11T18:59:36Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 249,
    "diffHunk" : "@@ -1,1 +2334,2338 @@    const nvinfer1::ITensor* output_tensor = nullptr;\n    TF_RETURN_IF_ERROR(params->converter->PrepareTensorForShape(\n        input, reshape_dims, &output_tensor));\n    tensor = const_cast<nvinfer1::ITensor*>(output_tensor);\n  }"
  },
  {
    "id" : "eeb6afdd-5c2d-474d-87d7-c7cf32fe46bc",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-201889170",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d995d935-3261-4e64-b373-5e1b28ff2992",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "If `input_dims[0]` is negative (i.e. batch_size is unknown), then `begin[0]` will be 0 no matter what its original value is, this seems to be a bug. I would recommend to check that batch dim is not modified inside this function instead of inside `ConvertStridedSliceHelper()`.",
        "createdAt" : "2019-02-10T07:25:17Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 386,
    "diffHunk" : "@@ -1,1 +2490,2494 @@      begin[i] += input_dims[i];\n    }\n    begin[i] = std::max(0, std::min(begin[i], input_dims[i]));\n    // End\n    if ((1 << i) & end_mask) {"
  },
  {
    "id" : "740f79b1-f177-4d91-a974-00a84b7b96ea",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-202288757",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54ab61ee-4b15-4287-b40a-3923a998f690",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Same here: for negative batch_size it'll always return \"not not supported\", but I think this is overly conservative. E.g. when batch_size is negative, we can support conversion in the following cases (assuming all other checks pass):\r\n```\r\n(begin==0 || begin_mask=1) && end_mask=1 && stride==1\r\n```",
        "createdAt" : "2019-02-10T07:32:52Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "a9a97fb4-0a8d-4753-95a2-e1aede6c69b7",
        "parentId" : "54ab61ee-4b15-4287-b40a-3923a998f690",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Is it possible that end_mask=0 and end == batch_size instead? We would want to convert in that case as well.",
        "createdAt" : "2019-02-11T19:16:17Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 393,
    "diffHunk" : "@@ -1,1 +2497,2501 @@      end[i] += input_dims[i];\n    }\n    end[i] = std::max(0, std::min(end[i], input_dims[i]));\n  }\n  // Negative or zero strides currently not supported."
  },
  {
    "id" : "8c8a0737-3e01-4d11-b7d4-4010c35c80b9",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-201889170",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58e3d709-a18b-4346-8f5c-6ed3f97292ba",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "If `input.batch_size()` is negative `size[0]` will be negative and it'll always return \"op not supported\". To solve this I think we should check the batch dim inside this function. Also see my comment below.",
        "createdAt" : "2019-02-10T07:38:11Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 320,
    "diffHunk" : "@@ -1,1 +2424,2428 @@  for (int i = 1; i < input_dims.size(); i++) {\n    if (size[i] == -1) {\n      size[i] = input_dims[i] - begin[i];\n    }\n  }"
  },
  {
    "id" : "94b1d225-b1ae-4d5c-b41b-02e7bd337d03",
    "prId" : 25531,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25531#pullrequestreview-203391974",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da149e2c-a813-40d2-9d61-63772ba7810a",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Just curious: why do we need to add this no-op layer? Does adding the input tensor as output work?",
        "createdAt" : "2019-02-12T06:17:37Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "dd876e93-04f9-491c-b464-875a00da6b7f",
        "parentId" : "da149e2c-a813-40d2-9d61-63772ba7810a",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "The C++ unit tests crash in the case that no layer is created, because an engine cannot be empty. Perhaps it would be better if I improved the capability of the unit tests?",
        "createdAt" : "2019-02-12T18:59:55Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      },
      {
        "id" : "2a13c048-84a4-45cc-b73e-78367deea955",
        "parentId" : "da149e2c-a813-40d2-9d61-63772ba7810a",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Agreed, could you add a comment about this and a TODO?",
        "createdAt" : "2019-02-13T19:05:13Z",
        "updatedAt" : "2019-02-14T16:59:00Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "63edb33a3a7b9d262b9beae650e36fc0d96ce9ec",
    "line" : 211,
    "diffHunk" : "@@ -1,1 +2283,2287 @@    // as output here.\n    if (params->validation_only) return Status::OK();\n    nvinfer1::IShuffleLayer* layer = params->converter->network()->addShuffle(\n        *const_cast<nvinfer1::ITensor*>(input.tensor()));\n    params->outputs->push_back(TRT_TensorOrWeights(layer->getOutput(0)));"
  },
  {
    "id" : "bb7ab99a-6263-4dbf-9ccf-8c64cc24a2f5",
    "prId" : 25328,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25328#pullrequestreview-198925585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d636735-296b-402f-895f-5d15ce97ad20",
        "parentId" : null,
        "authorId" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "body" : "Take both params by const reference so that it is clear that they are inputs. And in case of params, that it can't be nullptr.",
        "createdAt" : "2019-02-01T04:49:46Z",
        "updatedAt" : "2019-02-01T17:44:36Z",
        "lastEditedBy" : "d5b52da7-e430-40b5-acaf-5ed00acf4442",
        "tags" : [
        ]
      }
    ],
    "commit" : "d22fe4022cfd0e142e6f014899dbb8a7856897f4",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1302,1306 @@// while false means the input must be a tensor. In the future, false will mean\n// the input can be a tensor or weight.\ntensorflow::Status CheckInputsWeights(\n    const OpConverterParams& params,\n    const std::vector<std::pair<string, bool>>& inputs_is_weight) {"
  },
  {
    "id" : "c4b0f322-bd45-4e0b-91cb-564f71742b32",
    "prId" : 25180,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/25180#pullrequestreview-196728168",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e212411-a932-4dbf-a417-6c4fbf6cf0a3",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Do we need to set the type ***after*** marking it as output? Can we add a test for this fix as well?",
        "createdAt" : "2019-01-24T23:08:59Z",
        "updatedAt" : "2019-01-25T21:56:54Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "ad450f1c-7a50-4837-bc62-0a29b937576d",
        "parentId" : "5e212411-a932-4dbf-a417-6c4fbf6cf0a3",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "Yes, it must be after marking it as an output.\r\nI think the only difference is that if you set the type before, TRT will log a warning. But they claim to only support setType for inputs and outputs so we shouldn't do that.",
        "createdAt" : "2019-01-24T23:56:36Z",
        "updatedAt" : "2019-01-25T21:56:54Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      },
      {
        "id" : "d2a582bf-32bb-4a55-9f88-7933245e53f8",
        "parentId" : "5e212411-a932-4dbf-a417-6c4fbf6cf0a3",
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "Cool, thanks. If you can help to add a simple test using maybe TopK, to reproduce the problem (i.e. output dtype is kFLOAT before but kINT32 after), then we're good to go.",
        "createdAt" : "2019-01-25T01:14:53Z",
        "updatedAt" : "2019-01-25T21:56:54Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "f5e45332-1f76-44b8-bff7-78a6ee4b8a0c",
        "parentId" : "5e212411-a932-4dbf-a417-6c4fbf6cf0a3",
        "authorId" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "body" : "@aaroey Thanks, I have added a test.",
        "createdAt" : "2019-01-25T21:57:13Z",
        "updatedAt" : "2019-01-25T21:57:13Z",
        "lastEditedBy" : "7604040f-899b-4297-b5a5-c102eff4447a",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b1af3223042817fe3999dc961ee7dfa469324ef",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +979,983 @@    tensor->setName(output.dest_node_name.c_str());\n    network()->markOutput(*tensor);\n    // Set type after marking as output. TRT only supports setType for engine\n    // outputs and inputs (type is inferred otherwise).\n    tensor->setType(output.trt_dtype);"
  }
]