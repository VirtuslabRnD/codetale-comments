[
  {
    "id" : "6bd6cf0e-2ad5-427f-a090-2de3b5834f69",
    "prId" : 48383,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48383#pullrequestreview-657181011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd9477ae-7354-4c5d-806a-d925b7e519cf",
        "parentId" : null,
        "authorId" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "body" : "Can you document what are the returned values?",
        "createdAt" : "2021-05-11T19:59:12Z",
        "updatedAt" : "2021-05-11T20:40:49Z",
        "lastEditedBy" : "db119d71-0485-413b-9ea8-fd044b814e31",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bc7865cd7dff8c7b11c2f8afd60bcce69d4397d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1362,1366 @@// row vectorization.  The int is the number of inputs with the higher\n// rank.\nstd::pair<bool, int> RowVectorizationEnabled(mlir::lmhlo::FusionOp fusion) {\n  const auto is_row_major = [](mlir::Value value) {\n    // Only tested when the inputs are row-major. So only"
  },
  {
    "id" : "ee5ab9d0-3fa9-4f4d-bdd9-68cdfd77c6e4",
    "prId" : 48381,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48381#pullrequestreview-631352424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78c57cca-600c-4019-9d39-5e7782a9edef",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "RowVectorizationEnabled?",
        "createdAt" : "2021-04-07T22:39:01Z",
        "updatedAt" : "2021-04-09T19:12:28Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "5cd631ac-2766-4f15-8e8d-c54d707f9492",
        "parentId" : "78c57cca-600c-4019-9d39-5e7782a9edef",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "done.",
        "createdAt" : "2021-04-08T12:50:57Z",
        "updatedAt" : "2021-04-09T19:12:28Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "b96cbc778afb98d8b6fcf44b22f28fbc67dc5267",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +1360,1364 @@}\n\n// Determine if we enable the row optimized codegen.  When we have a\n// fusion with only point-wise operations, scalar broadcasting and row\n// broadcasting, we can trigger a kernel that vectorize the row loads."
  },
  {
    "id" : "33aa2fdc-4470-4be0-a6ec-c1fd3e7557d2",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-371208414",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Do we need to be specific about what reduction is vectorized?",
        "createdAt" : "2020-03-05T01:08:00Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "3765d965-5bff-41c0-b840-d3fdcbbd0acb",
        "parentId" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "I suppose you mean to check what inside the to_apply() HloComputation of the reduction.\r\nIn theory yes. But it wasn't done before. I'm not sure it is worth doing it.\r\nSo I'll add a todo about this to let people know about this.",
        "createdAt" : "2020-03-05T14:22:48Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "17c1f062-ab83-4436-ae00-1d8896c58912",
        "parentId" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Maybe let's make it more specific: state what kind of reductions still prevent vectorization.",
        "createdAt" : "2020-03-05T18:35:17Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "cd589259-bfd9-4343-9e23-c780ec1222ad",
        "parentId" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Reduction doesn't prevent vectorization. This is the point. The function MayPreventVectorization() return true when it may prevent vectorization. False when it doesn't.\r\n\r\nMaybe I could add a comment that tell reduction doesn't block vectorization or add a comment to the default case, that we suppose by default all operation block vectorization?",
        "createdAt" : "2020-03-05T19:12:32Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "ab5acc17-9836-4231-a540-1ea81b2a504d",
        "parentId" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "> Reduction doesn't prevent vectorization. This is the point\r\n\r\nI understand, I mean: could you specify in the comment explicitly what needs to be checked and why, e.g. \"return false only for row reductions which are ...\"?",
        "createdAt" : "2020-03-07T01:35:16Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "fe2fef6a-1b7a-40d0-ac99-47dee4897c02",
        "parentId" : "4796b7fc-54ec-4132-abd0-20a3ca97feae",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "This function is independent of the reduction being a row or a columns reductions. I updated it to be tell what to check.",
        "createdAt" : "2020-03-09T14:29:39Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1900,1904 @@    // TODO: check if the to_apply() attribute contains instruction\n    // that break LLVM vectorization.\n    return false;\n  }\n  return true;"
  },
  {
    "id" : "0d9c0d13-aeab-4e42-bc7c-e110b435b0af",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-369815102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f1858a9-29d2-4870-bc83-2de16384df50",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Perhaps insert a CHECK on what the indexing order has to be in the third case?",
        "createdAt" : "2020-03-05T01:09:10Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "9775b292-233d-4802-975d-e9fb194d4ae5",
        "parentId" : "5f1858a9-29d2-4870-bc83-2de16384df50",
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "I mean, you are assuming that the indexing order has to be linear, so it's useful to check for that.",
        "createdAt" : "2020-03-05T18:36:07Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1938,1942 @@  }\n  CHECK_EQ(mapping_scheme.GetIndexingOrder(), kLinearIndexingX);\n  int64 x_num_steps =\n      mapping_scheme.GetTileSizeX() / mapping_scheme.GetNumThreadsX();\n  return b->CreateMul(thread_id_x, constant(x_num_steps));"
  },
  {
    "id" : "a7018911-e2a8-4316-a558-48a042ea7087",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-369836570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f21d4026-4950-4121-b8c8-0b07c3e1fbf9",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Is this why the change to `MayPreventVectorization` was necessary? Or is that for fused computations as well?",
        "createdAt" : "2020-03-05T18:56:03Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "54ce2aa8-9d77-4308-9532-c85206843d1a",
        "parentId" : "f21d4026-4950-4121-b8c8-0b07c3e1fbf9",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "This new call cause the change to MayPreventVectorization.",
        "createdAt" : "2020-03-05T19:07:05Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "14f6e440-10f8-473a-acd2-ab0ee6268eff",
        "parentId" : "f21d4026-4950-4121-b8c8-0b07c3e1fbf9",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Exact. This new call cause the change done to MayPreventVectorization.",
        "createdAt" : "2020-03-05T19:10:06Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 306,
    "diffHunk" : "@@ -1,1 +3228,3232 @@        // Assuming XLA will perform the unrolling and LLVM will vectorize,\n        // disable the unroll for the cases that LLVM doesn't vectorize.\n        !MayPreventVectorization(*unnested_hlo)) {\n      vector_size = 2;\n    } else {"
  },
  {
    "id" : "4645b297-5017-47e4-a0c8-3fc92b1a98bd",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-370710396",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be343c89-db8f-459d-83aa-5adb3fa73d10",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "You don't need to explicitly dereference the function pointer, `emit_elem_function(...)` will do.",
        "createdAt" : "2020-03-07T01:37:14Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +1973,1977 @@                              &b_);\n      auto emit_element = [&] {\n        return (*emit_elem_function)(source_idx_x, y_loc, x_loc, linear_index);\n      };\n      if (check_x_tile_bounds) {"
  },
  {
    "id" : "44c284b7-77eb-4c49-bf83-e8fa77a5fdc1",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-382903356",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "850e38b5-54c4-474c-b1e2-ae0071a2752d",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Sorry, I am a bit confused on what is going on here, this code is new.\r\nWhy rank 2? Isn't `[2]` out of bounds in this case?",
        "createdAt" : "2020-03-26T23:22:52Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "218a8693-85be-49db-b18c-b3daf720756e",
        "parentId" : "850e38b5-54c4-474c-b1e2-ae0071a2752d",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Their is a \"normalization\" step of the input shapes to a 3d shape. So a matrix of shape MxN is converted to 1xMxN. A 3d tensor of shape MxNxK that we reduce on the first 2 dimensions is converted to a shape of 1xM*NxK, ...\r\nThis help simplify the code generator as the shapes he do not need to optimize those part.\r\n\r\nBut when we want to trigger the read, we need to \"unnormalize\" the shapes/indexing. This unnormalization isn't always well cleaned up by LLVM. This unnormalization is also done for each elements read, not once per threads.\r\n\r\nSo here, I simplify remove this unnormalization step when it isn't needed. This clean up the not optimized LLVM code and allow LLVM to vectorize more this case.\r\n\r\nThe unnormalization is taking the normalized 3d indexing, converting it to a 1d indexing, then converting it back to the original indexing. It is a afair amount of LLVM code.\r\n\r\nas multidim is the normalized shapes that is always 3d, multidim[2] is valid.",
        "createdAt" : "2020-03-27T14:23:40Z",
        "updatedAt" : "2020-03-30T21:10:31Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 189,
    "diffHunk" : "@@ -1,1 +2110,2114 @@    DCHECK_EQ(normalized_shape_index.dims()[0], 0);\n    auto multidim = normalized_shape_index.multidim();\n    return IrArray::Index({multidim[1], multidim[2]}, unnormalized_shape,\n                          normalized_shape_index.GetType());\n  }"
  },
  {
    "id" : "4d8b9f78-8350-494a-818a-930dab452a99",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-385752591",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62ca4b0f-a043-4360-a5fa-2500e90e51aa",
        "parentId" : null,
        "authorId" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "body" : "This DCHECK is wrong, it should check that the trivial dimension 0 has value 1.\r\nDCHECK_EQ(normalized_shape_index.dims()[0], 1)",
        "createdAt" : "2020-04-01T11:40:32Z",
        "updatedAt" : "2020-04-01T11:46:21Z",
        "lastEditedBy" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "tags" : [
        ]
      },
      {
        "id" : "03285f7b-1bcc-4a48-865d-ebe179c41686",
        "parentId" : "62ca4b0f-a043-4360-a5fa-2500e90e51aa",
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Going further, can we make it a CHECK_EQ instead?",
        "createdAt" : "2020-04-01T16:29:04Z",
        "updatedAt" : "2020-04-01T16:29:04Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 187,
    "diffHunk" : "@@ -1,1 +2108,2112 @@      unnormalized_shape.dimensions()[1] == normalized_shape_index.dims()[2] &&\n      unnormalized_shape.layout().minor_to_major(1) == 0) {\n    DCHECK_EQ(normalized_shape_index.dims()[0], 0);\n    auto multidim = normalized_shape_index.multidim();\n    return IrArray::Index({multidim[1], multidim[2]}, unnormalized_shape,"
  },
  {
    "id" : "9aa98fef-203f-4ae5-8b4c-2f0fb92b27ca",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-385503035",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d21d8a4-e482-46fb-9a8f-e8f583aec9f4",
        "parentId" : null,
        "authorId" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "body" : "this should be named unroll_inner_tile_loop according to the style guide. It is still a variable.",
        "createdAt" : "2020-04-01T11:41:43Z",
        "updatedAt" : "2020-04-01T11:46:21Z",
        "lastEditedBy" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +2045,2049 @@        llvm::Value* y_loc = b_.CreateAdd(\n            thread_id_info.thread_id_y, b_.CreateMul(y_indvar, num_threads_y));\n        auto unrollInnerTileLoop = [&](bool check_x_tile_bounds) {\n          return UnrollInnerTileLoop(check_x_tile_bounds, x_num_steps, step_x,\n                                     vector_size, loop_name, ksl,"
  },
  {
    "id" : "85afe030-99e3-4be0-9d91-ca62fb5829f7",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-385503035",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "debc14ee-9874-4f4a-88fc-fd3bec840111",
        "parentId" : null,
        "authorId" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "body" : "You could pull this line out of this function and already pass a source_idx_y to the function.\r\nLess generated code, although it would certainly be optimized away by LLVM anyway.",
        "createdAt" : "2020-04-01T11:42:41Z",
        "updatedAt" : "2020-04-01T11:46:21Z",
        "lastEditedBy" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +1969,1973 @@                                        start_offset_x, \"x_loc\");\n      IrArray::Index source_idx_x =\n          source_idx.AddOffsetToDim(y_loc, kDimY, &b_)\n              .AddOffsetToDim(constant(j * step_x * vector_size + i), kDimX,\n                              &b_);"
  },
  {
    "id" : "55c41e61-7572-4dcf-8f73-0f377c2fe316",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-385508830",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11165794-0bf6-4d5f-9616-42a5df57a7e8",
        "parentId" : null,
        "authorId" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "body" : "The int's should be int64's",
        "createdAt" : "2020-04-01T11:49:44Z",
        "updatedAt" : "2020-04-01T11:50:53Z",
        "lastEditedBy" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +1963,1967 @@    return llvm::ConstantInt::get(index_ty, val);\n  };\n  for (int j = 0; j < x_num_steps / vector_size; j++) {\n    for (int i = 0; i < vector_size; i++) {\n      int linear_index = j * vector_size + i;"
  },
  {
    "id" : "e3529f46-1add-40e5-a09a-be134bebc997",
    "prId" : 37260,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37260#pullrequestreview-385508830",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17d4ba12-466a-49f1-9012-6d65f1553be1",
        "parentId" : null,
        "authorId" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "body" : "Please pass source_idx as const reference (it is not changed), and a pointer IrBuilder instead of a reference (this is according to the style guide).",
        "createdAt" : "2020-04-01T11:50:49Z",
        "updatedAt" : "2020-04-01T11:50:53Z",
        "lastEditedBy" : "68fac570-a499-4a66-bf20-f8f2cbebf597",
        "tags" : [
        ]
      }
    ],
    "commit" : "40759ec97aca9b1870c9827829c18e8121b554a1",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +1957,1961 @@    int64 vector_size, const string& loop_name, KernelSupportLibrary* ksl,\n    llvm::Value* start_offset_x, llvm::Value* y_loc, llvm::Value* tile_width,\n    IrArray::Index& source_idx, llvm::IRBuilder<>& b_,\n    const IrEmitterUnnested::EmitElementFunction* emit_elem_function) {\n  llvm::Type* index_ty = tile_width->getType();"
  },
  {
    "id" : "a649ca0f-6fd1-4d0b-9cf1-b43474e8b4ab",
    "prId" : 36384,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/36384#pullrequestreview-353260482",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dabdf9d1-2c35-4534-8c24-f79c0f8e3062",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Note that tile_size_x is per thread block, wouldn't you need to divide by num_threads_x first?",
        "createdAt" : "2020-02-04T01:41:14Z",
        "updatedAt" : "2020-02-04T14:11:30Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "7cbdd6f6-18ed-4a3b-9358-afb822dba754",
        "parentId" : "dabdf9d1-2c35-4534-8c24-f79c0f8e3062",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Lets dive in the detail to make sure what should be done. I could have misunderstood something.\r\n\r\nSuppose we have a matrix of M,N and we reduce rows, so the output is of size M.\r\n\r\nWe have each thread handle up to U number. (The \"unroll\" factor)\r\nWe have num_threads_x the number of threads per block.\r\nWe have each block reduce a total of tile_size_x number.\r\nTo my understanding, the potential number of load from all the threads in a block : tile_size_x=num_threads_x*U.\r\nCurrently, when N isn't a multiple of tile_size_x, we launch an block that would reduce fewer elements then tile_size_x. then some threads would read invalid data. So there is a condition to check if the next element to read is within bound.\r\n\r\nDid I miss something? Mostly, if all threads from all blocks will always full unroll, we do not need the conditions.\r\nThe [pseudo-code](https://github.com/tensorflow/tensorflow/blob/eacb0742a9816ecfcd6e2710e0d1244fdd59f654/tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc#L1920) make me understand that one block can read up to tile_size_x elements.\r\n\r\nFor cols reduction, always_full_tile see to be frequently, but not always true in tests. I think the logic works too for columns reduction. All reduction tests that I found pass. ",
        "createdAt" : "2020-02-04T16:29:38Z",
        "updatedAt" : "2020-02-04T16:29:39Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "8928afa9-c838-4433-b512-ad5f71d53b3d",
        "parentId" : "dabdf9d1-2c35-4534-8c24-f79c0f8e3062",
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Suppose we get\r\n\r\n```\r\nnum_threads_x=32\r\ntile_size_x=32\r\ndims[2]=512\r\n```\r\n\r\n512 is divisible by 32, but not all threads will fit, as e.g. thread 15 will try to make accesses 480, 512, 544, 576, etc, and only the first two will be in bounds.",
        "createdAt" : "2020-02-04T19:24:27Z",
        "updatedAt" : "2020-02-04T19:24:27Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "2bac8467-199c-434a-a7f6-0c344f94cb95",
        "parentId" : "dabdf9d1-2c35-4534-8c24-f79c0f8e3062",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "In this case, each thread will only do 1 element. And many block will be submited.\r\nFrom this line: https://github.com/tensorflow/tensorflow/blob/eacb0742a9816ecfcd6e2710e0d1244fdd59f654/tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc#L1947\r\n\r\nWe see that the number of element one thread will load is \"tile_size_x / num_threads_x\". So 1 in this case.",
        "createdAt" : "2020-02-04T19:58:16Z",
        "updatedAt" : "2020-02-04T19:58:17Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "a00c29f2b4396d21388ee13038f59719d8753605",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1960,1964 @@  // So we do not need to emit condition.\n  bool always_full_tile =\n      mapping_scheme.GetDimsInElems()[2] % tile_size_x == 0;\n\n  ksl->For("
  },
  {
    "id" : "d49a4b57-c9ac-4582-9bee-b706ec46a42f",
    "prId" : 34880,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/34880#pullrequestreview-331462017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2abee867-5021-4ba5-b928-9907cf3a04a8",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "Actually you can just write `[&] -> ...`",
        "createdAt" : "2019-12-12T16:30:54Z",
        "updatedAt" : "2019-12-12T19:13:32Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "d6db3812-9cf8-4892-8e85-e06ec235d244",
        "parentId" : "2abee867-5021-4ba5-b928-9907cf3a04a8",
        "authorId" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "body" : "Ah. Will make the change.",
        "createdAt" : "2019-12-12T18:25:58Z",
        "updatedAt" : "2019-12-12T19:13:32Z",
        "lastEditedBy" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "tags" : [
        ]
      },
      {
        "id" : "3639c73f-6860-4989-bfba-4bb126dd3e9e",
        "parentId" : "2abee867-5021-4ba5-b928-9907cf3a04a8",
        "authorId" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "body" : "Did not make this change as I don't want to drop `-> absl::Span<HloInstruction* const>`",
        "createdAt" : "2019-12-12T19:14:46Z",
        "updatedAt" : "2019-12-12T19:15:53Z",
        "lastEditedBy" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6af4a54a1ecc1db750084781b0e409eddead606",
    "line" : 95,
    "diffHunk" : "@@ -1,1 +3129,3133 @@\n  HloInstruction* slice_or_tuple = unnested_hlo->fused_expression_root();\n  auto slice_instructions = [&]() -> absl::Span<HloInstruction* const> {\n    if (slice_or_tuple->opcode() == HloOpcode::kSlice) {\n      return absl::Span<HloInstruction* const>(&slice_or_tuple, 1);"
  }
]