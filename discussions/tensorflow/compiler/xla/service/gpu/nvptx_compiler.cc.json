[
  {
    "id" : "6ddcd954-5d81-4cb6-a9b0-c476831e5922",
    "prId" : 47121,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47121#pullrequestreview-595684121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d19c4cc1-0d44-4262-a833-515787718ea9",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "This change can be dropped from this commit?",
        "createdAt" : "2021-02-17T00:41:43Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "2fcc81bf-8190-4d75-8100-f008a3044d9d",
        "parentId" : "d19c4cc1-0d44-4262-a833-515787718ea9",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Moved to a commit just for that.",
        "createdAt" : "2021-02-23T15:31:09Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "deb37ee994c8923a5405b0ea5544a9f5e1e2cad2",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +206,210 @@bool MaybeLoadPtxFromFile(const HloModuleConfig module_config,\n                          const HloModule* module, std::string* ptx) {\n  // If the xla_gpu_ptx_file option is set, be explicit if a file is used\n  // and warn when a file is not used to ease catching typo in filename.\n  std::string prefix = xla::FilenameFor(*module, \"\", *ptx);"
  },
  {
    "id" : "fd0a20ed-3fee-4ed3-867c-45eb09ee4493",
    "prId" : 47121,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47121#pullrequestreview-595684121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a83a708-9208-4ec9-95bb-f7bca04c3965",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "I'm not sure I've seen VLOG(0) before: what is the intended semantics? Same as VLOG(1)?",
        "createdAt" : "2021-02-17T02:47:34Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "1632648d-b577-4efc-9547-55f758559df4",
        "parentId" : "8a83a708-9208-4ec9-95bb-f7bca04c3965",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "This is used in a few files. So this isn't a first in TF. I want that to always be printed. VLOG(0) does that.",
        "createdAt" : "2021-02-23T16:15:41Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "deb37ee994c8923a5405b0ea5544a9f5e1e2cad2",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +260,264 @@  if (xla_gpu_llvm_ir_file.size() > 0 &&\n      matched_filename == std::end(xla_gpu_llvm_ir_file)) {\n    VLOG(0) << \"RunBackend() - For module with prefix '\" << prefix\n            << \"', we did not found a LLVM file to load.\";\n  }"
  },
  {
    "id" : "65b01008-8c18-4cb7-98e4-44173a079292",
    "prId" : 47121,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/47121#pullrequestreview-595684121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89f48f41-7e1f-442e-928d-df930caa01fe",
        "parentId" : null,
        "authorId" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "body" : "LOG(FATAL) seems a bit harsh here, maybe return StatusOr instead?",
        "createdAt" : "2021-02-17T02:49:39Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "46fa9a61-9f6f-4ecb-a276-f19713d630df",
        "tags" : [
        ]
      },
      {
        "id" : "a08376e1-0ba2-4488-a714-be4b28c8819a",
        "parentId" : "89f48f41-7e1f-442e-928d-df930caa01fe",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "This would change the function signature that is `std::unique_ptr<llvm::Module>`.\r\nHere, we need to crash. I can change that function signature if you think this would give a better error message.\r\nI do not know what between `StatusOr` and `LOG(FATAL)` give the best error message. Do you?",
        "createdAt" : "2021-02-23T16:18:47Z",
        "updatedAt" : "2021-02-25T22:15:30Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "deb37ee994c8923a5405b0ea5544a9f5e1e2cad2",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +273,277 @@    if (!loaded_module) {\n      err.print(\"ERR\", llvm::errs());\n      LOG(FATAL) << \"Failed to load an LLVM file. It is probably invalid LLVM.\";\n    }\n    // Overwrite the dumped not optimized LLVM to show which one will be used."
  },
  {
    "id" : "118dbf13-e39a-4ae4-bcb2-28bf3c7fdbee",
    "prId" : 43888,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/43888#pullrequestreview-505042706",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d6506f3-5fb6-4fb9-ba42-38ea7dbb7d88",
        "parentId" : null,
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "The diff show up stream. I didn't move MaybeLoadPtxFromFile.\r\nI moved the function WarnIfBadDriverJITVersion outside the unnamed namespace. ",
        "createdAt" : "2020-10-08T18:11:26Z",
        "updatedAt" : "2020-10-15T15:15:25Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "7544886e58debd75b169f14d2843cfa38b17d178",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +200,204 @@\n// Try to load ptx from files defined in the FLAGS. If successful, return true.\nbool MaybeLoadPtxFromFile(const HloModule* module, std::string* ptx) {\n  // If the xla_gpu_ptx_file options is set, be explicit when a file is used\n  // and warn when a file is not used to ease catching typo in filename."
  },
  {
    "id" : "7c9a9173-e478-4878-aa0b-1d0cf2158f1a",
    "prId" : 43888,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/43888#pullrequestreview-507735607",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3441973-c25b-482a-a78d-763cf006662b",
        "parentId" : null,
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "XLA used to silently fallback to the driver when ptxas couldn't be found or compilation failed. The silent fallback behavior led to several bugs reported by users that were hard to reproduce and diagnose. We hence decided to turn ptxas issues into fatal errors (few people notice warnings in logs) and allow manual overwrite by the flag (--xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found).\r\nHave you considered to introduce a flag for the _ptxas_too_old case? I think that would be the better option.",
        "createdAt" : "2020-10-09T07:44:42Z",
        "updatedAt" : "2020-10-15T15:15:25Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      },
      {
        "id" : "d0d60fd7-4d8f-4433-8a72-7e3d3a391766",
        "parentId" : "f3441973-c25b-482a-a78d-763cf006662b",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Here it isn't a real compilation failure. Just that PTXAS doesn't know a specific SM version.\r\n\r\nWhere can I have more information about the bug that you had that triggered this decision?\r\n\r\nI'll think about your suggestion and come back about it.",
        "createdAt" : "2020-10-09T13:30:20Z",
        "updatedAt" : "2020-10-15T15:15:25Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "9ed8b1f3-2a95-4009-814a-f85b5997daef",
        "parentId" : "f3441973-c25b-482a-a78d-763cf006662b",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "Quick follow up:\r\nFor currently supported GPU, there is no change. The new fallback is only for new GPUs. So when an (current or old) container is used on a newer GPU, the fallback is used.",
        "createdAt" : "2020-10-13T18:51:23Z",
        "updatedAt" : "2020-10-15T15:15:25Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      }
    ],
    "commit" : "7544886e58debd75b169f14d2843cfa38b17d178",
    "line" : 91,
    "diffHunk" : "@@ -1,1 +416,420 @@                  hlo_module_config);\n            }\n          } else if (maybe_cubin.status().code() !=\n                     tensorflow::error::Code::UNIMPLEMENTED) {\n            // If unimplemented is returned, we fallback to the driver."
  },
  {
    "id" : "77c03aff-9678-44b2-b012-aaa9b7386fa0",
    "prId" : 34284,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/34284#pullrequestreview-322527114",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00c3f20f-1639-40c0-baa4-08ef707f7ad1",
        "parentId" : null,
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "This custom call is created by Visitor::HandleBatchNormTraining. Can we run algebraic_simplifier before that and use the fact \"batchnorm HLO returns {output, mean, variance} and variance is non-negative\" to perform the optimization? In this case, I think you may not even need to rely on AlgebraicSimplifierOptions turn on/off the optimization. ",
        "createdAt" : "2019-11-20T21:53:51Z",
        "updatedAt" : "2019-12-12T04:54:38Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "c790b99d-3964-426f-9c50-28361c616308",
        "parentId" : "00c3f20f-1639-40c0-baa4-08ef707f7ad1",
        "authorId" : "f5ab3aa4-6485-4b22-bd3b-5e0b0fefe39b",
        "body" : "I have thought about this but I couldn't not come to the conclusion that the pattern (motivation pattern mentioned in the description) emerges before the rewriter pass. What I can do is add another case to `IsNonNegative` (`IsPositive`) that handles batchnorm HLO. That seems to be a natural extension anyway. ",
        "createdAt" : "2019-11-20T22:19:20Z",
        "updatedAt" : "2019-12-12T04:54:38Z",
        "lastEditedBy" : "f5ab3aa4-6485-4b22-bd3b-5e0b0fefe39b",
        "tags" : [
        ]
      },
      {
        "id" : "3807520e-069b-45f5-87c0-39683e1981b7",
        "parentId" : "00c3f20f-1639-40c0-baa4-08ef707f7ad1",
        "authorId" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "body" : "Can you provide some detail on how the original code and the code generated by Visitor::HandleBatchNormTraining interact and produce the pattern? What I can tell is the transformation replaces a use of the x (batch norm result with index 2) with this function of y (custom call result with index 2):  power(y, -2) - epsilon.",
        "createdAt" : "2019-11-21T00:38:45Z",
        "updatedAt" : "2019-12-12T04:54:38Z",
        "lastEditedBy" : "90c49754-7917-45e3-8dd2-8e09527f3d4c",
        "tags" : [
        ]
      },
      {
        "id" : "6b470704-de6a-4de6-9e7b-b215416aad75",
        "parentId" : "00c3f20f-1639-40c0-baa4-08ef707f7ad1",
        "authorId" : "f5ab3aa4-6485-4b22-bd3b-5e0b0fefe39b",
        "body" : "Before `cudnn_batchnorm_rewiter`, the pattern that exist is `Inv([rsqrt(x+c)*rsqrt(x+c)])-c` which gets transformed to the one handled in this PR. This can also be simplified to `x` but might prove to be non-trivial. I can check if this pattern gets eliminated by existing transforms+the ones I've added here. However, do you think we need to add this case as well? ",
        "createdAt" : "2019-11-25T19:34:16Z",
        "updatedAt" : "2019-12-12T04:54:38Z",
        "lastEditedBy" : "f5ab3aa4-6485-4b22-bd3b-5e0b0fefe39b",
        "tags" : [
        ]
      }
    ],
    "commit" : "a26afaa73334e0b2cb0f324ae2f11b575fec22ce",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +134,138 @@    AlgebraicSimplifierOptions options;\n    options.set_cudnn_batchnorm_forward_training_metadata(\n        kCudnnBatchNormForwardTrainingCallTarget);\n    pass.AddPass<AlgebraicSimplifier>(options);\n  }"
  },
  {
    "id" : "ba1e2f3e-4a63-426c-b459-4acba655f03b",
    "prId" : 30759,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/30759#pullrequestreview-266934889",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1082aa5-6086-4aae-9af9-30413b358c6c",
        "parentId" : null,
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "Regarding VLOG levels: VLOG's purpose is to help understand the program flow at different levels of detail. High log levels are used for high level activities, like \"running buffer assignment\" or alike. Hence, VLOG(0) doesn't seem right here.\r\nWhat we want is to make the user aware of bad flags. That's important. Thinking about this again, the best way to do that is LOG(ERROR) or even LOG(FATAL). What do you think?",
        "createdAt" : "2019-07-25T16:46:57Z",
        "updatedAt" : "2019-07-25T16:47:02Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      },
      {
        "id" : "c071ae87-bb95-4b0a-b1b1-b0385936c3c5",
        "parentId" : "b1082aa5-6086-4aae-9af9-30413b358c6c",
        "authorId" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "body" : "I would need more complicated logic. Do we really want that for such a development feature?\r\nI already error when we have an empty or non-existing file.\r\nCurrently, if a module doesn't have a file, does it mean no file was provided or one file with a bad name?\r\n\r\nThe other option would be to let the user specify explicitly for which module which file is.\r\nBut then we would also need to detect when a module was specified but not created.\r\n\r\nAll option for better error seem more involved and personally I do not think this is worthwhile for such not frequently feature. If you think otherwise, tell me.",
        "createdAt" : "2019-07-25T17:00:21Z",
        "updatedAt" : "2019-07-25T17:00:21Z",
        "lastEditedBy" : "f5c553cb-d123-4eb4-9f6d-9a715871f6eb",
        "tags" : [
        ]
      },
      {
        "id" : "9f90f975-56e4-487b-8021-58018deef386",
        "parentId" : "b1082aa5-6086-4aae-9af9-30413b358c6c",
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "Fair enough.",
        "createdAt" : "2019-07-25T23:39:13Z",
        "updatedAt" : "2019-07-25T23:39:14Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f5e538ba905ee3616f72e73b73742e6ef4a6490",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +242,246 @@      matched_filename.empty()) {\n    VLOG(0) << \"RunBackend() - For module with prefix '\" << prefix\n            << \"', we did not found a PTX file to load.\";\n  }\n"
  }
]