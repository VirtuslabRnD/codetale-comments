[
  {
    "id" : "f5d0b197-1434-4303-abe9-f0ef9eec5457",
    "prId" : 40998,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/40998#pullrequestreview-445809549",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "882b49b2-4cce-419a-a8e6-39a600ff387b",
        "parentId" : null,
        "authorId" : "2861a495-42d5-4ac3-b543-23cf14c0a980",
        "body" : "`static` or put under anonymous namespace.",
        "createdAt" : "2020-07-09T03:23:55Z",
        "updatedAt" : "2020-07-09T17:59:47Z",
        "lastEditedBy" : "2861a495-42d5-4ac3-b543-23cf14c0a980",
        "tags" : [
        ]
      },
      {
        "id" : "f4d95c50-b76d-47fa-8092-614c05c1ce7a",
        "parentId" : "882b49b2-4cce-419a-a8e6-39a600ff387b",
        "authorId" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "body" : "My oversight. Thanks for the catch. Will update it soon,",
        "createdAt" : "2020-07-09T17:07:11Z",
        "updatedAt" : "2020-07-09T17:59:47Z",
        "lastEditedBy" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "tags" : [
        ]
      }
    ],
    "commit" : "372cc81974676059175137698752be6be28b9bd2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +31,35 @@\nnamespace {\nbool ElementIsF32OrF16(const Shape& shape) {\n  PrimitiveType type = shape.element_type();\n  return type == F32 || type == F16;"
  },
  {
    "id" : "37802945-1c9e-4774-a7f9-e1f664d83652",
    "prId" : 28399,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28399#pullrequestreview-239964943",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce481f58-e041-46e3-a275-f49972e87519",
        "parentId" : null,
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "Please revert whitespace changes.",
        "createdAt" : "2019-05-21T11:19:26Z",
        "updatedAt" : "2019-06-04T04:43:10Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      }
    ],
    "commit" : "be4cdca87894da1e2ade25bd120183274228f295",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +150,154 @@    return false;\n  }\n  // The following checks are potentially expensive.\t\n  if (FusionWouldBeTooLarge(*consumer, *producer)) {\n    return false;"
  },
  {
    "id" : "6587ef9d-a2c4-431c-a6c2-e06b79f6b1f6",
    "prId" : 28399,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/28399#pullrequestreview-239964943",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb819920-8f36-49be-8c54-027ab4c25cc6",
        "parentId" : null,
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "Would it make sense to handle variadic reductions in IsFusible too?",
        "createdAt" : "2019-05-21T11:22:23Z",
        "updatedAt" : "2019-06-04T04:43:10Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      }
    ],
    "commit" : "be4cdca87894da1e2ade25bd120183274228f295",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +149,153 @@  if (consumer->opcode() == HloOpcode::kReduce && consumer->shape().IsTuple()) {\n    return false;\n  }\n  // The following checks are potentially expensive.\t\n  if (FusionWouldBeTooLarge(*consumer, *producer)) {"
  }
]