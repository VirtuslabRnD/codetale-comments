[
  {
    "id" : "1786bdac-35f8-4d6e-8cc9-c2b3acc8418b",
    "prId" : 34882,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/34882#pullrequestreview-330914696",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05437e5c-e7a7-43d4-a98e-d70dd5e2d814",
        "parentId" : null,
        "authorId" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "body" : "Is it correct that horizontal fusion works for element-wise instructions only?",
        "createdAt" : "2019-12-11T13:35:20Z",
        "updatedAt" : "2020-01-31T23:59:02Z",
        "lastEditedBy" : "3c76b64e-5fbc-43db-843d-8c0f62dadcab",
        "tags" : [
        ]
      },
      {
        "id" : "163404d1-f215-4a08-9b09-f22468d00d4e",
        "parentId" : "05437e5c-e7a7-43d4-a98e-d70dd5e2d814",
        "authorId" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "body" : "It can work beyond element-wise instructions. I have left some more related comments in another reply.",
        "createdAt" : "2019-12-12T00:17:35Z",
        "updatedAt" : "2020-01-31T23:59:02Z",
        "lastEditedBy" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fc98209952114b68b2eaacc542cff87f193aa8b",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +86,90 @@// different shapes can be horizontally fused. The first pair of reshapes\n// (i.e., Reshape0 and Reshape1) reshape the dims to 1 dimension, so that the\n// outputs of the fused kernels can (always) be concatenated. The second pair\n// of reshapes (Reshape2 and Reshape3) restore the original shapes to the\n// output tensors."
  },
  {
    "id" : "48a84feb-9897-4749-a242-26909a9be98f",
    "prId" : 34882,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/34882#pullrequestreview-337868608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d18b90c9-1023-4296-99d1-dc0b8486843c",
        "parentId" : null,
        "authorId" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "body" : "I polished the comment to make explicit the condition when we can use bitcasts here (instead of using reshape).\r\n\r\nIf the outputs of mul and add are not row-major, we must use reshape, which will introduce copies.",
        "createdAt" : "2020-01-02T21:37:12Z",
        "updatedAt" : "2020-01-31T23:59:02Z",
        "lastEditedBy" : "04e5d7bd-a136-4f0a-9cb0-0e56fd16cec3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fc98209952114b68b2eaacc542cff87f193aa8b",
    "line" : 95,
    "diffHunk" : "@@ -1,1 +93,97 @@// and Reshape3, the other instructions are fused into an input fusion; the\n// output dims of the concatenate will be used as the kernel launch dims.\n// Instruction bitcasts can be used for Reshape2 and Reshape3 as long as the\n// outputs of Mul and Add are row-major.\nclass GpuHorizontalFusion : public HloModulePass {"
  }
]