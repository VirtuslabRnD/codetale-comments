[
  {
    "id" : "a01d55e7-abce-492e-9653-49ca62c6b261",
    "prId" : 31465,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/31465#pullrequestreview-300427599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "parentId" : null,
        "authorId" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "body" : "This test is failing during the merging, it seems the result is not deterministic, we're still investigating. Do you have any idea?",
        "createdAt" : "2019-10-10T17:43:28Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "1c0d3996-f30e-4521-a42e-7a5cdc08f5b5",
        "tags" : [
        ]
      },
      {
        "id" : "831007d1-283a-4ebb-bc83-c852ff240d6e",
        "parentId" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "After some looking / thinking, I don't know why this would fail. One hypothesis is that one of the ops used to implement the solution has changed and now operates non-deterministically, such as the reductions used in the back-prop of implicit broadcast. I think this is very unlikely however, and I'm seeing this test pass on TF `1.15.0rc2` with the same changes to `bias_add` as in this PR applied via a dynamic patch. Is there a publicly-visible commit hash that you could give me that I could try rebasing the changes onto in order to try to reproduce?",
        "createdAt" : "2019-10-10T18:20:57Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      },
      {
        "id" : "a4d95a32-ea34-4739-b193-b0015dfba814",
        "parentId" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "I'm wondering if the test is failing when run using XLA and that the XLA kernel fusion is replacing part or all of the deterministic solution with a non-deterministic kernel.",
        "createdAt" : "2019-10-10T23:48:26Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      },
      {
        "id" : "ce461271-b7f0-4971-a7ae-5c41444358c5",
        "parentId" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "In `tensorflow/tensorflow.bzl` in the master branch, it looks like `xla_enable_strict_auto_jit` is ignored. I'm wondering if it's not being ignored in the CI setup that the test is failing in. I'm wondering if `xla_enable_strict_auto_jit = True` should be removed from `tensorflow/python/kernel_tests/BUILD` for `bias_op_deterministic_test`. As an experiment, do you think it's worth me pushing a commit to this PR branch to remove it, @aaroey ?",
        "createdAt" : "2019-10-11T00:04:37Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      },
      {
        "id" : "fb9abdbb-e3cb-42c1-992e-a8ecdf1b4d2d",
        "parentId" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "I  have reproduced what appears to be the same issue in a slightly different context. Enabling auto-JIT does make that test fail. XLA is probably replacing the deterministic mini-graph of ops with the original non-deterministic op kernel. I'll push a commit with auto-JIT disabled in a minute.",
        "createdAt" : "2019-10-11T01:06:08Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      },
      {
        "id" : "e59d3b9b-9aad-4344-b70d-e07ddaae141d",
        "parentId" : "c07a1e4a-e3cc-4665-a3ab-422681be2d36",
        "authorId" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "body" : "Hi @aaroey, I just disabled XLA JIT for this test in the most recent commit. Please will you review and run tests again and see if that resolves the issue.",
        "createdAt" : "2019-10-11T01:17:06Z",
        "updatedAt" : "2019-10-17T04:07:21Z",
        "lastEditedBy" : "39e3aa8c-a3d1-45a2-8300-9bf553814b31",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff97edee775e6d13912f82897024baf699ff6329",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +94,98 @@    for i in range(5):\n      feed_dict = {upstream_gradients: self._random_ndarray(out_shape)}\n      self._assert_reproducible(bias_gradients_op, feed_dict=feed_dict)\n\n  # TODO(duncanriach): add test coverage for deterministic gradients"
  }
]