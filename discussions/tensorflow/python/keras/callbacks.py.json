[
  {
    "id" : "beeb877d-b839-4285-a262-783084584efe",
    "prId" : 37552,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37552#pullrequestreview-409959845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e00ba14a-3063-4855-a5b2-d700ab141ff6",
        "parentId" : null,
        "authorId" : "1290216e-6c84-49de-987f-71c8f2229351",
        "body" : "Could you retrieve `_decayed_lr` instead? Then the `isinstance` call etc. is taken care of, as well as any potential decay.",
        "createdAt" : "2020-05-07T13:42:24Z",
        "updatedAt" : "2020-07-14T23:01:46Z",
        "lastEditedBy" : "1290216e-6c84-49de-987f-71c8f2229351",
        "tags" : [
        ]
      },
      {
        "id" : "55ae14b5-4c7d-418e-8c1c-85f57dbf9091",
        "parentId" : "e00ba14a-3063-4855-a5b2-d700ab141ff6",
        "authorId" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "body" : "I didn't use `_decayed_lr` here initially since it is a private API that might not behave as expected in all cases.\r\nE.g. using `_decayed_lr` would break usage with `tf.keras.mixed_precision.experimental.LossScaleOptimizer` since it  only wraps an optimizer and would fail when trying to access `self._hyper[\"learning_rate\"]`. Also if users opt to implement optimizers that don't rely on a `learning_rate` hyperparameter to apply gradient updates, `_decayed_lr` would fail as well. Using `getattr(self.model.optimizer, \"lr\", None)` covers both cases, so I would prefer to keep it as, or am I missing something?",
        "createdAt" : "2020-05-11T20:49:34Z",
        "updatedAt" : "2020-07-14T23:01:46Z",
        "lastEditedBy" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "tags" : [
        ]
      },
      {
        "id" : "b0b97d92-da03-41da-9266-ea340b949af7",
        "parentId" : "e00ba14a-3063-4855-a5b2-d700ab141ff6",
        "authorId" : "1290216e-6c84-49de-987f-71c8f2229351",
        "body" : "Thanks for the clarification. I don't think you're missing anything. To be clear: you choose to retrieve the learning rate schedule (or constant, or callable) rather than the value that would actually be used during training (the value from `model._decayed_lr` that might have a decay applied)?",
        "createdAt" : "2020-05-12T11:17:50Z",
        "updatedAt" : "2020-07-14T23:01:46Z",
        "lastEditedBy" : "1290216e-6c84-49de-987f-71c8f2229351",
        "tags" : [
        ]
      },
      {
        "id" : "7a85bdb2-b0cc-441c-851a-d5860161f339",
        "parentId" : "e00ba14a-3063-4855-a5b2-d700ab141ff6",
        "authorId" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "body" : "Yes, I wasn't aware of the `decay` keyword argument, but it looks like it is only included for backward compatibility.",
        "createdAt" : "2020-05-12T11:47:40Z",
        "updatedAt" : "2020-07-14T23:01:46Z",
        "lastEditedBy" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "tags" : [
        ]
      }
    ],
    "commit" : "37a194ac9bed74c01183cc5c4b5db2ebcc0d858c",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2213,2217 @@\n  def _collect_learning_rate(self, logs):\n    lr_schedule = getattr(self.model.optimizer, \"lr\", None)\n    if isinstance(lr_schedule, learning_rate_schedule.LearningRateSchedule):\n      logs[\"learning_rate\"] = lr_schedule(self.model.optimizer.iterations)"
  },
  {
    "id" : "2a419feb-ac83-499d-b046-5afb477a6710",
    "prId" : 35607,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/35607#pullrequestreview-339637554",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "parentId" : null,
        "authorId" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "body" : "Hi, I've seen in most cases that \"Usage Example \" is used or nothing is used at all. However I may be wrong.",
        "createdAt" : "2020-01-06T13:51:29Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "tags" : [
        ]
      },
      {
        "id" : "3ee27442-18ae-4536-b6dc-832c6ec0cc0a",
        "parentId" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "authorId" : "a8fa0254-ffa1-4028-b9e6-a2459d91663e",
        "body" : "I checked multiple classes in tf.estimator, tf.keras.Sequential, tf.keras.callbacks, etc. and they mostly use 'Example'. However, if you have a strong preference for 'Usage Example', let me know and I will channge it.",
        "createdAt" : "2020-01-06T14:35:44Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "a8fa0254-ffa1-4028-b9e6-a2459d91663e",
        "tags" : [
        ]
      },
      {
        "id" : "b5dc4ca0-17f4-4009-b148-d8c9c67aeea1",
        "parentId" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "authorId" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "body" : "haha... No I dont have any strong preference or bias toward \"usage example\" being used.ðŸ˜Š\r\nBut if you wanted to follow the examples in the file they also had ```python``` in them, which, correct me if I misunderstand here, will stop them from running from doctests. What I'm trying to say here is that life can become infinitely easier for you if you follow the guidlines. I mean since they have all the rules to adding documentation to a function. do check it out at https://www.tensorflow.org/community/contribute/docs_ref . Neverthless my input to this pull request may be wildly irrelevant and unnecessary. Do let me know since I too am participating in the gci and am trying to figure all this out.ðŸ––",
        "createdAt" : "2020-01-06T15:12:47Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "tags" : [
        ]
      },
      {
        "id" : "abbc4521-b3ee-4283-8616-51472c827909",
        "parentId" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "authorId" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "body" : "Hey, I know this is out of topic, but, where are all of the people talking. you know the IRC chat. Please let me know I've been dying to find out",
        "createdAt" : "2020-01-06T15:14:04Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "3a20e185-1a58-4286-a2f2-149eb0504764",
        "tags" : [
        ]
      },
      {
        "id" : "c85f4bcd-d658-4010-87d1-752833143c87",
        "parentId" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "authorId" : "a8fa0254-ffa1-4028-b9e6-a2459d91663e",
        "body" : "I have no clue, I don't even know if one exists. This github isn't the right forum to discuss about the IRC chat though :)",
        "createdAt" : "2020-01-06T15:55:57Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "a8fa0254-ffa1-4028-b9e6-a2459d91663e",
        "tags" : [
        ]
      },
      {
        "id" : "d2dec76c-5122-4195-b3aa-bc74f68d1bd4",
        "parentId" : "5bd3758e-4996-47de-afe8-f4d27b53ebf3",
        "authorId" : "d792f478-27ce-4df3-b1b3-6bc58c7c25d6",
        "body" : "PSA to the TensorFlow GCI folks, I've inquired multiple times to the mentors about making an IRC chat, but their stance is that they don't want to due to worries about code plagarism :(",
        "createdAt" : "2020-01-08T04:07:38Z",
        "updatedAt" : "2020-01-09T11:34:57Z",
        "lastEditedBy" : "d792f478-27ce-4df3-b1b3-6bc58c7c25d6",
        "tags" : [
        ]
      }
    ],
    "commit" : "01ff4495c9ee137346afd4cfe8d9fde81324d823",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1461,1465 @@  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n\n  Example:\n  ```python\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
  },
  {
    "id" : "03703491-3b28-4431-89f5-c19dd1460724",
    "prId" : 32734,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/32734#pullrequestreview-294623673",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a7e5f7a-98d3-475c-9f22-116f99a8441d",
        "parentId" : null,
        "authorId" : "40b774fc-91d7-4f0e-9786-a96d78ebce36",
        "body" : "Can you add a comment why these two types are special cases?",
        "createdAt" : "2019-09-27T16:35:55Z",
        "updatedAt" : "2020-01-23T22:59:18Z",
        "lastEditedBy" : "40b774fc-91d7-4f0e-9786-a96d78ebce36",
        "tags" : [
        ]
      },
      {
        "id" : "de6fe87c-7e9b-4913-8d52-90deadb241bf",
        "parentId" : "2a7e5f7a-98d3-475c-9f22-116f99a8441d",
        "authorId" : "c6fff3f2-edd0-4483-89e7-668b7fd5f044",
        "body" : "Done",
        "createdAt" : "2019-09-28T06:15:03Z",
        "updatedAt" : "2020-01-23T22:59:18Z",
        "lastEditedBy" : "c6fff3f2-edd0-4483-89e7-668b7fd5f044",
        "tags" : [
        ]
      }
    ],
    "commit" : "06094928234856a89bf4b607e2fbc9eca9b2d35f",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1395,1399 @@      # therefore we must unwrap their scalar values and\n      # pass to the json-serializable dict 'send'\n      if isinstance(v, (np.ndarray, np.generic)):\n        send[k] = v.item()\n      else:"
  },
  {
    "id" : "b4ca1397-d27e-4ff8-948c-75e2c2ac032a",
    "prId" : 32734,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/32734#pullrequestreview-347639225",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f10b33a-bc17-4c12-9b4f-f4176a763963",
        "parentId" : null,
        "authorId" : "f5dd8398-4230-4def-9f54-7223465d62b8",
        "body" : "Do we know for sure that we'll get only scalar-shaped `numpy.ndarray`s? I understand that in many cases, this is just a numpy scalar. But I don't know if it's possible that the value can be a non-scalar shape (e.g., `(1, 2)`) now or in the future. \r\n\r\ncc @karmel @fchollet \r\n\r\nThere are two options:\r\n1. You may want to add a check of `len(v.shape) == 0` above. \r\n2. Call `v.tolist()` instead.\r\n\r\nI think 2 is the better option, as it works for scalar and non-scalar shapes alike.",
        "createdAt" : "2020-01-18T18:24:46Z",
        "updatedAt" : "2020-01-23T22:59:18Z",
        "lastEditedBy" : "f5dd8398-4230-4def-9f54-7223465d62b8",
        "tags" : [
        ]
      },
      {
        "id" : "39b93373-001c-4154-aa58-9717eb1a40f1",
        "parentId" : "4f10b33a-bc17-4c12-9b4f-f4176a763963",
        "authorId" : "c6fff3f2-edd0-4483-89e7-668b7fd5f044",
        "body" : "Followed up in latter conversations.",
        "createdAt" : "2020-01-23T22:03:56Z",
        "updatedAt" : "2020-01-23T22:59:18Z",
        "lastEditedBy" : "c6fff3f2-edd0-4483-89e7-668b7fd5f044",
        "tags" : [
        ]
      }
    ],
    "commit" : "06094928234856a89bf4b607e2fbc9eca9b2d35f",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +1396,1400 @@      # pass to the json-serializable dict 'send'\n      if isinstance(v, (np.ndarray, np.generic)):\n        send[k] = v.item()\n      else:\n        send[k] = v"
  }
]