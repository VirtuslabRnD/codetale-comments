[
  {
    "id" : "3e959914-0e29-421e-83d3-5444a359a427",
    "prId" : 31106,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/31106#pullrequestreview-268140945",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "036f6aff-d3fa-443e-abdc-fff5dd519971",
        "parentId" : null,
        "authorId" : "0184dacc-e36e-4f02-9c48-fb3acedd41da",
        "body" : "I love the replacement of tile (and its weird interface) with broadcast_to (and its saner interface). I tried to do this in the past and we had to roll it back because it was a performance regression.\r\n\r\nLet's try again.",
        "createdAt" : "2019-07-29T16:30:13Z",
        "updatedAt" : "2019-07-29T16:30:34Z",
        "lastEditedBy" : "0184dacc-e36e-4f02-9c48-fb3acedd41da",
        "tags" : [
        ]
      },
      {
        "id" : "19e28dde-1e88-480b-b4e5-1363fd6912b6",
        "parentId" : "036f6aff-d3fa-443e-abdc-fff5dd519971",
        "authorId" : "1b9eace9-ee4c-4289-a03a-ac37a8082cff",
        "body" : "if broadcast_to is slower than tile then probably broadcast_to kernel needs to be optimized, possibly by replacing it with tile's kernel. They are essentially doing the same thing anyway",
        "createdAt" : "2019-07-30T03:32:25Z",
        "updatedAt" : "2019-07-30T03:32:25Z",
        "lastEditedBy" : "1b9eace9-ee4c-4289-a03a-ac37a8082cff",
        "tags" : [
        ]
      }
    ],
    "commit" : "705d8dae3c132c5860ba2bd3f8ec2ac94f56b36a",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +169,173 @@      output_shape_kept_dims = math_ops.reduced_shape(input_shape, op.inputs[1])\n    grad = array_ops.reshape(grad, output_shape_kept_dims)\n  return [array_ops.broadcast_to(grad, input_shape), None]\n\n"
  },
  {
    "id" : "91cdad8d-6226-4611-8721-0a7fbc871fb3",
    "prId" : 4113,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/4113#pullrequestreview-6538253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e366efc-f71d-4a9d-b596-a5cf54cfe990",
        "parentId" : null,
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "I think this probably deserves some comment (same with Floor).  Why is the gradient of \"Rint\" [None] ?  Is this one of those \"It's not correct but it works\" type of things, or should we even be registering a gradient here at all?\n",
        "createdAt" : "2016-10-31T20:17:58Z",
        "updatedAt" : "2016-11-16T01:53:35Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      },
      {
        "id" : "7d7d125c-1c55-41c1-83fe-bb1fd14acbab",
        "parentId" : "4e366efc-f71d-4a9d-b596-a5cf54cfe990",
        "authorId" : "f7beb1db-3bff-4489-9df0-c170cb1132d1",
        "body" : "It's backward stable to always use zero as the gradient for floor, rint, ceil, etc.  I think `NoGradient` used to be the right thing to do; I don't know if someone got around renaming that to `ZeroGradient` or some such.\n",
        "createdAt" : "2016-10-31T20:24:28Z",
        "updatedAt" : "2016-11-16T01:53:35Z",
        "lastEditedBy" : "f7beb1db-3bff-4489-9df0-c170cb1132d1",
        "tags" : [
        ]
      },
      {
        "id" : "b6ca5957-b17b-47ac-82d6-5841c668b7c0",
        "parentId" : "4e366efc-f71d-4a9d-b596-a5cf54cfe990",
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "NoGradient caused all of our researchers to throw a hissy-fit so we renamed it NotDifferentiable (marginally better for how it was used in most places, but w/e), which is still not really the same as \"ZeroGradient\".  I'd be fine with adding a ZeroGradient somewhere that is also the same, but frankly this change is also good, just with a comment saying something like \"Propagate zeros in the gradient\".\n",
        "createdAt" : "2016-10-31T20:29:53Z",
        "updatedAt" : "2016-11-16T01:53:35Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      },
      {
        "id" : "4ff3613b-1d39-478b-8dca-c8654aeb4cfb",
        "parentId" : "4e366efc-f71d-4a9d-b596-a5cf54cfe990",
        "authorId" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "body" : "What is the final verdict here? just a Comment ? or something like ZeroGradient?\n",
        "createdAt" : "2016-10-31T22:27:13Z",
        "updatedAt" : "2016-11-16T01:53:35Z",
        "lastEditedBy" : "d3c7478f-38f7-4a9e-bbb7-cba056444e38",
        "tags" : [
        ]
      },
      {
        "id" : "7d47c495-b99f-44d9-8c53-9cf6be38cc69",
        "parentId" : "4e366efc-f71d-4a9d-b596-a5cf54cfe990",
        "authorId" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "body" : "just a comment\n",
        "createdAt" : "2016-10-31T22:31:24Z",
        "updatedAt" : "2016-11-16T01:53:35Z",
        "lastEditedBy" : "1836b116-1c54-4d2e-8c7f-d83e825237ef",
        "tags" : [
        ]
      }
    ],
    "commit" : "9696341a6a1779eb2888917909cfeab8ddf32644",
    "line" : null,
    "diffHunk" : "@@ -1,1 +778,782 @@\n\n@ops.RegisterGradient(\"Rint\")\ndef _RintGrad(_, unused_grad):\n  # the gradient of Rint is zero"
  },
  {
    "id" : "567ad1f7-9419-47a5-9945-e8c25aa573c3",
    "prId" : 2711,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac1a082d-9735-4d5e-8831-2af9330dc68b",
        "parentId" : null,
        "authorId" : "f7beb1db-3bff-4489-9df0-c170cb1132d1",
        "body" : "That is a lovely gradient function. :)\n",
        "createdAt" : "2016-06-13T20:17:58Z",
        "updatedAt" : "2016-07-12T23:22:15Z",
        "lastEditedBy" : "f7beb1db-3bff-4489-9df0-c170cb1132d1",
        "tags" : [
        ]
      },
      {
        "id" : "ed8c2df0-c37c-49df-b848-51b3232808a6",
        "parentId" : "ac1a082d-9735-4d5e-8831-2af9330dc68b",
        "authorId" : "030e8fc7-2757-4ba2-9a16-7bccc7a8333e",
        "body" : "@ibab The best. Your going to have to explain this to us at RSA 2017\n",
        "createdAt" : "2016-06-13T21:18:05Z",
        "updatedAt" : "2016-07-12T23:22:15Z",
        "lastEditedBy" : "030e8fc7-2757-4ba2-9a16-7bccc7a8333e",
        "tags" : [
        ]
      }
    ],
    "commit" : "83fe4f73c4e704c8eb3715a8ce0c8332d81510ee",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +844,848 @@  axis = op.inputs[1]\n  reverse = op.get_attr(\"reverse\")\n  return [math_ops.cumsum(grad, axis=axis, reverse=(not reverse)), None]\n\n"
  }
]