[
  {
    "id" : "50cce3c1-706f-47bd-8949-bc8b0ec5a44e",
    "prId" : 20108,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/20108#pullrequestreview-146218404",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "560ed85a-5731-4226-a308-074eb4f528b7",
        "parentId" : null,
        "authorId" : "3517ca44-bbf1-44f4-bada-c2b75e1ecd1e",
        "body" : "While we're here, could we remove this aliases (are they even effective? Do they do anything given that the tf_export decorators determine what's in the API?)?\r\n\r\n@annarev do you think these actually do anything?",
        "createdAt" : "2018-08-14T18:01:36Z",
        "updatedAt" : "2018-08-14T18:01:37Z",
        "lastEditedBy" : "3517ca44-bbf1-44f4-bada-c2b75e1ecd1e",
        "tags" : [
        ]
      },
      {
        "id" : "aef46d37-7f19-47b5-b32c-969d04064a22",
        "parentId" : "560ed85a-5731-4226-a308-074eb4f528b7",
        "authorId" : "348d02e7-fb87-40d6-9079-97142b662dc4",
        "body" : "Looks like these are used in contrib:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/framework/__init__.py\r\nI suppose they can be imported with \"as convolutional_orthogonal_*d\" instead.",
        "createdAt" : "2018-08-14T19:32:46Z",
        "updatedAt" : "2018-08-14T19:32:46Z",
        "lastEditedBy" : "348d02e7-fb87-40d6-9079-97142b662dc4",
        "tags" : [
        ]
      }
    ],
    "commit" : "65f544792950a8d60d5aa8e19f3239bcae66a99f",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +1206,1210 @@convolutional_orthogonal_1d = ConvolutionOrthogonal1D\nconvolutional_orthogonal_2d = ConvolutionOrthogonal2D\nconvolutional_orthogonal_3d = ConvolutionOrthogonal3D\n# pylint: enable=invalid-name\n"
  },
  {
    "id" : "ff0df7d7-d887-4a54-9dd0-f3ad652496e0",
    "prId" : 5164,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/5164#pullrequestreview-7392098",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06f9b8b3-71ee-41de-9820-fe451fb72375",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "Since the user can do a multiplication easier outside of this op, I don't see why it should belong in this op. The implementation doesn't take advantage of it to provide any performance benefit anyway. \n",
        "createdAt" : "2016-11-01T21:04:20Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "8385977f-1807-4e9d-ad56-2e9b9d024e2a",
        "parentId" : "06f9b8b3-71ee-41de-9820-fe451fb72375",
        "authorId" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "body" : "Fair point. Will drop the gain.\n",
        "createdAt" : "2016-11-01T22:28:44Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "tags" : [
        ]
      },
      {
        "id" : "27755a97-2a8e-44b0-88dd-8afc16b18016",
        "parentId" : "06f9b8b3-71ee-41de-9820-fe451fb72375",
        "authorId" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "body" : "On second thoughts, I think keeping the gain is useful because it simplifies the setup of variables (similar to not having to call `reshape`). It's more or less equivalent to the standard deviation for the `random_normal` initializer. Thoughts?\n",
        "createdAt" : "2016-11-07T10:50:46Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cb31e3ea41334e3718bad0f33a92dd5030ca229",
    "line" : null,
    "diffHunk" : "@@ -1,1 +358,362 @@\n  Args:\n    gain: multiplicative factor to apply to the orthogonal matrix\n    dtype: The type of the output.\n    seed: A Python integer. Used to create random seeds. See"
  },
  {
    "id" : "afbde5d6-ac4a-460e-870d-a0a248590d38",
    "prId" : 5164,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/5164#pullrequestreview-7390267",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0dfa3e1-ad05-4190-a893-c3e4579aa82c",
        "parentId" : null,
        "authorId" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "body" : "I think we need to clearly document what this shape means in the docstring: what is supported, and what is orthogonal as the output. \n\nSince even conv has multiple data formats, NHWC and NCHW, it is a good idea to separate them clearly. It is a good idea to keep this op has simple as possible, and requires the shape to be square matrices. \n",
        "createdAt" : "2016-11-01T21:18:17Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "17de39de-cc9c-45a3-95c0-7f6d00026c06",
        "tags" : [
        ]
      },
      {
        "id" : "5ca4e4c7-0f1e-45a9-8c9d-a501055eaa67",
        "parentId" : "c0dfa3e1-ad05-4190-a893-c3e4579aa82c",
        "authorId" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "body" : "I would be keen to keep the functionality as is but document more clearly as you suggested. The main reason is that I find\n\n``` python\nweights = tf.get_variable('weights', (5, 5, 8, 32), tf.float32, \n                          tf.orthogonal_initializer())\n```\n\nmuch more straightforward than\n\n``` python\nweights = tf.reshape(\n  tf.get_variable('weights', (200, 32), tf.float32, tf.orthogonal_initializer()), \n  (5, 5, 8, 32)\n)\n```\n",
        "createdAt" : "2016-11-07T10:39:39Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "a709924c-9e01-4bdb-b2b5-ef2f20579a3e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cb31e3ea41334e3718bad0f33a92dd5030ca229",
    "line" : null,
    "diffHunk" : "@@ -1,1 +374,378 @@    if len(shape) < 2:\n      raise ValueError('the tensor to initialize must be at least two-dimensional')\n    # Flatten the input shape with the last dimension remaining its original shape so it works for conv2d\n    num_rows = 1\n    for dim in shape[:-1]:"
  },
  {
    "id" : "f5724149-4385-4752-b8c0-1d7d3729f0da",
    "prId" : 5164,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/5164#pullrequestreview-8712314",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37b8ead8-3c9d-4c53-bc70-692a5e0fc801",
        "parentId" : null,
        "authorId" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "body" : "The SVD is an overly expensive algorithm to use for this purpose, we should have a QR factorization op for this. [No action required.]\n",
        "createdAt" : "2016-11-14T18:31:49Z",
        "updatedAt" : "2016-11-14T18:50:06Z",
        "lastEditedBy" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "tags" : [
        ]
      },
      {
        "id" : "dc68e607-6154-4bff-bf0b-649905015366",
        "parentId" : "37b8ead8-3c9d-4c53-bc70-692a5e0fc801",
        "authorId" : "6e47fa90-c319-4464-b7e4-bb5d52771cd8",
        "body" : "Agreed. And, further, I would recommend generating the entries with a normal distribution and then taking the Q from the QR factorization so that a Haar matrix is generated. Diaconis has a nice paper that discusses this and an alternative implicit version: http://www.ams.org/journals/bull/2003-40-02/S0273-0979-03-00975-3/S0273-0979-03-00975-3.pdf\n",
        "createdAt" : "2016-11-15T22:32:16Z",
        "updatedAt" : "2016-11-15T22:32:17Z",
        "lastEditedBy" : "6e47fa90-c319-4464-b7e4-bb5d52771cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cb31e3ea41334e3718bad0f33a92dd5030ca229",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +384,388 @@    a = random_ops.random_uniform(flat_shape, dtype=dtype, seed=seed)\n    # Compute the svd\n    _, u, v = linalg_ops.svd(a, full_matrices=False)\n    # Pick the appropriate singular value decomposition\n    if num_rows > num_cols:"
  },
  {
    "id" : "de4e7598-268d-46d0-9246-4f5eaf1560f3",
    "prId" : 4462,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/4462#pullrequestreview-561009",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84c4002f-636e-4db3-a223-057b39f6dbad",
        "parentId" : null,
        "authorId" : "8a0c7fb9-7e9e-4fb9-912b-3dda65aff0ce",
        "body" : "Move `array_ops.zeros_initializer()` here\n",
        "createdAt" : "2016-09-19T14:31:30Z",
        "updatedAt" : "2016-09-21T05:10:44Z",
        "lastEditedBy" : "8a0c7fb9-7e9e-4fb9-912b-3dda65aff0ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "3142a045e2455579619073542a57d3fda926d270",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +64,68 @@def zeros_initializer(shape, dtype=dtypes.float32, partition_info=None):\n  \"\"\"An adaptor for zeros() to match the Initializer spec.\"\"\"\n  return array_ops.zeros(shape, dtype)\n\n"
  }
]