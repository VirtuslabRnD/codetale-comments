[
  {
    "id" : "21d7bf69-71c4-4d34-8a3e-77222dddf11f",
    "prId" : 27898,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27898#pullrequestreview-227388761",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "109e08cb-a8ed-43fc-b7d1-505d3bcaefe9",
        "parentId" : null,
        "authorId" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "body" : "In the docstring for `update`, in the Args section, mention that a gradient in the list can also be None",
        "createdAt" : "2019-04-16T19:08:59Z",
        "updatedAt" : "2019-04-16T22:40:11Z",
        "lastEditedBy" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "tags" : [
        ]
      }
    ],
    "commit" : "395c93bbf9009163452f0013afb803a0e43c574a",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +195,199 @@\n\ndef _is_all_finite(grads):\n  \"\"\"Returns a scalar boolean tensor indicating if all gradients are finite.\"\"\"\n  is_finite_per_grad = ["
  },
  {
    "id" : "136b78ae-09d6-4f04-b99c-f5a07621600c",
    "prId" : 27898,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27898#pullrequestreview-227408205",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23704f0c-0bd6-4bf3-8f46-91c2de2c78f3",
        "parentId" : null,
        "authorId" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "body" : "If you want, also update the [Keras LossScale](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/mixed_precision/experimental/loss_scale.py). If you don't, I'll do it after this is submitted.",
        "createdAt" : "2019-04-16T19:09:57Z",
        "updatedAt" : "2019-04-16T22:40:11Z",
        "lastEditedBy" : "05c2b6c1-8a55-4dc9-ae76-02172416ea90",
        "tags" : [
        ]
      },
      {
        "id" : "df171f35-c77c-4168-9323-a9765459853f",
        "parentId" : "23704f0c-0bd6-4bf3-8f46-91c2de2c78f3",
        "authorId" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "body" : "Sounds good.  I applied the same changes to the keras loss_scale.py and loss_scale_test.py",
        "createdAt" : "2019-04-16T19:49:13Z",
        "updatedAt" : "2019-04-16T22:40:11Z",
        "lastEditedBy" : "53c3ad32-5f8d-4187-bb81-3faeb47b61f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "395c93bbf9009163452f0013afb803a0e43c574a",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +195,199 @@\n\ndef _is_all_finite(grads):\n  \"\"\"Returns a scalar boolean tensor indicating if all gradients are finite.\"\"\"\n  is_finite_per_grad = ["
  }
]