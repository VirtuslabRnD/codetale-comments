[
  {
    "id" : "b269a89a-1b6d-4f95-b1dd-25dbe44ae187",
    "prId" : 37074,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37074#pullrequestreview-377436737",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9be55e38-c0d4-412c-83e5-fc3fee8bf009",
        "parentId" : null,
        "authorId" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "body" : "Do you need the self._origin_step_stats? How about:\r\n\r\nif op_time == \"schedule\":\r\n     return\r\nself._step_stats = copy.deepcopy(self._step_stats)",
        "createdAt" : "2020-03-18T17:45:37Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "tags" : [
        ]
      },
      {
        "id" : "c322aae9-f884-4d84-bd9f-a15ebc93299e",
        "parentId" : "9be55e38-c0d4-412c-83e5-fc3fee8bf009",
        "authorId" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "body" : "The reason for the self._origin_step_stats is that user may use timeline this way:\r\n```\r\ntl = timeline.Timeline(run_metadata.step_stats)\r\nctf1 = tl.generate_chrome_trace_format('gpu')\r\nctf2 = tl.generate_chrome_trace_format()\r\n```\r\nIn this case, it would be better to have a origin copy of the step stats.",
        "createdAt" : "2020-03-19T05:42:03Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "4abe7b53ba2d88f6c023929da5e028ee2cfc3e2b",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +633,637 @@        its last kernel.\n    \"\"\"\n    if op_time == \"schedule\":\n      self._step_stats = self._origin_step_stats\n      return"
  },
  {
    "id" : "983688d1-1f16-4515-aa44-d6e3e8215cf4",
    "prId" : 37074,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37074#pullrequestreview-378207963",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b743b14c-18d4-4e54-a1ae-fd14b9caead9",
        "parentId" : null,
        "authorId" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "body" : "Can you add a docstring for this function as well?",
        "createdAt" : "2020-03-18T17:49:02Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "tags" : [
        ]
      },
      {
        "id" : "c68f2a71-01b9-44c2-ae20-a2a6f2bddd23",
        "parentId" : "b743b14c-18d4-4e54-a1ae-fd14b9caead9",
        "authorId" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "body" : "Added.",
        "createdAt" : "2020-03-19T05:50:27Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "tags" : [
        ]
      },
      {
        "id" : "6432b36e-176f-4c8a-b881-54794b01e164",
        "parentId" : "b743b14c-18d4-4e54-a1ae-fd14b9caead9",
        "authorId" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "body" : "supernit: \"Analyze the step stats and format it into Chrome Trace Format\" => \"Analyze the step stats and format it into Chrome Trace Format.\"\r\nOne-line docstring summary should end with \".\", \".)\", \"?\", or \"!\" , otherwise it triggers a lint error internally.\r\nCan you also run pylint to check your Python changes?\r\nhttps://www.tensorflow.org/community/contribute/code_style\r\n\r\n",
        "createdAt" : "2020-03-19T16:00:06Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "tags" : [
        ]
      },
      {
        "id" : "e865f535-d620-43ad-a561-b16d80049749",
        "parentId" : "b743b14c-18d4-4e54-a1ae-fd14b9caead9",
        "authorId" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "body" : "Thank you for pointing out the lint problem. I've added the period in the comment and made all lines less than 80 characters. Right now the remaining pylint alerts have nothing to do with PR. The pylint for `timeline.py` now is \r\n```\r\n************* Module tensorflow.python.client.timeline\r\ntensorflow/python/client/timeline.py:41:2: W0107: Unnecessary pass statement (unnecessary-pass)\r\ntensorflow/python/client/timeline.py:52:2: W0107: Unnecessary pass statement (unnecessary-pass)\r\ntensorflow/python/client/timeline.py:55:0: R0205: Class '_ChromeTraceFormatter' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/python/client/timeline.py:259:4: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\ntensorflow/python/client/timeline.py:265:0: R0205: Class '_TensorTracker' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/python/client/timeline.py:346:0: R0205: Class 'Timeline' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/python/client/timeline.py:528:4: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)\r\n\r\n------------------------------------------------------------------\r\nYour code has been rated at 9.78/10 (previous run: 9.78/10, +0.00)\r\n```",
        "createdAt" : "2020-03-20T02:43:11Z",
        "updatedAt" : "2020-03-20T02:43:12Z",
        "lastEditedBy" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "4abe7b53ba2d88f6c023929da5e028ee2cfc3e2b",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +698,702 @@    \"\"\"\n    self._preprocess_op_time(op_time)\n    self._allocate_pids()\n    self._assign_lanes()\n    self._analyze_tensors(show_memory)"
  },
  {
    "id" : "fc8e3fbb-0b39-49e5-adaf-2d12a04adc45",
    "prId" : 37074,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37074#pullrequestreview-377438940",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6abac942-1a93-45c2-b1e5-5953c4ee817c",
        "parentId" : null,
        "authorId" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "body" : "nit: op_time.",
        "createdAt" : "2020-03-18T17:51:28Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "tags" : [
        ]
      },
      {
        "id" : "39a47951-f1ad-4eb3-b709-da89a3e4d144",
        "parentId" : "6abac942-1a93-45c2-b1e5-5953c4ee817c",
        "authorId" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "body" : "I have changed the typo, thank you.",
        "createdAt" : "2020-03-19T05:49:18Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "4abe7b53ba2d88f6c023929da5e028ee2cfc3e2b",
    "line" : 90,
    "diffHunk" : "@@ -1,1 +664,668 @@\n    # Update the start and end time of each op according to the op_time\n    for stats in job_stats:\n      for op in stats.node_stats:\n        if op.node_name in op_gpu_start:"
  },
  {
    "id" : "8c8c12de-5926-4a76-ae30-cdee37aa22e6",
    "prId" : 37074,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37074#pullrequestreview-377438328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57ab8347-b231-4153-a70a-7a7c56814439",
        "parentId" : null,
        "authorId" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "body" : "How does this work for CPU only jobs?",
        "createdAt" : "2020-03-18T17:54:53Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "140aab03-80fa-47ed-a056-19891aa0be44",
        "tags" : [
        ]
      },
      {
        "id" : "529c66e2-e1ab-4dd6-bcb4-fa571207a182",
        "parentId" : "57ab8347-b231-4153-a70a-7a7c56814439",
        "authorId" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "body" : "There will be no influence on CPU only jobs, because we only check ops that relate to the kernels profiled in \"/stream:all\", which are all of the gpu kernels. Also, the current profiling method on CPU only ops in tensorflow does not have the async problem, so it would be ok to leave them where they were.",
        "createdAt" : "2020-03-19T05:47:30Z",
        "updatedAt" : "2020-03-20T02:35:57Z",
        "lastEditedBy" : "8f2c60bf-1331-4955-ac11-430c16b5f5a4",
        "tags" : [
        ]
      }
    ],
    "commit" : "4abe7b53ba2d88f6c023929da5e028ee2cfc3e2b",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +649,653 @@    # the last gpu kernel for all ops.\n    op_gpu_start = {}\n    op_gpu_end = {}\n    for stats in stream_all_stats:\n      for kernel in stats.node_stats:"
  }
]