[
  {
    "id" : "7ee50cc1-cdef-4e87-9795-5b27a70fc496",
    "prId" : 41981,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/41981#pullrequestreview-461115776",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30d9263c-fad4-4c72-90d4-f5209db7b470",
        "parentId" : null,
        "authorId" : "25d9ca1a-eec3-4905-a140-d1d6a3a2fde2",
        "body" : "Are you intentionally changing this comment (and the docstrings below)?  If so, then how is this related to the PR?",
        "createdAt" : "2020-08-03T18:53:59Z",
        "updatedAt" : "2020-08-19T17:51:28Z",
        "lastEditedBy" : "25d9ca1a-eec3-4905-a140-d1d6a3a2fde2",
        "tags" : [
        ]
      },
      {
        "id" : "cb8015ce-c273-404c-b9a6-0df50d8c4dd9",
        "parentId" : "30d9263c-fad4-4c72-90d4-f5209db7b470",
        "authorId" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "body" : "Nope, it's just some unintentional annoying artifact of the series of merges from the previous PR. However, this version corresponds to what we have in the master right now. Don't really understand if/how to fix it, so that it won't show in diff. Probably rewriting history of this branch via rebase could be an option, but no point in that I guess. Should merge correctly.",
        "createdAt" : "2020-08-04T19:36:47Z",
        "updatedAt" : "2020-08-19T17:51:28Z",
        "lastEditedBy" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab4cf37a02a0fb23f52920acac5ba55186d19cb1",
    "line" : 232,
    "diffHunk" : "@@ -1,1 +2170,2174 @@    `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n    contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n    the analysis fails to determine the number of elements in the dataset\n    (e.g. when the dataset source is a file).\n"
  },
  {
    "id" : "af1ffe82-856b-4341-893e-9c61d3394ecd",
    "prId" : 41981,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/41981#pullrequestreview-480516777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4d717b5-32a4-4ad1-b4e3-1f6951463504",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "Previously, `from_generator` would convert generated elements to match the types specified with `output_types`, but with this change `from_generator` will require an exact dtype match. The docs say \r\n\r\n> The elements generated by generator must be compatible with the given output_types\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\r\n\r\nCan we preserve the original behavior of converting compatible dtypes, and add a test to verify that it works?",
        "createdAt" : "2020-09-01T20:29:25Z",
        "updatedAt" : "2020-09-01T20:29:53Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "cf83a547-d82b-4aaf-82cf-ff4c6dcfd073",
        "parentId" : "c4d717b5-32a4-4ad1-b4e3-1f6951463504",
        "authorId" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "body" : "@aaudiber Can you give me the example (that we can later convert to the test) of this working in old version and not working in the new one?",
        "createdAt" : "2020-09-02T04:10:11Z",
        "updatedAt" : "2020-09-02T04:11:01Z",
        "lastEditedBy" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "tags" : [
        ]
      },
      {
        "id" : "b7a1bbe6-537d-44c5-8884-1b9325c0bf70",
        "parentId" : "c4d717b5-32a4-4ad1-b4e3-1f6951463504",
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "I looked into it further and I think the current code is still doing implicit conversions between compatible types, so no change is needed. Sorry for the confusion.",
        "createdAt" : "2020-09-02T05:33:05Z",
        "updatedAt" : "2020-09-02T05:33:06Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "ad8989e6-51b2-4d15-92c7-d8541f4a7a40",
        "parentId" : "c4d717b5-32a4-4ad1-b4e3-1f6951463504",
        "authorId" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "body" : "no worries",
        "createdAt" : "2020-09-02T06:26:44Z",
        "updatedAt" : "2020-09-02T06:26:45Z",
        "lastEditedBy" : "988dcfa4-5015-495b-bf9d-ba30b9f4365f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab4cf37a02a0fb23f52920acac5ba55186d19cb1",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +879,883 @@\n        try:\n          values = structure.normalize_element(values, output_signature)\n        except (TypeError, ValueError):\n          six.reraise("
  },
  {
    "id" : "2e766f7e-915e-4927-9448-9e0c59b6be89",
    "prId" : 37853,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37853#pullrequestreview-385522572",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee67edc5-4854-4b24-abcb-b9aba19e8123",
        "parentId" : null,
        "authorId" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "body" : "Please add information about that fact the the use of `tf.numpy_function` and `tf.py_function` in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).",
        "createdAt" : "2020-03-30T15:35:45Z",
        "updatedAt" : "2020-04-02T02:10:47Z",
        "lastEditedBy" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "tags" : [
        ]
      },
      {
        "id" : "3c229c7a-da8f-4d5b-9e62-40b68ac8f71f",
        "parentId" : "ee67edc5-4854-4b24-abcb-b9aba19e8123",
        "authorId" : "a9dbfdf6-2a00-45cb-b16f-cf79b1e97722",
        "body" : "Done",
        "createdAt" : "2020-04-01T12:10:55Z",
        "updatedAt" : "2020-04-02T02:10:47Z",
        "lastEditedBy" : "a9dbfdf6-2a00-45cb-b16f-cf79b1e97722",
        "tags" : [
        ]
      }
    ],
    "commit" : "16cc300fac3b81e7c30654b61cb1939875a175b7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1620,1624 @@    [b'HELLO', b'WORLD']\n\n    3) Use `tf.numpy_function`, which also allows you to write arbitrary\n    Python code. Note here that `tf.py_function` accepts `tf.Tensor` whereas\n    `tf.numpy_function` accepts numpy arrays and returns only numpy arrays."
  },
  {
    "id" : "dc9fece2-192c-4cb7-8dc5-365d84988999",
    "prId" : 37801,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/37801#pullrequestreview-379606681",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23ebdf5a-4646-44e0-95c8-e24ae269b1cb",
        "parentId" : null,
        "authorId" : "fa21cf91-4361-4622-b388-ce76c5f7f37e",
        "body" : "You should probably retain `elif deterministic is not None:`",
        "createdAt" : "2020-03-23T13:36:38Z",
        "updatedAt" : "2020-03-23T13:37:29Z",
        "lastEditedBy" : "fa21cf91-4361-4622-b388-ce76c5f7f37e",
        "tags" : [
        ]
      },
      {
        "id" : "fb500845-995a-4018-a334-f98e601ea9e8",
        "parentId" : "23ebdf5a-4646-44e0-95c8-e24ae269b1cb",
        "authorId" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "body" : "This won't make any difference since `compat.forward_compatible(2020, 2, 20)` will always be `True` and `if deterministic is not None or True` therfore will evaluate to `True` regardless of the value of `deterministic`.",
        "createdAt" : "2020-03-23T16:47:39Z",
        "updatedAt" : "2020-03-23T16:48:41Z",
        "lastEditedBy" : "c0e6af67-982a-4e5a-980e-4580b05253a0",
        "tags" : [
        ]
      }
    ],
    "commit" : "503f3418ca31b1e26bff1a21e7119fe6f80528c9",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +4270,4274 @@          deterministic=deterministic_string,\n          **self._flat_structure)\n    else:\n      variant_tensor = gen_dataset_ops.parallel_interleave_dataset_v3(\n          input_dataset._variant_tensor,  # pylint: disable=protected-access"
  },
  {
    "id" : "78f0bcf2-a5f0-46a7-80c8-121f5ee1f025",
    "prId" : 36989,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/36989#pullrequestreview-365144989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a51dd6b9-d955-43da-9ffc-4d0610dfc1ab",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "This section looks good to me :+1: ",
        "createdAt" : "2020-02-26T18:26:11Z",
        "updatedAt" : "2020-02-28T06:36:26Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "03730d39-9092-4402-b301-abde5e6597cc",
        "parentId" : "a51dd6b9-d955-43da-9ffc-4d0610dfc1ab",
        "authorId" : "a9dbfdf6-2a00-45cb-b16f-cf79b1e97722",
        "body" : "Done",
        "createdAt" : "2020-02-26T18:39:07Z",
        "updatedAt" : "2020-02-28T06:36:26Z",
        "lastEditedBy" : "a9dbfdf6-2a00-45cb-b16f-cf79b1e97722",
        "tags" : [
        ]
      }
    ],
    "commit" : "54726dd738c0146ec1afdfa0184b479a4251d2dd",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +543,547 @@    >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n    >>> list(dataset.as_numpy_iterator())\n    [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n\n    Note that if `tensors` contains a NumPy array, and eager execution is not"
  },
  {
    "id" : "80eeea08-11cf-403b-9891-c3c749378374",
    "prId" : 33485,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/33485#pullrequestreview-359174784",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7fdcf981-9ca9-4ba2-a62e-0bb548e1acac",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "I think we can remove this sentence now, since there are more detailed explanations before",
        "createdAt" : "2020-02-12T17:53:48Z",
        "updatedAt" : "2020-02-14T19:39:37Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "3f151191-8975-4352-a800-208e9028aea6",
        "parentId" : "7fdcf981-9ca9-4ba2-a62e-0bb548e1acac",
        "authorId" : "c4e6fae0-2e1a-478a-96bd-743fc5c75802",
        "body" : "Deleted this paragraph.",
        "createdAt" : "2020-02-14T19:38:41Z",
        "updatedAt" : "2020-02-14T19:39:37Z",
        "lastEditedBy" : "c4e6fae0-2e1a-478a-96bd-743fc5c75802",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbef16d675efd91846374a86717f4b038ad81444",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1809,1813 @@    will always be the first element of the input dataset.\n\n    The `stride` argument determines the stride of the input elements, and the\n    `shift` argument determines the shift of the window.\n"
  },
  {
    "id" : "66d46ff7-784c-42dd-b64f-6dfc68be917b",
    "prId" : 31897,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/31897#pullrequestreview-278625975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dcb86df4-27ef-4d14-9cea-eabf3f4bfd7d",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "Delete the trailing whitespace on lines 977, 989, and 992",
        "createdAt" : "2019-08-22T19:02:50Z",
        "updatedAt" : "2019-08-22T19:12:39Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      }
    ],
    "commit" : "d6467d8cb43e1a4eb5a3cfcf8e4bde9bc2223a39",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +990,994 @@    `shard` is a deterministic operator; the returned Dataset depends only\n    on the target Dataset, and the values of `num_shards` and `index`.\n    \n    This dataset operator is very useful when running distributed training, as\n    it allows each worker to read a unique subset."
  },
  {
    "id" : "1846f2f7-7bc9-48c1-b1f0-b47a0ea0e400",
    "prId" : 31897,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/31897#pullrequestreview-278625975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15f0e60a-d9c5-40cc-874d-014d1df59bd6",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "We can make this more precise: \"The dataset produced by `A.shard(n, i)` will contain all elements of `A` where their index mod `n` equals `i`.\"\r\n\r\nCan we move this sentence to replace \"For example:\" above? ",
        "createdAt" : "2019-08-22T19:09:51Z",
        "updatedAt" : "2019-08-22T19:12:39Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      }
    ],
    "commit" : "d6467d8cb43e1a4eb5a3cfcf8e4bde9bc2223a39",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +988,992 @@    ```\n    \n    `shard` is a deterministic operator; the returned Dataset depends only\n    on the target Dataset, and the values of `num_shards` and `index`.\n    "
  },
  {
    "id" : "ad9a3404-ae49-4405-ab26-9958d3bfd111",
    "prId" : 27933,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/27933#pullrequestreview-228412881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b574e815-40b3-497a-a9e7-e79db46ed8a5",
        "parentId" : null,
        "authorId" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "body" : "why do you introduce this comment here? I thought the purpose of this PR was to replace `{ ... }` with code that runs",
        "createdAt" : "2019-04-17T22:19:08Z",
        "updatedAt" : "2019-04-18T17:12:58Z",
        "lastEditedBy" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "tags" : [
        ]
      },
      {
        "id" : "e6e57754-2718-46df-b592-fae388fc079d",
        "parentId" : "b574e815-40b3-497a-a9e7-e79db46ed8a5",
        "authorId" : "28758994-c8ca-46f1-9639-130b8585d574",
        "body" : "There are several examples following line in line 944 - 961 that I didn't change in this request and still contain non executable code. I wanted to keep this request small because I expected some feedback. I'll take another look in a separate request.",
        "createdAt" : "2019-04-18T17:30:39Z",
        "updatedAt" : "2019-04-18T17:30:40Z",
        "lastEditedBy" : "28758994-c8ca-46f1-9639-130b8585d574",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4d040636ade8d91af6a70ad66643b899bc745be",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +942,946 @@\n    ```python\n    # NOTE: The following examples use `{ ... }` to represent the\n    # contents of a dataset.\n    # Each element is a `tf.Tensor` object."
  },
  {
    "id" : "374e53a7-3973-402e-b0d8-00a64dcf77e4",
    "prId" : 22429,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/22429#pullrequestreview-160378386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4bdead87-c2bc-4681-bf1e-fdb311c73bf5",
        "parentId" : null,
        "authorId" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "body" : "@mrry would it make sense to switch the implementation of `list_files` to use `MatchingFilesDataset` and if so, what is the mechanism do to that in a forward-compatible manner?",
        "createdAt" : "2018-10-01T16:25:28Z",
        "updatedAt" : "2018-10-15T21:38:29Z",
        "lastEditedBy" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d5b9d20cc3e3062aa4d443bc772bb3aed698d15",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +2653,2657 @@\n\nclass MatchingFilesDataset(Dataset):\n  \"\"\"A `Dataset` that list the files according to the input patterns.\"\"\"\n"
  },
  {
    "id" : "e702c01f-0992-488b-809a-04b73bf0175b",
    "prId" : 48894,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48894#pullrequestreview-721227070",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45390b6e-44f9-4444-b8b7-f55b5f2da93e",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "Add a comment for why we need to lazy load interleave_ops.",
        "createdAt" : "2021-08-03T00:13:13Z",
        "updatedAt" : "2021-08-03T00:21:45Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "107c1877-8d37-4e36-ae7b-17ab6dd5958a",
        "parentId" : "45390b6e-44f9-4444-b8b7-f55b5f2da93e",
        "authorId" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "body" : "addressed in the commit",
        "createdAt" : "2021-08-03T13:52:50Z",
        "updatedAt" : "2021-08-03T13:52:50Z",
        "lastEditedBy" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "tags" : [
        ]
      }
    ],
    "commit" : "451c651eed55a59f9d3d8332a58df4bf86c0d2a5",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +98,102 @@interleave_ops = lazy_loader.LazyLoader(\n    \"interleave_ops\", globals(),\n    \"tensorflow.python.data.experimental.ops.interleave_ops\")\n\nops.NotDifferentiable(\"ReduceDataset\")"
  },
  {
    "id" : "92e3430d-1ea2-483c-a790-8f93ed23ed60",
    "prId" : 48894,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48894#pullrequestreview-721226992",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "412ebd04-fa38-4e1e-ae9a-4f07368625cb",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "since the parameter is called `initial_dist`, it would be good to also use `initial_dist` in the example, so that users don't accidentally set `init_dist` instead of `initial_dist`.",
        "createdAt" : "2021-08-03T00:15:18Z",
        "updatedAt" : "2021-08-03T00:21:45Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "caf85907-130a-450b-8af0-e699005c46eb",
        "parentId" : "412ebd04-fa38-4e1e-ae9a-4f07368625cb",
        "authorId" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "body" : "addressed in the commit",
        "createdAt" : "2021-08-03T13:52:47Z",
        "updatedAt" : "2021-08-03T13:52:47Z",
        "lastEditedBy" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "tags" : [
        ]
      }
    ],
    "commit" : "451c651eed55a59f9d3d8332a58df4bf86c0d2a5",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +2952,2956 @@\n    Lets consider the following example where a dataset with an initial data\n    distribution of `init_dist` needs to be resampled into a dataset with\n    `target_dist` distribution.\n"
  },
  {
    "id" : "f92dc3c5-549a-4f24-9aee-9b911cbee6ef",
    "prId" : 48894,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/48894#pullrequestreview-721400408",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f782c30d-a3ca-4b76-b286-adda639a2e2a",
        "parentId" : null,
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "Moving all of our implementations into `dataset_ops.py` is making `dataset_ops.py` quite long and hard to navigate. In later PRs we should consider moving the dataset transformations from `dataset_ops.py` into their own files, similar to what we do for experimental ops. It would also make graduating experimental ops more straightforward. @jsimsa what are your thoughts?",
        "createdAt" : "2021-08-03T00:20:57Z",
        "updatedAt" : "2021-08-03T00:21:45Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "d0e87d31-8327-45fb-9c95-c91bb1469b5b",
        "parentId" : "f782c30d-a3ca-4b76-b286-adda639a2e2a",
        "authorId" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "body" : "This is a valid concern and I think it would be a useful refactor. That said, we should do this in a manner which does not require updating callsites that import `dataset_ops`. One option would be that we keep `dataset_ops.py` as a shim to import symbols from the \"per transformation\" modules.",
        "createdAt" : "2021-08-03T04:19:32Z",
        "updatedAt" : "2021-08-03T04:19:32Z",
        "lastEditedBy" : "b4c739be-8aba-4687-9314-60b582f3b6d6",
        "tags" : [
        ]
      },
      {
        "id" : "9284d91f-2909-4b3d-b1b9-6a3950fdd176",
        "parentId" : "f782c30d-a3ca-4b76-b286-adda639a2e2a",
        "authorId" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "body" : "@aaudiber @jsimsa we might also want to consider the circular dependencies and file duplications during the promotion/refactor process if we are going to maintain separate files per transformation and use them in `dataset_ops.py`. Also, if we are using `dataset_ops.py` as a shim where the API layout is unaffected for the users, we might have to maintain a new file with the actual functionality of the API's in `dataset_ops.py` so that circular dependencies can be prevented. WDYT?",
        "createdAt" : "2021-08-03T14:05:22Z",
        "updatedAt" : "2021-08-03T14:06:12Z",
        "lastEditedBy" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "tags" : [
        ]
      },
      {
        "id" : "739c370a-6e8e-47a5-86ca-be83227f2da6",
        "parentId" : "f782c30d-a3ca-4b76-b286-adda639a2e2a",
        "authorId" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "body" : "+1 for making `dataset_ops` a shim. The refactor should have no user-facing impact. We can use LazyLoader in the dataset impl files to handle the circular reference on `dataset_ops.py`. Keeping `dataset_ops` readable is much more important than avoiding circular dependencies between dataset implementations and `dataset_ops`.",
        "createdAt" : "2021-08-03T15:35:06Z",
        "updatedAt" : "2021-08-03T15:35:06Z",
        "lastEditedBy" : "565becc7-24cd-4159-ad62-3351ae56bcaf",
        "tags" : [
        ]
      },
      {
        "id" : "37304cc7-5a98-4e61-8274-195a6953bf52",
        "parentId" : "f782c30d-a3ca-4b76-b286-adda639a2e2a",
        "authorId" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "body" : "okay sounds good!",
        "createdAt" : "2021-08-03T16:17:24Z",
        "updatedAt" : "2021-08-03T16:17:24Z",
        "lastEditedBy" : "86ac81e0-c752-48e1-ab1f-2754e8fe88ef",
        "tags" : [
        ]
      }
    ],
    "commit" : "451c651eed55a59f9d3d8332a58df4bf86c0d2a5",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +2995,2999 @@    \"\"\"\n\n    target_dist_t = ops.convert_to_tensor(target_dist, name=\"target_dist\")\n    target_dist_t = math_ops.cast(target_dist_t, dtypes.float32)\n"
  }
]