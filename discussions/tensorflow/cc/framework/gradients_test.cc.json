[
  {
    "id" : "034d8b48-6819-49e5-b27e-e9c2abe88848",
    "prId" : 12397,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/12397#pullrequestreview-58491328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97ed4816-6a66-4905-9a81-8a7e9b43912b",
        "parentId" : null,
        "authorId" : "3aa28542-364d-4b33-92fe-22177c758757",
        "body" : "Can you add this comment to the above test as well?",
        "createdAt" : "2017-08-24T16:08:59Z",
        "updatedAt" : "2017-08-29T21:01:29Z",
        "lastEditedBy" : "3aa28542-364d-4b33-92fe-22177c758757",
        "tags" : [
        ]
      },
      {
        "id" : "d61a74ca-65b9-4082-b2a8-68c6246c398e",
        "parentId" : "97ed4816-6a66-4905-9a81-8a7e9b43912b",
        "authorId" : "44740936-3d9d-4370-a1fb-5caee6ab1b7b",
        "body" : "Above the output given to AddSymbolicGradients is m1 so the gradient is backpropagated from m1 but not from m2, so there is no sum. Here the output given to AddSymbolicGradients is {m1, m2} so the gradients from m1 and m2 are summed. That's why the comment is only here. I guess it should be like that?\r\nElse I agree with all others comments and will update soon.",
        "createdAt" : "2017-08-24T18:51:00Z",
        "updatedAt" : "2017-08-29T21:01:29Z",
        "lastEditedBy" : "44740936-3d9d-4370-a1fb-5caee6ab1b7b",
        "tags" : [
        ]
      },
      {
        "id" : "4a32354b-a587-42c4-ba0b-d67087dc0d18",
        "parentId" : "97ed4816-6a66-4905-9a81-8a7e9b43912b",
        "authorId" : "3aa28542-364d-4b33-92fe-22177c758757",
        "body" : "Ah right. Can you comment how you computed the gradient for above test then?",
        "createdAt" : "2017-08-24T19:55:41Z",
        "updatedAt" : "2017-08-29T21:01:29Z",
        "lastEditedBy" : "3aa28542-364d-4b33-92fe-22177c758757",
        "tags" : [
        ]
      }
    ],
    "commit" : "47e093dd36ff74c9ab8a3b2728d4c0c5331f1bef",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +426,430 @@\n  // the gradients from m1 and m2 will be summed to compute the gradient\n  // w.r.t y\n  // dz/dy = xT * dm1 + dm2 * zT\n  test::ExpectTensorNear<double>("
  }
]