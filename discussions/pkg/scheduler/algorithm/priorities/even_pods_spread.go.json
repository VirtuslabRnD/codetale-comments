[
  {
    "id" : "b6882a47-0200-419c-bcab-fe9e6b03ed03",
    "prId" : 84262,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84262#pullrequestreview-310233804",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73d2dae1-cba4-4ede-9b5c-879bb80705dd",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "why is nil returned here ?",
        "createdAt" : "2019-10-31T23:33:37Z",
        "updatedAt" : "2019-10-31T23:33:37Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "90603728fbff4db0a934bb5180f4873d96e1b48a",
    "line" : 127,
    "diffHunk" : "@@ -1,1 +107,111 @@\tif err := errCh.ReceiveError(); err != nil {\n\t\tklog.Error(err)\n\t\treturn nil\n\t}\n"
  },
  {
    "id" : "3c20c6dc-0f11-4657-8b9c-fed3f74b2e30",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-266347430",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1a615e4-9d96-4bbc-8a54-b72472805a48",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "should we run this in parallel?",
        "createdAt" : "2019-07-07T02:16:35Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "efb35032-4ada-49fb-b46d-349a86639741",
        "parentId" : "f1a615e4-9d96-4bbc-8a54-b72472805a48",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "We can.",
        "createdAt" : "2019-07-24T23:18:08Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "1e5929e0-ef08-4217-bfa1-0f298f628e7b",
        "parentId" : "f1a615e4-9d96-4bbc-8a54-b72472805a48",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Maybe not worth it due to the cost of lock. And here `nodes` are the filtered nodes.",
        "createdAt" : "2019-07-25T00:17:53Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +58,62 @@func (t *topologySpreadConstraintsMap) initialize(pod *v1.Pod, nodes []*v1.Node) {\n\tconstraints := getSoftTopologySpreadConstraints(pod)\n\tfor _, node := range nodes {\n\t\tif !predicates.NodeLabelsMatchSpreadConstraints(node.Labels, constraints) {\n\t\t\tcontinue"
  },
  {
    "id" : "bd538617-3eac-4a51-a769-75e709df96fd",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267347271",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ea86b5e-6745-4357-8964-008051e45675",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "this we can run in parallel as well.",
        "createdAt" : "2019-07-18T19:18:19Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "1bad9d71-af88-467d-b70b-a378c18b1cde",
        "parentId" : "7ea86b5e-6745-4357-8964-008051e45675",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "It seems like a not very expensive loop (we only iterate through nodes, not pods). It might require perf-testing.",
        "createdAt" : "2019-07-19T20:23:32Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "7384f538-138f-4d3a-8ea6-6ecadaf653c3",
        "parentId" : "7ea86b5e-6745-4357-8964-008051e45675",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "Probably, it depends on scale and cluster state though. Not worth doing it now though, I agree.",
        "createdAt" : "2019-07-26T21:16:08Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 194,
    "diffHunk" : "@@ -1,1 +192,196 @@\t\tfScore := float64(schedulerapi.MaxPriority) * (float64(total-t.nodeNameToPodCounts[node.Name]) / float64(maxMinDiff))\n\t\tresult[i].Score = int(fScore)\n\t}\n\n\treturn result, nil"
  },
  {
    "id" : "b9021c55-a7f1-4152-9a1a-8511a54aeb2c",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-266749549",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ecf27d39-2047-4832-96b3-008c1923f90a",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "remove empty line",
        "createdAt" : "2019-07-19T19:24:48Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "32656c7a-86a3-40aa-baa2-11c518b8a213",
        "parentId" : "ecf27d39-2047-4832-96b3-008c1923f90a",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "It seems a convention to keep \"k8s.io/klog\" apart with other imports.",
        "createdAt" : "2019-07-25T00:31:56Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "3e45f680-e041-4a7f-9f32-b56a0c70490c",
        "parentId" : "ecf27d39-2047-4832-96b3-008c1923f90a",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "Uhm... that's a weird one. It seems to be the second block though.",
        "createdAt" : "2019-07-25T16:38:21Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +28,32 @@\tschedulernodeinfo \"k8s.io/kubernetes/pkg/scheduler/nodeinfo\"\n\tschedutil \"k8s.io/kubernetes/pkg/scheduler/util\"\n\n\t\"k8s.io/klog\"\n)"
  },
  {
    "id" : "12f1024b-ac86-4fad-9db7-8fbdfe1e5119",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267808386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "Consider creating an issue for this",
        "createdAt" : "2019-07-19T20:17:07Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "b151dd9a-0e7a-46fb-9770-9d9859d65c6c",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "In my mind, if the node satisfy the constraints as if they were hard, it's priority should be `schedulerapi.MaxPriority`.",
        "createdAt" : "2019-07-25T17:36:37Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "7beda364-b3d2-404f-a098-e49228190ad0",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "In that case, we have to check the formula which is implemented in Predicates again, that calculation effort isn't trivial. IMO in terms of Priority, it's not worth that way. The current algorithm also can rank the nodes well.",
        "createdAt" : "2019-07-26T07:56:17Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "480d72f3-d370-4b34-b6d7-75b31b25bc52",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "We should be able to reuse calculations once we move to the framework. Can you open a tracking bug to consider a new formula?",
        "createdAt" : "2019-07-26T14:34:01Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "33b998e2-3286-4ec9-8d22-22a1f90115ba",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "we can't reuse the calculations because the predicate metadata is only computed for the hard constraints, not all constraints.",
        "createdAt" : "2019-07-26T21:01:28Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "4187da3f-4663-4198-b3e4-346a7c3e6f38",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "@ahg-g is right, they are separate constraints :)",
        "createdAt" : "2019-07-26T22:28:55Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "ffa459bf-e525-4f98-be44-6d3c86ff6cc5",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "I know... but the calculation is the same, if I'm not missing something. We should be able to iterate only once through all the nodes for all the constraints.",
        "createdAt" : "2019-07-29T13:38:57Z",
        "updatedAt" : "2019-07-29T13:38:58Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "3f01020b-398b-41fb-9c68-868cf88a5efb",
        "parentId" : "bce91ac2-7388-4c28-941b-f5f2f01dae22",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "I don't think the calculation is the same, we don't iterate over the soft constraints now at all, and so they are not matched against the node or the pods on the nodes. If we do that, and the node gets filtered out before getting scored, that calculation becomes a waste.",
        "createdAt" : "2019-07-29T14:09:29Z",
        "updatedAt" : "2019-07-29T14:10:54Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 168,
    "diffHunk" : "@@ -1,1 +166,170 @@\n\t// calculate final priority score for each node\n\t// TODO(Huang-Wei): in alpha version, we keep the formula as simple as possible.\n\t// current version ranks the nodes properly, but it doesn't take MaxSkew into\n\t// consideration, we may come up with a better formula in the future."
  },
  {
    "id" : "99c10df5-19f2-498c-b366-ebd9670d6ffa",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267040856",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d9f52104-d31c-47e0-9e1e-1a0ddc5de39c",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "Resurfacing an outdated suggestion:\r\nThis comment could start with a more high level (and more readable) sentence. What we are trying to say is that, the score of a node is the total number of pods minus the pods in it's same topology domain. There might be a few details that I'm missing regarding having multiple constraints.",
        "createdAt" : "2019-07-25T16:47:28Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "d8e885fa-c8e7-45de-be61-d086eaae35a5",
        "parentId" : "d9f52104-d31c-47e0-9e1e-1a0ddc5de39c",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "I haven't updated it yet. Will revisit tomorrow.",
        "createdAt" : "2019-07-26T07:56:45Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +74,78 @@}\n\n// CalculateEvenPodsSpreadPriority computes a score by checking through the topologySpreadConstraints\n// that are with WhenUnsatisfiable=ScheduleAnyway (a.k.a soft constraint).\n// The function works as below:"
  },
  {
    "id" : "e9456007-d429-4a70-9afb-04fd534e3dad",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267069637",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b1f8b14-3c1b-4a26-ac9c-71b59006feeb",
        "parentId" : null,
        "authorId" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "body" : "Where do we call this priority function? This is the only place \"CalculateEvenPodsSpreadPriority\" string appears.",
        "createdAt" : "2019-07-26T08:28:42Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "tags" : [
        ]
      },
      {
        "id" : "c8422999-b50f-4342-86ab-12120311bb91",
        "parentId" : "6b1f8b14-3c1b-4a26-ac9c-71b59006feeb",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Good question.. I realized the issue only until I wrote the integration test (i.e. in PR6, you can see the fix - it's actually an typo in `defaults.go`...)\r\n\r\nBut as you raised this, to avoid confusion, let me move that fix in PR6 to this PR.\r\n\r\nBTW: we can see the benefits of having different kinds of tests :)",
        "createdAt" : "2019-07-26T08:45:23Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "84ef2de0-69ad-40f6-9df6-9a01d07133bf",
        "parentId" : "6b1f8b14-3c1b-4a26-ac9c-71b59006feeb",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Oh... In addition to that typo, I made another rebasing mistake..",
        "createdAt" : "2019-07-26T08:50:07Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "be09c435-d3b5-47e6-baf4-0e41e405301c",
        "parentId" : "6b1f8b14-3c1b-4a26-ac9c-71b59006feeb",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Done. Squashed to commit \"EvenPodsSpread: Define a new Priority\".\r\n\r\nThanks for the catch! (Otherwise, the next PR is the only guard...)\r\n\r\nTo get the benefits of making each PR CI green, I paid way too much energy on rebasing...",
        "createdAt" : "2019-07-26T08:54:10Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "39d407ad-3677-49af-be9b-82b8fa7fb9a3",
        "parentId" : "6b1f8b14-3c1b-4a26-ac9c-71b59006feeb",
        "authorId" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "body" : "> Done. Squashed to commit \"EvenPodsSpread: Define a new Priority\".\r\n> \r\n> Thanks for the catch! (Otherwise, the next PR is the only guard...)\r\n> \r\n> To get the benefits of making each PR CI green, I paid way too much energy on rebasing...\r\n\r\nThe rebasing could cause tons of work. Thanks for breaking this into pieces.",
        "createdAt" : "2019-07-26T08:59:36Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +83,87 @@// Whether existingPod matches incomingPod doesn't contribute to the final score.\n// This is different from the Affinity API.\nfunc CalculateEvenPodsSpreadPriority(pod *v1.Pod, nodeNameToInfo map[string]*schedulernodeinfo.NodeInfo, nodes []*v1.Node) (schedulerapi.HostPriorityList, error) {\n\tresult := make(schedulerapi.HostPriorityList, len(nodes))\n\t// return if incoming pod doesn't have soft topology spread constraints."
  },
  {
    "id" : "28bcb291-bd27-4b66-8969-d12a6cc3b962",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267430242",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f82d2557-debd-4558-9413-6605ff4044b5",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "Can't we use int64 instead of a pointer? line 131 would look like this:\r\n\r\n```\r\nif _, ok := t.topologyPairToPodCounts[pair]; !ok {\r\n  continue;\r\n}\r\n```\r\n\r\nand lines 75-77 can be changed to just:\r\n```\r\nt.topologyPairToPodCounts[pair] = 0\r\n```",
        "createdAt" : "2019-07-26T18:43:38Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "38771c1c-17f3-470d-9a7f-1cfb9d19eb52",
        "parentId" : "f82d2557-debd-4558-9413-6605ff4044b5",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Unfortunately no. Golang doesn't support [addressing a map value](https://github.com/golang/go/issues/11865), i.e. if `topologyPairToPodCounts` is defined as `map[topologyPair]int64`, we can't operate `&topologyPairToPodCounts[pair]`.",
        "createdAt" : "2019-07-26T22:42:56Z",
        "updatedAt" : "2019-07-27T03:51:30Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +41,45 @@\tnodeNameToPodCounts map[string]int64\n\t// topologyPairToPodCounts is keyed with topologyPair, and valued with the number of matching pods.\n\ttopologyPairToPodCounts map[topologyPair]*int64\n}\n"
  },
  {
    "id" : "550d82db-2e46-4390-8cfd-dc740f32ccb6",
    "prId" : 79063,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79063#pullrequestreview-267476343",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3322a75b-52df-4d79-b544-d43567df724d",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "processNode seems to be better name.",
        "createdAt" : "2019-07-27T10:40:55Z",
        "updatedAt" : "2019-07-27T10:49:19Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      },
      {
        "id" : "c4315616-b094-4adf-9072-4b20f7a39bd8",
        "parentId" : "3322a75b-52df-4d79-b544-d43567df724d",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "That's the old name. Here I want to highlight that this function works for **all** nodes, instead of each **candidate** node which has passed Predicates check.",
        "createdAt" : "2019-07-27T17:37:50Z",
        "updatedAt" : "2019-07-27T17:37:50Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "755a3112d89770549aec0a33e2f6bb57ae092cc6",
    "line" : 103,
    "diffHunk" : "@@ -1,1 +101,105 @@\terrCh := schedutil.NewErrorChannel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tprocessAllNode := func(i int) {\n\t\tnodeInfo := nodeNameToInfo[allNodeNames[i]]\n\t\tnode := nodeInfo.Node()"
  }
]