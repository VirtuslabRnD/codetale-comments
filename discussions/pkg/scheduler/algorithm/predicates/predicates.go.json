[
  {
    "id" : "56eb39f3-5624-4040-a7c5-4ead5ac0af27",
    "prId" : 89437,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/89437#pullrequestreview-380581319",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c6fefa3-b59f-4e7a-bad6-6de76934f724",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "doing this is fine and simple because all the pods are from the same node.\r\n\r\n```suggestion\r\n\t\tif err != nil || existingPodNode == nil {\r\n```",
        "createdAt" : "2020-03-24T18:25:44Z",
        "updatedAt" : "2020-03-24T18:58:05Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f41500dd71475e748e5d61ca92ae57a33805e92",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +1379,1383 @@\tfor _, existingPod := range existingPods {\n\t\texistingPodNode, err := c.info.GetNodeInfo(existingPod.Spec.NodeName)\n\t\tif err != nil {\n\t\t\tif apierrors.IsNotFound(err) {\n\t\t\t\tcontinue"
  },
  {
    "id" : "b22c4bbe-e4b5-4b3c-aa7a-cac295f85fcd",
    "prId" : 87091,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87091#pullrequestreview-341503843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b34b056-4812-473f-ac23-bb7f73c88297",
        "parentId" : null,
        "authorId" : "41c25afd-5561-4611-9b3a-7df68582aa10",
        "body" : "Just a question, this would be move into kubelet?",
        "createdAt" : "2020-01-11T04:03:23Z",
        "updatedAt" : "2020-01-13T18:02:49Z",
        "lastEditedBy" : "41c25afd-5561-4611-9b3a-7df68582aa10",
        "tags" : [
        ]
      },
      {
        "id" : "81b365bb-54c9-451b-bb9f-2735743018e9",
        "parentId" : "7b34b056-4812-473f-ac23-bb7f73c88297",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "may be, not sure yet.",
        "createdAt" : "2020-01-11T04:37:58Z",
        "updatedAt" : "2020-01-13T18:02:49Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb66e807cd317254e5c7bf134186ddbfba757ef4",
    "line" : 293,
    "diffHunk" : "@@ -1,1 +73,77 @@\n// GeneralPredicates checks a group of predicates that the kubelet cares about.\nfunc GeneralPredicates(pod *v1.Pod, _ interface{}, nodeInfo *schedulernodeinfo.NodeInfo) (bool, []PredicateFailureReason, error) {\n\tif nodeInfo.Node() == nil {\n\t\treturn false, nil, fmt.Errorf(\"node not found\")"
  },
  {
    "id" : "29046b07-9e5c-4cea-a23e-90007b19e500",
    "prId" : 86205,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86205#pullrequestreview-331564942",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2fc4dfd1-ce6b-4b36-af50-cb3769ceee4a",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "We need a todo here to implement this, right?",
        "createdAt" : "2019-12-12T21:56:03Z",
        "updatedAt" : "2019-12-14T00:33:50Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "4b1b83e1-8977-4f48-be3c-d09ab9a2d040",
        "parentId" : "2fc4dfd1-ce6b-4b36-af50-cb3769ceee4a",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "done.",
        "createdAt" : "2019-12-12T22:24:07Z",
        "updatedAt" : "2019-12-14T00:33:50Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d353f5122d3da656d64ad8a22d8d4f8d7a3c0f2",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +1665,1669 @@\tif meta == nil {\n\t\t// TODO(autoscaler): get it implemented.\n\t\treturn false, nil, errors.New(\"metadata not pre-computed for PodTopologySpreadPredicate\")\n\t}\n"
  },
  {
    "id" : "634168f1-8cc3-4be3-8d4d-8e8f61102630",
    "prId" : 86175,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86175#pullrequestreview-330839113",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f6cbb35-7211-4bf6-a01d-2798e738dc60",
        "parentId" : null,
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "When autoscaler team have their logic covered, are we going to return err in the else block?",
        "createdAt" : "2019-12-11T22:37:21Z",
        "updatedAt" : "2019-12-12T20:20:25Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "e144a1a7-f483-46d5-899f-a77afc5ce93d",
        "parentId" : "5f6cbb35-7211-4bf6-a01d-2798e738dc60",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "I am not sure, we may keep this.",
        "createdAt" : "2019-12-11T23:55:57Z",
        "updatedAt" : "2019-12-12T20:20:25Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "2fdf1fa3c14b54dcae43bc2c5622fbcbb4857c17",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1357,1361 @@\tif meta != nil {\n\t\ttopologyMap = meta.topologyToMatchedExistingAntiAffinityTerms\n\t} else {\n\t\t// Filter out pods whose nodeName is equal to nodeInfo.node.Name, but are not\n\t\t// present in nodeInfo. Pods on other nodes pass the filter."
  },
  {
    "id" : "4be8027b-5734-4e5e-b24b-4793fd439faf",
    "prId" : 86175,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86175#pullrequestreview-331463526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3c7ba3f-d2cf-4491-a805-48330ba6b148",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "for a next PR: PodAffinityChecker sounds like a really bad name. We can rename it once we move it to the plugin file.",
        "createdAt" : "2019-12-12T19:01:57Z",
        "updatedAt" : "2019-12-12T20:20:25Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "ff86f64d-2c6b-4233-8171-ed22efde953e",
        "parentId" : "f3c7ba3f-d2cf-4491-a805-48330ba6b148",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "will not be needed at all.",
        "createdAt" : "2019-12-12T19:17:22Z",
        "updatedAt" : "2019-12-12T20:20:25Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "2fdf1fa3c14b54dcae43bc2c5622fbcbb4857c17",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1196,1200 @@\n// NewPodAffinityChecker returns a PodAffinityChecker.\nfunc NewPodAffinityChecker(sharedLister schedulerlisters.SharedLister) *PodAffinityChecker {\n\treturn &PodAffinityChecker{\n\t\tnodeInfoLister: sharedLister.NodeInfos(),"
  },
  {
    "id" : "7f881337-9526-4bce-bd21-2cbfcc3d0cd6",
    "prId" : 84273,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84273#pullrequestreview-306915541",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6c61f90-e44a-465e-a160-d3ab49445feb",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Does the lister init also have to be feature gated? https://github.com/kubernetes/kubernetes/blob/02ee2421f54b1594aec2f0c78331e308e1b1bb8e/pkg/scheduler/framework/plugins/nodevolumelimits/csi.go#L53",
        "createdAt" : "2019-10-24T23:16:01Z",
        "updatedAt" : "2019-10-24T23:16:37Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "2f17ed49-4ebf-452e-8fa4-3599e3e28b23",
        "parentId" : "a6c61f90-e44a-465e-a160-d3ab49445feb",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "Yes, here?\r\n\r\nhttps://github.com/kubernetes/kubernetes/pull/84273/files#diff-d4eb2aa05b0aaa444f6ee822fc3efed8",
        "createdAt" : "2019-10-24T23:23:40Z",
        "updatedAt" : "2019-10-24T23:23:40Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e2f2dde4d197f448621b498e39eafdad551567c",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +451,455 @@\t\terr     error\n\t)\n\tif c.csiNodeLister != nil {\n\t\tcsiNode, err = c.csiNodeLister.Get(node.Name)\n\t\tif err != nil {"
  },
  {
    "id" : "a2ffd556-280d-4ba5-88d2-d657ea82cb71",
    "prId" : 84193,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84193#pullrequestreview-305429872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03f8aa54-1d11-4cac-a993-4768bfe62a0d",
        "parentId" : null,
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Move it back to its original position? so that it doesn't generate a diff.",
        "createdAt" : "2019-10-22T18:34:33Z",
        "updatedAt" : "2019-10-22T22:11:17Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "07e03121-302c-48fd-a99a-843aff0a566e",
        "parentId" : "03f8aa54-1d11-4cac-a993-4768bfe62a0d",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "Oh, that's because I added NodeInfo back not in the same place after I realized that kubelet uses it, anyway we will remove NodeInfo soon, so this should be fine.",
        "createdAt" : "2019-10-22T18:47:39Z",
        "updatedAt" : "2019-10-22T22:11:17Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "d393804237919f13555905fcdf78e7faa118daa1",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +160,164 @@// The failure information is given by the error.\ntype FitPredicate func(pod *v1.Pod, meta PredicateMetadata, nodeInfo *schedulernodeinfo.NodeInfo) (bool, []PredicateFailureReason, error)\n\n// CSINodeInfo interface represents anything that can get CSINode object from node name.\ntype CSINodeInfo interface {"
  },
  {
    "id" : "fc5c0073-04ea-4cc0-9eb9-51883931cda6",
    "prId" : 84017,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84017#pullrequestreview-302955265",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b53297ca-6df3-470c-98e2-3d708b2ea53d",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "nit: the API object has been renamed to `CSINode` (the `Info` is omitted)",
        "createdAt" : "2019-10-16T23:39:47Z",
        "updatedAt" : "2019-10-19T03:52:33Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "95d6a28a-f82b-4fa8-93a1-e69053745362",
        "parentId" : "b53297ca-6df3-470c-98e2-3d708b2ea53d",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "I wanted to be consistent with the other few interfaces defined in the same file (all suffixed with info). I agree we probably don't need any of that, but as I mentioned I would like to keep the code consistent while working on removing all of them completely.",
        "createdAt" : "2019-10-17T00:59:06Z",
        "updatedAt" : "2019-10-19T03:52:33Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7727226605c6da96ebcc148ff4ee06ad2feb7b4",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +177,181 @@\n// CachedCSINodeInfo implements CSINodeInfoInfo\ntype CachedCSINodeInfo struct {\n\tv1beta1storagelisters.CSINodeLister\n}"
  },
  {
    "id" : "815dd7ee-69ec-4f53-8103-f58269e2a82e",
    "prId" : 84017,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84017#pullrequestreview-302953450",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99ece8f4-0a47-4096-8ae6-06072561e39c",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "nit: this interface should be renamed to `CSINodeGetter`",
        "createdAt" : "2019-10-16T23:43:04Z",
        "updatedAt" : "2019-10-19T03:52:33Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "2404eb70-6cbb-4019-9041-1ae830e37336",
        "parentId" : "99ece8f4-0a47-4096-8ae6-06072561e39c",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "replied in the other comment.",
        "createdAt" : "2019-10-17T00:50:09Z",
        "updatedAt" : "2019-10-19T03:52:33Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7727226605c6da96ebcc148ff4ee06ad2feb7b4",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +174,178 @@}\n\nvar _ CSINodeInfo = &CachedCSINodeInfo{}\n\n// CachedCSINodeInfo implements CSINodeInfoInfo"
  },
  {
    "id" : "3e164541-c22b-4c51-9cc1-731afdf51b5c",
    "prId" : 83578,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/83578#pullrequestreview-299081246",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "880c10ff-9f99-415e-a90b-1379c191c5d2",
        "parentId" : null,
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "I intentionally alias it to \"legacyapi\", which will get resolved in a followup PR.",
        "createdAt" : "2019-10-08T22:18:00Z",
        "updatedAt" : "2019-11-01T21:38:21Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "703a669db3081d4b5b375b9c41a1265a0f9b44ef",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +44,48 @@\t\"k8s.io/kubernetes/pkg/scheduler/algorithm\"\n\tpriorityutil \"k8s.io/kubernetes/pkg/scheduler/algorithm/priorities/util\"\n\tlegacyapi \"k8s.io/kubernetes/pkg/scheduler/api\"\n\tschedulerlisters \"k8s.io/kubernetes/pkg/scheduler/listers\"\n\tschedulernodeinfo \"k8s.io/kubernetes/pkg/scheduler/nodeinfo\""
  },
  {
    "id" : "337a010f-20cf-414f-ba3e-c57abe9c9162",
    "prId" : 82990,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/82990#pullrequestreview-291548854",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "948aa62d-6952-4add-b573-ce6b08fdf58b",
        "parentId" : null,
        "authorId" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "body" : "Moving the function here seems unnecessary",
        "createdAt" : "2019-09-23T02:38:36Z",
        "updatedAt" : "2019-09-23T04:50:34Z",
        "lastEditedBy" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "tags" : [
        ]
      },
      {
        "id" : "a92f2d6e-d1fa-49ec-844c-6ecb5da37318",
        "parentId" : "948aa62d-6952-4add-b573-ce6b08fdf58b",
        "authorId" : "e7b8fd7e-f93b-44b6-b6d0-4331207d901c",
        "body" : "Thanks for your feedback @draveness \r\nThe reasons for moving here are:\r\n1. closer to `predicatesOrdering` variable\r\n2. avoid interrupting `CachedPersistentVolumeInfo` and it's method",
        "createdAt" : "2019-09-23T02:49:15Z",
        "updatedAt" : "2019-09-23T04:50:34Z",
        "lastEditedBy" : "e7b8fd7e-f93b-44b6-b6d0-4331207d901c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cb4850699a4a3c1008382c8b05f245b66ce19ad",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +154,158 @@)\n\n// Ordering returns the ordering of predicates.\nfunc Ordering() []string {\n\treturn predicatesOrdering"
  },
  {
    "id" : "aead7c37-cf11-4d39-8a71-5c29f50b1366",
    "prId" : 82990,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/82990#pullrequestreview-292572682",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42cf6944-f499-41d4-8c9d-5eed79be16cf",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "This seems unnecessary as these are just internal packages and the definition of the interface is in the same file.",
        "createdAt" : "2019-09-23T14:13:58Z",
        "updatedAt" : "2019-09-23T14:14:02Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "e5edc128-604a-4bd4-85b0-e356b4fb8d61",
        "parentId" : "42cf6944-f499-41d4-8c9d-5eed79be16cf",
        "authorId" : "e7b8fd7e-f93b-44b6-b6d0-4331207d901c",
        "body" : "Yes, they are in the same file.\r\nBut I think it's still a good rule to always validate an interface implementation.\r\nSuch as:\r\n- https://github.com/kubernetes/kubernetes/blob/master/pkg/controller/controller_utils.go#L429-L443\r\n- https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/cpumanager/cpu_manager.go#L52-L102",
        "createdAt" : "2019-09-24T09:43:00Z",
        "updatedAt" : "2019-09-24T09:43:01Z",
        "lastEditedBy" : "e7b8fd7e-f93b-44b6-b6d0-4331207d901c",
        "tags" : [
        ]
      },
      {
        "id" : "34b527eb-935a-4361-8306-55cd5b6d2c6d",
        "parentId" : "42cf6944-f499-41d4-8c9d-5eed79be16cf",
        "authorId" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "body" : "> This seems unnecessary as these are just internal packages and the definition of the interface is in the same file.\r\n\r\nI think it is a good pattern which could help us to find problems during compile time.",
        "createdAt" : "2019-09-24T10:01:40Z",
        "updatedAt" : "2019-09-24T10:01:40Z",
        "lastEditedBy" : "9829b6c0-e54c-401b-8d97-73e5aa4e83c1",
        "tags" : [
        ]
      },
      {
        "id" : "3e5af4d5-bde6-4113-aeaf-43b320b3c260",
        "parentId" : "42cf6944-f499-41d4-8c9d-5eed79be16cf",
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "Note that compilation of the scheduler would still fail, because we use only the interface outside of this package (other than instantiation).",
        "createdAt" : "2019-09-24T14:18:58Z",
        "updatedAt" : "2019-09-24T14:19:16Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "b0761990-3857-4a72-9cef-450a32f8e121",
        "parentId" : "42cf6944-f499-41d4-8c9d-5eed79be16cf",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "@alculquicondor If each implementation follows this \"compile-time assertion\" pattern, potential issues can be found easily, and also it can speedup code refactoring if someday we want to change the interface.",
        "createdAt" : "2019-09-24T17:04:30Z",
        "updatedAt" : "2019-09-24T17:04:31Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cb4850699a4a3c1008382c8b05f245b66ce19ad",
    "line" : 80,
    "diffHunk" : "@@ -1,1 +196,200 @@}\n\nvar _ PersistentVolumeClaimInfo = &CachedPersistentVolumeClaimInfo{}\n\n// CachedPersistentVolumeClaimInfo implements PersistentVolumeClaimInfo"
  },
  {
    "id" : "b9b445aa-cb28-45ca-a6fb-54bd49558f83",
    "prId" : 80360,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/80360#pullrequestreview-267138426",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "parentId" : null,
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "What about this, would be acceptable to make the pod unschedulable?\r\n\r\nWe currently fail if the PVC name is empty, but we count the volume if the PVC is invalid.\r\n\r\n I think counting this volume is not correct, since at this point we're not sure whether the volume belongs to the running predicate (i.e., it could be a EBS volume being counted by the GCEPD predicate).\r\n\r\n",
        "createdAt" : "2019-07-22T11:03:15Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      },
      {
        "id" : "78e960ce-d8b6-4b48-b832-62efbc6bbc20",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "This was an error condition we added a while ago to handle the case where users may delete PVCs while Pods were still running and using them.  But now that we have StorageProtection, do we need this check?  cc @jsafrane ",
        "createdAt" : "2019-07-22T20:26:58Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "0bf176f2-3a16-47a0-96c1-a27ca9e08ee7",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "> This was an error condition we added a while ago to handle the case where users may delete PVCs while Pods were still running and using them\r\n\r\nHmm, scheduler ignores pods that are running. IMO this check covers users (and StatefulSets) creating Pods before PVCs.",
        "createdAt" : "2019-07-23T08:25:26Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "691e9532-0f30-426c-bcc1-0061022c6c8c",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "I think `filterVolumes` goes through volumes from new pods and volumes from running pods on the node. So it looks like this condition was meant to handle both cases:\r\n\r\n1) User deletes PVC while pod is still running and using it on the node\r\n2) User creates a pod before a PVC\r\n\r\nNot counting the volume here is bad because we won't handle these situations.\r\n\r\nHowever, if we keep counting the volume, the predicate will fail for pods that are not even using the underline plugin (e.g., CSI volumes). In other words, the hard limit for volumes with invalid PVCs will always be 16 (which is the limit for GCEPD and Azure).",
        "createdAt" : "2019-07-23T09:26:01Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      },
      {
        "id" : "0b6f1254-a6af-44c0-abf2-6e5a4b8a1870",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "My argument is that StorageProtection handles 1).  And scheduler prevents 2). If immediate binding, predicate fails. If delayed binding, we count further down.",
        "createdAt" : "2019-07-23T15:15:15Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "338613bc-85c7-4b28-847d-e2974094258d",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "PVC protection can be forced off, so scheduler can encounter a pod that refers to PVC that does not exist. If `filterVolumes` is counting running pods, I would suggest not to count the volume - user has broken something and miscalculations are IMO OK. If `filterVolumes` checks a newly scheduled pod, I'd return error and prevented the pod from scheduling.",
        "createdAt" : "2019-07-25T11:03:23Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "15742363-7643-4631-9bd1-aa00d0192922",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "I like this approach, it addresses my concern.",
        "createdAt" : "2019-07-25T15:14:10Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      },
      {
        "id" : "26272cd8-52e2-40c6-ba25-355c501304bc",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "We don't strictly need separate behavior for counting separate pods vs to be scheduled pod. The volume binding predicate checks for bound pvcs",
        "createdAt" : "2019-07-25T15:20:07Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "4f36bcff-59c4-480c-82c9-36f473275213",
        "parentId" : "6c0079a2-596d-4c0a-9919-e762a58c6b6c",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "Hm, yeah, it does make sense for this predicate to only make the pod unschedulable because of volume limits; and leave the pvc binding checks for the volume binding predicate.\r\n\r\nUpdated the code, PTAL.",
        "createdAt" : "2019-07-26T11:40:51Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e9112b7fe0b2d1208b7a307c653d640e99f1a4f",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +426,430 @@\t\t\t\t// there's no guarantee that it belongs to the running predicate.\n\t\t\t\tklog.V(4).Infof(\"Unable to look up PVC info for %s/%s, assuming PVC doesn't match predicate when counting limits: %v\", namespace, pvcName, err)\n\t\t\t\tcontinue\n\t\t\t}\n"
  },
  {
    "id" : "e4da4290-7824-46a9-ab1e-17fa145fe7b4",
    "prId" : 80360,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/80360#pullrequestreview-265214942",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07ef51c5-cd28-46c6-a1d4-c167d03455af",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "is migration handled correctly here?",
        "createdAt" : "2019-07-22T20:24:21Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "22ce28b4-f592-44ac-9b11-3d4575a4f423",
        "parentId" : "07ef51c5-cd28-46c6-a1d4-c167d03455af",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "If migration is enabled for the volume, it'll be deferred to the CSI predicate; so IMO we should only match the in-tree plugin here.",
        "createdAt" : "2019-07-23T07:46:38Z",
        "updatedAt" : "2019-07-31T11:01:48Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e9112b7fe0b2d1208b7a307c653d640e99f1a4f",
    "line" : 105,
    "diffHunk" : "@@ -1,1 +554,558 @@\n\tMatchProvisioner: func(sc *storagev1.StorageClass) (relevant bool) {\n\t\tif sc.Provisioner == csilibplugins.AWSEBSInTreePluginName {\n\t\t\treturn true\n\t\t}"
  },
  {
    "id" : "5a03492a-56ed-423a-9913-c3174098c75c",
    "prId" : 78319,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/78319#pullrequestreview-243443980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb55e17d-72de-4d7c-96ce-f8bce86023ee",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "can you please update the comment at the top of the function indicating that Overhead is added to the final result.",
        "createdAt" : "2019-05-28T19:33:57Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "a395bc7a-0963-474b-9e65-f0374b684448",
        "parentId" : "bb55e17d-72de-4d7c-96ce-f8bce86023ee",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "done.",
        "createdAt" : "2019-05-29T18:34:40Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      }
    ],
    "commit" : "9babbf8bd7f009b4b1738efbf524e90b1c340e85",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +763,767 @@\tif pod.Spec.Overhead != nil && utilfeature.DefaultFeatureGate.Enabled(features.PodOverhead) {\n\t\tresult.Add(pod.Spec.Overhead)\n\t}\n\n\treturn result"
  },
  {
    "id" : "a217eb44-c9e6-4afe-8060-97768a179906",
    "prId" : 78319,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/78319#pullrequestreview-251968233",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd278c27-142d-4da1-8156-1b33fa3bd466",
        "parentId" : null,
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Checking feature gates in the critical path of scheduling has shown to cause performance degradation. Feature gates should be read once and passed to the scheduler.",
        "createdAt" : "2019-06-18T00:27:44Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "db0b540e-8528-4628-b41f-ac807e4a3ed8",
        "parentId" : "cd278c27-142d-4da1-8156-1b33fa3bd466",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "Understood.  I am looking now for a pre-existing example, though nothing immediate comes up (looking at commit history and scheduler pkg).",
        "createdAt" : "2019-06-18T04:12:30Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      },
      {
        "id" : "3624ee9d-b502-4c99-bed1-9df127c5d211",
        "parentId" : "cd278c27-142d-4da1-8156-1b33fa3bd466",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Here is an example: https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/factory/factory.go#L290",
        "createdAt" : "2019-06-18T19:13:50Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "10bf6256-2e4b-42bc-a9a6-4ed13764578b",
        "parentId" : "cd278c27-142d-4da1-8156-1b33fa3bd466",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "Thanks @bsalamat.  In the case of enableNonPreempting, it is relatively straight forward since the consumption of the flag is limited to within the genericScheduler itself.\r\n\r\nIn the case of enablePodOverhead, it is needed in three places (at least):\r\n - [node-info](https://github.com/egernst/kubernetes/blob/scheduler-changes/pkg/scheduler/nodeinfo/node_info.go#L591-L602): \r\n```golang\r\n\t// If Overhead is being utilized, add to the total requests for the pod\r\n\tif pod.Spec.Overhead != nil && utilfeature.DefaultFeatureGate.Enabled(features.PodOverhead) {\r\n\t\tresPtr.Add(pod.Spec.Overhead)\r\n\r\n\t\tif _, found := pod.Spec.Overhead[v1.ResourceCPU]; found {\r\n\t\t\tnon0CPU += pod.Spec.Overhead.Cpu().MilliValue()\r\n\t\t}\r\n\r\n\t\tif _, found := pod.Spec.Overhead[v1.ResourceMemory]; found {\r\n\t\t\tnon0Mem += pod.Spec.Overhead.Memory().Value()\r\n\t\t}\r\n\t}\r\n```\r\n - [predicate's GetResourceRequest](https://github.com/egernst/kubernetes/blob/scheduler-changes/pkg/scheduler/algorithm/predicates/predicates.go#L746-L763)\r\n - [priority's resource allocation requests](https://github.com/egernst/kubernetes/blob/scheduler-changes/pkg/scheduler/algorithm/priorities/resource_allocation.go#L94-L116)\r\n\r\nThe problem I have is finding the appropriate structure to stash the PodOverhead flag in.\r\n\r\n## First attempt -- adding to NodeInfo structure:\r\nNodeInfo is available for each area, but this doesn't work well, since: 1) feature gate is looked up per node, and 2) the GetMetadata for both priority and [predicates](https://github.com/egernst/kubernetes/blob/scheduler-changes/pkg/scheduler/algorithm/predicates/metadata.go#L155) calls into the applicable function where node specific information isn't available (ie, GetMetadata operates on a set of nodes)\r\n\r\n## Second attempt -- add to the {Priority|Predicate}MetadataFactory\r\n\r\nThis isn't straightforward either, but looks like the 'best' option (at least, most apparent after quickly reviewing the scheduler base). Modifications would be needed within the algorithmprovider for creating New{Priority|Predicate}MetadataFactory.\r\n\r\nWDYT @bsalamat ? This match your expectation?",
        "createdAt" : "2019-06-18T22:12:51Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      },
      {
        "id" : "9757d3fe-2255-4d4c-8370-13c1299b4bd6",
        "parentId" : "cd278c27-142d-4da1-8156-1b33fa3bd466",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Thanks for checking the options. You are right that this particular feature gate is harder to pass to various parts of the scheduler. Unfortunately, none of the possible options are sufficiently clean. So, let's keep them as they are. Since we check  `pod.Spec.Overhead != nil` before checking the feature gate, this will not have a performance impact for pods that don't use the feature.",
        "createdAt" : "2019-06-19T20:59:19Z",
        "updatedAt" : "2019-07-16T22:03:48Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      }
    ],
    "commit" : "9babbf8bd7f009b4b1738efbf524e90b1c340e85",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +761,765 @@\n\t// If Overhead is being utilized, add to the total requests for the pod\n\tif pod.Spec.Overhead != nil && utilfeature.DefaultFeatureGate.Enabled(features.PodOverhead) {\n\t\tresult.Add(pod.Spec.Overhead)\n\t}"
  },
  {
    "id" : "45dde03c-8546-4436-a0e7-d4a7720a921d",
    "prId" : 77828,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/77828#pullrequestreview-240231360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7827837-44d9-4d87-a622-1d6dcb6ba84c",
        "parentId" : null,
        "authorId" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "body" : "why does this only get the hard topology constraints ?",
        "createdAt" : "2019-05-21T05:06:44Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "tags" : [
        ]
      },
      {
        "id" : "f212157f-e82f-4d21-b840-095ba3fbf679",
        "parentId" : "a7827837-44d9-4d87-a622-1d6dcb6ba84c",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "As predicates only care about hard constraints :) In Priority logic, it will take care of soft constraints.",
        "createdAt" : "2019-05-21T18:42:07Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "1822085088dcf43712049e3fa58c46f456505d03",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +1724,1728 @@\t}\n\n\tconstraints := getHardTopologySpreadConstraints(pod)\n\tif len(constraints) == 0 {\n\t\treturn true, nil, nil"
  },
  {
    "id" : "83572040-52d9-4967-a111-97547c78d1c2",
    "prId" : 77828,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/77828#pullrequestreview-240231748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d85c8f4-5d70-4e43-9408-931fd6a127f8",
        "parentId" : null,
        "authorId" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "body" : "when does this get populated ?",
        "createdAt" : "2019-05-21T05:07:08Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "tags" : [
        ]
      },
      {
        "id" : "946ba524-c5ee-4d57-8c7c-e8b77876a428",
        "parentId" : "2d85c8f4-5d70-4e43-9408-931fd6a127f8",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "As usual, at the beginning of Predicates phase.",
        "createdAt" : "2019-05-21T18:42:52Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "1822085088dcf43712049e3fa58c46f456505d03",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +1731,1735 @@\tvar topologyPairsPodSpreadMap *topologyPairsPodSpreadMap\n\tif predicateMeta, ok := meta.(*predicateMetadata); ok {\n\t\ttopologyPairsPodSpreadMap = predicateMeta.topologyPairsPodSpreadMap\n\t} else { // We don't have precomputed metadata. We have to follow a slow path to check spread constraints.\n\t\t// TODO(Huang-Wei): get it implemented"
  },
  {
    "id" : "4098eedb-e620-4319-b05c-5ed509ef914f",
    "prId" : 77828,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/77828#pullrequestreview-266179262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9412d06-19e1-4c4b-b4aa-f4ffe4671d05",
        "parentId" : null,
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "Is there actually a legitimate case where metadata is not pre-computed and we still would like to proceed and compute it here? If yes, can you please document that case here. \r\n\r\nI hope that we can always consider this an error, and not invoke the metadata generation logic here.\r\n",
        "createdAt" : "2019-07-06T12:35:23Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "6cf89a72-4667-40db-a904-02c9d651e862",
        "parentId" : "b9412d06-19e1-4c4b-b4aa-f4ffe4671d05",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "This always puzzled me as well. I once asked @bsalamat on this, the answer i got is that ClusterAutoscaler seems to use a non-default algorithmProvider, so they are the only consumer of the else block.\r\n\r\nTo be honest, I haven't checked the exact running path of CusterAutoscaler, and also have no knowledge on their background and usecase. ",
        "createdAt" : "2019-07-07T23:58:58Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "dfb9b053-9f9e-46bd-a0c6-e3e55c74a690",
        "parentId" : "b9412d06-19e1-4c4b-b4aa-f4ffe4671d05",
        "authorId" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "body" : "can you please create an issue to track this? we also need an issue to track optimizing the implementation by using counters instead of pod lists in the maps.",
        "createdAt" : "2019-07-24T14:43:16Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "570b631b-84a0-4888-a815-ca0e7934e412",
        "tags" : [
        ]
      },
      {
        "id" : "0f458e85-8fce-44ef-baba-3530d4216fe2",
        "parentId" : "b9412d06-19e1-4c4b-b4aa-f4ffe4671d05",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Let me put them as TODO items in the umbrella issue for now, and will create Issues/PRs resolving them after the code gets merged.",
        "createdAt" : "2019-07-24T17:41:32Z",
        "updatedAt" : "2019-07-24T17:41:32Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "1822085088dcf43712049e3fa58c46f456505d03",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +1733,1737 @@\t\ttopologyPairsPodSpreadMap = predicateMeta.topologyPairsPodSpreadMap\n\t} else { // We don't have precomputed metadata. We have to follow a slow path to check spread constraints.\n\t\t// TODO(Huang-Wei): get it implemented\n\t\treturn false, nil, errors.New(\"metadata not pre-computed for EvenPodsSpreadPredicate\")\n\t}"
  },
  {
    "id" : "70cf026d-186e-4ef2-a780-3213db0f259e",
    "prId" : 77828,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/77828#pullrequestreview-264485205",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b1d426d-1ad6-453f-84cb-83c9ad2b168b",
        "parentId" : null,
        "authorId" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "body" : "One observation: if the global minimum is the same node that we are inspecting, technically the skew could be either 1 or 0 depending on whether the minimum is unique. But that shouldn't matter because maxSkew >= 1. Is it worth commenting this?",
        "createdAt" : "2019-07-19T15:37:04Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "31fbce73-ef64-43f8-9faa-047479d8fc32",
        "tags" : [
        ]
      },
      {
        "id" : "32b70c17-bd88-4708-96a7-fab1eb46a0cb",
        "parentId" : "0b1d426d-1ad6-453f-84cb-83c9ad2b168b",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "Probably not. It's obvious :)",
        "createdAt" : "2019-07-20T05:52:13Z",
        "updatedAt" : "2019-07-24T17:30:19Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "1822085088dcf43712049e3fa58c46f456505d03",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +1767,1771 @@\t\t}\n\t\t// judging criteria:\n\t\t// 'existing matching num' + 'if self-match (1 or 0)' - 'global min matching num' <= 'maxSkew'\n\t\tmatchNum := len(topologyPairsPodSpreadMap.topologyPairToPods[pair])\n"
  },
  {
    "id" : "7533d0f4-eddc-4891-922d-8f2777b819e8",
    "prId" : 77595,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/77595#pullrequestreview-245425318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "parentId" : null,
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "I do not think this check implements KEP proposal. The KEP says:\r\n\r\n>old predicates will be modified to perform an additional check of `CSINode` object at very beginning of their code. If they detect that `CSINode` object contains limit of same underlying volume type or CSI migration has been enabled for the volume, the old predicate will return early(with success) and `MaxCSIVolumeCountPred` will be responsible for counting both CSI and in-tree volumes of same type.\r\n\r\n\r\nBut what this check does is - it only defers to CSI predicate when migration is enabled *AND* `CSINode` object has volume limits for migrated driver. I think originally we wanted to ensure that, volume limits for both in-tree and CSI driver is counted correctly even if both are in-use on a node. ",
        "createdAt" : "2019-05-31T14:55:08Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "5dcc715a-988f-440c-b096-93b62c7e925b",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "I missed that, and it should be easy to fix but this also implies that the old predicates will defer to the CSI predicate if `CSINode` contains volume limits, even if the migration is disabled.\r\n\r\nIt means that the limits of an in-tree volume will change if someone installs a CSI driver (that happens to be the \"migration counterpart\" of the given in-tree volume).",
        "createdAt" : "2019-06-03T09:27:03Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      },
      {
        "id" : "d1f6de9f-f8bd-45af-8af6-7901c79ae7b3",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "I still don't like moving limits between CSINode and Node back and forth as a driver is installed, I think that the KEP is wrong in this part. See @msau42's comment at https://github.com/kubernetes/enhancements/pull/942#discussion_r277060459, IMO her comment and the code in this PR it is the right thing to do.\r\n\r\nShall we fix the KEP?",
        "createdAt" : "2019-06-03T09:31:17Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "3e0485ed-c0e1-4e54-bfba-44eb19cd2a66",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "I think implementation and debugging will be cleaner if they're kept separate.  It means that we need to encourage turning migration on and/or using only in-tree or only csi.",
        "createdAt" : "2019-06-03T13:59:32Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "79b6addd-2e64-42d0-8ead-642cd71ceb2e",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "The reason for doing what we did was - to ensure that we count volumes correctly even if user is using CSI and in-tree volumes simultaneously in the cluster without explicitly enabling in-tree migration. Like imagine a user is using 20 in-tree EBS PVs and 30 CSI EBS PVs on a node, in which case if we kept volume counting to different predicates then we will not have accurate count. It was one of the goals.\r\n\r\nHaving said that - we can perhaps relax that requirement for now because I am not sure if mixed volumes use without explicitly enabling in-tree migration should be \"supported\" or not.",
        "createdAt" : "2019-06-03T14:05:12Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "899e628e-2dbb-4809-8a72-7847913fab23",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "The current (old) csi predicate already doesn't handle this case. I think we can consider supporting this use case if needed in the future, but I would prefer to keep the logic as simple as possible for now. It's already quite complex with all the cases that we need to handle.\r\n\r\nThis is only a temporary state while migration is not on yet.",
        "createdAt" : "2019-06-03T20:15:47Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "887d04eb-bc0b-49f8-8803-d436d7811bed",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "Yeah I am fine with dropping this requirement from KEP. ",
        "createdAt" : "2019-06-03T20:29:34Z",
        "updatedAt" : "2019-06-25T14:31:23Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "08d81ce7-2ea7-4d1b-b382-9c9f663e22ab",
        "parentId" : "18913982-a1f3-4511-aaa7-98598e105d51",
        "authorId" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "body" : "Updated, PTAL.",
        "createdAt" : "2019-06-04T12:55:03Z",
        "updatedAt" : "2019-06-25T14:31:24Z",
        "lastEditedBy" : "255dd885-bee4-4c1f-baef-ba11f903dc5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6abc04d059b42ffdc1b68f5b847f18e57ac0680d",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +613,617 @@\t},\n\n\tIsMigrated: func(csiNode *storagev1beta1.CSINode) bool {\n\t\treturn isCSIMigrationOn(csiNode, csilibplugins.CinderInTreePluginName)\n\t},"
  },
  {
    "id" : "9391fb77-32e9-4459-897c-52aeac72805c",
    "prId" : 74544,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74544#pullrequestreview-211329859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92523cd5-3e71-475e-9a97-3148cba999e8",
        "parentId" : null,
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "Where is the in-tree translation layer to CSI going to live?  Directly in the CSI predicate? cc @davidz627 ",
        "createdAt" : "2019-02-25T23:10:31Z",
        "updatedAt" : "2019-02-25T23:10:31Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      },
      {
        "id" : "2989c6f9-21e7-4352-a6cf-cd8b7c0e8c4c",
        "parentId" : "92523cd5-3e71-475e-9a97-3148cba999e8",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "I am thinking translation layer is going to live in attach_limit.go util file which is shared between volume plugins and scheduler. But as we discussed I am working on a proposal for using `CSINodeInfo` for storing attach limits and this detail will be more flexed out in that KEP - https://github.com/kubernetes/enhancements/pull/730 ",
        "createdAt" : "2019-02-26T17:19:10Z",
        "updatedAt" : "2019-02-26T17:19:10Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "f22834e3-c09a-4f72-8f36-373947d6e061",
        "parentId" : "92523cd5-3e71-475e-9a97-3148cba999e8",
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "nit: I think adding a comment mentioning enhancements KEP PR within code as a comment might be helpful?",
        "createdAt" : "2019-03-06T16:21:20Z",
        "updatedAt" : "2019-03-06T16:21:21Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c537b46939beed3713356f71449a8ad6829b725",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +80,84 @@\tCheckServiceAffinityPred = \"CheckServiceAffinity\"\n\t// MaxEBSVolumeCountPred defines the name of predicate MaxEBSVolumeCount.\n\t// DEPRECATED\n\t// All cloudprovider specific predicates are deprecated in favour of MaxCSIVolumeCountPred.\n\tMaxEBSVolumeCountPred = \"MaxEBSVolumeCount\""
  },
  {
    "id" : "eb336022-d0fa-47ca-b145-0fb2f7520a32",
    "prId" : 74544,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74544#pullrequestreview-211507562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "208d8787-be2a-4558-8c06-a48e8cf258ac",
        "parentId" : null,
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "Any timeline set to move these out of the scheduler ?",
        "createdAt" : "2019-03-06T22:22:12Z",
        "updatedAt" : "2019-03-06T22:22:20Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c537b46939beed3713356f71449a8ad6829b725",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +84,88 @@\tMaxEBSVolumeCountPred = \"MaxEBSVolumeCount\"\n\t// MaxGCEPDVolumeCountPred defines the name of predicate MaxGCEPDVolumeCount.\n\t// DEPRECATED\n\t// All cloudprovider specific predicates are deprecated in favour of MaxCSIVolumeCountPred.\n\tMaxGCEPDVolumeCountPred = \"MaxGCEPDVolumeCount\""
  },
  {
    "id" : "859d8ab2-00e8-43fb-91e1-b0dc54100777",
    "prId" : 74544,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74544#pullrequestreview-211807811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a141fe0-1bfa-4d6d-a1ea-08d1a56c7098",
        "parentId" : null,
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Please point out what the replacement is in the comment. Without a clear replacement, deprecating an existing feature causes confusion.",
        "createdAt" : "2019-03-06T23:04:27Z",
        "updatedAt" : "2019-03-06T23:05:03Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "78e9b7e0-fc47-4038-88f7-20f38253d507",
        "parentId" : "6a141fe0-1bfa-4d6d-a1ea-08d1a56c7098",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "But it is mentioned right there!\r\n\r\n> // DEPRECATED\r\n\t// All cloudprovider specific predicates are deprecated in favour of MaxCSIVolumeCountPred.\r\n\r\n`MaxCSIVolumeCountPred` will support all these in-tree volume types via migration path we discussed. I am working on updating the Volume limit KEP as per what we discussed - https://github.com/kubernetes/enhancements/pull/730 . \r\n",
        "createdAt" : "2019-03-07T14:21:12Z",
        "updatedAt" : "2019-03-07T14:21:13Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "e74edd96-4f89-4cc4-aaba-45a2a577eb4e",
        "parentId" : "6a141fe0-1bfa-4d6d-a1ea-08d1a56c7098",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "`MaxCSIVolumeCountPred` will support these in-tree volume types even if you are not using CSI. ",
        "createdAt" : "2019-03-07T14:22:13Z",
        "updatedAt" : "2019-03-07T14:22:13Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c537b46939beed3713356f71449a8ad6829b725",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +80,84 @@\tCheckServiceAffinityPred = \"CheckServiceAffinity\"\n\t// MaxEBSVolumeCountPred defines the name of predicate MaxEBSVolumeCount.\n\t// DEPRECATED\n\t// All cloudprovider specific predicates are deprecated in favour of MaxCSIVolumeCountPred.\n\tMaxEBSVolumeCountPred = \"MaxEBSVolumeCount\""
  },
  {
    "id" : "3dc613c6-fb7d-45cd-a884-390aa55e32c9",
    "prId" : 73652,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/73652#pullrequestreview-199368224",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c20c6ff4-9321-435d-96e0-010e04b9045e",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "I think adding a log statement with level 5 or above would here would help in debugging.",
        "createdAt" : "2019-02-03T01:02:05Z",
        "updatedAt" : "2019-02-03T01:08:12Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      }
    ],
    "commit" : "a20a2433802759fb9ac844576bd9d601e8b06051",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1654,1658 @@func (c *VolumeBindingChecker) predicate(pod *v1.Pod, meta PredicateMetadata, nodeInfo *schedulernodeinfo.NodeInfo) (bool, []PredicateFailureReason, error) {\n\t// If pod does not request any PVC, we don't need to do anything.\n\tif !podHasPVCs(pod) {\n\t\treturn true, nil, nil\n\t}"
  },
  {
    "id" : "064bf841-2a94-4893-b136-b6f97f85cd12",
    "prId" : 72980,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72980#pullrequestreview-193306224",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "767939fd-3853-4f94-a673-d42c93819f2b",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "Unrelated: Why do we have `DefaultMaxCinderVolumes` coming from volumeutil, whereas rest(like DefaultMaxAzureDiskVolumes etc) are coming from the current file",
        "createdAt" : "2019-01-16T19:04:41Z",
        "updatedAt" : "2019-01-16T20:17:34Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      },
      {
        "id" : "532e3729-dad3-4a26-a3a8-1e46ff520b33",
        "parentId" : "767939fd-3853-4f94-a673-d42c93819f2b",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "I think it is an oversight. All of these defaults should come from volumeutil. I will move them over. ",
        "createdAt" : "2019-01-16T19:06:26Z",
        "updatedAt" : "2019-01-16T20:17:34Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "d785f64d-4ca4-44ad-bbc6-d9d856fd6b84",
        "parentId" : "767939fd-3853-4f94-a673-d42c93819f2b",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "Or more specifically - `volumeutil.attach_limit.go` was introduced as common lib file that could be shared between plugin and scheduler. Most plugins use this file to derive keys and default limits. But scheduler already had those constants and they weren't removed and replaced when this new file was created. ",
        "createdAt" : "2019-01-16T19:08:10Z",
        "updatedAt" : "2019-01-16T20:17:34Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "4a067a91-7ddb-45f6-af45-40c4dc26ecd0",
        "parentId" : "767939fd-3853-4f94-a673-d42c93819f2b",
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "ok.",
        "createdAt" : "2019-01-16T19:15:03Z",
        "updatedAt" : "2019-01-16T20:17:34Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      }
    ],
    "commit" : "727b3097f9651d465f94232d0ba3355f24698b55",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +379,383 @@\t\t\treturn DefaultMaxAzureDiskVolumes\n\t\tcase CinderVolumeFilterType:\n\t\t\treturn volumeutil.DefaultMaxCinderVolumes\n\t\tdefault:\n\t\t\treturn -1"
  },
  {
    "id" : "c542a3ed-0bf5-421f-8255-85967392cb17",
    "prId" : 72980,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/72980#pullrequestreview-193304263",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17130982-f451-44c1-9c77-89ec886a3483",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "Please add some comments on when you want to remove this cloud provider specific code and rely on CSI plugin.",
        "createdAt" : "2019-01-16T19:10:23Z",
        "updatedAt" : "2019-01-16T20:17:34Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      }
    ],
    "commit" : "727b3097f9651d465f94232d0ba3355f24698b55",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +568,572 @@}\n\n// CinderVolumeFilter is a VolumeFilter for filtering Cinder Volumes\n// It will be deprecated once Openstack cloudprovider has been removed from in-tree.\nvar CinderVolumeFilter = VolumeFilter{"
  },
  {
    "id" : "77bbc3eb-463a-43ca-98d4-513809e4f5d3",
    "prId" : 62591,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/62591#pullrequestreview-112678392",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a2f9300-94b6-4dcf-81b6-ca68cb1538f4",
        "parentId" : null,
        "authorId" : "3c1422a0-6358-4857-8f56-961979171514",
        "body" : "Ditto.",
        "createdAt" : "2018-04-16T03:11:34Z",
        "updatedAt" : "2018-04-16T23:09:36Z",
        "lastEditedBy" : "3c1422a0-6358-4857-8f56-961979171514",
        "tags" : [
        ]
      },
      {
        "id" : "11bbe1bc-3f0b-4123-8649-f65d27dfde1e",
        "parentId" : "3a2f9300-94b6-4dcf-81b6-ca68cb1538f4",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "What is this \"ditto\" for?",
        "createdAt" : "2018-04-16T23:08:34Z",
        "updatedAt" : "2018-04-16T23:10:04Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "de879c39-f9f7-4d27-b1b9-ba4aba9a5dc1",
        "parentId" : "3a2f9300-94b6-4dcf-81b6-ca68cb1538f4",
        "authorId" : "33ab9fbe-6f55-45c0-a58d-be01aec201d9",
        "body" : "His meaning may be that the log information is exactly the same as above.",
        "createdAt" : "2018-04-17T06:24:06Z",
        "updatedAt" : "2018-04-17T06:24:07Z",
        "lastEditedBy" : "33ab9fbe-6f55-45c0-a58d-be01aec201d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f2155ae22255af122b0235b97309f223cce2418",
    "line" : 144,
    "diffHunk" : "@@ -1,1 +1502,1506 @@\t\t\t// Check if pod matches its own affinity properties (namespace and label selector).\n\t\t\tif !targetPodMatchesAffinityOfPod(pod, pod) {\n\t\t\t\tglog.V(10).Infof(\"Cannot schedule pod %+v onto node %v, because of PodAffinity\",\n\t\t\t\t\tpodName(pod), node.Name)\n\t\t\t\treturn ErrPodAffinityRulesNotMatch, nil"
  },
  {
    "id" : "545454a6-8c43-45a8-8288-9c141269b824",
    "prId" : 60386,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60386#pullrequestreview-99972037",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7b8811c-a441-4437-ab93-13387747b727",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "nit: Shouldn't the function be CheckNodeSchedulable instead as we return true if it is schedulable? Also, do you want to add a e2e test?",
        "createdAt" : "2018-02-25T19:45:10Z",
        "updatedAt" : "2018-02-28T08:11:11Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      },
      {
        "id" : "d6244034-f44a-46e0-ad94-6679bb0a4ce3",
        "parentId" : "c7b8811c-a441-4437-ab93-13387747b727",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "prefer to current name, as `Unschedulable` is a spec of node; and add e2e case when TaintNodesByCondition to beta :)",
        "createdAt" : "2018-02-28T08:15:18Z",
        "updatedAt" : "2018-02-28T08:15:19Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      }
    ],
    "commit" : "f94b7eda83510b70f9fd3d895fe6fbf321f6ac81",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1436,1440 @@\n// CheckNodeUnschedulablePredicate checks if a pod can be scheduled on a node with Unschedulable spec.\nfunc CheckNodeUnschedulablePredicate(pod *v1.Pod, meta algorithm.PredicateMetadata, nodeInfo *schedulercache.NodeInfo) (bool, []algorithm.PredicateFailureReason, error) {\n\tif nodeInfo == nil || nodeInfo.Node() == nil {\n\t\treturn false, []algorithm.PredicateFailureReason{ErrNodeUnknownCondition}, nil"
  },
  {
    "id" : "e4a11b7f-910b-49a8-b04d-7c409a76d906",
    "prId" : 60007,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60007#pullrequestreview-99170929",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35e676ed-234e-4f22-b61f-ec47c72f6640",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "Would it better to have a featuregating checked here? Something like `utilfeature.DefaultFeatureGate.Enabled(features.TaintNodesByCondition)`",
        "createdAt" : "2018-02-25T19:57:30Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      },
      {
        "id" : "889553f5-e95e-4235-a26b-d089b36c7487",
        "parentId" : "35e676ed-234e-4f22-b61f-ec47c72f6640",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "Good point :) , we need to remove/disable this predicate if TaintNodesByCondition enabled.\r\n\r\nxref https://github.com/kubernetes/kubernetes/pull/60398",
        "createdAt" : "2018-02-26T02:12:34Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "7e36d636-8392-488c-838e-d90edb303839",
        "parentId" : "35e676ed-234e-4f22-b61f-ec47c72f6640",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "Done",
        "createdAt" : "2018-02-26T02:16:13Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c10d15ae5366b3bc7596032b0baeea1ecd521b5",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1597,1601 @@// reporting pid pressure condition.\nfunc CheckNodePIDPressurePredicate(pod *v1.Pod, meta algorithm.PredicateMetadata, nodeInfo *schedulercache.NodeInfo) (bool, []algorithm.PredicateFailureReason, error) {\n\t// check if node is under pid pressure\n\tif nodeInfo.PIDPressureCondition() == v1.ConditionTrue {\n\t\treturn false, []algorithm.PredicateFailureReason{ErrNodeUnderPIDPressure}, nil"
  },
  {
    "id" : "43e65ede-5966-462d-9293-d31da95b0eb8",
    "prId" : 60007,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60007#pullrequestreview-100998456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "386bda38-8d77-4026-98af-330516c08a7c",
        "parentId" : null,
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Why didn't you add this check to `CheckNodeConditionPredicate` instead of this function?",
        "createdAt" : "2018-03-02T02:31:25Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "7c48b70c-0815-4c40-8987-17a5969f4d27",
        "parentId" : "386bda38-8d77-4026-98af-330516c08a7c",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "make sense :)",
        "createdAt" : "2018-03-02T04:51:50Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "659569f7-6ce0-4194-b8f1-cc19e31cacae",
        "parentId" : "386bda38-8d77-4026-98af-330516c08a7c",
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "agree with @bsalamat, we might want to check it there as it is nodeCondition.\r\n\r\nAlso to me, we might want to use taint instead, and let the toleration mechanism do the work, WDYT @k82cn ? ",
        "createdAt" : "2018-03-02T17:14:40Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      },
      {
        "id" : "98f6dd5d-9196-43d6-a787-8d0140917c90",
        "parentId" : "386bda38-8d77-4026-98af-330516c08a7c",
        "authorId" : "8f672b1e-0513-4363-b383-ad8d8de0cdb9",
        "body" : "@bsalamat  `CheckNodeMemoryPressurePred, CheckNodeDiskPressurePred` is also node condition, why we seprate these to two predicates?",
        "createdAt" : "2018-03-03T12:31:46Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "8f672b1e-0513-4363-b383-ad8d8de0cdb9",
        "tags" : [
        ]
      },
      {
        "id" : "61e47c82-91f2-4a68-9bdc-fd1aecc3b365",
        "parentId" : "386bda38-8d77-4026-98af-330516c08a7c",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "@wanghaoran1988 @k82cn I see a benefit to having separate predicates. Users can enable or disable individual predicates in scheduler policy config. So, a user can disable `CheckNodeMemoryPressurePred` and/or `CheckNodeDiskPressurePred` in their policy config while keeping `CheckNodeConditionPredicate` enabled. For the same reason it may make sense to keep `CheckNodePIDPressurePredicate` as a separate predicate as well.",
        "createdAt" : "2018-03-03T18:00:24Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "d2e7369e-28f7-4e9d-86ad-c03d6933ae52",
        "parentId" : "386bda38-8d77-4026-98af-330516c08a7c",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "yes. separate predicates give user more options :).\r\n\r\n> Also to me, we might want to use taint instead, and let the toleration mechanism do the work, \r\n\r\nHandled by https://github.com/kubernetes/kubernetes/pull/60008 .",
        "createdAt" : "2018-03-04T08:27:19Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c10d15ae5366b3bc7596032b0baeea1ecd521b5",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1596,1600 @@// CheckNodePIDPressurePredicate checks if a pod can be scheduled on a node\n// reporting pid pressure condition.\nfunc CheckNodePIDPressurePredicate(pod *v1.Pod, meta algorithm.PredicateMetadata, nodeInfo *schedulercache.NodeInfo) (bool, []algorithm.PredicateFailureReason, error) {\n\t// check if node is under pid pressure\n\tif nodeInfo.PIDPressureCondition() == v1.ConditionTrue {"
  },
  {
    "id" : "238933f7-93ff-4b15-88bb-4c685e19782f",
    "prId" : 60007,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60007#pullrequestreview-104904549",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8a908b6-6952-499d-b427-388293e5aa75",
        "parentId" : null,
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "If we keep this as a predicate, we might want to add it to the predicatesOrdering list, see [predicates.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/algorithm/predicates/predicates.go#L130)",
        "createdAt" : "2018-03-02T17:11:44Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      },
      {
        "id" : "1a810cc1-9a2b-421c-b83b-533a6a19edc7",
        "parentId" : "f8a908b6-6952-499d-b427-388293e5aa75",
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "cc @bsalamat @resouer ",
        "createdAt" : "2018-03-04T10:40:30Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      },
      {
        "id" : "420de0c3-054a-4112-9088-4a9a259c189c",
        "parentId" : "f8a908b6-6952-499d-b427-388293e5aa75",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "ok",
        "createdAt" : "2018-03-04T23:45:58Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "839310d4-aded-4f32-9845-a7cd08cc92ba",
        "parentId" : "f8a908b6-6952-499d-b427-388293e5aa75",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "done",
        "createdAt" : "2018-03-19T10:26:53Z",
        "updatedAt" : "2018-04-26T02:10:11Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c10d15ae5366b3bc7596032b0baeea1ecd521b5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +90,94 @@\tCheckNodeDiskPressurePred = \"CheckNodeDiskPressure\"\n\t// CheckNodePIDPressurePred defines the name of predicate CheckNodePIDPressure.\n\tCheckNodePIDPressurePred = \"CheckNodePIDPressure\"\n\n\t// DefaultMaxEBSVolumes is the limit for volumes attached to an instance."
  },
  {
    "id" : "047694f6-b888-4731-b37b-097376b922cc",
    "prId" : 59952,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59952#pullrequestreview-98735487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c2789cb-5e08-4910-adbc-fea8e2906ae9",
        "parentId" : null,
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "will that introduce backward compatibility?",
        "createdAt" : "2018-02-16T00:52:15Z",
        "updatedAt" : "2018-02-16T00:52:15Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "bbfaee2d-123b-4017-85e0-64d6926de057",
        "parentId" : "0c2789cb-5e08-4910-adbc-fea8e2906ae9",
        "authorId" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "body" : "Should be fine. According to: https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/factory/plugins.go#L207-L218\r\nThe name of this predicate is not part of scheduler policy configure file.",
        "createdAt" : "2018-02-16T05:12:39Z",
        "updatedAt" : "2018-02-16T05:12:39Z",
        "lastEditedBy" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "tags" : [
        ]
      },
      {
        "id" : "c09fc11d-3b21-43f7-ad35-129a0797d048",
        "parentId" : "0c2789cb-5e08-4910-adbc-fea8e2906ae9",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "But there could be existing policy config files that are already using the old name. ",
        "createdAt" : "2018-02-17T01:57:44Z",
        "updatedAt" : "2018-02-17T01:57:44Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      },
      {
        "id" : "1a1156c9-e8bb-4480-97a1-8f95f6db41c8",
        "parentId" : "0c2789cb-5e08-4910-adbc-fea8e2906ae9",
        "authorId" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "body" : "@bsalamat @k82cn AFAIK, the right way of using `serviceAffinity` in policy file is like below:\r\n```\r\n    \"apiVersion\": \"v1\",\r\n    \"kind\": \"Policy\",\r\n    \"predicates\": [\r\n        {\r\n            \"name\": \"NoVolumeZoneConflict\"\r\n        },\r\n        {\r\n            \"name\": \"MaxEBSVolumeCount\"\r\n        },\r\n        {\r\n            \"name\": \"MaxGCEPDVolumeCount\"\r\n        },\r\n        {\r\n            \"name\": \"MatchInterPodAffinity\"\r\n        },\r\n        {\r\n            \"name\": \"NoDiskConflict\"\r\n        },\r\n        {\r\n            \"name\": \"GeneralPredicates\"\r\n        },\r\n        {\r\n            \"name\": \"PodToleratesNodeTaints\"\r\n        },\r\n        {\r\n            \"name\": \"CheckNodeMemoryPressure\"\r\n        },\r\n        {\r\n            \"name\": \"CheckNodeDiskPressure\"\r\n        },\r\n        {\r\n            \"argument\": {\r\n                \"serviceAffinity\": {\r\n                    \"labels\": [\r\n                        \"region\"\r\n                    ]\r\n                }\r\n            },\r\n            \"name\": \"Region\"\r\n        }\r\n    ],\r\n```\r\n\r\nThat's why I claim \r\n> The name of this predicate is not part of scheduler policy configure file\r\n\r\nSince `serviceAffinity` is a `argument` which is not touched by this PR.\r\n\r\nCorrect me if I misunderstood sth :)",
        "createdAt" : "2018-02-22T20:02:00Z",
        "updatedAt" : "2018-02-22T20:02:00Z",
        "lastEditedBy" : "7dd504ec-7e63-45b3-98f8-6eb1c683e9c2",
        "tags" : [
        ]
      },
      {
        "id" : "17906396-e3fe-432b-b26e-3d951af76922",
        "parentId" : "0c2789cb-5e08-4910-adbc-fea8e2906ae9",
        "authorId" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "body" : "Ah, I see. Thanks for clarification.",
        "createdAt" : "2018-02-22T21:31:30Z",
        "updatedAt" : "2018-02-22T21:31:30Z",
        "lastEditedBy" : "15fb535e-c5be-47ce-a304-1cb5da5aca90",
        "tags" : [
        ]
      }
    ],
    "commit" : "136e5398ed56f8ec34202d803f22a9bbe80c5e4d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +74,78 @@\tCheckNodeLabelPresencePred = \"CheckNodeLabelPresence\"\n\t// CheckServiceAffinityPred defines the name of predicate checkServiceAffinity.\n\tCheckServiceAffinityPred = \"CheckServiceAffinity\"\n\t// MaxEBSVolumeCountPred defines the name of predicate MaxEBSVolumeCount.\n\tMaxEBSVolumeCountPred = \"MaxEBSVolumeCount\""
  },
  {
    "id" : "0caca81c-8010-42b9-aaf5-5a87ae919fcc",
    "prId" : 58689,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/58689#pullrequestreview-90862521",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06d5a1a4-88ec-4771-8f0e-6de94f2274aa",
        "parentId" : null,
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "maybe use `node := nodeInfo.Node()` ?",
        "createdAt" : "2018-01-23T13:08:34Z",
        "updatedAt" : "2018-01-23T13:09:05Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      },
      {
        "id" : "01b83db3-6fc0-46e7-8dd1-2a90e539e740",
        "parentId" : "06d5a1a4-88ec-4771-8f0e-6de94f2274aa",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "seems duplicated, nodeInfo.Node() is used only once :).",
        "createdAt" : "2018-01-23T13:21:12Z",
        "updatedAt" : "2018-01-23T13:21:12Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "c41793e4-ac5a-456d-bb6c-10260703fc9f",
        "parentId" : "06d5a1a4-88ec-4771-8f0e-6de94f2274aa",
        "authorId" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "body" : "it is used to check if it is nil, but it is just a nit, we can leave it as is.",
        "createdAt" : "2018-01-23T15:24:17Z",
        "updatedAt" : "2018-01-23T15:24:17Z",
        "lastEditedBy" : "e2ca6907-6765-444e-8bf6-1452233150d6",
        "tags" : [
        ]
      }
    ],
    "commit" : "430ebffe2b1dbad4347874933f6122fcbe24b3fd",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1400,1404 @@\t}\n\n\tif nodeInfo.Node().Spec.Unschedulable {\n\t\treturn false, []algorithm.PredicateFailureReason{ErrNodeUnschedulable}, nil\n\t}"
  },
  {
    "id" : "f1eaeba9-38fd-4b95-90d2-3d057c70ad89",
    "prId" : 58689,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/58689#pullrequestreview-98488953",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46e63e4a-b5d5-4a58-a62c-fcbbde868b9a",
        "parentId" : null,
        "authorId" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "body" : "This function, as its name suggests, should only check if the pod tolerates node taints. Because this is also used by DaemonSet controller, it causes non-backward compatible changes to DaemonSet, see #60163.",
        "createdAt" : "2018-02-21T23:33:21Z",
        "updatedAt" : "2018-02-21T23:33:22Z",
        "lastEditedBy" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "tags" : [
        ]
      },
      {
        "id" : "cc68bc41-7667-403e-a121-6ad9c6d99a11",
        "parentId" : "46e63e4a-b5d5-4a58-a62c-fcbbde868b9a",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "+1, let me handle it :)",
        "createdAt" : "2018-02-22T02:51:07Z",
        "updatedAt" : "2018-02-22T02:51:07Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "ba477fb2-5067-46df-8ba5-554b482056de",
        "parentId" : "46e63e4a-b5d5-4a58-a62c-fcbbde868b9a",
        "authorId" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "body" : "Thanks @k82cn!",
        "createdAt" : "2018-02-22T09:08:17Z",
        "updatedAt" : "2018-02-22T09:08:17Z",
        "lastEditedBy" : "01c14569-b640-48af-98cc-aa9dd12da7b6",
        "tags" : [
        ]
      }
    ],
    "commit" : "430ebffe2b1dbad4347874933f6122fcbe24b3fd",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1400,1404 @@\t}\n\n\tif nodeInfo.Node().Spec.Unschedulable {\n\t\treturn false, []algorithm.PredicateFailureReason{ErrNodeUnschedulable}, nil\n\t}"
  }
]