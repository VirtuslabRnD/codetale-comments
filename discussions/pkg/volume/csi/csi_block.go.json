[
  {
    "id" : "def35300-d6b1-4acb-85e7-b7c7586b361c",
    "prId" : 87978,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87978#pullrequestreview-359082995",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4733f366-84cc-4a31-9b88-72d69588757c",
        "parentId" : null,
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "Do we need to introduce uncertain device tracking for block volume calls? We can do this in a follow up but we should track that work somewhere?",
        "createdAt" : "2020-02-11T15:16:50Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "9348e5c6-1c7d-4592-b43c-3ee352de583a",
        "parentId" : "4733f366-84cc-4a31-9b88-72d69588757c",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "Yes, we should. Filled https://github.com/kubernetes/kubernetes/issues/88086",
        "createdAt" : "2020-02-12T18:09:48Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "ad5c1526-5ec8-4d8d-a668-40453e9b89d3",
        "parentId" : "4733f366-84cc-4a31-9b88-72d69588757c",
        "authorId" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "body" : "Wait is that correct? That is another PR..",
        "createdAt" : "2020-02-13T18:50:30Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "d3e684d7-edd2-4290-a8bf-e8b698c97338",
        "tags" : [
        ]
      },
      {
        "id" : "d6c6f0e3-3362-4c80-a117-10e34cec1e64",
        "parentId" : "4733f366-84cc-4a31-9b88-72d69588757c",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "sorry, I fixed my previous comment with the right link",
        "createdAt" : "2020-02-14T16:56:16Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      }
    ],
    "commit" : "073d0b234076b91b83f97085656c8b614955a04f",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +307,311 @@\t_, err = m.stageVolumeForBlock(ctx, csiClient, accessMode, csiSource, attachment)\n\tif err != nil {\n\t\tif volumetypes.IsOperationFinishedError(err) {\n\t\t\tcleanupErr := m.cleanupOrphanDeviceFiles()\n\t\t\tif cleanupErr != nil {"
  },
  {
    "id" : "2f73b777-bcb0-49e5-a670-33a89b94b45c",
    "prId" : 87978,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87978#pullrequestreview-356840091",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a186082-f590-49ee-92b4-dd3ee6ea81f6",
        "parentId" : null,
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "This is right. I seemed to forget to write down the existence of \"data/vol_data.json\" under xxx/plugins/kubernetes.io/csi/volumeDevices/<volume name> in L56 comments. \r\n\r\nShould we add a comment on the file, there?\r\nThen, I think that everyone will be able to check that all paths are cleaned up properly, just by comparing the comments and this cleanup function.",
        "createdAt" : "2020-02-11T17:16:44Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "073d0b234076b91b83f97085656c8b614955a04f",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +479,483 @@\n\t// Remove everything under xxx/plugins/kubernetes.io/csi/volumeDevices/<volume name>.\n\t// At this point it contains only \"data/vol_data.json\" and empty \"dev/\".\n\tvolumeDir := getVolumePluginDir(m.specName, m.plugin.host)\n\tmounter := m.plugin.host.GetMounter(m.plugin.GetPluginName())"
  },
  {
    "id" : "957d2873-7c54-4eb2-a6e8-65729d1902ba",
    "prId" : 87978,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87978#pullrequestreview-356921219",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8915b32-06ab-4eb8-99cf-11fc9c47ebfa",
        "parentId" : null,
        "authorId" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "body" : "suggest using `: %v` for errors instead of `%s`",
        "createdAt" : "2020-02-11T19:12:25Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "tags" : [
        ]
      }
    ],
    "commit" : "073d0b234076b91b83f97085656c8b614955a04f",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +311,315 @@\t\t\tif cleanupErr != nil {\n\t\t\t\t// V(4) for not so serious error\n\t\t\t\tklog.V(4).Infof(\"Failed to clean up block volume directory %s\", cleanupErr)\n\t\t\t}\n\t\t}"
  },
  {
    "id" : "756e7fef-af37-443e-9367-fb218c18bd94",
    "prId" : 87978,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87978#pullrequestreview-357676968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ecc20ef-8ac2-4291-8ee6-3a68341ce411",
        "parentId" : null,
        "authorId" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "body" : "Any reason we used `os.Remove` and not `os.RemoveAll`? Are we comfortable assuming that all files inside the directory were deleted by a different function?",
        "createdAt" : "2020-02-11T19:37:02Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "tags" : [
        ]
      },
      {
        "id" : "5389774d-1a69-4791-baf6-f7607bc93d3a",
        "parentId" : "8ecc20ef-8ac2-4291-8ee6-3a68341ce411",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "`Remove` is on the safe side. With our usage of bind mounts I don't want to accidentally remove stuff that was bind-mounted to a wrong place.",
        "createdAt" : "2020-02-12T18:15:19Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      }
    ],
    "commit" : "073d0b234076b91b83f97085656c8b614955a04f",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +467,471 @@\t// already unpublished at this point, the directory should be empty by now.\n\tpublishDir := m.getPublishDir()\n\tif err := os.Remove(publishDir); err != nil && !os.IsNotExist(err) {\n\t\treturn errors.New(log(\"failed to remove publish directory [%s]: %v\", publishDir, err))\n\t}"
  },
  {
    "id" : "62ce8d2f-df76-4a00-bf8b-b6ec311872a4",
    "prId" : 87978,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87978#pullrequestreview-360563185",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5345fd98-9278-41a1-9b37-18a6c50dff66",
        "parentId" : null,
        "authorId" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "body" : "Seems like a good use case for `os.RemoveAll` unless we want to be very explicit about what gets deleted.",
        "createdAt" : "2020-02-11T19:40:56Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "tags" : [
        ]
      },
      {
        "id" : "5bcfde58-8bc5-4280-af66-788e7ea7f524",
        "parentId" : "5345fd98-9278-41a1-9b37-18a6c50dff66",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "RemoveAll would remove also stuff that should be removed by GenerateUnmapVolumeFunc and we would not see this bug.\r\n",
        "createdAt" : "2020-02-13T10:04:33Z",
        "updatedAt" : "2020-02-17T09:52:41Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "a7d394a6-a4d1-401a-967f-e74f4b229c15",
        "parentId" : "5345fd98-9278-41a1-9b37-18a6c50dff66",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "Ok, I added `RemoveAll()` there, this directory contains only \"global\" bind-mount and metadata json. It is not used in stage/publish/unpublish/unstage loop, where blind RemoveAll could hide hard to track unpublish / unstage errors.",
        "createdAt" : "2020-02-17T10:01:46Z",
        "updatedAt" : "2020-02-17T10:01:46Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "36be0e73-397b-4126-96a0-2dfac8a17876",
        "parentId" : "5345fd98-9278-41a1-9b37-18a6c50dff66",
        "authorId" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "body" : "Thanks, I didn't realize the subtle implications with reference to bind mount and GenerateUnmapVolumeFunc.",
        "createdAt" : "2020-02-18T18:15:40Z",
        "updatedAt" : "2020-02-18T18:15:42Z",
        "lastEditedBy" : "5f2c1de8-4266-42c0-b343-ba247af3578f",
        "tags" : [
        ]
      }
    ],
    "commit" : "073d0b234076b91b83f97085656c8b614955a04f",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +478,482 @@\t}\n\n\t// Remove everything under xxx/plugins/kubernetes.io/csi/volumeDevices/<volume name>.\n\t// At this point it contains only \"data/vol_data.json\" and empty \"dev/\".\n\tvolumeDir := getVolumePluginDir(m.specName, m.plugin.host)"
  },
  {
    "id" : "dca4527f-bc27-4b59-ae97-3dd21c9b63ac",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-295746915",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53814956-966b-4d0f-8f6a-dd48fb98647e",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "Do we care about other elements in AccessModes (len(m.spec.PersistentVolume.Spec.AccessModes) > 1) ?",
        "createdAt" : "2019-09-13T15:49:22Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      },
      {
        "id" : "49f5664e-d5e8-46d4-8608-3543c5255ec1",
        "parentId" : "53814956-966b-4d0f-8f6a-dd48fb98647e",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "I agree that this should be imporved. \r\n\r\nBut I think that this needs to be updated for both filesystem and block, in the same way.\r\n(https://github.com/kubernetes/kubernetes/blob/master/pkg/volume/csi/csi_mounter.go#L176)\r\n\r\nSo, this would be outside the scope of this PR.\r\nLet's improve this in a separate PR.",
        "createdAt" : "2019-10-01T16:52:54Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 172,
    "diffHunk" : "@@ -1,1 +342,346 @@\taccessMode := v1.ReadWriteOnce\n\tif m.spec.PersistentVolume.Spec.AccessModes != nil {\n\t\taccessMode = m.spec.PersistentVolume.Spec.AccessModes[0]\n\t}\n"
  },
  {
    "id" : "d4ea31cd-e2b7-478c-8f81-d38fafec2b63",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-295746197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "846eb8c0-6c7e-4fda-ba97-5308d2a06a6a",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "It seems this can be lifted ahead of context.WithTimeout call (line 300).",
        "createdAt" : "2019-09-13T15:50:15Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      },
      {
        "id" : "12f3b1aa-d606-42e2-9d8d-dbb127db9377",
        "parentId" : "846eb8c0-6c7e-4fda-ba97-5308d2a06a6a",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "Thank you for your review and sorry for late response.\r\n\r\nI confirmted `SetUpAt` and `TearDownAt` is calling `csiClientGetter.Get` before calling `WithTimeout`.\r\nSo, fixed as suggested.",
        "createdAt" : "2019-10-01T16:51:41Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 178,
    "diffHunk" : "@@ -1,1 +348,352 @@\tdefer cancel()\n\n\tcsiClient, err := m.csiClientGetter.Get()\n\tif err != nil {\n\t\treturn \"\", errors.New(log(\"blockMapper.MapPodDevice failed to get CSI client: %v\", err))"
  },
  {
    "id" : "2caca4d1-ec3b-4299-8871-e8bcfe9d15cd",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-295746410",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d1a7e2f5-bede-48d1-b151-5d5e12a3f778",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "This can be lifted above line 429",
        "createdAt" : "2019-09-13T15:53:11Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      },
      {
        "id" : "e7fefa7f-cd26-4210-a909-16bf39c53fe2",
        "parentId" : "d1a7e2f5-bede-48d1-b151-5d5e12a3f778",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "Fixed.",
        "createdAt" : "2019-10-01T16:52:03Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 233,
    "diffHunk" : "@@ -1,1 +447,451 @@\tpublishPath := m.getPublishPath()\n\n\tcsiClient, err := m.csiClientGetter.Get()\n\tif err != nil {\n\t\treturn errors.New(log(\"blockMapper.UnmapPodDevice failed to get CSI client: %v\", err))"
  },
  {
    "id" : "a121d58b-20ef-44b1-9a2e-37e386f5c3d7",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-296546532",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29b53e44-52b8-49e6-8b9d-a1809cde9f06",
        "parentId" : null,
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "since we have changed publishPath and stagingPath, there might be a backwards-compatibility issue.\r\n\r\nPreviously, we created a symlink in the pod's volume directory to `plugins/kubernetes.io/csi/volumeDevices/publish/{pvname}`.\r\nNow, we create a symlink in the pod's volume directory to `plugins/kubernetes.io/csi/volumeDevices/publish/{volumeID}/{podUID}`.\r\n\r\nAfter an upgrade, we ask the plugin to unpublish `plugins/kubernetes.io/csi/volumeDevices/publish/{volumeID}/{podUID}` even if it, before the upgrade, published `plugins/kubernetes.io/csi/volumeDevices/publish/{pvname}`. So `plugins/kubernetes.io/csi/volumeDevices/publish/{pvname}` will be stuck in published state.\r\n\r\nWe may need to follow the symlink in the pod's volume directory to see if it links to the new path or the old path and call unpublish appropriately.",
        "createdAt" : "2019-10-02T20:58:52Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "71b9d47e-fa57-4cea-955e-f8150c6ba36f",
        "parentId" : "29b53e44-52b8-49e6-8b9d-a1809cde9f06",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "proper upgrade procedure you are supposed to drain the node first. So I'm not sure this is worth fixing.",
        "createdAt" : "2019-10-02T21:01:15Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "26dd8d7c-222e-4184-91a3-71f7070f2462",
        "parentId" : "29b53e44-52b8-49e6-8b9d-a1809cde9f06",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "Good investigation!\r\nThen, should we add a caution like below in release notes?\r\n\r\n```\r\nBefore this release, staging path and publish path for CSI block volume were as follows:\r\n- Staging path: plugins/kubernetes.io/csi/volumeDevices/staging/{pvname}\r\n- Publish path: plugins/kubernetes.io/csi/volumeDevices/publish/{pvname}\r\nIn this release these are changed as follows:\r\n- Staging path: plugins/kubernetes.io/csi/volumeDevices/staging/{volumeID}\r\n- Publish path: plugins/kubernetes.io/csi/volumeDevices/publish/{volumeID}/{podUID}\r\n\r\nAs a result, upgrading Kubernetes cluster while any pods with CSI block volumes running on a node will cause these path inconsistent, which will lead failure in unstaging/unpublishing volume. \r\nTherefore, all nodes need to be drained before upgrading Kubernetes cluster.\r\n```\r\n\r\nAny improvements in wording are welcome.",
        "createdAt" : "2019-10-02T21:36:19Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      },
      {
        "id" : "49c18a18-e201-48b6-a795-eb25bdfa162c",
        "parentId" : "29b53e44-52b8-49e6-8b9d-a1809cde9f06",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "Thanks, IMO it doesn't need to be too detailed about the specific paths, the last two sentences reminding people that nodes need to be drained else unpublish/unstage will fail should be enough.",
        "createdAt" : "2019-10-02T21:48:52Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 249,
    "diffHunk" : "@@ -1,1 +463,467 @@\t\t}\n\t} else {\n\t\terr := m.unpublishVolumeForBlock(ctx, csiClient, publishPath)\n\t\tif err != nil {\n\t\t\treturn err"
  },
  {
    "id" : "2d7e0d10-ab17-48e8-8df9-57da223b5887",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-299167738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "parentId" : null,
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "globalMapPath should be based on volumeID too, not pv name.",
        "createdAt" : "2019-10-07T18:07:30Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "cda7cfc0-1fda-4928-9d7a-943ba60db2fa",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@wongma7 \r\n\r\nI tried to fix both `getVolumeDevicePluginDir` and `getVolumeDeviceDataDir` to be based on `volumeID`. However, in `NewBlockVolumeUnmapper`, `volumeID` is gotten by calling `loadVolumeData` with specifying `unmapper.specName`, or volName. So, at least, `getVolumeDeviceDataDir` won't be able to be based on `volumeID`.\r\n\r\nShould we make only `getVolumeDevicePluginDir` based on `volumeID`, or keep the paths as they are?\r\nI think that pv name and volumeID is 1:1, so this change won't be a mandatory. Then, we would be easier to debug the volume if we keep device and volume data under the same directory.\r\n\r\nWDYT? \r\n",
        "createdAt" : "2019-10-07T20:28:58Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      },
      {
        "id" : "41a1324a-e16e-4314-a56c-e637ae0d7e4b",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "Why is pv name and volumeID 1:1? Can't PV name be anything? I assume that whoever wrote this code had a good reason to think pvname == volumeID but I am not so sure. I thought volumeID is supposed to be 1:1 with volumeHandle, not PV name?",
        "createdAt" : "2019-10-07T21:14:14Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "4ccb5f10-b3bd-422d-8e9c-fcaec0ac674f",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "It seems like variables are poorly named. \"specVolID\" is PV name. https://github.com/kubernetes/kubernetes/blob/39724859b524e345881eb8ef458f0d5a2f25bd9a/pkg/volume/csi/csi_mounter.go#L45 . This is not the same thing as `volume_id` in the CSI spec, that is volumeHandle?!",
        "createdAt" : "2019-10-07T21:23:43Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "bfc87851-9e22-4593-8d08-9cdb82f83773",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "The issue I see is it's possible (but unlikely) for the same volume_id to be used by two different PVs, in which case there will be two globalMapPaths for the same `volume_id` meaning NodeUnstage may be called early.\r\n\r\nI think you can keep the paths as they are to make this PR simpler, and you can leave the sorting out of paths as a follow-up for me...\r\n\r\ne: unmountdevice should not be called in the first place as ASW uses volumeHandle/`volume_id` to decide when it should be called. So unless ASW (or reconstruction of it) is buggy, it should be fine to keep the paths as they are.",
        "createdAt" : "2019-10-07T21:43:41Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "a0d51cbf-6fdd-4362-a185-005a7722d428",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@wongma7 \r\n\r\nIt seems that we have been using [`spec.Name()`](https://github.com/kubernetes/kubernetes/blob/master/pkg/volume/plugins.go#L472) as an ID for volume in [GetPodDeviceMapPath](https://github.com/kubernetes/kubernetes/blob/master/pkg/volume/gcepd/gce_pd_block.go#L178) in in-tree plugins. So, we should be able to use `m.specName` as CSI plugin's ID for volume.\r\n\r\nThe value of `m.specName` is like `pvc-82051086-eb98-4dd0-941a-1512bc438278`, so we won't need to sanitize it by calling `utilstrings.EscapeQualifiedName`.\r\nAlso, we should change the comment from `{pvname}` to `{specName}` to avoid confusion.\r\n\r\nIf you agree. I will change as so.",
        "createdAt" : "2019-10-08T19:09:07Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      },
      {
        "id" : "4cb2d62a-1f99-40d9-891a-667dea45022e",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "I agree 👍 ",
        "createdAt" : "2019-10-09T03:07:09Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      },
      {
        "id" : "3239c031-ed1b-4d8e-98ba-1f76d1f4d6f2",
        "parentId" : "d45f03f3-faec-4a33-9b8e-38224b772a37",
        "authorId" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "body" : "While I am not enough of a linux pro to understand why it works, I tried the fd lock thing today and it works as described by the comment before AttachFileDevice. I will need to check if it still works for the new bind mounted case...\r\n\r\n1. Start some nonsense container that periodically writes to the device\r\ndocker run --name test --device /dev/nvme2n3 nginx bash -c 'i=0; while true; do echo $i; ((i++)); echo $i > ./hello.txt; dd if=./hello.txt of=/dev/nvme2n3 bs=64 count=1; sleep 5; done'; docker rm test\r\n2. Detach the device, then it will get:\r\ndd: failed to open '/dev/nvme2n3': No such device or address\r\n3. Attach a different device, it will resume writing to it. This is the problem the comment for the lock described.\r\n\r\nIf you setup a loop device to keep the fd open:\r\n\r\n1. docker run --name test --device /dev/nvme2n3 nginx bash -c 'i=0; while true; do echo $i; ((i++)); echo $i > ./hello.txt; dd if=./hello.txt of=/dev/nvme2n3 bs=64 count=1; sleep 5; done'; docker rm test\r\n2. sudo losetup -f --show /dev/nvme2n3\r\n3. Detach the device, then it will get:\r\ndd: failed to open '/dev/nvme2n3': No such device or address\r\n4. Attach a different device, it will continue to get the above error which is better than writing to a different device...",
        "createdAt" : "2019-10-09T04:43:16Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "241ab19e-f85a-4d22-92e2-88f2b6287d14",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +106,110 @@\tklog.V(4).Infof(log(\"blockMapper.GetGlobalMapPath = %s\", dir))\n\treturn dir, nil\n}\n\n// getStagingPath returns a staging path for a directory (on the node) that should be used on NodeStageVolume/NodeUnstageVolume"
  },
  {
    "id" : "a76d594d-5460-456f-b6a4-b04f13543439",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-309427862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f012389-6167-4c73-ae15-a02a8019c273",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "can you clarify what a `global map path` and `pod device map path and filename` are, or what they are used for",
        "createdAt" : "2019-10-30T18:25:28Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +24,28 @@Summary of block volume related CSI driver's methods are as follows:\n - GetGlobalMapPath returns a global map path,\n - GetPodDeviceMapPath returns a pod device map path and filename,\n - SetUpDevice calls CSI's NodeStageVolume and stage a volume to its staging path,\n - MapPodDevice calls CSI's NodePublishVolume and publish a volume to its publish path,"
  },
  {
    "id" : "15bc282a-05f4-4ee5-b283-4c5abc6b71f9",
    "prId" : 74026,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74026#pullrequestreview-309427862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89583a5a-23a1-4d3b-ad50-9e329f78831c",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "what is `specName`",
        "createdAt" : "2019-10-30T18:30:28Z",
        "updatedAt" : "2019-11-15T02:00:20Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "4578c6c8ce85ea89c055b6be7a51b7c8e573e809",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +109,113 @@\n// getStagingPath returns a staging path for a directory (on the node) that should be used on NodeStageVolume/NodeUnstageVolume\n// Example: plugins/kubernetes.io/csi/volumeDevices/staging/{specName}\nfunc (m *csiBlockMapper) getStagingPath() string {\n\treturn filepath.Join(m.plugin.host.GetVolumeDevicePluginDir(CSIPluginName), \"staging\", m.specName)"
  },
  {
    "id" : "56736ef0-93bb-4441-8272-2b7b08150eb9",
    "prId" : 68635,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68635#pullrequestreview-159096004",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59837f30-b6fe-4cf2-8ce6-9d664e1eab53",
        "parentId" : null,
        "authorId" : "a7f673a6-4b23-4df6-aa10-f123fa9dcd5f",
        "body" : "should the volume be unstaged here?",
        "createdAt" : "2018-09-26T12:26:25Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "a7f673a6-4b23-4df6-aa10-f123fa9dcd5f",
        "tags" : [
        ]
      },
      {
        "id" : "e7df7ebc-8947-4a0a-82e1-f3f61d86bf7b",
        "parentId" : "59837f30-b6fe-4cf2-8ce6-9d664e1eab53",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@rootfs\r\n\r\nThank you for your comment.\r\n\r\nIIUC, reconciler will keep calling ```MountVolume``` to try to make ASW and DSW the same, even when ```MountVolume``` fails in ```SetUpDevice```. So, even if we call ```NodeUnstageVolume``` here to unstage the volume that failed in publish, another attempts to ```MountVolume``` would stage it again. (Then, ```MountVolume``` may fail in publish again.) In addition, if ```NodeUnstageVolume``` for Nth ```MountVolume``` are called before ```NodePublishVolume``` and after ```NodeStageVolume``` for N+1th ```MountVolume```, it will make ```NodePublishVolume``` call for unstaged volume, which violates CSI spec. Therefore, just calling ```NodeUnstageVolume``` here won't role back the status properly.\r\n\r\nHowever, this raises me a question whether it is safe to keep the volume staged, after the failure in publish. At a glance, it seems safe from data corruption viewpoint, for we won't directly touch to the staged device and staging path.\r\nThe worst case senarios that I noticed are below:\r\n  - If the pvc deletion is done before the publish-failed pod deletion, the device might be deleted while it is attached to a node,\r\n  - If the pvc is used in another pod scheduled on a different node before the publish-failed pod deletion, the device might be attached to multiple nodes. \r\n\r\n@vladimirvivien\r\n\r\nIs my understanding correct? And are there any issues that you can think of by not staging the volume there? ",
        "createdAt" : "2018-09-26T16:48:07Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c56b53390006b9853528bd0288a42e30ce390dc",
    "line" : 351,
    "diffHunk" : "@@ -1,1 +257,261 @@\tpublishPath, err := m.publishVolumeForBlock(ctx, m.csiClient, accessMode, csiSource, attachment, stagingPath)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n"
  },
  {
    "id" : "ab53df25-f18a-4f75-b4ff-3d6f63c8f9c6",
    "prId" : 68635,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68635#pullrequestreview-163450161",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1dbaf071-75b6-4192-816d-896174da4438",
        "parentId" : null,
        "authorId" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "body" : "Since calls to `m.stageVolumeForBlock` and `m.publishVolumeForBlock` happen successively at close proximity, I would recommend to create `csiClient` here (instead of creating an instance in each method).  Then pass the client as a parameter to these methods respectively. ",
        "createdAt" : "2018-10-10T16:45:38Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c56b53390006b9853528bd0288a42e30ce390dc",
    "line" : 316,
    "diffHunk" : "@@ -1,1 +238,242 @@\t\treturn \"\", errors.New(\"no existing VolumeAttachment found\")\n\t}\n\n\t//TODO (vladimirvivien) implement better AccessModes mapping between k8s and CSI\n\taccessMode := v1.ReadWriteOnce"
  },
  {
    "id" : "d89a7e05-4fd3-4a66-a3e3-b00eb8235b1d",
    "prId" : 68635,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68635#pullrequestreview-163450161",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "deafc766-668e-4557-89bd-cb01e647d7aa",
        "parentId" : null,
        "authorId" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "body" : "Same here. Since calls for `unpublishVolumeForBlock` and `unstageVolumeForBlock` happen successively, create a `csiClient` here and pass it to each method as a parameter respectively to avoid creating client inside each call.",
        "createdAt" : "2018-10-10T16:50:08Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c56b53390006b9853528bd0288a42e30ce390dc",
    "line" : 443,
    "diffHunk" : "@@ -1,1 +323,327 @@\n\tklog.V(4).Infof(log(\"unmapper.TearDownDevice(globalMapPath=%s; devicePath=%s)\", globalMapPath, devicePath))\n\n\tctx, cancel := context.WithTimeout(context.Background(), csiTimeout)\n\tdefer cancel()"
  },
  {
    "id" : "eacd15f3-711e-4c15-82ce-09068d01829a",
    "prId" : 68635,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68635#pullrequestreview-166351137",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "091134cb-78f6-4c6f-8fb0-6cc2b0dc059d",
        "parentId" : null,
        "authorId" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "body" : " Decouple this if-else blocks since they (os.Stat check and unstageVol call) are independent.  In addition the stat check should only fail if err is not IsNotExist(err)\r\n\r\nSuggestion:\r\n\r\n```go\r\nif _, err := os.Stat(...); os.IsNotExist(err) {\r\n    glog.V(4).Infof(log(\"blockMapper.TearDownDevice stagingPath(%s) has already been deleted...\"))\r\n} else{\r\n    return err\r\n}\r\nif err := m.unstageVolumeForBlock(ctx, m.csiClient, stagingPath); err != nil {\r\n    return err\r\n}\r\n```",
        "createdAt" : "2018-10-18T18:18:54Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "tags" : [
        ]
      },
      {
        "id" : "4ea712a3-6f55-4535-acae-63aa4d3ae9c5",
        "parentId" : "091134cb-78f6-4c6f-8fb0-6cc2b0dc059d",
        "authorId" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "body" : "@vladimirvivien \r\n\r\nThank you for your suggestion.\r\n\r\nI agree that os.stat check should only fail if err is not IsNotExist(err).\r\n\r\nFor IsNotExist(err) case, I intended to skip calling unstageVolumeForBlock because main purpose for unstageVolumeForBlock is to make staging path invisible, but the path does not exist already.\r\n\r\nSo, I fixed it as so. And I also applied the same change to unpublishVolumeForBlock.\r\n\r\nPTAL",
        "createdAt" : "2018-10-19T01:19:13Z",
        "updatedAt" : "2018-11-15T23:28:47Z",
        "lastEditedBy" : "9ce7bd1a-5286-4173-88a4-039146bf0d46",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c56b53390006b9853528bd0288a42e30ce390dc",
    "line" : 476,
    "diffHunk" : "@@ -1,1 +344,348 @@\t// Call NodeUnstageVolume\n\tstagingPath := m.getStagingPath()\n\tif _, err := os.Stat(stagingPath); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\tklog.V(4).Infof(log(\"blockMapper.TearDownDevice stagingPath(%s) has already been deleted, skip calling NodeUnstageVolume\", stagingPath))"
  },
  {
    "id" : "f26fb856-c5f6-4ac9-9d8b-32831ac101b8",
    "prId" : 65032,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/65032#pullrequestreview-129645500",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "454e46c4-dccf-47eb-84bb-3c36b0f99caf",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "this could be pulled out into a util function, looks like a similar thing is in MapDevice",
        "createdAt" : "2018-06-12T22:46:59Z",
        "updatedAt" : "2018-06-18T16:46:32Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "96b12ea0-58f9-451b-9d3e-6c132424bbd0",
        "parentId" : "454e46c4-dccf-47eb-84bb-3c36b0f99caf",
        "authorId" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "body" : "@davidz627 Wrapping this in another layer of indirection (func), would not buy too much here since there are no other logic involved other than opening the file.",
        "createdAt" : "2018-06-18T16:43:01Z",
        "updatedAt" : "2018-06-18T16:46:32Z",
        "lastEditedBy" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "tags" : [
        ]
      }
    ],
    "commit" : "6553e2c8499de5a7ca516646b8e27a94a929e888",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +141,145 @@\n\t// create block device file\n\tblockFile, err := os.OpenFile(globalMapPathBlockFile, os.O_CREATE|os.O_RDWR, 0750)\n\tif err != nil {\n\t\tglog.Error(log(\"blockMapper.SetupDevice failed to create dir %s: %v\", globalMapPathBlockFile, err))"
  },
  {
    "id" : "7bfc7361-d7b5-41af-8fea-6ed9f6ec17ac",
    "prId" : 64723,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/64723#pullrequestreview-126077201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3050871f-c362-4097-8fce-59f41a9aa33a",
        "parentId" : null,
        "authorId" : "8e448017-7838-493d-a424-33cada0da657",
        "body" : "It is unfortunate that we have this dependency between `MountDevice` (aka `SetupDevice`) and Attach. Ideally, these methods (along with `NodeStage`) should be able to be implement a local attach without a remote attach. But that is a larger refactor we can address in the future. + @davidz627 ",
        "createdAt" : "2018-06-04T22:29:53Z",
        "updatedAt" : "2018-06-05T20:54:27Z",
        "lastEditedBy" : "8e448017-7838-493d-a424-33cada0da657",
        "tags" : [
        ]
      },
      {
        "id" : "50beea69-63f9-4e32-97b9-8ddcf1fb7a55",
        "parentId" : "3050871f-c362-4097-8fce-59f41a9aa33a",
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "Issue tracked here: https://github.com/kubernetes/kubernetes/issues/64781",
        "createdAt" : "2018-06-05T17:38:03Z",
        "updatedAt" : "2018-06-05T20:54:27Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      }
    ],
    "commit" : "5044a3d12cd8a7c01045651646d6a76864661027",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +108,112 @@\n\t// search for attachment by VolumeAttachment.Spec.Source.PersistentVolumeName\n\tattachment, err := m.k8s.StorageV1beta1().VolumeAttachments().Get(attachID, meta.GetOptions{})\n\tif err != nil {\n\t\tglog.Error(log(\"blockMapper.SetupDevice failed to get volume attachment [id=%v]: %v\", attachID, err))"
  },
  {
    "id" : "54751038-2df0-4fec-a96e-4fbc4ab2a4d0",
    "prId" : 64723,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/64723#pullrequestreview-125791500",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74527723-8ee4-470b-929a-515aeeb0a5ea",
        "parentId" : null,
        "authorId" : "8e448017-7838-493d-a424-33cada0da657",
        "body" : "Shouldn't `NodeUnstageVolume` and `NodeUnpublishVolume` be called by `TearDownDevice` and `UnmapDevice` instead of both in the same method?",
        "createdAt" : "2018-06-05T00:43:49Z",
        "updatedAt" : "2018-06-05T20:54:27Z",
        "lastEditedBy" : "8e448017-7838-493d-a424-33cada0da657",
        "tags" : [
        ]
      },
      {
        "id" : "eefb6a75-bb98-4674-853d-8aa67852b145",
        "parentId" : "74527723-8ee4-470b-929a-515aeeb0a5ea",
        "authorId" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "body" : "@saad-ali yeah the API probably should have an `UnmapDevice` method.  But It does not.  Similarly, the `MapDevice` was introduced in the API with the refactor PR.  So, maybe later we do that.",
        "createdAt" : "2018-06-05T01:12:58Z",
        "updatedAt" : "2018-06-05T20:54:27Z",
        "lastEditedBy" : "54b8eb75-28dd-421d-a52b-63bf897147a9",
        "tags" : [
        ]
      }
    ],
    "commit" : "5044a3d12cd8a7c01045651646d6a76864661027",
    "line" : 275,
    "diffHunk" : "@@ -1,1 +273,277 @@\tpodVolumePath, volumeName := m.GetPodDeviceMapPath()\n\tpodVolumeMapPath := filepath.Join(podVolumePath, volumeName)\n\tif err := csi.NodeUnpublishVolume(ctx, m.volumeID, podVolumeMapPath); err != nil {\n\t\tglog.Error(log(\"blockMapper.TearDownDevice failed: %v\", err))\n\t\treturn err"
  }
]