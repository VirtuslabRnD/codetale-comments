[
  {
    "id" : "e03c17f0-3976-4c3e-84fe-4e64e38e46c0",
    "prId" : 64235,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/64235#pullrequestreview-125772576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7771614-990d-4b1c-bf75-1c6eba8111be",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Timeout when waiting for cache sync seems to be useful in general, consider adding a `WaitForCacheSyncUntil` to client-go. ",
        "createdAt" : "2018-06-04T23:09:40Z",
        "updatedAt" : "2018-06-04T23:51:51Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "7da3d65571d7e86b83710bf1285d5d9ff38f2cd3",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +230,234 @@\t\t\t// the call to resyncMonitors on the reattempt will no-op for resources that still exist.\n\t\t\t// note that workers stay paused until we successfully resync.\n\t\t\tif !controller.WaitForCacheSync(\"garbage collector\", waitForStopOrTimeout(stopCh, period), gc.dependencyGraphBuilder.IsSynced) {\n\t\t\t\tutilruntime.HandleError(fmt.Errorf(\"timed out waiting for dependency graph builder sync during GC sync (attempt %d)\", attempt))\n\t\t\t\treturn false, nil"
  },
  {
    "id" : "16e342d9-bc8a-4dcd-9298-8c4878fe3115",
    "prId" : 63446,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/63446#pullrequestreview-119334601",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7685ac2-6ad6-4a31-b709-73566e004046",
        "parentId" : null,
        "authorId" : "f0985d19-4073-49b4-832a-0b89b15a1431",
        "body" : "we should have kept the interface name. Would have made this easier. Maybe we can restore it in a follow-up?",
        "createdAt" : "2018-05-09T14:39:23Z",
        "updatedAt" : "2018-05-11T17:12:14Z",
        "lastEditedBy" : "f0985d19-4073-49b4-832a-0b89b15a1431",
        "tags" : [
        ]
      },
      {
        "id" : "aa76dd2b-f959-4b85-8f0f-9492b421bb00",
        "parentId" : "e7685ac2-6ad6-4a31-b709-73566e004046",
        "authorId" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "body" : "> we should have kept the interface name. Would have made this easier. Maybe we can restore it in a follow-up?\r\n\r\nThis actually is the \"old\" interface name.  `Interface` is the name used by the primary dynamic interface.  GC was updated to use the new before the new became primary.",
        "createdAt" : "2018-05-09T14:40:46Z",
        "updatedAt" : "2018-05-11T17:12:14Z",
        "lastEditedBy" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "tags" : [
        ]
      },
      {
        "id" : "625b87b9-c31e-48f7-8ece-4e25f4b28be1",
        "parentId" : "e7685ac2-6ad6-4a31-b709-73566e004046",
        "authorId" : "f0985d19-4073-49b4-832a-0b89b15a1431",
        "body" : ":+1: now with multiple commits this is even visible :)",
        "createdAt" : "2018-05-11T06:59:17Z",
        "updatedAt" : "2018-05-11T17:12:14Z",
        "lastEditedBy" : "f0985d19-4073-49b4-832a-0b89b15a1431",
        "tags" : [
        ]
      }
    ],
    "commit" : "fd044d152ee13a6cb812e4c3e7504ee8e24b5b8c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +61,65 @@type GarbageCollector struct {\n\trestMapper    resettableRESTMapper\n\tdynamicClient dynamic.Interface\n\t// garbage collector attempts to delete the items in attemptToDelete queue when the time is ripe.\n\tattemptToDelete workqueue.RateLimitingInterface"
  },
  {
    "id" : "7925fcd8-212a-40df-8d2a-4aa616519913",
    "prId" : 56446,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/56446#pullrequestreview-79318859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9740e927-4cfc-415d-877d-fa9005b15e33",
        "parentId" : null,
        "authorId" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "body" : "Although it hasn't been reported anywhere (that I know of), @liggitt noticed this potential bug during the course of reviewing the original patch. If there are no objections, I'd like to bundle the fix in this PR.",
        "createdAt" : "2017-11-27T21:30:53Z",
        "updatedAt" : "2017-11-27T21:50:38Z",
        "lastEditedBy" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "tags" : [
        ]
      }
    ],
    "commit" : "a62d07ce2aaf669b3cf48d8c4a23134fe0515d9c",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +217,221 @@\t\t// have succeeded to ensure we'll retry on subsequent syncs if an error\n\t\t// occured.\n\t\toldResources = newResources\n\t\tglog.V(2).Infof(\"synced garbage collector\")\n\t}, period, stopCh)"
  },
  {
    "id" : "e9870fb5-693e-449e-8b41-0da5dfbc5f00",
    "prId" : 56446,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/56446#pullrequestreview-79323812",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6881f937-a453-49ff-a782-7d35cb3fcd70",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "add a V(2) log message here that sync completed... want to be able to pair with the log message from line 183 to know resync completed",
        "createdAt" : "2017-11-27T21:42:11Z",
        "updatedAt" : "2017-11-27T21:50:38Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "fc00143e-f27b-41c6-bfd9-769eb63d8b04",
        "parentId" : "6881f937-a453-49ff-a782-7d35cb3fcd70",
        "authorId" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "body" : "Done",
        "createdAt" : "2017-11-27T21:47:50Z",
        "updatedAt" : "2017-11-27T21:50:38Z",
        "lastEditedBy" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "tags" : [
        ]
      }
    ],
    "commit" : "a62d07ce2aaf669b3cf48d8c4a23134fe0515d9c",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +214,218 @@\t\t}\n\n\t\t// Finally, keep track of our new state. Do this after all preceding steps\n\t\t// have succeeded to ensure we'll retry on subsequent syncs if an error\n\t\t// occured."
  },
  {
    "id" : "f7c962ba-7e2d-4db7-afb9-32ef0fc84c0b",
    "prId" : 56446,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/56446#pullrequestreview-103805005",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "When will it block forever?",
        "createdAt" : "2017-11-27T23:08:39Z",
        "updatedAt" : "2017-11-27T23:08:39Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "10e867c9-ecad-47a1-8a34-0bfd99c04bf0",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "if newResources contains GVKs that are being removed, and are gone by the time we get here, I think blocks until the informers for newResources are all synced, which will never happen successfully for the now-missing GVKs.\r\n\r\n1. add new resource (CRD, add-on APIService, etc)\r\n2. GC GetDeletableResources sees new resource, notices something has changed\r\n3. delete new resource\r\n4. GC resyncMonitors sets up new monitors/informers for newResources, including for the now-gone resource\r\n5. GC WaitForCacheSync waits until the informers are all synced, which will never succeed for the now-gone resource",
        "createdAt" : "2017-11-28T02:34:56Z",
        "updatedAt" : "2017-11-28T02:34:56Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "23dfc1e7-8b3d-4884-acdc-d129d94d1c3c",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Shall we plumb a flag into the reflector to instruct it to not retry listing if the error is 404?",
        "createdAt" : "2017-11-28T19:37:04Z",
        "updatedAt" : "2017-11-28T19:37:04Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "a017d36f-f81a-4f53-ad6d-049a8b387273",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "I don't know... requires more thought. @ironcladlou can you open an issue to track this to make sure it stays high on our radar?",
        "createdAt" : "2017-11-28T19:39:52Z",
        "updatedAt" : "2017-11-28T19:39:52Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "ad32ac93-4f9f-48ea-8e46-9f61ad443997",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "body" : "Is there an open issue for this? Based on the logs, I think it is the cause of #60037",
        "createdAt" : "2018-03-07T22:03:34Z",
        "updatedAt" : "2018-03-07T22:03:34Z",
        "lastEditedBy" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "tags" : [
        ]
      },
      {
        "id" : "bb61309f-42d5-43bd-afda-aed3d72d2a0d",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "body" : "@liggitt @ironcladlou I couldn't find the issue tracking this race\r\n\r\nI am wondering if something like https://github.com/kubernetes/kubernetes/pull/61057 will be enough to fix/mitigate this race condition",
        "createdAt" : "2018-03-12T19:46:56Z",
        "updatedAt" : "2018-03-12T19:47:19Z",
        "lastEditedBy" : "37324129-fa96-456d-92ea-e5f9b41f8c7f",
        "tags" : [
        ]
      },
      {
        "id" : "44ec71a6-9c0c-40b8-ab8a-bf380f9447a4",
        "parentId" : "d3cb59d2-1a05-41ac-b0c9-88a772293842",
        "authorId" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "body" : "@jennybuckley looks like I neglected to create the followup issue for this. I've been slammed the past couple weeks with things unrelated to Kube but I'll try to take a look at https://github.com/kubernetes/kubernetes/pull/61057 today. Thank you!",
        "createdAt" : "2018-03-14T12:58:24Z",
        "updatedAt" : "2018-03-14T12:58:24Z",
        "lastEditedBy" : "f04ec747-f3ff-4334-a66e-6daaf4497091",
        "tags" : [
        ]
      }
    ],
    "commit" : "a62d07ce2aaf669b3cf48d8c4a23134fe0515d9c",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +206,210 @@\t\t\treturn\n\t\t}\n\t\t// TODO: WaitForCacheSync can block forever during normal operation. Could\n\t\t// pass a timeout channel, but we have to consider the implications of\n\t\t// un-pausing the GC with a partially synced graph builder."
  },
  {
    "id" : "506261e2-98f7-471d-89d9-fc9018eb93dd",
    "prId" : 55259,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/55259#pullrequestreview-78129254",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "119253c8-d645-46b9-bab4-810d1842eb03",
        "parentId" : null,
        "authorId" : "21b457d2-6f88-4a9f-8d5a-debafbcb6cfe",
        "body" : "I've created https://github.com/kubernetes/kubernetes/pull/56150 to fix improper formatting.",
        "createdAt" : "2017-11-21T14:30:45Z",
        "updatedAt" : "2017-11-21T14:30:45Z",
        "lastEditedBy" : "21b457d2-6f88-4a9f-8d5a-debafbcb6cfe",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3dd82c30c8ea89c3125e7b09b0d414a94a55e02",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +597,601 @@\tif err != nil {\n\t\tif discovery.IsGroupDiscoveryFailedError(err) {\n\t\t\tglog.Warning(\"failed to discover some groups: %v\", err.(*discovery.ErrGroupDiscoveryFailed).Groups)\n\t\t} else {\n\t\t\tglog.Warning(\"failed to discover preferred resources: %v\", err)"
  },
  {
    "id" : "d94680d8-3b44-4030-8113-a03b4812318a",
    "prId" : 50335,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/50335#pullrequestreview-55113801",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4bdbc64d-d9ec-4e52-a21e-55c7455cfc6f",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "To clarify, this is not a new issue. The original code has the same inconsistency because the memcached discovery client always get the fresh server resource when `ServerPreferredResources` is called.",
        "createdAt" : "2017-08-09T01:24:44Z",
        "updatedAt" : "2017-08-09T17:33:36Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "60514d3d664244299b42e8f6af0c2212b0cee632",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +209,213 @@\t\t// Perform the monitor resync and wait for controllers to report cache sync.\n\t\t//\n\t\t// NOTE: It's possible that newResources will diverge from the resources\n\t\t// discovered by restMapper during the call to Reset, since they are\n\t\t// distinct discovery clients invalidated at different times. For example,"
  },
  {
    "id" : "55c630ac-57ec-41ea-b9b6-e49dd9d73eb5",
    "prId" : 49516,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/49516#pullrequestreview-52755721",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e892661-44ad-43a9-88d6-3cb2507427e9",
        "parentId" : null,
        "authorId" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "body" : "nit: `orphaning for dependent %s failed`",
        "createdAt" : "2017-07-27T19:07:05Z",
        "updatedAt" : "2017-07-27T19:07:06Z",
        "lastEditedBy" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e7d7c00a22871cf7076b34f302da7f8e3328770",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +423,427 @@\t\t\t// dependent, strategic merge patch will NOT return an error.\n\t\t\tif err != nil && !errors.IsNotFound(err) {\n\t\t\t\terrCh <- fmt.Errorf(\"orphaning %s failed, %v\", dependent.identity, err)\n\t\t\t}\n\t\t}(dependents[i])"
  },
  {
    "id" : "b495e3aa-214e-400e-81d5-4f3c03f0f991",
    "prId" : 38676,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/38676#pullrequestreview-23868530",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebe248c7-3fcf-4bfa-9b05-e5775dae7c91",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Not sure I agree with this TODO. This double-check also makes it a lot harder for a bug to cause GC to do a massive amount of wrong deletions.",
        "createdAt" : "2017-02-24T23:49:12Z",
        "updatedAt" : "2017-03-01T07:05:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "3b1b0875-a64e-47b5-83be-fee47f54d518",
        "parentId" : "ebe248c7-3fcf-4bfa-9b05-e5775dae7c91",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Add a note in the TODO list of https://github.com/kubernetes/kubernetes/pull/38679.",
        "createdAt" : "2017-02-25T22:28:32Z",
        "updatedAt" : "2017-03-01T07:05:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "31cb266340ac5d702a650ea30c730bb909cd99b5",
    "line" : 251,
    "diffHunk" : "@@ -1,1 +189,193 @@\t\treturn false, nil, err\n\t}\n\t// TODO: It's only necessary to talk to the API server if the owner node\n\t// is a \"virtual\" node. The local graph could lag behind the real\n\t// status, but in practice, the difference is small."
  },
  {
    "id" : "7bb8f213-40d8-47a4-ace3-5ee732d8d999",
    "prId" : 32805,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/32805#pullrequestreview-251195",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "297c6925-b44c-4308-b0f6-ef5d66fd5312",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "We may need to revisit this when we do synchronous GC. Does absent owner cache mean the deletion has been _started_ or actually _finished_?\n",
        "createdAt" : "2016-09-15T20:15:14Z",
        "updatedAt" : "2016-09-15T20:54:34Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "e52eaf71-58e3-4a6d-b7cd-c4c5d95ab6e3",
        "parentId" : "297c6925-b44c-4308-b0f6-ef5d66fd5312",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Yes, we should revisit. It means the deletion has started.\n",
        "createdAt" : "2016-09-15T20:49:31Z",
        "updatedAt" : "2016-09-15T20:54:34Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "d122de5371d6b41a17c0e6798755b3a38182a1fb",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +412,416 @@\t\tp.removeDependentFromOwners(existingNode, removed)\n\tcase event.eventType == deleteEvent:\n\t\tp.gc.absentOwnerCache.Add(accessor.GetUID())\n\t\tif !found {\n\t\t\tglog.V(6).Infof(\"%v doesn't exist in the graph, this shouldn't happen\", accessor.GetUID())"
  },
  {
    "id" : "94c36890-19fa-4c93-87eb-20497dacb90c",
    "prId" : 30316,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43703588-04cd-4249-8662-5143c7cd0fa6",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Can you open an issue so we'll revisit whether it's OK for garbage collector to mutate these objects?\n",
        "createdAt" : "2016-08-27T00:00:52Z",
        "updatedAt" : "2016-08-27T00:00:52Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "25efe24f-f474-481d-a584-ae428b51e041",
        "parentId" : "43703588-04cd-4249-8662-5143c7cd0fa6",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "https://github.com/kubernetes/kubernetes/issues/31569\n",
        "createdAt" : "2016-08-27T00:13:59Z",
        "updatedAt" : "2016-08-27T00:13:59Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ac91e5172fb343e1bcb3167d36836a0b74ec2e4",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +504,508 @@\t\t\t},\n\t\t\tUpdateFunc: func(oldObj, newObj interface{}) {\n\t\t\t\tsetObjectTypeMeta(newObj)\n\t\t\t\tevent := &event{updateEvent, newObj, oldObj}\n\t\t\t\tgc.propagator.eventQueue.Add(&workqueue.TimedWorkQueueItem{StartTime: gc.clock.Now(), Object: event})"
  },
  {
    "id" : "e515b671-325d-408d-a3f1-3be11936457b",
    "prId" : 29550,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03b955fe-0ad0-4a26-9528-5c4c0a48656f",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Might as well log here, too. \"Garbage Collector: Waiting for resource listings to finish...\"\n",
        "createdAt" : "2016-07-25T18:31:10Z",
        "updatedAt" : "2016-07-25T21:03:38Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "d077db366a299387da87b8fca59dbdf7209dc122",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +692,696 @@\twait.PollInfinite(10*time.Second, func() (bool, error) {\n\t\tfor _, monitor := range gc.monitors {\n\t\t\tif !monitor.controller.HasSynced() {\n\t\t\t\tglog.Infof(\"Garbage Collector: Waiting for resource monitors to be synced...\")\n\t\t\t\treturn false, nil"
  },
  {
    "id" : "cd170a28-6fef-4c3b-a7e0-ab0121f95133",
    "prId" : 28480,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c9a3799d-5b8d-4b85-aa2a-7ef462d13c35",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I suggest just making your new codec do this step?\n",
        "createdAt" : "2016-08-04T21:18:18Z",
        "updatedAt" : "2016-08-09T00:23:24Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "230018f2-926e-47cd-9de8-3382f5e81875",
        "parentId" : "c9a3799d-5b8d-4b85-aa2a-7ef462d13c35",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "I don't have a codec. One benefit of registering the MetaOnly to the scheme is utilizing the existing codecs, like the DirectCodec. I think it's neater to do it here unless we see other use cases then we can put a generalized codec. [edit] Also our a List doesn't set the gvk of items, we would need special decoder to workaround that as well.\n",
        "createdAt" : "2016-08-04T21:26:36Z",
        "updatedAt" : "2016-08-09T00:23:24Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "a0881b33-595d-4492-82b9-4c719a86c7b6",
        "parentId" : "c9a3799d-5b8d-4b85-aa2a-7ef462d13c35",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Chao convinced me IRL :(\n\nOn Thu, Aug 4, 2016 at 2:26 PM, Chao Xu notifications@github.com wrote:\n\n> In pkg/controller/garbagecollector/garbagecollector.go\n> https://github.com/kubernetes/kubernetes/pull/28480#discussion_r73605893\n> :\n> \n> > ```\n> >             event := event{\n> >                 eventType: addEvent,\n> >                 obj:       obj,\n> >             }\n> >             p.eventQueue.Add(event)\n> >         },\n> >         UpdateFunc: func(oldObj, newObj interface{}) {\n> > ```\n> > -               setObjectTypeMeta(newObj)\n> \n> I don't have a codec. One benefit of registering the MetaOnly to the\n> scheme is utilizing the existing codecs, like the DirectCodec. I think it's\n> neater to do it here unless we see other use cases then we can put a\n> generalized codec.\n> \n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/28480/files/41d92b1b3fe4883311ae3037fb816f858d565fbd#r73605893,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAngltTGxnes6BT_iSGGuyLD-HbyUuwZks5qclkWgaJpZM4JEvyT\n> .\n",
        "createdAt" : "2016-08-05T00:00:36Z",
        "updatedAt" : "2016-08-09T00:23:24Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d2350632c4c025e1a42495ddbf4bc804bc82607",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +497,501 @@\t\t\t},\n\t\t\tUpdateFunc: func(oldObj, newObj interface{}) {\n\t\t\t\tsetObjectTypeMeta(newObj)\n\t\t\t\tsetObjectTypeMeta(oldObj)\n\t\t\t\tevent := event{updateEvent, newObj, oldObj}"
  },
  {
    "id" : "1de9de14-4690-4510-ad9b-49356a4cbafe",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8e84af7-36a3-49d9-beab-31f1cafcd627",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "be level-triggered, not edge triggered. I.e., just check if the current object has a deletion timestamp. Doesn't matter what the old object was.\n",
        "createdAt" : "2016-05-14T00:18:13Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "827222dd-45df-4369-b2ab-98115e371c18",
        "parentId" : "c8e84af7-36a3-49d9-beab-31f1cafcd627",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "That may generate too much traffic. I prefer keep it is unless we have situations can't be handled by the level-triggered orphaning finalizer.\n",
        "createdAt" : "2016-05-15T23:49:16Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "1eb9142c-f745-4581-89b7-abadc1160260",
        "parentId" : "c8e84af7-36a3-49d9-beab-31f1cafcd627",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "What if it's already got deletion timestamp set the first time you see it? \n",
        "createdAt" : "2016-05-16T03:41:01Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "3f5692d2-b723-47a5-855c-7fce6b726fd0",
        "parentId" : "c8e84af7-36a3-49d9-beab-31f1cafcd627",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "That's handled in the previous `if` block.\n",
        "createdAt" : "2016-05-18T03:38:21Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "da0beaba-9408-40b4-87a2-40ef9ee2ac49",
        "parentId" : "c8e84af7-36a3-49d9-beab-31f1cafcd627",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Hm, OK, I see.\n",
        "createdAt" : "2016-05-18T23:21:51Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +226,230 @@\t\t\treturn false\n\t\t}\n\t\t// ignore the event if it's not updating DeletionTimestamp from non-nil to nil.\n\t\tif accessor.GetDeletionTimestamp() == nil || oldAccessor.GetDeletionTimestamp() != nil {\n\t\t\treturn false"
  },
  {
    "id" : "c711cc8e-0458-4b36-8522-e370fcf84715",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d14ef2df-1a9f-4e09-981b-d3d10eacb201",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "This line handles the case where the DeletionTimestamp is set at the first time GC sees it\n",
        "createdAt" : "2016-05-16T04:52:04Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : null,
    "diffHunk" : "@@ -1,1 +217,221 @@\t// event, so we need to check AddEvent as well.\n\tif e.oldObj == nil {\n\t\tif accessor.GetDeletionTimestamp() == nil {\n\t\t\treturn false\n\t\t}"
  },
  {
    "id" : "bb85eca6-d4e6-44a3-8f62-172ff5403e22",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d67b25a8-5be8-43d0-8e6a-9e42d51af1a3",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Do these all really need to be independently lockable? Why not just a single lock for the whole map?\n",
        "createdAt" : "2016-05-18T23:16:56Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "57463700-5c58-40f0-8ce2-73cfc46783f8",
        "parentId" : "d67b25a8-5be8-43d0-8e6a-9e42d51af1a3",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "I don't want to block the `orphan()` routine when the `processEvent()` is updating other parts of the graph.\n",
        "createdAt" : "2016-05-19T02:28:38Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "ca50eae7-8f26-40d3-aec9-5575024e82e8",
        "parentId" : "d67b25a8-5be8-43d0-8e6a-9e42d51af1a3",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "optional nil: as long as nodes are always passed by pointer, this doesn't need to be a pointer.\n",
        "createdAt" : "2016-05-20T23:40:36Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +68,72 @@\tidentity objectReference\n\t// dependents will be read by the orphan() routine, we need to protect it with a lock.\n\tdependentsLock *sync.RWMutex\n\tdependents     map[*node]struct{}\n\t// When processing an Update event, we need to compare the updated"
  },
  {
    "id" : "e4d40e59-7490-40f0-aa15-1510df5f7778",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "661cc6b3-4d4b-4692-8316-202968e6fc4b",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Updated the orphaning process to work in a queue/worker style. PTAL. \n",
        "createdAt" : "2016-05-19T17:09:53Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : 237,
    "diffHunk" : "@@ -1,1 +308,312 @@// the \"Orphan\" finalizer. The node is add back into the orphanQueue if any of\n// these steps fail.\nfunc (gc *GarbageCollector) orphanFinalizer() {\n\tkey, quit := gc.orphanQueue.Get()\n\tif quit {"
  },
  {
    "id" : "940ce09c-cc33-4c60-acf7-a7db07cbd67d",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d788ad5-e809-46f8-ab4f-4305b03c2f9b",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I would omit this loop and rely on your outer queue/retry thingy.\n",
        "createdAt" : "2016-05-20T23:47:57Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "a9635cd6-74d0-4a79-88d0-9486ba554090",
        "parentId" : "0d788ad5-e809-46f8-ab4f-4305b03c2f9b",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "A update operation can easily get false conflicts, so I let it retry immediately if the update fails with a conflict. If it's other kinds of error, I'll return error immediately and rely on the outer queue/retry thingy.\n",
        "createdAt" : "2016-05-22T05:28:27Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : null,
    "diffHunk" : "@@ -1,1 +265,269 @@func (gc *GarbageCollector) removeOrphanFinalizer(owner *node) error {\n\tconst retries = 5\n\tfor count := 0; count < retries; count++ {\n\t\townerObject, err := gc.getObject(owner.identity)\n\t\tif err != nil {"
  },
  {
    "id" : "cee0426a-29fc-4239-b00b-5e119249e428",
    "prId" : 25599,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08a98c29-63c4-4e57-91f0-3321baff5c62",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "`return`-- super important not to proceed until this step was successful\n",
        "createdAt" : "2016-05-20T23:50:18Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "98c7227e-293a-439f-bcbd-548932eb6603",
        "parentId" : "08a98c29-63c4-4e57-91f0-3321baff5c62",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Done.\n",
        "createdAt" : "2016-05-22T05:34:12Z",
        "updatedAt" : "2016-05-24T20:07:50Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "1665546d2d7ae2c15f35c038f26401322404884f",
    "line" : null,
    "diffHunk" : "@@ -1,1 +329,333 @@\tif err != nil {\n\t\tglog.V(6).Infof(\"orphanDependents for %s failed with %v\", owner.identity, err)\n\t\tgc.orphanQueue.Add(owner)\n\t\treturn\n\t}"
  },
  {
    "id" : "36a221be-d370-4422-89ae-445084abbefd",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "How will you prevent it from processing both batch/v1.Job and extensions/v1beta1.Job? This seems like a hard problem. Maybe we need to expose the cohabitating resources thingy somehow, or just the key under which we store things in etcd. Only one version of every object should be processed by the GC...\n",
        "createdAt" : "2016-04-21T00:24:48Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "a1333060-9388-4e16-928d-6076bd91d7a3",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "I think we need to add a field to the discovery API (strawman: `APIResource.ManagedbyGC`) to indicate if a resource should be managed by GC. Apart from marking the canonical version of Job, `APIResource.ManagedbyGC` can be used to indicate resources like \"v1/binding\" and \"extensions/v1beta1/replicationcontrollers\" are not managed by GC.\n",
        "createdAt" : "2016-04-26T04:04:48Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "55417409-2f25-41df-997d-973688e7a383",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "> Maybe we need to expose the cohabitating resources thingy somehow, or just the key under which we store things in etcd.\n\nI don't think we should leak the storage destinations or etcd keys into the API\n\n> I think we need to add a field to the discovery API (strawman: APIResource.ManagedbyGC) to indicate if a resource should be managed by GC. Apart from marking the canonical version of Job, APIResource.ManagedbyGC...\n\nSo jobs under extensions/v1beta1 would indicate they were not managed by GC, even though you could set owner references and finalizers on them, and GC would manage those jobs when they showed up under batch/v1? That seems really weird.\n",
        "createdAt" : "2016-04-26T04:19:52Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "7aa721f0-60c7-4c78-851a-4040e82ef28e",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "> So jobs under extensions/v1beta1 would indicate they were not managed by GC, even though you could set owner references and finalizers on them, and GC would manage those jobs when they showed up under batch/v1? That seems really weird.\n\nYeah, that's weird. How about adding a `APIResource.CanonicalGCResource`, which refers to the canonical version of the resource that is managed by GC? And if the field is empty, then GC won't manage the resource.\n\nOr, we can add two fields, `APIResource.CanonicalResource` referring the canonical version of a resource, and `APIResource.ManagedByGC` indicating if GC should manage this resource.\n",
        "createdAt" : "2016-04-26T04:32:52Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "63f4af76-a416-4524-bfc2-4ded7b66a1fe",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "We should be very careful about adding things to the discovery docs... they're unversioned and we don't get a second chance on additions.\n\nThe idea of a canonical resource could be useful, though it raises several questions:\n- do we always have enough information to know what the canonical resource is?\n- does that imply the canonical resource is always the superset?\n- as versions progress, would the canonical resource change to point to the newest version?\n- when the old versions aren't available via the API any longer, references to them would not be resolveable, even if the underlying object was still available (e.g. a reference to minion/v1beta3 wouldn't be traceable to node/v1 since minion/v1beta3 wouldn't be in the discovery doc any longer). Does that imply the relationship should go the other way (node/v1 could indicate it was a canonical resource of minion/v1beta3)?\n\nFor `ManagedByGC`, making resources declare controller-specific attributes seems inverted to me.\n",
        "createdAt" : "2016-04-26T04:51:26Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "1e6d2147-58cc-43d0-ba8d-813abcbd84c4",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "> when the old versions aren't available via the API any longer, references to them would not be resolveable, even if the underlying object was still available (e.g. a reference to minion/v1beta3 wouldn't be traceable to node/v1 since minion/v1beta3 wouldn't be in the discovery doc any longer). Does that imply the relationship should go the other way (node/v1 could indicate it was a canonical resource of minion/v1beta3)?\n\nI discussed with @lavalamp regarding this today. We had another primitive idea: we can add an endpoint to the API server, which will take a TypeMeta and/or ObjectMeta as input, and returns the URL for the resource or object. We could make the returned URL point to the canonical version. This feature would be needed by @krousey's work of simplifying kubectl code as well.\n\n> For ManagedByGC, making resources declare controller-specific attributes seems inverted to me.\n\nI'm suggesting adding such a field to the discovery API mainly because we have pluggable thirdparty API and federated API servers, both of which require dynamic ways to specify if GC should manage them. So far I don't have better ideas.\n",
        "createdAt" : "2016-04-26T19:09:28Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "48249835-592b-4f83-8c23-29e8350f40d1",
        "parentId" : "c690f810-9d88-4fc1-899f-9b6e31882c9d",
        "authorId" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "body" : "> We had another primitive idea: we can add an endpoint to the API server, which will take a TypeMeta and/or ObjectMeta as input, and returns the URL for the resource or object. We could make the returned URL point to the canonical version. This feature would be needed by @krousey's work of simplifying kubectl code as well.\n\nUsing `TypeMeta` to return a single URL doesn't seem right.  `TypeMeta` uses a `Kind` which can logically map to multiple `Resources`.  At best, such an API returns back an ordered list.\n\nEven if you create such an API, it doesn't given you  a \"canonical\" resource because you can end up with multiple distinct resources associated with the kind that each need to be garbage collected.\n\nI think we should be very careful about the cardinality assumptions we build in to avoid problems similar to the ones we've had with HPA.\n",
        "createdAt" : "2016-04-26T19:13:45Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +331,335 @@\t\tgc:         gc,\n\t}\n\tfor _, resource := range resources {\n\t\tif _, ok := ignoredResources[resource]; ok {\n\t\t\tglog.V(6).Infof(\"ignore resource %#v\", resource)"
  },
  {
    "id" : "b6aa90cd-f760-49c1-b069-95e43bbf7c4a",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bf43ce9-607d-4a0b-a7ec-bb9d1a1f3efa",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "need to check if the uid matches, if set in the owner reference\n",
        "createdAt" : "2016-04-26T04:25:44Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +453,457 @@\t\t}\n\t\towner, err := client.Resource(resource, item.identity.Namespace).Get(reference.Name)\n\t\tif err == nil {\n\t\t\tif owner.GetUID() != reference.UID {\n\t\t\t\tglog.V(6).Infof(\"object %s's owner %s/%s, %s is not found, UID mismatch\", item.identity.UID, reference.APIVersion, reference.Kind, reference.Name)"
  },
  {
    "id" : "6b22dc8c-7cb7-48d9-9ae9-0116e7dc4589",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c531e9b-7d2f-4fa7-8f73-2f10216d424a",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Document.\n",
        "createdAt" : "2016-05-06T22:24:43Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +244,248 @@// removing ownerReferences from the dependents if the owner is deleted with\n// DeleteOptions.OrphanDependents=true.\ntype GarbageCollector struct {\n\trestMapper meta.RESTMapper\n\tclientPool dynamic.ClientPool"
  },
  {
    "id" : "fe8066bc-ba51-45f0-b229-a14aa4a902e9",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62c13f58-d501-41d5-b508-a67fccd8e8d6",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "check this error?\n",
        "createdAt" : "2016-05-06T23:16:10Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +185,189 @@\t}\n\tobj := event.obj\n\taccessor, err := meta.Accessor(obj)\n\tif err != nil {\n\t\tutilruntime.HandleError(fmt.Errorf(\"cannot access obj: %v\", err))"
  },
  {
    "id" : "5003c2b8-d826-41b6-8ea3-4f80d82c53ec",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63745441-55e6-4042-9295-f53ad20ac420",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "missing return\n",
        "createdAt" : "2016-05-06T23:19:19Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +231,235 @@\tcase event.eventType == deleteEvent:\n\t\tif !found {\n\t\t\tglog.V(6).Infof(\"%v doesn't exist in the graph, this shouldn't happen\", accessor.GetUID())\n\t\t\treturn\n\t\t}"
  },
  {
    "id" : "1e039bd7-c121-4712-9043-6e92b5c1b355",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "401e5e0d-e0ed-4bc1-84af-b179c3b6ea43",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I'm worried that we're going to be keeping the contents of every object in the system in memory. Maybe you can construct the dynamic clients with a special codec which doesn't actually store the contents of the Unstructured objects, just the meta info?\n",
        "createdAt" : "2016-05-06T23:24:21Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "718f4d7d-33cf-426f-ba42-140ac223321b",
        "parentId" : "401e5e0d-e0ed-4bc1-84af-b179c3b6ea43",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "I did some rough math and I think storing metadata for everything shouldn't be an issue at the moment.\n",
        "createdAt" : "2016-05-06T23:28:17Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +253,257 @@\nfunc monitorFor(p *Propagator, clientPool dynamic.ClientPool, resource unversioned.GroupVersionResource) (monitor, error) {\n\t// TODO: consider store in one storage.\n\tglog.V(6).Infof(\"create storage for resource %s\", resource)\n\tvar monitor monitor"
  },
  {
    "id" : "266c47bf-9861-48a7-b810-00253425c360",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21f3c8c9-0cc6-42bb-84e1-62335ec63397",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "s/string/types.UID/?\n",
        "createdAt" : "2016-05-10T22:09:16Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +149,153 @@// when the number of references is small.\nfunc referencesDiffs(old []metatypes.OwnerReference, new []metatypes.OwnerReference) (added []metatypes.OwnerReference, removed []metatypes.OwnerReference) {\n\toldUIDToRef := make(map[string]metatypes.OwnerReference)\n\tfor i := 0; i < len(old); i++ {\n\t\toldUIDToRef[string(old[i].UID)] = old[i]"
  },
  {
    "id" : "d10560e2-863e-4b28-b9ec-5ba4570903ed",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ea327e6-e517-4d9b-b985-5d9d1784d04e",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Oh, I see. nvm.\n",
        "createdAt" : "2016-05-10T22:10:36Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +153,157 @@\t\toldUIDToRef[string(old[i].UID)] = old[i]\n\t}\n\toldUIDSet := sets.StringKeySet(oldUIDToRef)\n\tnewUIDToRef := make(map[string]metatypes.OwnerReference)\n\tfor i := 0; i < len(new); i++ {"
  },
  {
    "id" : "f26af799-029a-4a5a-b3b2-b02c28c90273",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1243e341-6843-4c86-8db9-a2c541da6e08",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "We may want to profile this function once everything else is working-- the naive N^2 algorithm is probably better when N is 1 or 2, since it doesn't need to allocate the maps.\n",
        "createdAt" : "2016-05-10T22:12:10Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "5c9b925f-06c6-48a7-a9b6-30d77c3c724d",
        "parentId" : "1243e341-6843-4c86-8db9-a2c541da6e08",
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "Right. I'll leave a todo.\n",
        "createdAt" : "2016-05-10T22:13:56Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +169,173 @@\t\tremoved = append(removed, oldUIDToRef[uid])\n\t}\n\treturn added, removed\n}\n"
  },
  {
    "id" : "31579d40-2945-434e-98f1-0624d84ccf64",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20365a41-d897-4709-b5a4-778604c5a695",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "@lavalamp actually I followed your suggestion and merged the two case.\n",
        "createdAt" : "2016-05-11T00:35:04Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : 201,
    "diffHunk" : "@@ -1,1 +199,203 @@\texistingNode, found := p.uidToNode[accessor.GetUID()]\n\tswitch {\n\tcase (event.eventType == addEvent || event.eventType == updateEvent) && !found:\n\t\tnewNode := &node{\n\t\t\tidentity: objectReference{"
  },
  {
    "id" : "b8125369-cab0-48d2-9426-a45915bb8be8",
    "prId" : 24509,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f9b08322-9650-4793-9337-89dded4c9721",
        "parentId" : null,
        "authorId" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "body" : "@lavalamp This function and the GraphHasUID function are used by the integration test. I don't want to expose them to users, do you have any suggestions?\n",
        "createdAt" : "2016-05-12T20:19:29Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "ca7e5a52-cab7-4f09-8ff8-da79f43339d4",
        "tags" : [
        ]
      },
      {
        "id" : "c02cc5a0-e9b9-4a52-88e3-dd70c7ad3646",
        "parentId" : "f9b08322-9650-4793-9337-89dded4c9721",
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Well, maybe you could make shut down block until the queues are completely\nempty?\n\nOn Thu, May 12, 2016 at 1:19 PM, Chao Xu notifications@github.com wrote:\n\n> In pkg/controller/garbagecollector/garbagecollector.go\n> https://github.com/kubernetes/kubernetes/pull/24509#discussion_r63089767\n> :\n> \n> > -       go monitor.controller.Run(stopCh)\n> > -   }\n> >   +\n> > -   // worker\n> > -   go wait.Until(gc.propagator.processEvent, 0, stopCh)\n> >   +\n> > -   for i := 0; i < workers; i++ {\n> > -       go wait.Until(gc.worker, 0, stopCh)\n> > -   }\n> > -   <-stopCh\n> > -   glog.Infof(\"Shutting down garbage collector\")\n> > -   gc.dirtyQueue.ShutDown()\n> > -   gc.propagator.eventQueue.ShutDown()\n> >   +}\n> >   +\n> >   +func (gc *GarbageCollector) QueuesDrained() bool {\n> \n> @lavalamp https://github.com/lavalamp This function and the GraphHasUID\n> function are used by the integration test. I don't want to expose them to\n> users, do you have any suggestions?\n> \n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/24509/files/510f27d865886e11fa8543d89e7c0609576aaac3#r63089767\n",
        "createdAt" : "2016-05-12T23:12:07Z",
        "updatedAt" : "2016-05-17T20:49:00Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cda99b8d7942c20e0242d6e5cf7564c30984615",
    "line" : null,
    "diffHunk" : "@@ -1,1 +489,493 @@// QueueDrained returns if the dirtyQueue and eventQueue are drained. It's\n// useful for debugging.\nfunc (gc *GarbageCollector) QueuesDrained() bool {\n\treturn gc.dirtyQueue.Len() == 0 && gc.propagator.eventQueue.Len() == 0\n}"
  }
]