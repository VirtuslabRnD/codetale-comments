[
  {
    "id" : "60b8224e-b0a0-4c36-aee0-8218db16a36d",
    "prId" : 93722,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/93722#pullrequestreview-461855534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1767234e-59e4-4352-9a21-9c0c29d52951",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "I'd like special attention on this change... the logged message explicitly called out the problematic behavior, so it seems like it was known, but it still seems incorrect to me.\r\n\r\nIf a pod infinitely tolerates all remaining taints on the node, I don't see why that should have different behavior than a node with no taints (for which we call cancelWorkWithEvent on line 348)",
        "createdAt" : "2020-08-05T16:54:47Z",
        "updatedAt" : "2020-08-05T18:25:45Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "1051e972-66cf-496a-8fab-c1189af311e1",
        "parentId" : "1767234e-59e4-4352-9a21-9c0c29d52951",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "original commit in https://github.com/kubernetes/kubernetes/pull/40355/files#diff-12d91ddb84ebd95c1ccaa6b5980108f6R337-R341, comments by @davidopp at https://github.com/kubernetes/kubernetes/pull/40355/files#r100682445\r\n\r\n> eviction that has not yet started gets moved later or canceled (e.g. eviction is added to the eviction queue, then pod is updated with larger tolerationSeconds for its soonest toleration, or all taints are removed from node) -- IIUC we do want to move the eviction later (or cancel it if removing all taints) in that case?\r\n\r\nI think \"removing all taints\" behavior should be equivalent to \"removing all taints except ones that are tolerated infinitely\"",
        "createdAt" : "2020-08-05T17:01:00Z",
        "updatedAt" : "2020-08-05T17:01:00Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "892bdf9a156251e0625f15857617719a0dd2c1e2",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +360,364 @@\tif minTolerationTime < 0 {\n\t\tklog.V(4).Infof(\"Current tolerations for %v tolerate forever, cancelling any scheduled deletion.\", podNamespacedName.String())\n\t\ttc.cancelWorkWithEvent(podNamespacedName)\n\t\treturn\n\t}"
  },
  {
    "id" : "c97e3dbd-5a5b-4097-b1b6-e4b98aa13635",
    "prId" : 79443,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79443#pullrequestreview-269256710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9715904e-1db3-4883-a9cb-199ff4365af1",
        "parentId" : null,
        "authorId" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "body" : "This now violates the contract as specified in the function comment.\r\n/hold",
        "createdAt" : "2019-07-31T20:16:10Z",
        "updatedAt" : "2019-08-05T17:45:35Z",
        "lastEditedBy" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "tags" : [
        ]
      }
    ],
    "commit" : "c811b2267f851043d731a8187133906aeccc78a9",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +131,135 @@// getMinTolerationTime returns minimal toleration time from the given slice, or -1 if it's infinite.\nfunc getMinTolerationTime(tolerations []v1.Toleration) time.Duration {\n\tminTolerationTime := int64(math.MaxInt64)\n\tif len(tolerations) == 0 {\n\t\treturn 0"
  },
  {
    "id" : "3b8cae63-3ab1-4d2f-a979-68b9af545930",
    "prId" : 79370,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79370#pullrequestreview-254532128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "badc4fd3-4df7-4a0d-ba68-0bfe4d62bc59",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "It's also critical that all updates from pods from a given node are processed by the same worker as the node itself (i.e. that update of a node and its pods are not being processed in parallel).\r\nCould you please add a comment like that? I guess somewhere here:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/controller/nodelifecycle/scheduler/taint_manager.go#L232",
        "createdAt" : "2019-06-26T11:00:47Z",
        "updatedAt" : "2019-06-26T11:36:38Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "98e9c78c132a6087b34e66229eb590cf2f2d5176",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +443,447 @@\t// getPodsAssignedToNode can be delayed as long as all future updates to pods will call\n\t// tc.PodUpdated which will use tc.taintedNodes to potentially delete delayed pods.\n\tpods, err := tc.getPodsAssignedToNode(node.Name)\n\tif err != nil {\n\t\tklog.Errorf(err.Error())"
  },
  {
    "id" : "35c803ee-22b1-4318-8159-e8954ab80fe4",
    "prId" : 67864,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/67864#pullrequestreview-150876246",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20c716f6-8ed5-409c-b37b-020761730963",
        "parentId" : null,
        "authorId" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "body" : "should this be a function of the number of nodes in the system ? ",
        "createdAt" : "2018-08-30T07:32:19Z",
        "updatedAt" : "2018-09-01T01:57:16Z",
        "lastEditedBy" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "tags" : [
        ]
      },
      {
        "id" : "8cfc9c51-5606-43c8-a229-046f523803eb",
        "parentId" : "20c716f6-8ed5-409c-b37b-020761730963",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I don't think it's really needed. In small clusters there will be very little work to do so it doesn't hurt much to have more workers.\r\nIdeally longer term it may depend on number of resource available for controller, but that's not needed now.",
        "createdAt" : "2018-08-30T07:57:11Z",
        "updatedAt" : "2018-09-01T01:57:16Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "85a19b109a048170c870bcb37817410c0c2607ca",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +47,51 @@\tNodeUpdateChannelSize = 10\n\t// UpdateWorkerSize defines the size of workers for node update or/and pod update.\n\tUpdateWorkerSize     = 8\n\tpodUpdateChannelSize = 1\n\tretries              = 5"
  },
  {
    "id" : "be69e413-c588-4db3-9277-c409cd4bfb72",
    "prId" : 65350,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/65350#pullrequestreview-166089312",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "026ef41e-9047-4f99-bef7-f31727fdca47",
        "parentId" : null,
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "Do we still need channel group? The performance of TaintNodeByCondition is acceptable by one channel.",
        "createdAt" : "2018-10-18T12:13:13Z",
        "updatedAt" : "2018-10-18T12:13:14Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "a4acaba2-3ac0-4e4f-b694-235a066ff735",
        "parentId" : "026ef41e-9047-4f99-bef7-f31727fdca47",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I would say \"now\".\r\nI think that once we will be able to bump default qps limits in large clusters, it may appear to be too slow. But yeah - it's mostly guessing...",
        "createdAt" : "2018-10-18T12:20:43Z",
        "updatedAt" : "2018-10-18T12:20:43Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "ca783717-1de9-429a-9e67-7b4556e1739c",
        "parentId" : "026ef41e-9047-4f99-bef7-f31727fdca47",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "TaintNodeByCondition is distributing a single update queue among multiple workers.\r\n\r\nThis has two update queues to coordinate, so the exact solution will look different. I think we can do something simpler than this two-layer async, but we need to do it in a way that still lets us fan out workers and give node update handling priority when handling pod update events.",
        "createdAt" : "2018-10-18T13:23:22Z",
        "updatedAt" : "2018-10-18T13:23:22Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9503c64f279ed551039ad41e351c8109df302a36",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +199,203 @@\n\tfor i := 0; i < UpdateWorkerSize; i++ {\n\t\ttc.nodeUpdateChannels = append(tc.nodeUpdateChannels, make(chan nodeUpdateItem, NodeUpdateChannelSize))\n\t\ttc.podUpdateChannels = append(tc.podUpdateChannels, make(chan podUpdateItem, podUpdateChannelSize))\n\t}"
  },
  {
    "id" : "1b702fec-bc25-481a-87a4-27327c57c899",
    "prId" : 64431,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/64431#pullrequestreview-124403680",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aefb8ee7-b638-4f3d-88d5-4ff54e77eae4",
        "parentId" : null,
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "Should we use `namespace/name` for pod? The nodename maybe changed from empty to some-host by bind.",
        "createdAt" : "2018-05-30T12:38:31Z",
        "updatedAt" : "2018-05-30T12:46:59Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      },
      {
        "id" : "cc2c001a-9467-433b-885e-a7945f78ab7c",
        "parentId" : "aefb8ee7-b638-4f3d-88d5-4ff54e77eae4",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "We want the pods to be processed by the same worker as their node is processed (to ensure that node updates are processed first).\r\n\r\nNote that pods that are not assigned yet are ignored later anyway:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/controller/nodelifecycle/scheduler/taint_manager.go#L346\r\n\r\nSo that is fine.\r\n",
        "createdAt" : "2018-05-30T12:49:37Z",
        "updatedAt" : "2018-05-30T12:49:37Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "f846b8b0-f5fd-4e33-b50a-ddbaa573ef78",
        "parentId" : "aefb8ee7-b638-4f3d-88d5-4ff54e77eae4",
        "authorId" : "72156db3-c40b-4455-9838-c12c0c606019",
        "body" : "OK to me :)",
        "createdAt" : "2018-05-30T13:31:13Z",
        "updatedAt" : "2018-05-30T13:31:14Z",
        "lastEditedBy" : "72156db3-c40b-4455-9838-c12c0c606019",
        "tags" : [
        ]
      }
    ],
    "commit" : "f7cf33e218b93da90e8051c51131b64843ca9cfc",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +71,75 @@}\n\nfunc (p *podUpdateItem) nodeName() string {\n\tif p.newPod != nil {\n\t\treturn p.newPod.Spec.NodeName"
  },
  {
    "id" : "18fad11c-ee8f-44ac-ace7-2960cf741b29",
    "prId" : 64431,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/64431#pullrequestreview-124386206",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9820ef13-8b85-453e-bf56-bf6f77575eab",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "That BTW is a fix for unit tests to make them use negligible amount of CPU instead of 10+ cores :)",
        "createdAt" : "2018-05-30T12:50:53Z",
        "updatedAt" : "2018-05-30T12:50:54Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "f7cf33e218b93da90e8051c51131b64843ca9cfc",
    "line" : 131,
    "diffHunk" : "@@ -1,1 +265,269 @@\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tcase nodeUpdate := <-tc.nodeUpdateChannels[worker]:\n\t\t\ttc.handleNodeUpdate(nodeUpdate)"
  },
  {
    "id" : "d2e63ff4-312e-4f57-a03a-f0988d84235c",
    "prId" : 57492,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/57492#pullrequestreview-86496544",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46f32db6-b530-4268-89ed-ac86a5413710",
        "parentId" : null,
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "why move these? usually std lib imports stick together",
        "createdAt" : "2018-01-03T21:27:31Z",
        "updatedAt" : "2018-01-04T20:54:27Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      }
    ],
    "commit" : "9187b343e17db2bf8f3470cd6e1ef7f661814c15",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +29,33 @@\t\"k8s.io/apimachinery/pkg/types\"\n\t\"sync\"\n\t\"time\"\n\n\t\"k8s.io/client-go/kubernetes/scheme\""
  }
]