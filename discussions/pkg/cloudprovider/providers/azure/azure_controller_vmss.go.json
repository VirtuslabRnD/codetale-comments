[
  {
    "id" : "7eab3a58-710c-408c-9626-2686b3ff7707",
    "prId" : 71495,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/71495#pullrequestreview-230455780",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7900ba3-9e00-4d80-ba31-6afa10978edc",
        "parentId" : null,
        "authorId" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "body" : "here is the PR for this dirty cache issue, originally whether succeed or not, this PR clean the cache anyway.\r\nI can move this clean cache operation `defer ss.vmssVMCache.Delete(key)` to conditions when only error happens, would that solve your issue @khenidak ?I can build one hot fix image if you wan to try this fix.\r\ncc@feiskyer \r\n\r\n\r\n",
        "createdAt" : "2019-04-25T05:30:46Z",
        "updatedAt" : "2019-04-25T05:30:47Z",
        "lastEditedBy" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "tags" : [
        ]
      }
    ],
    "commit" : "cd2930258c749372a11df8b5618d2db951233175",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +75,79 @@\t// Invalidate the cache right after updating\n\tkey := buildVmssCacheKey(nodeResourceGroup, ss.makeVmssVMName(ssName, instanceID))\n\tdefer ss.vmssVMCache.Delete(key)\n\n\tklog.V(2).Infof(\"azureDisk - update(%s): vm(%s) - attach disk(%s)\", nodeResourceGroup, nodeName, diskName)"
  },
  {
    "id" : "0237bb5a-6d85-424a-8277-ccccf557a517",
    "prId" : 59716,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59716#pullrequestreview-95644383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b91aa06-a52b-4555-bddc-08d85f2288f7",
        "parentId" : null,
        "authorId" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "body" : "this line is only different from Original `GetNextDiskLun`, I would encourage to combine these two different `GetNextDiskLun`",
        "createdAt" : "2018-02-11T06:41:17Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "tags" : [
        ]
      },
      {
        "id" : "3f388185-dd0d-457d-8959-7fb2887f4f34",
        "parentId" : "3b91aa06-a52b-4555-bddc-08d85f2288f7",
        "authorId" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "body" : "See https://github.com/kubernetes/kubernetes/pull/59716#issuecomment-364728621",
        "createdAt" : "2018-02-11T07:10:31Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbc871be3204425f10b4789b1f1ed73972159a89",
    "line" : 144,
    "diffHunk" : "@@ -1,1 +142,146 @@// GetDiskLun finds the lun on the host that the vhd is attached to, given a vhd's diskName and diskURI\nfunc (ss *scaleSet) GetDiskLun(diskName, diskURI string, nodeName types.NodeName) (int32, error) {\n\t_, _, vm, err := ss.getVmssVM(string(nodeName))\n\tif err != nil {\n\t\treturn -1, err"
  },
  {
    "id" : "cbd63150-3962-4b64-a8bd-86667c59a662",
    "prId" : 59716,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59716#pullrequestreview-95643777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0ef2a4f-637f-474c-b0f1-fe7b674377bc",
        "parentId" : null,
        "authorId" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "body" : "same as above",
        "createdAt" : "2018-02-11T06:41:41Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbc871be3204425f10b4789b1f1ed73972159a89",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +163,167 @@// return -1 if all luns are used\nfunc (ss *scaleSet) GetNextDiskLun(nodeName types.NodeName) (int32, error) {\n\t_, _, vm, err := ss.getVmssVM(string(nodeName))\n\tif err != nil {\n\t\treturn -1, err"
  },
  {
    "id" : "bb1908d7-fdb9-417f-909e-027250e09078",
    "prId" : 59716,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59716#pullrequestreview-95643777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b0b0f1e3-6cb9-4b21-b99c-92faf91e83c1",
        "parentId" : null,
        "authorId" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "body" : "same as above",
        "createdAt" : "2018-02-11T06:41:55Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "e0218e0a-9e55-43f5-8929-04673eea9015",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbc871be3204425f10b4789b1f1ed73972159a89",
    "line" : 192,
    "diffHunk" : "@@ -1,1 +190,194 @@\t}\n\n\t_, _, vm, err := ss.getVmssVM(string(nodeName))\n\tif err != nil {\n\t\tif err == cloudprovider.InstanceNotFound {"
  },
  {
    "id" : "2aff2fcc-d989-4d97-8670-3ab1bed24669",
    "prId" : 59716,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59716#pullrequestreview-95682693",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c2afc82-9f8d-4302-9092-fc01175608f2",
        "parentId" : null,
        "authorId" : "0c76e20f-41a5-4725-b3c3-d5b6cae89641",
        "body" : "We have to find a way to find if a VM is part of availability set or Scale Set. We can not try fail then retry. This information is either part of the VM/config/node label",
        "createdAt" : "2018-02-12T01:56:33Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "0c76e20f-41a5-4725-b3c3-d5b6cae89641",
        "tags" : [
        ]
      },
      {
        "id" : "de1d370c-b15b-488f-8d16-0ae5de817880",
        "parentId" : "7c2afc82-9f8d-4302-9092-fc01175608f2",
        "authorId" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "body" : "This is solved by availabilitySetNodesCache, which holds a list of VMs not managed by vmss.",
        "createdAt" : "2018-02-12T02:43:16Z",
        "updatedAt" : "2018-02-14T00:39:02Z",
        "lastEditedBy" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbc871be3204425f10b4789b1f1ed73972159a89",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +31,35 @@// AttachDisk attaches a vhd to vm\n// the vhd must exist, can be identified by diskName, diskURI, and lun.\nfunc (ss *scaleSet) AttachDisk(isManagedDisk bool, diskName, diskURI string, nodeName types.NodeName, lun int32, cachingMode compute.CachingTypes) error {\n\tssName, instanceID, vm, err := ss.getVmssVM(string(nodeName))\n\tif err != nil {"
  }
]