[
  {
    "id" : "77e40a77-6cd2-4092-b8ae-8052d0184174",
    "prId" : 74423,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74423#pullrequestreview-280435386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "@kad You mentioned [here](https://github.com/kubernetes/kubernetes/pull/80570#discussion_r317557836) that you would like to see the device plugin interface allow one to associate a single device with multiple NUMA nodes. \r\n\r\nCan you elaborate on the use case here. Also, would making this field a `repeated` field be sufficient for what you have in mind?",
        "createdAt" : "2019-08-26T12:30:20Z",
        "updatedAt" : "2019-08-26T12:30:20Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "bf950eb5-d251-43ab-a079-8dfdd6e670e4",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "body" : "I'm curious about this as well, as I can't think of a hardware device that connects to multiple NUMA nodes.\r\n\r\n(There's maybe a case for eventually representing higher-level topology like NVLink interconnect or something, but I think that'd need something more complicated than just a list of nodes here.)\r\n",
        "createdAt" : "2019-08-26T16:00:29Z",
        "updatedAt" : "2019-08-26T16:00:30Z",
        "lastEditedBy" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "tags" : [
        ]
      },
      {
        "id" : "670b011d-c608-40d2-9c7a-a6bb7d1884fb",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "My proposal for eventually supporting things like NVLINK are related to this:\r\nhttps://github.com/kubernetes/enhancements/pull/1121",
        "createdAt" : "2019-08-26T17:20:18Z",
        "updatedAt" : "2019-08-26T17:20:19Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "7a59e3ec-6d02-40f9-8e39-4f54cdf3e737",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "body" : "@klueska there are several scenarios: one example is technology in modern processors that is called sub-NUMA clustering. With it enabled, two memory controllers within one physical CPU started to be seen in Linux kernel as two separate NUMA nodes. For devices attached to PCI buses on this physical CPU, depending on device bandwidth,  this difference is almost negligible, so hint for this device would be to span across both of those NUMA nodes.\r\nAnother scenario is FPGA devices that are connected via non-PCI links to the CPUs (so they have direct access to the main memory), so alignment to the memory controller might be not so trivial as just single node.\r\n\r\nMaking it repeatable potentially could be good enough. So, zero instances of NUMANode might be seen \"unknown\" and one or more instances can be used to transform to `cpuset.mems` in future.",
        "createdAt" : "2019-08-26T20:57:44Z",
        "updatedAt" : "2019-08-26T20:57:44Z",
        "lastEditedBy" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "tags" : [
        ]
      },
      {
        "id" : "f469bf06-33f2-448a-bcf7-3216be165bc4",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Interesting. How is this exposed by the kernel? I.e. what are the contents of `/sys/bus/pci/devices/*/numa_node` in this case?",
        "createdAt" : "2019-08-26T21:32:51Z",
        "updatedAt" : "2019-08-26T21:32:51Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "7fcb233d-1388-4b9c-bde3-d9f599c3ff55",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "body" : "You mean FPGAs ? numa_node will have \"-1\".",
        "createdAt" : "2019-08-26T22:16:08Z",
        "updatedAt" : "2019-08-26T22:16:09Z",
        "lastEditedBy" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "tags" : [
        ]
      },
      {
        "id" : "d21fa054-e936-4480-8bd6-64dd6de2a474",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Ignoring FPGAs for a moment...\r\n\r\nI meant to say that a standard way of getting the NUMA association of a PCI device is from reading `/sys/bus/pci/devices/*/numa_node`. If the device now has two (or more) NUMA nodes associated with it, what is the recommended way to discover this?",
        "createdAt" : "2019-08-26T22:23:57Z",
        "updatedAt" : "2019-08-26T22:23:57Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "f9c9f7da-1c49-490e-935f-fe0fe1f45503",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "body" : "`local_cpulist`. It has better granularity and allows to align more precisely compared to single integer field `numa_node`. ",
        "createdAt" : "2019-08-26T22:38:07Z",
        "updatedAt" : "2019-08-26T22:38:07Z",
        "lastEditedBy" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "tags" : [
        ]
      },
      {
        "id" : "708d8804-9249-456e-99f0-ae09f988035c",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "body" : "@kad: looking at the linux kernel source, on a NUMA-aware system local_cpulist will always represent the CPUs of a single NUMA node.\r\n\r\n(Though it might in the future make sense for the kernel to change this on systems using sub-NUMA clustering.)",
        "createdAt" : "2019-08-26T22:57:42Z",
        "updatedAt" : "2019-08-26T23:01:10Z",
        "lastEditedBy" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "tags" : [
        ]
      },
      {
        "id" : "e60ba5bb-c7dd-4089-bd1d-a7f2e3678810",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "body" : "@cbf123 unless `dev_to_node(dev) == -1)`. And that usually a flag to device plugin to search hardware specific properties.",
        "createdAt" : "2019-08-27T07:06:05Z",
        "updatedAt" : "2019-08-27T07:06:06Z",
        "lastEditedBy" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "tags" : [
        ]
      },
      {
        "id" : "4137aaa1-00e1-47a0-9041-27437172bf2c",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Created: https://github.com/kubernetes/kubernetes/pull/82020",
        "createdAt" : "2019-08-27T14:21:05Z",
        "updatedAt" : "2019-08-27T14:21:05Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "979e5f96-2dfc-46d4-a4db-1531726c36d6",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "body" : "@kad In a kernel with CONFIG_NUMA enabled, if dev_to_node() returns -1, then local_cpulist will be \"all online CPUs\".  Which still doesn't help figure out which CPUs are \"near\" to the device.",
        "createdAt" : "2019-08-27T17:02:18Z",
        "updatedAt" : "2019-08-27T17:02:18Z",
        "lastEditedBy" : "f181934d-9b1f-41af-9c11-d9cf009ee92f",
        "tags" : [
        ]
      },
      {
        "id" : "a8e7efcd-b1dc-4faa-b8dc-8c7a52cdac77",
        "parentId" : "b3458392-f566-4c4a-ac35-d6822fea216d",
        "authorId" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "body" : "@cbf123 yes, but then it means that device plugin needs to use some other internal knowledge of the device or platform than just generic PCI sysfs entries. PCI is not the only one source of truth about real topology. E.g. for PMEM (persistent memory) will expose it via specific entry under something like this: `/sys/devices/LNXSYSTM:00/LNXSYBUS:00/ACPI0012:00/ndbus0/region1` and then that reported topology value should be transformed to node or cpulist, based on the mode in which memory controllers are operating now (e.g. depends on one or more \"nodes\" per physical CPU).\r\n\r\nAll in all, we are talking about interface for device plugin, and from kubelet stand point, it doesn't really matter from where device plugin gets the information. What matters is that DP sends a hint that will help to align other resources (CPUs, mems, other devices). One ideal example: device plugin can hint about usage of CPU cores with higher base frequency, in case where one \"NUMA node\" on a physical die has cores with different frequency/performance settings...\r\n\r\nIdeally, we should have ability for device plugins to expose both preferences on both `cpuset.cpus` and `cpuset.mems`, as in practice those two parameters depends on device's knowledge on what is critical resource: CPU-device or memory-device alignment, or both.\r\n\r\nBut that's longer story, let's get something minimal merged into k8s now, and then we will build up on it. And for things that we are defining now, let's have interfaces flexible enough to be able to extend it in the future. Like above optional/repeatable `NUMANode` (thanks @klueska) is better than single `int` that was in previous iteration.\r\n",
        "createdAt" : "2019-08-27T19:55:13Z",
        "updatedAt" : "2019-08-27T19:55:13Z",
        "lastEditedBy" : "659c7c1f-39ba-41a7-8331-fcc6b3b5f2fb",
        "tags" : [
        ]
      }
    ],
    "commit" : "674ecba935da543b80502f023640dfb226a8a642",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +75,79 @@\nmessage TopologyInfo {\n    \tNUMANode node = 1;\n}\n"
  },
  {
    "id" : "bdb2f1de-1dc4-4ee9-8895-6756c59d563d",
    "prId" : 60318,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60318#pullrequestreview-99075819",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b205f26-0513-4d8c-b4d6-08f6465f2bb7",
        "parentId" : null,
        "authorId" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "body" : "`GetDevicePluginOptionsRequest` and `GetDevicePluginOptionsResponse` ?",
        "createdAt" : "2018-02-23T19:55:18Z",
        "updatedAt" : "2018-02-24T00:15:24Z",
        "lastEditedBy" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "tags" : [
        ]
      },
      {
        "id" : "d41b88f2-bc6e-4eb7-8e2b-1776f515bfa7",
        "parentId" : "8b205f26-0513-4d8c-b4d6-08f6465f2bb7",
        "authorId" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "body" : "I was wondering about this but feel the chance we need to send extra information through this rpc seems quite low.",
        "createdAt" : "2018-02-23T22:47:28Z",
        "updatedAt" : "2018-02-24T00:15:24Z",
        "lastEditedBy" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "tags" : [
        ]
      }
    ],
    "commit" : "07beac600469a2551ba92f08c2cd20ea15d02f96",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +49,53 @@\t// GetDevicePluginOptions returns options to be communicated with Device\n        // Manager\n\trpc GetDevicePluginOptions(Empty) returns (DevicePluginOptions) {}\n\n\t// ListAndWatch returns a stream of List of Devices"
  },
  {
    "id" : "7814c3a3-0929-4181-b4b1-6558688fa6b7",
    "prId" : 60318,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60318#pullrequestreview-99090003",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7131fd72-cc85-4f9a-9bbd-3e6cbe7f1b35",
        "parentId" : null,
        "authorId" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "body" : "Since we are breaking the API should we call this RPC PodAdmit ?",
        "createdAt" : "2018-02-23T22:41:40Z",
        "updatedAt" : "2018-02-24T00:15:24Z",
        "lastEditedBy" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "tags" : [
        ]
      },
      {
        "id" : "8f006040-d3ce-464d-84e4-3accf7530491",
        "parentId" : "7131fd72-cc85-4f9a-9bbd-3e6cbe7f1b35",
        "authorId" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "body" : "Calling it PodAdmit may be a bit confusing since it is Kubelet side that does pod admission. On device plugin side, the operation is still mostly for device allocation.",
        "createdAt" : "2018-02-24T00:22:52Z",
        "updatedAt" : "2018-02-24T00:23:04Z",
        "lastEditedBy" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "tags" : [
        ]
      },
      {
        "id" : "52ecaeeb-bbc7-4a60-ba37-d35c81de795a",
        "parentId" : "7131fd72-cc85-4f9a-9bbd-3e6cbe7f1b35",
        "authorId" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "body" : "Ok lgtm",
        "createdAt" : "2018-02-24T00:26:50Z",
        "updatedAt" : "2018-02-24T00:26:50Z",
        "lastEditedBy" : "ac146833-f0d6-4680-968a-749269c0d55d",
        "tags" : [
        ]
      }
    ],
    "commit" : "07beac600469a2551ba92f08c2cd20ea15d02f96",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +106,110 @@// - Allocate allows Device Plugin to run device specific operations on\n//   the Devices requested\nmessage AllocateRequest {\n\trepeated ContainerAllocateRequest container_requests = 1;\n}"
  }
]