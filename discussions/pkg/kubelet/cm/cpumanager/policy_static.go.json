[
  {
    "id" : "cf99b5f4-6551-45f6-935d-1cf43fbf2b92",
    "prId" : 101432,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/101432#pullrequestreview-699173495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72dc2b42-768a-4fda-beb3-f4ba7026bbad",
        "parentId" : null,
        "authorId" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "body" : "This should be surrounded by the feature flag, right? There's no way to get the previous behaviour back otherwise.",
        "createdAt" : "2021-06-28T21:44:36Z",
        "updatedAt" : "2021-06-28T21:45:11Z",
        "lastEditedBy" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "tags" : [
        ]
      },
      {
        "id" : "764bbce8-00db-49df-8d10-e1a9bf262d2b",
        "parentId" : "72dc2b42-768a-4fda-beb3-f4ba7026bbad",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "We used to have a feature flag check but it was moved earlier in the flow (https://github.com/kubernetes/kubernetes/pull/101432/commits/91e6a8c4fbdd2bbbf607fc53e3fbf1fe705c4ff9). Once we are here, we can't possibly get the options (in the production code) unless we have the right set of feature flags.",
        "createdAt" : "2021-06-29T12:29:47Z",
        "updatedAt" : "2021-06-29T12:29:47Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "c8c7fe26-1400-4e58-8a59-00c9fe11e138",
        "parentId" : "72dc2b42-768a-4fda-beb3-f4ba7026bbad",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Agree with @fromanirh on the desired flow. All feature flag checks are done in the `containermanager`, with an empty set of options passed in if none are specified or the feature flag is turned off. This is consistent with how similar feature flags are treated for the topologymanager and devicemanager as well.",
        "createdAt" : "2021-07-05T13:31:55Z",
        "updatedAt" : "2021-07-05T13:32:35Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2fb8b00392a1bcf5c906dcddbf8d04247ddd85f",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +115,119 @@\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tklog.InfoS(\"Static policy created with configuration\", \"options\", opts)"
  },
  {
    "id" : "556fb903-752b-482a-b512-5e65908ba71c",
    "prId" : 101432,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/101432#pullrequestreview-699173495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2661a2d0-69a5-4dd5-8bc8-86b8358cce04",
        "parentId" : null,
        "authorId" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "body" : "Needs feature flag?",
        "createdAt" : "2021-06-28T21:44:49Z",
        "updatedAt" : "2021-06-28T21:45:11Z",
        "lastEditedBy" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "tags" : [
        ]
      },
      {
        "id" : "c55220fe-bae2-43da-b5b1-7a89a9340f8c",
        "parentId" : "2661a2d0-69a5-4dd5-8bc8-86b8358cce04",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "same as above",
        "createdAt" : "2021-06-29T12:29:53Z",
        "updatedAt" : "2021-06-29T12:29:54Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "4900957b-9c3a-4ae7-a294-9e010c48e085",
        "parentId" : "2661a2d0-69a5-4dd5-8bc8-86b8358cce04",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "ditto",
        "createdAt" : "2021-07-05T13:32:11Z",
        "updatedAt" : "2021-07-05T13:32:35Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2fb8b00392a1bcf5c906dcddbf8d04247ddd85f",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +252,256 @@\t\t// container belongs in an exclusively allocated pool\n\n\t\tif p.options.FullPhysicalCPUsOnly && ((numCPUs % p.topology.CPUsPerCore()) != 0) {\n\t\t\t// Since CPU Manager has been enabled requesting strict SMT alignment, it means a guaranteed pod can only be admitted\n\t\t\t// if the CPU requested is a multiple of the number of virtual cpus per physical cores."
  },
  {
    "id" : "0bb7bcb2-f1f1-4d62-af1b-c619df6c5980",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-473526408",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "So empty list will result in non-admission? Is it guaranteed?",
        "createdAt" : "2020-07-16T00:02:50Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "19770ba7-cf85-4711-9ffb-dbdcdf8c9b0f",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "not necessarily, an empty list will result in generating a hint with `NUMANodeAffinity: nil, Preferred: true`, which will be treated as \"no preference\". ",
        "createdAt" : "2020-07-21T07:56:09Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "ac038fdf-6493-4f80-bb17-9799a63da9df",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "An empty list is *not* treated as no-preference. In fact, it is exactly the opposite. It is treated as \"I *do* have a preference, but I was not able to generate any alignment hints\".\r\n\r\nPlease see:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/topologymanager/policy.go#L85\r\n\r\nFor all but the the best-effort policy, the topology manager will throw a pod-admission error in this case.",
        "createdAt" : "2020-07-22T12:19:09Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "9a76ca75-7cf0-4957-8f0c-2df64e6eed3d",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "As suggested above, ideally this should be added as a comment here. This knowledge is non-trivial.",
        "createdAt" : "2020-08-19T18:27:55Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "33bbc406-bff0-465d-9810-e9b3a3d7ff5a",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Alright, this is the comment I suggest:\r\n```\r\n// An empty list of hints will be treated as a preference that cannot be satisfied.\r\n// In definition of hints this is equal to: TopologyHint[NUMANodeAffinity: nil, Preferred: false].\r\n// For all but the best-effort policy, the Topology Manager will throw a pod-admission error. \r\nreturn map[string][]topologymanager.TopologyHint{\r\n\tstring(v1.ResourceCPU): {},\r\n}\r\n```",
        "createdAt" : "2020-08-20T12:16:11Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "417f850a-a0ba-48f9-8c54-5a7b3d009410",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "yep, this would explain the logic",
        "createdAt" : "2020-08-20T16:59:58Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "246f6062-8597-4f5b-9f9f-ec464b44e87f",
        "parentId" : "1721898a-e6c5-4427-942a-4c072fa6dd62",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Comment applied.",
        "createdAt" : "2020-08-24T14:10:27Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 149,
    "diffHunk" : "@@ -1,1 +409,413 @@\t\t\t\t// For all but the best-effort policy, the Topology Manager will throw a pod-admission error.\n\t\t\t\treturn map[string][]topologymanager.TopologyHint{\n\t\t\t\t\tstring(v1.ResourceCPU): {},\n\t\t\t\t}\n\t\t\t}"
  },
  {
    "id" : "2ebf72f8-216d-47c5-bedd-56a27ac0dba7",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-473526562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "Does this signify an error? Would it mean non-admittance? Why it's nil here and empty map in case of error below?",
        "createdAt" : "2020-07-16T00:22:46Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "0b2f2e26-9eb9-4d16-b926-8806abe25f19",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "It's not an error. If pod is not a Guaranteed QoS class pod `requestedByPod` will be equal to `0`, because function returns CPUs only when pod has that QoS class. \r\n\r\nreturning `nil` will be treated as providing hint `NUMANodeAffinity: nil, Preferred: false`, which can mean non-admission but it depends on the Topology Manager policy",
        "createdAt" : "2020-07-21T08:00:55Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "47756272-7910-49d1-a668-dcdc206d1e44",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "I can confirm that `nil` is what you want to return here. However, the interpretation of `nil` as `NUMANodeAffinity: nil, Preferred: false` is incorrect.\r\n\r\nThe topologymanager will actually treat this as a `NUMANodeAffinity: nil, Preferred: true` as shown here:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/topologymanager/policy.go#L71\r\n\r\nThis essentially translates to a `no preference`, which causes the topologymanager to ignore this resource as something that should be considered for alignment.",
        "createdAt" : "2020-07-22T12:13:58Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "7da28ae8-135e-41b0-acb8-0a7beddb13b2",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Yes, that is right, I even checked that before answering, however, I mixed it in the answer. Thanks for correcting",
        "createdAt" : "2020-07-22T14:50:13Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "d63c0a6b-f90d-4eeb-a639-de55b27344f4",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "would it benefit to leave a comment here? It's not easy to understand by looking at method code how `nil` is different from the empty collection below",
        "createdAt" : "2020-07-22T21:00:01Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "98afcee4-0d64-4e1b-84b9-0f9fb9f40304",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "52c1dc43-e977-4af3-9278-e5ff9cd02be2",
        "body" : "At the hint's perspective, `nil` means no-preference. So, pod does not have prefer resource and any resource can be allocated to the pod. But, in case of empty list `{ }`, the pod has preference and there is no resource that satisfies the preferences that pod wants.",
        "createdAt" : "2020-08-07T08:25:53Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "52c1dc43-e977-4af3-9278-e5ff9cd02be2",
        "tags" : [
        ]
      },
      {
        "id" : "01c9376d-93f4-497a-9d67-4dc861f0e1c8",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "I'd suggest to add comment next to return statement or in the description of the whole method what every return means. The knowledge that `nil` is so much different that empty collection is non-trivial and need to be explicit.",
        "createdAt" : "2020-08-19T18:26:58Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "af958ef0-9193-46b1-8cc2-98c37d0fabff",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Something like this for above code part is understandable and explanatory?\r\n```\r\n// Number of required CPUs by particular containers is not integer or a pod hasn't got a Guaranteed QoS class.\r\n// It will be treated by Topology Manager as having no preference and cause to ignore this\r\n// resource while considering a pod alignment.\r\n// In definition of hints this is equal to: TopologyHints[NUMANodeAffinity: nil, Preferred: true].\r\nif requestedByPod == 0 {\r\n\treturn nil\r\n}\r\n```",
        "createdAt" : "2020-08-20T12:24:45Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "4a7506b4-9871-49db-9fb8-06d11d4462ac",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "sounds great for me. I think having the comment will help to maintain code long term",
        "createdAt" : "2020-08-20T16:59:47Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "2ed64b05-9135-43c4-b4cd-9d8acbe11a27",
        "parentId" : "bbac2064-6a7d-4b5f-aa35-4b6205104890",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Comment applied.",
        "createdAt" : "2020-08-24T14:10:38Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +393,397 @@\t// In terms of hints, this is equal to: TopologyHints[NUMANodeAffinity: nil, Preferred: true].\n\tif requested == 0 {\n\t\treturn nil\n\t}\n"
  },
  {
    "id" : "e18f3391-1c8a-46c8-a6c5-ddb8b813582e",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-453248703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24250418-6aec-4f94-a055-f4891f734489",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "theoretically you can calculate `requestedByPod ` in this loop. Are the call to `guaranteedCPUs ` expensive to optimize for one loop?",
        "createdAt" : "2020-07-16T00:24:48Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "dbb66d7b-8347-49a6-bd3b-fdf339d8d853",
        "parentId" : "24250418-6aec-4f94-a055-f4891f734489",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "By keeping functions separate we can check in the beginning if pod is not in Guaranteed QoS and just skip it (checking if it already exists or has any resources allocated). \r\n\r\n> Are the call to guaranteedCPUs expensive to optimize for one loop?\r\nI don't think it is needed to optimize it for one loop.",
        "createdAt" : "2020-07-21T09:10:16Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      },
      {
        "id" : "2bd547e0-286e-43e1-b29a-81756ca3b2fb",
        "parentId" : "24250418-6aec-4f94-a055-f4891f734489",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "I agree. Having these separated has made it much easier for me to confirm the flow of the logic here. ",
        "createdAt" : "2020-07-22T12:15:09Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +397,401 @@\n\tassignedCPUs := cpuset.NewCPUSet()\n\tfor _, container := range append(pod.Spec.InitContainers, pod.Spec.Containers...) {\n\t\trequestedByContainer := p.guaranteedCPUs(pod, &container)\n\t\t// Short circuit to regenerate the same hints if there are already"
  },
  {
    "id" : "5dc4724a-96c5-4450-942d-011d8bdf8fad",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-469474968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "daee7ba1-2707-4588-ab22-8b39c1d8475f",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "I'll need to come back and do a closer pass on this function.\r\n\r\nSomething doesn't seem right between the code above this line and the code below this line, in terms of guaranteeing that the correct set of CPUs are considered when generating the hint. I can't put my finger on it right this minute though.",
        "createdAt" : "2020-07-22T12:32:58Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "51d4ee1f-8d97-4986-a379-263ccc619175",
        "parentId" : "daee7ba1-2707-4588-ab22-8b39c1d8475f",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "I think I understand what may seem to be strange:\r\n1. In the first part we check which CPUs are already allocated to containers that exist - `assignedCPUs`\r\n```\r\n        assignedCPUs := cpuset.NewCPUSet()\r\n\tfor _, container := range append(pod.Spec.InitContainers, pod.Spec.Containers...) {\r\n\t\trequested := p.guaranteedCPUs(pod, &container)\r\n\t\tif allocated, exists := s.GetCPUSet(string(pod.UID), container.Name); exists {\r\n\t\t\tif allocated.Size() != requested {\r\n\t\t\t\tklog.Errorf(\"[cpumanager] CPUs already allocated to (pod %v, container %v) with different number than request: requested: %d, allocated: %d\", format.Pod(pod), container.Name, requested, allocated.Size())\r\n\t\t\t\treturn map[string][]topologymanager.TopologyHint{\r\n\t\t\t\t\tstring(v1.ResourceCPU): {},\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tassignedCPUs = assignedCPUs.Union(allocated)\r\n\t\t}\r\n\t}\r\n\tif assignedCPUs.Size() == requestedByPod {\r\n\t\tklog.Infof(\"[cpumanager] Regenerating TopologyHints for CPUs already allocated to pod %v\", format.Pod(pod))\r\n\t\treturn map[string][]topologymanager.TopologyHint{\r\n\t\t\tstring(v1.ResourceCPU): p.generateCPUTopologyHints(assignedCPUs, cpuset.CPUSet{}, requestedByPod),\r\n\t\t}\r\n\t}\r\n```\r\n2. In the second part we gather hints for all required CPUs (including those in `assignedCPUs`)\r\n```\r\n// Get a list of available CPUs.\r\n\tavailable := p.assignableCPUs(s)\r\n\treusable := p.cpusToReuse[string(pod.UID)]\r\n\r\n\t// Generate hints.\r\n\tcpuHints := p.generateCPUTopologyHints(available, reusable, requestedByPod)\r\n```\r\nSo we look where we can fit the whole pod, without considering placement of resources from step 1. And this may be a problem only in situation where we would have some containers with already assigned resources and some of them without. However, I'm not aware of such scenario.\r\nI was wondering, is it possible that pod could be extended with a container requiring resources and wouldn't be recreated (something like ephemeral container)? \r\n\r\nOne way to avoid the above (possible?) issue would be to add those `assignedCPUs` to `reusable` (`reusable=reusable.Union(assignedCPUs)`). In this case we will end with AffinityMask aligned to previously assigned resources and also correct number of CPUs available will be taken under consideration. \r\n\r\n\r\n```\r\nfunc (p *staticPolicy) generateCPUTopologyHints(availableCPUs cpuset.CPUSet, reusableCPUs cpuset.CPUSet, request int) []topologymanager.TopologyHint {\r\n               ...\r\n                // Then check to see if all of the reusable CPUs are part of the bitmask.\r\n\t\tnumMatching := 0\r\n\t\tfor _, c := range reusableCPUs.ToSlice() {\r\n\t\t\t// Disregard this mask if its NUMANode isn't part of it.\r\n\t\t\tif !mask.IsSet(p.topology.CPUDetails[c].NUMANodeID) {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tnumMatching++\r\n\t\t}\r\n               ...\r\n}\r\n```",
        "createdAt" : "2020-08-18T13:50:21Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 164,
    "diffHunk" : "@@ -1,1 +424,428 @@\n\t// Get a list of available CPUs.\n\tavailable := p.assignableCPUs(s)\n\n\t// Get a list of reusable CPUs (e.g. CPUs reused from initContainers)."
  },
  {
    "id" : "fd047087-8f04-42fd-9a78-412d6750b8c5",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-504673326",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2553e07c-6669-4b96-9938-52ea1e1a0e26",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "The `GetTopologyHints()` has a code block here of:\r\n```\r\n    // If there are no CPU resources requested for this container, we do not\r\n    // generate any topology hints.\r\n    if _, ok := container.Resources.Requests[v1.ResourceCPU]; !ok {\r\n        return nil\r\n    }\r\n```\r\n\r\nI think this is redundant (since the following call to `p.guaranteedCPUs()` will account for this). For consistency, can you remove this as part of this PR?",
        "createdAt" : "2020-10-01T11:26:15Z",
        "updatedAt" : "2020-11-12T11:26:45Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "2064f99b-86e6-41c0-ac5f-75f6e8815b2a",
        "parentId" : "2553e07c-6669-4b96-9938-52ea1e1a0e26",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "It doesn't look like this was done either.",
        "createdAt" : "2020-10-06T10:24:44Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "b5c1be9b-fa8f-450a-b5e2-a1add7faf292",
        "parentId" : "2553e07c-6669-4b96-9938-52ea1e1a0e26",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "Checked and ensured it is done.",
        "createdAt" : "2020-10-08T11:12:46Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +384,388 @@}\n\nfunc (p *staticPolicy) GetPodTopologyHints(s state.State, pod *v1.Pod) map[string][]topologymanager.TopologyHint {\n\t// Get a count of how many guaranteed CPUs have been requested by Pod.\n\trequested := p.podGuaranteedCPUs(pod)"
  },
  {
    "id" : "31d19569-2bc7-480d-ae5a-a7234b4c8581",
    "prId" : 92967,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92967#pullrequestreview-504679832",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca17e405-745b-4065-8333-ff775e1c2312",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "I see, it looks like you \"fixed-up\" all of these white-space changes at the end with a run of `update-all.sh`.\r\nIn the future, it would be nice to not include these at all along the way, so that they are not seen at all when reviewing commit-by-commit.",
        "createdAt" : "2020-10-06T10:42:53Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "ef018bc3-a4dd-4ed1-ba05-fc463e75a97f",
        "parentId" : "ca17e405-745b-4065-8333-ff775e1c2312",
        "authorId" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "body" : "It was unnecessarily introduced in refactoring. I squashed white-space changes to original commits.",
        "createdAt" : "2020-10-08T11:21:48Z",
        "updatedAt" : "2020-11-12T11:26:46Z",
        "lastEditedBy" : "a1d73c29-275d-437e-b673-7957d6a4d943",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7714918db923523d98e6dd834f53b57a407acd0",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +378,382 @@\tcpuHints := p.generateCPUTopologyHints(available, reusable, requested)\n\tklog.Infof(\"[cpumanager] TopologyHints generated for pod '%v', container '%v': %v\", format.Pod(pod), container.Name, cpuHints)\n\n\treturn map[string][]topologymanager.TopologyHint{\n\t\tstring(v1.ResourceCPU): cpuHints,"
  },
  {
    "id" : "27f963b6-5c64-4ba9-84bf-e2f102d0de71",
    "prId" : 87759,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/87759#pullrequestreview-369160239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "386a8498-cc2f-4098-83b6-5882c18bfabb",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "this makes sense per the prior commit to ensure that init containers have cpusets that are exclusive only to life of the init container.",
        "createdAt" : "2020-02-20T22:20:22Z",
        "updatedAt" : "2020-02-27T16:10:17Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "c53a1d45-d931-408f-826b-dd060a87a42a",
        "parentId" : "386a8498-cc2f-4098-83b6-5882c18bfabb",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "This would only work if Pod admission is serialized. @derekwaynecarr can you confirm that this is the case?\r\n\r\nIf containers from two different pods are able to try and pull CPUs from this concurrently, then releasing them back into the shared pool won't work.",
        "createdAt" : "2020-02-25T13:48:40Z",
        "updatedAt" : "2020-02-27T16:10:17Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "5b74dd7e-97c3-41d7-9f89-3e53bc58512e",
        "parentId" : "386a8498-cc2f-4098-83b6-5882c18bfabb",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "each handler runs in sequence:\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kubelet.go#L1793\r\n\r\nall pod admission is handled in HandlePodAdditions call\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kubelet.go#L2070\r\n\r\nthe sync loop iteration is not asynch which is where all pod additions are called out from:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kubelet.go#L1894\r\n\r\n",
        "createdAt" : "2020-03-04T22:08:31Z",
        "updatedAt" : "2020-03-04T22:08:31Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "2327934a8602d2f0dad369a86c5475d27fc1b062",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +213,217 @@\t\t// Check if the container that has just been allocated resources is an init container.\n\t\t// If so, release its CPUs back into the shared pool so they can be reallocated.\n\t\tfor _, initContainer := range pod.Spec.InitContainers {\n\t\t\tif container.Name == initContainer.Name {\n\t\t\t\tif toRelease, ok := s.GetCPUSet(string(pod.UID), container.Name); ok {"
  },
  {
    "id" : "7869cbd4-f5d4-48ed-a4fb-34e58c626009",
    "prId" : 66718,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/66718#pullrequestreview-141828531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa9039c4-978d-4aa9-abae-7a3f2590dfe6",
        "parentId" : null,
        "authorId" : "8b309230-89cb-4a04-bf89-29a323dad0d8",
        "body" : "Could you please add a unit test for each case of this conditional? It should be possible to either extend the existing test for Start or create a new test for this validateState function.",
        "createdAt" : "2018-07-30T20:56:38Z",
        "updatedAt" : "2018-07-31T07:23:03Z",
        "lastEditedBy" : "8b309230-89cb-4a04-bf89-29a323dad0d8",
        "tags" : [
        ]
      },
      {
        "id" : "d5432468-2abe-46e8-b563-119a08b5cdc6",
        "parentId" : "fa9039c4-978d-4aa9-abae-7a3f2590dfe6",
        "authorId" : "931a9d14-ddc7-40c6-a3a5-d7d7c5157663",
        "body" : "I added two test cases now. The test where the amount of CPUs equals in state and topology was already present (\"non-corrupted state\"), so I just tested the cases where the number of CPUs doesn't match.",
        "createdAt" : "2018-07-31T07:25:01Z",
        "updatedAt" : "2018-07-31T07:25:01Z",
        "lastEditedBy" : "931a9d14-ddc7-40c6-a3a5-d7d7c5157663",
        "tags" : [
        ]
      }
    ],
    "commit" : "3bb5ca925733208c9a2749e186e531eef2d67595",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +159,163 @@\t}\n\tif !totalKnownCPUs.Equals(p.topology.CPUDetails.CPUs()) {\n\t\treturn fmt.Errorf(\"current set of available CPUs \\\"%s\\\" doesn't match with CPUs in state \\\"%s\\\"\",\n\t\t\tp.topology.CPUDetails.CPUs().String(), totalKnownCPUs.String())\n\t}"
  },
  {
    "id" : "e38293b8-1d09-45ce-8ab8-63284deaf301",
    "prId" : 54410,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/54410#pullrequestreview-78590423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8e42063-fe18-4de9-b5c9-27567beacf29",
        "parentId" : null,
        "authorId" : "06c8ba1e-f06e-4e0f-b9bd-1533747adc93",
        "body" : "Do we still need this `if` block?",
        "createdAt" : "2017-11-22T21:48:28Z",
        "updatedAt" : "2017-11-27T10:22:32Z",
        "lastEditedBy" : "06c8ba1e-f06e-4e0f-b9bd-1533747adc93",
        "tags" : [
        ]
      },
      {
        "id" : "4d852614-89d0-4263-9d45-72d5a772da4c",
        "parentId" : "a8e42063-fe18-4de9-b5c9-27567beacf29",
        "authorId" : "8b309230-89cb-4a04-bf89-29a323dad0d8",
        "body" : "Yes, this a semantic change in that Add must now be idempotent just like remove. @flyingcougar could you add a note about idempotency to the Policy interface for both Add and Remove?",
        "createdAt" : "2017-11-22T21:52:16Z",
        "updatedAt" : "2017-11-27T10:22:32Z",
        "lastEditedBy" : "8b309230-89cb-4a04-bf89-29a323dad0d8",
        "tags" : [
        ]
      },
      {
        "id" : "1adb09ad-c619-4ffc-af69-96f39faa1d05",
        "parentId" : "a8e42063-fe18-4de9-b5c9-27567beacf29",
        "authorId" : "06c8ba1e-f06e-4e0f-b9bd-1533747adc93",
        "body" : "I understand. However, the runtime will not call `AddContainer` for containers already in state. And after the panic PR merges, the reconcile loop should not be calling `AddContainer` on a container already in state (see: https://github.com/kubernetes/kubernetes/pull/54410/files#diff-67c46e7cbb41ea5e675000a3298e6b32R249). But I'm good with making it idempotent. ",
        "createdAt" : "2017-11-22T22:00:11Z",
        "updatedAt" : "2017-11-27T10:22:32Z",
        "lastEditedBy" : "06c8ba1e-f06e-4e0f-b9bd-1533747adc93",
        "tags" : [
        ]
      },
      {
        "id" : "dce0b2db-c74d-47b2-9791-a037c2c2ffce",
        "parentId" : "a8e42063-fe18-4de9-b5c9-27567beacf29",
        "authorId" : "dc057fa7-ae55-4b46-a679-e19975231dd7",
        "body" : "i think it will just prevent us from unnecessary calling 'AddContainer()' in `reconcile` for containers that are already in state.",
        "createdAt" : "2017-11-22T22:01:20Z",
        "updatedAt" : "2017-11-27T10:22:32Z",
        "lastEditedBy" : "dc057fa7-ae55-4b46-a679-e19975231dd7",
        "tags" : [
        ]
      },
      {
        "id" : "6d37a0f7-c6e1-44dc-b018-e2f30f2dbe90",
        "parentId" : "a8e42063-fe18-4de9-b5c9-27567beacf29",
        "authorId" : "dc057fa7-ae55-4b46-a679-e19975231dd7",
        "body" : "@ConnorDoyle  ok",
        "createdAt" : "2017-11-22T22:06:34Z",
        "updatedAt" : "2017-11-27T10:22:32Z",
        "lastEditedBy" : "dc057fa7-ae55-4b46-a679-e19975231dd7",
        "tags" : [
        ]
      }
    ],
    "commit" : "552e4d3a9ddb102bce50d4ddbad164880cf2f68c",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +161,165 @@\t\t// container belongs in an exclusively allocated pool\n\n\t\tif _, ok := s.GetCPUSet(containerID); ok {\n\t\t\tglog.Infof(\"[cpumanager] static policy: container already present in state, skipping (container: %s, container id: %s)\", container.Name, containerID)\n\t\t\treturn nil"
  }
]