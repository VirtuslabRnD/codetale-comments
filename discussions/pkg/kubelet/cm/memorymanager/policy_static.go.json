[
  {
    "id" : "4ed55377-80e1-45c2-8d8e-459b77ddef83",
    "prId" : 101030,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/101030#pullrequestreview-686352842",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2425d5b-23fd-4b3b-a2ab-a18a2dfaf479",
        "parentId" : null,
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "this is safe to be called concurrently, right?",
        "createdAt" : "2021-06-17T06:09:28Z",
        "updatedAt" : "2021-06-17T06:12:49Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      },
      {
        "id" : "5bb00ccb-420f-4f33-99e0-81a5703c9682",
        "parentId" : "c2425d5b-23fd-4b3b-a2ab-a18a2dfaf479",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "Yes, it has a lock inside of it\r\nhttps://github.com/kubernetes/kubernetes/blob/0abb908638dcea611253ed1dfc6d66e8b31d42d4/pkg/kubelet/cm/memorymanager/state/state_checkpoint.go#L103",
        "createdAt" : "2021-06-17T13:12:45Z",
        "updatedAt" : "2021-06-17T13:49:20Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "aa1ed71f-4b50-4031-b119-f68bfb3cae69",
        "parentId" : "c2425d5b-23fd-4b3b-a2ab-a18a2dfaf479",
        "authorId" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "body" : "And does a `Clone()`. So we're golden.",
        "createdAt" : "2021-06-17T14:03:35Z",
        "updatedAt" : "2021-06-17T14:03:35Z",
        "lastEditedBy" : "154a8533-a24d-4af9-81fb-0e2db0a9acf3",
        "tags" : [
        ]
      }
    ],
    "commit" : "681905706d43c91403bace725a600d35e02d59c1",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +772,776 @@func (p *staticPolicy) GetAllocatableMemory(s state.State) []state.Block {\n\tvar allocatableMemory []state.Block\n\tmachineState := s.GetMachineState()\n\tfor numaNodeID, numaNodeState := range machineState {\n\t\tfor resourceName, memoryTable := range numaNodeState.MemoryMap {"
  },
  {
    "id" : "2b13d7a6-a251-4e88-a920-4cae2f172a94",
    "prId" : 99640,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/99640#pullrequestreview-693971190",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54e3a998-d8b5-493b-88e9-ac87d9bdf6c1",
        "parentId" : null,
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "When / why are this affinities converted from a `bitmask.BitMask` type to an `[]int`? I ask because if they were still their original `bitmask` type, then you could just use `IsEqual()`:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/topologymanager/bitmask/bitmask.go#L135",
        "createdAt" : "2021-06-25T13:29:51Z",
        "updatedAt" : "2021-06-25T13:29:51Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "8291df3a-6312-4b24-9c56-4630b02fed34",
        "parentId" : "54e3a998-d8b5-493b-88e9-ac87d9bdf6c1",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "I used the `[]int` because the NUMA mask saved under the state file as `[]int`, I can convert it back to `BitMask`, but I unsure if it worth it because I have a number of places where I will need to do it.",
        "createdAt" : "2021-06-27T12:56:54Z",
        "updatedAt" : "2021-06-27T15:57:26Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "8978020c-9360-48cd-8ebe-edb57aa7be5b",
        "parentId" : "54e3a998-d8b5-493b-88e9-ac87d9bdf6c1",
        "authorId" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "body" : "Maybe keep this function, but implement the body of it as a conversion to `bitmask` and a call to `isEqual()`.",
        "createdAt" : "2021-06-28T13:03:22Z",
        "updatedAt" : "2021-06-28T13:03:22Z",
        "lastEditedBy" : "8eff55b7-2f52-4dd6-b8a6-b75a1c427179",
        "tags" : [
        ]
      },
      {
        "id" : "70ff49bd-59af-4883-b872-f22d6588fe41",
        "parentId" : "54e3a998-d8b5-493b-88e9-ac87d9bdf6c1",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "makes sense, will do it",
        "createdAt" : "2021-06-28T13:41:33Z",
        "updatedAt" : "2021-06-28T13:41:34Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb6d5b1f95a95fc877068223c3317d560369e2e2",
    "line" : 383,
    "diffHunk" : "@@ -1,1 +934,938 @@}\n\nfunc isNUMAAffinitiesEqual(numaAffinity1, numaAffinity2 []int) bool {\n\tbitMask1, err := bitmask.NewBitMask(numaAffinity1...)\n\tif err != nil {"
  },
  {
    "id" : "15a49da5-b265-470e-a512-c98cb6c31097",
    "prId" : 95479,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95479#pullrequestreview-537370573",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "parentId" : null,
        "authorId" : "6b615853-2f21-4512-b580-64f6789a6839",
        "body" : "so, it was kind of decided a year ago that Topology Alignment should not be tied to the QoS class of a Pod, see: https://github.com/kubernetes/kubernetes/pull/83492\r\n\r\nare we going back on this and placing an extra restriction just on memory alignment, and if yes, why?\r\n\r\n",
        "createdAt" : "2020-11-20T10:25:39Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "6b615853-2f21-4512-b580-64f6789a6839",
        "tags" : [
        ]
      },
      {
        "id" : "ee918f20-7e8b-4739-9028-e6d4138e3ada",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "It pretty the same for the CPU manager - https://github.com/kubernetes/kubernetes/blob/b2ecd1b3a3192fbbe2b9e348e095326f51dc43dd/pkg/kubelet/cm/cpumanager/policy_static.go#L220, and the reason that only for the guaranteed class you can reserve the exact amount of CPUs or memory. In general, it should not affect the topology manager, for all other QoS classes the hint will be nil, so from the topology manager every hint will be good for the hint provider.",
        "createdAt" : "2020-11-22T11:04:55Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "cb18da3b-cf81-43ee-b8fc-b0389fd07f2e",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "6b615853-2f21-4512-b580-64f6789a6839",
        "body" : "the reason while it makes sense in the CPU Manager to do that, is because exclusive CPU allocation, aka. the only resource managed by that component possibly needing NUMA alignment is already tied to the Guaranteed QoS class. if the Pod is not in Guaranteed QoS for sure it did not ask for exclusive CPUs, so for sure there is nothing to align, easy early return case\r\n\r\nthe allocation of hugepages on the other hand -the resources managed by this manager possibly needing NUMA alignment- is not tied to Guaranteed QoS class. the documentation states the following: \"Note that when requesting hugepage resources, either memory **or** CPU resources must be requested as well.\"\r\nEven the example Pod is not in the Guaranteed QoS class (https://kubernetes.io/docs/tasks/manage-hugepages/scheduling-hugepages/)\r\n\r\nso, applying the same restriction to a resource working differently goes against the intention of the PR I linked. the reason why that restriction was removed from the topology manager is because not all workloads requiring NUMA allocation asks for exclusive CPUs, or will be in the guaranteed QoS class. don't forget, topology manager manages three resource types. isn't it possible an app just wants hugepages, and devices?\r\n\r\nso, what is the functional reason behind having the restriction in place? if it was simply an assumption that it is needed based on the CPU manager code but there is no explicit reason to have it, IMO it should be removed from the code\r\nif the functional reason is to be able to early return in the majority of the use-case, just simply apply the logic -but not the code- of the CPU Manager early return case. \"does this Pod even have a possibly NUMA alignable resource I might need to take care of, or can I stop processing?\"\r\nunlike CPU Management verifying this doesn't require implicit guessing though. you could just literally check if hugepages were requested, and return if not",
        "createdAt" : "2020-11-23T10:00:04Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "6b615853-2f21-4512-b580-64f6789a6839",
        "tags" : [
        ]
      },
      {
        "id" : "12a929a4-e6fe-48af-ab34-f8d4316905b4",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "> so, what is the functional reason behind having the restriction in place? if it was simply an assumption that it is needed based on the CPU manager code but there is no explicit reason to have it, IMO it should be removed from the code\r\n> if the functional reason is to be able to early return in the majority of the use-case, just simply apply the logic -but not the code- of the CPU Manager early return case. \"does this Pod even have a possibly NUMA alignable resource I might need to take care of, or can I stop processing?\"\r\n> unlike CPU Management verifying this doesn't require implicit guessing though. you could just literally check if hugepages were requested, and return if not\r\n\r\nLike I wrote above, the main reason it only for guaranteed class we can calculate correctly the amount of reserved and free memory. Another reason, that only for the guaranteed containers we can guarantee the maximal density of containers, please see [link](https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/1769-memory-manager#simulation---how-the-memory-manager-works-by-examples).",
        "createdAt" : "2020-11-23T10:46:00Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "a732ce57-9c1a-4490-9b6d-0d51c31116ac",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "6b615853-2f21-4512-b580-64f6789a6839",
        "body" : "memory request = memory limits and Guaranteed QoS are not the same though, and that's my main issue\r\nGuaranteed QoS also means **CPU** requests and limits 1: exist 2: are equal\r\nTo clarify, I'm not worried about admittance. I'm worried about alignment. When you return nil to the Topology Manager in all non-guaranteed cases you also push all the Pods into preferred. And in some cases I really don't think that's correct\r\n\r\nLet's run it through an example. Take the case of a container having 5GB hugepages in both request and limit, and also asking for one Device in both requests and limits. This container won't be guaranteed because of the missing CPU request/limits, right?\r\nSo with the current code memory manager returns \"all NUMA are ok\", CPU manager returns \"all NUMA are ok\". Device Manager let's say returns \"NUMA [0,1] are ok\" because there are available Devices from these nodes. \r\n\r\nWhat happens in this case if memory in reality would be available from both nodes? The Pod is admitted even into a a single-NUMA policy node, and the memory will be assigned disjointed from the Device assignment, right? basically alignment will be up to luck, again, on a Node having single-numa policy where the requesting container rightfully expected to always get the memory and the Device from the same place\r\n\r\nif I'm wrong please feel free to correct me :) (for example in case assignment of memory is not gated behind QoS check, only the hint providing logic)\r\nif not, I understand the need to have a check, I only argue that that mem manager should not be checking Guaranteed QoS, but maybe could check request = limit purely for memory instead, without implicitly involving the CPU requests and limits checking via dragging Guaranteed QoS into the equation\r\nor maybe only gate hinting logic behind the QoS check, but not the memory assignment itself",
        "createdAt" : "2020-11-23T11:19:25Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "6b615853-2f21-4512-b580-64f6789a6839",
        "tags" : [
        ]
      },
      {
        "id" : "9a1ccee0-7499-4e68-9c02-02a832460a8b",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "A lot of thanks for the example, it totally makes sense. \r\n\r\nAn additional reason why we want to allocate memory only for guaranteed pods because we want to prevent additional OOM errors, for example, you run a lot of burstable and best-effort containers on the NUMA node 0, and you start an additional burstable container that has hugepages requests and limits equal, so the memory manager will check the memory reservation and will see that the NUMA node 0 has enough memory(we did not add previous container reservations because requests.hugepages != limits.hugepages) and will pin the container to the NUMA node 0, but it does not really have enough memory because it already consumed by previous containers and our new container can be killed because of the OOM(it has the same `oom_score_adj` as all other containers) and it can happen again and again. \r\n\r\nThe guaranteed container has a smaller `oom_score_adj` value(https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#node-oom-behavior) so it will be killed only after Burstable and Best-Efforts containers, but these containers can just be restarted on the different NUMA node(no pinning for them). \r\n\r\nI hope it will clarify why do we apply static policy logic to the guaranteed pods.",
        "createdAt" : "2020-11-23T14:43:30Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      },
      {
        "id" : "1e5d728e-9a17-4b9b-80eb-04fe06619225",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "6b615853-2f21-4512-b580-64f6789a6839",
        "body" : "yeah, this totally makes sense! thanks for the extra elaboration.\r\nthis way my -unfortunetaly not-so hypotethical- scenario would be still unaddressed, so I wonder if there is a way to reconcile the two and find a common working solution?\r\n\r\nMaybe:\r\n- setting/overwriting the OOM score of \"NUMA aligned containers\" regardless of their QoS class would solve the issue right? indeed,  it could result in the removal of other non-pinned containers from the same node but as you mentioned that is generally not seen as problematic, cause it would happen automatically\r\n- bookkeeping the hugepages **limits** of all containers, and make decisions based on that? it is kind of dimensioning for the worst-case, true, but something for something\r\n\r\nI'm totally fine discussing this outside the scope of this PR, but can we at least add this issue into the scope of the beta plan? just to sensure we spend some cycles thinking about it, maybe coming up with a configuration option if a generic allgorithm cannot be found etc.\r\n",
        "createdAt" : "2020-11-23T16:06:39Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "6b615853-2f21-4512-b580-64f6789a6839",
        "tags" : [
        ]
      },
      {
        "id" : "aae046b5-26ad-4b7e-a2bc-810ebe02753a",
        "parentId" : "834f489f-bd34-4421-b900-b08df124bc5c",
        "authorId" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "body" : "@Levovar Totally makes sense, let's continue the discussion under the [document](https://docs.google.com/document/d/1FHvJgleXkyIWiWfntbneF-cYdms7sJ2SiDj3yfRfqXA/edit#heading=h.fhko4rmz59bh)\r\n",
        "createdAt" : "2020-11-24T10:52:10Z",
        "updatedAt" : "2021-02-08T23:22:50Z",
        "lastEditedBy" : "b15151c4-81af-487d-8c8f-a4f39690bd34",
        "tags" : [
        ]
      }
    ],
    "commit" : "102124464a994946e151c976775cf751423b14f7",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +87,91 @@func (p *staticPolicy) Allocate(s state.State, pod *v1.Pod, container *v1.Container) error {\n\t// allocate the memory only for guaranteed pods\n\tif v1qos.GetPodQOS(pod) != v1.PodQOSGuaranteed {\n\t\treturn nil\n\t}"
  }
]