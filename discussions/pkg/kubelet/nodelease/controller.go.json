[
  {
    "id" : "03369b7e-88f2-4571-b2fb-5d054a614a1e",
    "prId" : 84998,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/84998#pullrequestreview-315749079",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d914f8b9-7d3a-475c-8f31-6f2dcabc76a0",
        "parentId" : null,
        "authorId" : "4186ed58-9575-4126-b730-073268bc67cb",
        "body" : "If we want to ensure a new lease always have OwnerReferences, should we do it in newLease() and return \"missing owner ref\" error in such case?",
        "createdAt" : "2019-11-12T18:15:55Z",
        "updatedAt" : "2019-11-12T18:16:08Z",
        "lastEditedBy" : "4186ed58-9575-4126-b730-073268bc67cb",
        "tags" : [
        ]
      },
      {
        "id" : "417fc0b0-fe32-4503-a983-4a76171c8157",
        "parentId" : "d914f8b9-7d3a-475c-8f31-6f2dcabc76a0",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "I was thinking about that, but that would be much more invasive change (despite the first glance, the flow is non-trivial). I wanted to avoid making significant rewrite on the last moment before code-freeze.\r\nAlso note that if we create the Lease correctly, we will be fine (assuming noone will remove it, but that could cause issues anyway, because the node may be deleted in the meantime, so protecting against it is not the goal).\r\n\r\nSo I actually think the current approach is the best tradeoff between simplicity of code-changes and the goal to achieve.",
        "createdAt" : "2019-11-12T18:23:19Z",
        "updatedAt" : "2019-11-12T18:23:20Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "525b3ec6-3d2a-493f-9fa0-c19672f0b211",
        "parentId" : "d914f8b9-7d3a-475c-8f31-6f2dcabc76a0",
        "authorId" : "4186ed58-9575-4126-b730-073268bc67cb",
        "body" : "ACK",
        "createdAt" : "2019-11-12T18:29:00Z",
        "updatedAt" : "2019-11-12T18:29:00Z",
        "lastEditedBy" : "4186ed58-9575-4126-b730-073268bc67cb",
        "tags" : [
        ]
      }
    ],
    "commit" : "07200a0764271af5fa9199305089e79475c409e5",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +148,152 @@\t\tleaseToCreate := c.newLease(nil)\n\t\tif len(leaseToCreate.OwnerReferences) == 0 {\n\t\t\t// We want to ensure that a lease will always have OwnerReferences set.\n\t\t\t// Thus, given that we weren't able to set it correctly, we simply\n\t\t\t// not create it this time - we will retry in the next iteration."
  },
  {
    "id" : "5d538c49-9422-4822-9c91-f5eb7b7ca4f7",
    "prId" : 81663,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/81663#pullrequestreview-278543276",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "377b7130-37f2-4d39-a15e-9b4f28d79511",
        "parentId" : null,
        "authorId" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "body" : "if err := c.retryUpdateLease(c.newLease(c.latestLease)); err == nil {\r\n  return \r\n}",
        "createdAt" : "2019-08-22T11:15:02Z",
        "updatedAt" : "2019-08-22T11:15:03Z",
        "lastEditedBy" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "tags" : [
        ]
      },
      {
        "id" : "2a2cfd8d-3d10-4606-8fa4-0bcb2a0fe1c1",
        "parentId" : "377b7130-37f2-4d39-a15e-9b4f28d79511",
        "authorId" : "c67fd0c8-b4a0-45e6-b808-28edbb7bc636",
        "body" : "In this case, the `err` would be undefined in the klog.",
        "createdAt" : "2019-08-22T11:37:20Z",
        "updatedAt" : "2019-08-22T11:37:39Z",
        "lastEditedBy" : "c67fd0c8-b4a0-45e6-b808-28edbb7bc636",
        "tags" : [
        ]
      },
      {
        "id" : "992830f6-5ee1-41c8-ad4a-16ccf87dbb62",
        "parentId" : "377b7130-37f2-4d39-a15e-9b4f28d79511",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "For logging purposes below - I agree.",
        "createdAt" : "2019-08-22T11:56:29Z",
        "updatedAt" : "2019-08-22T11:56:29Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "6d6aa3e7-5253-4912-9651-e7db5804bb46",
        "parentId" : "377b7130-37f2-4d39-a15e-9b4f28d79511",
        "authorId" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "body" : "ok, LTGM",
        "createdAt" : "2019-08-22T16:29:50Z",
        "updatedAt" : "2019-08-22T16:29:50Z",
        "lastEditedBy" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "tags" : [
        ]
      }
    ],
    "commit" : "7773662b6a97877b0b143052717283906b524c31",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +99,103 @@\t\t// can result in performance degradation, because we will end up with calling additional\n\t\t// GET/PUT - at this point this whole \"if\" should be removed.\n\t\terr := c.retryUpdateLease(c.newLease(c.latestLease))\n\t\tif err == nil {\n\t\t\treturn"
  },
  {
    "id" : "a832c620-2598-43e9-b8bd-801817f498ea",
    "prId" : 81174,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/81174#pullrequestreview-273075124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bdc49a8c-d81b-4618-94f6-d0c78ead994a",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "This has certain assumptions, i.e. the net result will be much worse if there would be another component frequently updating that lease object too.\r\nhttps://github.com/kubernetes/enhancements/pull/1116 is one proposal that will change that (though the updates to lease object by the controller would be very rare and shouldn't really matter).\r\n\r\nSo basically, this seems reasonable to me in the current state, but requires extensive comment about assumptions.\r\nSomething like:\r\n```\r\n// As long as node lease is not (or very rarely) updated by any other agent that Kubelet,\r\n// we can optimistically assume it didn't change since our last update and try updating\r\n// based on the version from that time. Thanks to it we avoid GET call and reduce load\r\n// on etcd and kube-apiserver.\r\n// If at some point other agents will also be frequently updating the Lease object, this\r\n// can result in performance degradation, because we will end up with calling additional\r\n// PUT - at this point this whole \"if\" should be removed.",
        "createdAt" : "2019-08-09T07:56:29Z",
        "updatedAt" : "2019-08-09T11:01:03Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "17fc4326-4e9f-4b6b-9d2d-fa0d871d093d",
        "parentId" : "bdc49a8c-d81b-4618-94f6-d0c78ead994a",
        "authorId" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "body" : "thanks, done",
        "createdAt" : "2019-08-09T11:02:23Z",
        "updatedAt" : "2019-08-09T11:02:23Z",
        "lastEditedBy" : "f3e672e5-b55c-4e3f-9443-b9abf25195da",
        "tags" : [
        ]
      }
    ],
    "commit" : "acdac6e9995e2b920cb525ca2f090567b8c5d91d",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +99,103 @@\t\t// can result in performance degradation, because we will end up with calling additional\n\t\t// GET/PUT - at this point this whole \"if\" should be removed.\n\t\tlease, err := c.leaseClient.Update(c.newLease(c.latestLease))\n\t\tif err == nil {\n\t\t\tc.latestLease = lease"
  },
  {
    "id" : "4ff4f09a-3cc2-4ee1-9f83-bab84065d428",
    "prId" : 79341,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/79341#pullrequestreview-255024525",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "874c77f0-5319-45cd-ac87-bc6e6e872752",
        "parentId" : null,
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "Much better now - thanks.",
        "createdAt" : "2019-06-27T06:19:20Z",
        "updatedAt" : "2019-06-27T11:44:28Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d45197a8b0fe1961a074b9774bafa1ad36aa99f8",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +155,159 @@\t\t\tbase, _ = c.backoffEnsureLease()\n\t\t\tcontinue\n\t\t}\n\t\tif i > 0 && c.onRepeatedHeartbeatFailure != nil {\n\t\t\tc.onRepeatedHeartbeatFailure()"
  },
  {
    "id" : "5d4a5724-b4a1-48f4-8ae8-cc642ddaf145",
    "prId" : 66257,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/66257#pullrequestreview-138017163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "218b6d96-886a-4cac-b536-44b24af4daed",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "is this working today in a test cluster with authz enabled? I expected to see modifications to the Node authorizer and NodeRestriction admission plugin to let kubelets mess with their own leases",
        "createdAt" : "2018-07-17T20:35:06Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "3a7ad566-abff-4f96-89b9-90a57c3563d6",
        "parentId" : "218b6d96-886a-4cac-b536-44b24af4daed",
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "Good point, I forgot about that. I will add those changes to this PR, and it probably makes sense to ensure the e2e test also runs in the standard e2e suite, instead of just the e2e node suite.\r\n\r\nWe also don't currently run the node authorizer/node restriction in the e2e node tests. Maybe I should revisit https://github.com/kubernetes/kubernetes/pull/60172?\r\n",
        "createdAt" : "2018-07-17T21:02:04Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b7d06e025fef842a4323d786ad80507f509dcd2",
    "line" : 126,
    "diffHunk" : "@@ -1,1 +124,128 @@\tif apierrors.IsNotFound(err) {\n\t\t// lease does not exist, create it\n\t\tlease, err := c.client.Create(c.newLease(nil))\n\t\tif err != nil {\n\t\t\treturn nil, false, err"
  },
  {
    "id" : "a16b790b-7827-4839-8690-ffe99220dd14",
    "prId" : 66257,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/66257#pullrequestreview-139261629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "parentId" : null,
        "authorId" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "body" : "Do these client calls include a request timeout?",
        "createdAt" : "2018-07-17T20:49:35Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "tags" : [
        ]
      },
      {
        "id" : "a0ec72e7-7eac-43d9-b59c-6f9a946fb36b",
        "parentId" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "heartbeatClient is explicitly constructed with a timeout to avoid eternal hangs, and a distinct QPS to avoid starvation by other kube API calls, but is currently fixed to corev1. need to adapt/widen that for use here",
        "createdAt" : "2018-07-17T21:01:01Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "bc496ee7-251b-415d-a731-929bf493d012",
        "parentId" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "I believe that is configured on the client before it is passed to the controller.",
        "createdAt" : "2018-07-17T21:03:17Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      },
      {
        "id" : "22202925-4436-446a-b8ae-fe8bc70f3a71",
        "parentId" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "If we want the timeout to match the heartbeat frequency, then we need a distinct client, since the Lease-based heartbeat potentially has a different frequency than the node status update, right?",
        "createdAt" : "2018-07-17T21:38:51Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      },
      {
        "id" : "524545ba-efd8-449f-a537-aa03b223167e",
        "parentId" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "Taking the shorter of the two would probably be fine",
        "createdAt" : "2018-07-17T21:47:30Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "8a6bc4ec-28d3-40de-894b-cd28464d242e",
        "parentId" : "a65d1d96-4a71-4c32-90d2-e238f901f13d",
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "done",
        "createdAt" : "2018-07-21T15:49:46Z",
        "updatedAt" : "2018-08-26T23:03:47Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b7d06e025fef842a4323d786ad80507f509dcd2",
    "line" : 126,
    "diffHunk" : "@@ -1,1 +124,128 @@\tif apierrors.IsNotFound(err) {\n\t\t// lease does not exist, create it\n\t\tlease, err := c.client.Create(c.newLease(nil))\n\t\tif err != nil {\n\t\t\treturn nil, false, err"
  },
  {
    "id" : "2c1ab14f-90ec-4366-b2b1-278aab4faee0",
    "prId" : 66257,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/66257#pullrequestreview-147761435",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a74872a5-6258-4fa8-b7a9-2a250d5ff5ec",
        "parentId" : null,
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "I know this is copied from `retryUpdateNodeStatus`, but just FYI, we've found before that there were multiple layers of retries..and that was probably unnecessary.  https://github.com/kubernetes/node-problem-detector/issues/124#issuecomment-311449714",
        "createdAt" : "2018-07-17T23:57:27Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      },
      {
        "id" : "0083c7a4-7fd8-48d6-98bf-4c232ecd4058",
        "parentId" : "a74872a5-6258-4fa8-b7a9-2a250d5ff5ec",
        "authorId" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "body" : "Noted. Is the client advanced enough now for us to remove onRepeatedHeartbeatFailure too?\r\n@liggitt?",
        "createdAt" : "2018-07-21T15:48:54Z",
        "updatedAt" : "2018-08-26T23:03:47Z",
        "lastEditedBy" : "881df817-68e6-43dd-b4ea-f0b973f7dc41",
        "tags" : [
        ]
      },
      {
        "id" : "34bfcf26-29be-448c-93ae-71b2af7895b4",
        "parentId" : "a74872a5-6258-4fa8-b7a9-2a250d5ff5ec",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "No. That is required to force close dead TCP connections. ",
        "createdAt" : "2018-07-21T16:13:22Z",
        "updatedAt" : "2018-08-26T23:03:47Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "1487972d-3444-4568-a0e8-9306c4b77c3a",
        "parentId" : "a74872a5-6258-4fa8-b7a9-2a250d5ff5ec",
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "Maybe we can lower the `maxUpdateRetries` later in a separate PR.",
        "createdAt" : "2018-08-20T20:28:34Z",
        "updatedAt" : "2018-08-26T23:03:47Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b7d06e025fef842a4323d786ad80507f509dcd2",
    "line" : 141,
    "diffHunk" : "@@ -1,1 +139,143 @@// retryUpdateLease attempts to update the lease for maxUpdateRetries,\n// call this once you're sure the lease has been created\nfunc (c *controller) retryUpdateLease(base *coordv1beta1.Lease) {\n\tfor i := 0; i < maxUpdateRetries; i++ {\n\t\t_, err := c.client.Update(c.newLease(base))"
  },
  {
    "id" : "2c690884-9dc2-4b4e-b3c7-9f1780dc3ef9",
    "prId" : 66257,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/66257#pullrequestreview-138040423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f11a4dc-0b89-4828-8a4c-28104a15c949",
        "parentId" : null,
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "Is OwnerReference going to be added in follow-up PR, or a different mechanism will be used to ensure the leases are cleaned up?",
        "createdAt" : "2018-07-17T23:59:51Z",
        "updatedAt" : "2018-08-26T23:03:46Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b7d06e025fef842a4323d786ad80507f509dcd2",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +168,172 @@\tlease.Spec.LeaseDurationSeconds = pointer.Int32Ptr(c.leaseDurationSeconds)\n\tlease.Spec.RenewTime = &metav1.MicroTime{Time: c.clock.Now()}\n\treturn lease\n}\n"
  }
]