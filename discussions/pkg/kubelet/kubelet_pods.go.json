[
  {
    "id" : "d9262575-89eb-4a6c-bb85-d23bf71f7f5c",
    "prId" : 103434,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/103434#pullrequestreview-702396872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd20b65a-fb8f-4db4-8a0b-bec4fa31878b",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "the grammar of this sentence may need work. Unrelated to this PR",
        "createdAt" : "2021-07-08T18:50:17Z",
        "updatedAt" : "2021-07-08T18:50:17Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e2b728c68ac5fb15a53b0acdad3e348419b8ffa",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +146,150 @@// - if it is Windows and ContainerD is used.\n// Kubernetes will not mount /etc/hosts if:\n// - when the Pod sandbox is being created, its IP is still unknown. Hence, PodIP will not have been set.\n// - Windows pod contains a hostProcess container\nfunc shouldMountHostsFile(pod *v1.Pod, podIPs []string, supportsSingleFileMapping bool) bool {"
  },
  {
    "id" : "96955f17-ca17-4668-8536-f523fc7be129",
    "prId" : 103307,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/103307#pullrequestreview-700420366",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a197ae6c-c68b-41a5-ace5-4b1603644a30",
        "parentId" : null,
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "Don't you want `make([]string, 0, len(podStatus.IPs))` ?  Set capacity not size?",
        "createdAt" : "2021-07-06T20:33:55Z",
        "updatedAt" : "2021-07-06T20:33:55Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "7d524c98-dd36-4068-a0b0-8e7c1dc5d693",
        "parentId" : "a197ae6c-c68b-41a5-ace5-4b1603644a30",
        "authorId" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "body" : "I did wrong the `for` loop to copy, it should not be an `append` it should set the `ip` directly",
        "createdAt" : "2021-07-06T22:09:41Z",
        "updatedAt" : "2021-07-06T22:09:41Z",
        "lastEditedBy" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7469cf680453df35a674d0cb686643fee4ce3d5",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +1616,1620 @@\n\t// copy pod status IPs to avoid race conditions with PodStatus #102806\n\tpodIPs := make([]string, len(podStatus.IPs))\n\tfor j, ip := range podStatus.IPs {\n\t\tpodIPs[j] = ip"
  },
  {
    "id" : "850f2789-f898-48e4-8cda-b09c39b06aad",
    "prId" : 103307,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/103307#pullrequestreview-700463820",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bce011aa-2b93-4fee-92d8-b01eb5a987d2",
        "parentId" : null,
        "authorId" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "body" : "is there some subtle golang thing that disallow this?",
        "createdAt" : "2021-07-06T22:24:28Z",
        "updatedAt" : "2021-07-06T22:24:44Z",
        "lastEditedBy" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "tags" : [
        ]
      },
      {
        "id" : "852beb47-c4c2-448e-b454-155f5215aafb",
        "parentId" : "bce011aa-2b93-4fee-92d8-b01eb5a987d2",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "I don't know - is something not working?",
        "createdAt" : "2021-07-06T22:39:15Z",
        "updatedAt" : "2021-07-06T22:39:15Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "3d69ce4f-81e1-48fa-adc8-aec78f0c96d3",
        "parentId" : "bce011aa-2b93-4fee-92d8-b01eb5a987d2",
        "authorId" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "body" : "it does work, I just pass the slice as argument and override the same variable with the output, I think is fine, but I just wanted to double check",
        "createdAt" : "2021-07-06T23:48:57Z",
        "updatedAt" : "2021-07-06T23:48:57Z",
        "lastEditedBy" : "203dfb85-d185-4057-88b3-a1b4f09fd1fd",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7469cf680453df35a674d0cb686643fee4ce3d5",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +1622,1626 @@\n\t// make podIPs order match node IP family preference #97979\n\tpodIPs = kl.sortPodIPs(podIPs)\n\tfor _, ip := range podIPs {\n\t\tapiPodStatus.PodIPs = append(apiPodStatus.PodIPs, v1.PodIP{IP: ip})"
  },
  {
    "id" : "49b9daaa-7517-4bd5-8648-4dbe725eb5aa",
    "prId" : 102344,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102344#pullrequestreview-678952513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d25d31c2-2a34-4318-b5fd-79d75975d9a4",
        "parentId" : null,
        "authorId" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "body" : "Thanks for the comment! I was just thinking about that race condition. :)",
        "createdAt" : "2021-06-08T22:31:38Z",
        "updatedAt" : "2021-06-11T07:11:56Z",
        "lastEditedBy" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eadd1a9ead7a009a9abfbd603a5efd0560473cc",
    "line" : 225,
    "diffHunk" : "@@ -1,1 +994,998 @@// HandlePodCleanups performs a series of cleanup work, including terminating\n// pod workers, killing unwanted pods, and removing orphaned volumes/pod\n// directories. No config changes are sent to pod workers while this method\n// is executing which means no new pods can appear.\n// NOTE: This function is executed by the main sync loop, so it"
  },
  {
    "id" : "ee75e533-4e68-43d3-af23-5b5cf8c712c0",
    "prId" : 102344,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102344#pullrequestreview-682218521",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4b4af01-84ff-43cd-ba8c-8c6facd9a472",
        "parentId" : null,
        "authorId" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "body" : "Probably add a comment to explain that: There won't be running runtime pod started after `allPodsByUID` is populated, because no config changes are sent to pod workers while this method is executing.",
        "createdAt" : "2021-06-08T22:47:49Z",
        "updatedAt" : "2021-06-11T07:11:56Z",
        "lastEditedBy" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "tags" : [
        ]
      },
      {
        "id" : "672ba7eb-8f78-4173-83a6-54e73f7daa72",
        "parentId" : "b4b4af01-84ff-43cd-ba8c-8c6facd9a472",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "Will do.",
        "createdAt" : "2021-06-11T21:11:22Z",
        "updatedAt" : "2021-06-11T21:11:23Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eadd1a9ead7a009a9abfbd603a5efd0560473cc",
    "line" : 295,
    "diffHunk" : "@@ -1,1 +1076,1080 @@\t\t\t// know that another pod wasn't started in the background so we are safe to terminate the\n\t\t\t// unknown pods.\n\t\t\tif _, ok := allPodsByUID[runningPod.ID]; !ok {\n\t\t\t\tklog.V(3).InfoS(\"Clean up orphaned pod containers\", \"podUID\", runningPod.ID)\n\t\t\t\tone := int64(1)"
  },
  {
    "id" : "a93e56f7-0523-4da0-9ccf-c22e4b6704db",
    "prId" : 102344,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102344#pullrequestreview-690897541",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "991e6a32-76c3-459e-8933-9b3a2b8acf65",
        "parentId" : null,
        "authorId" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "body" : "I'm actually not sure how useful this is. :/\r\n\r\nThe kill pod is not synchronized even before this change, so the kill pod behavior change should not affect the result.\r\n\r\nIt was synchronized when the code was introduced. https://github.com/kubernetes/kubernetes/pull/7525\r\n\r\nI think we can remove this code now, just a note here, we can keep it as it is in this change to limit the change size. :) Just want to think out loud to make sure the kill pod code change would not break things",
        "createdAt" : "2021-06-10T00:36:07Z",
        "updatedAt" : "2021-06-11T07:11:56Z",
        "lastEditedBy" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "tags" : [
        ]
      },
      {
        "id" : "60cc83ad-5002-4b1d-86b9-382b4631d6ad",
        "parentId" : "991e6a32-76c3-459e-8933-9b3a2b8acf65",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "In this case it's allowing the pod worker to own all termination logic.  Effectively this is going to create a worker for \"orphan pods\" and the orphan pod worker then unifies all the handling (so orphaned volume, lagging controller, etc) is set up.  So this is kind of the reverse of SyncKnownPods - we *could* simply pass this in to pod worker and have that method handle it, but I'd prefer to do the loop here in a predictable order.  Is that a better way of framing why this makes sense to do?",
        "createdAt" : "2021-06-22T17:19:25Z",
        "updatedAt" : "2021-06-22T17:19:25Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "5ee1730f-0d0e-4db9-96d4-aaec79417455",
        "parentId" : "991e6a32-76c3-459e-8933-9b3a2b8acf65",
        "authorId" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "body" : "The variable name change makes sense to me.\r\n\r\nWhat I meant is that this line tries to get the new set of running pods after unwanted pods are killed. However, because the kill is not synchronized, this line here may not be that useful.\r\n\r\nThis line was added when kill pod is synchronized.",
        "createdAt" : "2021-06-23T16:32:58Z",
        "updatedAt" : "2021-06-23T17:10:31Z",
        "lastEditedBy" : "4e418bc8-21fb-4523-80c1-9c751c193126",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eadd1a9ead7a009a9abfbd603a5efd0560473cc",
    "line" : 317,
    "diffHunk" : "@@ -1,1 +1097,1101 @@\t// running pods to clean up the volumes.\n\t// TODO: Evaluate the performance impact of bypassing the runtime cache.\n\trunningRuntimePods, err = kl.containerRuntime.GetPods(false)\n\tif err != nil {\n\t\tklog.ErrorS(err, \"Error listing containers\")"
  },
  {
    "id" : "988230fb-851e-46c7-9d07-cd66a642b9e3",
    "prId" : 98847,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/98847#pullrequestreview-612474416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce08e28f-b34b-4367-8534-aa1595595fb0",
        "parentId" : null,
        "authorId" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "body" : "s/Error/error",
        "createdAt" : "2021-03-15T17:40:35Z",
        "updatedAt" : "2021-03-15T17:40:36Z",
        "lastEditedBy" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "90bfd38b836a704c4b4a39490df868b156175e41",
    "line" : 130,
    "diffHunk" : "@@ -1,1 +971,975 @@\truntimeStatus, err := kl.podCache.Get(pod.UID)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Pod is terminated, Error getting runtimeStatus from the podCache\", \"pod\", klog.KObj(pod), \"err\", err)\n\t\treturn false\n\t}"
  },
  {
    "id" : "e05e3223-c4c0-425c-b6b8-0aacb14d5659",
    "prId" : 98424,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/98424#pullrequestreview-582881007",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15005432-65db-4266-90ca-d58aee059f9e",
        "parentId" : null,
        "authorId" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "body" : "Do we wanna lock first before logging? Can lock acquisition fail or would it just block for a while?",
        "createdAt" : "2021-02-03T22:45:28Z",
        "updatedAt" : "2021-02-04T17:46:01Z",
        "lastEditedBy" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "tags" : [
        ]
      },
      {
        "id" : "46e594d2-68fb-4f33-82f1-9aad6ad7a0a9",
        "parentId" : "15005432-65db-4266-90ca-d58aee059f9e",
        "authorId" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "body" : "Typically we don't want to lock within a log statement since it may block, and fmt.Printf() style calls are generally slower. ",
        "createdAt" : "2021-02-03T23:01:04Z",
        "updatedAt" : "2021-02-04T17:46:01Z",
        "lastEditedBy" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f918e11e3aaef25fee0525f9552e36d23b6b86a6",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +1210,1214 @@func (pk *podKillerWithChannel) markPodTerminated(uid string) {\n\tklog.V(4).Infof(\"marking pod termination %q\", uid)\n\tpk.podKillingLock.Lock()\n\tdefer pk.podKillingLock.Unlock()\n\tdelete(pk.mirrorPodTerminationMap, uid)"
  },
  {
    "id" : "bb345fc0-398a-497b-998f-07c96c3743ed",
    "prId" : 98424,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/98424#pullrequestreview-580800892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab03f0d9-f54f-4dad-abfb-5fdf72b1c564",
        "parentId" : null,
        "authorId" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "body" : ":100: ",
        "createdAt" : "2021-02-03T22:48:01Z",
        "updatedAt" : "2021-02-04T17:46:01Z",
        "lastEditedBy" : "31a2ac00-6c67-4307-a4bc-bfd13f41ef27",
        "tags" : [
        ]
      }
    ],
    "commit" : "f918e11e3aaef25fee0525f9552e36d23b6b86a6",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +1248,1252 @@\t\t\tklog.V(4).Infof(\"api pod %q is pending termination\", podPair.APIPod.UID)\n\t\t} else {\n\t\t\tklog.V(4).Infof(\"running pod %q is pending termination\", podPair.RunningPod.ID)\n\t\t}\n\t\treturn true"
  },
  {
    "id" : "51884ad3-6ff4-496f-8283-c7bbf77c92a4",
    "prId" : 96451,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/96451#pullrequestreview-582945305",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0af1950-3a80-4974-9bc0-d37e191317ba",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "Also use it here: https://github.com/kubernetes/kubernetes/blob/ac101cbdda382d4c23485a3aa5583d79e5379e31/pkg/kubelet/kubelet_test.go#L1458?",
        "createdAt" : "2020-12-23T23:20:59Z",
        "updatedAt" : "2021-02-04T00:48:37Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "33ad4bd6-6b5b-4216-a8c3-17885abae701",
        "parentId" : "c0af1950-3a80-4974-9bc0-d37e191317ba",
        "authorId" : "61a9a744-a5c3-4fab-b291-e721679fb5fd",
        "body" : "@SergeyKanzhelev yes, I've modified, thanks!",
        "createdAt" : "2021-02-04T00:54:18Z",
        "updatedAt" : "2021-02-04T00:54:18Z",
        "lastEditedBy" : "61a9a744-a5c3-4fab-b291-e721679fb5fd",
        "tags" : [
        ]
      }
    ],
    "commit" : "4103ff490fe2575683fc38866a01e9b80c602105",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +81,85 @@// Container state reason list\nconst (\n\tPodInitializing   = \"PodInitializing\"\n\tContainerCreating = \"ContainerCreating\"\n)"
  },
  {
    "id" : "77a2a1e9-2530-4b23-b5bc-44306e0b5f08",
    "prId" : 95561,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95561#pullrequestreview-508695467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8010e97c-6c2f-42d8-886a-a5cc7932d14f",
        "parentId" : null,
        "authorId" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "body" : "As we discussed in slack, I tested adding the `status.RestartCount = oldStatus.RestartCount + 1` and see the correct RestartCount... +1 to adding it.",
        "createdAt" : "2020-10-14T19:31:52Z",
        "updatedAt" : "2020-10-15T16:26:28Z",
        "lastEditedBy" : "3eccedfc-5c53-4555-94cb-69f2b56e485c",
        "tags" : [
        ]
      },
      {
        "id" : "5d2b06c1-93ff-4c6e-ad38-3c52743f7423",
        "parentId" : "8010e97c-6c2f-42d8-886a-a5cc7932d14f",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "just to make sure i understand, this is asserting that the runtime tried to restart the container.\r\n\r\nthe count is not precise today for sure, so i think this is fine.\r\n\r\nfor reference:\r\n\r\ntypes.go\r\n```sh\r\n\t// Note that this is calculated from dead containers.  But those containers are subject to\r\n\t// garbage collection.  This value will get capped at 5 by GC.\r\n\tRestartCount int32\r\n```",
        "createdAt" : "2020-10-14T20:18:29Z",
        "updatedAt" : "2020-10-15T16:26:28Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff7d1444f01843339c54b0127d614870b7306537",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +1662,1666 @@\t\t\t// for the case where the CRI did not return a status, we need to manually increment the restart count to be accurate.\n\t\t\tstatus.RestartCount = oldStatus.RestartCount + 1\n\n\t\tdefault:\n\t\t\t// this collapses any unknown state to container waiting.  If any container is waiting, then the pod status moves to pending even if it is running."
  },
  {
    "id" : "19a54ac3-7355-4025-bd4c-0e64c4949ea7",
    "prId" : 95561,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95561#pullrequestreview-508695467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f917bf8a-665b-4fbe-86f1-2f6ae8011be4",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "@deads2k appreciate your help chasing these down.\r\n\r\nI think we are reaching point of 'unit test would be really helpful', can you look at `TestGenerateAPIPodStatusWithReasonCache` and see if you can extend to cover this scenario?  I think it will hit your flow changes.",
        "createdAt" : "2020-10-14T20:16:38Z",
        "updatedAt" : "2020-10-15T16:26:28Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff7d1444f01843339c54b0127d614870b7306537",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +1646,1650 @@\t\t\t}\n\n\t\tcase cs.State == kubecontainer.ContainerStateUnknown &&\n\t\t\toldStatus != nil && // we have an old status\n\t\t\toldStatus.State.Running != nil: // our previous status was running"
  },
  {
    "id" : "01f53c2d-e290-4d96-a049-2632136bf48a",
    "prId" : 92442,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92442#pullrequestreview-439530763",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53985a3d-f517-4db6-aaa8-8b7e6edb3009",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "just recording to myself:\r\n\r\nat this state we have the following:\r\n- the static pod manifest has been moved (HandlePodRemove should have resulted in local delete flow)\r\n- the static pod has already been signaled for termination via normal podKiller\r\n- the mirror pod exists in API server\r\n- `HandlePodCleanups` is invoking this from main kubelet sync loop\r\n\r\nthe question at this point is should we delete the mirror pod records from the API server?",
        "createdAt" : "2020-06-29T19:52:43Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "e7da94a6-8065-436d-ab1a-43845c3bb426",
        "parentId" : "53985a3d-f517-4db6-aaa8-8b7e6edb3009",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "just recording to myself:\r\n\r\nEarlier in `HandlePodCleanups` , we pass any non-desired pod to a podKillingCh.\r\n\r\n- podKiller watches the channel of pods pending deletion\r\n- it removes the pod from the podKillingCh when we know the pod has been killed",
        "createdAt" : "2020-06-29T20:18:34Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "cd76d847-321f-4b69-bd24-5086b26b4a7d",
        "parentId" : "53985a3d-f517-4db6-aaa8-8b7e6edb3009",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "just recording to myself:\r\n\r\n> SyncLoop (REMOVE, \"file\") static-pod-xyz\r\n\r\nHere we do following:\r\n- pod manager `DeletePod`  (note: this will actually make the pod now appear \"orphaned\" in mirror pod case)\r\n- kubelet deletePod (this will result in adding the pod to the podKillingCh to be removed by podKiller (async)\r\n- probe manager removePod\r\n\r\n>SyncLoop (DELETE, \"api\") static-pod-xyz\r\n- pod manager is told to update pod\r\n- if pod is mirror pod (which it is in this case, we call handleMirrorPod which will dispatch work if actual pod still exists in pod manager (which it wont)\r\n\r\nnote: derek to check ramification of that for when we remove map entries in DeletePod\r\n\r\n>SyncLoop (REMOVE, \"api\") static-pod-xyz\r\n\r\n- pod manager delete pod is invoked, since its a mirror pod, we dispatch work to non-existing worker\r\n\r\nAnything not caught in the above flow is basically at this point at the whim of the periodic cleanup that this `deleteOrphanedMirrorPods` is attempting to handle.\r\n",
        "createdAt" : "2020-06-29T20:58:10Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "0702c3e8-f599-44a3-a7aa-5cac0e4e71f7",
        "parentId" : "53985a3d-f517-4db6-aaa8-8b7e6edb3009",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "@tedyu I am wondering the following.\r\n\r\nCan the logic in this method, and what we are attempting to track in pod manager be simplified to only call `deleteMirrorPod` if and only if the pod is not in the `podKillingCh`?  If the pod is in the `podKillingCh`, we know it hasn't actually been fully removed?  In this manner, we do not need to track termination phase in pod manager itself?\r\n\r\nAm I mistaken, or do you agree that that would be a simplification?",
        "createdAt" : "2020-06-29T21:01:11Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "7f75f770-721a-4e47-a075-fae7c0673f22",
        "parentId" : "53985a3d-f517-4db6-aaa8-8b7e6edb3009",
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "Responded in https://github.com/kubernetes/kubernetes/pull/92442#discussion_r447277746\r\n\r\nAlso, in terms of kubelet restart, we should do no worse than what this PR does: for mirror pod pending termination, the second kubelet should remove the mirror pod after kubelet restart.\r\nIt seems there would be non-trivial amount of code to cover all the scenarios which are handled by this PR.\r\n\r\nIf that response hasn't covered your question here, please let me know.\r\n\r\nThanks",
        "createdAt" : "2020-06-29T22:01:15Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "a76a959294ba13bfe931a0c2df568450f71148e2",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1029,1033 @@// If pod killing is done, podManager.DeleteMirrorPod() is called to delete mirror pod\n// from the API server\nfunc (kl *Kubelet) deleteOrphanedMirrorPods() {\n\tpodFullNames := kl.podManager.GetOrphanedMirrorPodNames()\n\tfor _, podFullname := range podFullNames {"
  },
  {
    "id" : "9745d3f5-9c8f-4281-92d5-6ce23ea1b06a",
    "prId" : 92442,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92442#pullrequestreview-439397886",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a3ac446-e356-4101-92aa-4bfd349ab304",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "note to self, at this point:\r\n\r\n`SyncLoop (REMOVE, \"file\")` record would have removed the pod from the pod manager\r\nmirror pod record remains in pod manager itself",
        "createdAt" : "2020-06-29T21:06:18Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "a76a959294ba13bfe931a0c2df568450f71148e2",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +1030,1034 @@// from the API server\nfunc (kl *Kubelet) deleteOrphanedMirrorPods() {\n\tpodFullNames := kl.podManager.GetOrphanedMirrorPodNames()\n\tfor _, podFullname := range podFullNames {\n\t\tif !kl.podKiller.IsMirrorPodPendingTerminationByPodName(podFullname) {"
  },
  {
    "id" : "45c8fcbb-90c1-4fd1-97fe-6a1518f81b54",
    "prId" : 92442,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/92442#pullrequestreview-441125379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e428c101-7508-4342-b70e-edc6039b2574",
        "parentId" : null,
        "authorId" : "8e9f49fc-1050-4601-b81c-83bf660c5eb8",
        "body" : "this also seems unrelated",
        "createdAt" : "2020-07-01T17:26:37Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "8e9f49fc-1050-4601-b81c-83bf660c5eb8",
        "tags" : [
        ]
      },
      {
        "id" : "8e15727b-a5b3-4a6b-9ce7-46c43bb5fe12",
        "parentId" : "e428c101-7508-4342-b70e-edc6039b2574",
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "This is actually used by the enhanced unit test (TestDeleteOrphanedMirrorPods) where using single instance of pcm during one HandlePodCleanups() call allows the assertion to be written.\r\n\r\nAlso, it seems cleaner using single instance of pcm which reduces garbage for Go runtime.",
        "createdAt" : "2020-07-01T19:02:22Z",
        "updatedAt" : "2020-07-08T20:38:41Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "a76a959294ba13bfe931a0c2df568450f71148e2",
    "line" : 184,
    "diffHunk" : "@@ -1,1 +1834,1838 @@// cleanupOrphanedPodCgroups removes cgroups that should no longer exist.\n// it reconciles the cached state of cgroupPods with the specified list of runningPods\nfunc (kl *Kubelet) cleanupOrphanedPodCgroups(pcm cm.PodContainerManager, cgroupPods map[types.UID]cm.CgroupName, activePods []*v1.Pod) {\n\t// Add all running pods to the set that we want to preserve\n\tpodSet := sets.NewString()"
  },
  {
    "id" : "7706ac24-6b6c-46ea-9398-689a5a1c24ee",
    "prId" : 91500,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/91500#pullrequestreview-421000996",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af752747-b5a0-40a7-bd5d-ef10d47b0a2f",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "can you update `TestMakeEnvironmentVariables` to test a scenario where serviceHasSynced returns false to ensure this does error?",
        "createdAt" : "2020-05-29T14:17:05Z",
        "updatedAt" : "2020-05-29T21:11:28Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "85e8da20-ca1c-4fa9-b295-1b5400ba9820",
        "parentId" : "af752747-b5a0-40a7-bd5d-ef10d47b0a2f",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "the test case has a way of identifying a nil lister, if we can update it to have a case of service not synced on one additional scenario, that would be great.",
        "createdAt" : "2020-05-29T14:20:52Z",
        "updatedAt" : "2020-05-29T21:11:28Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "4da0e64bc1b9c23b71589ff38e875ff67e8f649e",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +562,566 @@\t// The KUBERNETES_SERVICE_HOST link is special because it is unconditionally injected into pods and is read by the\n\t// in-cluster-config for pod clients\n\tif !kubetypes.IsStaticPod(pod) && !kl.serviceHasSynced() {\n\t\treturn nil, fmt.Errorf(\"services have not yet been read at least once, cannot construct envvars\")\n\t}"
  },
  {
    "id" : "17e9b398-32ec-4e83-8bf6-369ec48ab957",
    "prId" : 90216,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/90216#pullrequestreview-408939361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0a54ccf-8324-4a89-9778-9f63b6d57754",
        "parentId" : null,
        "authorId" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "body" : "- Took a quick look, the solution seems reasonable(), but so far , its hard for me to figure out if podStatus indeed is something that can be operated concurrently or is on the stack and not affected by syncLoops goroutines. \r\n- i also see a lack of tests for these functions\r\n\r\ni will try to take another deeper look  by next week, if this hasnt been reviewed by someone more familiar with the code.",
        "createdAt" : "2020-05-11T07:52:25Z",
        "updatedAt" : "2021-03-09T09:14:35Z",
        "lastEditedBy" : "224e1088-78fe-4bdd-99d1-31be3e464996",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb3fe633b471a28eb3ea437a128bd730a118427f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1840,1844 @@\t// Copy the slice before sorting it\n\tcontainerStatusesCopy := make([]*kubecontainer.Status, len(podStatus.ContainerStatuses))\n\tcopy(containerStatusesCopy, podStatus.ContainerStatuses)\n\n\t// Make the latest container status comes first."
  },
  {
    "id" : "f552d817-a850-4482-89ed-1b21badf399a",
    "prId" : 90216,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/90216#pullrequestreview-652341270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bf29cf2-88a7-4a1c-aa1b-b033d0664bde",
        "parentId" : null,
        "authorId" : "36b049e7-5c64-46e2-809a-9067732f0056",
        "body" : "I personally would prefer having a lock here.",
        "createdAt" : "2021-05-05T13:16:39Z",
        "updatedAt" : "2021-05-05T13:17:33Z",
        "lastEditedBy" : "36b049e7-5c64-46e2-809a-9067732f0056",
        "tags" : [
        ]
      },
      {
        "id" : "33fcd297-2400-4cd3-b119-4824532295bb",
        "parentId" : "0bf29cf2-88a7-4a1c-aa1b-b033d0664bde",
        "authorId" : "c5277080-6605-4c27-a06c-4fab1d1902cc",
        "body" : "Thanks for the review ! A couple of questions regarding a lock-based approach:\r\n- The function / code path is supposed to be purely transformative and not alter the kubelet State (I suppose, including the podCache), should we change that assumption ? https://github.com/kubernetes/kubernetes/blob/v1.20.4/pkg/kubelet/kubelet_pods.go#L1540-L1542 \r\nIt would also potentially alter the assumption that callers should not modify objects from the pod cache https://github.com/kubernetes/kubernetes/blob/v1.20.4/pkg/kubelet/container/cache.go#L81-L88\r\n- Where should the lock live ? Should we add an attribute `ContainerStatusesLock` to the pod status https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/container/runtime.go#L290-L304 / or higher on the podCache level ? ",
        "createdAt" : "2021-05-05T13:42:48Z",
        "updatedAt" : "2021-05-05T13:42:48Z",
        "lastEditedBy" : "c5277080-6605-4c27-a06c-4fab1d1902cc",
        "tags" : [
        ]
      },
      {
        "id" : "d60b7cc9-c50d-4758-97d4-357285193f99",
        "parentId" : "0bf29cf2-88a7-4a1c-aa1b-b033d0664bde",
        "authorId" : "36b049e7-5c64-46e2-809a-9067732f0056",
        "body" : "> * The function / code path is supposed to be purely transformative and not alter the kubelet State (I suppose, including the podCache), should we change that assumption ? https://github.com/kubernetes/kubernetes/blob/v1.20.4/pkg/kubelet/kubelet_pods.go#L1540-L1542\r\n\r\nI think so, since the assumption seems wrong with the `Sort()` call. We could also assume that the status is already sorted and move the sorting code to another code path, but this way we would still require the lock from what I can see.\r\n\r\n>   It would also potentially alter the assumption that callers should not modify objects from the pod cache https://github.com/kubernetes/kubernetes/blob/v1.20.4/pkg/kubelet/container/cache.go#L81-L88\r\n> * Where should the lock live ? Should we add an attribute `ContainerStatusesLock` to the pod status https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/container/runtime.go#L290-L304 / or higher on the podCache level ?\r\n\r\nA higher lock would mean that we lock the whole `PodStatus`, right? I personally would prefer locking only the structure we need, which means the lock would be part of `PodStatus`.",
        "createdAt" : "2021-05-05T13:59:07Z",
        "updatedAt" : "2021-05-05T13:59:07Z",
        "lastEditedBy" : "36b049e7-5c64-46e2-809a-9067732f0056",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb3fe633b471a28eb3ea437a128bd730a118427f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1840,1844 @@\t// Copy the slice before sorting it\n\tcontainerStatusesCopy := make([]*kubecontainer.Status, len(podStatus.ContainerStatuses))\n\tcopy(containerStatusesCopy, podStatus.ContainerStatuses)\n\n\t// Make the latest container status comes first."
  },
  {
    "id" : "e28bd643-56ee-4f3a-9cc7-973b6e1af009",
    "prId" : 89667,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/89667#pullrequestreview-388611910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a41896b-b559-4fb5-b54a-5c732118e52c",
        "parentId" : null,
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "I think `%+v` can be used to print out lists.  Does this work here?",
        "createdAt" : "2020-04-06T20:33:53Z",
        "updatedAt" : "2020-04-13T21:36:55Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      },
      {
        "id" : "33ab248c-dbbc-4c13-ae81-59d46cbf742e",
        "parentId" : "3a41896b-b559-4fb5-b54a-5c732118e52c",
        "authorId" : "af81f9c4-a75e-4ffc-8796-b6a575aa6a95",
        "body" : "this is an array of pointers and hence had to use the loop",
        "createdAt" : "2020-04-06T20:42:21Z",
        "updatedAt" : "2020-04-13T21:36:55Z",
        "lastEditedBy" : "af81f9c4-a75e-4ffc-8796-b6a575aa6a95",
        "tags" : [
        ]
      },
      {
        "id" : "51dba5b4-3472-4d09-8133-8c3d7b1085d3",
        "parentId" : "3a41896b-b559-4fb5-b54a-5c732118e52c",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "right.",
        "createdAt" : "2020-04-06T20:58:23Z",
        "updatedAt" : "2020-04-13T21:36:55Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b9cf33771a7797570cd917f5ca404a2457a99c5",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +945,949 @@\t\tvar sandboxStr string\n\t\tfor _, sandbox := range runtimeStatus.SandboxStatuses {\n\t\t\tsandboxStr += fmt.Sprintf(\"%+v \", *sandbox)\n\t\t}\n\t\tklog.V(3).Infof(\"Pod %q is terminated, but some pod sandboxes have not been cleaned up: %s\", format.Pod(pod), sandboxStr)"
  },
  {
    "id" : "c1b69393-c537-4503-b801-77c1e0e9e8a6",
    "prId" : 83123,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/83123#pullrequestreview-317351147",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb2001fa-b9c8-4d46-b3c0-65e663569c3a",
        "parentId" : null,
        "authorId" : "6dd71efb-88b1-4bb0-b30a-0df658362f14",
        "body" : "This seems scary, is there a reason we can't keep this as `len(podIP) > 0`? It ensures existing behavior and has the same result since primary pod IP is guaranteed to be set here anyways. ",
        "createdAt" : "2019-11-06T21:40:59Z",
        "updatedAt" : "2019-11-06T21:40:59Z",
        "lastEditedBy" : "6dd71efb-88b1-4bb0-b30a-0df658362f14",
        "tags" : [
        ]
      },
      {
        "id" : "afd5b91e-33e5-43fc-92c8-7e1e2e273e00",
        "parentId" : "eb2001fa-b9c8-4d46-b3c0-65e663569c3a",
        "authorId" : "62eb404a-5fe6-4b29-afab-583b57ce8f19",
        "body" : "The `podIP` and `podIPs` are passed from caller `SyncPod`. Here `podIP` is set explicitly to the first value of `podIPs` - https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L744-L747. So `podIPs` is guaranteed to be set right? If `podIPs` is empty, then `podIP` is going to be empty here.",
        "createdAt" : "2019-11-06T22:52:07Z",
        "updatedAt" : "2019-11-06T22:52:08Z",
        "lastEditedBy" : "62eb404a-5fe6-4b29-afab-583b57ce8f19",
        "tags" : [
        ]
      },
      {
        "id" : "c77fd6f9-1536-4413-9594-f5f6b3eb89a1",
        "parentId" : "eb2001fa-b9c8-4d46-b3c0-65e663569c3a",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "This is changing the meaning of the test.  Before it was checking whether the podIP was valid (kind of - does it have any bytes).  Now it is testing whether the list of podIPs has and values listed.\r\n\r\nThat is meaningfully different, though I *think* it will come out the same, since we should never set podIPs[0] if there is not a valid IP.  I *think*.  I checked the conversion code and it seems safe.",
        "createdAt" : "2019-11-15T00:47:04Z",
        "updatedAt" : "2019-11-15T01:13:41Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      }
    ],
    "commit" : "af4d18ccf9330a8dd7354c5441ccd841d469cee5",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +136,140 @@\t// Kubernetes will not mount /etc/hosts if:\n\t// - when the Pod sandbox is being created, its IP is still unknown. Hence, PodIP will not have been set.\n\tmountEtcHostsFile := len(podIPs) > 0 && runtime.GOOS != \"windows\"\n\tklog.V(3).Infof(\"container: %v/%v/%v podIPs: %q creating hosts mount: %v\", pod.Namespace, pod.Name, container.Name, podIPs, mountEtcHostsFile)\n\tmounts := []kubecontainer.Mount{}"
  },
  {
    "id" : "efec69e4-4b2b-459a-871a-dd15d08766a8",
    "prId" : 81204,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/81204#pullrequestreview-272894668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "461605ae-e7eb-4211-a75c-3c900a2bfb28",
        "parentId" : null,
        "authorId" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "body" : "nit: unrelated change",
        "createdAt" : "2019-08-08T23:42:10Z",
        "updatedAt" : "2019-08-09T18:41:14Z",
        "lastEditedBy" : "542e5d2f-2ff9-4674-ab44-78f31768e7a1",
        "tags" : [
        ]
      },
      {
        "id" : "457380bd-4c78-4a94-a9f4-18a5e09b93f3",
        "parentId" : "461605ae-e7eb-4211-a75c-3c900a2bfb28",
        "authorId" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "body" : "This is automatically modified by one of the go formatting tools. Many files in Kubernetes have this now.",
        "createdAt" : "2019-08-09T00:05:31Z",
        "updatedAt" : "2019-08-09T18:41:14Z",
        "lastEditedBy" : "209ee091-cf29-4efa-8a1b-a98334ea3f9a",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e25b7c04235b2cdc38f5c8d533a8b7a8254fe4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +33,37 @@\t\"sync\"\n\n\tv1 \"k8s.io/api/core/v1\"\n\t\"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\""
  },
  {
    "id" : "75da1d7b-5da2-4fee-920c-4064a57135d0",
    "prId" : 78373,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/78373#pullrequestreview-440431802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24e86432-9bbd-4b49-aabf-6abbaad5bf95",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "since there are two calls to sort - worth duplicating this comment",
        "createdAt" : "2020-06-30T22:34:15Z",
        "updatedAt" : "2020-06-30T22:34:15Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f043dd8a06a553de91e1bfb84500d66daf97e18",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1546,1550 @@\t}\n\n\t// Sort the container statuses since clients of this interface expect the list\n\t// of containers in a pod has a deterministic order.\n\tif isInitContainer {"
  },
  {
    "id" : "7b7db5f9-6ef5-4e21-a935-ff36ccf492d9",
    "prId" : 74222,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74222#pullrequestreview-208551749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f4c170e-eb53-44a4-8ed7-719c9910b7b6",
        "parentId" : null,
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "Why can't we make this change within `GetPodsAndMirrorPods()` fn? I don't see any other place in the code where this is being used.",
        "createdAt" : "2019-02-26T13:51:55Z",
        "updatedAt" : "2019-02-26T13:51:56Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      },
      {
        "id" : "a07606c8-1178-40a9-a053-382fb294b43d",
        "parentId" : "1f4c170e-eb53-44a4-8ed7-719c9910b7b6",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "`GetPodsAndMirrorPods()` is defined as:\r\n\r\n> // GetPodsAndMirrorPods returns the both regular and mirror pods.\r\n\r\nSo IMO \"regular pods\" literally means all pods including \"real regular\" and \"static\" pods. I prefer to think of current function as a consistent behavior with the comment.",
        "createdAt" : "2019-02-26T16:17:55Z",
        "updatedAt" : "2019-02-26T16:17:55Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      },
      {
        "id" : "1ac3db14-dcc1-41dc-a6eb-3bf3d11458b1",
        "parentId" : "1f4c170e-eb53-44a4-8ed7-719c9910b7b6",
        "authorId" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "body" : "I am fine with the change, just that I am not sure, if there is a need of using static pods somewhere else in the code base instead of using mirror pods. If we have some use then it makes sense to keep the function as is.",
        "createdAt" : "2019-02-27T14:28:02Z",
        "updatedAt" : "2019-02-27T14:28:03Z",
        "lastEditedBy" : "38ca4f80-c365-4775-8981-1e56b713b07b",
        "tags" : [
        ]
      }
    ],
    "commit" : "76174b3d0fd50f13c065cc73cf4fb87237c6f25b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +89,93 @@// GetActivePods returns non-terminal pods\nfunc (kl *Kubelet) GetActivePods() []*v1.Pod {\n\tallPods, mirrorPods := kl.podManager.GetPodsAndMirrorPods()\n\tmirrorPodSet := make(map[string]*v1.Pod)\n\tfor _, p := range mirrorPods {"
  },
  {
    "id" : "a170ac33-f1c3-4f8e-b3fd-3b030fbfc2f1",
    "prId" : 74222,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/74222#pullrequestreview-212627600",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f48a3925-2ba4-4a78-993d-62a8b4602638",
        "parentId" : null,
        "authorId" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "body" : "Looking at the other usage of mirrorPods in removeOrphanedPodStatuses, the mirrorPods can be in the Map structure shown below (and not affecting functionality).\r\nI wonder if GetPodsAndMirrorPods should return mirror pods in Map.",
        "createdAt" : "2019-03-10T23:03:20Z",
        "updatedAt" : "2019-03-10T23:03:20Z",
        "lastEditedBy" : "42b1e004-4fa7-4e43-84cf-5378839b49ad",
        "tags" : [
        ]
      },
      {
        "id" : "222f4723-bb2e-4e51-bbb9-ec20676ce56b",
        "parentId" : "f48a3925-2ba4-4a78-993d-62a8b4602638",
        "authorId" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "body" : "@tedyu this PR is incomplete. Please check the other PR #75144. ",
        "createdAt" : "2019-03-10T23:07:51Z",
        "updatedAt" : "2019-03-10T23:07:52Z",
        "lastEditedBy" : "06cbf859-1cac-4be7-80e6-3b34dcff1812",
        "tags" : [
        ]
      }
    ],
    "commit" : "76174b3d0fd50f13c065cc73cf4fb87237c6f25b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +89,93 @@// GetActivePods returns non-terminal pods\nfunc (kl *Kubelet) GetActivePods() []*v1.Pod {\n\tallPods, mirrorPods := kl.podManager.GetPodsAndMirrorPods()\n\tmirrorPodSet := make(map[string]*v1.Pod)\n\tfor _, p := range mirrorPods {"
  },
  {
    "id" : "cd829666-bf87-47ba-b727-0132cfa2393b",
    "prId" : 71351,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/71351#pullrequestreview-188032461",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98b1fbdc-2aa0-45f3-a0fd-e263e3753c76",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "should this fail if both mount.SubPath and mount.SubPathExpr are set?",
        "createdAt" : "2018-12-26T20:45:22Z",
        "updatedAt" : "2019-02-20T01:37:45Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "6a243957-d965-48d7-9c87-309d830b8c2d",
        "parentId" : "98b1fbdc-2aa0-45f3-a0fd-e263e3753c76",
        "authorId" : "0d43352d-b6ae-4016-9e7f-921f64611474",
        "body" : "The validator ensures that they are mutually exclusive. Do we need to add another validation test here?",
        "createdAt" : "2018-12-27T08:43:49Z",
        "updatedAt" : "2019-02-20T01:37:45Z",
        "lastEditedBy" : "0d43352d-b6ae-4016-9e7f-921f64611474",
        "tags" : [
        ]
      }
    ],
    "commit" : "a64b854137b5fc6c60724cbe349122e3bda8b09e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +162,166 @@\n\t\tsubPath := mount.SubPath\n\t\tif mount.SubPathExpr != \"\" {\n\t\t\tif !utilfeature.DefaultFeatureGate.Enabled(features.VolumeSubpath) {\n\t\t\t\treturn nil, cleanupAction, fmt.Errorf(\"volume subpaths are disabled\")"
  },
  {
    "id" : "9ff92610-6d84-4760-8191-9ad0d83737a4",
    "prId" : 68754,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68754#pullrequestreview-157911403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e61ddc88-538e-40a6-b2cf-e54fd1855f2d",
        "parentId" : null,
        "authorId" : "3dbe41a5-367a-43aa-9aff-7479deaff757",
        "body" : "Are environment variables from this namespace absolutely needed for technical reasons? If not, why not just leave them out entirely?",
        "createdAt" : "2018-09-22T08:03:30Z",
        "updatedAt" : "2018-09-22T08:05:21Z",
        "lastEditedBy" : "3dbe41a5-367a-43aa-9aff-7479deaff757",
        "tags" : [
        ]
      },
      {
        "id" : "f95da000-3afe-4315-9e9e-c457c4d8a6db",
        "parentId" : "e61ddc88-538e-40a6-b2cf-e54fd1855f2d",
        "authorId" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "body" : "It is just the \"kubernetes\" service from the master service namespace, not all of them.\r\n\r\nThis was kept per Tim's comment in an out of date PR that clients depend on the KUBERNETES_* env vars:\r\nhttps://github.com/kubernetes/kubernetes/pull/60206#discussion_r212702201",
        "createdAt" : "2018-09-22T14:21:23Z",
        "updatedAt" : "2018-09-22T14:21:42Z",
        "lastEditedBy" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "tags" : [
        ]
      }
    ],
    "commit" : "a596030cb310e8425ec3abc61dc0bd87471a9bd0",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +519,523 @@\t\t// We also add environment variables for other services in the same\n\t\t// namespace, if enableServiceLinks is true.\n\t\tif service.Namespace == kl.masterServiceNamespace && masterServices.Has(serviceName) {\n\t\t\tif _, exists := serviceMap[serviceName]; !exists {\n\t\t\t\tserviceMap[serviceName] = service"
  },
  {
    "id" : "e99ee1af-69a8-485a-81c4-542a5198f4e6",
    "prId" : 68754,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/68754#pullrequestreview-158782611",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "parentId" : null,
        "authorId" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "body" : "@bradhoekstra @thockin \r\nthe panic i'm seeing is because of this line.\r\n\r\nis the field guarantied to be non-nil at this point?\r\n",
        "createdAt" : "2018-09-25T22:10:23Z",
        "updatedAt" : "2018-09-25T22:37:59Z",
        "lastEditedBy" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "tags" : [
        ]
      },
      {
        "id" : "1e2a4ce5-50a6-4d57-96dd-03bc594cb2c6",
        "parentId" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "authorId" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "body" : "this POC patch fixes the kubelet:\r\n\r\n```go\r\ndiff --git a/pkg/kubelet/kubelet_pods.go b/pkg/kubelet/kubelet_pods.go\r\nindex 1854554824..0add92af22 100644\r\n--- a/pkg/kubelet/kubelet_pods.go\r\n+++ b/pkg/kubelet/kubelet_pods.go\r\n@@ -550,7 +550,11 @@ func (kl *Kubelet) makeEnvironmentVariables(pod *v1.Pod, container *v1.Container\r\n        // To avoid this users can: (1) wait between starting a service and starting; or (2) detect\r\n        // missing service env var and exit and be restarted; or (3) use DNS instead of env vars\r\n        // and keep trying to resolve the DNS name of the service (recommended).\r\n-       serviceEnv, err := kl.getServiceEnvVarMap(pod.Namespace, *pod.Spec.EnableServiceLinks)\r\n+       enableServiceLinks := v1.DefaultEnableServiceLinks\r\n+       if pod.Spec.EnableServiceLinks != nil {\r\n+               enableServiceLinks = *pod.Spec.EnableServiceLinks\r\n+       }\r\n+       serviceEnv, err := kl.getServiceEnvVarMap(pod.Namespace, enableServiceLinks)\r\n        if err != nil {\r\n                return result, err\r\n        }\r\n```",
        "createdAt" : "2018-09-25T22:24:44Z",
        "updatedAt" : "2018-09-25T22:37:40Z",
        "lastEditedBy" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "tags" : [
        ]
      },
      {
        "id" : "7dd200c6-65b2-4851-8770-c5504196149f",
        "parentId" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "authorId" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "body" : "I was under the impression [this change](https://github.com/kubernetes/kubernetes/pull/68754/files#diff-f4a6ea0883571048398880099571eea7R185) to defaults.go would guarantee that.\r\n\r\nIf not, I can copy the defaulting logic to this file.",
        "createdAt" : "2018-09-25T23:08:09Z",
        "updatedAt" : "2018-09-25T23:08:09Z",
        "lastEditedBy" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "tags" : [
        ]
      },
      {
        "id" : "cb6b547a-2bb9-4842-90f7-dad038cb951b",
        "parentId" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "authorId" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "body" : "Thanks for debugging this @neolit123 ",
        "createdAt" : "2018-09-25T23:08:42Z",
        "updatedAt" : "2018-09-25T23:08:43Z",
        "lastEditedBy" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "tags" : [
        ]
      },
      {
        "id" : "b7b6a56d-4122-48a7-b5ce-939726a83834",
        "parentId" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "authorId" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "body" : "> Thanks for debugging this @neolit123\r\n\r\n@bradhoekstra \r\nno problem!\r\nlet me know if you want me to submit the PR as i have it ready here.\r\n\r\n> I was under the impression this change to defaults.go would guarantee that.\r\n\r\ni think it only does that when generating a default pod spec.\r\n\r\nhere is a similar case for `Pod.Spec.SecurityContext`:\r\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_sandbox.go#L159\r\n",
        "createdAt" : "2018-09-25T23:18:33Z",
        "updatedAt" : "2018-09-25T23:18:33Z",
        "lastEditedBy" : "2ce2b44c-9841-49e7-983e-fb7696974908",
        "tags" : [
        ]
      },
      {
        "id" : "25a4cb94-341d-4651-994d-16be3bf4dc8d",
        "parentId" : "c88836e4-e551-4c3e-86aa-7df1590f2227",
        "authorId" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "body" : "If you have the PR ready go for it!",
        "createdAt" : "2018-09-25T23:21:19Z",
        "updatedAt" : "2018-09-25T23:21:19Z",
        "lastEditedBy" : "b12b98dd-afb7-414f-b601-04a45e82a4c3",
        "tags" : [
        ]
      }
    ],
    "commit" : "a596030cb310e8425ec3abc61dc0bd87471a9bd0",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +551,555 @@\t// missing service env var and exit and be restarted; or (3) use DNS instead of env vars\n\t// and keep trying to resolve the DNS name of the service (recommended).\n\tserviceEnv, err := kl.getServiceEnvVarMap(pod.Namespace, *pod.Spec.EnableServiceLinks)\n\tif err != nil {\n\t\treturn result, err"
  },
  {
    "id" : "b32dfb2a-0b55-4f47-ba0e-52b9e6ee7903",
    "prId" : 60275,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/60275#pullrequestreview-99095928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ea22172-a9e9-4789-bf82-d73740f9d734",
        "parentId" : null,
        "authorId" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "body" : "I am expecting we have more like this coming. Can you add a TODO to make this kind of Windows specific configuration / tuning can be easily managed? I don't want things like this scattered everywhere in our codebase, but can live with it for now with a TODO to unblock our progress. \r\n",
        "createdAt" : "2018-02-24T01:09:18Z",
        "updatedAt" : "2018-02-24T01:09:18Z",
        "lastEditedBy" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "tags" : [
        ]
      },
      {
        "id" : "7791a095-8376-4738-90ab-2ee495c09a5e",
        "parentId" : "1ea22172-a9e9-4789-bf82-d73740f9d734",
        "authorId" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "body" : "Ok, I filed https://github.com/kubernetes/kubernetes/issues/60338 as a record, so that we can process your pr asap. ",
        "createdAt" : "2018-02-24T01:16:41Z",
        "updatedAt" : "2018-02-24T01:16:41Z",
        "lastEditedBy" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "tags" : [
        ]
      },
      {
        "id" : "e21067f8-4217-49d1-850b-90139429e056",
        "parentId" : "1ea22172-a9e9-4789-bf82-d73740f9d734",
        "authorId" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "body" : "Thanks",
        "createdAt" : "2018-02-24T01:33:16Z",
        "updatedAt" : "2018-02-24T01:33:16Z",
        "lastEditedBy" : "0df1da34-610c-4ce5-b0cf-bbda668bf9c1",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d942dab68b64e684dd2b75232cf9daabc6e0a95",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +273,277 @@// runtimeapi.MountPropagation.\nfunc translateMountPropagation(mountMode *v1.MountPropagationMode) (runtimeapi.MountPropagation, error) {\n\tif runtime.GOOS == \"windows\" {\n\t\t// Windows containers doesn't support mount propagation, use private for it.\n\t\t// Refer https://docs.docker.com/storage/bind-mounts/#configure-bind-propagation."
  },
  {
    "id" : "a71f1c8d-ebf4-4e75-a518-c032f2c860dd",
    "prId" : 59767,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/59767#pullrequestreview-95957059",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7587fd73-6953-4c56-8cfe-d3ecd510d4ef",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "should we put this block before the getPhase call, and only call getPhase if this does not get executed?\r\n\r\ni feel like the core bug is in getPhase with some garbage collection scenario.",
        "createdAt" : "2018-02-12T21:49:35Z",
        "updatedAt" : "2018-02-12T21:49:44Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "aa332ef7-82a9-4347-a113-8a376c9182df",
        "parentId" : "7587fd73-6953-4c56-8cfe-d3ecd510d4ef",
        "authorId" : "8e9f49fc-1050-4601-b81c-83bf660c5eb8",
        "body" : "I would like to call `getPhase()` regardless so that we can catch it in the act and hopefully determine the root cause and possibly remove this check in the future.",
        "createdAt" : "2018-02-12T21:51:59Z",
        "updatedAt" : "2018-02-12T21:51:59Z",
        "lastEditedBy" : "8e9f49fc-1050-4601-b81c-83bf660c5eb8",
        "tags" : [
        ]
      },
      {
        "id" : "0222c942-4aef-4fe5-b58f-a57615eda177",
        "parentId" : "7587fd73-6953-4c56-8cfe-d3ecd510d4ef",
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "so i am skeptical that the logging will help identify the core problem any better.\r\n\r\ni think in a future pr, we should look to augment getPhase to pass in what we think the computed phase should have been in the case of a terminal state to help understand or better isolate why its coming up with something different, but for now, this is fine and helps alleviate a major issue we are seeing.",
        "createdAt" : "2018-02-12T21:58:50Z",
        "updatedAt" : "2018-02-12T21:58:50Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ab9ddeb19ca6db1cad11904894a41c87ce76a1b",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1360,1364 @@\tallStatus := append(append([]v1.ContainerStatus{}, s.ContainerStatuses...), s.InitContainerStatuses...)\n\ts.Phase = getPhase(spec, allStatus)\n\t// Check for illegal phase transition\n\tif pod.Status.Phase == v1.PodFailed || pod.Status.Phase == v1.PodSucceeded {\n\t\t// API server shows terminal phase; transitions are not allowed"
  },
  {
    "id" : "5f6dffd3-a615-40ce-8aa9-0292bda8a4c8",
    "prId" : 55665,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/55665#pullrequestreview-76652135",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "995e1e4e-e912-4567-99b4-cbe0c9cf99ba",
        "parentId" : null,
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "Should this just be in kubelet_windows.go and kubelet_linux.go files?",
        "createdAt" : "2017-11-14T23:46:03Z",
        "updatedAt" : "2017-11-17T00:22:04Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "3f6e8cdc-7043-4e59-bd9b-473946c8bc73",
        "parentId" : "995e1e4e-e912-4567-99b4-cbe0c9cf99ba",
        "authorId" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "body" : "I like it here better, since that way it will run in the unit tests on either platform.",
        "createdAt" : "2017-11-15T01:26:58Z",
        "updatedAt" : "2017-11-17T00:22:04Z",
        "lastEditedBy" : "d0e97b49-eba2-4b22-8695-df4f8a6776ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "6fa527869c78ea995ac7fe8300478115f939c10b",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +112,116 @@}\n\nfunc makeAbsolutePath(goos, path string) string {\n\tif goos != \"windows\" {\n\t\treturn \"/\" + path"
  },
  {
    "id" : "6ab2f93a-bad9-4ed4-9205-49e277713659",
    "prId" : 53167,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/53167#pullrequestreview-65929107",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a707f98-a8d7-4ae4-9c4e-03ba7c8d85e9",
        "parentId" : null,
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "nit: add `or if the pod has been deleted.`",
        "createdAt" : "2017-09-28T00:16:08Z",
        "updatedAt" : "2017-09-28T16:56:39Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      },
      {
        "id" : "f45bc05f-8c52-4b66-9682-53e4803d2497",
        "parentId" : "2a707f98-a8d7-4ae4-9c4e-03ba7c8d85e9",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "done",
        "createdAt" : "2017-09-28T16:57:37Z",
        "updatedAt" : "2017-09-28T16:57:37Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "4300c75d486ef0f6582c6a65f76108fff3cad330",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +821,825 @@}\n\n// IsPodTerminated returns trus if the pod with the provided UID is in a terminated state (\"Failed\" or \"Succeeded\")\n// or if the pod has been deleted or removed\nfunc (kl *Kubelet) IsPodTerminated(uid types.UID) bool {"
  },
  {
    "id" : "e1149051-3493-4e1f-9cf3-0476ea7a10b0",
    "prId" : 51209,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/51209#pullrequestreview-59445273",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1114cac5-d917-435d-ad58-c5ec8e1e9ff6",
        "parentId" : null,
        "authorId" : "87a378b9-1941-4a57-a346-cf12dbb73416",
        "body" : "What happens when there's some environment variable in both `opts.Envs` and `envs`?",
        "createdAt" : "2017-08-29T21:51:07Z",
        "updatedAt" : "2017-09-01T18:56:49Z",
        "lastEditedBy" : "87a378b9-1941-4a57-a346-cf12dbb73416",
        "tags" : [
        ]
      },
      {
        "id" : "fe3bda88-f2fb-4a2b-a03b-1bf570332452",
        "parentId" : "1114cac5-d917-435d-ad58-c5ec8e1e9ff6",
        "authorId" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "body" : "good question. We may add logic here to detect and log error such cases, but I think container runtime should handle this properly.",
        "createdAt" : "2017-08-30T06:05:03Z",
        "updatedAt" : "2017-09-01T18:56:49Z",
        "lastEditedBy" : "611b3189-700b-4eda-8a2a-2c4280218d7c",
        "tags" : [
        ]
      }
    ],
    "commit" : "02001af752cb6068ecab42ec5fd6a2792df38945",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +386,390 @@\t\treturn nil, false, err\n\t}\n\topts.Envs = append(opts.Envs, envs...)\n\n\t// Disabling adding TerminationMessagePath on Windows as these files would be mounted as docker volume and"
  },
  {
    "id" : "f14887e8-b1d3-46ea-b189-ec1aaac7edaa",
    "prId" : 47290,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/47290#pullrequestreview-44468726",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d52d8baa-5bbe-46d2-a94f-bb30c4c04a81",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "@jhorwit2 did you ever track down whether we need to be concerned with traversals in mount.MountPath?",
        "createdAt" : "2017-06-12T18:57:07Z",
        "updatedAt" : "2017-06-16T20:52:53Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "e08c5606-577e-4ad9-9012-24d431a781ff",
        "parentId" : "d52d8baa-5bbe-46d2-a94f-bb30c4c04a81",
        "authorId" : "e45395cd-3c20-445c-b404-a2b9ffe5efab",
        "body" : "I don't feel like that's a concern. That's the path within the container where the volume is mounted. Escaping out of that directory only yields you directories in the container you can already access; not extra info on the host. ",
        "createdAt" : "2017-06-12T19:31:26Z",
        "updatedAt" : "2017-06-16T20:52:53Z",
        "lastEditedBy" : "e45395cd-3c20-445c-b404-a2b9ffe5efab",
        "tags" : [
        ]
      },
      {
        "id" : "bf5ec6fd-e056-4edc-8541-2fc3036b7e33",
        "parentId" : "d52d8baa-5bbe-46d2-a94f-bb30c4c04a81",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "conceptually, that's what I would expect, but I don't know enough about the implementation to know if that is actually the case. would like an ack on that from @kubernetes/sig-storage-pr-reviews ",
        "createdAt" : "2017-06-12T20:38:15Z",
        "updatedAt" : "2017-06-16T20:52:53Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "6cde62a5-bd44-44d6-95ab-ab2ae9324e3b",
        "parentId" : "d52d8baa-5bbe-46d2-a94f-bb30c4c04a81",
        "authorId" : "e45395cd-3c20-445c-b404-a2b9ffe5efab",
        "body" : "This question is also outstanding, correct?",
        "createdAt" : "2017-06-16T03:13:06Z",
        "updatedAt" : "2017-06-16T20:52:53Z",
        "lastEditedBy" : "e45395cd-3c20-445c-b404-a2b9ffe5efab",
        "tags" : [
        ]
      },
      {
        "id" : "2f4100a7-bd7d-402b-ba20-7d7615c6be7b",
        "parentId" : "d52d8baa-5bbe-46d2-a94f-bb30c4c04a81",
        "authorId" : "8e448017-7838-493d-a424-33cada0da657",
        "body" : "@jhorwit2 is right, `MountPath` is relative to the inside of the container so it does not matter. `mount.SubPath` should be checked.",
        "createdAt" : "2017-06-16T03:49:31Z",
        "updatedAt" : "2017-06-16T20:52:53Z",
        "lastEditedBy" : "8e448017-7838-493d-a424-33cada0da657",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b3fb84abdc0fee12299eed262da287d48110de",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +139,143 @@\t\t\treturn nil, err\n\t\t}\n\t\tif mount.SubPath != \"\" {\n\t\t\tif filepath.IsAbs(mount.SubPath) {\n\t\t\t\treturn nil, fmt.Errorf(\"error SubPath `%s` must not be an absolute path\", mount.SubPath)"
  },
  {
    "id" : "d8471e1c-072d-443f-b5ff-3b1d95bcac9e",
    "prId" : 46444,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/46444#pullrequestreview-59983389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4de41f3b-5de8-4b51-8cb8-42769ae01d89",
        "parentId" : null,
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "If the feature is enabled, there is no way to specify `PRIVATE` and the default changes to HOST_TO_CONTAINER. \r\n\r\nThis *might* be fine for Alpha, but can we actually change the default mode in Beta/GA? Sorry I didn't follow the PR proposal closely, so most likely this has been answered before.",
        "createdAt" : "2017-08-31T18:43:16Z",
        "updatedAt" : "2017-09-01T19:39:42Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      },
      {
        "id" : "3493e733-48aa-4b08-a3dd-ca43fd75f020",
        "parentId" : "4de41f3b-5de8-4b51-8cb8-42769ae01d89",
        "authorId" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "body" : "The proposal expects that HOST_TO_CONTAINER is the new default and PRIVATE is not needed at all. We need to test this theory in alpha.",
        "createdAt" : "2017-08-31T19:32:37Z",
        "updatedAt" : "2017-09-01T19:39:42Z",
        "lastEditedBy" : "8b64e744-955d-4523-a3b7-60fae9df0857",
        "tags" : [
        ]
      },
      {
        "id" : "2115637c-5758-41fd-a70e-cb8c2ebe35f7",
        "parentId" : "4de41f3b-5de8-4b51-8cb8-42769ae01d89",
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "I'm slightly concerned that we won't gain enough confidence through feedback of this alpha feature. Changing the default behavior is always tricky.\r\nI don't want to block the PR since the proposal has been through rounds of reviews. We can come back to this before graduating the feature to beta.",
        "createdAt" : "2017-08-31T20:37:10Z",
        "updatedAt" : "2017-09-01T19:39:42Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      }
    ],
    "commit" : "03b753daad55b492bfc71d17b0c3109d404ee8e3",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +225,229 @@\t\treturn runtimeapi.MountPropagation_PROPAGATION_PRIVATE, nil\n\t}\n\tswitch {\n\tcase mountMode == nil:\n\t\t// HostToContainer is the default"
  },
  {
    "id" : "f72f8ca4-731a-446d-b088-55159a828077",
    "prId" : 45148,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/45148#pullrequestreview-35538727",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f161ecb3-e81c-46ac-8ac3-dddfd7787718",
        "parentId" : null,
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "Comment that this was previously validated to be a valid IP address and hostname?",
        "createdAt" : "2017-05-01T04:33:56Z",
        "updatedAt" : "2017-05-01T04:35:53Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      }
    ],
    "commit" : "407fe8b356f951a9e7fb3805faed3f9d899c5d6a",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +237,241 @@\tfor _, hostAlias := range hostAliases {\n\t\tfor _, hostname := range hostAlias.Hostnames {\n\t\t\tbuffer.WriteString(fmt.Sprintf(\"%s\\t%s\\n\", hostAlias.IP, hostname))\n\t\t}\n\t}"
  },
  {
    "id" : "d860c2b0-dbd9-4f7b-a830-f6ede14fa9a4",
    "prId" : 42585,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/42585#pullrequestreview-30673894",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ecb5ae67-6e9f-4dd6-8b40-ab61c3420879",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "@dashpole can we cleanup the volume code to use this active pod lister method instead? Not necessary for this PR",
        "createdAt" : "2017-03-06T23:21:24Z",
        "updatedAt" : "2017-03-06T23:21:24Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "acf007ee-2a4b-49b8-845a-2cf31228696f",
        "parentId" : "ecb5ae67-6e9f-4dd6-8b40-ab61c3420879",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "yes.  Nothing would give me more joy :)",
        "createdAt" : "2017-03-06T23:24:24Z",
        "updatedAt" : "2017-03-06T23:24:24Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      },
      {
        "id" : "1ba51379-7f2a-4b25-924f-6e2a8c2e53d6",
        "parentId" : "ecb5ae67-6e9f-4dd6-8b40-ab61c3420879",
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "@derekwaynecarr your change to `podIsTerminated` may cause other race conditions (e.g., pod worker still trying to start new containers). Could you remove this? \r\n\r\n/cc @Random-Liu @dchen1107 ",
        "createdAt" : "2017-03-09T02:47:40Z",
        "updatedAt" : "2017-03-09T02:47:40Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      },
      {
        "id" : "351699c3-5bf7-451f-a187-01372f051dc5",
        "parentId" : "ecb5ae67-6e9f-4dd6-8b40-ab61c3420879",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "This shouldn't have any effects during pod startup, as this change only makes a difference when the deletion timestamp is set.  I agree that we should do a more thorough review of what effects this could have, though.  In general, I think this is a better definition of podIsTerminated, as a pod that has been deleted, and has no containers running is definitely in a terminal state.",
        "createdAt" : "2017-04-04T01:59:28Z",
        "updatedAt" : "2017-04-04T01:59:28Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ce298c9aaa93708cd46df40ba20a080cc1a8b18",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +688,692 @@\t\tstatus = pod.Status\n\t}\n\treturn status.Phase == v1.PodFailed || status.Phase == v1.PodSucceeded || (pod.DeletionTimestamp != nil && notRunning(status.ContainerStatuses))\n}\n"
  },
  {
    "id" : "bb4fa35f-aecd-4bc9-8a20-237998551f0b",
    "prId" : 40239,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/40239#pullrequestreview-17773745",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "604115d7-13db-46ae-a156-1c5d9e9bad50",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "We need to add pod cgroups here. I'm ok with adding that in a separate PR.",
        "createdAt" : "2017-01-20T20:08:29Z",
        "updatedAt" : "2017-01-25T21:44:10Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "12ede81c-de9c-414a-9e16-5aa36e281423",
        "parentId" : "604115d7-13db-46ae-a156-1c5d9e9bad50",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "added.",
        "createdAt" : "2017-01-20T21:59:33Z",
        "updatedAt" : "2017-01-25T21:44:10Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1b9686c91a1739d68eb5e6a726a57172691a0dd",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +740,744 @@\t\treturn false\n\t}\n\tif kl.podVolumesExist(pod.UID) && !kl.kubeletConfiguration.KeepTerminatedPodVolumes {\n\t\t// We shouldnt delete pods whose volumes have not been cleaned up if we are not keeping terminated pod volumes\n\t\tglog.V(3).Infof(\"Pod %q is terminated, but some volumes have not been cleaned up\", format.Pod(pod))"
  },
  {
    "id" : "604eaee1-a694-4028-a1e7-f2ee432aab4a",
    "prId" : 40239,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/40239#pullrequestreview-17768002",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88db970b-d772-4a97-aadb-0252a3983d26",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "is it worth logging here or is there sufficient logging elsewhere if/when the volume could not be cleaned up (suspect there is, but worth confirming)",
        "createdAt" : "2017-01-20T20:32:03Z",
        "updatedAt" : "2017-01-25T21:44:10Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      },
      {
        "id" : "55c4ed1c-a751-4e37-8880-18f6313074eb",
        "parentId" : "88db970b-d772-4a97-aadb-0252a3983d26",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "There is logging related to volume unmounting in [pkg/kubelet/volumemanager/reconciler/reconciler.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/volumemanager/reconciler/reconciler.go).  My only concern is that most debugging people wont make the connection that their pod is not being deleted because unmounting a volume failed.  But I'm not sure how to notify users without logging every time they try to delete a pod (which is useless).",
        "createdAt" : "2017-01-20T21:25:54Z",
        "updatedAt" : "2017-01-25T21:44:10Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1b9686c91a1739d68eb5e6a726a57172691a0dd",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +741,745 @@\t}\n\tif kl.podVolumesExist(pod.UID) && !kl.kubeletConfiguration.KeepTerminatedPodVolumes {\n\t\t// We shouldnt delete pods whose volumes have not been cleaned up if we are not keeping terminated pod volumes\n\t\tglog.V(3).Infof(\"Pod %q is terminated, but some volumes have not been cleaned up\", format.Pod(pod))\n\t\treturn false"
  },
  {
    "id" : "79b7fec9-14ba-42ca-a060-f362d5971351",
    "prId" : 39479,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/39479#pullrequestreview-15376809",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01cfe399-03fd-4da2-98b1-d2c633219dc4",
        "parentId" : null,
        "authorId" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "body" : "nit: add a one-line comment explaining that the mutex is used to guard the mutation of the `killing` set.",
        "createdAt" : "2017-01-05T19:42:12Z",
        "updatedAt" : "2017-01-05T19:52:38Z",
        "lastEditedBy" : "1bd2d65a-7c93-4c22-b408-c7794d037dc5",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb3a1d6851319cf678b428e89b983dcf48c7239d",
    "line" : null,
    "diffHunk" : "@@ -1,1 +802,806 @@\tkilling := sets.NewString()\n\t// guard for the killing set\n\tlock := sync.Mutex{}\n\tfor {\n\t\tselect {"
  },
  {
    "id" : "d0e8f6bb-dc48-49cf-bdc6-a8240534e033",
    "prId" : 38989,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/38989#pullrequestreview-15952421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ad22a77-6157-469f-bce8-f6d04c7738f5",
        "parentId" : null,
        "authorId" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "body" : "just add a note that this is needed to ensure upgrade from 1.5 to 1.6 to set the field on upgrade.",
        "createdAt" : "2017-01-10T16:19:42Z",
        "updatedAt" : "2017-01-10T22:32:02Z",
        "lastEditedBy" : "6eca0ade-9879-4dd7-ad14-547e16f5c041",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2402b781b27ec9fa11827e64096d476ad49176b",
    "line" : null,
    "diffHunk" : "@@ -1,1 +1123,1127 @@\tapiPodStatus.PodIP = podStatus.IP\n\t// set status for Pods created on versions of kube older than 1.6\n\tapiPodStatus.QOSClass = qos.GetPodQOS(pod)\n\n\tapiPodStatus.ContainerStatuses = kl.convertToAPIContainerStatuses("
  },
  {
    "id" : "b82f1231-44f8-4000-adff-7315d0d601ca",
    "prId" : 36965,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/36965#pullrequestreview-283086961",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d470bb7-758b-45b7-9944-65ec85c50ed2",
        "parentId" : null,
        "authorId" : "52696d9d-2265-4848-a665-b13261a67e67",
        "body" : "i'm wondering if we should have put the log statement below this line where we trim off `-.` ",
        "createdAt" : "2019-09-03T15:39:56Z",
        "updatedAt" : "2019-09-03T15:39:56Z",
        "lastEditedBy" : "52696d9d-2265-4848-a665-b13261a67e67",
        "tags" : [
        ]
      }
    ],
    "commit" : "e9f1b0f972ae136a84fa0ddb9d21e33bf17292de",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +239,243 @@\tglog.Errorf(\"hostname for pod:%q was longer than %d. Truncated hostname to :%q\", podName, hostnameMaxLen, truncated)\n\t// hostname should not end with '-' or '.'\n\ttruncated = strings.TrimRight(truncated, \"-.\")\n\tif len(truncated) == 0 {\n\t\t// This should never happen."
  },
  {
    "id" : "653cd576-2f52-4fcf-add9-5df548179859",
    "prId" : 36245,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/36245#pullrequestreview-13551432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5dde63e7-c7bb-403f-a012-37e37807fb92",
        "parentId" : null,
        "authorId" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "body" : "Add a comment here explaining the order of evaluation of `EnvFrom` and `Env`",
        "createdAt" : "2016-12-19T13:31:55Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94866b3beee16e9db416395be9e3b27b81da2902",
    "line" : null,
    "diffHunk" : "@@ -1,1 +422,426 @@\t// Env will override EnvFrom variables.\n\t// Process EnvFrom first then allow Env to replace existing values.\n\tfor _, envFrom := range container.EnvFrom {\n\t\tif envFrom.ConfigMapRef != nil {\n\t\t\tname := envFrom.ConfigMapRef.Name"
  },
  {
    "id" : "bb66623e-0ca3-4a09-b336-91e8224cb664",
    "prId" : 36245,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/36245#pullrequestreview-13557039",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "002e2672-059f-4bfb-8da6-77fb291c150a",
        "parentId" : null,
        "authorId" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "body" : "I have doubts about whether this nil check is needed.  I realize that you're following the current pattern in this method, but as the original author of the method, I have doubts.",
        "createdAt" : "2016-12-19T13:35:16Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "tags" : [
        ]
      },
      {
        "id" : "bdbf52c7-bb64-4ead-b403-e43b6d9b7df0",
        "parentId" : "002e2672-059f-4bfb-8da6-77fb291c150a",
        "authorId" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "body" : "This type of check happens everywhere because there is no guarantee at the time of creation. It seems to allow a nil kubeClient.",
        "createdAt" : "2016-12-19T14:05:49Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "tags" : [
        ]
      }
    ],
    "commit" : "94866b3beee16e9db416395be9e3b27b81da2902",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +427,431 @@\t\t\tconfigMap, ok := configMaps[name]\n\t\t\tif !ok {\n\t\t\t\tif kl.kubeClient == nil {\n\t\t\t\t\treturn result, fmt.Errorf(\"Couldn't get configMap %v/%v, no kubeClient defined\", pod.Namespace, name)\n\t\t\t\t}"
  },
  {
    "id" : "376fed8c-8071-4197-a493-0657c0bf340f",
    "prId" : 36245,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/36245#pullrequestreview-14255029",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bc010f0-37e6-492e-9040-7e6b6e24602d",
        "parentId" : null,
        "authorId" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "body" : "I don't think this is the right behavior.  We shouldn't error out here -- skip this key or transform it.",
        "createdAt" : "2016-12-19T13:36:09Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "tags" : [
        ]
      },
      {
        "id" : "e348a7f3-4b30-468a-a89d-e8ff5f472a8b",
        "parentId" : "3bc010f0-37e6-492e-9040-7e6b6e24602d",
        "authorId" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "body" : "This is the behavior you get if you define invalid env vars as well. The problem here is that we need to do it at run time instead. But this is how the proposal was written.\r\n\r\nWe can't transform it since we don't know what was invalid. Skipping is even worse since you have no idea why an environment variable went missing.\r\nCurrently you will see your container failed to start and a message in the log.",
        "createdAt" : "2016-12-19T14:07:32Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "tags" : [
        ]
      },
      {
        "id" : "f2a95165-4642-4f13-92b4-9ad628d8bd07",
        "parentId" : "3bc010f0-37e6-492e-9040-7e6b6e24602d",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "I agree - mutating it is wrong, ignoring it is wrong.  ",
        "createdAt" : "2016-12-23T01:13:21Z",
        "updatedAt" : "2017-01-03T16:45:52Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      }
    ],
    "commit" : "94866b3beee16e9db416395be9e3b27b81da2902",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +438,442 @@\t\t\t}\n\t\t\tfor k, v := range configMap.Data {\n\t\t\t\tif errMsgs := utilvalidation.IsCIdentifier(k); len(errMsgs) != 0 {\n\t\t\t\t\treturn result, fmt.Errorf(\"Invalid environment variable name, %v, from configmap %v/%v: %s\", k, pod.Namespace, name, errMsgs[0])\n\t\t\t\t}"
  },
  {
    "id" : "2201f02e-250b-4b7d-bf1a-4603a98da4cd",
    "prId" : 36245,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/36245#pullrequestreview-15026885",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8aa0fca-a9d1-450b-9d8b-ce667957e864",
        "parentId" : null,
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "shouldn't the `IsCIdentifier` check go after we've prepended the prefix and determined the final `k` we will use?",
        "createdAt" : "2017-01-03T22:10:58Z",
        "updatedAt" : "2017-01-03T22:11:02Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "0b055c06-98d0-4435-8ec2-2b596bced096",
        "parentId" : "d8aa0fca-a9d1-450b-9d8b-ce667957e864",
        "authorId" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "body" : "In theory it shouldn't matter but it can be moved.\r\nThe Prefix is already guaranteed to be a valid C identifier. I cannot imagine a case where you merge 2 c identifiers create an invalid c identifier. But it would be more clear.",
        "createdAt" : "2017-01-03T22:15:02Z",
        "updatedAt" : "2017-01-03T22:15:02Z",
        "lastEditedBy" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "tags" : [
        ]
      },
      {
        "id" : "3f6c7e3e-bfc5-469d-847d-2d530dd9b133",
        "parentId" : "d8aa0fca-a9d1-450b-9d8b-ce667957e864",
        "authorId" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "body" : "> I cannot imagine a case where you merge 2 c identifiers create an invalid c identifier. But it would be more clear.\r\n\r\nOther way around. A prefix could make a key that is not a valid C identifier (like `123`) valid (e.g. `FOO_123`).",
        "createdAt" : "2017-01-03T22:28:59Z",
        "updatedAt" : "2017-01-03T22:29:04Z",
        "lastEditedBy" : "8be927c4-cfb4-4077-b355-f4f3d84849b8",
        "tags" : [
        ]
      },
      {
        "id" : "a0dd9d4e-c08b-4574-aa49-d22cfd55a755",
        "parentId" : "d8aa0fca-a9d1-450b-9d8b-ce667957e864",
        "authorId" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "body" : "Will fix this in a separate PR. Thi is the case where a configmap can make a prefix required.",
        "createdAt" : "2017-01-03T22:35:30Z",
        "updatedAt" : "2017-01-03T22:35:30Z",
        "lastEditedBy" : "6314844c-5310-477a-96a1-0fc838ec485f",
        "tags" : [
        ]
      }
    ],
    "commit" : "94866b3beee16e9db416395be9e3b27b81da2902",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +443,447 @@\n\t\t\t\tif len(envFrom.Prefix) > 0 {\n\t\t\t\t\tk = envFrom.Prefix + k\n\t\t\t\t}\n\t\t\t\t// Accesses apiserver+Pods."
  },
  {
    "id" : "ff6837a0-dba7-436c-9583-0596d31ba215",
    "prId" : 33663,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/33663#pullrequestreview-6413831",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff4d2d8b-1b80-477c-b2bf-33cb4a5cba9e",
        "parentId" : null,
        "authorId" : "c63e1ceb-64bd-4726-b8ef-e647d73dae0c",
        "body" : "Maybe comment it with `Isolate pods on each host from one another by default`? Thought it is already captured in the docs (I liked reading it), the comment here could help to make the correct associations sooner. Just nit.\n",
        "createdAt" : "2016-10-27T11:45:07Z",
        "updatedAt" : "2016-10-27T11:45:21Z",
        "lastEditedBy" : "c63e1ceb-64bd-4726-b8ef-e647d73dae0c",
        "tags" : [
        ]
      },
      {
        "id" : "814f1c4c-62de-4d1b-8f36-e638a7c35456",
        "parentId" : "ff4d2d8b-1b80-477c-b2bf-33cb4a5cba9e",
        "authorId" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "body" : "@ingvagabund I'm not sure I understand what is being asked for here.  Elaborate?\n",
        "createdAt" : "2016-10-28T14:57:38Z",
        "updatedAt" : "2016-10-28T14:57:39Z",
        "lastEditedBy" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "tags" : [
        ]
      },
      {
        "id" : "6e136a63-44ed-4da6-892c-fb5b6004a5c1",
        "parentId" : "ff4d2d8b-1b80-477c-b2bf-33cb4a5cba9e",
        "authorId" : "c63e1ceb-64bd-4726-b8ef-e647d73dae0c",
        "body" : "to point out the `SELinuxRelabel` is set to true to isolate the pods from each other by default.\n",
        "createdAt" : "2016-10-31T10:38:53Z",
        "updatedAt" : "2016-10-31T10:38:53Z",
        "lastEditedBy" : "c63e1ceb-64bd-4726-b8ef-e647d73dae0c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa855b9f24d73e4b62aab7cd15ddb4bf1f5061dc",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +138,142 @@\t\tHostPath:       hostsFilePath,\n\t\tReadOnly:       false,\n\t\tSELinuxRelabel: true,\n\t}, nil\n}"
  },
  {
    "id" : "70a30a24-e23d-4300-b51b-b29297277d75",
    "prId" : 31169,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1fce9f0-67ad-4d2b-9b85-88cd70738a7f",
        "parentId" : null,
        "authorId" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "body" : "note to other reviewers: I asked @pweil- to name this file as such, going to put a ton of other stuff into it in a planned refactor.\n",
        "createdAt" : "2016-08-23T12:59:28Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "498aade9-b8f0-4e29-8055-89afa6f5fcc8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0d78f478ce0fb9d5e121db3b7c6993b482af82c",
    "line" : null,
    "diffHunk" : "@@ -1,1 +15,19 @@*/\n\npackage kubelet\n\nimport ("
  },
  {
    "id" : "5b1d7f28-d4e4-4ee9-98e8-a9a7fe05e858",
    "prId" : 31169,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Why does the entire pod have to run in the native userns if a single container is privileged? \n",
        "createdAt" : "2016-09-02T18:36:33Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "066cb247-905f-49ab-b747-005f63a0243b",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "body" : "I worry about the interaction between mixed namespaces in a single pod.  We've seen issues in the past with them that were very hard to debug.  Also, the flags for controlling namespaces are on the host level and get applied to every container so I went with that convention here.\n",
        "createdAt" : "2016-09-02T18:51:47Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "tags" : [
        ]
      },
      {
        "id" : "e375c469-7cb4-4f53-9190-ba0a0ea44f50",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "body" : "> Also, the flags for controlling namespaces are on the host level and get applied to every container so I went with that convention here.\n\nI should say, specifically, the flags are on the `PodSecurityContext`.\n",
        "createdAt" : "2016-09-02T18:52:35Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "tags" : [
        ]
      },
      {
        "id" : "84cb0de6-0a23-4051-aa5b-af7ccd0e854a",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "Yeah I thought this was consistent with the other flags.  Specifically net\n(you can't escape net in just one container).\n\nAlthough as soon as I typed that, I realized that we have a use case for\nprivileged in one container and not in another coming up which now has me\nterribly worried.\n\nOn Fri, Sep 2, 2016 at 2:52 PM, Paul Weil notifications@github.com wrote:\n\n> In pkg/kubelet/kubelet_pods.go\n> https://github.com/kubernetes/kubernetes/pull/31169#discussion_r77395627\n> :\n> \n> > -   \"k8s.io/kubernetes/pkg/api\"\n> >   +)\n> >   +\n> >   +// enableHostUserNamespace determines if the host user namespace should be used by the container runtime.\n> >   +// Returns true if the pod is using a host pid, pic, or network namespace, the pod is using a non-namespaced\n> >   +// capability, the pod contains a privileged container, or the pod has a host path volume.\n> >   +func (kl *Kubelet) enableHostUserNamespace(pod *api.Pod) bool {\n> > -   if hasPrivilegedContainer(pod) || hasHostNamespace(pod) ||\n> > -       hasHostVolume(pod) || hasNonNamespacedCapability(pod) || kl.hasHostMountPVC(pod) {\n> > -       return true\n> > -   }\n> > -   return false\n> >   +}\n> >   +\n> >   +// hasPrivilegedContainer returns true if any of the containers in the pod are privileged.\n> >   +func hasPrivilegedContainer(pod *api.Pod) bool {\n> \n> Also, the flags for controlling namespaces are on the host level and get\n> applied to every container so I went with that convention here.\n> \n> I should say, specifically, the flags are on the PodSecurityContext.\n> \n> \n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/31169/files/423ccec9b7b7582c3a4298015d4d23a71d664567#r77395627,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABG_p5xAH6Vm_YI1XPXdmCfGMBQLe9YJks5qmHCBgaJpZM4JqWln\n> .\n",
        "createdAt" : "2016-09-02T20:07:23Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "0443001b-a759-4317-b193-8f73000e143a",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "AFAIK, we don't share userns in a pod. So why would it matter if a single\ncontainer in a multi-container pod were to use native userns?\n\nOn Fri, Sep 2, 2016 at 1:08 PM, Clayton Coleman notifications@github.com\nwrote:\n\n> In pkg/kubelet/kubelet_pods.go\n> https://github.com/kubernetes/kubernetes/pull/31169#discussion_r77404766\n> :\n> \n> > -   \"k8s.io/kubernetes/pkg/api\"\n> >   +)\n> >   +\n> >   +// enableHostUserNamespace determines if the host user namespace should be used by the container runtime.\n> >   +// Returns true if the pod is using a host pid, pic, or network namespace, the pod is using a non-namespaced\n> >   +// capability, the pod contains a privileged container, or the pod has a host path volume.\n> >   +func (kl *Kubelet) enableHostUserNamespace(pod *api.Pod) bool {\n> > -   if hasPrivilegedContainer(pod) || hasHostNamespace(pod) ||\n> > -       hasHostVolume(pod) || hasNonNamespacedCapability(pod) || kl.hasHostMountPVC(pod) {\n> > -       return true\n> > -   }\n> > -   return false\n> >   +}\n> >   +\n> >   +// hasPrivilegedContainer returns true if any of the containers in the pod are privileged.\n> >   +func hasPrivilegedContainer(pod *api.Pod) bool {\n> \n> Yeah I thought this was consistent with the other flags. Specifically net\n> (you can't escape net in just one container). Although as soon as I typed\n> that, I realized that we have a use case for privileged in one container\n> and not in another coming up which now has me terribly worried.\n>  <#m_-3924339393635099543_>\n> On Fri, Sep 2, 2016 at 2:52 PM, Paul Weil **_@**_.***> wrote: In\n> pkg/kubelet/kubelet_pods.go <#31169 (comment)\n> https://github.com/kubernetes/kubernetes/pull/31169#discussion_r77395627>\n> : > + \"k8s.io/kubernetes/pkg/api\" > +) > + > +// enableHostUserNamespace\n> determines if the host user namespace should be used by the container\n> runtime. > +// Returns true if the pod is using a host pid, pic, or network\n> namespace, the pod is using a non-namespaced > +// capability, the pod\n> contains a privileged container, or the pod has a host path volume. > +func\n> (kl *Kubelet) enableHostUserNamespace(pod *api.Pod) bool { > + if\n> hasPrivilegedContainer(pod) || hasHostNamespace(pod) || > +\n> hasHostVolume(pod) || hasNonNamespacedCapability(pod) ||\n> kl.hasHostMountPVC(pod) { > + return true > + } > + return false > +} > + >\n> +// hasPrivilegedContainer returns true if any of the containers in the pod\n> are privileged. > +func hasPrivilegedContainer(pod *api.Pod) bool { Also,\n> the flags for controlling namespaces are on the host level and get applied\n> to every container so I went with that convention here. I should say,\n> specifically, the flags are on the PodSecurityContext.  You are receiving\n> this because you were mentioned. Reply to this email directly, view it on\n> GitHub <https://github.com/kubernetes/kubernetes/pull/31169/files/\n> 423ccec9b7b7582c3a4298015d4d23a71d664567#r77395627>, or mute the thread <\n> https://github.com/notifications/unsubscribe-auth/ABG_p5xAH6Vm_\n> YI1XPXdmCfGMBQLe9YJks5qmHCBgaJpZM4JqWln> .\n> \n> \n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/31169/files/423ccec9b7b7582c3a4298015d4d23a71d664567#r77404766,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AGvIKMyft_lxbDu_hDB2dsGOTKwmfxqEks5qmIIsgaJpZM4JqWln\n> .\n",
        "createdAt" : "2016-09-02T20:43:08Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "8b7706a5-2d6c-4f90-9f8b-129fa810c6a6",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "body" : "> AFAIK, we don't share userns in a pod. So why would it matter if a single container in a multi-container pod were to use native userns?\n\nActually, it is required that a container shares a userns with another container if it shares any namespace with the other container else it won't have the correct capabilities in the namespace. (This happens by default in docker).\n",
        "createdAt" : "2016-09-02T21:18:16Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "tags" : [
        ]
      },
      {
        "id" : "3a13b40a-c106-4824-8ecc-5c584037be59",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Ohhh!!! Does this mean that with userns enabled, containers in a pod will\nautomatically share userns with docker?\n\nOn Fri, Sep 2, 2016 at 2:19 PM, Mrunal Patel notifications@github.com\nwrote:\n\n> In pkg/kubelet/kubelet_pods.go\n> https://github.com/kubernetes/kubernetes/pull/31169#discussion_r77413259\n> :\n> \n> > -   \"k8s.io/kubernetes/pkg/api\"\n> >   +)\n> >   +\n> >   +// enableHostUserNamespace determines if the host user namespace should be used by the container runtime.\n> >   +// Returns true if the pod is using a host pid, pic, or network namespace, the pod is using a non-namespaced\n> >   +// capability, the pod contains a privileged container, or the pod has a host path volume.\n> >   +func (kl *Kubelet) enableHostUserNamespace(pod *api.Pod) bool {\n> > -   if hasPrivilegedContainer(pod) || hasHostNamespace(pod) ||\n> > -       hasHostVolume(pod) || hasNonNamespacedCapability(pod) || kl.hasHostMountPVC(pod) {\n> > -       return true\n> > -   }\n> > -   return false\n> >   +}\n> >   +\n> >   +// hasPrivilegedContainer returns true if any of the containers in the pod are privileged.\n> >   +func hasPrivilegedContainer(pod *api.Pod) bool {\n> \n> AFAIK, we don't share userns in a pod. So why would it matter if a single\n> container in a multi-container pod were to use native userns?\n> \n> Actually, it is required that a container shares a userns with another\n> container if it shares any namespace with the other container else it won't\n> have the correct capabilities in the namespace. (This happens by default in\n> docker).\n> \n> \n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/31169/files/423ccec9b7b7582c3a4298015d4d23a71d664567#r77413259,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AGvIKGUbkJJZLbPYiXhYhlFA9xq0AxoFks5qmJLMgaJpZM4JqWln\n> .\n",
        "createdAt" : "2016-09-02T22:43:03Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "b2f77d8e-526d-49c0-b167-55fed11a35e6",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "body" : "Yes.\n\n> On Sep 2, 2016, at 3:43 PM, Vish Kannan notifications@github.com wrote:\n> \n> In pkg/kubelet/kubelet_pods.go:\n> \n> > -   \"k8s.io/kubernetes/pkg/api\"\n> >   +)\n> >   +\n> >   +// enableHostUserNamespace determines if the host user namespace should be used by the container runtime.\n> >   +// Returns true if the pod is using a host pid, pic, or network namespace, the pod is using a non-namespaced\n> >   +// capability, the pod contains a privileged container, or the pod has a host path volume.\n> >   +func (kl *Kubelet) enableHostUserNamespace(pod *api.Pod) bool {\n> > -   if hasPrivilegedContainer(pod) || hasHostNamespace(pod) ||\n> > -       hasHostVolume(pod) || hasNonNamespacedCapability(pod) || kl.hasHostMountPVC(pod) {\n> > -       return true\n> > -   }\n> > -   return false\n> >   +}\n> >   +\n> >   +// hasPrivilegedContainer returns true if any of the containers in the pod are privileged.\n> >   +func hasPrivilegedContainer(pod *api.Pod) bool {\n> >   Ohhh!!! Does this mean that with userns enabled, containers in a pod will automatically share userns with docker?\n> >   \n> >   \n> >   You are receiving this because you were mentioned.\n> >   Reply to this email directly, view it on GitHub, or mute the thread.\n",
        "createdAt" : "2016-09-02T22:53:37Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "tags" : [
        ]
      },
      {
        "id" : "a39f5b08-9f46-4a79-90b1-e3821e70f6e8",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "body" : "I think this is resolved then.  Thanks @mrunalp for clarifying\n",
        "createdAt" : "2016-09-06T12:50:32Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "tags" : [
        ]
      },
      {
        "id" : "ababa607-a0e0-4973-9b0a-0f4b1c97e8e5",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Ok. Then all containers in k8s should be sharing userns since they share netns by default. \n@pweil- Can you include this information as a comment in your PR?\n",
        "createdAt" : "2016-09-06T18:10:50Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "fa7f8f9f-9f1d-4631-afdc-1ea3ce2c70e2",
        "parentId" : "75ff7d0b-e69e-452a-8d07-5c74f0f2d18c",
        "authorId" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "body" : "added\n\n```\n// NOTE: when if a container shares any namespace with another container it must also share the user namespace\n// or it will not have the correct capabilities in the namespace.  This means that host user namespace\n// is enabled per pod, not per container.\n```\n\nto `kubelet_pods.go`\n",
        "createdAt" : "2016-09-07T12:53:54Z",
        "updatedAt" : "2016-11-14T16:12:18Z",
        "lastEditedBy" : "fb0525d4-54d0-4bfa-8b41-17f8b31b43fd",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0d78f478ce0fb9d5e121db3b7c6993b482af82c",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1420,1424 @@\n// hasPrivilegedContainer returns true if any of the containers in the pod are privileged.\nfunc hasPrivilegedContainer(pod *api.Pod) bool {\n\tfor _, c := range pod.Spec.Containers {\n\t\tif c.SecurityContext != nil &&"
  }
]