[
  {
    "id" : "53798731-e563-471d-a88f-357646d99ae7",
    "prId" : 102444,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/102444#pullrequestreview-698638857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ff3fc83-eed4-4d88-914f-e91b1990a338",
        "parentId" : null,
        "authorId" : "30ef68c0-8c88-498d-992d-fb90e4036cc2",
        "body" : "just use `float64(s.StartTime.Unix())` here?",
        "createdAt" : "2021-07-04T05:38:18Z",
        "updatedAt" : "2021-07-04T05:38:18Z",
        "lastEditedBy" : "30ef68c0-8c88-498d-992d-fb90e4036cc2",
        "tags" : [
        ]
      }
    ],
    "commit" : "43f8f58895d29f46a7de5524a143f035772507b3",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +165,169 @@\t}\n\n\tch <- metrics.NewLazyConstMetric(containerStartTimeDesc, metrics.GaugeValue, float64(s.StartTime.UnixNano())/float64(time.Second), s.Name, pod.PodRef.Name, pod.PodRef.Namespace)\n}\n"
  },
  {
    "id" : "3d87fefd-22b3-45e2-ae60-2729a14eebdf",
    "prId" : 95839,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95839#pullrequestreview-524515537",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "330e49c5-bfa1-4c7e-a1e4-7c4719e178b0",
        "parentId" : null,
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "lacking context here. I wonder how this value is being populated in the first place. Is there a test on it?",
        "createdAt" : "2020-10-30T21:58:48Z",
        "updatedAt" : "2020-11-03T18:15:09Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "a2cca4d1-c081-403b-82c1-761789290117",
        "parentId" : "330e49c5-bfa1-4c7e-a1e4-7c4719e178b0",
        "authorId" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "body" : "also: would it be helpful to validate that sum of containers is less then the value of this metric in runtime?",
        "createdAt" : "2020-10-30T21:59:35Z",
        "updatedAt" : "2020-11-03T18:15:09Z",
        "lastEditedBy" : "85d51570-e06e-4b3f-a869-f5f820e49119",
        "tags" : [
        ]
      },
      {
        "id" : "ae3d46f3-e4a6-4d93-9be3-d26e24730fde",
        "parentId" : "330e49c5-bfa1-4c7e-a1e4-7c4719e178b0",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "@dashpole, please correct me if I'm wrong.\r\n\r\nThese are values which are pulled from the memory and CPU cgroups on the host. *I* don't think it would make sense to do any validation here, since we are reporting values from the cgroups.  \r\n\r\nThe container cgroups are children of the pod cgroup, so we should not hit that scenario (unless we are reading the values at different times).",
        "createdAt" : "2020-11-02T17:20:47Z",
        "updatedAt" : "2020-11-03T18:15:09Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      },
      {
        "id" : "2d4f899a-6b90-423d-9007-b38b41cd6e21",
        "parentId" : "330e49c5-bfa1-4c7e-a1e4-7c4719e178b0",
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "I'd rather do validation of the values as part of e2e tests than in code.  I don't think we have enough information to know if values are correct here.  As @egernst points out, it may be tricky to get such a validation to avoid false positives, as different collection times can mean the containers can temporarily exceed pod values.",
        "createdAt" : "2020-11-05T17:47:19Z",
        "updatedAt" : "2020-11-05T17:47:20Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      }
    ],
    "commit" : "b26b755e94a709f343d030e18391c3d0cc05e78a",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +178,182 @@\tch <- metrics.NewLazyMetricWithTimestamp(pod.CPU.Time.Time,\n\t\tmetrics.NewLazyConstMetric(podCPUUsageDesc, metrics.CounterValue,\n\t\t\tfloat64(*pod.CPU.UsageCoreNanoSeconds)/float64(time.Second), pod.PodRef.Name, pod.PodRef.Namespace))\n}\n"
  },
  {
    "id" : "2ec5def5-47f6-431f-b614-db51a8bacca3",
    "prId" : 95839,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95839#pullrequestreview-526865703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89bc5185-f32d-44a8-b0d9-d156b20b0311",
        "parentId" : null,
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "How is this different from `container_memory_working_set_bytes{pod=\"X\",namespace=\"Y\",container=\"\"}` (which should be working set of the pod)?",
        "createdAt" : "2020-11-03T19:30:34Z",
        "updatedAt" : "2020-11-03T19:30:35Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "ccf133fa-e7ad-4692-9773-30fb43e00193",
        "parentId" : "89bc5185-f32d-44a8-b0d9-d156b20b0311",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "Not all processes associated with running a pod are within the container cgroups themselves, but instead within the pod cgroup created by kubelet. For example, conmon in the standard/crio case.\r\n\r\nTo facilitate accurate accounting when utilizing sandboxed runtimes, it is important to be able to assess pod level resource usage, since this will account for any VMM/sentry/conmon/shim processes running to facilitate running the containers. Sum of container usage will be less than pod usage, and this is a major issue when using sandboxed runtimes.",
        "createdAt" : "2020-11-03T21:02:46Z",
        "updatedAt" : "2020-11-03T21:06:56Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      },
      {
        "id" : "254eeb47-0fa0-4cfe-8ea5-2bac55861643",
        "parentId" : "89bc5185-f32d-44a8-b0d9-d156b20b0311",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "`container_memory_working_set_bytes{pod=\"X\",namespace=\"Y\",container=\"\"}` is the pod cgroup measurement today of memory.  This should not be sum of container usage, but is the direct cgroup measured value (and has been for quite a few releases).  Crio should account for conmon in the pod cgroup (although I know recently we changed some stuff around - @mrunalp what was the outcome here?)\r\n\r\nHere's a 1.19 cluster with crio from systemd-cgls:\r\n\r\n```\r\n  │ ├─kubepods-burstable-podb7e40d48_a9da_4b45_bc36_d5d1a6cc2fe2.slice\r\n  │ │ ├─crio-44974e038bd96557f71f44779b0a1603bb02b42494ee8ffce3aae974fc40264f.scope\r\n  │ │ │ ├─4076273 /bin/sh /var/lib/tuned/bin/run start\r\n  │ │ │ ├─4076299 openshift-tuned -v=0\r\n  │ │ │ └─4076484 /usr/libexec/platform-python -Es /usr/sbin/tuned --no-dbus\r\n  │ │ ├─crio-conmon-d3ed68c63a2c3dfadc1082574d4dae59946120a7c49056d18f970b75ca520e43.scope\r\n  │ │ │ └─4076177 /usr/libexec/crio/conmon -b /var/run/containers/storage/overlay-containers/d3ed68c63a2c3dfadc1082574d4dae59946120a7c49056d18f970b75ca520e43/userdata ->\r\n```\r\n\r\n```\r\n$ cat /sys/fs/cgroup/memory/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podb7e40d48_a9da_4b45_bc36_d5d1a6cc2fe2.slice/memory.memsw.usage_in_bytes\r\n65708032\r\n```\r\n\r\nFrom prometheus \r\n\r\n```\r\ncontainer_memory_usage_bytes{endpoint=\"https-metrics\",id=\"/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podb7e40d48_a9da_4b45_bc36_d5d1a6cc2fe2.slice\",instance=\"10.0.153.142:10250\",job=\"kubelet\",metrics_path=\"/metrics/cadvisor\",namespace=\"openshift-cluster-node-tuning-operator\",node=\"ip-10-0-153-142.ec2.internal\",pod=\"tuned-cg8rv\",service=\"kubelet\"} 65708032\r\n```\r\n\r\n`container=\"\"` shows the pod cgroup usage correctly on 1.19 at least.\r\n\r\n",
        "createdAt" : "2020-11-07T20:47:08Z",
        "updatedAt" : "2020-11-07T20:47:55Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "ff48b5e5-6291-49c8-8efb-ae2a3aaf7383",
        "parentId" : "89bc5185-f32d-44a8-b0d9-d156b20b0311",
        "authorId" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "body" : "@smarterclayton We ship with the conmon scope nested under the pod cgroup slice. We have an option to move it to a dedicated cgroup slice outside the pod, but don't use it in OpenShift.",
        "createdAt" : "2020-11-10T05:34:10Z",
        "updatedAt" : "2020-11-10T05:34:10Z",
        "lastEditedBy" : "5328b1c0-0dbd-4fd8-869d-e914880959c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b26b755e94a709f343d030e18391c3d0cc05e78a",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +64,68 @@\tpodMemoryUsageDesc = metrics.NewDesc(\"pod_memory_working_set_bytes\",\n\t\t\"Current working set of the pod in bytes\",\n\t\t[]string{\"pod\", \"namespace\"},\n\t\tnil,\n\t\tmetrics.ALPHA,"
  },
  {
    "id" : "856db274-a3fe-41d0-b628-c2eca6d09ac6",
    "prId" : 95839,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/95839#pullrequestreview-522871853",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c332e3e-6797-42a2-9c93-2848be44d00b",
        "parentId" : null,
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "How is this different from `container_cpu_usage_seconds_total{pod=\"X\",namespace=\"Y\",container=\"\"}` (which should be total CPU seconds of the pod cgroup)?",
        "createdAt" : "2020-11-03T19:31:17Z",
        "updatedAt" : "2020-11-03T19:31:26Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "f26f7916-acb4-4ebb-8e01-b52572116384",
        "parentId" : "4c332e3e-6797-42a2-9c93-2848be44d00b",
        "authorId" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "body" : "Not all processes associated with running a pod are within the container cgroups themselves, but instead within the pod cgroup created by kubelet. For example, conmon in the standard/crio case.\r\n\r\nTo facilitate accurate accounting when utilizing sandboxed runtimes, it is important to be able to assess pod level resource usage, since this will account for any VMM/sentry/conmon/shim processes running to facilitate running the containers. Sum of container usage will be less than pod usage, and this is a major issue when using sandboxed runtimes.",
        "createdAt" : "2020-11-03T21:02:41Z",
        "updatedAt" : "2020-11-03T21:07:01Z",
        "lastEditedBy" : "1ccd067e-9fba-4e11-a385-9b3c638dbd8a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b26b755e94a709f343d030e18391c3d0cc05e78a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +55,59 @@\t\t\"\")\n\n\tpodCPUUsageDesc = metrics.NewDesc(\"pod_cpu_usage_seconds_total\",\n\t\t\"Cumulative cpu time consumed by the pod in core-seconds\",\n\t\t[]string{\"pod\", \"namespace\"},"
  },
  {
    "id" : "8eafaa4e-fd44-47d0-903b-905cab3cd103",
    "prId" : 86282,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/86282#pullrequestreview-333695493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "abd3c4ec-2cc6-4d89-a801-94c6bbd23e9f",
        "parentId" : null,
        "authorId" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "body" : "This appears to be very similar to the existing collector.  Can we re-use that one?",
        "createdAt" : "2019-12-16T19:31:58Z",
        "updatedAt" : "2019-12-16T19:31:58Z",
        "lastEditedBy" : "d2b16581-e7e9-48b8-9f76-6f6bcb9ec300",
        "tags" : [
        ]
      },
      {
        "id" : "9eeac20b-e175-4a82-9d7b-f4342fd7766c",
        "parentId" : "abd3c4ec-2cc6-4d89-a801-94c6bbd23e9f",
        "authorId" : "ae15cfb8-5436-4398-94e0-d443e413b257",
        "body" : "Yes we can, but that is very limited.\r\n\r\nWe can only share the `DescribeWithStability`, that is the limited thing i mean, but if we do that, we need a little bit more complex logic  in `CollectWithStability`.  So I think we may lose more than we gain.\r\n\r\nConsidering the existing will be removed later, we only need to remove dead code by then, and don't need to change any working code.",
        "createdAt" : "2019-12-18T02:16:46Z",
        "updatedAt" : "2019-12-18T02:16:46Z",
        "lastEditedBy" : "ae15cfb8-5436-4398-94e0-d443e413b257",
        "tags" : [
        ]
      }
    ],
    "commit" : "c394d821fdafd719619eb63fcd1065a95ec02ef9",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +15,19 @@*/\n\npackage collectors\n\nimport ("
  }
]