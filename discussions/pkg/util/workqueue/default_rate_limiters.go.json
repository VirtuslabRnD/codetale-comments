[
  {
    "id" : "23c1b89d-3d1f-4b72-ae92-07ffa13dd588",
    "prId" : 32082,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "parentId" : null,
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "1000 seconds?!\n",
        "createdAt" : "2016-09-06T14:18:52Z",
        "updatedAt" : "2016-09-06T14:18:52Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "be60bc2b-a696-472b-9afc-9b66c5e17b28",
        "parentId" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "This didn't change - it was 1000s also before this PR.\n",
        "createdAt" : "2016-09-06T14:19:38Z",
        "updatedAt" : "2016-09-06T14:19:38Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "8b57d18d-9a85-440f-877e-2c455959f859",
        "parentId" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "It seems that @deads2k has strong opinion that this value should be high.\n",
        "createdAt" : "2016-09-06T14:20:01Z",
        "updatedAt" : "2016-09-06T14:20:01Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "f63186ef-2858-4772-8346-6a235530f355",
        "parentId" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "authorId" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "body" : "I'm fine\n",
        "createdAt" : "2016-09-06T14:29:47Z",
        "updatedAt" : "2016-09-06T14:29:47Z",
        "lastEditedBy" : "6e2b5eda-1533-4798-a56c-432faaf38480",
        "tags" : [
        ]
      },
      {
        "id" : "eda53753-7d33-4ab3-b7d2-92dc4acea3e1",
        "parentId" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "authorId" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "body" : "> It seems that @deads2k has strong opinion that this value should be high.\n\n@smarterclayton does too, since we want to have controllers retry on external conditions that are eventually fixed, but not loop quickly on them.  An image import that fails 20 times for instance.  Maybe it comes back up.  May as well try infrequently, especially since we're talking about removing resync-ing.\n",
        "createdAt" : "2016-09-06T14:32:00Z",
        "updatedAt" : "2016-09-06T14:32:00Z",
        "lastEditedBy" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "tags" : [
        ]
      },
      {
        "id" : "b468a48f-bfc3-4fd3-b2a3-c67b9ba786e0",
        "parentId" : "be7482a1-3808-4da0-92e9-c521679b0ea4",
        "authorId" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "body" : "Yeah - I wanted to make it a 100, but there was a strong opposition:)\n",
        "createdAt" : "2016-09-06T15:00:08Z",
        "updatedAt" : "2016-09-06T15:00:08Z",
        "lastEditedBy" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b8aeaf50028504bbe830c047f01fd66c8e421ae",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +39,43 @@func DefaultControllerRateLimiter() RateLimiter {\n\treturn NewMaxOfRateLimiter(\n\t\tNewItemExponentialFailureRateLimiter(5*time.Millisecond, 1000*time.Second),\n\t\t// 10 qps, 100 bucket size.  This is only for retry speed and its only the overall factor (not per item)\n\t\t&BucketRateLimiter{Bucket: ratelimit.NewBucketWithRate(float64(10), int64(100))},"
  },
  {
    "id" : "66be6d90-0df0-4502-b3b5-bdd7aefdabe7",
    "prId" : 31396,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "446b0ad6-179e-4e43-8152-2e6fa261b06c",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Please cap exp before the Pow10 instead of doing a float64 comparison.\n",
        "createdAt" : "2016-08-25T17:50:50Z",
        "updatedAt" : "2016-08-25T17:50:50Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "c8f62496-8e9a-49ed-b61a-f3584c77c101",
        "parentId" : "446b0ad6-179e-4e43-8152-2e6fa261b06c",
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "Yeah sorry didn't catch this last night. Youre implicitly converting maxint64 into a float larger than maxint64. You can early return with something like  exp >= int64(math.Log10(math.MaxInt64)) instaed. \n",
        "createdAt" : "2016-08-25T19:04:34Z",
        "updatedAt" : "2016-08-25T19:04:34Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      },
      {
        "id" : "8cb1cc8d-abc1-47f0-b99c-2d181938071d",
        "parentId" : "446b0ad6-179e-4e43-8152-2e6fa261b06c",
        "authorId" : "e535b047-00fc-4269-992a-b8d65bd7c57b",
        "body" : "Ack. Will follow up with another PR fixing this.\n",
        "createdAt" : "2016-08-25T19:28:50Z",
        "updatedAt" : "2016-08-25T19:28:50Z",
        "lastEditedBy" : "e535b047-00fc-4269-992a-b8d65bd7c57b",
        "tags" : [
        ]
      }
    ],
    "commit" : "00e41888b09783acd7372c309360bf22f45bd3ef",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +96,100 @@\t// The backoff is capped such that 'calculated' value never overflows.\n\tbackoff := float64(r.baseDelay.Nanoseconds()) * math.Pow10(exp)\n\tif backoff > math.MaxInt64 {\n\t\treturn r.maxDelay\n\t}"
  },
  {
    "id" : "1f8e752e-846d-4407-ac51-263aea95705d",
    "prId" : 24052,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ff6009b-a1e7-4b6e-a193-19d2eebd898f",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "We already have some rate limiting stuff in util/? Is it not reusable here? I'd prefer not to add a rate limiter to the workqueue package.\n",
        "createdAt" : "2016-04-11T23:41:50Z",
        "updatedAt" : "2016-05-10T13:04:42Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      },
      {
        "id" : "2f61de77-e4c0-406b-a8a4-5bf651e0352e",
        "parentId" : "1ff6009b-a1e7-4b6e-a193-19d2eebd898f",
        "authorId" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "body" : "> We already have some rate limiting stuff in util/? Is it not reusable here? I'd prefer not to add a rate limiter to the workqueue package.\n\nIt's a slight different interface for the queuer to allow it automatically backoff per-item as well as per-queue.  There is an adapter for handling the bucket rate limiter we use as a godep so that you can reliably rate limit both the controller and the items to prevent excessive burst utilization by a single item.\n",
        "createdAt" : "2016-04-11T23:55:20Z",
        "updatedAt" : "2016-05-10T13:04:42Z",
        "lastEditedBy" : "fa477146-9a47-4754-b38c-de8062e65e13",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf95b124e66acf503e6699e42504d8a5d45883ca",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +25,29 @@)\n\ntype RateLimiter interface {\n\t// When gets an item and gets to decide how long that item should wait\n\tWhen(item interface{}) time.Duration"
  },
  {
    "id" : "7d23314f-b611-4c4f-ab6d-36721fd61e46",
    "prId" : 24052,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63557dfa-761f-422a-ab80-f780cc24a7bf",
        "parentId" : null,
        "authorId" : "b86e7e78-bb07-417f-8470-39407559c779",
        "body" : "Note that waiting extra wrt a particular limiter could cause it to apparently exceed its burst setting.\n",
        "createdAt" : "2016-04-20T23:36:57Z",
        "updatedAt" : "2016-05-10T13:04:42Z",
        "lastEditedBy" : "b86e7e78-bb07-417f-8470-39407559c779",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf95b124e66acf503e6699e42504d8a5d45883ca",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +163,167 @@}\n\n// MaxOfRateLimiter calls every RateLimiter and returns the worst case response\n// When used with a token bucket limiter, the burst could be apparently exceeded in cases where particular items\n// were separately delayed a longer time."
  }
]