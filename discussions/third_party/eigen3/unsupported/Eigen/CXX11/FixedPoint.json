[
  {
    "id" : "0555154c-1125-495e-9b19-acd6de0e2b01",
    "prId" : 6323,
    "prUrl" : "https://github.com/tensorflow/tensorflow/pull/6323#pullrequestreview-13053742",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3533b00-a4aa-4cfd-b7e5-0af9a1eeffff",
        "parentId" : null,
        "authorId" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "body" : "Why elif? It seems so sad to go from AVX2 to AVX-512 only to lose the optimized AVX2 matmul. Can't we fiddle the packet_traits definitions to enable us to use the optimized quantized AVX2 matmul even when AVX512 is enabled for other things like casting and elementwise ops? (Fine to do as a followup I suppose)",
        "createdAt" : "2016-12-15T01:44:52Z",
        "updatedAt" : "2016-12-15T01:58:03Z",
        "lastEditedBy" : "0ba8fb18-637a-4ab3-a7c8-cd971823fe45",
        "tags" : [
        ]
      },
      {
        "id" : "c338aa54-58bf-4c26-a020-b0231dcc64da",
        "parentId" : "a3533b00-a4aa-4cfd-b7e5-0af9a1eeffff",
        "authorId" : "c88af626-95c4-44a1-a457-e22900d07eda",
        "body" : "MatMul will come in follow up changes.",
        "createdAt" : "2016-12-15T03:04:38Z",
        "updatedAt" : "2016-12-15T03:04:38Z",
        "lastEditedBy" : "c88af626-95c4-44a1-a457-e22900d07eda",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c943af3b139f07aa1f3ba5c976e2f0765e75960",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +37,41 @@#include \"src/FixedPoint/TypeCastingAVX512.h\"\n\n#elif defined EIGEN_VECTORIZE_AVX2\n#define EIGEN_USE_OPTIMIZED_INT8_UINT8_MAT_MAT_PRODUCT\n#define EIGEN_USE_OPTIMIZED_INT16_INT16_MAT_MAT_PRODUCT"
  }
]