[
  {
    "id" : "8e508ffd-ccb8-4736-a6c6-3aefa79d8822",
    "prId" : 4590,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4590#pullrequestreview-712977346",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa7fbc54-03cb-4088-8114-b3a4db334c12",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Can we add tests to ensure autologging is disabled during these `cross_xxx` functions?",
        "createdAt" : "2021-07-22T16:06:36Z",
        "updatedAt" : "2021-07-22T16:06:37Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "50e0c36c1cd53277cc1a77494d09ad89778c5d10",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1512,1516 @@            manage_run=False,\n        )\n\n\ndef eval_and_log_metrics(model, X, y_true, *, prefix, sample_weight=None):"
  },
  {
    "id" : "64b88016-f674-4c94-b0de-17e3f31cd281",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-707975679",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "965f91d2-3852-4916-af10-de3ef09d28f8",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "This is fantastic! Nice job @WeichenXu123 !",
        "createdAt" : "2021-07-16T03:29:31Z",
        "updatedAt" : "2021-07-16T03:29:31Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 186,
    "diffHunk" : "@@ -1,1 +658,662 @@        # When the `predict_result` object being GCed, its ID may be reused, so register a finalizer\n        # to clear the ID from the dict for preventing wrong ID mapping.\n        weakref.finalize(predict_result, clean_id, prediction_result_id)\n\n    @staticmethod"
  },
  {
    "id" : "793be28f-46d5-40fa-8a7e-5015574ba3e9",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-710032519",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Now that we use weakref.finalize, do we still need to do the sampling?",
        "createdAt" : "2021-07-16T03:53:39Z",
        "updatedAt" : "2021-07-16T03:53:39Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "cfbf8f55-141e-4209-951f-acda698159f7",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "(1) The finalizer callback is applied on \"prediction_result_object_id\", but here it refer to the id of \"eval_dataset_object\". The two kinds of objects are different.\r\n\r\n(2) for \"eval_dataset_object\", we can also register finalizer callback, but the callback cleanup logic will be complex (we need cleanup/rename related ids scattered in `eval_dataset_info_map`), so I don't apply this approach for \"eval_dataset_object\".\r\n\r\n(3) The eval_dataset row samples is useful, prepared to be logged in artifacts (as discussed before), and here the row samples can be used to double check (avoid wrong mapping caused by ID reusing, and the row samples checking here is short-circuit so it won't affect performance)\r\n",
        "createdAt" : "2021-07-16T04:25:20Z",
        "updatedAt" : "2021-07-16T04:26:48Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "bcefc7d9-020e-41c6-97ac-1313cf49c754",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Actually, do we want to log eval datasets as artifacts? They may contain sensitive information. We have a config flag for `log_input_examples` in autologging based on the training data. Do we need to log additional eval artifacts each time an eval dataset is passed to an sklearn metric? Seems like that might be overkill.",
        "createdAt" : "2021-07-16T05:54:58Z",
        "updatedAt" : "2021-07-16T05:54:58Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "27d1b8ce-85fd-4c32-a92a-ed731ada5a7e",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "ok. Then I suggest: checking `log_input_examples` param, if on then we also log sample rows for eval_dataset, otherwise do not log.\r\nThe sample rows could help user debug, there're several cases we may map the eval dataset name into the same name, then user will see name like \"name_1\", \"name_2\", ... and don't know which name match which dataset, e.g. the case:\r\n\r\n```\r\neval_X, eval_y = load_dataA(...)\r\nmodel.score(eval_X, eval_y)\r\n\r\neval_X, eval_y = load_dataB(...) # re-assign eval_X var\r\nmodel.score(eval_X, eval_y)\r\n```\r\nthis case for dataA and dataB, we will capture the same name \"eval_X\", and in autologging metric we will  log keys like `{model_name}_score_on_eval_X-1` and `{model_name}_score_on_eval_X-2`, but without additional artifact containing map of \"name --> rows sample\" user don't know \"eval_X-1\" and \"eval_X-2\" map to which data.\r\n\r\nI add a TODO for this: https://github.com/mlflow/mlflow/blob/d16e3a99cc51fdf2cc53f802da2be0d7e10b2864/mlflow/sklearn/__init__.py#L708",
        "createdAt" : "2021-07-16T06:37:22Z",
        "updatedAt" : "2021-07-16T13:57:19Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "e090cedf-605c-4840-adf5-d9111a302e25",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "seems like for most cases, for each model, user will score on one evaluation dataset. We can initially skip log additional eval row samples artifacts, if user requires this, we can add it in future version.",
        "createdAt" : "2021-07-17T06:41:37Z",
        "updatedAt" : "2021-07-17T06:41:37Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "bf834733-0bfa-4865-85f3-e591ca8b0bb1",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "+1 for not logging row samples for each metric. If anything, it would be more helpful to log a map from metric names to full API calls.\r\n\r\nE.g. `accuracy_score_eval_X -> accuracy_score(eval_X, eval_y, normalize=True, ...)`",
        "createdAt" : "2021-07-18T07:04:06Z",
        "updatedAt" : "2021-07-18T07:04:07Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "3929c491-b77f-40ad-ae3e-5a6e819f8d33",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "I suggest prepend a prefix like `metric_call_{index}' before all autologged metric, like:\r\n![image](https://user-images.githubusercontent.com/19235986/126188020-94b06c55-6f9b-40f2-b3d7-0c51806c3a95.png)\r\nThis will help sorting when displayed in the UI.",
        "createdAt" : "2021-07-19T15:43:56Z",
        "updatedAt" : "2021-07-19T15:43:56Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "b1a8e014-d5b6-4cf2-a076-321fc03813f2",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "@harupy \r\nThe semantic now (proposed by @dbczumar) is: we create an increasing index when we detect a metric call from user code, and log the metric, and in artifact, also log the metric call command like: `logged_metric_key -> accuracy_score(eval_X, eval_y, normalize=True, ...)`\r\n\r\nSo if it is such semantic, I still prefer the key format of \"{metric_name}_on_{xx_dataset}\"",
        "createdAt" : "2021-07-19T15:46:32Z",
        "updatedAt" : "2021-07-19T15:46:32Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "87780824-1d29-48b3-b294-d1c4c3bf1cf4",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Agree with the format `<metric name>_<dataset name>`.",
        "createdAt" : "2021-07-19T15:51:40Z",
        "updatedAt" : "2021-07-19T16:00:27Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "cc024627-f628-4839-98e7-5823988b2f79",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "This is how the `<metric call x>_<metric name>_<dataset name>` format looks like in the runs table. The metric and dataset names are hidden.\r\n\r\n![image](https://user-images.githubusercontent.com/17039389/126191498-2c1ffedf-5156-4d2f-bedf-cd2ed6293478.png)\r\n",
        "createdAt" : "2021-07-19T16:07:21Z",
        "updatedAt" : "2021-07-19T16:25:42Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "41581b2d-7cc6-4be9-9459-011a5c7c529b",
        "parentId" : "2ef92ee0-4817-4f2d-807e-61856a6a2b5a",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I agree with @harupy. I don't think we should add another `metric_call` prefix.",
        "createdAt" : "2021-07-19T22:34:21Z",
        "updatedAt" : "2021-07-19T22:34:21Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +612,616 @@         2. check whether eval_dataset_info_map already registered this eval dataset.\n            will check by object id and comparing row samples.\n            Note: only check object id is not sufficient, id may be reused.\n         3. register eval dataset (with id and row samples information)\n         4. return eval dataset name with index."
  },
  {
    "id" : "1415efd1-fe42-44a9-a7ca-ebd6d871102a",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-710473675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c28b5548-6cd0-4492-88fa-69e08c20bf69",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "In python 3.6 >=, `dict` preserver insertion order so I think the following code should work (sorry if I'm wrong):\r\n\r\n```suggestion\r\n            dict_to_log = dict(call_commands_list)\r\n```",
        "createdAt" : "2021-07-20T11:09:49Z",
        "updatedAt" : "2021-07-20T11:28:11Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "6f1c0d3e-ef46-43d0-ab9c-b3e5c08db834",
        "parentId" : "c28b5548-6cd0-4492-88fa-69e08c20bf69",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "https://stackoverflow.com/a/39980744/12301610\r\n\r\nSeems it is only a CPython implementation details in python 3.6",
        "createdAt" : "2021-07-20T11:25:00Z",
        "updatedAt" : "2021-07-20T11:25:00Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "d5ce995b-4957-4a12-a42d-136359fc2b47",
        "parentId" : "c28b5548-6cd0-4492-88fa-69e08c20bf69",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "got it, thanks!",
        "createdAt" : "2021-07-20T11:35:15Z",
        "updatedAt" : "2021-07-20T11:35:15Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 304,
    "diffHunk" : "@@ -1,1 +776,780 @@\n            call_commands_list.sort(key=lambda x: x[0])\n            dict_to_log = OrderedDict(call_commands_list)\n            client.log_dict(run_id=run_id, dictionary=dict_to_log, artifact_file=\"metric_info.json\")\n            self._metric_info_artifact_need_update[run_id] = False"
  },
  {
    "id" : "84fa71f2-10bc-4d17-833b-c1921e91a778",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711288133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc9293d0-5f4e-4035-bb08-c3f4123b16e4",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Nit: Can we rename this class `_AutologgingMetricsManager`?",
        "createdAt" : "2021-07-21T06:10:52Z",
        "updatedAt" : "2021-07-21T06:10:52Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +503,507 @@\nclass _AutologgingMetricsManager:\n    \"\"\"\n    This class is designed for holding information which is used by autologging metrics\n    It will hold information of:"
  },
  {
    "id" : "c49c7bf9-2d5f-4f7f-a4f7-90addb812b0f",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-714197034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d305dd2b-109d-4b9b-b6bd-fc051277b8d0",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Nit: To reduce the file size of `mlflow/sklearn/__init__.py`, could we file a follow-up PR to:\r\n\r\n1. Convert `mlflow.sklearn.utils` into a directory with an `__init__.py` file, where we move the contents from `mlflow/sklearn/utils.py` into `mlflow/sklearn/utils/__init__.py`\r\n2. Move the metrics logic introduced by this PR into `mlflow/sklearn/utils/metrics_utils.py`",
        "createdAt" : "2021-07-21T06:12:26Z",
        "updatedAt" : "2021-07-21T06:12:26Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "f9550402-0f65-4000-af06-92e0ddd28cf1",
        "parentId" : "d305dd2b-109d-4b9b-b6bd-fc051277b8d0",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "create followup ticket for this https://databricks.atlassian.net/browse/ML-16603",
        "createdAt" : "2021-07-22T07:11:24Z",
        "updatedAt" : "2021-07-22T07:11:24Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "3a79962b-695a-4d21-85d0-6f85ccc31790",
        "parentId" : "d305dd2b-109d-4b9b-b6bd-fc051277b8d0",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Thank you!",
        "createdAt" : "2021-07-24T02:19:36Z",
        "updatedAt" : "2021-07-24T02:19:37Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +504,508 @@class _AutologgingMetricsManager:\n    \"\"\"\n    This class is designed for holding information which is used by autologging metrics\n    It will hold information of:\n    (1) a map of \"prediction result object id\" to a tuple of dataset name(the dataset is"
  },
  {
    "id" : "2db05292-72ef-4076-8081-3347d122c825",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711293569",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61723aa1-1471-429a-9b4f-d7fda681b92e",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add an inline comment explaining this logic?",
        "createdAt" : "2021-07-21T06:21:25Z",
        "updatedAt" : "2021-07-21T06:21:25Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 219,
    "diffHunk" : "@@ -1,1 +691,695 @@        arg_names = list(param_sig.keys())\n\n        if self_obj is not None:\n            # If metric_fn is a method of an instance, e.g. `model.score`,\n            # then the first argument is `self` which we need exclude it."
  },
  {
    "id" : "984681f6-6b61-4183-8473-0453be0c3bcb",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711293777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cebc79b4-164a-43be-b8cc-f95322fc04d1",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add parameter documentation for this method, particularly for `self_obj`?",
        "createdAt" : "2021-07-21T06:21:47Z",
        "updatedAt" : "2021-07-21T06:21:47Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 194,
    "diffHunk" : "@@ -1,1 +666,670 @@        Note: this method include inspecting argument variable name.\n         So should be called directly from the \"patched method\", to ensure it capture\n         correct argument variable name.\n\n        :param self_obj: If the metric_fn is a method of an instance (e.g. `model.score`),"
  },
  {
    "id" : "dfa43e3d-66ef-42e1-a408-5d3d197e9e08",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-712507268",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86307f5d-b37a-4525-a2fd-fcf3e041db35",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Nit:\r\n\r\nIs it sufficient to replace this with the following?:\r\n\r\n```suggestion\r\n            call_commands_list = list(self._metric_api_call_info[run_id].values())\r\n```",
        "createdAt" : "2021-07-21T06:30:04Z",
        "updatedAt" : "2021-07-21T06:30:04Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "4b17be95-e75d-40a8-a99d-633264491a70",
        "parentId" : "86307f5d-b37a-4525-a2fd-fcf3e041db35",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "No. I use `list.extend` which means concat the lists (all dict values).\r\n",
        "createdAt" : "2021-07-22T07:59:58Z",
        "updatedAt" : "2021-07-22T07:59:59Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "60051e2d-8e65-4195-9987-f750fa7eec46",
        "parentId" : "86307f5d-b37a-4525-a2fd-fcf3e041db35",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Got it!",
        "createdAt" : "2021-07-22T08:55:22Z",
        "updatedAt" : "2021-07-22T08:55:22Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 301,
    "diffHunk" : "@@ -1,1 +773,777 @@            call_commands_list = []\n            for v in self._metric_api_call_info[run_id].values():\n                call_commands_list.extend(v)\n\n            call_commands_list.sort(key=lambda x: x[0])"
  },
  {
    "id" : "c1ce94c3-098d-4d36-ba79-57596dfe5814",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711311797",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5203101b-50e2-4d92-b256-414796482d7c",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add an explanation to this docstring for why we need this map instead of just setting the `run_id` attribute on the prediction result? I.e. because certain dataset types, like numpy arrays, don't support attribute assignment.",
        "createdAt" : "2021-07-21T06:51:43Z",
        "updatedAt" : "2021-07-21T06:51:43Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +507,511 @@    It will hold information of:\n    (1) a map of \"prediction result object id\" to a tuple of dataset name(the dataset is\n       the one which generate the prediction result) and run_id.\n       Note: We need this map instead of setting the run_id into the \"prediction result object\"\n       because the object maybe a numpy array which does not support additional attribute"
  },
  {
    "id" : "e17615ee-f1f5-4588-aea2-818b805102a0",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711314252",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "143ebbdc-e632-4550-b8ac-7de85f9e712e",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we remove the `model` parameter and have the caller pass in the `run_id` instead? In `patched_predict` we'll fetch the run ID from the model and pass it to this function:\r\n\r\n```\r\n         run_id = self.get_run_id_for_model(model)\r\n         status.register_prediction_result(\r\n                run_id, eval_dataset_name, predict_result)\r\n```\r\n\r\nThis makes it clearer than the prediction result is being associated with a dataset name and a run ID, rather than a dataset name and a model.",
        "createdAt" : "2021-07-21T06:55:34Z",
        "updatedAt" : "2021-07-21T06:55:34Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +642,646 @@\n    def register_prediction_result(self, run_id, eval_dataset_name, predict_result):\n        \"\"\"\n        Register the relationship\n         id(prediction_result) --> (eval_dataset_name, run_id)"
  },
  {
    "id" : "c65661d6-4f14-4dda-b6ce-413f19a4356d",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711316784",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d34208ce-d80f-4954-a38e-1e20d67f3653",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add an inline comment explaining why we're disabling metric logging here?",
        "createdAt" : "2021-07-21T06:59:12Z",
        "updatedAt" : "2021-07-21T06:59:12Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 509,
    "diffHunk" : "@@ -1,1 +1368,1372 @@            # `model.score` may call metric APIs internally, in order to prevent nested metric call\n            # being logged, temporarily disable post_training_metrics patching.\n            with status.disable_log_post_training_metrics():\n                score_value = original(self, *args, **kwargs)\n"
  },
  {
    "id" : "ae488b07-57f4-440b-b0cd-77a9ae40184d",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-711317687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e79b5565-62f6-471e-8c7b-09331b391f7e",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add an inline comment explaining why we're disabling the logging of post training metrics?",
        "createdAt" : "2021-07-21T07:00:26Z",
        "updatedAt" : "2021-07-21T07:00:27Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 595,
    "diffHunk" : "@@ -1,1 +1535,1539 @@    \"\"\"\n    status = _get_autologging_metrics_manager()\n    with status.disable_log_post_training_metrics():\n        return _eval_and_log_metrics_impl(\n            model, X, y_true, prefix=prefix, sample_weight=sample_weight"
  },
  {
    "id" : "2a2276de-7a7d-4c67-90bf-6043b332a3ca",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-714197425",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2607a66-eba7-45bc-828a-065c21c4d9ef",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "As a follow-up PR, we should introduce a flag to control whether or not post-training metrics should be logged. This is particularly important for backwards compatibility with existing tools that add metrics to autologging runs (e.g. AutoML tools).",
        "createdAt" : "2021-07-21T07:27:31Z",
        "updatedAt" : "2021-07-21T07:27:31Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "b4528e50-ed09-4309-b985-431d6f7b6aaf",
        "parentId" : "f2607a66-eba7-45bc-828a-065c21c4d9ef",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "Create followup ticket https://databricks.atlassian.net/browse/ML-16605",
        "createdAt" : "2021-07-22T08:53:47Z",
        "updatedAt" : "2021-07-22T08:53:47Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "f6f27b1c-8c11-4033-9c2a-3935c78dbe89",
        "parentId" : "f2607a66-eba7-45bc-828a-065c21c4d9ef",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Thanks!",
        "createdAt" : "2021-07-24T02:25:38Z",
        "updatedAt" : "2021-07-24T02:25:38Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 346,
    "diffHunk" : "@@ -1,1 +818,822 @@@experimental\n@autologging_integration(FLAVOR_NAME)\ndef autolog(\n    log_input_examples=False,\n    log_model_signatures=True,"
  },
  {
    "id" : "41de78f7-43f1-4099-aa48-d747da4e8c35",
    "prId" : 4491,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4491#pullrequestreview-712506052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc9bd1a6-03a6-424b-9bae-9208ef1a9c0f",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I think there may be a small bug in the metric name that we're using in the patched function. I tried computing 3 different metrics in the following example:\r\n\r\n```\r\nimport sklearn\r\n\r\nfrom sklearn import datasets\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nimport mlflow\r\nmlflow.autolog()\r\n\r\niris = datasets.load_iris()\r\n\r\nlogistic = LogisticRegression(solver=\"saga\", max_iter=200, random_state=0)\r\ntrain_out = logistic.fit(iris.data, iris.target)\r\n\r\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\r\n\r\ntest_y = logistic.predict(iris.data)\r\n\r\nr2_score(test_y, iris.target)\r\nmean_absolute_error(test_y, iris.target)\r\nmean_squared_error(test_y, iris.target)\r\n```\r\n\r\nHowever, this created 3 metrics with incorrect names:\r\n\r\n```\r\nbrier_score_loss_unknown_dataset\r\nbrier_score_loss-2_unknown_dataset\r\nbrier_score_loss-3_unknown_dataset\r\n```\r\n\r\nPerhaps `brier_score_loss` is the first metric name that appears in the list?",
        "createdAt" : "2021-07-21T07:33:45Z",
        "updatedAt" : "2021-07-21T07:33:46Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "1b80f511-a347-48f3-b828-e6fce125a4c9",
        "parentId" : "dc9bd1a6-03a6-424b-9bae-9208ef1a9c0f",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "addressed. it is code bug.",
        "createdAt" : "2021-07-22T08:54:01Z",
        "updatedAt" : "2021-07-22T08:54:01Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      }
    ],
    "commit" : "94dde8f999c61180d2a5a69bca09678e043df79f",
    "line" : 585,
    "diffHunk" : "@@ -1,1 +1484,1488 @@\n    for metric_name in _get_metric_name_list():\n        safe_patch(FLAVOR_NAME, metrics, metric_name, patched_metric_api, manage_run=False)\n\n"
  },
  {
    "id" : "77b7405b-9ad0-406b-901c-c4a1d7cbdf34",
    "prId" : 4486,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4486#pullrequestreview-688116643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d3a3a35-0c40-4c2d-b783-6b41afdb25ad",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Removed `[...]` to use a generator and avoid cheking all items in `excluded_module_names`",
        "createdAt" : "2021-06-21T07:37:53Z",
        "updatedAt" : "2021-06-21T12:22:35Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "d48af0fc83b2b52813d497a3e8432a11cbefe184",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +921,925 @@            for excluded_module_name in excluded_module_names\n        )\n    ]\n\n    for class_def in estimators_to_patch:"
  },
  {
    "id" : "2f51171c-7511-4709-bb2a-716c60aab233",
    "prId" : 4486,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4486#pullrequestreview-688367821",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7e2ed2d-23f7-429b-96a0-3c96e7d6f0af",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "`sklearn.compose` contains `TransformedTargetRegressor` which I think should be patched:\r\n\r\nhttps://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn-compose-transformedtargetregressor",
        "createdAt" : "2021-06-21T12:32:44Z",
        "updatedAt" : "2021-06-22T02:33:36Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "d48af0fc83b2b52813d497a3e8432a11cbefe184",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +911,915 @@    excluded_class_names = [\n        \"sklearn.compose._column_transformer.ColumnTransformer\",\n    ]\n\n    estimators_to_patch = ["
  },
  {
    "id" : "6a2bf4a1-f78e-404f-b696-45c59d2836a3",
    "prId" : 4416,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4416#pullrequestreview-685749385",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "697249bb-5a21-48d2-bacf-4984be84e1c6",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "This portion of the change integrates the new `MlflowAutologgingQueueingClient` (defined in `mlflow/utils/autologging_utils/client.py`) into the `mlflow.sklearn` autologging integration.",
        "createdAt" : "2021-06-16T23:41:04Z",
        "updatedAt" : "2021-06-16T23:41:04Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0a64505fffd8d07eac9f59b203f05e4c5b27d99",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +31,35 @@from mlflow.utils.mlflow_tags import MLFLOW_AUTOLOGGING\nfrom mlflow.utils.model_utils import _get_flavor_configuration\nfrom mlflow.utils.autologging_utils import (\n    autologging_integration,\n    safe_patch,"
  },
  {
    "id" : "1430821f-d386-45f2-9307-60f8d9e2ce1d",
    "prId" : 4325,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4325#pullrequestreview-653961108",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21b0d47b-dfab-43e6-8c54-d7917d7fdaa6",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "In the future, we can likely add metrics for unsupervised techniques that don't depend on labels (e.g. https://scikit-learn.org/stable/modules/classes.html#pairwise-metrics for clustering). For now, printing a warning seems like a good idea, since users *can* pass labels to clustering methods and record metrics.",
        "createdAt" : "2021-05-06T23:03:25Z",
        "updatedAt" : "2021-05-06T23:03:25Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d67c870ab7aac2737a7de68d7e8a7b88afa71f5",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +766,770 @@        )\n        if y_true is None and not logged_metrics:\n            _logger.warning(\n                \"Training metrics will not be recorded because training labels were not specified.\"\n                \" To automatically record training metrics, provide training labels as inputs to\""
  },
  {
    "id" : "58c034cc-b8a3-43a9-bbb8-985cb11585f5",
    "prId" : 4218,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4218#pullrequestreview-625798331",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b010f54-f2da-4858-8610-275ede6d2fb6",
        "parentId" : null,
        "authorId" : "1b6f9778-4aa7-4624-a54a-7d13658a8187",
        "body" : "Maybe worth documenting the error handling behavior. ",
        "createdAt" : "2021-03-31T18:38:18Z",
        "updatedAt" : "2021-04-06T04:57:42Z",
        "lastEditedBy" : "1b6f9778-4aa7-4624-a54a-7d13658a8187",
        "tags" : [
        ]
      },
      {
        "id" : "7e5e2e3c-b7e2-4cb9-af63-d3badc708cd3",
        "parentId" : "2b010f54-f2da-4858-8610-275ede6d2fb6",
        "authorId" : "13c2fe5d-a515-45e7-aa45-fbbe80a8a8a0",
        "body" : "Added a comment about potential failure modes. I can update it if we decide to remove model_uri.",
        "createdAt" : "2021-03-31T23:33:35Z",
        "updatedAt" : "2021-04-06T04:57:42Z",
        "lastEditedBy" : "13c2fe5d-a515-45e7-aa45-fbbe80a8a8a0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2039111a72896c3c2015692d608e4c1297957188",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +993,997 @@    Computes and logs metrics (and artifacts) for the given model and labeled dataset.\n    The metrics/artifacts mirror what is auto-logged when training a model\n    (see mlflow.sklearn.autolog).\n\n    :param model: The model to be evaluated."
  },
  {
    "id" : "66f79fea-502c-45c3-ba61-57b5a3c4f352",
    "prId" : 4218,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4218#pullrequestreview-628231599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0747189-1112-47f7-95f3-4597b31fd456",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "```suggestion\r\n    (see mlflow.sklearn.autolog). Metrics and artifacts are logged under the currently active run.\r\n    If no run is active, this method will create a new active run.\r\n```\r\n\r\nJust to document the active-run creation behavior of this method",
        "createdAt" : "2021-04-05T23:25:15Z",
        "updatedAt" : "2021-04-06T04:57:42Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "50f6aaae-7f5d-4c7e-b34e-f4ebb5f2e2f9",
        "parentId" : "c0747189-1112-47f7-95f3-4597b31fd456",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Oops, realized we state this later on!",
        "createdAt" : "2021-04-05T23:28:10Z",
        "updatedAt" : "2021-04-06T04:57:42Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "2039111a72896c3c2015692d608e4c1297957188",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +993,997 @@    Computes and logs metrics (and artifacts) for the given model and labeled dataset.\n    The metrics/artifacts mirror what is auto-logged when training a model\n    (see mlflow.sklearn.autolog).\n\n    :param model: The model to be evaluated."
  },
  {
    "id" : "43313ed4-395f-4b25-b646-09a4cee45e37",
    "prId" : 3582,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3582#pullrequestreview-517137952",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f95fac9e-9f2c-43bc-a98d-23933b6a07f8",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "This (together line 914) is the critical change to address problem (2) from https://github.com/mlflow/mlflow/issues/3574#issuecomment-714994583. \r\n\r\nAssume that the old line was being invoked from a patched `fit` call on a class called `Parent` and that `self` refers to an instance of class `Child` which inherits from `Parent`. Calling `get_original_attribute()` on `self` would yield the `Child.fit()` function, rather than `Parent.fit()`, leading to recursive behavior.\r\n\r\nNow, instead of fetching the attribute from `self`, we fetch it from `clazz` (which would refer to `Parent` in the above example).",
        "createdAt" : "2020-10-26T20:11:51Z",
        "updatedAt" : "2020-10-27T05:56:11Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "daa732b926250deaa72a1c86ee2b6f09b0370e00",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +737,741 @@        _log_pretraining_metadata(self, *args, **kwargs)\n\n        original_fit = gorilla.get_original_attribute(clazz, func_name)\n        try:\n            fit_output = original_fit(self, *args, **kwargs)"
  },
  {
    "id" : "fc7d8c92-c203-4438-8f56-17294007af10",
    "prId" : 3359,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3359#pullrequestreview-478071840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71ad0433-804b-45ab-a04d-d642ed157b4e",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "This link doesn't work now. We need to merge #3324 right after 1.11.0 release.",
        "createdAt" : "2020-08-28T23:33:13Z",
        "updatedAt" : "2020-08-28T23:33:13Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "f727a31abf26ba1b11e9968889d98a98ce7dd4ac",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +571,575 @@    **Example**\n\n    `See more examples <https://github.com/mlflow/mlflow/blob/master/examples/sklearn_autolog>`_\n\n    .. code-block:: python"
  },
  {
    "id" : "05deff51-4b1b-4cb9-bc96-9a3d61d764b4",
    "prId" : 3326,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3326#pullrequestreview-476988545",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e578979-b3bc-48d6-9461-be972a4ddd49",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "@harupy I simplified the logic here to encapsulate the entire row sampling + signature inference procedure into a single try/catch block. While the error messages may be a bit less granular, the key point users should be aware of is that the input example and signature are not logged in the event of an error; this structure makes that a bit clearer, and it improves the readability of the code.",
        "createdAt" : "2020-08-27T18:44:33Z",
        "updatedAt" : "2020-08-28T00:03:26Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "165440f39d6489ed6fadcb0901d803499cd304b5",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +729,733 @@        input_example = None\n        signature = None\n        if hasattr(estimator, \"predict\"):\n            try:\n                # Fetch an input example using the first several rows of the array-like"
  },
  {
    "id" : "3551cc77-7076-4ac0-b841-1c2790478a6b",
    "prId" : 3326,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3326#pullrequestreview-477109355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30f7a039-d23b-4963-bf1e-405097a097b8",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Made a minor tweak to this comment to remove the double negative",
        "createdAt" : "2020-08-27T18:45:01Z",
        "updatedAt" : "2020-08-28T00:03:26Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "70605b66-3965-4e36-b6ed-3904ec59f357",
        "parentId" : "30f7a039-d23b-4963-bf1e-405097a097b8",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "makes sense. Thanks!",
        "createdAt" : "2020-08-27T21:51:12Z",
        "updatedAt" : "2020-08-28T00:03:26Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "165440f39d6489ed6fadcb0901d803499cd304b5",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +189,193 @@        yaml.safe_dump(conda_env, stream=f, default_flow_style=False)\n\n    # `PyFuncModel` only works for sklearn models that define `predict()`.\n    if hasattr(sk_model, \"predict\"):\n        pyfunc.add_to_model("
  },
  {
    "id" : "25373028-45ea-4efe-93cd-53f38bc56c08",
    "prId" : 3326,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3326#pullrequestreview-477140700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "612dd64e-96b4-4a4f-8140-08d05a0c9121",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Added this line because `input_example` should not be logged when  `estimator.predict` or `infer_signature` fails.",
        "createdAt" : "2020-08-27T23:04:03Z",
        "updatedAt" : "2020-08-28T00:03:26Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "165440f39d6489ed6fadcb0901d803499cd304b5",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +741,745 @@                signature = infer_signature(input_example, model_output)\n            except Exception as e:  # pylint: disable=broad-except\n                input_example = None\n                msg = \"Failed to infer an input example and model signature: \" + str(e)\n                _logger.warning(msg)"
  },
  {
    "id" : "e9a28d12-ba5d-4e5d-9694-174ce795bab4",
    "prId" : 3287,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3287#pullrequestreview-470722386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c0859a4-4830-4c9b-97ad-f7270eb4a3b4",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "We should add the `@experimental` decorator to this function.",
        "createdAt" : "2020-08-19T18:15:38Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "86a008595f5ef17520849ab1e871dce5a91cee6c",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +510,514 @@\n@experimental\ndef autolog():\n    \"\"\"\n    Enables autologging for scikit-learn estimators."
  },
  {
    "id" : "c884b519-62f3-47bd-8c24-875d97299d8b",
    "prId" : 3287,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3287#pullrequestreview-472884824",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a852abe9-0b9e-480c-ba8b-352620fc0987",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "@dbczumar This sounds like a follow-up task (because this PR is already gigantic), but we could emit a warning when a user has already imported estimators before enabling autolog.\r\n\r\n```python\r\nimport warnings\r\n\r\nfrom sklearn.linear_model import LinearRegression  # import estimator before enabling autolog\r\n\r\n# mlflow.sklearn.autolog()\r\n\r\ndef is_estimator_class(obj):\r\n    from sklearn.base import BaseEstimator\r\n\r\n    return isinstance(obj, type) and (obj != BaseEstimator) and issubclass(obj, BaseEstimator)\r\n\r\n\r\nestimators_imported = list(filter(is_estimator_class, globals().values()))\r\n\r\nif len(estimators_imported):\r\n    warnings.warn(\"< warning message to encourage users to enable autolog before importing estimators >\")\r\n```",
        "createdAt" : "2020-08-21T01:47:02Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "d8031b98-8634-45c0-af29-a910c341aee9",
        "parentId" : "a852abe9-0b9e-480c-ba8b-352620fc0987",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "@harupy Based on my somewhat-limited testing, I don't think there's a problem with importing estimators prior to autologging. For example, the following code seems to produce the expected MLflow run with metrics/tags/params:\r\n\r\n```\r\nfrom sklearn import svm, datasets\r\niris = datasets.load_iris()\r\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 5, 10]}\r\nsvc = svm.SVC()\r\n\r\nimport mlflow.sklearn\r\nmlflow.sklearn.autolog()\r\n\r\nsvc.fit(iris.data, iris.target)\r\n```\r\n\r\nLet me know if there's something I'm missing here.",
        "createdAt" : "2020-08-21T16:05:29Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "cd81c26b-1d26-43dd-9cd7-26da016c72a3",
        "parentId" : "a852abe9-0b9e-480c-ba8b-352620fc0987",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "I thought the code below doesn't work after reading [this issue report](https://github.com/christophercrouzet/gorilla/issues/2) in gorilla's repository, but looks like I was wrong.\r\n\r\n```python\r\nfrom sklearn.linear_model import LinearRegression\r\nimport mlflow\r\n\r\n# enable autologging AFTER importing an estimator class\r\nmlflow.sklearn.autolog()\r\n\r\n# assert LinearRegression is patched by gorilla\r\nassert \"_gorilla_original_fit\" in dir(LinearRegression)\r\n\r\n```",
        "createdAt" : "2020-08-22T01:12:46Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "86a008595f5ef17520849ab1e871dce5a91cee6c",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +510,514 @@\n@experimental\ndef autolog():\n    \"\"\"\n    Enables autologging for scikit-learn estimators."
  },
  {
    "id" : "08566277-af9b-4f4c-865f-8af224f8cdd3",
    "prId" : 3287,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3287#pullrequestreview-472613639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c042eb8b-d609-4181-bb29-9185be7b713a",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "This docstring is fantastic! Thanks @harupy !",
        "createdAt" : "2020-08-21T16:13:13Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "86a008595f5ef17520849ab1e871dce5a91cee6c",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +512,516 @@def autolog():\n    \"\"\"\n    Enables autologging for scikit-learn estimators.\n\n    **When is autologging performed?**"
  },
  {
    "id" : "f74cd4fe-6a1a-4c18-9ba1-bb53c69cd15a",
    "prId" : 3287,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3287#pullrequestreview-472890977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f46a94e-67bd-495d-9623-afc14815f069",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Marked this task as TODO",
        "createdAt" : "2020-08-22T02:38:59Z",
        "updatedAt" : "2020-08-22T13:15:08Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "86a008595f5ef17520849ab1e871dce5a91cee6c",
    "line" : 249,
    "diffHunk" : "@@ -1,1 +723,727 @@                patch_func = functools.wraps(original)(patch_func)\n                patch = gorilla.Patch(class_def, func_name, patch_func, settings=patch_settings)\n                gorilla.apply(patch)"
  }
]