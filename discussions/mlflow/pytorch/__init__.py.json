[
  {
    "id" : "23ca1221-863f-42ae-b9aa-f5ae049157ad",
    "prId" : 3808,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3808#pullrequestreview-552005248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bef37b97-acdf-4884-be1c-9f61f2090ab3",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "I think we should check if the input is list or dict and say that pytorch flavor does not currently support those.",
        "createdAt" : "2020-12-15T00:07:36Z",
        "updatedAt" : "2020-12-21T19:44:39Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "b515a54d7e1dda24141c4615b42df81f58863060",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +706,710 @@            )\n        else:\n            raise TypeError(\"Input data should be pandas.DataFrame or numpy.ndarray\")\n\n        self.pytorch_model.to(device)"
  },
  {
    "id" : "8c97c23e-8956-42f7-991b-65a7e2de8a2f",
    "prId" : 3753,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3753#pullrequestreview-545760136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d621d95c-b155-4c33-88ae-5fee34698882",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "I think just showing what `get_default_conda_env` returns should be enough. ",
        "createdAt" : "2020-12-06T23:14:58Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9241e32ecf09df4c648f9d6af0eb5ae41c44009",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +60,64 @@\n        # Fetch the associated conda environment\n        env = mlflow.pytorch.get_default_conda_env()\n        print(\"conda env: {}\".format(env))\n"
  },
  {
    "id" : "d63b4b18-dfed-441c-a1c8-440cccf610c4",
    "prId" : 3753,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3753#pullrequestreview-546783811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Is this line really correct? `\"{}/{}\".format(os.getcwd(), model_path)` doesn't seem to be the right path.",
        "createdAt" : "2020-12-07T00:26:26Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "aec83ad3-fc0e-4757-a0d5-0c1696b51c6d",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "body" : "Yes, it [seems to work.](https://github.com/dmatrix/mlflow-tests/blob/master/py/mlflow/models/pytorch/save_model.py) The saving model seems to save it under the local path. \r\n\r\n![Screen Shot 2020-12-06 at 7 14 54 PM](https://user-images.githubusercontent.com/1117597/101305403-77207e00-37f7-11eb-842f-f81698654a17.png)\r\n",
        "createdAt" : "2020-12-07T02:11:44Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "tags" : [
        ]
      },
      {
        "id" : "48605641-ed3e-40f1-b9fb-ac24867bc43d",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "I think this is because the artifact directory points to the current working directory.",
        "createdAt" : "2020-12-07T14:40:58Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "f6c94d24-e288-46dc-a48f-66c7cd04df82",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "body" : "Is there anything wrong with it If the current artifact directory points to cwd and it's where you wish to save the model? ",
        "createdAt" : "2020-12-07T21:52:08Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "tags" : [
        ]
      },
      {
        "id" : "5e2caef5-f2aa-4ab7-8fc0-0531aa2a84a7",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "If the current artifact directory didn't point to cwd, it would fail. I think it's safe to use `mlflow.get_artifact_uri` instead of `os.getcwd`.",
        "createdAt" : "2020-12-07T22:58:03Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "86c5a4e4-873d-46b4-97da-ffa0fd8768d7",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "or we could use `runs:{run_id}/{artifact_path}` format.",
        "createdAt" : "2020-12-07T23:16:18Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "731b1119-923b-45f1-a0fa-642d70aefefe",
        "parentId" : "7deb3f87-0cf5-4797-b389-fb41b189ebe0",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "sorry I misunderstood this is `log_model`.",
        "createdAt" : "2020-12-08T06:39:42Z",
        "updatedAt" : "2020-12-09T15:32:33Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9241e32ecf09df4c648f9d6af0eb5ae41c44009",
    "line" : 180,
    "diffHunk" : "@@ -1,1 +414,418 @@        # Load each saved model for inference\n        for model_path in [\"model\", \"scripted_model\"]:\n            model_uri = \"{}/{}\".format(os.getcwd(), model_path)\n            loaded_model = mlflow.pytorch.load_model(model_uri)\n            print(\"Loaded {}:\".format(model_path))"
  },
  {
    "id" : "8a5e1adf-51ae-443f-b9c4-357605106539",
    "prId" : 3705,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3705#pullrequestreview-565931250",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f74bef8-08db-4423-b0d6-31e98fee7267",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "```suggestion\r\n.. warning:\r\n    We currently don't support logging a state_dict as an MLflow model.\r\n    # or\r\n    This function doesn't generate an MLflow model.\r\n```\r\n\r\n@smurching Shoule we explicitly mention that we currently don't support logging a state_dict as an MLflow model to prevent users from misunderstanding state_dict = MLflow model = servable?",
        "createdAt" : "2021-01-12T04:30:19Z",
        "updatedAt" : "2021-01-12T14:34:21Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "f016620ba5e5a31c7e8d61d0a86538a27eab964d",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +739,743 @@    :param artifact_path: Run-relative artifact path.\n    :param kwargs: kwargs to pass to ``torch.save``.\n\n    .. code-block:: python\n        :caption: Example"
  },
  {
    "id" : "884a7f2d-2304-4cbd-b2ea-2565a2f970d3",
    "prId" : 3607,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3607#pullrequestreview-522118814",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8756d689-ea41-4dad-b183-18bd7aa61f8c",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "`os.path.basename` works for URI too.",
        "createdAt" : "2020-11-03T00:08:39Z",
        "updatedAt" : "2020-11-03T05:54:43Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "5bb7f313-5a22-4e32-a548-0a44c400916f",
        "parentId" : "8756d689-ea41-4dad-b183-18bd7aa61f8c",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "```python\r\n>>> os.path.basename(\"/user/foo.txt\")\r\n'foo.txt'\r\n>>> os.path.basename(\"file:///user/foo.txt\")\r\n'foo.txt'\r\n>>> os.path.basename(\"aaa:bbb///user/foo.txt\")\r\n'foo.txt'\r\n```",
        "createdAt" : "2020-11-03T00:09:27Z",
        "updatedAt" : "2020-11-03T00:25:10Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca50f27cad874f761201f5b680fad0ca94390542",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +415,419 @@                artifact_uri=requirements_file, output_path=tmp_requirements_dir.path()\n            )\n            rel_path = os.path.basename(requirements_file)\n            torchserve_artifacts_config[_REQUIREMENTS_FILE_KEY] = {\"path\": rel_path}\n            shutil.move(tmp_requirements_dir.path(rel_path), path)"
  },
  {
    "id" : "9dd0b8b0-b23d-4bae-8f2e-cef5a655cf79",
    "prId" : 3601,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3601#pullrequestreview-520467450",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ca321b1-e894-44c1-9b1f-2f6bf47f17ff",
        "parentId" : null,
        "authorId" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "body" : "Followed same convention as in spark library (https://github.com/mlflow/mlflow/blob/64c93c81167b8a132bf00535fc23f3420c9caf7f/mlflow/spark.py#L630-L688)",
        "createdAt" : "2020-10-30T08:44:19Z",
        "updatedAt" : "2020-11-03T03:56:58Z",
        "lastEditedBy" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a0d0785d3d5162e9596922749f606ccd523a724",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +592,596 @@                       are logged after every epoch.\n    \"\"\"\n    from mlflow.pytorch._pytorch_autolog import _autolog\n\n    _autolog(log_every_n_epoch=log_every_n_epoch)"
  },
  {
    "id" : "f6a49983-1da7-48d2-b590-5b6a5a68921b",
    "prId" : 3601,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3601#pullrequestreview-522177089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d63ffc92-a982-4185-abae-97731342e6be",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Can we mark this API as experimental initially to give ourselves flexibility to change it in the future based on user feedback? You should be able to do so by adding (to the top of the file):\r\n\r\n```\r\nfrom mlflow.utils.annotations import experimental\r\n```\r\n\r\nAnd then annotating this method with `@experimental`",
        "createdAt" : "2020-11-03T00:37:17Z",
        "updatedAt" : "2020-11-03T03:56:58Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "783bd174-5400-4d25-977a-930ea10132cf",
        "parentId" : "d63ffc92-a982-4185-abae-97731342e6be",
        "authorId" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "body" : "i have marked it as experimental. ",
        "createdAt" : "2020-11-03T03:57:38Z",
        "updatedAt" : "2020-11-03T03:57:39Z",
        "lastEditedBy" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a0d0785d3d5162e9596922749f606ccd523a724",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +574,578 @@\n\ndef autolog(log_every_n_epoch=1):\n    \"\"\"\n    Wrapper for `mlflow.pytorch._pytorch_autolog.autolog` method."
  },
  {
    "id" : "83cb5509-cf03-4089-b7b4-30014228b01f",
    "prId" : 3557,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3557#pullrequestreview-514311404",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "212c926e-0d84-4044-9ae9-edf542dbb98c",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Is there any difference between `torch.jit.ScriptModule.save` and `torch.jit.save`?",
        "createdAt" : "2020-10-22T02:12:50Z",
        "updatedAt" : "2020-11-02T22:49:54Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "8775dc2d9296dd8eee7a77806ec4fe9e77c3fc4e",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +399,403 @@    model_path = os.path.join(model_data_path, _SERIALIZED_TORCH_MODEL_FILE_NAME)\n    if isinstance(pytorch_model, torch.jit.ScriptModule):\n        torch.jit.ScriptModule.save(pytorch_model, model_path)\n    else:\n        torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)"
  },
  {
    "id" : "0d043a4d-7326-4ff4-a9de-74d8b6f97ace",
    "prId" : 3557,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3557#pullrequestreview-519471385",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95313f66-34f8-460d-a1b0-fcc73279dcdb",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Could we update the docstrings of `mlflow.pytorch.log_model` and `mlflow.pytorch.save_model` to mention that you can now also log a TorchScript model (i.e. the output of `torch.jit.trace` or `torch.jit.script`)?\r\n\r\nAlso, should we test usage of `torch.jit.trace`, i.e. `mlflow.pytorch.log_model(torch.jit.trace(model))`? I noticed all of our tests invoke `torch.jit.script` instead",
        "createdAt" : "2020-10-28T16:34:40Z",
        "updatedAt" : "2020-11-02T22:49:54Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "a30a4f67-eddd-4ef8-8928-e3f5c5a477dd",
        "parentId" : "95313f66-34f8-460d-a1b0-fcc73279dcdb",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "It'd also be good to update the documentation of ``mlflow.pytorch.load_model`` to clarify that we load back either an eager model (subclass of `torch.nn.Module`) or a TorchScripted model, depending on whether an eager or TorchScripted model was originally logged.",
        "createdAt" : "2020-10-28T16:40:37Z",
        "updatedAt" : "2020-11-02T22:49:54Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "93e940c2-02a5-4b29-bfea-30e1efce8460",
        "parentId" : "95313f66-34f8-460d-a1b0-fcc73279dcdb",
        "authorId" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "body" : "Updated the doc strings by mentioning the support of scripted model. In the example section, added the code to log and save model as well",
        "createdAt" : "2020-10-29T09:22:13Z",
        "updatedAt" : "2020-11-02T22:49:54Z",
        "lastEditedBy" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "tags" : [
        ]
      },
      {
        "id" : "816cc176-8064-4b9d-93a6-8386530afb2a",
        "parentId" : "95313f66-34f8-460d-a1b0-fcc73279dcdb",
        "authorId" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "body" : "We will raise a separate PR for updating documentation of `mlflow.pytorch`",
        "createdAt" : "2020-10-29T09:23:15Z",
        "updatedAt" : "2020-11-02T22:49:54Z",
        "lastEditedBy" : "5ea9649b-c37c-4aab-88b3-7bfcd507163e",
        "tags" : [
        ]
      }
    ],
    "commit" : "8775dc2d9296dd8eee7a77806ec4fe9e77c3fc4e",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +398,402 @@    # Save pytorch model\n    model_path = os.path.join(model_data_path, _SERIALIZED_TORCH_MODEL_FILE_NAME)\n    if isinstance(pytorch_model, torch.jit.ScriptModule):\n        torch.jit.ScriptModule.save(pytorch_model, model_path)\n    else:"
  },
  {
    "id" : "472bdb2e-79a9-49f7-a3ba-1589dec3a864",
    "prId" : 3436,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3436#pullrequestreview-518245160",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5972fe79-08a0-42dc-ba7e-d79653a1093a",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "The logic here seems correct, but just wondering - do people tend to log requirements.txt files from remote artifact stores, e.g. s3, as part of their pytorch models?\r\n\r\nWe could simplify this by requiring requirements.txt to be a file on the local filesystem. With the current logic, in the seemingly-common case where requirements.txt is in the local filesystem, we'll copy it to another temporary directory (`tmp_requirements_dir`) on the same local filesystem, which seems a bit redundant. The same is true for `extra_files`, where I imagine copying the extra files to a local `tmp_requirements_dir` could actually be quite expensive for large embedding files etc.",
        "createdAt" : "2020-10-27T23:06:41Z",
        "updatedAt" : "2020-10-27T23:11:01Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "fb6b4762-c115-4a0a-b237-7dacc572ff6d",
        "parentId" : "5972fe79-08a0-42dc-ba7e-d79653a1093a",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "From offline discussion with @chauhang:\r\n\r\nIt varies based on the files. The requirements.txt will generally be local or from github. The vocab files will be from a shared storage like S3. Other files will be very model specific so we won't know where they will come from. Hence we need support for remote download of the files if they are not local\r\n\r\nThus let's stick with the logic as is for now - we can iterate on it later if we need to optimize for whatever reason",
        "createdAt" : "2020-10-28T00:31:24Z",
        "updatedAt" : "2020-10-28T00:31:25Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6c2e9f57b96cf3371029ac14205a9a235962ff18",
    "line" : 113,
    "diffHunk" : "@@ -1,1 +382,386 @@            raise TypeError(\"Path to requirements file should be a string\")\n\n        with TempDir() as tmp_requirements_dir:\n            saved_requirements_dir_subpath = \"requirements\"\n            _download_artifact_from_uri("
  },
  {
    "id" : "cb1fb38d-5357-44bf-8d59-21af585d06f3",
    "prId" : 3436,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3436#pullrequestreview-518215752",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "499e7460-6f6d-4af7-9580-6dad18293321",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "I have the same question as https://github.com/mlflow/mlflow/pull/3436/files#r513084383 for `extra_files` (do people log `extra_files` stored remotely in S3 alongside their pytorch models, or are the extra_files usually on the local filesystem)? Happy to defer to your judgment here on what's common for pytorch users",
        "createdAt" : "2020-10-27T23:07:46Z",
        "updatedAt" : "2020-10-27T23:07:46Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6c2e9f57b96cf3371029ac14205a9a235962ff18",
    "line" : 134,
    "diffHunk" : "@@ -1,1 +403,407 @@            shutil.move(\n                tmp_extra_files_dir.path(), posixpath.join(path, saved_extra_files_dir_subpath)\n            )\n\n    torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)"
  },
  {
    "id" : "a3d29ea6-4f14-440e-9b7e-4f84a3f1600a",
    "prId" : 3436,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3436#pullrequestreview-518273352",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f620a1f0-c7cf-4698-a13b-ad7439bbe4ec",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Can we store `requirements_file` and `extra_files` values in the `MLmodel` file to make it eaiser look them up when archiving the model?",
        "createdAt" : "2020-10-28T00:28:25Z",
        "updatedAt" : "2020-10-28T01:39:29Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "0116f26d-41aa-4f01-8ccb-031ef158f8b7",
        "parentId" : "f620a1f0-c7cf-4698-a13b-ad7439bbe4ec",
        "authorId" : "005113e6-923f-4238-88d9-8c097ed155e1",
        "body" : "@harupy Adding to MLmodel has performance implications during model inference loading so these files need to be kept as separate artifacts, but bundled along with the model for version tracking and matching artifacts",
        "createdAt" : "2020-10-28T00:48:03Z",
        "updatedAt" : "2020-10-28T00:48:03Z",
        "lastEditedBy" : "005113e6-923f-4238-88d9-8c097ed155e1",
        "tags" : [
        ]
      },
      {
        "id" : "65ee2e75-1e26-4cfa-a24f-6bb68fc01706",
        "parentId" : "f620a1f0-c7cf-4698-a13b-ad7439bbe4ec",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "@chauhang\r\n\r\n> these files need to be kept as separate artifacts\r\n\r\nYes, they will be kept as separate files and `MLmodel` file (which contains metadata of a logged model) should contains information of where they are located like below.\r\n\r\n```yml\r\n# Example of MLmodel file\r\nartifact_path: models\r\nflavors:\r\n  python_function:\r\n    data: data\r\n    env: conda.yaml\r\n    loader_module: mlflow.pytorch\r\n    pickle_module_name: mlflow.pytorch.pickle_module\r\n    python_version: 3.6.10\r\n  pytorch:\r\n    model_data: data\r\n    pytorch_version: 1.4.0\r\n    # ðŸ”¥ new fields\r\n    requirements_file: ...\r\n    extra_files:\r\n      - ...\r\n      - ...\r\nrun_id: cd8c2872466c463790bc4ac70b9d161f\r\nutc_time_created: '2020-10-27 23:22:47.135800'\r\n\r\n```",
        "createdAt" : "2020-10-28T02:03:18Z",
        "updatedAt" : "2020-10-28T02:05:12Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "6c2e9f57b96cf3371029ac14205a9a235962ff18",
    "line" : 80,
    "diffHunk" : "@@ -1,1 +299,303 @@                          base64-encoded.\n\n    :param requirements_file: A string containing the path to requirements file. Remote URIs\n                      are resolved to absolute filesystem paths.\n                      For example, consider the following ``requirements_file`` string -"
  },
  {
    "id" : "9ca7a973-68b3-4164-81be-41eb19467d2d",
    "prId" : 1194,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1194#pullrequestreview-233653713",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "824d2730-ff28-4b97-8008-01d5ab9d5d6f",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "If an alternate method prototype is included in the first line of the docstring, Sphinx will use it in place of the autogenerated prototype (see http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html#confval-autodoc_docstring_signature and https://stackoverflow.com/questions/43979369/sphinx-autodoc-with-parameter-from-a-mocked-module-on-readthedocs).",
        "createdAt" : "2019-05-03T20:08:04Z",
        "updatedAt" : "2019-05-03T20:08:05Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "2d8709cf-ebaa-4dc6-b8d5-9fde83c7bf46",
        "parentId" : "824d2730-ff28-4b97-8008-01d5ab9d5d6f",
        "authorId" : "672c9aff-2ae2-4b23-92a1-3e0ef1c935e9",
        "body" : "good to know!",
        "createdAt" : "2019-05-03T20:17:05Z",
        "updatedAt" : "2019-05-03T20:17:08Z",
        "lastEditedBy" : "672c9aff-2ae2-4b23-92a1-3e0ef1c935e9",
        "tags" : [
        ]
      }
    ],
    "commit" : "2eb337360115449c0b637d073f066f4895b747a7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +60,64 @@              pickle_module=mlflow_pytorch_pickle_module, **kwargs):\n    \"\"\"\n    log_model(pytorch_model, artifact_path, conda_env=None, code_paths=None,\\\n              pickle_module=mlflow.pytorch.pickle_module, **kwargs)\n"
  },
  {
    "id" : "be8cc854-6c0d-471a-93f4-3cf60cdf10af",
    "prId" : 861,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/861#pullrequestreview-199316574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66447662-00b7-47fa-a0e5-11c1e05837d5",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "since the pickle module is an argument, should we add it here? I.e. turn this into a function taking the pickle_module argument?",
        "createdAt" : "2019-02-01T19:48:15Z",
        "updatedAt" : "2019-02-02T23:41:32Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      },
      {
        "id" : "2ef878f2-4e72-4c30-be80-bb30221e7f07",
        "parentId" : "66447662-00b7-47fa-a0e5-11c1e05837d5",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I'm not sure how to go about resolving a pip/conda package from a pickle module. In some cases, the package and module name are the same, but this may not always hold (i.e `mlflow.pytorch.pickle_module != mlflow`).\r\n\r\nUsers can always copy / modify the default conda environment and use the `conda_env` parameter of `save_model` and `log_model` if necessary.",
        "createdAt" : "2019-02-01T21:18:39Z",
        "updatedAt" : "2019-02-02T23:41:32Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "6d539607-b040-4064-9cea-e0729709dcae",
        "parentId" : "66447662-00b7-47fa-a0e5-11c1e05837d5",
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Makes sense.",
        "createdAt" : "2019-02-02T00:10:58Z",
        "updatedAt" : "2019-02-02T23:41:32Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d6d729b4602846f61d09b0ff774d244effc317b",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +44,48 @@        # it's required by the default pickle module used by `save_model()`\n        # and `log_model()`: `mlflow.pytorch.pickle_module`.\n        \"cloudpickle=={}\".format(cloudpickle.__version__)\n    ],\n    additional_conda_channels=["
  }
]