[
  {
    "id" : "63f2fd6a-9f81-4d27-add0-75ee29203273",
    "prId" : 4319,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4319#pullrequestreview-682301427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "parentId" : null,
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "Could you explain why add this attribute address the issue ? the `model` attribute is not used in `predict`",
        "createdAt" : "2021-06-02T14:39:39Z",
        "updatedAt" : "2021-06-02T14:39:39Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "e0613633-fae9-4d20-bc31-df6aee7f5315",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "body" : "Why the existing `_TF2Wrapper` doesn't work:\r\nThe TensorFlow model is loaded inside of the `_load_pyfunc` method. After loading the model the reference count of the `loaded_model` object is set to 1. When the `_load_pyfunc` method returns the reference count is decreased to 0 and the model gets deallocated. If you then try to call the infer signature, TensorFlow won't be able to find the `loaded_model` anymore.\r\n\r\nWhy the modified `_TF2Wrapper` works:\r\nIf you instead pass the model to the `_TF2Wrapper` also this object will hold a reference to the\r\n`loaded_model` object. That means in this case the reference count is 2. When the `_load_pyfunc` method returns, the reference count is reduced to 1 but never reaches zero because the `_TF2Wrapper` still exists. This avoids that the model gets deallocated.\r\n\r\nHope this answers helps. If you have more questions don't hesitate to ask me.",
        "createdAt" : "2021-06-03T20:54:11Z",
        "updatedAt" : "2021-06-03T20:54:11Z",
        "lastEditedBy" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "tags" : [
        ]
      },
      {
        "id" : "38a8ced1-cf2a-4797-8619-2f40470649a1",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "Make sense.\r\nThis looks more like a TF2 bug , the returned signature should keep reference to the model, (but actually the reference count is decreased to 0 ), but the workaround here is fine.",
        "createdAt" : "2021-06-07T12:46:00Z",
        "updatedAt" : "2021-06-07T12:46:00Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "a0377a86-c58b-4578-8094-c444fdd40347",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "body" : "I think the reason is that ConcreteFunctions (the signature is such a function) only retain a weak reference to the model variables. The behavior is described here: https://www.tensorflow.org/guide/function",
        "createdAt" : "2021-06-07T19:06:53Z",
        "updatedAt" : "2021-06-07T19:06:53Z",
        "lastEditedBy" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "tags" : [
        ]
      },
      {
        "id" : "7e1f2f56-f97c-4b8f-8537-c90c958fcbf1",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "ok i see. Thanks!\r\nCould you help add test for model serving on TF2 ?",
        "createdAt" : "2021-06-08T06:13:16Z",
        "updatedAt" : "2021-06-08T06:13:17Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "2de71341-e52b-4fdc-b133-af94485e52c3",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "body" : "Sure I can help. \r\n\r\nA unit test ist already part of this pull request:\r\nhttps://github.com/mlflow/mlflow/pull/4319/files/d05ba3e41325b159945169dc6ed1a71755172f24#diff-314e8120f884dcac5855f9ce3d1094d7871d4cc07d885d41b425d1f66c8d0e72\r\n\r\n\r\nDo you need more? ",
        "createdAt" : "2021-06-08T12:09:49Z",
        "updatedAt" : "2021-06-08T12:09:49Z",
        "lastEditedBy" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "tags" : [
        ]
      },
      {
        "id" : "ba43ed50-49f9-496d-8fd1-a8800d23a528",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "I update your added test. and move it into tests/tensorflow/test_tensorflow2_model_export.py and add `@pytest.mark.large`",
        "createdAt" : "2021-06-11T08:50:53Z",
        "updatedAt" : "2021-06-11T08:50:54Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "7fdd0c50-c23c-4645-88c0-61f31864f35d",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "Follow-up question: could you explain why the existing test passed ? \r\nhttps://github.com/mlflow/mlflow/blob/b454522ecc7727e6d90b59969019428ee49e6779/tests/tensorflow/test_tensorflow2_model_export.py#L596\r\n\r\nThe existing test also run under Tensorflow2 and also do similar thing, the only difference is it use 'predict' signature, but you use 'serving_default' signature.",
        "createdAt" : "2021-06-11T08:55:10Z",
        "updatedAt" : "2021-06-11T08:55:10Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      },
      {
        "id" : "e323df64-ead4-4b3d-9c77-8beb4ffde7d0",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "body" : "The test passed because the `saved_tf_iris_model` was defined using the Estimator API (`tf.estimator.DNNClassifier`). The API already existed in TensorFlow 1 and  doesn’t use `tf.functions`, that’s why it works. I don’t know the TensorFlow Roadmap but I assume that Google will deprecate the Estimator API sometime in the future. The Estimator documentation (https://www.tensorflow.org/guide/estimator) says the following: \r\n\r\n> TensorFlow implements several pre-made Estimators. Custom estimators are still suported, but mainly as a backwards compatibility measure. Custom estimators should not be used for new code\r\n\r\nMoreover, the TFX documentation (https://www.tensorflow.org/tfx/guide/keras) mentions:\r\n\r\n> The Estimator API has been retained in TensorFlow 2.x, but is not the focus of new features and development.\r\n\r\nRegarding `pyfunc_wrapper.predict`: At runtime `pyfunc_wrapper.predict` calls `_TF2Wrapper.predict` and this method also uses the signature (`self.infer`).\r\n",
        "createdAt" : "2021-06-11T13:34:43Z",
        "updatedAt" : "2021-06-11T13:34:44Z",
        "lastEditedBy" : "b550050a-b21e-4a2e-9346-ea3ff6020cbc",
        "tags" : [
        ]
      },
      {
        "id" : "3e16e7be-0f90-4f39-8813-008eeb240981",
        "parentId" : "361ae134-708e-4036-a9a7-3bf790c750de",
        "authorId" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "body" : "@saschaschramm Thanks for the explanation ! I add related comments into code.",
        "createdAt" : "2021-06-12T06:22:52Z",
        "updatedAt" : "2021-06-12T06:22:52Z",
        "lastEditedBy" : "52b26aee-f464-4ce0-af48-b29e1a3f86e2",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b1577baaf5a83ae7b04d3de897577d7fe24a9fb",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +562,566 @@        #  variables they close over.\n        #  See https://www.tensorflow.org/guide/function#deleting_tfvariables_between_function_calls\n        self.model = model\n        self.infer = infer\n"
  },
  {
    "id" : "b13e5764-c7ea-43d1-b0c2-c629a693020b",
    "prId" : 4195,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4195#pullrequestreview-617769459",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89eac9b2-6838-4d57-88da-7ec81838c401",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Add a newline to more clearly delineate early stopping callback logging from the original / underlying ML function invocation",
        "createdAt" : "2021-03-22T17:00:50Z",
        "updatedAt" : "2021-03-23T05:27:02Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "7bd723e33525cef9608ec58e3296808ba3731232",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1071,1075 @@                early_stop_callback = _get_early_stop_callback(callbacks)\n                _log_early_stop_callback_params(early_stop_callback)\n\n                history = original(inst, *args, **kwargs)\n"
  },
  {
    "id" : "5cfc90dc-eeb7-4b87-821e-a62a0e8a564c",
    "prId" : 4194,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4194#pullrequestreview-619300602",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "010a41a4-7b2f-42fb-8aeb-639d233deac9",
        "parentId" : null,
        "authorId" : "9b00f760-3323-47e3-bb69-3add3073befc",
        "body" : "I am pretty sure this was the behavior before anyway, but this makes it a little more clear that if `try_mlflow_log` fails to log a metric x, that metric won't be in the queue anymore due to line 630 and so will never be logged.\r\nNot blocking though since this was already the case.",
        "createdAt" : "2021-03-23T19:57:49Z",
        "updatedAt" : "2021-03-23T19:57:49Z",
        "lastEditedBy" : "9b00f760-3323-47e3-bb69-3add3073befc",
        "tags" : [
        ]
      },
      {
        "id" : "af3ed4d7-5711-487c-8eef-d964be72287f",
        "parentId" : "010a41a4-7b2f-42fb-8aeb-639d233deac9",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Yep! That's expected / is consistent with past behavior. Thanks for calling this out!",
        "createdAt" : "2021-03-24T04:20:21Z",
        "updatedAt" : "2021-03-24T04:20:21Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "23f530ae0f076c57e36faaa69b63a406304efccf",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +632,636 @@            metrics_by_run = _assoc_list_to_map(snapshot)\n            for run_id, metrics in metrics_by_run.items():\n                try_mlflow_log(client.log_batch, run_id, metrics=metrics, params=[], tags=[])\n    finally:\n        if acquired_lock:"
  },
  {
    "id" : "55c8bf9d-4119-462f-ac34-9d68387b2e9a",
    "prId" : 3861,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3861#pullrequestreview-554629751",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18221bb0-d239-4c4e-b897-bede99048ebf",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "In tensorflow autologging, multiple functions are patched:\r\n\r\n```python\r\npatches = [\r\n        (EventFileWriter, \"add_event\", add_event),\r\n        (EventFileWriterV2, \"add_event\", add_event),\r\n        (tensorflow.estimator.Estimator, \"train\", train),\r\n        (tensorflow.keras.Model, \"fit\", fit),\r\n        (tensorflow.estimator.Estimator, \"export_saved_model\", export_saved_model),\r\n        (tensorflow.estimator.Estimator, \"export_savedmodel\", export_savedmodel),\r\n        (FileWriter, \"add_summary\", add_summary),\r\n    ]\r\n```\r\n\r\n@dbczumar Is it possible to patch multple functions with `safe_patch` and share the same active run across them?",
        "createdAt" : "2020-12-17T03:36:18Z",
        "updatedAt" : "2020-12-18T07:22:35Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "ff5bc988-6ca0-4e5c-91a2-a740e023aedb",
        "parentId" : "18221bb0-d239-4c4e-b897-bede99048ebf",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "↑ Just never mind",
        "createdAt" : "2020-12-17T13:52:26Z",
        "updatedAt" : "2020-12-18T07:22:35Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "4f0914da-9390-4d47-9e7a-395226334276",
        "parentId" : "18221bb0-d239-4c4e-b897-bede99048ebf",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "The current tensorfolw autologging works like this (maybe I'm wrong):\r\n\r\n```python\r\n# no active run exists\r\n\r\nclassifier.train(...)\r\n# -> creates a new run, stores the run_id in `_AUTOLOG_RUN_ID`, and terminates it\r\n\r\nclassifier.export_saved_model(...)\r\n# -> restarts the run created by `classifier.train` using `_AUTOLOG_RUN_ID` and saves the model in it\r\n#\r\n# Does this behavior conflict with `safe_patch`?\r\n```\r\n\r\n@dbczumar I'm not sure if we really need to support this use case. I think a user can simply do:\r\n\r\n```python\r\nwith mlflow.start_run():\r\n    classifier.train(...)\r\n    classifier.export_saved_model(...)\r\n```",
        "createdAt" : "2020-12-17T14:01:36Z",
        "updatedAt" : "2020-12-18T07:22:35Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0b3d405a3c569b0efaedc9df123bf5f46a7f57c",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +33,37 @@from mlflow.utils.annotations import keyword_only, experimental\nfrom mlflow.utils.environment import _mlflow_conda_env\nfrom mlflow.utils.file_utils import _copy_file_or_tree\nfrom mlflow.utils.model_utils import _get_flavor_configuration\nfrom mlflow.utils.mlflow_tags import MLFLOW_AUTOLOGGING"
  },
  {
    "id" : "cfec073a-6fc9-4d98-8a45-c99b568aca19",
    "prId" : 3861,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3861#pullrequestreview-555162358",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b341d41f-6572-46c7-af88-832ed52dcdf6",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Manually set an `MLFLOW_AUTOLOGGING` tag.",
        "createdAt" : "2020-12-18T04:17:20Z",
        "updatedAt" : "2020-12-18T07:22:35Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0b3d405a3c569b0efaedc9df123bf5f46a7f57c",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +887,891 @@            else:\n                try_mlflow_log(mlflow.start_run)\n                try_mlflow_log(mlflow.set_tag, MLFLOW_AUTOLOGGING, FLAVOR_NAME)\n                auto_end = True\n"
  },
  {
    "id" : "7bceecfd-7560-4098-b641-6e853012522f",
    "prId" : 3808,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3808#pullrequestreview-555681798",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4db0afbb-23e6-4144-a6bb-4766484612cf",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "We can probably simplify now that know data is DataFrame to:`feed_dict = {k: tensorflow.constant(v.values) for k, v in list(data)}`",
        "createdAt" : "2020-12-15T00:15:24Z",
        "updatedAt" : "2020-12-21T19:44:39Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      },
      {
        "id" : "0b949b09-891d-4e63-8040-cc5db18ccd4c",
        "parentId" : "4db0afbb-23e6-4144-a6bb-4766484612cf",
        "authorId" : "6df779be-baaa-40f8-bfb9-de44c59eb7af",
        "body" : "Oh I think the purpose of this implementation is explained in the comments below. We need to also check if `data[df_col_name]` is also a dataframe (there are multiple columns with the same name) and convert that to a np array instead. If there's only one column, `data[df_col_name]` will have a `pandas.core.series.Series` type, which is fine to pass into `tensorflow.constant` I guess",
        "createdAt" : "2020-12-16T01:06:22Z",
        "updatedAt" : "2020-12-21T19:44:39Z",
        "lastEditedBy" : "6df779be-baaa-40f8-bfb9-de44c59eb7af",
        "tags" : [
        ]
      },
      {
        "id" : "c69f9e03-adba-4594-ab6f-6066511db0de",
        "parentId" : "4db0afbb-23e6-4144-a6bb-4766484612cf",
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Oh, interesting, I did not know! Thanks for clarifying this.\r\nI guess this is another way of passing tensors in a Dataframe.",
        "createdAt" : "2020-12-18T17:34:14Z",
        "updatedAt" : "2020-12-21T19:44:39Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "b515a54d7e1dda24141c4615b42df81f58863060",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +564,568 @@            feed_dict = {k: tensorflow.constant(v) for k, v in data.items()}\n        elif isinstance(data, pandas.DataFrame):\n            for df_col_name in list(data):\n                # If there are multiple columns with the same name, selecting the shared name\n                # from the DataFrame will result in another DataFrame containing the columns"
  },
  {
    "id" : "0f5b9234-7602-403b-9754-14450de0e4f6",
    "prId" : 3735,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3735#pullrequestreview-538209722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ea63169-1997-40d0-a240-f17e654a5684",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "`kwargs[\"callbacks\"]` may still be `None`, as this is the default value for the argument. For example, `fit_generator()` calls `fit()` with `callbacks=None` in TensorFlow >= 2.1.0. Many of our other autologging integrations address this case, but this one does not.",
        "createdAt" : "2020-11-25T07:15:35Z",
        "updatedAt" : "2020-11-26T00:31:10Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "8cc2957ff2b6882e6c2b73b437c7c6f434ee09bd",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +997,1001 @@                tmp_list[5], log_dir = _setup_callbacks(tmp_list[5], log_models)\n                args = tuple(tmp_list)\n            elif kwargs.get(\"callbacks\"):\n                early_stop_callback = _early_stop_check(kwargs[\"callbacks\"])\n                kwargs[\"callbacks\"], log_dir = _setup_callbacks(kwargs[\"callbacks\"], log_models)"
  },
  {
    "id" : "41b36c51-740f-44a1-b86e-db81525ffab7",
    "prId" : 3663,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3663#pullrequestreview-530374173",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04b0d639-0c00-4040-9e64-28c083f7623f",
        "parentId" : null,
        "authorId" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "body" : "maybe we can avoid attaching the callback altogether if log_models is False? It seems like the only thing the callback is doing is logging the model. also please lemme know if i'm missing something :)",
        "createdAt" : "2020-11-12T23:44:17Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "tags" : [
        ]
      },
      {
        "id" : "892e123f-26a1-4670-8179-c094a696bac0",
        "parentId" : "04b0d639-0c00-4040-9e64-28c083f7623f",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "These callbacks log parameters, metrics, & tags containing other relevant content. Even if we're omitting the model, we should preserve these callbacks.",
        "createdAt" : "2020-11-13T20:14:08Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "22b8871c8db9781e8473fd43560e6cd977c3af53",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +638,642 @@\n\ndef _setup_callbacks(lst, log_models):\n    \"\"\"\n    Adds TensorBoard and MlfLowTfKeras callbacks to the"
  },
  {
    "id" : "d714a4d8-d9b0-4b69-acc6-1f0d19275111",
    "prId" : 3387,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3387#pullrequestreview-483736105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "02e75d27-caf2-4cda-b6fd-ecaf9eb9cafd",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "@dbczumar Should we make the `name` argument of `wrap_patch` optional so we can omit it when a patch function has the same name as a target destination attribute?\r\n\r\n```python\r\ndef wrap_patch(dest, patch, name=None, ...):\r\n    name = patch.__name__ if name is None else name\r\n    ...\r\n```",
        "createdAt" : "2020-09-04T07:39:05Z",
        "updatedAt" : "2020-09-04T07:39:40Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "2b10e2dd-69ec-4d03-bd3d-d08da5e1fe61",
        "parentId" : "02e75d27-caf2-4cda-b6fd-ecaf9eb9cafd",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I don't think that optimization is strictly necessary. `gorilla` doesn't do it, for example.",
        "createdAt" : "2020-09-08T00:43:40Z",
        "updatedAt" : "2020-09-08T00:43:40Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "98c16a32-ca7a-477a-b4f2-3c6b25b3fcb9",
        "parentId" : "02e75d27-caf2-4cda-b6fd-ecaf9eb9cafd",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "makes sense",
        "createdAt" : "2020-09-08T00:47:36Z",
        "updatedAt" : "2020-09-08T00:47:36Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "a97931c15b19c89416ce7e870110269ccc91a43e",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +1059,1063 @@        (tensorflow.estimator.Estimator, \"export_saved_model\", export_saved_model),\n        (tensorflow.estimator.Estimator, \"export_savedmodel\", export_savedmodel),\n        (FileWriter, \"add_summary\", add_summary),\n    ]\n"
  },
  {
    "id" : "8d73be8d-7a53-49c2-a4a4-8528decb5a48",
    "prId" : 2873,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2873#pullrequestreview-430183582",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b068cf7-812f-445f-af25-db7c753565a1",
        "parentId" : null,
        "authorId" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "body" : "Great that we moved this up top! A lot of people were definitely confused by this...",
        "createdAt" : "2020-06-14T03:00:19Z",
        "updatedAt" : "2020-06-16T14:39:19Z",
        "lastEditedBy" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d77ca085e213bcd88b05edbb1f549b24f6b4cd9",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +696,700 @@    \"\"\"\n    Enables automatic logging from TensorFlow to MLflow.\n    Note that autologging for ``tf.keras`` is handled by :py:func:`mlflow.tensorflow.autolog`,\n    not :py:func:`mlflow.keras.autolog`.\n    As an example, try running the"
  },
  {
    "id" : "a2844ae2-b813-4262-a894-057968445ef5",
    "prId" : 2873,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2873#pullrequestreview-432102561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dde9f40f-6b18-487f-b65d-70fdc59d9886",
        "parentId" : null,
        "authorId" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "body" : "In the screenshots, it looks like the `Parameters` subheader has the same style as the subheaders for the different modules listed earlier (e.g. `TensorFlow Core`). Is there any way to meaningfully differentiate the headers to make it clear we're done with listing modules?",
        "createdAt" : "2020-06-14T03:10:35Z",
        "updatedAt" : "2020-06-16T14:39:19Z",
        "lastEditedBy" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "tags" : [
        ]
      },
      {
        "id" : "6e45b7cb-a8cf-4ffb-bca5-5e5c3c2f11cd",
        "parentId" : "dde9f40f-6b18-487f-b65d-70fdc59d9886",
        "authorId" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "body" : "Note two things:\r\n\r\n- the sentence following TF 1.x and TF2.x refers to link to the TF examples\r\n- The last sentence after `TensoreCore:` module signals that this is the end of the modules and frameworks. In a way, it delineates this from the `Parameters` list as part of the argument to the method.\r\n\r\nTop-level bulleted strings within docstring have that style.  \r\n\r\nAnother option is to move the `Parameters` (as part of the method call argument) up and above  \"Enables automatic logging from TensorFlow to MLflow. Note that autologging ...\r\n\r\nEither works, yet I lean toward leaving as is because it's consistent with how we describe what the method does and its semantics (in this case a bit elaborate), followed by what argument it takes and what it returns, as the last bit.\r\n\r\n\r\n",
        "createdAt" : "2020-06-16T14:05:05Z",
        "updatedAt" : "2020-06-16T16:26:03Z",
        "lastEditedBy" : "6d4a2e11-d3e1-4165-abba-00dd048f07b1",
        "tags" : [
        ]
      },
      {
        "id" : "54d8f03e-8cce-4f61-968d-ef2966e5bbc9",
        "parentId" : "dde9f40f-6b18-487f-b65d-70fdc59d9886",
        "authorId" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "body" : "Ah ok I see what you mean. In that case I think we should be ok leaving it as is. Thanks for looking into it!",
        "createdAt" : "2020-06-17T06:46:17Z",
        "updatedAt" : "2020-06-17T06:46:28Z",
        "lastEditedBy" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d77ca085e213bcd88b05edbb1f549b24f6b4cd9",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +743,747 @@    <https://www.mlflow.org/docs/latest/tracking.html#tensorflow-and-keras-experimental>`_.\n\n    :param every_n_iter: The frequency with which metrics should be logged.\n                                  Defaults to 100. Ex: a value of 100 will log metrics\n                                  at step 0, 100, 200, etc."
  },
  {
    "id" : "87aa7b40-cf73-4481-9e64-516bf6dc94dc",
    "prId" : 2094,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2094#pullrequestreview-318160817",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b9b794d-663e-4b06-9687-f3d6da402592",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Should we pull this logic for checking if a run is active & creating one if not into a helper like `_maybe_create_active_run`? Would make it easier to standardize / reduce code duplication",
        "createdAt" : "2019-11-18T08:28:31Z",
        "updatedAt" : "2019-11-19T01:55:37Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef49a17e1bf649ad100e1f57b8e1a11ec7197129",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +585,589 @@    \"\"\"\n    if not mlflow.active_run():\n        try_mlflow_log(mlflow.start_run)\n        global _AUTOLOG_RUN_ID\n        _AUTOLOG_RUN_ID = mlflow.active_run().info.run_id"
  },
  {
    "id" : "4aa33794-7e14-4401-a68c-7b15428d55b1",
    "prId" : 2055,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2055#pullrequestreview-314524975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41a02560-ef4a-445f-9b86-fc29232e0448",
        "parentId" : null,
        "authorId" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "body" : "Same thing here with moving the model summary to the beginning of training",
        "createdAt" : "2019-11-09T00:29:17Z",
        "updatedAt" : "2019-11-09T00:38:45Z",
        "lastEditedBy" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "tags" : [
        ]
      },
      {
        "id" : "cc11f1e7-44f8-4ac3-9434-c16b85c69ebc",
        "parentId" : "41a02560-ef4a-445f-9b86-fc29232e0448",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Done!",
        "createdAt" : "2019-11-09T00:38:55Z",
        "updatedAt" : "2019-11-09T00:39:03Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a5658084b56740290c51d6af0700e2fcad0fa54",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +482,486 @@        pass\n\n    def on_train_end(self, logs=None):  # pylint: disable=unused-argument\n        try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')\n"
  },
  {
    "id" : "00442cee-f227-4701-a444-70b1469e9869",
    "prId" : 2055,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2055#pullrequestreview-314524975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3538adce-a71b-431e-ba6d-d10d755a3657",
        "parentId" : null,
        "authorId" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "body" : "Just adding a comment so you don't forget to move the summary logging here as well!",
        "createdAt" : "2019-11-09T00:30:26Z",
        "updatedAt" : "2019-11-09T00:38:45Z",
        "lastEditedBy" : "e71c4958-9dfb-45f1-bc0b-6dd7ac6aef54",
        "tags" : [
        ]
      },
      {
        "id" : "b78b391f-5ad3-46ef-93b7-7432f40ccfb5",
        "parentId" : "3538adce-a71b-431e-ba6d-d10d755a3657",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Done, thank you! :D",
        "createdAt" : "2019-11-09T00:39:00Z",
        "updatedAt" : "2019-11-09T00:39:03Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a5658084b56740290c51d6af0700e2fcad0fa54",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +505,509 @@        for attribute in config:\n            try_mlflow_log(mlflow.log_param, \"opt_\" + attribute, config[attribute])\n\n        sum_list = []\n        self.model.summary(print_fn=sum_list.append)"
  },
  {
    "id" : "5b3fe8c5-40a9-4895-be89-dd3738e48509",
    "prId" : 1872,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1872#pullrequestreview-292636344",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "143cad1c-5d7b-4c39-b8a0-27f8bbd7acc4",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Looks like most of the code (calling `_download_artifact_from_uri `, `_get_and_parse_flavor_configuration`),  in this if/else block is common across TF 1.x & 2.0, maybe we can pull the common code out of the if/else block?",
        "createdAt" : "2019-09-24T18:52:32Z",
        "updatedAt" : "2019-09-27T23:02:00Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "cbb3c6ce1d9c29dbab58d75bdf254a3ce5890b58",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +254,258 @@    \"\"\"\n\n    if LooseVersion(tensorflow.__version__) < LooseVersion('2.0.0'):\n        if not tf_sess:\n            tf_sess = tensorflow.get_default_session()"
  },
  {
    "id" : "456b5cc9-522d-4312-887d-e526b25b6c9b",
    "prId" : 1520,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1520#pullrequestreview-256575440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18bafa9a-a5a9-423c-820f-eeb3eb8bac3e",
        "parentId" : null,
        "authorId" : "9b00f760-3323-47e3-bb69-3add3073befc",
        "body" : "There doesn't seem to be a better fix for this. Pylint seems to be unable to find any members of TensorFlow (especially in the form `from tensorflow.x import y`)",
        "createdAt" : "2019-07-01T21:41:21Z",
        "updatedAt" : "2019-07-12T16:17:04Z",
        "lastEditedBy" : "9b00f760-3323-47e3-bb69-3add3073befc",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b0bd51f98f58d5d6e0e3eeff2e7d000063a2bc7",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +27,31 @@import tensorflow\nimport mlflow.keras\nfrom tensorflow.keras.callbacks import Callback, TensorBoard  # pylint: disable=import-error\nfrom mlflow import pyfunc\nfrom mlflow.exceptions import MlflowException"
  },
  {
    "id" : "0f4e1f14-62f7-457c-9813-e38250ed4971",
    "prId" : 1520,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1520#pullrequestreview-257772104",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa650cd0-5773-48b0-9d29-7e7a2b8f8a2d",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "We should remember to add a docstring here (it'll show hosted API docs, e.g. [see the docs](https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html#mlflow.tensorflow.load_model) for `mlflow.tensorflow.load_model` and the [corresponding code](https://github.com/mlflow/mlflow/blob/0539a16f841f990717b3d1260e9670074e30a71c/mlflow/tensorflow.py#L181))",
        "createdAt" : "2019-07-03T23:16:39Z",
        "updatedAt" : "2019-07-12T16:17:04Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b0bd51f98f58d5d6e0e3eeff2e7d000063a2bc7",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +474,478 @@\n@experimental\ndef autolog(metrics_every_n_steps=100):\n    # pylint: disable=E0611\n    \"\"\""
  },
  {
    "id" : "d48b56f4-3f61-440d-b45d-5002ce9bd4fe",
    "prId" : 1520,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1520#pullrequestreview-257772104",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87b1f4b6-1dde-4d9b-8c4a-a3d36d542ec5",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Maybe before this check we can verify that the TF version is a supported one (e.g. >=1.12, <2.0) and log a warning / exit if it's not.",
        "createdAt" : "2019-07-03T23:19:33Z",
        "updatedAt" : "2019-07-12T16:17:04Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b0bd51f98f58d5d6e0e3eeff2e7d000063a2bc7",
    "line" : 254,
    "diffHunk" : "@@ -1,1 +500,504 @@        return\n\n    try:\n        from tensorflow.python.summary.writer.event_file_writer import EventFileWriter\n        from tensorflow.python.summary.writer.event_file_writer_v2 import EventFileWriterV2"
  },
  {
    "id" : "b4008901-5b95-48d9-9063-82d593e07b22",
    "prId" : 692,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/692#pullrequestreview-172646296",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a87cb70-a565-4a53-8d75-b51a9c055385",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "The [TF 1.12 release notes](https://github.com/tensorflow/tensorflow/blob/61c6c84964b4aec80aeace187aab8cb2c3e55a72/RELEASE.md#bug-fixes-and-other-changes) suggest that accessing `meta_graph_def.signature_def[tf_signature_def_key]` should raise a KeyError if `tf_signature_def_key` isn't in `meta_graph_def.signature_def`, but a SignatureDef is returned instead. Thus we check whether `tf_signature_def_key` is present here. ",
        "createdAt" : "2018-11-07T18:56:55Z",
        "updatedAt" : "2018-11-07T18:58:28Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "70f753f732a2f75730af39a8ed23e3d2f164ceed",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +190,194 @@            tags=tf_meta_graph_tags,\n            export_dir=tf_saved_model_dir)\n    if tf_signature_def_key not in meta_graph_def.signature_def:\n        raise MlflowException(\"Could not find signature def key %s\" % tf_signature_def_key)\n    return meta_graph_def.signature_def[tf_signature_def_key]"
  },
  {
    "id" : "515ba98b-ba06-498c-9840-ac7c00589ec3",
    "prId" : 612,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/612#pullrequestreview-163969800",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3ef11bc-98c1-4e82-a8f0-66db0fa4e1c0",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Are there reasonable defaults we could set for `tf_meta_graph_tags`, `tf_signature_def_key` for ease of use?\r\n\r\nAt least for `tf_meta_graph_tags`, it looks like we could set a default of [`tag_constants.SERVING`](https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants) - both the `tf.saved_model.simple_save` and `tf.estimator.Estimator.export_saved_model` produce a SavedModel contianing a MetaGraphDef associated with the `tag_constants.SERVING` key.\r\n\r\nFor `tf_signature_def_key` it might be trickier:\r\n* It looks like [custom tf.Estimators](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_saved_model) are required to include a signature def of `tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY`.\r\n* It's a bit harder to tell what hapepns when using [`tf.saved_model.simple_save`](https://www.tensorflow.org/guide/saved_model#simple_save), but based on [this unit test](https://github.com/tensorflow/tensorflow/blob/708b30f4cb82271bb28cb70a1e0c89a1933f5b64/tensorflow/python/saved_model/simple_save_test.py#L72) seems like it saves a signature def with `DEFAULT_SERVING_SIGNATURE_DEF_KEY` as well\r\n* Unfortunately canned estimators seem don't seem to include `DEFAULT_SERVING_SIGNATURE_DEF_KEY` by default (or at least our test breaks if I try to add a default)\r\n\r\nSo maybe we could just set a default for `tf_meta_graph_tags`, let me know what you think :)",
        "createdAt" : "2018-10-10T07:24:50Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "28f8f262-2c6f-4182-a7c3-85c9b675f24f",
        "parentId" : "c3ef11bc-98c1-4e82-a8f0-66db0fa4e1c0",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I would be more on board with the idea of specifying default values if we had reasonable defaults for both parameters. It seems that the user will need to know the value of their `SavedModel`'s `signature_def_key` because a default value for this parameter is somewhat difficult to nail down. Finding this value requires the same understanding and skillset as finding the value for the meta graph tags. Additionally, there are many Tensorflow examples that save models with the `tf_meta_graph_tags = tag_constants.TRAINING`. \r\n\r\nFor these reasons, I'm more in favor of requiring explicit values for both parameters. If you still feel strongly about having a default value for `tf_meta_graph_tags`, we can incorporate it.",
        "createdAt" : "2018-10-11T19:06:58Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d24380e65017df02e02db4704142ae17782895d2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +31,35 @@\n\ndef log_model(tf_saved_model_dir, tf_meta_graph_tags, tf_signature_def_key, artifact_path,\n              conda_env=None):\n    \"\"\""
  },
  {
    "id" : "53cffd69-a1fd-4003-86e2-c655a91ea0d9",
    "prId" : 612,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/612#pullrequestreview-163969800",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00d2abcd-b1fb-4e6e-97f2-5de013dce1a0",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Could we validate here that the specified `meta_graph_tags`, `signature_def_key` are actually present in the saved model? It'd be nice to do that so users don't persist a model that can't be loaded back properly, and also add a unit test that verifies that we perform the check properly",
        "createdAt" : "2018-10-10T20:37:59Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "ad025107-82e9-4240-b44e-d9232a87ae12",
        "parentId" : "00d2abcd-b1fb-4e6e-97f2-5de013dce1a0",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Yep, good idea! Added a `_validate_saved_model` method that attempts to load the specified Tensorflow model in a fresh graph, emitting useful error output if the loading process fails.",
        "createdAt" : "2018-10-11T19:07:43Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d24380e65017df02e02db4704142ae17782895d2",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +98,102 @@    if os.path.exists(path):\n        raise MlflowException(\"Path '{}' already exists\".format(path), DIRECTORY_NOT_EMPTY)\n    os.makedirs(path)\n    root_relative_path = _copy_file_or_tree(src=tf_saved_model_dir, dst=path, dst_dir=None)\n    model_dir_subpath = \"tfmodel\""
  },
  {
    "id" : "c4bbc41d-9b5f-4db5-a20f-57a57b5ab2b5",
    "prId" : 612,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/612#pullrequestreview-163969800",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0ce08cf-0287-42b0-ad06-aaa963abc622",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Was thinking we should try to avoid using `tf.contrib` if we can, since it'll be deprecated / split up in TF 2.0 ([see roadmap]( https://www.tensorflow.org/community/roadmap#roadmap_2)). However the roadmap isn't super clear on the plan for `tf.contrib` & I can't find an equivalent utility method outside of contrib, so seems fine to leave this as is & refactor later",
        "createdAt" : "2018-10-10T20:42:48Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "bb05f216-679e-4f22-acfd-ccb6ddbf02b1",
        "parentId" : "f0ce08cf-0287-42b0-ad06-aaa963abc622",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Good point! Unfortunately, I also can't seem to find an equivalent utility. I added a TODO with a link to the roadmap as a reminder to switch away from `tf.contrib` when an alternative becomes available.",
        "createdAt" : "2018-10-11T19:42:13Z",
        "updatedAt" : "2018-10-12T01:13:13Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d24380e65017df02e02db4704142ae17782895d2",
    "line" : 232,
    "diffHunk" : "@@ -1,1 +192,196 @@    # TODO: Stop relying on `tf.contrib` when it becomes deprecated. For reference, see the\n    #       Tensorflow roadmap: https://www.tensorflow.org/community/roadmap#roadmap_2.\n    signature_def = tf.contrib.saved_model.get_signature_def_by_key(\n            meta_graph_def, tf_signature_def_key)\n    return signature_def"
  },
  {
    "id" : "5721f6f9-a793-4199-8d12-830a6a974dc9",
    "prId" : 94,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/94#pullrequestreview-133047124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5e56f5d-163f-4e20-9451-5ec5e43d8aae",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Main change: pass a dictionary of `output_name -> output_tensor` to `sess.run`. The result (`raw_preds`) is a dictionary of `output_name -> numpy arr of values` obtained by running the TensorFlow graph. See [tf.Session.run() docs](https://www.tensorflow.org/api_docs/python/tf/Session#run) for more info",
        "createdAt" : "2018-06-28T21:23:29Z",
        "updatedAt" : "2018-06-28T22:44:38Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "e0dd1a9c-5ce6-429d-9168-84724d57ca0b",
        "parentId" : "a5e56f5d-163f-4e20-9451-5ec5e43d8aae",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "@tomasatdatabricks had a good question here about whether the model outputs have a fixed ordering - the outputs are a proto `map<string, TensorInfo>` ([see SignatureDef doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/meta_graph.proto#L83)), and proto maps [have no guaranteed ordering](https://developers.google.com/protocol-buffers/docs/proto#maps)",
        "createdAt" : "2018-06-28T22:41:02Z",
        "updatedAt" : "2018-06-28T22:44:38Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "501c5cc0e474f029bf217e38862d0f21cb958acb",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +56,60 @@            feed_dict = {graph.get_tensor_by_name(tnsr_info.name): df[sigdef_input].values\n                        for sigdef_input, tnsr_info in sig_def.inputs.items()}\n            raw_preds = sess.run(fetch_mapping, feed_dict=feed_dict)\n            pred_dict = {fetch_name: list(values) for fetch_name, values in raw_preds.items()}\n            return pandas.DataFrame(data=pred_dict)"
  }
]