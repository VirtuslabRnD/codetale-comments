[
  {
    "id" : "e7ca7e8d-55c9-43f5-8e8a-c93db3b28178",
    "prId" : 4416,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4416#pullrequestreview-685842985",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc2536f6-d9f0-46f0-a6b3-1c42537e545d",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "This is unfortunate. We could consider special-casing non-file-store tracking URIs. We've had discussions in the past about deprecating the file store, but we haven't yet taken that step.\r\n\r\nFor now, I'd opt for synchronous / sequential execution of logging within a run. This also reduces the likelihood of saturating / overloading the Databricks MLflow Tracking server (and other third-party Tracking implementations).",
        "createdAt" : "2021-06-16T23:44:20Z",
        "updatedAt" : "2021-06-16T23:44:41Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "79fdac65-a85a-4c1a-a890-fe024c4c5223",
        "parentId" : "dc2536f6-d9f0-46f0-a6b3-1c42537e545d",
        "authorId" : "ae7dd827-9f9e-4fb6-b1ba-d051793e929e",
        "body" : "This is probably fine for now. For file store we could potentially introduce chunked files to support concurrent write.",
        "createdAt" : "2021-06-17T04:07:15Z",
        "updatedAt" : "2021-06-17T04:08:52Z",
        "lastEditedBy" : "ae7dd827-9f9e-4fb6-b1ba-d051793e929e",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0a64505fffd8d07eac9f59b203f05e4c5b27d99",
    "line" : 262,
    "diffHunk" : "@@ -1,1 +260,264 @@        NB: Operations are not parallelized on a per-run basis because MLflow's File Store, which\n        is frequently used for local ML development, does not support threadsafe metadata logging\n        within a given run.\n        \"\"\"\n        if pending_operations.create_run:"
  },
  {
    "id" : "c3c0987a-2790-40d5-a2f4-ce09400268db",
    "prId" : 4416,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4416#pullrequestreview-686865621",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e2b7f10-bffa-4df2-a44e-61f29aa6cf49",
        "parentId" : null,
        "authorId" : "ae7dd827-9f9e-4fb6-b1ba-d051793e929e",
        "body" : "Could this number become negative? It seems not the intention to use it that way below.",
        "createdAt" : "2021-06-17T21:05:41Z",
        "updatedAt" : "2021-06-17T21:10:31Z",
        "lastEditedBy" : "ae7dd827-9f9e-4fb6-b1ba-d051793e929e",
        "tags" : [
        ]
      },
      {
        "id" : "634a9f2f-6b14-4599-b2ca-d67b34a30142",
        "parentId" : "0e2b7f10-bffa-4df2-a44e-61f29aa6cf49",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Good callout! I've added logic to ensure that the value is never negative.",
        "createdAt" : "2021-06-17T21:48:43Z",
        "updatedAt" : "2021-06-17T21:48:43Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0a64505fffd8d07eac9f59b203f05e4c5b27d99",
    "line" : 298,
    "diffHunk" : "@@ -1,1 +296,300 @@            param_batches_to_log, tag_batches_to_log, fillvalue=[]\n        ):\n            metrics_batch_size = min(\n                MAX_ENTITIES_PER_BATCH - len(params_batch) - len(tags_batch), MAX_METRICS_PER_BATCH,\n            )"
  }
]