[
  {
    "id" : "81e1df2f-4bd5-4dbd-b71e-f2e3f03ab991",
    "prId" : 3663,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3663#pullrequestreview-530346551",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4fbb9193-3b5c-4ca9-b616-856a89ab42d4",
        "parentId" : null,
        "authorId" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "body" : "for the cases where we have the log_input_examples and log_model_signatures parameters, I wonder if it would make sense to put the log_models param at the front? It's a nit but it might make more sense for users reading the docs, since if log_models is False they can just skip reading the explanations for log_input_examples and log_model_signatures",
        "createdAt" : "2020-11-12T23:48:27Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "tags" : [
        ]
      },
      {
        "id" : "46609e10-b245-4ddc-919c-d2a2abf337be",
        "parentId" : "4fbb9193-3b5c-4ca9-b616-856a89ab42d4",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "That's unfortunately a backwards-incompatible change at this point since the API has been released with a particular argument ordering for log_input_examples / log_model_signatures.",
        "createdAt" : "2020-11-13T19:28:00Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "22b8871c8db9781e8473fd43560e6cd977c3af53",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +282,286 @@\n@experimental\ndef autolog(log_input_examples=False, log_model_signatures=True, log_models=True):\n    \"\"\"\n    Enables automatic logging from LightGBM to MLflow. Logs the following."
  },
  {
    "id" : "be3fab1f-2824-480c-a50f-45fed0be8134",
    "prId" : 3663,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3663#pullrequestreview-530423672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a50e457b-a967-4439-9a85-507c38396f4c",
        "parentId" : null,
        "authorId" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "body" : "We could also consider avoiding computing the input_example and signature altogether in the case where log_models is False. It's kind of nitpicky but technically we are currently not ignoring the log_input_example and log_signature options, as we still compute them. I think in most cases that's totally fine, but I believe we added the log_signature option for performance reasons (as signature inference can take some time for datasets with a lot of features) so in some cases it would be nice to speed up the user's workflow by not inferring the signature if log_models is false.",
        "createdAt" : "2020-11-12T23:54:52Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "4009fe74-c5d1-469a-bdb2-62f993bc2d7d",
        "tags" : [
        ]
      },
      {
        "id" : "b5adf2c4-6672-4cf0-ae6a-0628321f8883",
        "parentId" : "a50e457b-a967-4439-9a85-507c38396f4c",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "+1",
        "createdAt" : "2020-11-13T20:13:09Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      },
      {
        "id" : "f850efa9-bc7b-4226-a2c5-8a528bc7bae9",
        "parentId" : "a50e457b-a967-4439-9a85-507c38396f4c",
        "authorId" : "c7dda55d-9e2b-478f-9c63-d6cdec83a883",
        "body" : "I agree, will update in next commit",
        "createdAt" : "2020-11-13T21:21:49Z",
        "updatedAt" : "2020-11-18T03:30:28Z",
        "lastEditedBy" : "c7dda55d-9e2b-478f-9c63-d6cdec83a883",
        "tags" : [
        ]
      }
    ],
    "commit" : "22b8871c8db9781e8473fd43560e6cd977c3af53",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +501,505 @@\n        # Whether to automatically log the trained model based on boolean flag.\n        if log_models:\n            # Will only resolve `input_example` and `signature` if `log_models` is `True`.\n            input_example, signature = resolve_input_example_and_signature("
  },
  {
    "id" : "c317b816-a593-4273-aeca-f1e050286aa1",
    "prId" : 2275,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2275#pullrequestreview-340987350",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2420029d-d498-496f-a49f-606ceae8a785",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Just to confirm, it sounds ([from the docs](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html#lightgbm-train)) that `best_iteration` is set as long as the user configures their Booster to use early stopping, even if we end up training for the full number of training epochs & do not stop early (?)",
        "createdAt" : "2020-01-10T00:09:43Z",
        "updatedAt" : "2020-01-10T07:05:02Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "b7592c4d-c51d-4961-b5f8-9e64b040253c",
        "parentId" : "2420029d-d498-496f-a49f-606ceae8a785",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Yes, it doesn't matter whether or not the training stopped early.\r\n\r\nhttps://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/callback.html#early_stopping",
        "createdAt" : "2020-01-10T01:52:31Z",
        "updatedAt" : "2020-01-10T07:05:02Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "c58cb683-5e6c-47c6-bf99-69c8deb6c7c8",
        "parentId" : "2420029d-d498-496f-a49f-606ceae8a785",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Wrote a simple test code to confirm this.\r\n\r\n```python\r\n# code\r\nmodel = lgb.train(params,\r\n                  train_set,\r\n                  num_boost_round=2,\r\n                  early_stopping_rounds=10,  # setting larger value than num_boost_round\r\n                  valid_sets=[train_set, valid_set],\r\n                  valid_names=['train', 'valid'])\r\nprint(model.best_iteration)\r\nprint(model.best_score)\r\n```\r\n\r\noutput\r\n\r\n```\r\n[1]     train's multi_logloss: 0        valid's multi_logloss: 0\r\nTraining until validation scores don't improve for 10 rounds\r\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\r\n[2]     train's multi_logloss: 0        valid's multi_logloss: 0\r\nDid not meet early stopping. Best iteration is:\r\n[1]     train's multi_logloss: 0        valid's multi_logloss: 0\r\n1\r\ndefaultdict(<class 'collections.OrderedDict'>, {'train': OrderedDict([('multi_logloss', 0.0)]), 'valid': OrderedDict([('multi_logloss', 0.0)])})\r\n```",
        "createdAt" : "2020-01-10T03:13:06Z",
        "updatedAt" : "2020-01-10T07:05:02Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      },
      {
        "id" : "acb00b26-0d9f-4b11-a834-92a3e7128807",
        "parentId" : "2420029d-d498-496f-a49f-606ceae8a785",
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "Added a comment on this behavior for clarification.\r\n\r\n",
        "createdAt" : "2020-01-10T07:18:30Z",
        "updatedAt" : "2020-01-10T07:18:30Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "29bfadd070695e93c0ff3abb864194ebd9f8d1d9",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +276,280 @@            try_mlflow_log(mlflow.log_metric, 'stopped_iteration', len(eval_results))\n            # best_iteration is set even if training does not stop early.\n            try_mlflow_log(mlflow.log_metric, 'best_iteration', model.best_iteration)\n            # iteration starts from 1 in LightGBM.\n            try_mlflow_log(mlflow.log_metrics, eval_results[model.best_iteration - 1],"
  }
]