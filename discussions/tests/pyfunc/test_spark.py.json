[
  {
    "id" : "4bcb3a8f-d47f-4f62-b953-c24e910e2669",
    "prId" : 4243,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4243#pullrequestreview-634191454",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "222eb2a5-6217-472a-b6ea-fb5a1e9f8776",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "This line doesn't raise `Py4JJavaError` in pyspark 3.x. \r\n\r\n```\r\n>               raise converted from None\r\nE               pyspark.sql.utils.PythonException: \r\nE                 An exception was thrown from the Python worker. Please see the stack trace below.\r\n```\r\n\r\nhttps://github.com/mlflow/mlflow/runs/2330220978#step:6:611\r\n\r\n",
        "createdAt" : "2021-04-13T05:44:41Z",
        "updatedAt" : "2021-04-13T05:46:49Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d2d6fdbb0bdba895abe5b888ec90972b7c9d25",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +136,140 @@        )\n        with pytest.raises(pyspark.sql.utils.PythonException):\n            res = data.withColumn(\"res1\", udf(\"a\", \"b\")).select(\"res1\").toPandas()\n\n        res = data.withColumn(\"res2\", udf(\"a\", \"b\", \"c\")).select(\"res2\").toPandas()"
  },
  {
    "id" : "ce2e1303-ba1a-492f-94c9-2837a656e4ad",
    "prId" : 4236,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4236#pullrequestreview-633708574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "351bee53-5663-49be-9ae0-5feaa295ee95",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Can we also test that if user gives argument list we respect that? E.g. assert that the following raises: \r\n`res = good_data.withColumn(\"res\", udf(struct(\"b\", \"c\")))`",
        "createdAt" : "2021-04-12T16:02:55Z",
        "updatedAt" : "2021-04-16T21:45:38Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8189577ac80363f4953ad53cae37474090ecc58",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +137,141 @@        )\n        res = good_data.withColumn(\"res\", udf()).select(\"res\").toPandas()\n        assert res[\"res\"][0] == [\"a\", \"b\", \"c\"]\n\n        with pytest.raises("
  },
  {
    "id" : "1fbf5122-1315-4961-9540-38a6ca8e7fbd",
    "prId" : 4236,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/4236#pullrequestreview-633708574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30de3e03-4395-4d41-a69c-b3e405fbed43",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Can we add a test case for what happens if the model has no signature and user calls it with empty argument list?",
        "createdAt" : "2021-04-12T16:03:40Z",
        "updatedAt" : "2021-04-16T21:45:38Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8189577ac80363f4953ad53cae37474090ecc58",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +153,157 @@        with pytest.raises(AnalysisException, match=r\"cannot resolve '`a`' given input columns\"):\n            bad_data.withColumn(\"res\", udf())\n\n    nameless_signature = ModelSignature(\n        inputs=Schema([ColSpec(\"long\"), ColSpec(\"long\"), ColSpec(\"long\")]),"
  },
  {
    "id" : "afc0375e-7249-4954-8ae6-6acc0bfa05c6",
    "prId" : 2743,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/2743#pullrequestreview-402940375",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c46b530-fa4e-4549-a1f4-035eb8940f17",
        "parentId" : null,
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Can you clarify why is this needed in a comment?",
        "createdAt" : "2020-04-24T18:32:40Z",
        "updatedAt" : "2020-04-29T11:41:08Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      },
      {
        "id" : "5d0020db-b370-49dd-b52e-305b40fc96d0",
        "parentId" : "9c46b530-fa4e-4549-a1f4-035eb8940f17",
        "authorId" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "body" : "Awesome, thanks!",
        "createdAt" : "2020-04-29T18:43:26Z",
        "updatedAt" : "2020-04-29T18:43:27Z",
        "lastEditedBy" : "d79ebb0f-0833-4329-8a37-7ae540003587",
        "tags" : [
        ]
      }
    ],
    "commit" : "4573a80e54e04d9d9cca53ce261676a9a520ee29",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +55,59 @@    # https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html# \\\n    # compatibiliy-setting-for-pyarrow--0150-and-spark-23x-24x\n    os.environ[\"ARROW_PRE_0_15_IPC_FORMAT\"] = \"1\"\n    conf.set(key=\"spark_session.python.worker.reuse\", value=True)\n    return pyspark.sql.SparkSession.builder\\"
  },
  {
    "id" : "5fdc4d7e-5845-4586-9183-4a601c51944a",
    "prId" : 1075,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1075#pullrequestreview-222436206",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1fc5669b-9ca6-4fa7-9bb0-7cee32ac431e",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Ah good catch - I'm realizing that we intentionally decided to run tests for different model frameworks in different `pytest` invocations in https://github.com/mlflow/mlflow/pull/325/files (IIRC because the memory overhead from importing multiple different model frameworks in the same process could cause Travis tests to OOM). I was going to suggest that we start/stop SparkSessions in each test that uses them, but it seems starting multiple SparkSessions within the same Python process is not well-supported ([link](https://stackoverflow.com/questions/41491972/how-can-i-tear-down-a-sparksession-and-create-a-new-one-within-one-application)).\r\n\r\nThus maybe the right course of action here is to update our contributor guide (in CONTRIBUTING.rst) with test steps that more closely reflect our .travis.yml, as opposed to installing unused mleap dependencies in test_spark.py. I'll file a separate GitHub issue for updating CONTRIBUTING.rst - in this PR I'd suggest we remove changes to test_spark.py",
        "createdAt" : "2019-04-03T21:05:02Z",
        "updatedAt" : "2019-04-03T21:50:45Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "1547bca963106c92406ad78b4a93689914102650",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +23,27 @@\ndef score_model_as_udf(model_path, run_id, pandas_df, result_type=\"double\"):\n    spark = pyspark.sql.SparkSession.builder\\\n        .config(key=\"spark.python.worker.reuse\", value=True)\\\n        .master(\"local-cluster[2, 1, 1024]\")\\"
  },
  {
    "id" : "9a3f90f6-7456-4b3d-8ad2-139f527f2fc0",
    "prId" : 793,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/793#pullrequestreview-192315333",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb317ce5-517b-46e0-bbcc-71c8ba33f852",
        "parentId" : null,
        "authorId" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "body" : "Maybe comment at the top of this test that we plan to save the model in two different ways (although ideally these are two separate tests which just share code; if this test fails for one of the two branches, it may be challenging to figure out which one failed).",
        "createdAt" : "2019-01-14T17:11:47Z",
        "updatedAt" : "2019-01-15T06:30:57Z",
        "lastEditedBy" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "tags" : [
        ]
      },
      {
        "id" : "35d30eb3-6297-47fc-a2d6-7f82234320fa",
        "parentId" : "cb317ce5-517b-46e0-bbcc-71c8ba33f852",
        "authorId" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "body" : "I also don't love that you felt the need to add an integration test here; ideally, the contract and architecture of pyfunc save_model should ensure that it's not possible that one works and the other doesn't. This might be an argument for implementing save_model with loader_module in terms of PythonModel.",
        "createdAt" : "2019-01-14T17:13:03Z",
        "updatedAt" : "2019-01-15T06:30:57Z",
        "lastEditedBy" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "tags" : [
        ]
      },
      {
        "id" : "f8f45088-4bad-4026-a8df-795bee259946",
        "parentId" : "cb317ce5-517b-46e0-bbcc-71c8ba33f852",
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "I've removed the additional test case for `PythonModel`. I had originally refactored `test_spark_udf` to only use the `PythonModel` case because I had planned to remove support for the `loader_module` case. When I introduced a backwards-compatible solution for `loader_module`, it seemed reasonable to merge in the old `test_spark_udf` logic as well. However, based on your comment regarding the contract of pyfunc `save_model`, this is unnecessary.",
        "createdAt" : "2019-01-14T22:42:00Z",
        "updatedAt" : "2019-01-15T06:30:57Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "be18a22a370ffaacab75b44cff15223c5f180d0c",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +68,72 @@@pytest.mark.large\ndef test_spark_udf(spark, model_path):\n    mlflow.pyfunc.save_model(\n        dst_path=model_path,\n        loader_module=__name__,"
  },
  {
    "id" : "5d764bf7-f97e-463b-a42c-ccc6702068ae",
    "prId" : 719,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/719#pullrequestreview-183439002",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "961a5ce1-9fcb-4864-aee4-5fe52c183852",
        "parentId" : null,
        "authorId" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "body" : "Can we add `float` and `int` here too?",
        "createdAt" : "2018-12-10T23:28:18Z",
        "updatedAt" : "2018-12-19T22:33:20Z",
        "lastEditedBy" : "3f60ced2-d2f0-4cc5-9898-5aefe16e0be8",
        "tags" : [
        ]
      }
    ],
    "commit" : "46d40cc23382cf8a24feb872cdaa8a9b500b579b",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +77,81 @@                    \"int\": (IntegerType(), np.int32),\n                    \"double\": (DoubleType(), np.number),\n                    \"long\": (LongType(), np.int),\n                    \"string\": (StringType(), None)}\n"
  }
]