[
  {
    "id" : "3e80cdf3-29e1-4caa-8554-636c6acc06bc",
    "prId" : 3881,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3881#pullrequestreview-657412065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d1167b7d-3f23-494a-bf80-2ceb916e6c58",
        "parentId" : null,
        "authorId" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "body" : "@smurching @wamartin-aml \r\n\r\nI found that this test fails when using a file store backend.\r\n\r\n### Code to reproduce:\r\n\r\n```suggestion\r\n@pytest.mark.notrackingurimock\r\ndef test_list_experiments_paginated_returns_in_correct_order(tmpdir):\r\n    mlflow.set_tracking_uri(tmpdir.strpath)\r\n```\r\n\r\n### pytest error logs:\r\n\r\n```\r\n% pytest tests/tracking/test_tracking.py -k test_list_experiments_paginated_returns_in_correct_order\r\n===================================================================== test session starts ======================================================================\r\nplatform darwin -- Python 3.7.9, pytest-3.2.1, py-1.10.0, pluggy-0.4.0\r\nrootdir: /Users/harutakakawamura/Desktop/repositories/mlflow, inifile: pytest.ini\r\nplugins: typeguard-2.12.0, localserver-0.5.0, cov-2.6.0\r\ncollected 120 items                                                                                                                                             \r\n\r\ntests/tracking/test_tracking.py F\r\n\r\n=================================================================== slowest 5 test durations ===================================================================\r\n0.18s call     tests/tracking/test_tracking.py::test_list_experiments_paginated_returns_in_correct_order\r\n0.00s setup    tests/tracking/test_tracking.py::test_list_experiments_paginated_returns_in_correct_order\r\n0.00s teardown tests/tracking/test_tracking.py::test_list_experiments_paginated_returns_in_correct_order\r\n=========================================================================== FAILURES ===========================================================================\r\n___________________________________________________ test_list_experiments_paginated_returns_in_correct_order ___________________________________________________\r\n\r\ntmpdir = local('/private/var/folders/33/kkm875tn7cxb89b8mmcykrx00000gn/T/pytest-of-harutakakawamura/pytest-36/test_list_experiments_paginate0')\r\n\r\n    @pytest.mark.notrackingurimock\r\n    def test_list_experiments_paginated_returns_in_correct_order(tmpdir):\r\n    \r\n        mlflow.set_tracking_uri(tmpdir.strpath)\r\n        testnames = []\r\n        for i in range(20):\r\n            name = \"paginated_exp_order_\" + str(i)\r\n            mlflow.create_experiment(name)\r\n            testnames.append(name)\r\n    \r\n        client = tracking.MlflowClient()\r\n        # test that pagination will return all valid results in sorted order\r\n        # by name ascending\r\n        result = client.list_experiments(max_results=3, page_token=None)\r\n        assert result.token is not None\r\n>       assert [exp.name for exp in result[1:]] == testnames[0:2]\r\nE       AssertionError: assert ['paginated_e..._exp_order_0'] == ['paginated_ex..._exp_order_1']\r\nE         At index 0 diff: 'paginated_exp_order_9' != 'paginated_exp_order_0'\r\nE         Use -v to get the full diff\r\n\r\nclient     = <mlflow.tracking.client.MlflowClient object at 0x7f8a907b59d0>\r\ni          = 19\r\nname       = 'paginated_exp_order_19'\r\nresult     = [<Experiment: artifact_location='/private/var/folders/33/kkm875tn7cxb89b8mmcykrx00000gn/T/pytest-of-harutakakawamura/p...est_list_experiments_paginate0/0', experiment_id='0', lifecycle_stage='active', name='paginated_exp_order_0', tags={}>]\r\ntestnames  = ['paginated_exp_order_0', 'paginated_exp_order_1', 'paginated_exp_order_2', 'paginated_exp_order_3', 'paginated_exp_order_4', 'paginated_exp_order_5', ...]\r\ntmpdir     = local('/private/var/folders/33/kkm875tn7cxb89b8mmcykrx00000gn/T/pytest-of-harutakakawamura/pytest-36/test_list_experiments_paginate0')\r\n\r\ntests/tracking/test_tracking.py:171: AssertionError\r\n===================================================================== 119 tests deselected =====================================================================\r\n=========================================================== 1 failed, 119 deselected in 0.38 seconds ===========================================================```\r\n```\r\n\r\nIs this what we intend?",
        "createdAt" : "2021-05-12T02:29:18Z",
        "updatedAt" : "2021-05-12T02:32:14Z",
        "lastEditedBy" : "0e487e6e-a7e7-4430-a4d6-ca9e76a34cba",
        "tags" : [
        ]
      }
    ],
    "commit" : "6cc91e43665ef8cbbc0134124d1b4db4f75958fe",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +154,158 @@\n\ndef test_list_experiments_paginated_returns_in_correct_order():\n    testnames = []\n    for i in range(20):"
  },
  {
    "id" : "07f7cda2-b7a6-4048-864d-e10713f69e1f",
    "prId" : 3728,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3728#pullrequestreview-538906426",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18261dc8-4feb-4f80-b461-74af4cba2056",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Could we also add tests for some of the `if` branches in the `log_image` implementation, to ensure we have thorough [branch coverage](https://en.wikipedia.org/wiki/Code_coverage#Basic_coverage_criteria)? For example, can we add a test for the clipping behavior for ints vs non-ints?",
        "createdAt" : "2020-11-25T23:38:46Z",
        "updatedAt" : "2020-11-26T06:55:52Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "669516eb-e3b9-4553-ab7f-2f0152384f61",
        "parentId" : "18261dc8-4feb-4f80-b461-74af4cba2056",
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Actually, I think ^the other branches are covered pretty well, besides the clipping behavior",
        "createdAt" : "2020-11-25T23:39:18Z",
        "updatedAt" : "2020-11-26T06:55:52Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc6a1107cef493dfda6a258ad9d7a0c32325b8b0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +592,596 @@\n@pytest.mark.large\n@pytest.mark.parametrize(\"subdir\", [None, \".\", \"dir\", \"dir1/dir2\", \"dir/..\"])\ndef test_log_image_numpy(subdir):\n    import numpy as np"
  },
  {
    "id" : "94d5af9a-5098-4d9c-9291-20c428317b86",
    "prId" : 3728,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/3728#pullrequestreview-538906821",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "699fc645-ef1f-43cd-85ab-d6bb566efb6d",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Could we also enhance this test and `test_log_image_numpy_shape` to load back the image and verify that the contents match the original? I wonder if Pillow makes it easy to load the image back and compare to the original etc",
        "createdAt" : "2020-11-25T23:40:52Z",
        "updatedAt" : "2020-11-26T06:55:52Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc6a1107cef493dfda6a258ad9d7a0c32325b8b0",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +608,612 @@        artifact_uri = mlflow.get_artifact_uri(artifact_path)\n        run_artifact_dir = local_file_uri_to_path(artifact_uri)\n        assert os.listdir(run_artifact_dir) == [filename]\n\n        logged_path = os.path.join(run_artifact_dir, filename)"
  },
  {
    "id" : "4b95d352-6e5f-4c7b-ba65-ea09306c7934",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-228851977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff0114ed-f575-499d-9c13-9cbd4c97ace5",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "I made a number of changes like this that try to wrap the return value of `start_run` in a with block immediately. Otherwise, if intermediate logic between the `start_run` and `with` block throws, almost every other test in this suite fails because the run created by `start_run` is never terminated & MLflow complains that that run is already active. This was sufficiently annoying while debugging that I made the change in this PR, but I could defer it.",
        "createdAt" : "2019-04-19T23:30:31Z",
        "updatedAt" : "2019-04-22T20:33:06Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +118,122 @@\ndef test_start_run_context_manager(tracking_uri_mock):\n    with start_run() as first_run:\n        first_uuid = first_run.info.run_uuid\n        # Check that start_run() causes the run information to be persisted in the store"
  },
  {
    "id" : "b90acc13-5d5b-4dc7-b72d-9bdea54cf72a",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-228853713",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e45e6e0a-2833-433a-9eb9-b40f35f6e117",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "This is an actual test code change - here we validate that step is correctly set by `MlflowClient.log_batch`",
        "createdAt" : "2019-04-19T23:46:29Z",
        "updatedAt" : "2019-04-22T20:33:06Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +170,174 @@    for key, value in finished_run.data.metrics.items():\n        assert expected_metrics[key] == value\n    # TODO: use client get_metric_history API here instead once it exists\n    fs = FileStore(os.path.join(tmpdir.strpath, \"mlruns\"))\n    metric_history0 = fs.get_metric_history(run_uuid, \"metric-key0\")"
  },
  {
    "id" : "590bac77-8853-4aa7-ac4c-05e21ec7cd96",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-228853753",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19fdd0c8-22db-43d5-9da6-5af86ffab6d8",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Actual test code change: validate that step is set correctly by `log_metric`",
        "createdAt" : "2019-04-19T23:46:55Z",
        "updatedAt" : "2019-04-22T20:33:06Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 135,
    "diffHunk" : "@@ -1,1 +207,211 @@    for key, value in finished_run.data.metrics.items():\n        assert expected_pairs[key] == value\n    # TODO: use client get_metric_history API here instead once it exists\n    fs = FileStore(os.path.join(tmpdir.strpath, \"mlruns\"))\n    metric_history_name1 = fs.get_metric_history(run_uuid, \"name_1\")"
  },
  {
    "id" : "42325d7b-f986-4e66-9612-aa4740f5ebf9",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-228855142",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f95a1433-f141-4a8c-9eaf-f6dd8c45a1a6",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Actual test code change: validate that step is set correctly by `log_metrics` (plural)\r\n\r\n",
        "createdAt" : "2019-04-20T00:00:53Z",
        "updatedAt" : "2019-04-22T20:33:06Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 150,
    "diffHunk" : "@@ -1,1 +222,226 @@\n@pytest.mark.parametrize(\"step_kwarg\", [None, -10, 5])\ndef test_log_metrics(tracking_uri_mock, step_kwarg):\n    expected_metrics = {\"name_1\": 30, \"name_2\": -3, \"nested/nested/name\": 40}\n    with start_run() as active_run:"
  },
  {
    "id" : "628d4e04-d311-4949-a81b-ae3d105f5bf1",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-228855189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc41166b-9ae3-4ad3-a48c-9b4a3c6d5573",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Note: all changes from here onwards are refactoring related to wrapping the return value of `start_run` in a `with` block",
        "createdAt" : "2019-04-20T00:01:18Z",
        "updatedAt" : "2019-04-22T20:33:06Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +248,252 @@    exact_expected_tags = {\"name_1\": \"c\", \"name_2\": \"b\", \"nested/nested/name\": \"5\"}\n    approx_expected_tags = set([MLFLOW_SOURCE_NAME, MLFLOW_SOURCE_TYPE])\n    with start_run() as active_run:\n        run_uuid = active_run.info.run_uuid\n        mlflow.set_tags(exact_expected_tags)"
  },
  {
    "id" : "133004e2-ad0d-4b47-83b7-99fddf16a853",
    "prId" : 1143,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/1143#pullrequestreview-229239478",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "924b9b66-246f-464f-b6df-aa7bff0556c5",
        "parentId" : null,
        "authorId" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "body" : "Are we tracking making this change?",
        "createdAt" : "2019-04-22T20:42:04Z",
        "updatedAt" : "2019-04-22T20:42:04Z",
        "lastEditedBy" : "6e958077-8d60-494d-8079-e77af3a2951f",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e35d0446aaade7f0c739b015aaa3bb9c13c807c",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +170,174 @@    for key, value in finished_run.data.metrics.items():\n        assert expected_metrics[key] == value\n    # TODO: use client get_metric_history API here instead once it exists\n    fs = FileStore(os.path.join(tmpdir.strpath, \"mlruns\"))\n    metric_history0 = fs.get_metric_history(run_uuid, \"metric-key0\")"
  },
  {
    "id" : "c7c0d9c3-5ab1-41aa-a210-3747571e024f",
    "prId" : 547,
    "prUrl" : "https://github.com/mlflow/mlflow/pull/547#pullrequestreview-158795169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b6b0853-f5d2-4c80-a252-091f4671b2b1",
        "parentId" : null,
        "authorId" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "body" : "Nit: an existing test (`test_no_nested_run`) already verifies this - maybe we can just delete `test_no_nested_run`",
        "createdAt" : "2018-09-25T05:39:22Z",
        "updatedAt" : "2018-09-26T00:47:32Z",
        "lastEditedBy" : "bd3067fd-855b-4bd1-898d-ca29199fd092",
        "tags" : [
        ]
      },
      {
        "id" : "09d16210-3c28-4e01-a8e2-ece65eff0a6b",
        "parentId" : "1b6b0853-f5d2-4c80-a252-091f4671b2b1",
        "authorId" : "91d7919c-02c4-40e4-8f30-7f297efebb01",
        "body" : "also nice, will remove `test_no_nested_run`.",
        "createdAt" : "2018-09-26T00:30:49Z",
        "updatedAt" : "2018-09-26T00:47:32Z",
        "lastEditedBy" : "91d7919c-02c4-40e4-8f30-7f297efebb01",
        "tags" : [
        ]
      }
    ],
    "commit" : "137cc9d284e3fbc8aa37082fe4ba04ab357a0a32",
    "line" : 334,
    "diffHunk" : "@@ -1,1 +209,213 @@def test_parent_create_run(tracking_uri_mock):\n    parent_run = mlflow.start_run()\n    with pytest.raises(Exception, match='To start a nested run'):\n        mlflow.start_run()\n    child_run = mlflow.start_run(nested=True)"
  }
]