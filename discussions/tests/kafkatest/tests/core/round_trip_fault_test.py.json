[
  {
    "id" : "9e1f64ba-8aa8-4800-8a19-0ff492666fd3",
    "prId" : 6912,
    "prUrl" : "https://github.com/apache/kafka/pull/6912#pullrequestreview-248769842",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b6c982d5-647b-48ad-8f54-f9e6aa46eeb1",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "the sleep shouldn't be needed here, right?",
        "createdAt" : "2019-06-11T18:29:35Z",
        "updatedAt" : "2019-06-21T12:12:50Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "1e62e941-78ad-446f-a81f-696750237ec7",
        "parentId" : "b6c982d5-647b-48ad-8f54-f9e6aa46eeb1",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Not sure -- it copied from the above tests. Maybe this was added to reduce flakiness in the task getting creating?",
        "createdAt" : "2019-06-11T19:41:22Z",
        "updatedAt" : "2019-06-21T12:12:50Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      },
      {
        "id" : "4315293d-b137-4686-a8c8-e0d5c0a17d9a",
        "parentId" : "b6c982d5-647b-48ad-8f54-f9e6aa46eeb1",
        "authorId" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "body" : "Indeed, without this sleep the test only passes about half the time.",
        "createdAt" : "2019-06-12T13:44:37Z",
        "updatedAt" : "2019-06-21T12:12:50Z",
        "lastEditedBy" : "083f2f03-ca7e-48a1-9781-482564dfdf53",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1e856baf4397906a3a0c2872c7bfc79410d9202",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +97,101 @@    def test_produce_consume_with_latency(self):\n        workload1 = self.trogdor.create_task(\"workload1\", self.round_trip_spec)\n        time.sleep(2)\n        node_specs = {}\n        for node in self.kafka.nodes + self.zk.nodes:"
  },
  {
    "id" : "26e154b0-6296-4df0-ae2f-d41e18905a76",
    "prId" : 7446,
    "prUrl" : "https://github.com/apache/kafka/pull/7446#pullrequestreview-316378240",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9398b0f7-754c-400f-b1df-ee4169fcdf41",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "nit: could we name the arguments?",
        "createdAt" : "2019-11-13T16:30:21Z",
        "updatedAt" : "2019-11-15T23:49:38Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "78784514585ed6b9787e115d58870aa7d9db5af8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +98,102 @@        workload1 = self.trogdor.create_task(\"workload1\", self.round_trip_spec)\n        time.sleep(2)\n        spec = DegradedNetworkFaultSpec(0, 60000)\n        for node in self.kafka.nodes + self.zk.nodes:\n            spec.add_node_spec(node.name, \"eth0\", latencyMs=100, rateLimitKbit=3000)"
  },
  {
    "id" : "ed13ac6f-81ac-483a-bcaf-311b0ab70e74",
    "prId" : 10105,
    "prUrl" : "https://github.com/apache/kafka/pull/10105#pullrequestreview-595757987",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c284cfc9-d6e5-4ad3-bb2c-eff6714f647c",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "should this throw an exception? Or does the current code actually work for this case?",
        "createdAt" : "2021-02-22T18:28:20Z",
        "updatedAt" : "2021-02-22T20:39:12Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "329995d9-b251-4af2-bf81-575293cbc77c",
        "parentId" : "c284cfc9-d6e5-4ad3-bb2c-eff6714f647c",
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "> throw an exception or does the current code actually work for this case?\r\n\r\nThe code always needs `<Kafka nodes>` + `<remote quorum nodes>`, where the latter are the ZooKeeper or remote Controller Quorum nodes.  If we were to run this test with co-located Raft Quorum controllers then those nodes would be accounted for because they are part of the Kafka nodes, so there is no need to explicitly add them.  So this code is correct in that it return an empty list for that case.  As was indicated in the comment, it's here just in case we ever decide we want to test it.",
        "createdAt" : "2021-02-22T19:32:17Z",
        "updatedAt" : "2021-02-22T20:39:12Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      },
      {
        "id" : "449c8e77-e368-4c36-ad08-4b9efb9baa9e",
        "parentId" : "c284cfc9-d6e5-4ad3-bb2c-eff6714f647c",
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "sounds good",
        "createdAt" : "2021-02-22T20:34:30Z",
        "updatedAt" : "2021-02-22T20:39:12Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e8646110001e4353014cd6946d2fab92acffff6",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +73,77 @@            return self.kafka.controller_quorum.nodes\n        else: # co-located case, which we currently don't test but handle here for completeness in case we do test it\n            return []\n\n    @cluster(num_nodes=9)"
  }
]