[
  {
    "id" : "27d3e707-c93c-47a4-928f-54720dc5edad",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-313755927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3573e84b-a05f-46ea-b9f9-6ee003736323",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Trying something new here... Rather than defining the service for this test in a separate file together with a bunch of unrelated services for other tests, I'm proposing to define it right here in the same file as the test itself. That way, you can see all the relevant logic for this one test in one place.\r\n\r\nThe only bummer I found was that the log4j config template is required to be at a specific relative path to the service class, so I had to copy it over (it's part of this PR as well). Of course, if we like this pattern, and want to migrate other tests to it, then the template will already be in place.",
        "createdAt" : "2019-11-08T03:44:32Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +22,26 @@\n\nclass StreamsRelationalSmokeTestService(StreamsTestBaseService):\n    def __init__(self, test_context, kafka, mode, nodeId):\n        super(StreamsRelationalSmokeTestService, self).__init__("
  },
  {
    "id" : "9d95d8b2-d865-46ee-88de-3d514e4c2efc",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-321300278",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00df4f4b-a4c7-42cd-9829-2c02632eda33",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "One thing to note is the avoidance of log_monitor, which doesn't work the way that it seems like we thought it works. Instead, we're structuring our ssh/grep commands to make the minimum ordering assumptions and be correct by looking for unique events.",
        "createdAt" : "2019-11-08T04:55:36Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "4b5f096a-7568-4bcd-9aaa-3c5af6b4e8e8",
        "parentId" : "00df4f4b-a4c7-42cd-9829-2c02632eda33",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could you elaborate a bit more about `log_monitor` why it does not work as expected?",
        "createdAt" : "2019-11-08T22:29:26Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a6cfde2f-630f-4991-877a-108b92c918a0",
        "parentId" : "00df4f4b-a4c7-42cd-9829-2c02632eda33",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The log monitor looks up the current rail position of the file just once when you create it. Subsequently, each grep invocation uses the exact same starting point in the file. \r\n\r\nI’ve noticed that some of our tests seem to assume that the monitor maintains a cursor in the file, but it does not. \r\n\r\nThe one nice thing about the monitor is that within it, you’re guaranteed not to see any log messages from before the time you created it, but in practice there are still too many opportunities to miss something or make an incorrect assumption in the test. \r\n\r\nI think a more robust approach is to just expect to search the entire log each time and figure out how to phrase the query as an invariant. ",
        "createdAt" : "2019-11-22T02:08:35Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +84,88 @@    @cluster(num_nodes=8)\n    @matrix(crash=[False, True])\n    def test_streams(self, crash):\n        driver = StreamsRelationalSmokeTestService(self.test_context, self.kafka, \"driver\", \"ignored\")\n"
  },
  {
    "id" : "80153454-cf37-4b64-937f-276db662bbef",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-328540758",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1d8eaaf-d827-482c-99b3-ee8cebbaa0f7",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Should we close processor3 at the end?",
        "createdAt" : "2019-11-08T22:32:52Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f2b04ba0-192b-4f75-821c-21cfc55cfc20",
        "parentId" : "a1d8eaaf-d827-482c-99b3-ee8cebbaa0f7",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Yes. Good call.",
        "createdAt" : "2019-12-07T05:44:42Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +121,125 @@        driver.node.account.ssh(\"grep 'Smoke test complete: passed' %s\" % driver.LOG_FILE, allow_fail=False)\n\n        driver.stop()\n\n        # the test is over, and the node is going to be cleaned, so there's no need to wait for a clean shutdown."
  },
  {
    "id" : "4470e6a6-4462-4cb2-9cee-97d88d312339",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-329259668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7448c8fd-832a-41a8-bf64-ec149f5852fc",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In other tests we start all three processors, and the rolling bounce them; here we start 2, shutdown 1, and start a new one, and shutdown another. Is it intentional and what's the motivation?",
        "createdAt" : "2019-11-08T22:35:46Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "44307aed-1d03-422d-a4b6-8549029d145a",
        "parentId" : "7448c8fd-832a-41a8-bf64-ec149f5852fc",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I wanted to make sure that the computation survives state shuffling as a result of processor 3 having to recover all of processor 1's state, and then subsequently all of processor 2's state.\r\n\r\nConversely, if we just do a rolling bounce, then instances would still be able to make use of the state from before.\r\n\r\nDo you think this makes sense, or is it just fuzzy thinking on my part?",
        "createdAt" : "2019-12-07T05:48:56Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2316e6dd-c3b1-4e0f-a92e-ed29003701ed",
        "parentId" : "7448c8fd-832a-41a8-bf64-ec149f5852fc",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Okay I think this makes sense, let's just follow this pattern then.",
        "createdAt" : "2019-12-09T21:38:20Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +105,109 @@        processor1.stop_nodes(not crash)\n\n        processor3 = StreamsRelationalSmokeTestService(self.test_context, self.kafka, \"application\", \"processor3\")\n        processor3.start()\n        processor3.await_command(\"grep -q 'Streams has started' %s\" % LOG_FILE)"
  }
]