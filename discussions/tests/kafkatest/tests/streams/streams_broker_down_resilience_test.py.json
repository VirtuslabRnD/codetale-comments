[
  {
    "id" : "6c4e63a7-db17-4c04-a25d-91cc4ef376d4",
    "prId" : 4513,
    "prUrl" : "https://github.com/apache/kafka/pull/4513#pullrequestreview-94156242",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58becf51-5027-464b-8a0f-107042debbc9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`processor_3.stop()` missing?\r\n",
        "createdAt" : "2018-02-02T21:00:41Z",
        "updatedAt" : "2018-02-07T15:50:05Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9be21a08-03ad-482f-bf66-8475975db921",
        "parentId" : "58becf51-5027-464b-8a0f-107042debbc9",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "For this test, we want to stop the broker, kill 2 streams nodes, then start the broker back up and ensure remaining streams nodes still function properly.  So we actually want to leave `processor_3` up.  Sorry, my test description is lacking.",
        "createdAt" : "2018-02-05T21:42:54Z",
        "updatedAt" : "2018-02-07T15:50:05Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "f9a4215c-06d8-4b8d-ac8b-ceb15c75ec99",
        "parentId" : "58becf51-5027-464b-8a0f-107042debbc9",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "maybe rename `test_streams_should_scale_in_while_brokers_down` ?",
        "createdAt" : "2018-02-05T21:53:02Z",
        "updatedAt" : "2018-02-07T15:50:05Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0390346035e44f40d413e78cd08f1781c8e2bd46",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +197,201 @@\n        processor.stop()\n        processor_2.stop()\n\n        shutdown_message = \"Complete shutdown of streams resilience test app now\""
  },
  {
    "id" : "5704910f-1913-4b23-ad95-cf8e53e8d1d2",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185657447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b382504-32a6-4d51-bf57-5a2a45394903",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "This was one source of flakiness as before starting kafka and the subsequent discovery of group coordinator could happen before we can grab `monitor` and inspect log file. This is done throughout the test, but I'll only comment here.",
        "createdAt" : "2018-12-17T15:51:57Z",
        "updatedAt" : "2018-12-17T16:05:25Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +62,66 @@        time.sleep(broker_down_time_in_seconds)\n\n        with processor.node.account.monitor_log(processor.LOG_FILE) as monitor:\n            self.kafka.start_node(node)\n            monitor.wait_until(self.connected_message,"
  },
  {
    "id" : "af5bf539-46b4-497b-92d5-d75423f9ca9b",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185657447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44038930-2304-49b4-9f4d-af184dc75b80",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Grab `monitor` for each respective streams client before starting kafka",
        "createdAt" : "2018-12-17T15:54:41Z",
        "updatedAt" : "2018-12-17T16:05:45Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +100,104 @@        self.wait_for_verification(processor_3, broker_unavailable_message, processor_3.LOG_FILE, 10)\n\n        with processor.node.account.monitor_log(processor.LOG_FILE) as monitor_1:\n            with processor_2.node.account.monitor_log(processor_2.LOG_FILE) as monitor_2:\n                with processor_3.node.account.monitor_log(processor_3.LOG_FILE) as monitor_3:"
  },
  {
    "id" : "9a11d2d7-498c-4702-be2e-bf3ec2d71da5",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185657447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1f0b267-10f8-479c-b41c-720db1f30382",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Similar process here,  grab `monitor` before producing any messages",
        "createdAt" : "2018-12-17T15:59:09Z",
        "updatedAt" : "2018-12-17T16:06:11Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +115,119 @@                                         err_msg=(\"Never saw '%s' on \" % self.connected_message) + str(processor_3.node.account))\n\n        with processor.node.account.monitor_log(processor.STDOUT_FILE) as monitor_1:\n            with processor_2.node.account.monitor_log(processor_2.STDOUT_FILE) as monitor_2:\n                with processor_3.node.account.monitor_log(processor_3.STDOUT_FILE) as monitor_3:"
  },
  {
    "id" : "c0dfd6b3-b5dc-4a7b-bb5d-3f526835770e",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185657447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5db3b98e-fc51-4578-ac85-86ba228fa675",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "break assertion of production to streams app and consuming from topic written to by streams into separate parts. I've done this in other parts of the test, but I won't comment on each section.",
        "createdAt" : "2018-12-17T16:00:41Z",
        "updatedAt" : "2018-12-17T16:03:18Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +119,123 @@                with processor_3.node.account.monitor_log(processor_3.STDOUT_FILE) as monitor_3:\n\n                    self.assert_produce(self.inputTopic,\n                                        \"sending_message_after_broker_down_initially\",\n                                        num_messages=self.num_messages,"
  },
  {
    "id" : "e9df47d1-c15b-4285-ba36-166990944412",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185657447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0263898-367e-4ebf-93c7-ba38cc3df665",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "confirm each streams client is processing messages. Same as above, I've done this in other sections but I'll only call it out here.",
        "createdAt" : "2018-12-17T16:02:42Z",
        "updatedAt" : "2018-12-17T16:03:18Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +124,128 @@                                        timeout_sec=120)\n\n                    monitor_1.wait_until(self.message,\n                                         timeout_sec=120,\n                                         err_msg=(\"Never saw '%s' on \" % self.message) + str(processor.node.account))"
  },
  {
    "id" : "f456e0c4-2beb-469c-bac7-d9c2aa34e0a6",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185665631",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35c28d69-4098-49c3-8225-6dea1321ce21",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I'm not breaking the produce/consume assertion here as there is only one streams client in this test.",
        "createdAt" : "2018-12-17T16:04:50Z",
        "updatedAt" : "2018-12-17T16:04:51Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +51,55 @@        processor.start()\n\n        self.assert_produce_consume(self.inputTopic,\n                                    self.outputTopic,\n                                    self.client_id,"
  },
  {
    "id" : "ac38d13e-e767-4ca3-8675-3498c0a3f030",
    "prId" : 6041,
    "prUrl" : "https://github.com/apache/kafka/pull/6041#pullrequestreview-185841498",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c162314-c83a-4e09-8789-4ee06934d5e1",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why only monitor on processor_3 not the previous two?",
        "createdAt" : "2018-12-17T22:30:10Z",
        "updatedAt" : "2018-12-17T22:31:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "87fa2452-1550-4651-bb1a-44c367a9d429",
        "parentId" : "4c162314-c83a-4e09-8789-4ee06934d5e1",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Since processor 3 is the last streams client to join the group, once it has transitioned from `REBALANCE to RUNNING` the test is ready to proceed.",
        "createdAt" : "2018-12-17T23:06:04Z",
        "updatedAt" : "2018-12-17T23:06:04Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cd8aadbe12bbeaa540a70836c74b10968bf57e",
    "line" : 199,
    "diffHunk" : "@@ -1,1 +229,233 @@\n        # need to wait for rebalance once\n        rebalance = \"State transition from REBALANCING to RUNNING\"\n        with processor_3.node.account.monitor_log(processor_3.LOG_FILE) as monitor:\n            processor_3.start()"
  }
]