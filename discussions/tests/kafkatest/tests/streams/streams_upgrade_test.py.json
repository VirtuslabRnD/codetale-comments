[
  {
    "id" : "fece5076-6416-4450-94c8-b00e3a367cb1",
    "prId" : 4689,
    "prUrl" : "https://github.com/apache/kafka/pull/4689#pullrequestreview-103658728",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I think you can do the zookeeper start in the `setUp` method",
        "createdAt" : "2018-03-13T21:01:08Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "0d56ce4b-66a8-47eb-be34-ab7d0b832749",
        "parentId" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "hm. actually, there isn't a `setUp` method... Are you suggesting I make one?\r\n\r\nFWIW, I think it's actually fine like this. The test is linearly readable this way.",
        "createdAt" : "2018-03-13T23:30:14Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "7e3a761f-6a73-43f4-a536-39ca3a426b99",
        "parentId" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "There's a `setUp` method on the [Test](https://github.com/confluentinc/ducktape/blob/master/ducktape/tests/test.py#L98) class that we can override.  It's fine like it is, but most of the other tests do ZK start-up in the `setUp` method, so I was aiming for consistency.",
        "createdAt" : "2018-03-14T00:05:52Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "8c6c8a52-26d5-4ba8-8964-6b7d97af77d2",
        "parentId" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "aha, I gotcha. sure, I can do that.",
        "createdAt" : "2018-03-14T00:11:18Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "80f4e799-4b0a-47c0-ab00-37a9379cb2fc",
        "parentId" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "+1",
        "createdAt" : "2018-03-14T00:17:09Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f32e23ba-fa74-4559-9004-3209d16a12a4",
        "parentId" : "14f6126b-4147-407e-a012-0ff8b075b02b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, I'm glad that I know what you were talking about now. I actually think in this case, it's a little better as is, since we want to start the broker with different versions during the test.\r\n\r\nWe could still do it, but then we'd have to stop the broker and upgrade it and restart it during the test, or only start zk in startUp and start the broker during the tests... I think in this case, it's a more complicated control flow in the tests in exchange for diminishing returns.\r\n\r\nI can totally get it for tests that just need zk and kafka running and don't care about the version, but in this case, I think I like it better flat.",
        "createdAt" : "2018-03-14T00:21:32Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "31719e4426c9591c2fb2f640070c1c0709f2a737",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +93,97 @@            # Setup phase\n            self.zk = ZookeeperService(self.test_context, num_nodes=1)\n            self.zk.start()\n\n            # number of nodes needs to be >= 3 for the smoke test"
  },
  {
    "id" : "2f44116d-5745-4ee4-a947-5403db499124",
    "prId" : 4689,
    "prUrl" : "https://github.com/apache/kafka/pull/4689#pullrequestreview-103611152",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8a530fb-7e8d-41b4-9798-d5b1601a75aa",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "same as above",
        "createdAt" : "2018-03-13T21:01:41Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "31719e4426c9591c2fb2f640070c1c0709f2a737",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +135,139 @@            # Setup phase\n            self.zk = ZookeeperService(self.test_context, num_nodes=1)\n            self.zk.start()\n\n            # number of nodes needs to be >= 3 for the smoke test"
  },
  {
    "id" : "da168fbc-0671-427e-ba3d-e19dc4840bd9",
    "prId" : 4746,
    "prUrl" : "https://github.com/apache/kafka/pull/4746#pullrequestreview-105944367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf448dd5-38b2-414c-b322-7cb3c98d6180",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a meta comment: in newer versions we should consider parameterize it instead of writing a new function for each from / to version pair.",
        "createdAt" : "2018-03-21T21:50:26Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c6685a36-ee88-4c01-a8f0-06865472756f",
        "parentId" : "cf448dd5-38b2-414c-b322-7cb3c98d6180",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Agreed. I'll upgrade the code accordingly when porting the PR to other branches.",
        "createdAt" : "2018-03-21T23:27:57Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe469ed34fb4f0d1094a542e2b2dd7d27cedd2e2",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +77,81 @@        self.driver.stop()\n\n    def start_all_nodes_with_0100(self):\n        # start first with 0.10.0\n        self.prepare_for_0100(self.processor1)"
  },
  {
    "id" : "15e98bbe-e6fb-48ac-bf0c-560439e8fb33",
    "prId" : 4746,
    "prUrl" : "https://github.com/apache/kafka/pull/4746#pullrequestreview-106648066",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1a0444f-323e-4607-84b0-2ec60d55b949",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I might have missed it... did we verify that everything is using the new metadata version after the second bounce?",
        "createdAt" : "2018-03-23T15:56:14Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "129a1412-8172-4546-b415-83faedb8e704",
        "parentId" : "a1a0444f-323e-4607-84b0-2ec60d55b949",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Hmmm... Not really... Also not sure how to check this? Ideas? We could put additional DEBUG logs that print the version of the received `AssignmentInfo`. \\cc @bbejeck @guozhangwang  WDYT?\r\n\r\nWe only make sure that the instances did not crash and process data after second rolling bounce.",
        "createdAt" : "2018-03-23T17:09:21Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "79e8c31d-b7e7-43c1-9d95-6ae9eb82ea2d",
        "parentId" : "a1a0444f-323e-4607-84b0-2ec60d55b949",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think this check should better be covered in unit test or integration test, not system test.",
        "createdAt" : "2018-03-23T18:27:15Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "76c01d8c-b0f0-454c-ad53-243d097a3536",
        "parentId" : "a1a0444f-323e-4607-84b0-2ec60d55b949",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "It's covered in `StreamPartitionAssignorTest` -- seems we are good than.",
        "createdAt" : "2018-03-23T19:54:54Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "07921b5f-37a8-4cb8-98f2-103f7838828f",
        "parentId" : "a1a0444f-323e-4607-84b0-2ec60d55b949",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : ":+1: ",
        "createdAt" : "2018-03-23T21:03:26Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe469ed34fb4f0d1094a542e2b2dd7d27cedd2e2",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +75,79 @@                                   err_msg=\"Never saw output 'UPGRADE-TEST-CLIENT-CLOSED' on\" + str(node.account))\n\n        self.driver.stop()\n\n    def start_all_nodes_with_0100(self):"
  },
  {
    "id" : "29e246e2-69f9-49cc-95b5-8f4ebf4cca66",
    "prId" : 4746,
    "prUrl" : "https://github.com/apache/kafka/pull/4746#pullrequestreview-106572993",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ab117da-c3e9-45fb-ae81-b794db7a579e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "\"wait on rebalance\" was not part of the instructions in the doc. Is this a necessary step?\r\n\r\nI suppose it is the distinction between an offline upgrade and a rolling one...\r\n\r\nSupposing that is the intent, maybe a better phrasing would be \"stop processor and ensure the others continue making progress\".",
        "createdAt" : "2018-03-23T16:07:41Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "830fac61-26f8-4a78-ad9d-96ff4ea9de0d",
        "parentId" : "8ab117da-c3e9-45fb-ae81-b794db7a579e",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For users, it's not required. It's a system test thing, that allows us to \"track\" the progress -- if we bounce instances without waiting, we introduce a race condition in the test because we don't know how many rebalances might actually be triggered: it could be a single rebalance or two, depending how quickly the instance comes back online.",
        "createdAt" : "2018-03-23T17:15:00Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe469ed34fb4f0d1094a542e2b2dd7d27cedd2e2",
    "line" : 150,
    "diffHunk" : "@@ -1,1 +148,152 @@        second_other_node = second_other_processor.node\n\n        # stop processor and wait for rebalance of others\n        with first_other_node.account.monitor_log(first_other_processor.STDOUT_FILE) as first_other_monitor:\n            with second_other_node.account.monitor_log(second_other_processor.STDOUT_FILE) as second_other_monitor:"
  },
  {
    "id" : "2f0d03c7-d0b4-4f6d-9d9f-edd67e330b97",
    "prId" : 4758,
    "prUrl" : "https://github.com/apache/kafka/pull/4758#pullrequestreview-106649262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7568ea78-465d-4de2-801f-8da515ba3299",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For this upgrade, we do not need two rolling bounces with `upgrade.from` config I think?",
        "createdAt" : "2018-03-23T06:00:37Z",
        "updatedAt" : "2018-03-26T00:23:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "ca9ffbcc-8cef-4159-ac5c-a83a6cc90ece",
        "parentId" : "7568ea78-465d-4de2-801f-8da515ba3299",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes. The test does only do one rolling bounce. Not sure what you mean? Is the comment confusing? It does actually no say anything about the number of rolling bounces.",
        "createdAt" : "2018-03-23T07:05:36Z",
        "updatedAt" : "2018-03-26T00:23:29Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "58ab84a9-c6de-4db5-8315-5864d6c50e22",
        "parentId" : "7568ea78-465d-4de2-801f-8da515ba3299",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "My bad, I'd better leave this comment on line 57 below. I meant that we do not need to specify `0.10.0` for the upgrade.from parameter, but instead we should be able to just write\r\n\r\n```\r\nself.do_rolling_bounce(p, \"\", new_version, counter)\r\n```\r\n\r\nIs that right?",
        "createdAt" : "2018-03-23T16:26:34Z",
        "updatedAt" : "2018-03-26T00:23:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "fa9c0401-b461-4afd-a079-9250a6856cb6",
        "parentId" : "7568ea78-465d-4de2-801f-8da515ba3299",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Good catch!",
        "createdAt" : "2018-03-23T21:08:11Z",
        "updatedAt" : "2018-03-26T00:23:29Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cb064a5d0891c989ee8a725d115d21dbe82aed1",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +41,45 @@    def test_simple_upgrade(self):\n        \"\"\"\n        Starts 3 KafkaStreams instances with version 0.10.1, and upgrades one-by-one to 0.10.2\n        \"\"\"\n"
  },
  {
    "id" : "f4cacb32-903c-41f7-8202-cc887b0783fb",
    "prId" : 4768,
    "prUrl" : "https://github.com/apache/kafka/pull/4768#pullrequestreview-108683306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27d9df89-bdf0-4d69-8a3a-a049e1022383",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I did a double-take here... I think I get it now, but to check my understanding...\r\n\r\nThe plan is to wait until those patch releases, and then do something like :\r\n```\r\n@matrix(new_version=simple_upgrade_versions_metadata_version_2)\r\n```\r\n\r\nYou're effectively slicing 0.10.0 out from the upgrade/downgrade test matrix because:\r\n* upgrading from 0.10.0 requires a different algorithm (double bounce)\r\n* downgrading to 0.10.0 is not supported\r\n\r\nRight?",
        "createdAt" : "2018-04-02T14:40:43Z",
        "updatedAt" : "2018-04-02T14:42:09Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "b1ef78c6-cac9-4a60-85b1-3607aa4a5185",
        "parentId" : "27d9df89-bdf0-4d69-8a3a-a049e1022383",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes. Upgrading from 0.10.0 requires two rolling bounces including the new config `upgrade.from` and thus we have this extra test for it -- this new config is only available in un-release code (for older non-dev branches) and thus, we cannot run this test for those versions atm.\r\n\r\nWe chould add a downgrade test though -- but it would be a new test method, too, as it also requires two rolling bounces but with different order of command compare to this test. It would be something like:\r\n - prepare all instances to bounce and set config `upgrade.from=\"0.10.0\"`\r\n - do first round of rolling bounce -- in this rolling bounce you stay on current version and don't downgrade yet, but only prepare all instances for downgrading (via setting the config)\r\n - do a second round of rolling bounces downgrading to 0.10.0\r\n\r\nI think it's not worth to add a downgrade test.",
        "createdAt" : "2018-04-02T17:11:04Z",
        "updatedAt" : "2018-04-02T17:11:04Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d3442cbd-86a3-40e0-9d48-361888ec6b32",
        "parentId" : "27d9df89-bdf0-4d69-8a3a-a049e1022383",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Agreed. We have no evidence that downgrade is necessary. We don't need to document it or test it unless or until we actually choose to support it.",
        "createdAt" : "2018-04-02T17:45:56Z",
        "updatedAt" : "2018-04-02T17:45:56Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d3e925e7bdce704a3cedfb5f130ec114cfc441",
    "line" : 175,
    "diffHunk" : "@@ -1,1 +169,173 @@    #@parametrize(new_version=str(LATEST_0_10_2)) we cannot run this test until Kafka 0.10.2.2 is released\n    #@parametrize(new_version=str(LATEST_0_11_0)) we cannot run this test until Kafka 0.11.0.3 is released\n    @parametrize(new_version=str(DEV_VERSION))\n    def test_metadata_upgrade(self, new_version):\n        \"\"\""
  }
]