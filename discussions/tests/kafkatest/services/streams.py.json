[
  {
    "id" : "0d910e8b-a076-4a12-8af4-57c47c1084dd",
    "prId" : 4513,
    "prUrl" : "https://github.com/apache/kafka/pull/4513#pullrequestreview-94758026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "326e2fcd-9997-4285-a47d-881b4482789e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Where is this function used?",
        "createdAt" : "2018-02-07T00:45:26Z",
        "updatedAt" : "2018-02-07T15:50:05Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d8d3a6c3-ae7a-4ab7-bea3-428f2585d98f",
        "parentId" : "326e2fcd-9997-4285-a47d-881b4482789e",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "when calling `processor.start()`.  It overrides the `streams.py#start_cmd` which in turn overrides the [Service.start_cmd](http://ducktape-docs.readthedocs.io/en/latest/_modules/ducktape/services/service.html#Service.start) \r\n\r\nThis is needed due to one test starting with Kafka down.  The default implementation verifies Kafka is up, but we need to skip that for the `test_streams_runs_with_broker_down_initially`",
        "createdAt" : "2018-02-07T15:48:08Z",
        "updatedAt" : "2018-02-07T15:50:05Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0390346035e44f40d413e78cd08f1781c8e2bd46",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +217,221 @@                                                                 configs)\n\n    def start_cmd(self, node):\n        args = self.args.copy()\n        args['kafka'] = self.kafka.bootstrap_servers(validate=False)"
  },
  {
    "id" : "6aa5088a-3114-4bea-89a1-b950e62a21f0",
    "prId" : 4636,
    "prUrl" : "https://github.com/apache/kafka/pull/4636#pullrequestreview-123526358",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9cfdfb5e-582b-412c-89b2-159dfab97047",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "will the system test results still get errors when these files aren't found?",
        "createdAt" : "2018-05-25T21:30:29Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "a5eafb9b-7502-468c-8142-831dfc7f503c",
        "parentId" : "9cfdfb5e-582b-412c-89b2-159dfab97047",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes, we need to specify all used files here -- otherwise they won't be collected after the test finished.",
        "createdAt" : "2018-05-25T22:16:58Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a87bd5254155a9d60ba479371305ddaae99282d",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +54,58 @@            \"collect_default\": True},\n        \"streams_log.1\": {\n            \"path\": LOG_FILE + \".1\",\n            \"collect_default\": True},\n        \"streams_stdout.1\": {"
  },
  {
    "id" : "ba34f1b7-62f8-4177-b905-5cf79bc86f71",
    "prId" : 4689,
    "prUrl" : "https://github.com/apache/kafka/pull/4689#pullrequestreview-103171384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be7775ee-f390-4d5b-a19f-e825819da993",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "So, this wasn't valid python3... It's also the only `super` invocation in kafkatest that's formatted this way. I'm not sure if it's valid python2.\r\n\r\nBut it only affects cleanup for the Eos test, and it just generates a warning instead of failing the test. So I can see how this could go unnoticed if the tests are usually run from a clean state instead of cleaning up after themselves.",
        "createdAt" : "2018-03-12T18:41:24Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "31719e4426c9591c2fb2f640070c1c0709f2a737",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +165,169 @@    def clean_node(self, node):\n        if self.clean_node_enabled:\n            super(StreamsEosTestBaseService, self).clean_node(node)\n\n"
  },
  {
    "id" : "257c8dbb-e083-4cbb-9dec-bbe04f6150de",
    "prId" : 4689,
    "prUrl" : "https://github.com/apache/kafka/pull/4689#pullrequestreview-103655784",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6301adca-1f36-4c97-bc4e-9796dd524611",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I got a lot of value out of having this in the output. What do you think about leaving this in?",
        "createdAt" : "2018-03-13T18:49:01Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8e340265-3fad-45cd-81da-b34042ce5432",
        "parentId" : "6301adca-1f36-4c97-bc4e-9796dd524611",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "+1 from me",
        "createdAt" : "2018-03-13T20:32:40Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "79118d6b-d071-435a-89f7-9e6cf155e360",
        "parentId" : "6301adca-1f36-4c97-bc4e-9796dd524611",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "+1.",
        "createdAt" : "2018-03-14T00:03:45Z",
        "updatedAt" : "2018-03-15T15:32:40Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "31719e4426c9591c2fb2f640070c1c0709f2a737",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +124,128 @@              \" %(kafka)s %(state_dir)s %(user_test_args)s %(user_test_args1)s %(user_test_args2)s\" \\\n              \" %(user_test_args3)s & echo $! >&3 ) 1>> %(stdout)s 2>> %(stderr)s 3> %(pidfile)s\" % args\n        self.logger.info(\"Executing: \" + cmd)\n\n        return cmd"
  },
  {
    "id" : "753aff8a-0adb-46a1-b609-95568c856f14",
    "prId" : 4746,
    "prUrl" : "https://github.com/apache/kafka/pull/4746#pullrequestreview-105945754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87030422-561d-48fe-a46a-cc040cc5cd3c",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could you elaborate a bit why we need to disable_auto_terminate here?",
        "createdAt" : "2018-03-21T21:59:30Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d4d62ee7-885b-4cb5-9007-4ae1f0f14304",
        "parentId" : "87030422-561d-48fe-a46a-cc040cc5cd3c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The SmokeTestDriver generates 5000 records and terminates -- this is not enough data for the upgrade test. I modified the SmokeTestDriver to allow generating and \"infinite\" amount of data, ie, it does not auto-terminate itself after 5000 records but runs until it's stopped externally.",
        "createdAt" : "2018-03-21T23:35:16Z",
        "updatedAt" : "2018-03-27T01:03:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe469ed34fb4f0d1094a542e2b2dd7d27cedd2e2",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +258,262 @@        args['pidfile'] = self.PID_FILE\n        args['log4j'] = self.LOG4J_CONFIG_FILE\n        args['disable_auto_terminate'] = self.DISABLE_AUTO_TERMINATE\n        args['kafka_run_class'] = self.path.script(\"kafka-run-class.sh\", node)\n"
  },
  {
    "id" : "9c5b767e-db74-44b1-8448-ed2fa0e56add",
    "prId" : 6382,
    "prUrl" : "https://github.com/apache/kafka/pull/6382#pullrequestreview-212484491",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Let me know if there's a better way to do this...",
        "createdAt" : "2019-03-06T17:05:37Z",
        "updatedAt" : "2019-03-08T19:03:13Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "40167662-58fd-4128-81d1-761056b78f1c",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I thought there were already existing`EOS` tests that use the `StreamsSmokeTest`?",
        "createdAt" : "2019-03-06T18:47:04Z",
        "updatedAt" : "2019-03-08T19:03:13Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "159099f7-f151-4965-9663-dc595acfc32c",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "To my other comment above: what's the difference of running `StreamsSmokeTestBaseService#process-eos` v.s. `StreamsEosTestBaseService#process`? The former uses StreamsSmokeTest while the latter use StreamsEosTest client. Can we just consolidate them?",
        "createdAt" : "2019-03-07T01:24:09Z",
        "updatedAt" : "2019-03-08T19:03:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "08376545-cb33-4f84-9663-be19ba3dd954",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Shameful admission: I thought about this, but just didn't take the time to check.\r\n\r\nThe bounce test was obviously duplicated, but the eos test is more complex. I knew I'd have to do a case-by-case check to make sure I didn't remove coverage. I'll do my homework now...",
        "createdAt" : "2019-03-07T18:24:54Z",
        "updatedAt" : "2019-03-08T19:03:13Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0b3b0378-46ae-4a2f-8c01-6cb84a6b39af",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, so the smoke test and the eos test are similar, but not identical.\r\n\r\nThe smoke test application has more features in it, though. So, we have more feature coverage under eos when we test with the smoke test.\r\n\r\nThe eos test evaluates two topologies one with no repartition, and one with a repartition. The smoke test topology contains repartitions, so it only tests _with_ repartition. I think that it should be sufficient to test only _with_ repartition.\r\n\r\nThe eos test verification specifically checks that \"all transactions finished\" (`org.apache.kafka.streams.tests.EosTestDriver#verifyAllTransactionFinished`). I'm not clear on exactly what we're looking for here. It looks like we create a transactional producer and send a record to each partition and then expect to get all those records back, without seeing any other records. But I'm not sure why we're doing this. If we want to drop the eos test, then we might need to add this to the smoke test verification.\r\n\r\nWDYT?",
        "createdAt" : "2019-03-07T19:38:38Z",
        "updatedAt" : "2019-03-08T19:03:13Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6d9327d4-8db8-4bdf-b32a-6228c1a1d81a",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`verifyAllTransactionFinished` aimed to avoid a situation that some dangling txn is open forever, without committing or aborting. Because the consumer needs to guarantee offset ordering when returning data, with read-committed they will also be blocked on those open txn's data forever (this usually indicates a broker-side issue, not streams though, but still).\r\n\r\nI think we should still retain this check if we want to merge in the EosTest to SmokeTest, but also if you do not want to drag on it we could keep it as a separate ticket and merge this as-is. Your call :)",
        "createdAt" : "2019-03-08T19:16:49Z",
        "updatedAt" : "2019-03-08T19:16:50Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0f8e7997-0a4c-4f04-a976-c9deb7753998",
        "parentId" : "8d8e4644-cb87-42f3-9341-09f194b057bb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, thanks for the explanation. Let's merge this, and I'll create a ticket to follow up by including this check and removing the eos test.\r\n\r\nThat'll help review burden as well, I think.",
        "createdAt" : "2019-03-08T21:20:16Z",
        "updatedAt" : "2019-03-08T21:20:16Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7420fd04c43eb0f9ac183756a964f27ab8d1d218",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +356,360 @@class StreamsSmokeTestEOSJobRunnerService(StreamsSmokeTestBaseService):\n    def __init__(self, test_context, kafka):\n        super(StreamsSmokeTestEOSJobRunnerService, self).__init__(test_context, kafka, \"process-eos\")\n\n"
  },
  {
    "id" : "65a078ed-0c95-4667-a896-2e5713efb7ec",
    "prId" : 7441,
    "prUrl" : "https://github.com/apache/kafka/pull/7441#pullrequestreview-306281581",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "faa030a8-b1c4-4e4a-874e-8a265a0328d3",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Could you clarify the motivation of modifying the system test here? By default StreamsSmokeTest client is configured with 3 threads.",
        "createdAt" : "2019-10-21T21:35:28Z",
        "updatedAt" : "2019-10-24T17:00:49Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "6b74d0e7-6885-4c78-a9e8-d1949e4ca776",
        "parentId" : "faa030a8-b1c4-4e4a-874e-8a265a0328d3",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Stated in the caller code",
        "createdAt" : "2019-10-24T01:57:28Z",
        "updatedAt" : "2019-10-24T17:00:49Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bdf5cf22677bebab206c070889d709efcc7aa1e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +304,308 @@    \"\"\"Base class for Streams Smoke Test services providing some common settings and functionality\"\"\"\n\n    def __init__(self, test_context, kafka, command, num_threads = 3):\n        super(StreamsSmokeTestBaseService, self).__init__(test_context,\n                                                          kafka,"
  },
  {
    "id" : "da64fc98-dc03-4bbe-8a34-092675ab3afc",
    "prId" : 7529,
    "prUrl" : "https://github.com/apache/kafka/pull/7529#pullrequestreview-302929434",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d46503e5-3f0d-48be-a999-26a70a05bcd0",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "nice ðŸ˜„ ",
        "createdAt" : "2019-10-16T23:36:26Z",
        "updatedAt" : "2019-10-17T02:39:12Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce2e86b1297c78b52afff364eb8d667dd90b9f95",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +630,634 @@                del properties['upgrade.from']\n            except KeyError:\n                self.logger.info(\"Key 'upgrade.from' not there, better safe than sorry\")\n\n        if self.upgrade_phase is not None:"
  },
  {
    "id" : "ee0f6584-b877-4395-88b3-503095f3761b",
    "prId" : 7529,
    "prUrl" : "https://github.com/apache/kafka/pull/7529#pullrequestreview-302987154",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cba1b248-10ac-4bfc-b5cd-52633e8deb19",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I'm a bit confused here: we did not use the passed in kafka string to set `BOOTSTRAP_SERVERS_CONFIG` in any of the versioned streams instance, is that intentional? ",
        "createdAt" : "2019-10-17T01:01:26Z",
        "updatedAt" : "2019-10-17T02:39:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "71670430-3d23-4986-b29d-905cb0ea7d7e",
        "parentId" : "cba1b248-10ac-4bfc-b5cd-52633e8deb19",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Also why in 2.4 we do not need `kafka` any more?",
        "createdAt" : "2019-10-17T01:04:42Z",
        "updatedAt" : "2019-10-17T02:39:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a9f68e7c-b809-4ed9-b93d-fd2fe31caa98",
        "parentId" : "cba1b248-10ac-4bfc-b5cd-52633e8deb19",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I was following the pattern from the existing upgrade test.  Again maybe I can refactor this test in a follow-on PR?",
        "createdAt" : "2019-10-17T01:45:23Z",
        "updatedAt" : "2019-10-17T02:39:12Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "ea41408c-673c-4194-a3f5-e48ffabfd48b",
        "parentId" : "cba1b248-10ac-4bfc-b5cd-52633e8deb19",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Personally I'd vote for focusing on correctness now and saving any larger scale cleanup/refactoring for a follow-up PR",
        "createdAt" : "2019-10-17T03:35:19Z",
        "updatedAt" : "2019-10-17T03:35:20Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce2e86b1297c78b52afff364eb8d667dd90b9f95",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +596,600 @@                                          str(LATEST_0_11_0), str(LATEST_1_0), str(LATEST_1_1),\n                                          str(LATEST_2_0), str(LATEST_2_1), str(LATEST_2_2), str(LATEST_2_3)]:\n            args['kafka'] = self.kafka.bootstrap_servers()\n        else:\n            args['kafka'] = \"\""
  },
  {
    "id" : "a51a803f-3c69-4560-b11b-d093f47568e4",
    "prId" : 8367,
    "prUrl" : "https://github.com/apache/kafka/pull/8367#pullrequestreview-382404529",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bcd1cfd0-aec6-4a51-bdc4-2894cfd68f70",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Switch from \"boolean\" flag to \"string\"",
        "createdAt" : "2020-03-26T20:12:35Z",
        "updatedAt" : "2020-03-27T19:25:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "217e4290-ece2-4c96-8a70-37a7f38faa49",
        "parentId" : "bcd1cfd0-aec6-4a51-bdc4-2894cfd68f70",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good call.",
        "createdAt" : "2020-03-26T20:47:06Z",
        "updatedAt" : "2020-03-27T19:25:36Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef41d1a1c748b3930b4bf6175a015896eaefe962",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +397,401 @@\nclass StreamsBrokerCompatibilityService(StreamsTestBaseService):\n    def __init__(self, test_context, kafka, processingMode):\n        super(StreamsBrokerCompatibilityService, self).__init__(test_context,\n                                                                kafka,"
  },
  {
    "id" : "f266b266-e76c-4f9d-93fd-e29442548eab",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-400306958",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b45a6c7-da0f-4aec-87fd-60a021329426",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I've added this as a general mechanism in a couple of places to pass specific configs into Streams, so we don't have to make new constructors for every different parameterization.",
        "createdAt" : "2020-04-24T22:35:09Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +481,485 @@\n    def set_config(self, key, value):\n        self.extra_properties[key] = value\n\n    def set_version(self, kafka_streams_version):"
  },
  {
    "id" : "459d8029-e4ca-4139-9924-99efd34096de",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-400306958",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2563d79f-f5fa-495a-bd1e-413cd36f45fa",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "These will become follow-on tasks to fix each test. Thankfully, there aren't many.",
        "createdAt" : "2020-04-24T22:36:01Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +570,574 @@        properties['input.topic'] = self.INPUT_TOPIC\n        # TODO KIP-441: consider rewriting the test for HighAvailabilityTaskAssignor\n        properties['internal.task.assignor.class'] = \"org.apache.kafka.streams.processor.internals.assignment.StickyTaskAssignor\"\n\n        cfg = KafkaConfig(**properties)"
  },
  {
    "id" : "e85d1eee-d73f-44c3-8078-f540c43aaf18",
    "prId" : 8716,
    "prUrl" : "https://github.com/apache/kafka/pull/8716#pullrequestreview-417052308",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1734ab8f-8755-4024-9e03-c8a8b1a63780",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "It was handy to be able to see the used config file while debugging.",
        "createdAt" : "2020-05-22T17:11:19Z",
        "updatedAt" : "2020-05-27T14:44:04Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "94194f2f6cc87a202266fbabfe426f8bc4fb09aa",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +47,51 @@        \"streams_config\": {\n            \"path\": CONFIG_FILE,\n            \"collect_default\": True},\n        \"streams_log\": {\n            \"path\": LOG_FILE,"
  },
  {
    "id" : "7d61f0fb-a1e1-4cf3-b87a-b8e77e8c692d",
    "prId" : 8716,
    "prUrl" : "https://github.com/apache/kafka/pull/8716#pullrequestreview-417052308",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42c3f6c3-fd2e-4cbc-aa4f-7f99e114de19",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Added this configuration to fix the flaky `StreamsOptimizedTest.test_upgrade_optimized_topology`",
        "createdAt" : "2020-05-22T17:11:58Z",
        "updatedAt" : "2020-05-27T14:44:04Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "94194f2f6cc87a202266fbabfe426f8bc4fb09aa",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +471,475 @@        # Long.MAX_VALUE lets us do the assignment without a warmup\n        properties['acceptable.recovery.lag'] = \"9223372036854775807\"\n\n        cfg = KafkaConfig(**properties)\n        return cfg.render()"
  },
  {
    "id" : "d423007f-26b9-45b0-8382-6437ef6ea6f6",
    "prId" : 8913,
    "prUrl" : "https://github.com/apache/kafka/pull/8913#pullrequestreview-439765527",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "becedc0f-fb0e-49ec-8c37-5d5cb73a9682",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "@ableegoldman Please take a look :)",
        "createdAt" : "2020-06-30T08:01:12Z",
        "updatedAt" : "2020-07-07T07:07:06Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "4268ab25b8a7241b391f8cbbecfc01e71a015a52",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +502,506 @@                                                        configs)\n\nclass StreamsResetter(StreamsTestBaseService):\n    def __init__(self, test_context, kafka, topic, applicationId):\n        super(StreamsResetter, self).__init__(test_context,"
  },
  {
    "id" : "8fc50752-67fe-48eb-a043-84f66a8cc612",
    "prId" : 8914,
    "prUrl" : "https://github.com/apache/kafka/pull/8914#pullrequestreview-437430342",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54452d26-e456-4056-8f57-afc56297db03",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I need to do this because otherwise the callback `int` will throw a cast exception when an error occurred in `ssh_capture()` that returned an error message.",
        "createdAt" : "2020-06-25T12:11:04Z",
        "updatedAt" : "2020-06-25T12:14:29Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "911b7a2f0ab716750bd3875852e155e877b9c348",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +218,222 @@        try:\n            pids = [pid for pid in node.account.ssh_capture(\"cat \" + self.PID_FILE, callback=str)]\n            return [int(pid) for pid in pids]\n        except Exception, exception:\n            self.logger.debug(str(exception))"
  },
  {
    "id" : "10f01c0c-0185-4d43-8f28-2df4d2dbab96",
    "prId" : 8914,
    "prUrl" : "https://github.com/apache/kafka/pull/8914#pullrequestreview-437432309",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "529e616a-4f23-4ebb-a7ca-8c34f9278043",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "We just log the exception on debug level. I do not know how much this will help, but it is better than nothing. ",
        "createdAt" : "2020-06-25T12:14:04Z",
        "updatedAt" : "2020-06-25T12:14:05Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "911b7a2f0ab716750bd3875852e155e877b9c348",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +220,224 @@            return [int(pid) for pid in pids]\n        except Exception, exception:\n            self.logger.debug(str(exception))\n            return []\n"
  },
  {
    "id" : "b0368b63-bf9b-4a9c-a1be-377bf8833ea8",
    "prId" : 8938,
    "prUrl" : "https://github.com/apache/kafka/pull/8938#pullrequestreview-438715011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23f9e6e7-e546-4c0b-9ab0-43c186851f9c",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Added the ability to set this, so that we can just run one broker from the upgrade tests.",
        "createdAt" : "2020-06-27T18:22:36Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "0163c8023d3b9fc61df35c0428269ca2752e9e6f",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +318,322 @@    \"\"\"Base class for Streams Smoke Test services providing some common settings and functionality\"\"\"\n\n    def __init__(self, test_context, kafka, command, processing_guarantee = 'at_least_once', num_threads = 3, replication_factor = 3):\n        super(StreamsSmokeTestBaseService, self).__init__(test_context,\n                                                          kafka,"
  },
  {
    "id" : "03ab4eb9-ed83-42c1-9313-9f822b0a45f6",
    "prId" : 8938,
    "prUrl" : "https://github.com/apache/kafka/pull/8938#pullrequestreview-438715011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d58d6c1-9daf-4c7a-92dd-e59f6036b32a",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "some other stuff for the upgrade tests.",
        "createdAt" : "2020-06-27T18:22:51Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "0163c8023d3b9fc61df35c0428269ca2752e9e6f",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +333,337 @@\n    def set_upgrade_from(self, upgrade_from):\n        self.UPGRADE_FROM = upgrade_from\n\n    def prop_file(self):"
  },
  {
    "id" : "c8093376-70f8-469b-9962-2dc3afd5f193",
    "prId" : 8938,
    "prUrl" : "https://github.com/apache/kafka/pull/8938#pullrequestreview-438715011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e67069df-be5e-442f-af9a-74f9afc992e2",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "moved from Java",
        "createdAt" : "2020-06-27T18:23:06Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "0163c8023d3b9fc61df35c0428269ca2752e9e6f",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +345,349 @@                      \"commit.interval.ms\": 1000,\n                      \"auto.offset.reset\": \"earliest\",\n                      \"acks\": \"all\"}\n\n        if self.UPGRADE_FROM is not None:"
  },
  {
    "id" : "fffb716e-7c82-4996-b7f1-e9f991257459",
    "prId" : 8938,
    "prUrl" : "https://github.com/apache/kafka/pull/8938#pullrequestreview-441154981",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d0d92dd-5640-465d-ab2c-bfc32634a64a",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Rotating the config file as well as the logs gives us better visibility for debugging.",
        "createdAt" : "2020-07-01T18:03:16Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "dcd66374-13ff-426b-8d9a-1e47862cc8d0",
        "parentId" : "1d0d92dd-5640-465d-ab2c-bfc32634a64a",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why only .1 / 0-1/ 1-1? There are more rotated log files below?",
        "createdAt" : "2020-07-01T19:32:33Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4cfdf565-ba2b-47cf-937e-15455d9985b7",
        "parentId" : "1d0d92dd-5640-465d-ab2c-bfc32634a64a",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Yep, but those are for other tests. The upgrade tests only roll one time. I wanted to try and avoid touching any other tests in this PR, so I only implemented config file rotation for the new test.",
        "createdAt" : "2020-07-01T19:53:10Z",
        "updatedAt" : "2020-07-01T19:53:11Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "0163c8023d3b9fc61df35c0428269ca2752e9e6f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +57,61 @@        \"streams_config.1-1\": {\n            \"path\": CONFIG_FILE + \".1-1\",\n            \"collect_default\": True},\n        \"streams_log\": {\n            \"path\": LOG_FILE,"
  },
  {
    "id" : "9856747e-2dcc-437a-bd72-24113edd30a2",
    "prId" : 10673,
    "prUrl" : "https://github.com/apache/kafka/pull/10673#pullrequestreview-658370341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Should we set it to 3 instead? IIRC, we run all system tests with 3 brokers? Wondering why the change broke the system tests, as they should have overwritten the default to 3 anyway?",
        "createdAt" : "2021-05-11T23:07:24Z",
        "updatedAt" : "2021-05-11T23:07:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "56c9a705-1195-4603-bd03-5d7ec2a5f0b9",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Sounds like we don't override the default after all? Or we have at least one test where that slipped through ðŸ¤·â€â™€ï¸ ",
        "createdAt" : "2021-05-11T23:23:02Z",
        "updatedAt" : "2021-05-11T23:23:02Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "01d6fd87-f718-469b-8e42-c21ed0de6824",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I guess the logic scattered between Python and Java code... And maybe we need 3 only for EOS tests? Not sure either.\r\n\r\nAlso ok with me to just merge this PR as-is? Or should we update Java code instead?",
        "createdAt" : "2021-05-11T23:47:55Z",
        "updatedAt" : "2021-05-11T23:47:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "58ff7229-3490-4ba7-b177-3913eb685e45",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Ah, yeah, I bet that's it: we only set it for the EOS tests. Might be better to just set it in the Java code instead as it's easier to find and read, and I believe most other configs are set there. I think this test runs the `StreamsSmokeTest`?",
        "createdAt" : "2021-05-11T23:53:01Z",
        "updatedAt" : "2021-05-11T23:53:01Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b0b8a92c-8dd1-40c5-9ac6-a860dcb1d48a",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "> Should we set it to 3 instead? IIRC, we run all system tests with 3 brokers?\r\n\r\nnot really. `streams_broker_compatibility_test.py` run test with single broker ( https://github.com/apache/kafka/blob/trunk/tests/kafkatest/tests/streams/streams_broker_compatibility_test.py#L45)\r\n\r\n> Might be better to just set it in the Java code instead as it's easier to find and read, and I believe most other configs are set there. \r\n\r\nI prefer to change python code rather than java code since the number of brokers is connected to replication refactor. If we add hardcode (i.e `replication refactor = 1`) in the java class, it is hard to change both of them in python.\r\n\r\n>  I think this test runs the StreamsSmokeTest?\r\n\r\nBrokerCompatibilityTest (https://github.com/apache/kafka/blob/trunk/tests/kafkatest/services/streams.py#L466)",
        "createdAt" : "2021-05-12T07:41:02Z",
        "updatedAt" : "2021-05-12T07:41:02Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "e7bcb06f-d7ad-4d4c-9b3d-ba53546b248f",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Fine with me either way. Thanks for the fix",
        "createdAt" : "2021-05-12T19:28:33Z",
        "updatedAt" : "2021-05-12T19:28:33Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "cbca08b8-ad7d-4d33-ac85-0dbb49e9db0d",
        "parentId" : "184b796c-0dfa-4c40-be99-334f739117f9",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fine with me, too. Feel free to merge.",
        "createdAt" : "2021-05-12T20:49:54Z",
        "updatedAt" : "2021-05-12T20:49:54Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f043149a2af175884c45ee579a95e04285c2a60",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +471,475 @@                      streams_property.KAFKA_SERVERS: self.kafka.bootstrap_servers(),\n                      # the old broker (< 2.4) does not support configuration replication.factor=-1\n                      \"replication.factor\": 1}\n\n        cfg = KafkaConfig(**properties)"
  }
]