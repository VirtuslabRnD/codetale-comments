[
  {
    "id" : "b67f9191-f518-4a6b-a32b-a290e70f762a",
    "prId" : 4650,
    "prUrl" : "https://github.com/apache/kafka/pull/4650#pullrequestreview-105177306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "parentId" : null,
        "authorId" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "body" : "Not really related to this pr - I was looking at the surrounding code and noticed that the `server_prop_overides arg` is defaulted to `[]`. Its probably fine since its not being written, but you almost never want that since every instance will share the same global list. Might want to fix that while you're here.",
        "createdAt" : "2018-03-08T06:25:26Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "tags" : [
        ]
      },
      {
        "id" : "3cfadb11-1306-4ea7-8b88-9915d311037b",
        "parentId" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@rodesai what do you mean by the \"global list\"?",
        "createdAt" : "2018-03-14T00:47:40Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b13f36f5-b294-421c-ae70-705ce43e7785",
        "parentId" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "authorId" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "body" : "When the interpreter processes the function def it will initialize one list that it passes to every instance of KafkaService thats constructed without specifying its own server_prop_overrides. Here's an illustrative example:\r\n```code\r\n>>> class A(object):\r\n...     def __init__(self, a, b=[]):\r\n...         b.append(a)\r\n...         self.b = b\r\n...\r\n>>> print A(1).b\r\n[1]\r\n>>> print A(2).b\r\n[1, 2]\r\n>>> print A(3).b\r\n[1, 2, 3]\r\n```",
        "createdAt" : "2018-03-14T01:17:02Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "tags" : [
        ]
      },
      {
        "id" : "2cf5d232-f686-4978-9d32-ce9a2f991c7a",
        "parentId" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Got it, thanks! Please let me know if the fix makes sense to you.",
        "createdAt" : "2018-03-15T01:11:15Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "fffc22b2-6bc0-43ea-8d6e-bf38c70c8a60",
        "parentId" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "authorId" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "body" : "This still has the same problem, though its more explicit. Not sure if that was the intent. The standard approach is something like this\r\n```{code}\r\ndef __init__(self, ..., server_prop_overrides=None, ...):\r\n    if server_prop_overrides is None:\r\n        server_prop_overrides = []\r\n```",
        "createdAt" : "2018-03-19T23:26:57Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "tags" : [
        ]
      },
      {
        "id" : "0a4d6e6f-4001-4416-bec5-802fab3a533e",
        "parentId" : "79bf2aaf-82e1-43a6-a888-cad1e0841272",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ah got it. I will try this in the code:\r\n\r\n```\r\nif server_prop_overides is None:\r\n            self.server_prop_overides = []\r\nelse:\r\n            self.server_prop_overides = server_prop_overides\r\n```",
        "createdAt" : "2018-03-19T23:38:41Z",
        "updatedAt" : "2018-03-22T23:45:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d42620a1d7cc64ee0107012d24ff2e6d6329e78b",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +76,80 @@        :type context\n        :type zk: ZookeeperService\n        :type topics: dict\n        \"\"\"\n        Service.__init__(self, context, num_nodes)"
  },
  {
    "id" : "ff0f6be5-ec15-4946-97c6-76c03d60130f",
    "prId" : 5373,
    "prUrl" : "https://github.com/apache/kafka/pull/5373#pullrequestreview-138374294",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8c10a6a-f95c-49b9-bc7c-9c1e81c097f0",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "I'm wondering if we should log this exception in case `thread_dump` raises an unexpected error. We don't want to lose the original error.",
        "createdAt" : "2018-07-18T18:06:27Z",
        "updatedAt" : "2018-07-18T18:52:21Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      }
    ],
    "commit" : "9665796aeabebe84253c82b3cd2f38690c9bb14d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +292,296 @@        try:\n            wait_until(lambda: len(self.pids(node)) == 0, timeout_sec=60, err_msg=\"Kafka node failed to stop\")\n        except Exception:\n            self.thread_dump(node)\n            raise"
  },
  {
    "id" : "2fe10115-c089-4a97-bd52-4c78377f72d7",
    "prId" : 6938,
    "prUrl" : "https://github.com/apache/kafka/pull/6938#pullrequestreview-251431802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f9a00e2-19ff-440e-b33a-ba8778de09a3",
        "parentId" : null,
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "Have we considered making this a bit more flexible? For example, would it be better to allow tests to specify `client_listener_name` and `interbroker_listener_name` rather than a flag. There is a lot of tech debt here since this code was written before listener names were introduced. I was wondering if this could be an opportunity to clear some of that. If you have already considered that and found it a lot of work, then we merge this and consider that later.",
        "createdAt" : "2019-06-17T18:27:30Z",
        "updatedAt" : "2019-06-20T18:13:58Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "8135b956-207e-4643-81a9-5588deff67cc",
        "parentId" : "7f9a00e2-19ff-440e-b33a-ba8778de09a3",
        "authorId" : "d4a29de4-254d-4d4d-b37e-651082f95fa9",
        "body" : "Yes, all good points. I originally intended to do a bigger change, encapsulating all listener-related stuff (security protocol, port, sasl config) in a separate Listener class, and instead of pre-defined dict with ports we could actually add and remove listener objects to/from the dict. But that's a massive and not particularly backwards compatible change.\r\nAs for 'client_listener_name' and 'interbroker_listener_name' - I originally wrote a PR like that (only for interbroker one though, client change, again, is much bigger and harder to keep backwards compatible) - but went for boolean for practical reasons, since in the tests that we envision so far we don't care about listener name, just the fact that there are two listeners on the same security protocol - so effectively I was just calling constructor with interbroker_listener_name=KafkaService.INTERBROKER_LISTENER_NAME.\r\nI can send a follow-up PR to enable custom name interbroker listener or update this one, whichever you prefer. I would suggest making changes to client listeners in separate PRs.",
        "createdAt" : "2019-06-17T20:06:19Z",
        "updatedAt" : "2019-06-20T18:13:58Z",
        "lastEditedBy" : "d4a29de4-254d-4d4d-b37e-651082f95fa9",
        "tags" : [
        ]
      },
      {
        "id" : "810b1c1d-e4dc-46dd-84c1-a44969d0a44e",
        "parentId" : "7f9a00e2-19ff-440e-b33a-ba8778de09a3",
        "authorId" : "d4a29de4-254d-4d4d-b37e-651082f95fa9",
        "body" : "I played a bit with 'interbroker_listener_name' and its tricky to marry two concepts - existing one and custom named one, without having quite a messy code. I'd suggest keeping this PR as is, with boolean value, since the tests are passing and send a follow up with custom names - this way I can unblock several people who depend on separate interbroker listener, but don't care about custom names. Wdyt?",
        "createdAt" : "2019-06-19T01:05:43Z",
        "updatedAt" : "2019-06-20T18:13:58Z",
        "lastEditedBy" : "d4a29de4-254d-4d4d-b37e-651082f95fa9",
        "tags" : [
        ]
      }
    ],
    "commit" : "33bd50de5718ec9d02dec262430aaff7ced6662a",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +95,99 @@                 authorizer_class_name=None, topics=None, version=DEV_BRANCH, jmx_object_names=None,\n                 jmx_attributes=None, zk_connect_timeout=5000, zk_session_timeout=6000, server_prop_overides=None, zk_chroot=None,\n                 use_separate_interbroker_listener=False):\n        \"\"\"\n        :param context: test context"
  },
  {
    "id" : "a7f9e385-0b4f-4ddd-8d69-0b95b441bd08",
    "prId" : 7827,
    "prUrl" : "https://github.com/apache/kafka/pull/7827#pullrequestreview-331595765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b946408-c115-4c8b-b9c6-87418ae0aaef",
        "parentId" : null,
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "just fixing some typos",
        "createdAt" : "2019-12-12T23:46:11Z",
        "updatedAt" : "2019-12-24T04:21:43Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d632598cfb18afab20b441c2da98a91d1baef11",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +675,679 @@        self.logger.debug(\"Querying zookeeper to find assigned replicas for topic %s and partition %d\" % (topic, partition))\n        zk_path = \"/brokers/topics/%s\" % (topic)\n        assignment = self.zk.query(zk_path, chroot=self.zk_chroot)\n\n        if assignment is None:"
  },
  {
    "id" : "c000f983-def0-447b-b724-3c02e196d432",
    "prId" : 7827,
    "prUrl" : "https://github.com/apache/kafka/pull/7827#pullrequestreview-331595785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5da03fe2-691a-416e-9c3d-bc8e11be4b81",
        "parentId" : null,
        "authorId" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "body" : "typo",
        "createdAt" : "2019-12-12T23:46:16Z",
        "updatedAt" : "2019-12-24T04:21:43Z",
        "lastEditedBy" : "6c4430fc-3795-49d6-9c36-cf6aa694824e",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d632598cfb18afab20b441c2da98a91d1baef11",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +560,564 @@\n        # send command\n        self.logger.info(\"Verifying partition reassignment...\")\n        self.logger.debug(cmd)\n        output = \"\""
  },
  {
    "id" : "3ee031b8-4455-48ec-bb21-192d7d818f38",
    "prId" : 8695,
    "prUrl" : "https://github.com/apache/kafka/pull/8695#pullrequestreview-421664661",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23fc6da5-de5f-4a54-9b82-e2100f10fc98",
        "parentId" : null,
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Why do we need this change?",
        "createdAt" : "2020-05-31T21:48:28Z",
        "updatedAt" : "2020-06-02T19:59:22Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      },
      {
        "id" : "e854ed80-bd2c-4242-868e-f9fa275962c1",
        "parentId" : "23fc6da5-de5f-4a54-9b82-e2100f10fc98",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "In the constructor of `SecurityConfig` we don't know node java version.\r\nTherefore we should fix `tls.version` after node version known.\r\n```\r\n    def setup_node(self, node):\r\n...\r\n        if java_version(node) <= 11 and self.properties['tls.version'] == 'TLSv1.3':\r\n            self.properties.update({'tls.version': 'TLSv1.2'})\r\n\r\n```",
        "createdAt" : "2020-06-01T08:08:36Z",
        "updatedAt" : "2020-06-02T19:59:22Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2935783c54e17b208832a749600a12923b625d8",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +361,365 @@\n        self.security_config.setup_node(node)\n        self.security_config.setup_credentials(node, self.path, self.zk_connect_setting(), broker=True)\n\n        prop_file = self.prop_file(node)"
  },
  {
    "id" : "e7c3af4a-6f16-46be-ae94-c7cf7d8a1718",
    "prId" : 8974,
    "prUrl" : "https://github.com/apache/kafka/pull/8974#pullrequestreview-442685540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8499e637-83b2-4318-af98-df404f0cd018",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "This is another bug that we don't honor the timeout parameters assigned to ```KafkaService```",
        "createdAt" : "2020-07-05T15:15:19Z",
        "updatedAt" : "2020-07-07T01:26:05Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "da92657604e1e6c3145127ba41df348e435ca383",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +187,191 @@            node.version = version\n            node.config = KafkaConfig(**{\n                config_property.BROKER_ID: self.idx(node),\n                config_property.ZOOKEEPER_CONNECTION_TIMEOUT_MS: zk_connect_timeout,\n                config_property.ZOOKEEPER_SESSION_TIMEOUT_MS: zk_session_timeout"
  },
  {
    "id" : "986035bd-8241-4748-b8cd-19cb0368bd4b",
    "prId" : 8974,
    "prUrl" : "https://github.com/apache/kafka/pull/8974#pullrequestreview-443331649",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80344c4a-4f15-45a8-b5ce-229d46b8f3de",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Could we change the default ZK session timeout and ZK connection timeout in line 101 to 18 secs too?",
        "createdAt" : "2020-07-06T18:57:38Z",
        "updatedAt" : "2020-07-07T01:26:05Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      }
    ],
    "commit" : "da92657604e1e6c3145127ba41df348e435ca383",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +188,192 @@            node.config = KafkaConfig(**{\n                config_property.BROKER_ID: self.idx(node),\n                config_property.ZOOKEEPER_CONNECTION_TIMEOUT_MS: zk_connect_timeout,\n                config_property.ZOOKEEPER_SESSION_TIMEOUT_MS: zk_session_timeout\n            })"
  },
  {
    "id" : "f2cd0a38-af95-48f3-ac57-ed07105075fd",
    "prId" : 9032,
    "prUrl" : "https://github.com/apache/kafka/pull/9032#pullrequestreview-478796421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89b35c4b-b244-4f15-8e3b-911763329f20",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "It's sort of weird that we're creating files on the fly with `'<(echo '%s')` rather than just using a file in `/mnt/security`.  This will result in some pretty long command lines, right?\r\n\r\nConsidering this is an existing pattern in `kafka.py` (but nowhere else?), let's file a follow-on JIRA to look into this and fix it.  Unless there's some really good reason why `kafka.py` is doing this, but I can't think of any.",
        "createdAt" : "2020-08-27T19:40:22Z",
        "updatedAt" : "2020-09-02T17:54:03Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "a4b7cf47-0c25-4e1c-b2a7-1632a52d02a4",
        "parentId" : "89b35c4b-b244-4f15-8e3b-911763329f20",
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "I created https://issues.apache.org/jira/browse/KAFKA-10451 to track this.",
        "createdAt" : "2020-08-31T17:17:13Z",
        "updatedAt" : "2020-09-02T17:54:03Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      }
    ],
    "commit" : "04a882b1794f90bbe002f460803cda9a2beebccc",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +580,584 @@        # Use this for everything related to kafka-configs except User SCRAM Credentials\n        if node.version.kafka_configs_command_uses_bootstrap_server():\n            return \"--bootstrap-server %s --command-config <(echo '%s')\" % (self.bootstrap_servers(self.security_protocol),\n                                                                            self.security_config.client_config())\n        else:"
  },
  {
    "id" : "2c86386f-f2a5-4865-a6c4-5c1ef0c1e8e7",
    "prId" : 9142,
    "prUrl" : "https://github.com/apache/kafka/pull/9142#pullrequestreview-469563657",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88fbcef0-5006-4d14-bf22-b711e2df05ec",
        "parentId" : null,
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "create/describe/list use `use_zk_to_..._topic=True` so I'm wondering if it is best to remain consistent here.  For example, if running an older version, might `--bootstrap-server` not be available?",
        "createdAt" : "2020-08-07T20:53:36Z",
        "updatedAt" : "2020-08-07T20:57:58Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      },
      {
        "id" : "d8e00ca2-5c11-41d1-90e6-5b43a3555efd",
        "parentId" : "88fbcef0-5006-4d14-bf22-b711e2df05ec",
        "authorId" : "0437327f-f1bc-4c4a-b258-4c8dd6851ac9",
        "body" : "Yeah that's a good point, but in this scenario I was thinking to remain consistent with the original implementation. Also I'm not sure how far we want to backport this, but if we backport it past the version where `--bootstrap-server` is not available, then I think we would have to rewrite this function to account for that. Also since we are on our way to deprecate and remove ZK, this would be a good way to start pushing us towards doing that.",
        "createdAt" : "2020-08-07T21:21:34Z",
        "updatedAt" : "2020-08-07T21:21:34Z",
        "lastEditedBy" : "0437327f-f1bc-4c4a-b258-4c8dd6851ac9",
        "tags" : [
        ]
      },
      {
        "id" : "9b1d34ae-9b49-4a93-93e6-de228705ac0b",
        "parentId" : "88fbcef0-5006-4d14-bf22-b711e2df05ec",
        "authorId" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "body" : "@rondagostino are we ok with merging this to trunk? Since this is not required for existing tests which either use ZK or PLAINTEXT brokers, not planning to backport to older versions.",
        "createdAt" : "2020-08-16T10:21:15Z",
        "updatedAt" : "2020-08-16T10:21:15Z",
        "lastEditedBy" : "b4936a15-698a-496e-85a1-b1e229b4986b",
        "tags" : [
        ]
      },
      {
        "id" : "beb896d7-0e30-4a29-93ba-32cf036cb815",
        "parentId" : "88fbcef0-5006-4d14-bf22-b711e2df05ec",
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "@rajinisivaram Yes, merging to just trunk seems fine to me.",
        "createdAt" : "2020-08-18T15:21:25Z",
        "updatedAt" : "2020-08-18T15:21:25Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      }
    ],
    "commit" : "387bd9ed9d2b9b56ed1b11ba62b290f2b12e59d4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +504,508 @@        node.account.ssh(cmd)\n\n    def delete_topic(self, topic, node=None, use_zk_to_delete_topic=False):\n        \"\"\"\n        Delete a topic with the topics command"
  },
  {
    "id" : "1e9f69bf-5ad6-4370-b7a6-e0621267c760",
    "prId" : 10093,
    "prUrl" : "https://github.com/apache/kafka/pull/10093#pullrequestreview-587627691",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d0955e2-0af6-424b-b400-400cb230d26f",
        "parentId" : null,
        "authorId" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "body" : "what happens if we have more brokers than 7?  There are tests like that.\r\n\r\nShould we use something like 700 here?",
        "createdAt" : "2021-02-10T00:26:39Z",
        "updatedAt" : "2021-02-10T14:02:24Z",
        "lastEditedBy" : "514c0afb-8649-4fd9-a6ea-ee9e1b695274",
        "tags" : [
        ]
      },
      {
        "id" : "4786b319-3ac9-4206-a744-ed4d43f99a8e",
        "parentId" : "6d0955e2-0af6-424b-b400-400cb230d26f",
        "authorId" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "body" : "This is calculating the port for the inter-broker listener.  The mapping from security protocol to port is as shown below.  This change is simply a rewrite of an existing hard-coded number (9099) to a calculation (9092 + 7).  There is no issue regardless of the number of brokers.\r\n\r\n```\r\nClient listener when using SecurityConfig.PLAINTEXT ==> 9092\r\nClient listener when using SecurityConfig.SS ==> 9093\r\nClient listener when using SecurityConfig.SASL_PLAINTEXT ==> 9094\r\nClient listener when using SecurityConfig.SASL_SSL ==> 9095\r\nInter-broker listener (and whatever security protocol it is set to) ==> 9092 + 7 = 9099\r\n```",
        "createdAt" : "2021-02-10T13:54:16Z",
        "updatedAt" : "2021-02-10T14:02:24Z",
        "lastEditedBy" : "e0554c25-f6f3-4e49-a325-bcc5d4dc5fb2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b16fc75f684e893249e67674693387edecd55d42",
    "line" : 254,
    "diffHunk" : "@@ -1,1 +350,354 @@        broker_only_port_mappings = {\n            KafkaService.INTERBROKER_LISTENER_NAME:\n                KafkaListener(KafkaService.INTERBROKER_LISTENER_NAME, config_property.FIRST_BROKER_PORT + 7, None, False)\n        }\n        controller_only_port_mappings = {}"
  }
]