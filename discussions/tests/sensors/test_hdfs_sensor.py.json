[
  {
    "id" : "ff42c837-e243-405a-ae09-f16efa0d650f",
    "prId" : 6544,
    "prUrl" : "https://github.com/apache/airflow/pull/6544#pullrequestreview-315480377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18d3a62a-a085-41cc-b309-ae3e65431447",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Maybe it's worth to consider to make `tests.test_utils.mocks` to keep there all fake / mock stuff?",
        "createdAt" : "2019-11-12T11:41:20Z",
        "updatedAt" : "2019-11-12T14:49:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "a28cc078-1299-4722-a239-b91f4b634239",
        "parentId" : "18d3a62a-a085-41cc-b309-ae3e65431447",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "If there are a large number of them, we can create such a structure. Now it would only complicate the situation/import.",
        "createdAt" : "2019-11-12T11:54:54Z",
        "updatedAt" : "2019-11-12T14:49:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "cdfc4d92-2371-4943-96df-4837fc458a82",
        "parentId" : "18d3a62a-a085-41cc-b309-ae3e65431447",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "If someone wants to add more things to HDFS then they will have ready place. ",
        "createdAt" : "2019-11-12T11:55:44Z",
        "updatedAt" : "2019-11-12T14:49:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2f1b64ed78f923c14d8c21da34bead3fbb16967",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +23,27 @@from airflow.sensors.hdfs_sensor import HdfsSensor\nfrom airflow.utils.timezone import datetime\nfrom tests.test_utils.hdfs_utils import FakeHDFSHook\n\nDEFAULT_DATE = datetime(2015, 1, 1)"
  }
]