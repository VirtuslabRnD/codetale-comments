[
  {
    "id" : "1190a377-71b7-4556-81bd-707a678df2c1",
    "prId" : 12093,
    "prUrl" : "https://github.com/numpy/numpy/pull/12093#pullrequestreview-162150850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c8b2fa4-103a-4a0d-9553-9f087c38ad39",
        "parentId" : null,
        "authorId" : "73d6f7d8-2c7d-4a48-8754-5ce4a97a850f",
        "body" : "Looks harmless at first glance if it helps a downstream project. I don't think we have plans to explicitly support Python 3.4 issues moving forward, but this may be fair enough.\r\n\r\nI suppose one could add a unit test that uses a regex on the ValueError message, although maybe that's overkill.",
        "createdAt" : "2018-10-05T17:07:42Z",
        "updatedAt" : "2018-10-05T17:07:42Z",
        "lastEditedBy" : "73d6f7d8-2c7d-4a48-8754-5ce4a97a850f",
        "tags" : [
        ]
      },
      {
        "id" : "73cdf197-d557-4f2b-85ec-da722f485218",
        "parentId" : "5c8b2fa4-103a-4a0d-9553-9f087c38ad39",
        "authorId" : "2035b7cb-d7e4-423a-a3b4-2c5117021872",
        "body" : "FWIW those failures also happen with 3.5 at times (so I was told), or I misunderstood and this code path is 3.4 specific?",
        "createdAt" : "2018-10-05T18:14:46Z",
        "updatedAt" : "2018-10-05T18:14:47Z",
        "lastEditedBy" : "2035b7cb-d7e4-423a-a3b4-2c5117021872",
        "tags" : [
        ]
      },
      {
        "id" : "724fdab7-db76-4f93-8acc-89fa366aa177",
        "parentId" : "5c8b2fa4-103a-4a0d-9553-9f087c38ad39",
        "authorId" : "73d6f7d8-2c7d-4a48-8754-5ce4a97a850f",
        "body" : "If the issue isn't 3.4-specific that probably make a more compelling case to fix it",
        "createdAt" : "2018-10-05T18:19:28Z",
        "updatedAt" : "2018-10-05T18:19:29Z",
        "lastEditedBy" : "73d6f7d8-2c7d-4a48-8754-5ce4a97a850f",
        "tags" : [
        ]
      }
    ],
    "commit" : "43ecbdc95a09e85f570bb7ce530da72ad78d9cc5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +514,518 @@        self.key = \"%s%d\" % (self.kind, self.bits)\n        if self.kind not in 'iu':\n            raise ValueError(\"Invalid integer data type %r.\" % (self.kind,))\n\n    def min(self):"
  },
  {
    "id" : "a53df3e7-e9db-44be-9642-1fedbf7d534f",
    "prId" : 18536,
    "prUrl" : "https://github.com/numpy/numpy/pull/18536#pullrequestreview-678675897",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de9634b1-f05f-44b8-8a6c-c9054d9ad9f4",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Do we consider `MachArLike` private?  In that case we could just rename `tiny` to `smallest_normal` here.  Otherwise, maybe skip `smallest_normal` and set it in the init to avoid the duplication?",
        "createdAt" : "2021-06-07T19:27:04Z",
        "updatedAt" : "2021-06-07T19:56:38Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "2780b2fd-23ed-4351-a17a-b333588c5df3",
        "parentId" : "de9634b1-f05f-44b8-8a6c-c9054d9ad9f4",
        "authorId" : "966f7863-1017-450c-9dac-376e60544f73",
        "body" : "I'm not sure how we want to perform the transition here, for backwards compatibility we will have those two duplicated inside the class but I don't know what keyword in the constructor should we leave for the long term. I can leave in the constructor only `smallest_normal`",
        "createdAt" : "2021-06-08T04:47:39Z",
        "updatedAt" : "2021-06-08T04:47:39Z",
        "lastEditedBy" : "966f7863-1017-450c-9dac-376e60544f73",
        "tags" : [
        ]
      },
      {
        "id" : "9b990e5a-3cdb-442f-a69f-81c8ab7de757",
        "parentId" : "de9634b1-f05f-44b8-8a6c-c9054d9ad9f4",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I dunno, even JAX which has `bfloat16` and [subclasses `np.finfo`](https://github.com/google/jax/pull/5486/files) does not use it:\r\n```\r\nobj.machar = None  # np.core.getlimits.MachArLike does not support bfloat16.\r\n```\r\n(I honestly don't think this should be public to begin with, but that is a follow-up.)\r\n\r\n\r\nBut well, we can try to keep it compatible for now (which I guess means passing *only* `tiny`)?  And should probably deprecate the whole thing (i.e. make it non-public for good).  It shouldn't be public, but maybe we have to go the slow route.",
        "createdAt" : "2021-06-08T15:29:49Z",
        "updatedAt" : "2021-06-08T15:29:49Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2b6ebad0a792153490101fc3bf5cb66ee4751ef",
    "line" : 176,
    "diffHunk" : "@@ -1,1 +293,297 @@                             epsneg=exp2(ld(-106)),\n                             huge=huge_dd,\n                             tiny=smallest_normal_dd,\n                             smallest_subnormal=smallest_subnormal_dd)\n    # double double; low, high order (e.g. PPC 64)"
  },
  {
    "id" : "a4154aa0-8c70-41a4-baf6-4fa7881a397b",
    "prId" : 18536,
    "prUrl" : "https://github.com/numpy/numpy/pull/18536#pullrequestreview-677803379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "268c6273-84e5-4a33-a04d-7b37613f7653",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Thanks for fixing this!",
        "createdAt" : "2021-06-07T19:27:15Z",
        "updatedAt" : "2021-06-07T19:56:38Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2b6ebad0a792153490101fc3bf5cb66ee4751ef",
    "line" : 144,
    "diffHunk" : "@@ -1,1 +274,278 @@    # These numbers have the same exponent range as float64, but extended number of\n    # digits in the significand.\n    huge_dd = nextafter(ld(inf), ld(0), dtype=ld)\n    # As the smallest_normal in double double is so hard to calculate we set\n    # it to NaN."
  },
  {
    "id" : "4b48b206-d3fc-48a3-9d08-7c94595beaa2",
    "prId" : 18536,
    "prUrl" : "https://github.com/numpy/numpy/pull/18536#pullrequestreview-705685546",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0be4101f-7238-42fb-b4a0-a96e42f00999",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "The warning here, is also a bit weird, just like the other warning.  But since this warning should never happen except for broken installs, I am willing to ignore it.",
        "createdAt" : "2021-07-14T01:40:42Z",
        "updatedAt" : "2021-07-14T15:20:45Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2b6ebad0a792153490101fc3bf5cb66ee4751ef",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +81,85 @@            warnings.warn(\n                'The value of the smallest subnormal for {} type '\n                'is zero.'.format(self.ftype), UserWarning, stacklevel=2)\n\n        return self._float_to_float(value)"
  },
  {
    "id" : "faaf7738-756b-4bc5-a47d-01048566f318",
    "prId" : 18536,
    "prUrl" : "https://github.com/numpy/numpy/pull/18536#pullrequestreview-709026068",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "parentId" : null,
        "authorId" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "body" : "I might be missing some context here, so forgive me if I'm confusing matters. It appears that you are able to compute the smallest positive subnormal ðœŽ, and a few lines below you define `macheps`, so I take it you are able to compute the machine epsilon ðœ€. From there, you can in fact compute the smallest positive normal ðœ” as ðœŽ â¨¸ ðœ€, where â¨¸ means division in the relevant floating point system (which is what the `/` operator does in C and Python). In Python terms, you can do approximately the following, but you'll need to move up the definition of `macheps` from below.\r\n\r\n```Python\r\n    # Leave the same value for the smallest subnormal as double\r\n    smallest_subnormal_dd = ld(nextafter(0., 1.))\r\n    smallest_normal_dd = smallest_subnormal / macheps\r\n```\r\n",
        "createdAt" : "2021-07-15T13:05:01Z",
        "updatedAt" : "2021-07-15T21:09:46Z",
        "lastEditedBy" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "tags" : [
        ]
      },
      {
        "id" : "e2b65445-fc77-43ad-b4f9-b3f6b55a8343",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "966f7863-1017-450c-9dac-376e60544f73",
        "body" : "Calculating the value for smallest_normal in some architectures is messy, so after a lot of discussions and thoughts we defined that it is safer to leave this value as NaN because the previous value is wrong. Once this PR is merged, I'll open a new issue to discuss how we should approach the calculation of this value in a way where everyone feels confident with the resulting number. ",
        "createdAt" : "2021-07-15T21:15:54Z",
        "updatedAt" : "2021-07-15T21:15:55Z",
        "lastEditedBy" : "966f7863-1017-450c-9dac-376e60544f73",
        "tags" : [
        ]
      },
      {
        "id" : "204cf029-d63f-4629-9d43-3d68be66ab30",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "@wkschwartz I am not happy to have this NaN, but unless we get clarity for one more person agreeing on the correct value, I am unwilling to make this my decision. I _am_ willing to sign off someone else's research if I get a bit more background (or just a spec/prior art) â€“ including an argument why the double-double specific storage scheme doesn't break e.g. your reasoning.\r\n\r\nEven `macheps` is only an [\"appropriate\" value](https://www.ibm.com/docs/en/aix/7.1?topic=sepl-128-bit-long-double-floating-point-data-type), so we should be a bit careful...  I suspect that may give you the \"most appropriate\" value (i.e. the smallest number that has the full 106-bit of \"guaranteed\" mantissa, of which one is implicit).\r\n\r\nThat said, I also come to the a value of `np.exp2(-969.0)` which is identical to `np.log2(np.nextafter(0., 1.)) + 105` (105 and is just 52+53, since we include the implicit mantissa bit of the second float).  But, I have never worked with double-double and would like someone else to think it through first.",
        "createdAt" : "2021-07-15T22:14:48Z",
        "updatedAt" : "2021-07-15T22:14:48Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "d004ed25-c99f-4d80-b6be-c37ed07bd804",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "body" : "I guess I'm confused about the target FP system here. Am I correct that this is for double-double implementations of [`long double`]? The [AIX 7.1 documentation] you linked to says explicitly that its 128-bit `long double` is _not_ compliant with C99 because it does not have a fixed precision (number of bits in the significand):\r\n\r\n> The actual number of bits of precision can vary.... The ANSI C standard... requires that the number of base _b_ digits is fixed, which is not true for 128-bit long double numbers.\r\n\r\nI didn't realize that this code was targeting variable-precision number formats when I wrote my first post. **I think I take back my suggestion above?**\r\n\r\nYou wrote\r\n\r\n> if I get a bit more background (or just a spec/prior art)\r\n\r\nI would argue that a variable-precision number format is not a floating-point format. Is it really appropriate to present information about such a format through `finfo` (\"leaky abstraction\", etc.)?â€  The definitions of _floating point system_ in Goldberg (1991), Higham (2002), and Muller, _et al._ (2010) require fixed precision. I don't know which theorems that numerical analysts rely on for designing accurate algorithms (Higham, 2002) apply to variable-precision formats. Muller, _et al._ (2010, Ch. 14) discusses them a little, offers some references, and says some not very nice things about them (\"must be used with caution\", etc.). I haven't read the whole chapter, so that's as much as I can offer at this point.\r\n\r\nI guess my question is this: **What platforms that Numpy targetsâ€”aside from AIX's `xlc128` compilerâ€”have a `long double` with variable precision?** It seems to me (but I immediately defer to your expertise here) that the rest of Numpy presupposes at least an FP format compliant with C99, no? **If AIX's `xlc128` compiler is the only such platform, then I think the data presented from `finfo` about `long double` should just directly target that one platform. In particular, I suppose that there _is no_ standard for double-double formats, they're always idiosyncratic where they exist, and they're not really even floating-point systems.**\r\n\r\nFor what it's worth, the [AIX 7.1 documentation] says\r\n\r\n> When the value to be represented is in the denormal range, this representation provides no more precision than the 64-bit double-precision data type.\r\n\r\nThis suggests that `smallest_normal_dd` is the same as the smallest, positive normal in a `double`. (Also it should be the same as C's [`LDBL_MIN`](https://en.cppreference.com/w/c/types/limits#Limits_of_floating_point_types).)\r\n\r\n### References\r\n\r\nI'm copypasta-ing some references here from an paper I've been working on (FP-related, not double-double related). Maybe someone else can make use of some of these links to shed some light on this?\r\n\r\n1. David Goldberg, â€œWhat Every Computer Scientist Should Know about Floating-Point Arithmeticâ€ in _ACM Computing Surveys_, vol. 23, no. 1 (March 1991), 5â€“48. [doi:10.1145/103162.103163](https://doi.org/10.1145/103162.103163). *Available at* http://lux.dmcs.p.lodz.pl/ak/IEEE754_article.pdf.\r\n2. Nicholas J. Higham. _Accuracy and Stability of Numerical Algorithms_, 2nd ed. Philadelphia: Society for Industrial and Applied Mathematics, 2002.\r\n3. â€œIEEE Standard for Floating-Point Arithmeticâ€ in _IEEE Std 754-2008_, 29 Aug. 2008, [doi:10.1109/IEEESTD.2008.4610935](https://doi.org/10.1109/IEEESTD.2008.4610935). _Available at_ https://irem.univ-reunion.fr/IMG/pdf/ieee-754-2008.pdf.\r\n4. ISO/IEC 9899:1999, committee draft WG14 N1256, _Programming languages â€“ C_, 2007-09-07. International Organization for Standardization. Geneva, Switzerland. _Available at_ http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf. This is not the published international standard, but the latest publicly available draft, which â€œreflects what was to become the standard at the time of issueâ€, according to [open-std.org](http://www.open-std.org/jtc1/sc22/wg14/www/standards.html). The official ISO page is https://www.iso.org/standard/29237.html.\r\n5. Jean-Michel Muller, Nicolas Brisebarre, Florent de Dinechin, Claude-Pierre Jeannerod, Vincent LefÃ¨vre, Guillaume Melquiond, Nathalie Revol, Damien StehlÃ©, and Serge Torres. _Handbook of Floating-Point Arithmetic_. Boston: BirkhÃ¤user, 2010. [doi:10.1007/978-0-8176-4705-6](https://doi.org/10.1007/978-0-8176-4705-6), e-ISBN: 978-0-8176-4705-6.\r\n\r\n--------------\r\n\r\nâ€ Of course, backward compatibility rules here. I'm not actually proposing in the middle of a different PR to rip out support for AIX's `xlc128` compiler that's already been around for awhile. The ship has sailed, the horse is out of the etc.\r\n\r\n\r\n[`long double`]: https://numpy.org/doc/stable/user/basics.types.html#extended-precision\r\n[AIX 7.1 documentation]: https://www.ibm.com/docs/en/aix/7.1?topic=sepl-128-bit-long-double-floating-point-data-type",
        "createdAt" : "2021-07-16T15:35:43Z",
        "updatedAt" : "2021-07-16T15:35:44Z",
        "lastEditedBy" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "tags" : [
        ]
      },
      {
        "id" : "4a5a966b-2a5d-4d3e-9c7a-7d87eb5ac682",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "> This suggests that smallest_normal_dd is the same as the smallest, positive normal in a double.\r\n\r\nTrue, that is what it was, but then `finfo` lies about the precision, if you say that every number larger than `smallest_normal` should have full (in this case at least) the number of mantissa bits advertised.  That would be 106bits (including the implicit one).\r\n\r\nWe have those two main choices: just go with double precision (the old value) or go with the smallest number that has a 106bit (implicit) mantissa (and above which all numbers do!).  Which actually aligns with what you said, and is `np.exp2(-969.0)` (although I am only 95% certain).\r\n\r\nDouble-double is not IEEE compliant, so we have to make a choice.  It would be nice to just point to someone else's choice here, but I don't know it.  I am perfectly fine with us making the choice here, if we are pretty confident about one.",
        "createdAt" : "2021-07-16T15:51:10Z",
        "updatedAt" : "2021-07-16T15:51:25Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "aa1b8181-f1b6-497c-96e2-c396d8c6be6e",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "body" : "> We have those two main choices: just go with double precision (the old value) or go with the smallest number that has a 106bit (implicit) mantissa (and above which all numbers do!)\n\nUpon further reflection the correct answer is the latter. I can explain more later but for now the basic idea is that the distinction between subnormal and normal is all about guaranteed minimum precision. Subnormals don't satisfy the main axiom of FP in numerical analysis that _relative_ errors are bounded by half a machine epsilon. Normals do maintain that invariant. So setting the dividing line between them based on precision is the only useful way to go.",
        "createdAt" : "2021-07-16T23:26:10Z",
        "updatedAt" : "2021-07-17T16:36:57Z",
        "lastEditedBy" : "ed5564b3-30de-4cde-83d3-042942f7203d",
        "tags" : [
        ]
      },
      {
        "id" : "40a24e64-e3f7-4f3d-9131-caec5c786098",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I am confused. We had agreed to merge this PR with undefined values for long double. But now we are opening the discussion up again? ",
        "createdAt" : "2021-07-18T12:07:46Z",
        "updatedAt" : "2021-07-18T12:07:47Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "e4f3c2cf-5a69-45d4-bdbb-6d91337033cb",
        "parentId" : "2f66c20e-d4af-4fd5-8293-2cd8e441f772",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "No, I am happy to follow up here, we can move into an issue.",
        "createdAt" : "2021-07-18T13:18:20Z",
        "updatedAt" : "2021-07-18T13:18:20Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2b6ebad0a792153490101fc3bf5cb66ee4751ef",
    "line" : 149,
    "diffHunk" : "@@ -1,1 +279,283 @@    smallest_normal_dd = NaN\n    # Leave the same value for the smallest subnormal as double\n    smallest_subnormal_dd = ld(nextafter(0., 1.))\n    float_dd_ma = MachArLike(ld,\n                             machep=-105,"
  }
]