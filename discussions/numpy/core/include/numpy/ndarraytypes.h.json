[
  {
    "id" : "7c8e5173-4b54-4333-b4ac-976b4dac0e45",
    "prId" : 87,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "900e45d1-9032-4fe8-9d31-61f13dd8e864",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Could these go in npy_common.h?\n",
        "createdAt" : "2011-06-15T05:04:07Z",
        "updatedAt" : "2011-06-16T19:50:35Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "7c20fdc4-f550-436b-8e73-b32186e35fad",
        "parentId" : "900e45d1-9032-4fe8-9d31-61f13dd8e864",
        "authorId" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "body" : "Yeah, that sounds fine. I'm wanting to rename away from the 'frequency' nomenclature as well.\n",
        "createdAt" : "2011-06-15T15:07:58Z",
        "updatedAt" : "2011-06-16T19:50:36Z",
        "lastEditedBy" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d7d59aef203ebf25b268ceaccfa1be45237b0df",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +231,235 @@\ntypedef enum {\n        NPY_FR_Y, /* Years */\n        NPY_FR_M, /* Months */\n        NPY_FR_W, /* Weeks */"
  },
  {
    "id" : "6bbc44bc-e490-4d60-857f-03c180cee019",
    "prId" : 87,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0870359d-250b-41e4-a9f2-62f9536c32a9",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I've moved that into npy_common for the sort library. Looks like I'll need to do some merging ;)\n",
        "createdAt" : "2011-06-15T05:05:34Z",
        "updatedAt" : "2011-06-16T19:50:35Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "b54f8db6-acbf-47fc-bc83-8920e6219a65",
        "parentId" : "0870359d-250b-41e4-a9f2-62f9536c32a9",
        "authorId" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "body" : "I want to do a relatively invasive header shuffle at some point towards managing future ABI compatibility, we'll have to make sure not to step on each others toes with that.\n",
        "createdAt" : "2011-06-15T15:10:40Z",
        "updatedAt" : "2011-06-16T19:50:36Z",
        "lastEditedBy" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d7d59aef203ebf25b268ceaccfa1be45237b0df",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +292,296 @@\n/*\n * This is to typedef npy_intp to the appropriate pointer size for\n * this platform.  Py_intptr_t, Py_uintptr_t are defined in pyport.h.\n */"
  },
  {
    "id" : "26e2c28f-cd37-476a-817d-2755d83f69a8",
    "prId" : 116,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "263911b7-ed64-4ab9-b30d-72098baaff3b",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I believe tags are in their own namespace, so the tag prefix isn't really needed. Adding '_t' to the typedef is more commonly done.\n",
        "createdAt" : "2011-07-20T02:24:52Z",
        "updatedAt" : "2011-07-26T17:12:40Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "c1e3894d-b21b-459a-a949-64a6662efc4d",
        "parentId" : "263911b7-ed64-4ab9-b30d-72098baaff3b",
        "authorId" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "body" : "I haven't noticed any consistent convention in NumPy with regards to this. I agree that typedefs like npy_int32 should be npy_int32_t as you suggest, but there are lots of things to change to make it consistent. This is the kind of thing that would go in a NumPy coding standards document somewhere...\n",
        "createdAt" : "2011-07-20T14:36:27Z",
        "updatedAt" : "2011-07-26T17:12:40Z",
        "lastEditedBy" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "tags" : [
        ]
      }
    ],
    "commit" : "affea42d886e8233fdd6f3c5760708e3a9e9b1b8",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +617,621 @@ */\n#ifdef NPY_NO_DEPRECATED_API\ntypedef struct tagPyArrayObject {\n        PyObject_HEAD\n} PyArrayObject;"
  },
  {
    "id" : "8cf433ad-3370-41c1-9cdf-5e8b703ce08d",
    "prId" : 116,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06a23291-64e1-4fcb-b84d-a5ed48f790b0",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Now I contradict myself and wonder if these should be inline functions. Having a typecheck on the 'it' variable could be helpful.\n",
        "createdAt" : "2011-07-20T02:27:46Z",
        "updatedAt" : "2011-07-26T17:12:40Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "21f48f51-0a31-4b77-b4a4-87e13627068a",
        "parentId" : "06a23291-64e1-4fcb-b84d-a5ed48f790b0",
        "authorId" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "body" : "It's unfortunate that all the NumPy array creation functions return PyObject\\* instead of PyArrayObject*.\n",
        "createdAt" : "2011-07-20T14:38:41Z",
        "updatedAt" : "2011-07-26T17:12:40Z",
        "lastEditedBy" : "95359633-f0b0-4899-8e46-e2146fd11511",
        "tags" : [
        ]
      }
    ],
    "commit" : "affea42d886e8233fdd6f3c5760708e3a9e9b1b8",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +971,975 @@}\n\n#define _PyArray_ITER_NEXT2(it) { \\\n        if ((it)->coordinates[1] < (it)->dims_m1[1]) { \\\n                (it)->coordinates[1]++; \\"
  },
  {
    "id" : "9745460c-74e9-4b1d-9de0-571206b3161b",
    "prId" : 451,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f74ab02f-1d74-4dd3-86e5-b4d79703b67b",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Maybe NPY_UNSAFE_CASTING_WARN ?\n\nAlso the comment formatting should be\n\n```\n/*\n * blah\n */\n```\n",
        "createdAt" : "2012-09-20T22:17:10Z",
        "updatedAt" : "2012-09-20T23:25:38Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f18987a69c297b5602b00c22b9759d2ece4a7bf1",
    "line" : null,
    "diffHunk" : "@@ -1,1 +206,210 @@         * release, see below\n         * */\n        NPY_INTERNAL_UNSAFE_CASTING_BUT_WARN_UNLESS_SAME_KIND = 100,\n} NPY_CASTING;\n"
  },
  {
    "id" : "7d5a1379-be0c-4cd5-9d7b-b4096acc08dd",
    "prId" : 3527,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee81f261-8fb9-40f9-a58a-07879f6e4611",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "This is harmless, but I'd probably omit it on grounds of overkill.\n",
        "createdAt" : "2013-08-01T00:34:48Z",
        "updatedAt" : "2013-08-01T22:23:25Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "f21c6745-cada-4d72-8d50-304e046da014",
        "parentId" : "ee81f261-8fb9-40f9-a58a-07879f6e4611",
        "authorId" : "3e976b32-2704-45fd-84e7-9d4b44e1e692",
        "body" : "Maybe it's not overkill if the code rests for a while, someone else defines NPY_DEPRECATED_INCLUDES for whatever reason and is then puzzled why it doesn't work. As this is really a minor question (no difference in the compiled code), I don't change this – unless more people comment and form a majority vote, of course.\n",
        "createdAt" : "2013-08-01T22:21:42Z",
        "updatedAt" : "2013-08-01T22:23:25Z",
        "lastEditedBy" : "3e976b32-2704-45fd-84e7-9d4b44e1e692",
        "tags" : [
        ]
      }
    ],
    "commit" : "62282a90424f1643ea50375e53c326af48fee898",
    "line" : null,
    "diffHunk" : "@@ -1,1 +1738,1742 @@ * npy_*_*_deprecated_api.h are only included from here and nowhere else.\n */\n#ifdef NPY_DEPRECATED_INCLUDES\n#error \"Do not use the reserved keyword NPY_DEPRECATED_INCLUDES.\"\n#endif"
  },
  {
    "id" : "d8c19735-c4b5-4b5f-a94f-ad037a5248de",
    "prId" : 3527,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7320cfba-7996-4ac8-987b-1b1874867ce6",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I short comment before this line would be appropriate.\n",
        "createdAt" : "2013-08-01T00:35:16Z",
        "updatedAt" : "2013-08-01T22:23:25Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "62282a90424f1643ea50375e53c326af48fee898",
    "line" : null,
    "diffHunk" : "@@ -1,1 +1741,1745 @@#error \"Do not use the reserved keyword NPY_DEPRECATED_INCLUDES.\"\n#endif\n#define NPY_DEPRECATED_INCLUDES\n#if !defined(NPY_NO_DEPRECATED_API) || \\\n    (NPY_NO_DEPRECATED_API < NPY_1_7_API_VERSION)"
  },
  {
    "id" : "488e58bd-0cf4-40a9-8c80-421414500b8d",
    "prId" : 3798,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "parentId" : null,
        "authorId" : "605dc99f-e6a8-4691-8567-69df7bedb615",
        "body" : "@seberg can you try to keep the existing struct ABI ? If possible, we'd like to keep ABI compatibility in the 1.x branch.\n",
        "createdAt" : "2013-10-28T14:18:07Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "605dc99f-e6a8-4691-8567-69df7bedb615",
        "tags" : [
        ]
      },
      {
        "id" : "e054c8c0-a22e-4ef9-aade-4b595a546510",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I hope I did keep everything ABI compatible (well everything that is reasonably to use). This is used in two different tests for `ufunc.at` and another one more specific, but as of yet not tested for ABI, only for API compatibility. I am aware it still needs checking. I think Thaeno is probably the only project using this API (it was only exposed in 1.8. and that is not even officially released yet).\n",
        "createdAt" : "2013-10-28T14:25:33Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "9858e9af-84e5-4ea2-81a8-d0ec423c514a",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "this structure was already exposed in at least 1.7 possibly much earlier.\n",
        "createdAt" : "2013-10-28T14:51:46Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "9ae66391-e9a5-46b7-98a3-ebb1844b2002",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Maybe the structure, but MapIterArray was not. So nobody could have possibly used it before 1.8.x (though I admit in master it has been possibly a year).\n",
        "createdAt" : "2013-10-28T14:58:52Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "09360dfb-26e0-4913-bc67-cc6f77a8d497",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "over which functions is it used in 1.8? I could only find PyArray_MapIterNew which is not exposed.\n\nif it is private we should move it out of the public header into a private one.\n",
        "createdAt" : "2013-10-28T15:08:31Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "30838cef-8edb-44e7-84d9-a806545316e3",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "It can be used via `PyArray_MapIterArray`, `PyArray_MapIterNext`, `PyArray_MapIterReset` (maybe) and `PyArray_MapIterSwapAxes`. It is used for `ufunc.at` and the `inplace_add` test in `multiarray_tests.c.src`. The fields that are used there, should be compatible, so unless someone is naughty enough to not use `PyArray_MapIterNext` to iterate, ABI compatibility should be there.\n",
        "createdAt" : "2013-10-28T15:15:21Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "626adaf6-a7bc-490c-8241-3c423574d1f4",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "@charris should we still make the structure private for 1.8 to be on the safe side?\n",
        "createdAt" : "2013-10-28T15:21:15Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "71bf91f7-8af7-4891-8cca-4969c64e72f5",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "body" : "The problem is that multiarray and ufunc are different modules, and only\nallowed to communicate via the public api.\n\nIMHO this creates all kinds of ugly distortions of the public api, and\nsooner or later we should merge these modules together so they can\ncollaborate more directly. But that's not happening in 1.8 ;-)\nOn 28 Oct 2013 15:21, \"Julian Taylor\" notifications@github.com wrote:\n\n> In numpy/core/include/numpy/ndarraytypes.h:\n> \n> > @@ -1270,33 +1291,71 @@ struct PyArrayIterObject_tag {\n> >          npy_intp              index;                   /\\* current index _/\n> >          int                   nd;                      /_ number of dims _/\n> >          npy_intp              dimensions[NPY_MAXDIMS]; /_ dimensions */\n> > -        PyArrayIterObject     _iters[NPY_MAXDIMS];     /_ index object\n> > -                                                          iterators */\n> > -        PyArrayIterObject     _ait;                    /_ flat Iterator for\n> > -                                                          underlying array */\n> > -        NpyIter               _outer;                  /_ index objects\n> \n> @charris https://github.com/charris should we still make the structure\n> private for 1.8 to be on the safe side?\n> \n> —\n> Reply to this email directly or view it on GitHubhttps://github.com/numpy/numpy/pull/3798/files#r7251223\n> .\n",
        "createdAt" : "2013-10-28T15:42:38Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "tags" : [
        ]
      },
      {
        "id" : "4a1c26c2-0383-4df0-bbd1-a4d678600eb2",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "@juliantaylor That would make me nervous and another rc would probably be indicated. The problem with changes in the C code is that it can be difficult to predict the consequences. In this case, did anyone use this structure? Sebastian mentions theano as one possibility. OTOH, if there is good reason to believe that no one depends on direct access to the structure, we could probably move it or even deprecate direct access in 1.9. The latter might be the best way to go if the structure has really been public since 1.7.\n",
        "createdAt" : "2013-10-28T16:18:56Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "27d1e1e7-cca7-4f70-a209-fa0115959984",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "That said, there are enough changes in 1.8.x that I'm on the edge of thinking another rc is needed in any case, this would push me over that edge.\n",
        "createdAt" : "2013-10-28T16:24:45Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "c41cfabe-3cfa-45ae-bcbf-27cfb00131fd",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Well, at this point the whole \"public api\" is not even documented... Flagging it as experimental might be best and should mean that thaeno doesn't need to worry about anything (I don't know what they use it for).\n",
        "createdAt" : "2013-10-28T16:55:43Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "30b078e5-26e5-496d-83e4-93a0219a2f25",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Sounds like we should leave 1.8 alone and figure out what to do for 1.9. That will provide more time and the deprecation mechanism provides a way to hide the structure in the future if that seems appropriate. At a minimum we should ping theano to see what they need.\n",
        "createdAt" : "2013-10-28T17:04:06Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "febe6617-0ce1-479b-87ea-c997d149cedb",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "for 1.8 we could at least deprecate PyArrayMapIterObject via comments in the code to avoid that we get new code using it:\nWhat about these:\nPyArrayIterObject\nPyArrayMultiIterObject\nPyArrayNeighborhoodIterObject\ncan they be deprecated? the first two are probably more commonly used so deprecation of direct access might be premature without existing get/set methods.\n",
        "createdAt" : "2013-10-29T18:27:48Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "d931df7b-4893-4cac-8f1d-d2663021f135",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I've already tagged 1.8 and am waiting for Ralf to do the binaries. If we get this figured out, we could maybe do a 1.8.1, but I'd rather figure out something for 1.9. This doesn't fall into the category of a bug fix and it isn't clear to me that we yet have a consensus on what should be done, or for that matter, what has already been done. For instance, IIRC, PyArrayNeighborhoodIterObject goes back several releases. All that makes me loathe to stop the 1.8 process at this point.\n",
        "createdAt" : "2013-10-29T18:44:58Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "0a0aa68f-73a5-44cf-a4e4-1907393b6196",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "yes lets figure something out for 1.9 and not delay 1.8 any longer.\n",
        "createdAt" : "2013-10-29T19:01:13Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "3b8ef730-ca59-4a32-aa57-6060ad3dfb09",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I know, nobody has really time for this probably :). But I just tested the `multiarray_tests.test_inplace_add` compiled with master and ran it with this branch and it works. So I am pretty confident that it is binary compatible for the usage which makes sense, unless there may be some subtleties on other architectures or compilers or so.\n",
        "createdAt" : "2013-12-18T12:46:34Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "32a27cb3-9c2f-4780-b43f-080a503266ba",
        "parentId" : "2dfbfa39-b423-4138-b353-4517f6efb6c9",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "@juliantaylor @seberg \n\n```\nPyArrayIterObject\nPyArrayMultiIterObject\nPyArrayNeighborhoodIterObject\n```\n\nI haven't checked the others yet, but it looks like PyArrayNeighborhoodIterObject already has functions for accesses, so we could move it into a deprecated file I think. That should not break anyone's code unless we start moving the internals around, at which point folks will probably need to recompile as the functions are inline, i.e., the accesses to struct internals will still be there. So we can guarantee API but not ABI. That is already the case for PyArrayObject, but I don't know if that is widely publicised. It may be that we need to make that a policy, because otherwise we are frozen.\n",
        "createdAt" : "2014-02-02T06:22:59Z",
        "updatedAt" : "2014-02-07T14:07:27Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "d554c2954b82b120ce77c1fd9a74c4deb85503a3",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1276,1280 @@        int                   nd;                      /* number of dims */\n        npy_intp              dimensions[NPY_MAXDIMS]; /* dimensions */\n        NpyIter               *outer;                  /* index objects\n                                                          iterator */\n        void                  *unused[NPY_MAXDIMS - 2];"
  },
  {
    "id" : "d978018c-bb0d-4030-9d77-145f35fca7c6",
    "prId" : 4475,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "996d21b4-555b-4b3c-b56f-b1c1ccb3ffee",
        "parentId" : null,
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "the structure exists even with single threaded python\n",
        "createdAt" : "2014-03-11T19:47:16Z",
        "updatedAt" : "2014-03-11T19:48:45Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      }
    ],
    "commit" : "7add97bcee029ae5269532c33b9531ebf26f89c5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +930,934 @@\n/* the variable is used in some places, so always define it */\n#define NPY_BEGIN_THREADS_DEF PyThreadState *_save=NULL;\n#if NPY_ALLOW_THREADS\n#define NPY_BEGIN_ALLOW_THREADS Py_BEGIN_ALLOW_THREADS"
  },
  {
    "id" : "f0a07f90-83cc-47b7-a82c-a6572651fe13",
    "prId" : 5343,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "parentId" : null,
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "this unfortunately breaks the ABI and causes forward compatibility issues with cython.\nthough I am playing with breaking ABI by hiding the ufunc structure (at least partially) maybe we could break this too.\nBut if we do we should do it properly and add a pointer to a private object or something similar.\n",
        "createdAt" : "2014-12-04T06:47:31Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "06832c38-a2d4-4851-aac5-17b77c323bf4",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "body" : "Shouldn't adding a field at the end be fine, ABI-wise? We don't allow\nsubclassing. What cython issue are you thinking of?\n\nI doubt there's any legitimate reason for anyone outside numpy to access\nanything besides a few fields at the beginning anyway though (in\nparticularly itemsize), and I've also been pondering plans to rewrite the\ndtype struct. So I wouldn't rule that out either. Rather than using a\npimpl, though, it might be sufficient to just hide the private fields\nbehind a private struct definition that only we can cast to.\nOn 4 Dec 2014 06:47, \"Julian Taylor\" notifications@github.com wrote:\n\n> In numpy/core/include/numpy/ndarraytypes.h:\n> \n> > @@ -619,6 +620,10 @@ typedef struct _PyArray_Descr {\n> >           \\* for NumPy 1.7.0.\n> >           */\n> >          NpyAuxData *c_metadata;\n> > -        /\\* Cached hash value (-1 if not yet computed).\n> > -         \\* This was added for NumPy 2.0.0.\n> > -         */\n> > -        npy_hash_t hash;\n> \n> this unfortunately breaks the ABI and causes forward compatibility issues\n> with cython.\n> though I am playing with breaking ABI by hiding the ufunc structure (at\n> least partially) maybe we could break this too.\n> But if we do we should do it properly and add a pointer to a private\n> object or something similar.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/numpy/numpy/pull/5343/files#r21288459.\n",
        "createdAt" : "2014-12-04T06:56:53Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "tags" : [
        ]
      },
      {
        "id" : "82df1323-ca4a-4501-9f18-2fa9f1cdd9c8",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "body" : "> But if we do we should do it properly and add a pointer to a private object or something similar.\n\nThat sounds reasonable. Do you have a patch for that somewhere?\n",
        "createdAt" : "2014-12-04T10:33:02Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "tags" : [
        ]
      },
      {
        "id" : "c272212b-b869-46f8-a0b6-7e1e5c580a8d",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "extending structs breaks programs embedding this struct into other structures (unlikely) and cython checks the size of these types and complains if they are different than what the program was built with, thats just an annoyance but one that comes up very often.\n",
        "createdAt" : "2014-12-04T14:31:14Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "86aefd97-2347-4583-aa2d-7be0a46e45c3",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "I haven't finished my ufunc patch yet, though it goes along the lines that njsmith suggested, keep the current structure and internally use a larger one. Additionally it might be interesting to mangle the public part in the development version to trigger failures for people that use the internals. For release the mangling can be reverted.\n",
        "createdAt" : "2014-12-04T14:36:29Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "7adebdbd-5609-4379-88a4-4ea5ea78eaae",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "body" : "I hope no-one is embedding this struct into a larger one, b/c that's going\nto be broken no matter what. I guess they might be able to get away with it\nATM because dtypes don't actually support GC traversal, but this is a bug\n-- dtypes can participate in reference loops! (for example\ndtype->subarray->base is a pointer to a dtype). And any type supporting GC\n_must_ have all instances allocated via PyObject_GC_New, b/c this allocates\nsome extra memory at a known offset where the GC will scribble bookkeeping\ninformation during its traversal. If you try to stick a GC-supporting type\ninto another struct or something anything like that, then the GC will end\nup scribbling on random memory.\n\nSo I'm not too worried about breaking code that does that. It'll be broken\nsooner or later regardless.\n\nAnd I concur that the cython thing is just an annoyance. Probably we should\nask them to get rid of it.\n\nI don't recall any reports of brokenness after the 1.7 release, which was\nthe last time we increased the size of dtype instances.\n\nWe should talk more about dtype rejiggering but probably this is not the\nright thread for that discussion :-)\n\nOn Thu, Dec 4, 2014 at 2:36 PM, Julian Taylor notifications@github.com\nwrote:\n\n> In numpy/core/include/numpy/ndarraytypes.h:\n> \n> > @@ -619,6 +620,10 @@ typedef struct _PyArray_Descr {\n> >           \\* for NumPy 1.7.0.\n> >           */\n> >          NpyAuxData *c_metadata;\n> > -        /\\* Cached hash value (-1 if not yet computed).\n> > -         \\* This was added for NumPy 2.0.0.\n> > -         */\n> > -        npy_hash_t hash;\n> \n> I haven't finished my ufunc patch yet, though it goes along the lines that\n> njsmith suggested, keep the current structure and internally use a larger\n> one. Additionally it might be interesting to mangle the public part in the\n> development version to trigger failures for people that use the internals.\n> For release the mangling can be reverted.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/numpy/numpy/pull/5343/files#r21306949.\n\n## \n\nNathaniel J. Smith\nPostdoctoral researcher - Informatics - University of Edinburgh\nhttp://vorpus.org\n",
        "createdAt" : "2014-12-04T19:38:26Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "tags" : [
        ]
      },
      {
        "id" : "3af5ce42-88a7-4fe7-994c-d27977e82f6e",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "there is also the issue that users can create and fill their own dtype structures, by extending it the new fields are uninitialized and in this case would cause dtypes to have random hashes.\nThis problem can't be avoided, but if we do it we might as well do it properly by eliminating this problem for all future additions.\n",
        "createdAt" : "2014-12-04T20:25:16Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "521b8ef1-a569-44e6-973d-b2358ea00076",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "34105ae0-9fd2-4403-be9b-7c550a729828",
        "body" : "I was bit by that when adding frozen dimensions to ufuncs: the ufunc struct is initialized on its own by `np.frompyfunc` and the extra array I had added there was never allocated, leading to nasty crashes in the tests.\n\nI'd love to see what you have in mind fleshed out in a little more detail, Julian.\n",
        "createdAt" : "2014-12-04T20:52:43Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "34105ae0-9fd2-4403-be9b-7c550a729828",
        "tags" : [
        ]
      },
      {
        "id" : "4f49d89a-1f47-4b96-bad4-935844f220be",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "body" : "Shouldn't users creating their own dtype instances still be calling\nPyArray_DescrNew to do so? Or even if not I don't think there's any legal\nway to allocate a PyObject that doesn't at least zero-initialize all the\nfields. If we're worried we could make the \"uninitialized\" value here be\nzero.\n\nOn Thu, Dec 4, 2014 at 8:25 PM, Julian Taylor notifications@github.com\nwrote:\n\n> In numpy/core/include/numpy/ndarraytypes.h:\n> \n> > @@ -619,6 +620,10 @@ typedef struct _PyArray_Descr {\n> >           \\* for NumPy 1.7.0.\n> >           */\n> >          NpyAuxData *c_metadata;\n> > -        /\\* Cached hash value (-1 if not yet computed).\n> > -         \\* This was added for NumPy 2.0.0.\n> > -         */\n> > -        npy_hash_t hash;\n> \n> there is also the issue that users can create and fill their own dtype\n> structures, by extending it the new fields are uninitialized and in this\n> case would cause dtypes to have random hashes.\n> This problem can't be avoided, but if we do it we might as well do it\n> properly by eliminating this problem for all future additions.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/numpy/numpy/pull/5343/files#r21333142.\n\n## \n\nNathaniel J. Smith\nPostdoctoral researcher - Informatics - University of Edinburgh\nhttp://vorpus.org\n",
        "createdAt" : "2014-12-04T21:52:50Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "tags" : [
        ]
      },
      {
        "id" : "c23f87d9-bed8-49b8-a524-4a8d5affe0cc",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "body" : "I'm less knowledgeable than you guys :) What should be the way forward?\n",
        "createdAt" : "2015-01-07T08:59:13Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "tags" : [
        ]
      },
      {
        "id" : "146fe1a1-f65d-40a6-ad09-d4bd020b1185",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "one way would be to implement the hiding of the object internals, another wait until someone else does it, but that might take a while.\nUnfortunately the dtype internals are probably far more commonly used than the ufunc internals I want to hide. This probably gives us much less wiggle room for breaking the ABI.\nUnless someone finds a way to do so without breaking it, maybe some kind of magic number in one of the existing fields could work.\n",
        "createdAt" : "2015-01-27T20:15:47Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "784d5670-a74d-4343-b18f-f1aeb67cd5de",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "body" : "maybe I am also just overly cautious, in light of no better idea if you want to work on it I think the approach of adding a second private struct that embeds the public struct is worthwhile. Its only problem is that we technically can't trust the hash to be correct if others do unusual stuff with the public part.\n",
        "createdAt" : "2015-01-27T20:26:40Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "0e0ae9fd-53e5-41a6-8774-29bcec6001df",
        "tags" : [
        ]
      },
      {
        "id" : "f0b8f687-e299-4650-9181-e236a2bce46f",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "body" : "Would the general scheme work like PyArray_Fields currently does? Which dtype fields should be private vs. public exactly?\n",
        "createdAt" : "2015-01-27T22:53:07Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "tags" : [
        ]
      },
      {
        "id" : "f24792b5-52b8-40b2-84bd-e95066441c99",
        "parentId" : "5da391dc-0f97-413c-b62a-8cd782696322",
        "authorId" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "body" : "Ping on my questions above :)\n",
        "createdAt" : "2015-02-11T18:34:11Z",
        "updatedAt" : "2015-04-04T16:45:23Z",
        "lastEditedBy" : "4d247404-3edc-44db-9c1a-e6671fa3608e",
        "tags" : [
        ]
      }
    ],
    "commit" : "cca2c1a4fecfa5533b5579204c5f28a12c5b078a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +623,627 @@         * This was added for NumPy 2.0.0.\n         */\n        npy_hash_t hash;\n} PyArray_Descr;\n"
  },
  {
    "id" : "58e07933-b379-49a2-b4ae-c5ea3c9c3e78",
    "prId" : 9639,
    "prUrl" : "https://github.com/numpy/numpy/pull/9639#pullrequestreview-75242535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53152367-53d8-4390-90fc-e4826d0138b2",
        "parentId" : null,
        "authorId" : "a4f03a99-2e43-482b-a9bc-5a9e359abb03",
        "body" : "So presumably this `2` version is only needed during the deprecation phase, afterwards we will redefine `NPY_ARRAY_INOUT_FARRAY` to use `NPY_ARRAY_WRITEBACKIFCOPY`.",
        "createdAt" : "2017-11-08T19:17:27Z",
        "updatedAt" : "2017-11-08T19:34:43Z",
        "lastEditedBy" : "a4f03a99-2e43-482b-a9bc-5a9e359abb03",
        "tags" : [
        ]
      },
      {
        "id" : "c23a1c91-2831-411f-8627-025f94996dec",
        "parentId" : "53152367-53d8-4390-90fc-e4826d0138b2",
        "authorId" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "body" : "That's one option, but it's a bit risky since we don't have any way to know when all the old code using `NPY_ARRAY_INOUT_FARRAY` is gone. We might just keep the `2` version forever – it's not pretty but it's safe and works.",
        "createdAt" : "2017-11-08T19:23:01Z",
        "updatedAt" : "2017-11-08T19:34:43Z",
        "lastEditedBy" : "762e53b3-7c6a-4fbb-8098-a2c522dd50a6",
        "tags" : [
        ]
      },
      {
        "id" : "d056591c-9073-4ec9-9661-cc4b14310b44",
        "parentId" : "53152367-53d8-4390-90fc-e4826d0138b2",
        "authorId" : "a4f03a99-2e43-482b-a9bc-5a9e359abb03",
        "body" : "yeah we can leave the 2 version forever, but after the deprecation phase no one needs to use it any more.",
        "createdAt" : "2017-11-08T20:43:36Z",
        "updatedAt" : "2017-11-08T20:43:37Z",
        "lastEditedBy" : "a4f03a99-2e43-482b-a9bc-5a9e359abb03",
        "tags" : [
        ]
      }
    ],
    "commit" : "dcf304fc76eb73597bf5b289a88fe50b1565ce91",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +904,908 @@                                NPY_ARRAY_UPDATEIFCOPY)\n#define NPY_ARRAY_INOUT_FARRAY2 (NPY_ARRAY_FARRAY | \\\n                                NPY_ARRAY_WRITEBACKIFCOPY)\n\n#define NPY_ARRAY_UPDATE_ALL   (NPY_ARRAY_C_CONTIGUOUS | \\"
  },
  {
    "id" : "57b95a3c-06fe-4b71-8215-c79a0c9c1a77",
    "prId" : 9953,
    "prUrl" : "https://github.com/numpy/numpy/pull/9953#pullrequestreview-74244846",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3ac0baa-149b-4a5c-a0bf-a70d2f73afd7",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "This is one of those cases where `(0 == (dtype)->elsize)` is a bit safer. Many years ago there was an attempt to subvert linux with a bit of trick code someone slipped into the public branch that replaced a check, something like `user == 0`, by `user = 0`.  Site shutdown and a months long hunt for the attacker's pathway ensued. That said, I don't think this is worth worrying about, it just reminds me when I see it ;)",
        "createdAt" : "2017-11-04T02:29:20Z",
        "updatedAt" : "2017-11-04T02:29:20Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cfbaf67ce18474c0c01b9e50052863112382742",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1677,1681 @@#define PyDataType_HASFIELDS(obj) (((PyArray_Descr *)(obj))->names != NULL)\n#define PyDataType_HASSUBARRAY(dtype) ((dtype)->subarray != NULL)\n#define PyDataType_ISUNSIZED(dtype) ((dtype)->elsize == 0)\n#define PyDataType_MAKEUNSIZED(dtype) ((dtype)->elsize = 0)\n"
  },
  {
    "id" : "8a2d8ac2-8819-4a21-9180-1bfb07049c44",
    "prId" : 12757,
    "prUrl" : "https://github.com/numpy/numpy/pull/12757#pullrequestreview-194373903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7557d2e-91ba-4454-8305-8fa75c0258ba",
        "parentId" : null,
        "authorId" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "body" : "~~Note that `F(macro_arg, other, args)` is already safe, and there is no point adding the extra parens. Macro arguments cannot contain unprotected commas~~",
        "createdAt" : "2019-01-19T23:34:15Z",
        "updatedAt" : "2019-01-19T23:38:46Z",
        "lastEditedBy" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "tags" : [
        ]
      },
      {
        "id" : "b8dce47a-94bd-44b1-bdb1-92634f3ff7b4",
        "parentId" : "a7557d2e-91ba-4454-8305-8fa75c0258ba",
        "authorId" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "body" : "Actually, turns out I'm wrong, but you have to really be trying: https://godbolt.org/z/eCCZuh\r\n```C\r\n#define COMMA ,\r\n\r\n#define FOO(x) BAR(x, 1, 2)\r\n\r\nFOO(a COMMA b)\r\n```\r\nResults in `BAR(a, b, 1, 2)`",
        "createdAt" : "2019-01-19T23:37:43Z",
        "updatedAt" : "2019-01-19T23:39:06Z",
        "lastEditedBy" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "tags" : [
        ]
      }
    ],
    "commit" : "ac39d763bc2700f6595d806a4bca8a2a62cecab6",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +956,960 @@\n#define PyArray_IS_C_CONTIGUOUS(m) PyArray_CHKFLAGS((m), NPY_ARRAY_C_CONTIGUOUS)\n#define PyArray_IS_F_CONTIGUOUS(m) PyArray_CHKFLAGS((m), NPY_ARRAY_F_CONTIGUOUS)\n\n/* the variable is used in some places, so always define it */"
  },
  {
    "id" : "89dc6896-f15a-4221-bd7b-942823ae135e",
    "prId" : 12757,
    "prUrl" : "https://github.com/numpy/numpy/pull/12757#pullrequestreview-194373841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e84167fe-a41a-4925-92f0-fa8a23191ff9",
        "parentId" : null,
        "authorId" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "body" : "~~This is the only bug fix in this patch~~",
        "createdAt" : "2019-01-19T23:34:31Z",
        "updatedAt" : "2019-01-19T23:39:50Z",
        "lastEditedBy" : "ab55dc5f-f626-43b1-ba83-3d8843d79a45",
        "tags" : [
        ]
      }
    ],
    "commit" : "ac39d763bc2700f6595d806a4bca8a2a62cecab6",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +966,970 @@#define NPY_END_THREADS   do { if (_save) \\\n                { PyEval_RestoreThread(_save); _save = NULL;} } while (0);\n#define NPY_BEGIN_THREADS_THRESHOLDED(loop_size) do { if ((loop_size) > 500) \\\n                { _save = PyEval_SaveThread();} } while (0);\n"
  },
  {
    "id" : "60b47363-10d2-45ff-bf8b-5a1471b6c4a0",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-439163052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d47096c-1fa0-4d77-b2ab-05f083bca9d3",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Could this get an \"added\r\n```suggestion\r\n        /*\r\n         * DType methods, these could be moved into its own struct. Added\r\n         * in version 1.20\r\n         */\r\n```",
        "createdAt" : "2020-06-29T13:50:14Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +1891,1895 @@        PyArray_ArrFuncs *f;\n\n        /* DType methods, these could be moved into its own struct */\n        discover_descr_from_pyobject_function *discover_descr_from_pyobject;\n        is_known_scalar_type_function *is_known_scalar_type;"
  },
  {
    "id" : "aac4e76f-05c0-45bc-a7d0-f1c8923e227c",
    "prId" : 16938,
    "prUrl" : "https://github.com/numpy/numpy/pull/16938#pullrequestreview-515217019",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Could we use flags to version this struct and indicate whether `_buffer_info` exists or not? If it doesn't exist we should raise an error when trying to use it.",
        "createdAt" : "2020-07-24T06:29:06Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "375e1a26-d90a-491c-9282-d9b34ce28d70",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I am not sure I am following.  We could add a version, but I guess we already have the NumPy version to find out how large the struct will be (or even the type object).  If we would version it, C-side subclassers (if we can even figure out someone is that), would need to opt-in with a flag and we otherwise keep using the global? (and maybe try to give a deprecation warning)",
        "createdAt" : "2020-07-24T15:21:43Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "cc2ed0a5-f91d-4809-a860-0176dc05ddc6",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I was thinking more along the lines of \"Detect that we did not set up this `PyArrayObject_fields`, refuse to do any buffer processing\". That would force anyone mimicking our struct to also add the field and update the flag, otherwise they would get errors. So then there are two parts: \r\n- set something inside the struct itself to show it has this extra field\r\n- detect this thing and raise an error rather than write past the end of the struct\r\n\r\nIt needs to be inside the struct since the struct can be fed in by C-API consumers. ",
        "createdAt" : "2020-07-24T15:36:59Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "5bfe980e-44aa-425d-a10c-f286b5903363",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I would be happy to get rid of the global registry and force the few people who reproduce the `PyArrayObject_fields` struct to update or fail.",
        "createdAt" : "2020-07-24T15:39:00Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "2a08f96e-3473-4293-88e9-8744f535e40f",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Good point, I have to think whether its feasible/easy, since python subclasses must not notice any of such things.",
        "createdAt" : "2020-07-24T15:47:12Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "0dfc2ac7-df60-4850-97c1-a39feaf2991c",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "@mattip, I guess we could initialize the field with a singleton/garbage (instead of NULL), in the hope that it makes clashes/crashes more likely.  The only usage that would really find, is if the subclasser also initializes the field to NULL and does not end up using it consistently.  (Since any non-NULL value should lead to a crash during dealloc.)\r\n\r\nI am not sure there is a good way to find C-side subclassing, aside from checking whether the types `basicsize` changed, which would be the case unless the subclasser added a single pointer at the end.  So that is something we can do: raise an error if the types size differs, but there isn't some additional flag set.  But it seems a bit convoluted? We would have to set that flag on each instance probably, or require reimplementation of the buffer export, which seems strange?",
        "createdAt" : "2020-08-03T20:25:53Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "760aeb46-2175-4bb9-84e4-d914e61d928c",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "This is the scenario that worries me:\r\n- Someone uses the older C-API to create an ndarray, using something like `PyArray_NewFromDescr`. Now they have a `PyArrayObject` that is smaller than the one after this PR.\r\n- They somehow pass it to a newer NumPy. Now we get a `PyObject*`, and \r\n- NumPy 1.20 casts it to a `PyArrayObject`. Whoops, we will read this field off the end of the memory they gave us.\r\n\r\nThis is similar to the problems we were having with Cython compiled code like cython/cython#2221 that led to cython/cython#2627.\r\n\r\n`sizeof()` or junk memory will not help here. I think the only way to detect this is to have some kind of versioning in the struct itself, which is why I suggested we add a value to the flag, I think something like `#define NPY_ARRAY_HAS_BUFFER_INFO 0x4000` might work. Then we can set the flag whenever we allocate and initialize a new `PyArrayObject_fields`, and check that the flag has that value set whenever we wish to manipulate the `_buffer_info`.",
        "createdAt" : "2020-08-03T20:43:53Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "d1170d2f-e4b5-4251-9232-3ea73c6eb06b",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "`basicsize` might work as well.",
        "createdAt" : "2020-08-03T20:45:27Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "c033b8d0-476d-47f4-84b9-8046f6196919",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "So the example we want to guard against is mainly this type of thing?:\r\n```\r\ncimport numpy as npc\r\n\r\ncdef class sub(npc.ndarray):\r\n    pass\r\n```\r\nwithout any extra fields the struct will be too small (I thought cpython would check this, but it does not), if we add more fields they will be incompatible.  The case where the struct is too small is simple though: We can just raise an error in `tp_alloc`.  But if you add a single new field there, we will not know and need the flag (or hope for the best with guards).\r\nI am actually not sure where the flag should be set. `tp_alloc` is plausible, but not sure its available in cython, I guess in cython you may have to set it in `__array_finalize__` (but only if numpy is new enough).\r\n\r\nFor heaptypes, we would have to walk the mro (to see if there is a static subclass involved) – they always have at least one additional field `tp_dict`, and may have more for `__slots__`. Or simply assume that there is no static subclass involved.\r\n\r\nI am not sure about `PyArray_NewFromDescr`, you can't create an incompatible `ndarray` in any reasonable way I think. (It would have to be a stack allocated array, which is possible, but pretty dirty – at least outside of NumPy).",
        "createdAt" : "2020-08-03T21:40:10Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "8c3b9906-5c54-4f2d-948d-c60f5752353c",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : " Let's discuss the implications at the next triage meeting.",
        "createdAt" : "2020-10-20T08:21:38Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "bb768290-d496-45ac-a7b0-829ed166c3c9",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "OK, thinking about it a bit more. I don't have a big new idea.  We noted flags in the meeting, there is the option to:\r\n\r\n1. Add a flag to indicate that a buffer was exported, the only use would be a sanity check on `dealloc` (so that we do not crash hard).\r\n2. Somehow allow downstream to indicate that they are aware of a growing struct. But I don't see how downstream can add a flag here, since it needs to be flagged on the type object.\r\n\r\nThere is no perfect solution, since point 1 can easily crash hard if an array exports a buffer and then the field gets modified.  That is super rare, but I thought an alternative could be to tag the pointer to give us a chance to convert the hard crash into a useful message.\r\n\r\nI was going to polish this up a bit, but it would be good to finish gh-16936 and gh-17295 since it modifies the same code.",
        "createdAt" : "2020-10-22T00:04:40Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "b46e61d7-6e21-43f1-a14e-91c25f47a866",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Isn't [the `PyArray_GetNDArrayCVersion` mechnism](https://numpy.org/doc/stable/reference/c-api/array.html?highlight=pyarray_getndarraycversion#c.PyArray_GetNDArrayCVersion) supposed to adequately protect us from ABI changes?",
        "createdAt" : "2020-10-22T08:39:44Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "78b2e3cf-568f-47c8-8310-1f048f067d0c",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Ooops, yeah. That forces everyone to recompile even though almost nobody will have to, but is maybe best. But, it seems the current check won't allow to easily compile against both versions of NumPy, which is probably still problematic (unless we assume that this happens so rarely that packaging isn't probably an issue for these projects)?",
        "createdAt" : "2020-10-22T13:47:22Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "c76a77b5-4605-4c43-95d1-2f6232e9b5d2",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Maybe try building this PR and running it against an version of SciPy compiled for 1.19 or older",
        "createdAt" : "2020-10-22T13:57:31Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "eb1169f0-f3e7-4eca-8b8b-34a6a44a0e57",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I think PyArray_GetNDArrayCVersion works properly when mixing NumPy versions in, say, SciPy and Numpy. Otherwise we would have heard loud screams when we modified PyUFuncObject in v1.16 and changed the ABI version number. So I am 99% sure this discussion is a non-issue. I guess one way to find out is to merge this now, and wait for the weekly builds to percolate through the system.",
        "createdAt" : "2020-10-22T15:04:29Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "f1b6a2a0-4e63-411b-b335-aec176c7a486",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "... which means fixing the merge conflict and getting tests to pass.",
        "createdAt" : "2020-10-22T15:05:10Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "23ac7cce-2c8e-4700-88d0-3d1df7a93423",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I hope it is, but check here:\r\n\r\nhttps://github.com/numpy/numpy/blame/39c915c1236d61debb4b3e10dfadf910da6c9b30/numpy/core/setup_common.py#L24\r\n\r\nWe have the API version and the ABI version. The API version we can increase easily, since it will only affect anything if you compile against a new NumPy version and then run it on an old one (which we can assume nobody does). But the ABI version has not been touched in 10 years.  Now I don't know how well that worked out 10 years ago, but it seems like a time before widespread comfortable pip?",
        "createdAt" : "2020-10-22T15:15:45Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "a7b2882f-4a72-48ea-b99c-0f86ff2d428f",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "OK, then I guess we need to do some testing to make sure.",
        "createdAt" : "2020-10-22T16:05:55Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "c76a2bef-140e-4f6c-8625-7da47c5046fa",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I played with this for a while with `pip install scipy` and a local `numpy` build (after changing `C_ABI_VERSION` in `numpy/core/setup_common.py`. I also modified `_import_array` in `b/numpy/core/code_generators/generate_numpy_api.py` to print when it is called. If I import `scipy`, I see it calls `_impport_array`, and the `C_ABI_VERSION` is the new one. Which makes sense, the function is exposed via `_multiarrayumath.so`, which comes from NumPy, but I just wanted to confirm.",
        "createdAt" : "2020-10-22T22:33:33Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "69da52ca-5450-4ac6-81a8-50c3bd10d05b",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I don't understand.  I just tried as well. First, I had to clean up to get the new C-ABI version, I think.  Second `import_array` is defined as part of `__multiarray_api.h` and should be included as a header and not linked? If it is linked, that would defeat the purpose.  So I assume your pip install compiled scipy?\r\n\r\nImporting the system ScPy after incrementing the C-ABI version, I get this (version was 100009 or so before):\r\n```\r\nIn [2]: f\"{np.core._multiarray_umath._get_ndarray_c_version():x}\"                                                       \r\nOut[2]: '200000a'\r\n\r\nIn [3]: from scipy import linalg                                                                                        \r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nRuntimeError: module compiled against ABI version 0x1000009 but this version of numpy is 0x200000a\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nImportError: numpy.core.multiarray failed to import\r\n```",
        "createdAt" : "2020-10-22T22:56:37Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "9a8b2665-dc91-4b26-8207-7e64926fe2e4",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "OK, I didn't try importing scipy.linalg (which I guess is compiled by cython). Thanks for checking more deeply. So we cannot change C_ABI_VERSION without recompiling the world.\r\n\r\nWhere does that leave us with this PR (and the one to configure memory allocations)?",
        "createdAt" : "2020-10-22T23:03:38Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "bdc8b8b8-d891-4553-b670-f63817087dde",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I guess we either:\r\n\r\n1. Wait until some day where we actually do a big bang NumPy 2.0 (I am fan of a 2.0, but not of recompile the world 2.0)\r\n2. Define the size of these structs as \"undefined\"? Placing it into the downstream responsibility of checking for binary compatibility in this case (this is what cython normally does, although with a warning? I have yet to test it here though).\r\n3. We think about some extremely slow route, with compile time warnings...?\r\n\r\nMy opinion about option 2 has not changed (with two caveats):\r\n\r\n* I would like to give a reasonable error/warning at least in the majority of (hypothetical) cases. This is to *decrease the severity* if the issue appears.\r\n* No big \"user\" of this shows up and shouts loudly. Which is, unfortunately, plausible.\r\n\r\nOf course, if you go by strict policies, you might just dismiss my opinion. But IMO, we should be using quality assurance type triaging, which means map out how likely it is (how many users are affected), how sever it is:\r\n\r\n* Affects: Exceedingly few users (we are not aware of any, none of the large open source ~pages~ projects seem affected)\r\n* Severity: Crash bug, which is easy to fix by recompiling once the issue is found.  That is fairly sever, but *not* super high, since it is seems pretty much impossible that you get wrong results without a loud crash as well.  (EDIT: missing not)\r\n\r\nSo because it should be reasonable to fix, and be a loud crash that affects very few users. My personal opinion is that it might well be much lower impact than some \"bug fixes\".\r\n\r\nOf course, you have to weigh that with the benefit. In this case probably a few percent of speedup for many scripts relying on small to mid-sized arrays and simpler code.  And later your change, which might make some big-data  use cases much faster.",
        "createdAt" : "2020-10-22T23:24:52Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "0ca64b16-ff53-4f2e-9917-b02b648e553f",
        "parentId" : "61b9e6fb-9255-4343-ae6a-42c892366e76",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "On the up-side here, I was trying around with cython code such as:\r\n```\r\ncdef class myarr(np.ndarray):\r\n    cdef int myint  # or just pass\r\n```\r\nAnd even that crashes hard. I guess because cython supports cyclic GC, but we do not.  So that rules out one set of potential users who run into this unwittingly...\r\n\r\nI wonder if could declare `np.ndarray` as final in the `__init__.pyd`. Or in some other way telling cython that `cdef` style subclassing is *not* valid (or at least not simple).",
        "createdAt" : "2020-10-23T01:11:27Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a216c5b3508a2c9c62a4e37c133350832ce26f86",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +699,703 @@    PyArray_Descr *descr;\n    /* Flags describing array -- see below */\n    int flags;\n    /* For weak references */\n    PyObject *weakreflist;"
  },
  {
    "id" : "ab27b56d-fce6-4462-a3e4-ad6b0a92808b",
    "prId" : 16938,
    "prUrl" : "https://github.com/numpy/numpy/pull/16938#pullrequestreview-537771425",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "What was wrong with this?",
        "createdAt" : "2020-11-23T23:19:17Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "fedd4331-449e-489a-ada7-eb72e1e7fcd9",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Nothing as such, but it is a trap, and most code that uses it, such as:\r\n```\r\nstruct MySubclass {\r\n    char space_for_ndarray[NPY_SIZEOF_PYARRAYOBJECT];\r\n    int myslot;\r\n}\r\n```\r\nis probably problematic and most likely not be binary compatible with all numpy versions.  So it gives a false sense security?",
        "createdAt" : "2020-11-23T23:24:20Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "c251d156-f37c-4603-8238-faebca162d89",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I don't see why, it is defined at compile time just as before. The API is changed anyway, so apps compiled against 1.20 are not guaranteed to be backwards compatible.",
        "createdAt" : "2020-11-23T23:32:23Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "ecb6a3b8-cdbc-41b5-b07e-2a0d9778e36f",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "And code that extends NumPy internals has never been guaranteed to be forward compatible.",
        "createdAt" : "2020-11-23T23:34:33Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "b715940e-58c1-4fa3-940e-6987df82e878",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "True, this is only interesting for forward compatibility with possible future size changes.  I would have a faint hope that it may help someone realize that since their module doesn't compile on 1.20+, it has to be modified even if you compile it with an earlier version to run in 1.20+...\r\n\r\nI agree, we probably never promised not to modify struct sizes in this way, we have certainly done with many structs (aside from `ndarray` itself).\r\n\r\nThe first version here, I replaced the macro with `PyArray_Type.tp_basicsize` to make it a runtime constan, which is safe and will still fail if used for static sizes. (It is also probably a pretty useless macro, but...)",
        "createdAt" : "2020-11-23T23:42:40Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "033bb43e-126b-493b-9fbf-039723e44dae",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I suppose the argument is to break the compilation of downstream apps that extend the structure, but if they are compiling against 1.20 they cannot expect to be backwards compatible in any case, and their solution would be the same workaround you use here. ",
        "createdAt" : "2020-11-23T23:45:34Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "c1b58b22-ebba-4d71-80dc-bde7bd1f30a6",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "This macro is misleading, since its name seems to guarantee it will faithfully return the size of the struct, but it cannot do so at compile time. Hopefully people who use `PyArray_Type.tp_basicsize` will realize they can only do so at runtime. Removing the macro seems like a good way to signal to people who might have been using it - \"don't do that\".",
        "createdAt" : "2020-11-24T06:23:08Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "0f2483d0-3e03-4b84-801a-5a7df5683411",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "> but it cannot do so at compile time.\r\n\r\nCould you explain that? `sizeof` is a compiler operator.\r\n\r\n> Sizeof is a much used operator in the C or C++. It is a compile time unary operator which can be used to compute the size of its operand.",
        "createdAt" : "2020-11-24T15:17:46Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "c1c99dfb-3566-4ee6-94ed-49726e07f211",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "But someone who uses this macro currently will incorrectly believe that their code is forward compatible. They are even avoiding the \"deprecated API\" to ensure binary compatibility with a potential NumPy release messing with the structs internals.",
        "createdAt" : "2020-11-24T16:01:41Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "1fd26a71-d0a8-4626-a57e-a3676cde3ce6",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Why not just rename it then? Put an underscore on it or something. ",
        "createdAt" : "2020-11-24T17:11:42Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "9352c529-cc07-4397-83be-1546188db20c",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "At least just comment it out with an explanation of why it is done. The first place people will look for an explanation of trouble will be in the include file.",
        "createdAt" : "2020-11-24T17:19:35Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "ab08cb96-5f5e-41c0-a826-4165352f7230",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "OK, let me make this macro a static assert as Matti posted.  Even if a compiler should not support it the compiler error will point to some text regarding to what is going on...",
        "createdAt" : "2020-11-24T17:48:53Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "47c6583e-cf66-44ab-86ed-3bee5b2f96fa",
        "parentId" : "3716a943-eb1d-41c1-bb58-99d1b966db6f",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Hmm, although, I am not sure that actually compiles well always (i.e. without super confusing things). The stack-overflow posts seem to a be a bit unsure about it. Some people seem to suggest the weird:\r\n```\r\nstatic int assert_NPY_SIZEOF_PYARRAYOBJECT_was_removed_because_it_is_misleading_see_1_20_Release_Notes[-1]\r\n```\r\ninstead, which is weird, hmmmpf.",
        "createdAt" : "2020-11-24T17:58:41Z",
        "updatedAt" : "2020-11-26T06:06:54Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a216c5b3508a2c9c62a4e37c133350832ce26f86",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +734,738 @@ */\n\n\n/* Array Flags Object */\ntypedef struct PyArrayFlagsObject {"
  },
  {
    "id" : "08b8ca3a-04c6-4795-8305-091f8d1b7dfb",
    "prId" : 17137,
    "prUrl" : "https://github.com/numpy/numpy/pull/17137#pullrequestreview-475209980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8cc73f7d-1008-421c-9251-cc21f0de35ed",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "In a follow-on PR it would be nice to move this out of public headers, it is guarded by `NPY_INTERNAL_BUILD` anyway.",
        "createdAt" : "2020-08-26T07:11:17Z",
        "updatedAt" : "2020-09-02T18:43:06Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      }
    ],
    "commit" : "b40f6bb22d7e71533e0b450493530e8fdd08afa5",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1903,1907 @@    };\n\n#endif  /* NPY_INTERNAL_BUILD */\n\n"
  },
  {
    "id" : "a37b5c7d-b750-4235-87d0-5b02cd76f9c5",
    "prId" : 17401,
    "prUrl" : "https://github.com/numpy/numpy/pull/17401#pullrequestreview-523820843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d68a810-e7a2-4605-aef4-fbcfc2652429",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Thought I had commented here before...  Extending this struct is not ideal, but I like the path of returning the casting safety instead of asserting it (e.g. also allows adding new casting safety levels in theory). Further, indicating when a cast is a view seems helpful (no need to fetch a casting loop).\r\nBut, extending the enum is not ideal for two reasons:\r\n\r\n1. The new fields are not useful for existing API which *requests* a certain casting safety rather than reporting it.\r\n2. I don't want to make this public quite yet.\r\n\r\nSo, not quite sure how to best handle it? A new enum for now?\r\n\r\nThere are two other details:\r\n\r\n1. `NPY_NO_CASTING` should be equivalent to be `NPY_EQUIV_CASTING | NPY_CAST_IS_VIEW).`, the code right now doesn't use that (I had that before, it probably is fine -- Void might have some corner cases, due to weird promotion rules, but right now everything seems to pan out.)\r\n2. An error `-1` return cannot distinguish an impossible cast from a real error without `PyErr_Occurred()`, adding an `NPY_IMPOSSIBLE_CAST` may be better?",
        "createdAt" : "2020-10-17T04:56:37Z",
        "updatedAt" : "2020-11-25T05:20:55Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "b616b510-eb7e-4ca8-a85a-cf3dc7ace43e",
        "parentId" : "0d68a810-e7a2-4605-aef4-fbcfc2652429",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "I think it is fine to add more constants to an enum.",
        "createdAt" : "2020-11-04T06:26:11Z",
        "updatedAt" : "2020-11-25T05:20:55Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "01e63e8d-aa56-4ef6-85b7-410d2d5b6c36",
        "parentId" : "0d68a810-e7a2-4605-aef4-fbcfc2652429",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "The reason why I pointed to it is that this is the only public API change right now.  There is no definitely no issue with extending the enum itself.",
        "createdAt" : "2020-11-04T23:55:31Z",
        "updatedAt" : "2020-11-25T05:20:55Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a806c21f787132525316002926e4780243d948cc",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +228,232 @@         */\n        // TODO-DTYPES: Needs to be documented.\n        _NPY_CAST_IS_VIEW = 1 << 16,\n} NPY_CASTING;\n"
  },
  {
    "id" : "8316ee3e-ec63-4fe5-9f86-2cc8c0194ec8",
    "prId" : 17401,
    "prUrl" : "https://github.com/numpy/numpy/pull/17401#pullrequestreview-523864613",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "873d019e-8653-4b7a-af61-1fe8cbd2d680",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Could you add a comment here about what these are?",
        "createdAt" : "2020-11-04T06:28:34Z",
        "updatedAt" : "2020-11-25T05:20:55Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "002ba2d5-4eee-4d51-bdaf-f7b0f5a45a1b",
        "parentId" : "873d019e-8653-4b7a-af61-1fe8cbd2d680",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Done (I think).",
        "createdAt" : "2020-11-05T02:02:01Z",
        "updatedAt" : "2020-11-25T05:20:55Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a806c21f787132525316002926e4780243d948cc",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1914,1918 @@         * This should potentially become a weak mapping in the future.\n         */\n        PyObject *castingimpls;\n    };\n"
  },
  {
    "id" : "8859a8b4-b375-401b-9ea6-3e1e706ce9d5",
    "prId" : 18987,
    "prUrl" : "https://github.com/numpy/numpy/pull/18987#pullrequestreview-659086672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fdc14349-d305-4c09-8762-1724f4fb2ce8",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Sorry, shouldn't hvae \"dismissed the review\".  This had looked a bit weird to me with all the division (and I missed the modulo later).  I still wonder if there isn't a nicer way to do this. But thats a different issue :).",
        "createdAt" : "2021-05-13T16:32:54Z",
        "updatedAt" : "2021-05-13T16:32:55Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "16295ad1-6d86-48fe-808c-a5ed36bc73b7",
        "parentId" : "fdc14349-d305-4c09-8762-1724f4fb2ce8",
        "authorId" : "5a2c8032-c199-46b2-a971-a4b2d2d63beb",
        "body" : "I copied what GOTO does.",
        "createdAt" : "2021-05-13T16:33:54Z",
        "updatedAt" : "2021-05-13T16:33:55Z",
        "lastEditedBy" : "5a2c8032-c199-46b2-a971-a4b2d2d63beb",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bb9cedac51778e2dcadcd2f26e2d532d306c7c5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1227,1231 @@                     __npy_i++) { \\\n                        _PyAIT(it)->coordinates[__npy_i] = \\\n                                (__npy_ind / _PyAIT(it)->factors[__npy_i]); \\\n                        _PyAIT(it)->dataptr += \\\n                                (__npy_ind / _PyAIT(it)->factors[__npy_i]) \\"
  }
]