[
  {
    "id" : "92282a69-b9ec-471b-b78d-0ed8cbd2886f",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-436790038",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4da84bf8-7b39-48a7-b479-16cab9053f56",
        "parentId" : null,
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "I need to take a deeper look here, but I couldn't understand the purpose of coercion_cache. Having some comments about coercion cache here would be great! ",
        "createdAt" : "2020-06-24T01:19:18Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "8e67d806-5271-4bf9-a692-214a4577089e",
        "parentId" : "4da84bf8-7b39-48a7-b479-16cab9053f56",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Ah OK, the cache is consumed by `PyArray_AssignFromCache`, I should probably just reference that function, since it is the only consumer.  There are few cases were we do not actually need the cache, that could be an improvement to allow passing in `NULL` for the cache to indicate not filling it up.  It should be very simple (also later), will mean a bit of changes to correct for refcounting.",
        "createdAt" : "2020-06-24T14:32:31Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "434f42bc-dbda-463c-b810-4f8eceffc3a5",
        "parentId" : "4da84bf8-7b39-48a7-b479-16cab9053f56",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Added a comment to the function with some details (and expanded the details in `PyArray_DiscoverDTypeAndShape`) admittedly, you probably have to read *both*, let me know if you have thoughts on more explanations!",
        "createdAt" : "2020-06-24T16:00:20Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 884,
    "diffHunk" : "@@ -1,1 +882,886 @@        PyObject *obj, int curr_dims, int max_dims, PyArray_Descr**out_descr,\n        npy_intp out_shape[NPY_MAXDIMS],\n        coercion_cache_obj ***coercion_cache_tail_ptr,\n        PyArray_DTypeMeta *fixed_DType, enum _dtype_discovery_flags *flags)\n{"
  },
  {
    "id" : "12377bf0-f159-4202-9dd7-5b63dc74e69f",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-436815557",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ba9380e-caf9-4926-aaef-58617e600665",
        "parentId" : null,
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "initially i was confused if this was a dtype class or a dtype object. would Dtype_class or Dtype_type make more sense here (probably with a _obj suffix) ?",
        "createdAt" : "2020-06-24T01:23:45Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "87835784-682f-416c-8530-aa1605eb96d3",
        "parentId" : "1ba9380e-caf9-4926-aaef-58617e600665",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Hmmm, I think in most cases I use `descr` currently for the instance and often probably upper case for the class, maybe just making sure it is almost always upper-case for the class? And `descr` in any place its the instance but its unclear?",
        "createdAt" : "2020-06-24T14:29:51Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "7342509f-5ed6-4384-b617-4523f15f91ca",
        "parentId" : "1ba9380e-caf9-4926-aaef-58617e600665",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "since ``descr`` is the convention for instance this is probably fine the way it is.",
        "createdAt" : "2020-06-24T16:35:01Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 146,
    "diffHunk" : "@@ -1,1 +144,148 @@        PyArray_DTypeMeta *DType, PyTypeObject *pytype, npy_bool userdef)\n{\n    PyObject *Dtype_obj = (PyObject *)DType;\n\n    if (userdef) {"
  },
  {
    "id" : "0e6b25da-2caa-4f73-81e3-2a75959523c0",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-437763732",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "parentId" : null,
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "i am quite sure this is not a very important use case , but doesnt look like it handles cases like \r\n```\r\nx[0] = np.datetime64(\"2020-01-01\") \r\n```\r\nwhere x is a string array.",
        "createdAt" : "2020-06-24T22:47:04Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "a81e2482-5451-441c-85e7-ad9d10a37123",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Hmm, can you elaborate on this (or maybe I just need to step through the code)?  This should hit this code with the changes, if it does not, I missed a case where `dtype->setitem` should be replaced with `PyArray_Pack()`, since thats now the defined way to put a scalar into an array (I find it pretty fun that we never had a true correct way to do it).\r\n\r\nI left out a few cases, on purpose, they seemed either corner case, or have well defined input, but this should not be one of them.",
        "createdAt" : "2020-06-25T02:45:46Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "95c311ac-de65-4f0f-a053-f5988b49acee",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "After this code change :\r\n\r\n```\r\n>>> x = np.array([\"qwdqwdqwd\", \"wqdqwd\"])\r\n>>> x[0] = np.datetime64(\"2020-01-01\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nRuntimeError: The string provided for NumPy ISO datetime formatting was too short, with length 9\r\n```\r\n\r\non numpy 1.18.5\r\n\r\n```\r\n>>> import numpy as np\r\n>>> x = np.array([\"qwdqwdqwd\", \"wqdqwd\"])\r\n>>> x[0] = np.datetime64(\"2020-01-01\")\r\n>>> x\r\narray(['2020-01-0', 'wqdqwd'], dtype='<U9')\r\n```",
        "createdAt" : "2020-06-25T03:43:47Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "a7012714-675b-4908-9963-eef97fb6ca30",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "Aah, didnt really pay attention the error message. I guess this is considered one of the fixed bugs of this PR !?",
        "createdAt" : "2020-06-25T03:52:45Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "d095dd15-7a12-4100-9507-40166cd27d2e",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "The reuslt is now consistent with `np.datetime64(\"2020-01-01\").astype(\"U5\"), whether the casting behaviour is ideal, is another question...\r\n\r\nI guess this is reversed to the float64(NaN) case though, because its actually more strict now, hmmmm.  I could fix that, by defining that a datetime64 is a type known to string (and thus handled by `string->setitem`m which calls `str(...)` itself. Or just do that for all `NumPy scalars -> string` conversions, since at least the `__str__` dunder is pretty well defined...",
        "createdAt" : "2020-06-25T15:02:41Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "933c4df1-182b-46a0-aace-65ead66c9f1e",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Oh, and I have to relax it for `np.array(np.datetime64(\"2020-01-01\"), \"U9\")` as well...",
        "createdAt" : "2020-06-25T15:56:55Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "6fd098d6-14fb-4ef1-8ae0-0ce23ea773e9",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "> The reuslt is now consistent with `np.datetime64(\"2020-01-01\").astype(\"U5\"), whether the casting behaviour is ideal, is another question...\r\n\r\naah got it.\r\n\r\n> I could fix that, by defining that a datetime64 is a type known to string (and thus handled by string->setitemm which calls str(...) itself.\r\n\r\nsorry not familiar with all the code here. how will this change look on PyArray_pack side ? currently it calls DATETIME_setitem in this line \r\n\r\n```\r\n      if (tmp_descr->f->setitem(value, data, &arr_fields) < 0) {\r\n```\r\n\r\nwill this change somehow ?\r\n\r\n> Or just do that for all NumPy scalars -> string conversions, since at least the __str__ dunder is pretty well defined...\r\n\r\nThis sounds reasonable to me. So `np.datetime64(\"2020-01-01\").astype(\"U5\")` will also not error now right ? not sure about the backward compatibility and deprecation cycle though, since this is a behavior change. ",
        "createdAt" : "2020-06-25T17:51:41Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "e7bf9a3e-c16d-4510-ba6c-4607a22bfa4a",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I just pushed that change, I am starting to be unwilling to squabble about whether or not this is small enough to just document as a change.  Normally, I would say deprecate, but I am starting to wear down, there are too many of these tiny things making it hard to focus on the big picture.  It is super difficult to fix the big picture while retaining behaviour that was never well defined :/.\r\n\r\n(not to say it isn't important to undo it for now to be on the safe side)\r\n\r\nSorry: And as the explentation. For `PyArray_Pack()` the change in the code path is that it will hit:\r\n```\r\nString->is_known_scalar_type(datetime64)\r\n```\r\nand unlike before it now returns `True` and thus it calls `String->setitem(datetime64)`, instead of using\r\n```\r\nDatetime->setitem(...).astype(\"S6\")\r\n```\r\ninternally (i.e. using the `Datetime` setitem to convert the scalar into an \"array\" (so to say)).",
        "createdAt" : "2020-06-25T18:07:08Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "3ff40854-3274-4ee9-95a0-a7311dcce3fe",
        "parentId" : "837fc56c-93f5-4564-a069-4c8aca6f8149",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "Thanks for the explanation, this sounds good to me,  and agreed we should get rid of the inconsistency with `np.datetime64(\"2020-01-01\").astype(\"U5\")`  in the future.",
        "createdAt" : "2020-06-25T18:42:55Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 431,
    "diffHunk" : "@@ -1,1 +429,433 @@ */\nNPY_NO_EXPORT int\nPyArray_Pack(PyArray_Descr *descr, char *item, PyObject *value)\n{\n    PyArrayObject_fields arr_fields = {"
  },
  {
    "id" : "7a906e13-18ba-4d7d-9336-068690dcc073",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-437740440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d727561e-2692-4569-b190-9c324574afd7",
        "parentId" : null,
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "is this something that is not implemented yet ? asking because \r\n\r\n```*out_DType = NULL;\r\n*out_descr = NULL;\r\n```\r\nwhich doesn't seem to be consistent with this.",
        "createdAt" : "2020-06-25T00:10:03Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "5423216c-9630-4805-bd26-880d4e786903",
        "parentId" : "d727561e-2692-4569-b190-9c324574afd7",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "The one branch that sets it, first sets `out_DType`?  The up-front NULL'ing is probably unnecessary (would have to put an `else` instead I guess. ",
        "createdAt" : "2020-06-25T02:54:23Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "d505d12c-e8df-4a2a-b79e-1d719b3075e4",
        "parentId" : "d727561e-2692-4569-b190-9c324574afd7",
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "> The one branch that sets it, first sets `out_DType`? The up-front NULL'ing is probably unnecessary (would have to put an `else` instead I guess.\r\n\r\nI  was assuming that if ``out_descr`` is set by caller then the out_DType should be accordingly set, but maybe there is no need for that use case to be supported here ?",
        "createdAt" : "2020-06-25T17:56:55Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "643d88f7-8838-42de-910e-e94e82c9a1b5",
        "parentId" : "d727561e-2692-4569-b190-9c324574afd7",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Oh, the user is only supposed to pass in `dtype` here. I guess its different from the discovery function, where it is possible to pass in a \"starting\" dtype because we use it in a few places.  Maybe a few words in the `@param`'s would help?",
        "createdAt" : "2020-06-25T18:11:26Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 1336,
    "diffHunk" : "@@ -1,1 +1334,1338 @@ * Given either a DType instance or class, (or legacy flexible instance),\n * ands sets output dtype instance and DType class. Both results may be\n * NULL, but if `out_descr` is set `out_DType` will always be the\n * corresponding class.\n *"
  },
  {
    "id" : "173bb752-2c45-4300-b29e-f6c04b46de54",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-437134271",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47dfee5f-3604-41d8-b161-f669f9e130f0",
        "parentId" : null,
        "authorId" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "body" : "in my opinion this should be useful!",
        "createdAt" : "2020-06-25T01:22:51Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "fe664d20-2239-4242-9bd1-2c7a4f010863",
        "tags" : [
        ]
      },
      {
        "id" : "10c93cf1-5079-4eb5-bc06-b5fefe06df75",
        "parentId" : "47dfee5f-3604-41d8-b161-f669f9e130f0",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "We could support it in coercion.  In general, I think its nicer to just use types (e.g. float32 -> S32, etc.) without looking at values (that also gives type safety).  For coercion, looking at values can be nice I guess, within ufuncs I am not sure. It feels like it just creates complexities that are probably unnecessary.\r\nYou can always create a small utility functions to do most of these things.  But yes, I guess it is a plausible addition, but I am not keen rushing it :).  I could make the comment less judgmental ;)",
        "createdAt" : "2020-06-25T02:51:31Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 790,
    "diffHunk" : "@@ -1,1 +788,792 @@         *       This is value based casting!\n         * Unless of course we actually want to support this kind of thing\n         * in general (not just for object dtype)...\n         */\n        PyArray_DatetimeMetaData meta;"
  },
  {
    "id" : "8be50c68-ddd2-40c7-8ac2-72aabf3685e2",
    "prId" : 16200,
    "prUrl" : "https://github.com/numpy/numpy/pull/16200#pullrequestreview-438469786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "parentId" : null,
        "authorId" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "body" : "Will this hold onto references forever? What about type factories and so on, where this could get arbitrarily large?",
        "createdAt" : "2020-06-26T11:48:07Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "tags" : [
        ]
      },
      {
        "id" : "35d7b9dd-7e0e-4dc7-b523-fdf63db6c36e",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Yes, should I expand the comment at the top of the function?\r\n\r\nObviously that is not ideal, but you _could_ do a weak mapping eventually. Unfortunately, I think you may also need circular reference resolution to really support thing (or possibly tie the live-span to the python type using a weakref, although then you need to do it even when the DType is not part of this mapping).\r\n\r\nLets be clear, there is a natural ref-cycle between type<->DType I have mentioned often I feel. And if someone has a genius solution to it, I am all ears. But, I am not smart enough to resolve it directly.\r\nBoth DType and type must keep each-other alive (usually) after all, the only way to try and resolve it would be cramming the dtype into the type itself (requiring to modify the type) and making dtypes without a clear type possibly weird (you don't have to be part of this mapping).  Plus it would require that the user creates two classes instead of one, because generally, you still need to extend the dtype storage anyway.",
        "createdAt" : "2020-06-26T13:54:21Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "a49c1cbd-ad3f-40d8-9133-66ca025903a8",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "To be clear, there may not be a good solution, and it boils down to *how* we add things to this mapping in the end.  The mapping can be weak (in most cases), but to resolve dynamically created `pytype<->DType` pairs, you must use cyclic garbage collection.\r\nSo when you add something to the mapping for a dynamically created pytype, things are different. And we could force the user to attach a reference of their `DType` to the `type` in the process (however exactly) to allow adding it to this map (or generally lookup).  That is clean *for dyncamically created pytypes*.  For most heaptypes, we could probably just do that even, since we can inject `__associated_numpy_DType__` into their dict, thus automatically enabling cyclic reference counting.  And maybe that is already a nice solution, just use cyclic refcounting and then allow it to resolve `DType<->pytype` pairs (if their are heaptypes).  I guess it may be a user has `__slots__` or so to make their type read-only, that would be their problem then, its a *much* simpler update then having to create a pair of classes to begin with IMO.  I honestly feel the mental load of having a single Pytype+DType is pretty high, but maybe there is a nice way to formalize it that makes it all clear in a whizz.\r\n\r\nEverything else would require the DType to live on the pytype to begin with (always), there could be no `DType` class as such, it would need to refer for everything to the pytype through lookup on the instance or so).  That seems complicated to me, but maybe I am missing some great pattern here.  The trick would be that the DType class is light-weight, and does not know about the pytype, only its instances do.",
        "createdAt" : "2020-06-26T15:03:33Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "6de19a5c-b4a9-475c-b944-383a025d3af0",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "body" : "The solution to break refcount cycles is to make one of the links in the cycle a weakref, as suggested. I'm okay with cycles, just not okay with a global dict that lives forever. The issue is very practical... Suppose one writes the following code with `a = 1 meter` (and assuming each new unit is a new dtype)\r\n```\r\nb = 1\r\nfor i in range(500):\r\n    b *= a\r\n```\r\n\r\nIn this case you have 500 new dtypes being stuck in this dict forever, 499 of them useless.",
        "createdAt" : "2020-06-26T15:30:09Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "tags" : [
        ]
      },
      {
        "id" : "bddea3f3-1e78-484a-b5f4-3c7c2366f858",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I will add a paragraph on this to NEP 42, with the dunder ~method~ attribute solution.  The mapping will have to be complicated, but that is a technical ~program~ problem that can be adjourned for a very long time.  Hell, I quite frankly think it is fine to release with this as a \"known bug\" (but fixable) that dynamically created `pytype<->DType` *pairs* are immortal.\r\n\r\nEDIT: Jeesh, need more coffee...",
        "createdAt" : "2020-06-26T15:32:02Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "13503bab-6b57-4f56-8415-a401db19e675",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "@hameerabbasi no, it is *not* that simple, and this type of unit is *not* an issue or relevant here unless you also create `meter_scalar(3)` and want `np.array(meter_scalar(3))` to automatically go to your new dtype.  That is *not* how the NEP describes you should be doing it, there are parametric dtypes for a reason.\r\n\r\nIt is far less practically important than you think, I frankly believe.  Each new unit is a new *dtype instance*, making each new unit a new DType is very impractical on many levels.  I.e. ufunc loop lookup/casting would have to be defined for some kind of super-class and than figure out how it works for that subclass?\r\n\r\nThere are imaginable use-cases. E.g. an `Enum` DType for `Enum` types (which are metaclasses). But, quite honestly, I think `unit` is a contrived one (show me an example of someone putting the unit on the *class* and not on the instance).  And except `Enum` I cannot think of any actual use-case (Categorical does not count, because its polymorphic(?) enum, there is no actual type to it).\r\n\r\nSo, yes its important, but its not *central* to any serious use-case I am aware of, such as Units, DNA, special integers, masked integers, datetimes, ...",
        "createdAt" : "2020-06-26T15:39:58Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "a0b49a29-858c-4a21-b969-b289c4fd9226",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "body" : "Ah, if the instance is not cached then it’s fine I guess. Parametrised dtypes are good enough.",
        "createdAt" : "2020-06-26T15:43:18Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "tags" : [
        ]
      },
      {
        "id" : "2c8c2be1-9a82-4d01-afee-01d4ec8c6625",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Yeah, I *really* want it to be resolvable at least in theory in the future though, so thanks for prodding me towards the \"just add a special attribute\" to the python type when/if registering to be discoverable like this.  It seems like a reasonable solution to me, and simple to understand for an implementor:  They get an error \"making `np.array(scalar)` without dtype work, requires numpy to add `__associated_array_dtype__` to the type, this failed\".  Would be good to enforce it from the start when we have public API (even if we may not fully support it immediately).",
        "createdAt" : "2020-06-26T15:54:37Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "3b3779f3-3c0c-4108-8036-a82e34036ae7",
        "parentId" : "573c9535-c9e9-4bfd-9aae-c58127d125ab",
        "authorId" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "body" : "It would also be good to track this in an issue when this PR gets merged.",
        "createdAt" : "2020-06-26T17:24:35Z",
        "updatedAt" : "2020-07-08T23:39:29Z",
        "lastEditedBy" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "tags" : [
        ]
      }
    ],
    "commit" : "22ee97190db0e2432e21d3d830e04776feb0f0a6",
    "line" : 186,
    "diffHunk" : "@@ -1,1 +184,188 @@    }\n\n    return PyDict_SetItem(_global_pytype_to_type_dict,\n            (PyObject *)pytype, Dtype_obj);\n}"
  },
  {
    "id" : "42f9abe9-2fb0-4d0b-bb1a-a37710f24f9d",
    "prId" : 17706,
    "prUrl" : "https://github.com/numpy/numpy/pull/17706#pullrequestreview-523055371",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9baf65d5-877c-4fde-a4b0-850bef627410",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "parameter description in the comment above needs expanding",
        "createdAt" : "2020-11-04T05:38:15Z",
        "updatedAt" : "2020-11-09T22:08:06Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      }
    ],
    "commit" : "0eab3d0a0b60c960c87365f9e6815e1b2c24ce3d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +609,613 @@static NPY_INLINE int\nhandle_promotion(PyArray_Descr **out_descr, PyArray_Descr *descr,\n        PyArray_DTypeMeta *fixed_DType, enum _dtype_discovery_flags *flags)\n{\n    assert(!(*flags & DESCRIPTOR_WAS_SET));"
  },
  {
    "id" : "75896a87-0e99-4f1e-9145-70b7cc02acbb",
    "prId" : 17706,
    "prUrl" : "https://github.com/numpy/numpy/pull/17706#pullrequestreview-523055371",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a868a21-72e9-45c7-b434-857927919a22",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Here too it seems the documentation does not describe the parameters correctly, so it is difficult to follow the logic.",
        "createdAt" : "2020-11-04T05:40:27Z",
        "updatedAt" : "2020-11-09T22:08:06Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      }
    ],
    "commit" : "0eab3d0a0b60c960c87365f9e6815e1b2c24ce3d",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +671,675 @@        return -1;\n    }\n    if (handle_promotion(out_descr, descr, fixed_DType, flags) < 0) {\n        Py_DECREF(descr);\n        return -1;"
  },
  {
    "id" : "5413ce7c-50d4-465a-8ef4-c937d54b46aa",
    "prId" : 17973,
    "prUrl" : "https://github.com/numpy/numpy/pull/17973#pullrequestreview-549546725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebb0ed0d-a655-455a-856a-c86eaed0ebc9",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "I had this wrong first. Thought I can drop through to handle the scalar with the last fall-back path.  This does not work, because it would break the current usage where we ignore everything from the `__array__` protocol *except* the dtype. (The last fall-back forces object dtype.)",
        "createdAt" : "2020-12-10T19:48:37Z",
        "updatedAt" : "2020-12-10T22:13:44Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "8caabdf36c63098bc5743306df55e2c45b5808e3",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +967,971 @@                }\n                Py_DECREF(arr);\n                return max_dims;\n            }\n        }"
  }
]