[
  {
    "id" : "d8ccb170-47c8-4cec-9f66-3e43eade2957",
    "prId" : 19292,
    "prUrl" : "https://github.com/numpy/numpy/pull/19292#pullrequestreview-695270291",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4ccfd2b-3319-4f53-a596-6c34987c532f",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "Using 0 instead of NULL?",
        "createdAt" : "2021-06-29T16:21:15Z",
        "updatedAt" : "2021-06-29T16:21:16Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "1116a311-0f52-4e9a-98c3-3107c82cf7b7",
        "parentId" : "d4ccfd2b-3319-4f53-a596-6c34987c532f",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I guess `calloc` does that also.",
        "createdAt" : "2021-06-29T16:44:36Z",
        "updatedAt" : "2021-06-29T16:44:36Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f05a46fd4a5d0d9273724bdd950dbf83af8b6df8",
    "line" : 209,
    "diffHunk" : "@@ -1,1 +207,211 @@    else {\n        /* Clear the bucket -- just the value should be enough though. */\n        memset(tb_item, 0, (tb->key_len + 1) * sizeof(PyObject *));\n    }\n"
  },
  {
    "id" : "9402b122-a6ab-4bd2-8671-1c35cd1931b3",
    "prId" : 19292,
    "prUrl" : "https://github.com/numpy/numpy/pull/19292#pullrequestreview-695395715",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71e62d69-54a0-4d0d-8c70-8486aa796737",
        "parentId" : null,
        "authorId" : "1794b506-aeff-4fdc-9354-7fd193f97b33",
        "body" : "Like @charris, I must admit I was surprised by this! I guess one could put `perturb` here and have a `RuntimeError` at the end... Then even if someone overwrote the cache by accident this could never go into an endless loop.",
        "createdAt" : "2021-06-29T18:28:51Z",
        "updatedAt" : "2021-06-29T18:28:51Z",
        "lastEditedBy" : "1794b506-aeff-4fdc-9354-7fd193f97b33",
        "tags" : [
        ]
      },
      {
        "id" : "68679146-984f-4d35-ab86-5dc28fcf4b80",
        "parentId" : "71e62d69-54a0-4d0d-8c70-8486aa796737",
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "Yeah, the loop finishes due to the fact that the table is always partially empty and the perturbation strategy should visit everything eventually (apparently).  IIRC, I had a type bug here when copying from Python that caused an incorrect perturb and the windows CI actually went into the infinite loop.\r\n\r\nSo yeah, its reasonable to be worried about... at least the infinite-loop case is a \"loud\" failure so to speak ;).",
        "createdAt" : "2021-06-29T18:34:34Z",
        "updatedAt" : "2021-06-29T18:34:34Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      },
      {
        "id" : "5cb212d6-f004-427a-bd09-ec08f0720791",
        "parentId" : "71e62d69-54a0-4d0d-8c70-8486aa796737",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "I suppose one could use a for loop to limit the number of iterations. OTOH, this looks like something that is probably in the standard literature somewhere. Last time I implemented a hash table it used a linear search from the collision location, which is (was) also a standard method, but probably doesn't keep entries scattered as well.",
        "createdAt" : "2021-06-29T18:56:23Z",
        "updatedAt" : "2021-06-29T18:56:23Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f05a46fd4a5d0d9273724bdd950dbf83af8b6df8",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +69,73 @@\n    bucket = (npy_intp)hash & mask;\n    while (1) {\n        item = &(tb->buckets[bucket * (tb->key_len + 1)]);\n"
  }
]