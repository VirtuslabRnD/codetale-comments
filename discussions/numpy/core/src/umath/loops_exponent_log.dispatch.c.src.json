[
  {
    "id" : "52fad8e5-d058-49fa-9235-e26ba9af6329",
    "prId" : 18101,
    "prUrl" : "https://github.com/numpy/numpy/pull/18101#pullrequestreview-563349075",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "913cb821-b5c2-4e39-b908-5a0fcaa7847d",
        "parentId" : null,
        "authorId" : "16f8768b-62bb-468a-bef5-f7adfae4fef5",
        "body" : "I'm considering reconstruct `exp/log` by using universal intrinsics so the performance improvement benefits other architecture, but some intrinsics such as `_mm256_mask_i32gather_pd`, `_mm256_blendv_ps`,`_mm512_getmant_ps` is hard to simulate or have a risk to get a slower performance than using scalar.",
        "createdAt" : "2021-01-05T03:23:00Z",
        "updatedAt" : "2021-01-05T03:23:01Z",
        "lastEditedBy" : "16f8768b-62bb-468a-bef5-f7adfae4fef5",
        "tags" : [
        ]
      },
      {
        "id" : "a6a3b5be-bba0-4ad9-999c-2b4a14d00257",
        "parentId" : "913cb821-b5c2-4e39-b908-5a0fcaa7847d",
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "@Qiyu8 is this an actionable review comment on this PR? It seems like more of a general statement of intent, correct?",
        "createdAt" : "2021-01-07T09:20:33Z",
        "updatedAt" : "2021-01-07T09:20:33Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "964a231e-636b-49c7-a71c-82b43a66f8bd",
        "parentId" : "913cb821-b5c2-4e39-b908-5a0fcaa7847d",
        "authorId" : "23ffb2ec-0278-4386-95f5-84cc15ce2cfd",
        "body" : "> but some intrinsics such as _mm256_mask_i32gather_pd, _mm256_blendv_ps,_mm512_getmant_ps is hard to simulate or have a risk to get a slower performance than using scalar.\r\n\r\nwhat do you mean hard to simulate? we already did it except for `_mm512_getmant_ps`\r\n\r\n`*_i32gather_*` ->  `npyv_loadn_*`  and `npyv_loadn_till_*`\r\n`*_i32scatter_*` -> `npyv_storen_*` and `npyv_storen_till_*`\r\n`_mm256_blend*` -> `npyv_select_*`\r\n\r\n> have a risk to get a slower performance than using scalar.\r\n\r\nnative x86 gather and scatter operations are too expensive and the same for the emulated ones, we should use them without specializing only with large kernels. without specializing -> [loops_trigonometric.dispatch.c.src](https://github.com/numpy/numpy/blob/master/numpy/core/src/umath/loops_trigonometric.dispatch.c.src),  with specializing [loops_unary_fp.dispatch.c.src](https://github.com/numpy/numpy/blob/master/numpy/core/src/umath/loops_unary_fp.dispatch.c.src)\r\n\r\n",
        "createdAt" : "2021-01-07T09:50:19Z",
        "updatedAt" : "2021-01-07T10:12:49Z",
        "lastEditedBy" : "23ffb2ec-0278-4386-95f5-84cc15ce2cfd",
        "tags" : [
        ]
      },
      {
        "id" : "4cbb4239-9783-45dd-b43e-c78f4b07e856",
        "parentId" : "913cb821-b5c2-4e39-b908-5a0fcaa7847d",
        "authorId" : "23ffb2ec-0278-4386-95f5-84cc15ce2cfd",
        "body" : "note: `_mm256_blend*` blend operations are \"not\" expensive almost for all SIMD extensions.",
        "createdAt" : "2021-01-07T09:51:36Z",
        "updatedAt" : "2021-01-07T09:51:36Z",
        "lastEditedBy" : "23ffb2ec-0278-4386-95f5-84cc15ce2cfd",
        "tags" : [
        ]
      }
    ],
    "commit" : "d57f9a54539abb285ed66049afa7bc74d6be0774",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +90,94 @@                     __m256d mask)\n{\n    return _mm256_mask_i32gather_pd(src, addr, vindex, mask, 8);\n}\n"
  }
]