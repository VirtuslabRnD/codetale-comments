[
  {
    "id" : "3c468b53-1ced-46be-89d2-1b202bcd6df0",
    "prId" : 13761,
    "prUrl" : "https://github.com/numpy/numpy/pull/13761#pullrequestreview-248907634",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e52c675d-73cf-405d-99c8-08edb189a1d4",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Why does the result change?",
        "createdAt" : "2019-06-12T08:46:56Z",
        "updatedAt" : "2019-06-14T20:14:47Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "afb64ab8-c10e-46f9-a9e7-ed800ff738a0",
        "parentId" : "e52c675d-73cf-405d-99c8-08edb189a1d4",
        "authorId" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "body" : "There was a bug in the old HRUA code that made it less efficient than it should have been.  HRUA is a rejection method, and with the fixed formula, the new code will generally have fewer rejections than the old code.  That means that even with the same bit generator and the same seed, the stream of variates out of the hypergeometric distribution will be different.  I didn't touch the legacy version (other than to move it to legacy-distributions.c), so the variates from the legacy hypergeometric distribution in RandomState haven't changed.",
        "createdAt" : "2019-06-12T17:24:32Z",
        "updatedAt" : "2019-06-14T20:14:47Z",
        "lastEditedBy" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2d2b677c26c8da7052bbc653b20ad9717f078fe",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +900,904 @@        desired = np.array([[9, 9],\n                            [10, 9],\n                            [9, 10]])\n        assert_array_equal(actual, desired)\n"
  },
  {
    "id" : "8dff64fc-0912-43b4-b0a0-3b1e5bb55dab",
    "prId" : 13761,
    "prUrl" : "https://github.com/numpy/numpy/pull/13761#pullrequestreview-248908252",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93163361-44de-4b3c-9be9-b2e53b3c2671",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "Why does the result change?",
        "createdAt" : "2019-06-12T08:47:44Z",
        "updatedAt" : "2019-06-14T20:14:47Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "2bf8d198-1059-465b-9054-eb3ceaa9f8d0",
        "parentId" : "93163361-44de-4b3c-9be9-b2e53b3c2671",
        "authorId" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "body" : "(See my earlier response to the same question about the other test result change.)",
        "createdAt" : "2019-06-12T17:25:44Z",
        "updatedAt" : "2019-06-14T20:14:47Z",
        "lastEditedBy" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2d2b677c26c8da7052bbc653b20ad9717f078fe",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +1876,1880 @@        bad_nsample_two = [4]\n        hypergeom = random.hypergeometric\n        desired = np.array([0, 0, 1])\n\n        self.set_seed()"
  },
  {
    "id" : "c753b129-04c9-49ad-940a-8ba6f5156cfe",
    "prId" : 13812,
    "prUrl" : "https://github.com/numpy/numpy/pull/13812#pullrequestreview-260855186",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e6eee75-9c76-4274-9d53-1a810e8b59af",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "This would be a good place to add a test that shows the use of the `shuffle` kwarg",
        "createdAt" : "2019-07-11T04:07:51Z",
        "updatedAt" : "2019-07-11T17:41:52Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      },
      {
        "id" : "d35fc384-5600-471c-975f-6e4c1125ea7f",
        "parentId" : "3e6eee75-9c76-4274-9d53-1a810e8b59af",
        "authorId" : "687286db-0b77-4674-8126-7050bbcc81ed",
        "body" : "added a test, thanks.",
        "createdAt" : "2019-07-11T17:43:01Z",
        "updatedAt" : "2019-07-11T17:43:01Z",
        "lastEditedBy" : "687286db-0b77-4674-8126-7050bbcc81ed",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e44812c32b6702dc76411c94000bc4ff461890c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +569,573 @@        random = Generator(MT19937(self.seed))\n        actual = random.choice(4, 3, replace=False)\n        desired = np.array([2, 0, 3], dtype=np.int64)\n        assert_array_equal(actual, desired)\n        actual = random.choice(4, 4, replace=False, shuffle=False)"
  },
  {
    "id" : "336cefbb-476c-4386-82e1-0a9079b104da",
    "prId" : 14197,
    "prUrl" : "https://github.com/numpy/numpy/pull/14197#pullrequestreview-303034821",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc2d55bc-6a45-476a-aba2-f09c18e82733",
        "parentId" : null,
        "authorId" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "body" : "I'd add a test for complex numbers as well.",
        "createdAt" : "2019-10-17T06:53:17Z",
        "updatedAt" : "2019-11-03T18:02:42Z",
        "lastEditedBy" : "48239ed9-0e9e-4f16-80c7-12419f1efd99",
        "tags" : [
        ]
      }
    ],
    "commit" : "87840dc2f09ebeed12c3b9fef68b94dc04f4d16f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1199,1203 @@        assert_array_equal(actual, desired)\n\n    @pytest.mark.parametrize(\"method\", [\"svd\", \"eigh\", \"cholesky\"])\n    def test_multivariate_normal(self, method):\n        random = Generator(MT19937(self.seed))"
  },
  {
    "id" : "b327bb63-f90b-4073-a5f8-ddd4207e7f9b",
    "prId" : 14241,
    "prUrl" : "https://github.com/numpy/numpy/pull/14241#pullrequestreview-275306653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f34eeb6-b912-43c1-94c2-c6de225e9bf1",
        "parentId" : null,
        "authorId" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "body" : "This block and the try, except block above should be the only changes in this PR. All the other formatting changes should be reverted.",
        "createdAt" : "2019-08-15T08:09:26Z",
        "updatedAt" : "2019-08-19T21:01:44Z",
        "lastEditedBy" : "919d650d-5f9e-4069-90f7-968e2cf7bb16",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cb88048391a992f9942df42e4aaf4a0df53e494",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +764,768 @@        bad_x_float = 1.2\n        assert_raises(np.AxisError, random.permutation, bad_x_float)\n\n        random = Generator(MT19937(self.seed))\n        integer_val = 10"
  },
  {
    "id" : "7f71b021-c88c-4cac-9b5d-422bdb1ec70e",
    "prId" : 14924,
    "prUrl" : "https://github.com/numpy/numpy/pull/14924#pullrequestreview-320323214",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48a533b1-85a1-4519-875a-c7f1718dce66",
        "parentId" : null,
        "authorId" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "body" : "I appreciate adding whitespace for readability, but I think the space in this array is too much. Maybe something like\r\n\r\n```\r\n        expected = np.array([\r\n            [[1., 0.],\r\n             [1., 0.]],\r\n            [[1., 0.],\r\n             [1., 0.]],\r\n            [[1., 0.],\r\n             [1., 0.]]\r\n        ])",
        "createdAt" : "2019-11-20T00:18:42Z",
        "updatedAt" : "2020-04-28T03:34:46Z",
        "lastEditedBy" : "8de63a41-1bc1-4e93-a2df-4f2f940433cf",
        "tags" : [
        ]
      },
      {
        "id" : "4f3183a0-5ae2-4550-922b-199dc98f52f2",
        "parentId" : "48a533b1-85a1-4519-875a-c7f1718dce66",
        "authorId" : "b6a6a929-2fde-4ea1-acd5-acebd73d7b91",
        "body" : "Fixed according to your suggestions.",
        "createdAt" : "2019-11-20T21:34:33Z",
        "updatedAt" : "2020-04-28T03:34:46Z",
        "lastEditedBy" : "b6a6a929-2fde-4ea1-acd5-acebd73d7b91",
        "tags" : [
        ]
      }
    ],
    "commit" : "6b181c8e607f35b0de1a6a12dd280ddf2bc439f5",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +1060,1064 @@        random = Generator(MT19937(self.seed))\n        actual = random.dirichlet(alpha, size=(3, 2))\n        expected = np.array([\n            [[1., 0.],\n             [1., 0.]],"
  },
  {
    "id" : "d0528d3f-95e2-4743-8cf5-fbada50173bd",
    "prId" : 15872,
    "prUrl" : "https://github.com/numpy/numpy/pull/15872#pullrequestreview-387765997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2614df00-c35e-4460-9e03-cf19e093ddf2",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "It would be better to use a separate test here, say `test_multivariate_normal_stats` or some such, that way you can use a new (seeded) rng and and the stats will be independent of possible changes in other parts of the test. This test will fail about 35 times out of a 1000 if the random stream is random. It will also allow marking it as `@pytest.mark.slow` if we want to do better statistics, currently it is around .6 seconds, which is already a bit slow.",
        "createdAt" : "2020-04-04T19:40:44Z",
        "updatedAt" : "2020-04-05T01:27:48Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "6c2d37c6-4bb7-4a69-b0a1-955cae19bd41",
        "parentId" : "2614df00-c35e-4460-9e03-cf19e093ddf2",
        "authorId" : "75fd9ffc-aedf-446c-8941-530d91a93ad1",
        "body" : "I mean using a fixed seed and checking the samples will do the trick for validating correctness of the formulation. The statistics test is really more and end-to-end integration test. That should really be done in a \"statistical unit testing\" setting where you run the test a bunch of times under a hypothesis test and then see that you get reasonably close to your selected significance level across many runs. But that shouldn't be part of the regular test suite. ",
        "createdAt" : "2020-04-04T21:05:44Z",
        "updatedAt" : "2020-04-05T01:27:48Z",
        "lastEditedBy" : "75fd9ffc-aedf-446c-8941-530d91a93ad1",
        "tags" : [
        ]
      },
      {
        "id" : "59a27145-eb1f-4c74-b24e-218834baf8fe",
        "parentId" : "2614df00-c35e-4460-9e03-cf19e093ddf2",
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "> But that shouldn't be part of the regular test suite.\r\n\r\nI would support adding a validation test suite at some point. But for now we could keep this and move it later. It did uncover the Cholesky problem and would have caught the `eigh` problem.\r\n\r\nThe various random functions were tested for statistical accuracy many years ago, we should really have tests somewhere that we could use to revalidate the results since there have been changes since. Hmm, that could almost be a GSOC project next time that rolls around, not that statistical tests are the least bit trivial but the problem is well stated. Validating the generators themselves might be worth something just to make sure we didn't drop the ball somewhere, after all, there was the buggy generation of low precision integers that we should have caught earlier.\r\n\r\n@bashtage @rkern Thoughts?",
        "createdAt" : "2020-04-04T21:35:11Z",
        "updatedAt" : "2020-04-05T01:27:48Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      },
      {
        "id" : "fa9ebd62-5897-4bcb-bf40-d55914c93df5",
        "parentId" : "2614df00-c35e-4460-9e03-cf19e093ddf2",
        "authorId" : "85b881e8-d8a0-43d4-81d3-7e233dc5f1ae",
        "body" : "Agreed.",
        "createdAt" : "2020-04-04T23:07:20Z",
        "updatedAt" : "2020-04-05T01:27:48Z",
        "lastEditedBy" : "85b881e8-d8a0-43d4-81d3-7e233dc5f1ae",
        "tags" : [
        ]
      }
    ],
    "commit" : "72457f01832d10c72a1839aafc178cf4f53449cb",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1243,1247 @@                      check_valid='raise', method='eigh')\n\n        # check degenerate samples from singular covariance matrix\n        cov = [[1, 1], [1, 1]]\n        if method in ('svd', 'eigh'):"
  },
  {
    "id" : "6f95be06-a94a-4316-8214-6265e1a82fe8",
    "prId" : 15872,
    "prUrl" : "https://github.com/numpy/numpy/pull/15872#pullrequestreview-387766871",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44d47746-a0de-4b8c-ac78-62e0c0421fcc",
        "parentId" : null,
        "authorId" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "body" : "```\r\nrandom = Generator(MT19937(self.seed))\r\n```\r\nOtherwise it uses the global unseeded generator defined at the top of the file. We should probably get rid of that at some point. ",
        "createdAt" : "2020-04-04T23:25:13Z",
        "updatedAt" : "2020-04-05T01:27:48Z",
        "lastEditedBy" : "e6b1ca39-8ea5-45f7-ae52-a080cee1181b",
        "tags" : [
        ]
      }
    ],
    "commit" : "72457f01832d10c72a1839aafc178cf4f53449cb",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +1276,1280 @@        n_s = 1000\n        mean = np.array([1, 2])\n        cov = np.array([[2, 1], [1, 2]])\n        s = random.multivariate_normal(mean, cov, size=(n_s,), method=method)\n        s_center = s - mean"
  },
  {
    "id" : "7c985257-5eb0-44cb-8624-c84eafd8986a",
    "prId" : 16153,
    "prUrl" : "https://github.com/numpy/numpy/pull/16153#pullrequestreview-406342773",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "parentId" : null,
        "authorId" : "601a715b-2061-4116-8c4e-279c9b01b97f",
        "body" : "I'd probably add another test covering the issue I originally opened:\r\n\r\n```py\r\n    { # You already have this one\r\n        \"seed\": 0,\r\n        \"steps\": 10,\r\n        \"initial\": {\"key_md5\": \"64eaf265d2203179fb5ffb73380cd589\", \"pos\":  9},\r\n        \"jumped\": {\"key_md5\": \"8cb7b061136efceef5217a9ce2cc9a5a\", \"pos\": 598},\r\n    },\r\n    { # But don't have this one\r\n        \"seed\": 0,\r\n        \"steps\": 11,\r\n        \"initial\": {\"key_md5\": \"64eaf265d2203179fb5ffb73380cd589\", \"pos\": 10},\r\n        \"jumped\": {\"key_md5\": \"8cb7b061136efceef5217a9ce2cc9a5a\", \"pos\": 599},\r\n    },\r\n```\r\n\r\nThe added test ensures that we have the following behaviour:\r\n`jump(next(mt19937)) == next(jump(mt19937))` - _or something close_",
        "createdAt" : "2020-05-04T17:52:25Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "601a715b-2061-4116-8c4e-279c9b01b97f",
        "tags" : [
        ]
      },
      {
        "id" : "c6927342-5858-4629-b949-305f0f717bcd",
        "parentId" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "authorId" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "body" : "The only guarantee that I think we should try and make is that the code is faithful to the original author's code.  Whether this is true or not I think is a different issue.",
        "createdAt" : "2020-05-04T21:38:35Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "tags" : [
        ]
      },
      {
        "id" : "999fea6f-6f25-42cc-90a2-8c65719413f6",
        "parentId" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "authorId" : "82de5832-492d-4fea-8570-cdc36128aabe",
        "body" : "If I understand it correctly, the test you propose will not work (in the current implementation / original authors source code) / tried it out and it didn't work:\r\n\r\n> `jump(next(mt19937)) == next(jump(mt19937))` - _or something close_\r\n\r\nHowever, if this is the case, then I don't think that this pull request closes  #15394, does it?\r\nOr put it the other way around: With the current state of the PR, shouldn't the [documentation](https://numpy.org/doc/stable/reference/random/bit_generators/generated/numpy.random.MT19937.jumped.html?highlight=numpy%20random%20mt19937%20mt19937%20jumped#numpy.random.MT19937.jumped) be adopted too?\r\n\r\nCurrent documentation:\r\n> The state of the returned big generator is jumped as-if 2**(128 * jumps) random numbers have been generated.\r\n\r\nOn this note:\r\n> The only guarantee that I think we should try and make is that the code is faithful to the original author's code. Whether this is true or not I think is a different issue.\r\n\r\nTo what extend is this the policy? I totally understand that you may not have the time to check that all implementation are \"true\" - but still I think it's worrisome if the random generator behaves in a way we don't understand. So what should the documentation of jump say? If I exaggerate a little: *the original author claims that it is as if 2**(128 * jumps) *random numbers have been generated; but when we test it, that it not true*`",
        "createdAt" : "2020-05-05T20:16:05Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "82de5832-492d-4fea-8570-cdc36128aabe",
        "tags" : [
        ]
      },
      {
        "id" : "65082069-ffc8-4629-ae4a-0cf8f495a476",
        "parentId" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "authorId" : "82de5832-492d-4fea-8570-cdc36128aabe",
        "body" : "Another note: Shall we implement the same type of test\r\n\r\n> `jump(next(mt19937)) == next(jump(mt19937))` - _or something close_\r\n\r\nin the tests for  `PCG64`? There it should pass; but nice to have this ensured for the future, too.",
        "createdAt" : "2020-05-05T20:56:29Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "82de5832-492d-4fea-8570-cdc36128aabe",
        "tags" : [
        ]
      },
      {
        "id" : "77cdc4fd-1f93-4ad4-bcaa-c5328a07a36f",
        "parentId" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "authorId" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "body" : "Depends on what the point of #15394 is.  If it is to check the implementation, then I think this PR closes that.  If it is to make jumped work in a way different from the original code, then it does not.  I don't think the latter is realistic.",
        "createdAt" : "2020-05-05T22:23:43Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "tags" : [
        ]
      },
      {
        "id" : "d065ec00-1e23-4181-a865-f487c7a1d504",
        "parentId" : "1cfb0ec0-5d44-465d-9322-dcf91425eceb",
        "authorId" : "601a715b-2061-4116-8c4e-279c9b01b97f",
        "body" : "My original point when opening the issue was the following:\r\n\r\nAs a user of the library I saw that the jump was supposed to offset by a fixed number of iterations. So my expectation and the reason why I opened the issue was `jump(next(mt19937))` should always be the same as `next(jump(mt19937))` - _or at least we might somehow be able to find the same sequence close enough as we should jump very close in both cases_. If it is not the case it seems problematic as it looks like the `2**128` skipped iterations are not true so I cannot safely rely on a jump if we don't know where it jumps.\r\n\r\nActually I found this issue while implementing a jump for mersenne twister on a [JavaScript library I am maintaining](https://github.com/dubzzz/pure-rand/pull/12). I already had a working implementation of the mersenne generator but needed a reference one for the jump to compare my results to it. So I compared it to the jump of numpy. In the set of tests, I use on my generators [one of them](https://github.com/dubzzz/pure-rand/blob/d3fa7faa517c13fd4315f4135de91179dde2f02d/test/unit/generator/RandomGenerator.properties.ts#L34-L43) - _based on property based testing (see [hypothesis](https://hypothesis.works/) for Python)_ - checks that: `jump(next(generator)) == next(jump(generator))`. And here is how I found the problem.",
        "createdAt" : "2020-05-06T06:53:54Z",
        "updatedAt" : "2020-05-12T22:27:30Z",
        "lastEditedBy" : "601a715b-2061-4116-8c4e-279c9b01b97f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ac72f8d63e8d5522b680758a3d6537ab722cabd4",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +15,19 @@random = Generator(MT19937())\n\nJUMP_TEST_DATA = [\n    {\n        \"seed\": 0,"
  },
  {
    "id" : "3bd37372-bcf8-48f5-85e4-f34fe95f749a",
    "prId" : 17921,
    "prUrl" : "https://github.com/numpy/numpy/pull/17921#pullrequestreview-546435509",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d48a4a07-d436-427c-a271-63dc8859e098",
        "parentId" : null,
        "authorId" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "body" : "```suggestion\r\n        assert_raises(ValueError, func,  [[0, 1], [2, 3]], 2)\r\n```",
        "createdAt" : "2020-12-07T18:48:43Z",
        "updatedAt" : "2020-12-11T15:31:20Z",
        "lastEditedBy" : "b0342685-bd89-441f-a04f-0e75db24c07f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3bb19df580454a6b98c34e29a00c271c2e411af",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1680,1684 @@        assert_raises(ValueError, func, 2, 1)\n        assert_raises(ValueError, func,  [1, 2], [1, 1])\n        assert_raises(ValueError, func,  [[0, 1],[2, 3]], 2)\n\n    def test_scalar_exception_propagation(self):"
  },
  {
    "id" : "392c3594-5692-4434-9f57-bd0a8fdc3905",
    "prId" : 18498,
    "prUrl" : "https://github.com/numpy/numpy/pull/18498#pullrequestreview-599833711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3317126f-a53d-4901-beeb-4bc992b108e4",
        "parentId" : null,
        "authorId" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "body" : "I think that coverage is a bit suspicious.  I added this test to ensure that all code paths are hit.",
        "createdAt" : "2021-02-26T18:26:25Z",
        "updatedAt" : "2021-02-26T18:43:02Z",
        "lastEditedBy" : "b15cf1a1-ba9d-47aa-b157-e0c1f40c5c5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa529592b33262bb9fdd73df3b493a3d3cf2e392",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1755,1759 @@        r = random.vonmises(mu, kappa, 50)\n        assert_(np.all(r > -np.pi) and np.all(r <= np.pi))\n\n    def test_wald(self):\n        random = Generator(MT19937(self.seed))"
  }
]