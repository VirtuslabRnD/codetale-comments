[
  {
    "id" : "997d6cb9-3e93-48b0-8a15-0814e4aaf8b0",
    "prId" : 9223,
    "prUrl" : "https://github.com/apache/airflow/pull/9223#pullrequestreview-428817002",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "@potiuk Why we need docker here? I don't think that is necessary.",
        "createdAt" : "2020-06-11T08:36:52Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "dc676d36-6b33-46de-be84-be1e4fd14835",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Because those files are owned by root  and this way we get root access to those files and can change the ownership. Otherwise you need to use sudo and provide password.  This is much more convenient.",
        "createdAt" : "2020-06-11T09:57:18Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "b9fd6346-3e32-4d9b-949d-9811cfdfeea9",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "But we run this script in the container. Do we have to run the container in the container? I think breeze uses root by default, so it should work. This is a problem if the script would be run by the host but it is not. This script is run in the container.\r\n\r\n```\r\nroot@09797f7fa137:/opt/airflow# id\r\nuid=0(root) gid=0(root) groups=0(root)\r\n```\r\n\r\n",
        "createdAt" : "2020-06-11T10:03:04Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "92bf284b-fd92-4bdd-a9a1-37973b808010",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "ah yeah . Silly me.  indeed we run it from the container :)",
        "createdAt" : "2020-06-11T10:16:53Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "bcdc2ac8-f6de-443d-856e-0dd265970639",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "> > Why /root/ here ? The volumes are mapped from host not from the container because we are using the same engine that is in the host\r\n> \r\n> We use these paths to determine which directories to fix, but we do it in the container, so we need to use the path from the container. Saying differently, these paths are used in scripts that run in the container.\r\n\r\nOnce we run it no via another container (I need some rest) - then yes\r\n",
        "createdAt" : "2020-06-11T10:21:34Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "f2f58295-e377-4ae9-afbf-dd084208313a",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "But ..... it makes sense, because we mount additional volumes with credentials. The main container cannot access them. No container should have access to them unless ``--forward-credentials`` flag is passed, but that's another problem. I want to take care of them later. ",
        "createdAt" : "2020-06-11T10:23:56Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "bc8c4e6d-aa63-41ad-9926-d04d1c2ad88e",
        "parentId" : "e9ed49ef-55dd-4a00-aa23-52e9a05afe26",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Ah.Ok. Now I remember why I did that indeed (tired again). I wanted to make sure that this works without --forward-credentials at all.. \r\n\r\nThere is no reason why we should not forward credentials to the official gcloud/ aws/ etc. tools . Forwarding credentials just to those tools is equivalent to running them locally, so there is no risk. So indeed both running docker and using HOME made sense from the start.",
        "createdAt" : "2020-06-11T11:20:44Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "cde5a7e348a5466d09faf5ea7d3f9f017a59757f",
    "line" : 164,
    "diffHunk" : "@@ -1,1 +162,166 @@        \"find ${DIRECTORIES_TO_FIX[@]@Q} -user root -print0 | xargs --null chown '${HOST_USER_ID}.${HOST_GROUP_ID}' --no-dereference\")\n\n    docker run \"${FIX_DOCKER_ARGS[@]}\" \"${AIRFLOW_CI_IMAGE}\" \"${FIX_COMMAND[@]}\" >/dev/null 2>&1\nfi\n"
  },
  {
    "id" : "266a7816-b691-4fed-9c36-5a12f7cb06ed",
    "prId" : 9223,
    "prUrl" : "https://github.com/apache/airflow/pull/9223#pullrequestreview-428711730",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c690b5e4-95f6-4c1c-bbd2-4618706910f6",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "```suggestion\r\nif [ -z \"${HOST_AIRFLOW_SOURCES}\" ]; then\r\n    echo \"Missing environment variable HOST_AIRFLOW_SOURCES\"\r\n    exit 1\r\nfi\r\nif [ -z \"${HOST_USER_ID}\" ]; then\r\n    echo \"Missing environment variable HOST_USER_ID\"\r\n    exit 1\r\nfi\r\nif [ -z \"${HOST_GROUP_ID}\" ]; then\r\n    echo \"Missing environment variable HOST_GROUP_ID\"\r\n    exit 1\r\nfi\r\n\r\n```",
        "createdAt" : "2020-06-11T08:45:21Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "cde5a7e348a5466d09faf5ea7d3f9f017a59757f",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +35,39 @@    exit 1\nfi\n\nSCRIPT_NAME=\"$( basename \"${BASH_SOURCE[0]}\")\"\n# Drop \"-update\" suffix, if exists"
  },
  {
    "id" : "a8146d23-1ec2-408c-aaee-e04478f4802f",
    "prId" : 9223,
    "prUrl" : "https://github.com/apache/airflow/pull/9223#pullrequestreview-428771187",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "```suggestion\r\nCONTAINER_ID=\"$(head -n 1 < /proc/self/cgroup | cut -d \":\" -f 3 | cut -d \"/\" -f 3)\"\r\n\r\nCOMMON_DOCKER_ARGS=(\r\n    # Share namespaces between all containers.\r\n    # This way we are even closer to run those tools like if they were installed.\r\n    # More information: https://docs.docker.com/get-started/overview/#namespaces\r\n    --ipc \"container:${CONTAINER_ID}\"\r\n    --pid \"container:${CONTAINER_ID}\"\r\n    --network \"container:${CONTAINER_ID}\"\r\n```\r\n@feluelle @potiuk What do you think about it? The Dataflow tasks start the java container. I would like to be able to see if this process was actually started.",
        "createdAt" : "2020-06-11T09:01:26Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "798d9718-bd38-47e9-a79e-be9f4c601ed6",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "Why do you think this is necessary? Can we not go just for the exit code?",
        "createdAt" : "2020-06-11T09:11:08Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "242a605a-210e-4254-855d-1f5969130165",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "Should we care / monitor the processes inside?\r\n",
        "createdAt" : "2020-06-11T09:11:49Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "63dbfca0-bdf0-49f1-90bc-de40d43971d8",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "In my opinion this sounds more like kind of a debugging functionality rather than functionality we need to kick off those cli's. ",
        "createdAt" : "2020-06-11T09:14:19Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "0dceb8a2-76e0-4f77-9188-0082883a4255",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I run a long-running process using Airflow and I just want to be able to do \"ps -aux\" to see what process it is The exit-code is not enough, because sometimes the container hangs or runs an interactive terminal. In this situation, I don't have any logs, because the process is waiting for actions from the user.\r\n\r\n",
        "createdAt" : "2020-06-11T09:15:19Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "a4f1606d-b637-46f1-93c3-6a67aee8be35",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "+0. What about you Jarek?",
        "createdAt" : "2020-06-11T09:16:13Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "9abb1e03-1ac9-4bb3-ac87-429c7c8043c9",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Real example:\r\nI working system tests for DataflowCreateJavaJobOperator operator. This operator starts the java process to submit Dataflow job,  This operation may take a while, because it must send the necessary files to Google. Then it waits for the Job ID to appear in the log. If I have problems with the process, I don't have a simple tool to see the whole system situation. I need to check individual containers to check situations. Previously, I could run the `ps -aux` command and see that I have` pytest`, `local task job`,` dataflow`, and others running.  I don't think anyone needs this insulation here.  For a developer, this makes work difficult. For a production environment, this is an important safeguard.",
        "createdAt" : "2020-06-11T09:24:15Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "5bab71da-581e-474e-87ac-04b771ea5709",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "I see. This then makes totally sense.",
        "createdAt" : "2020-06-11T09:39:43Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "5df15f37-1398-409d-8e7f-8025f438f0b3",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "Side note: rename `COTAINER_ID` to `CONTAINER_ID`",
        "createdAt" : "2020-06-11T09:47:45Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "c6be6bf3-021f-480f-b66b-3907a8e9db05",
        "parentId" : "031a13de-9e07-4a9c-af19-90edd71fa7f6",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Ye. COTAINER_ID shoudl be renamed. And yes - using the same namespace, ipc and network makes sense - this way we are even closer to run those tools  like if they were installed.\r\n\r\nIt would be nice to add comment about why we are doing it though - those are very rarely used switches ",
        "createdAt" : "2020-06-11T10:07:12Z",
        "updatedAt" : "2020-06-11T15:44:06Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "cde5a7e348a5466d09faf5ea7d3f9f017a59757f",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +69,73 @@CONTAINER_ID=\"$(head -n 1 < /proc/self/cgroup | cut -d \":\" -f 3 | cut -d \"/\" -f 3)\"\n\nCOMMON_DOCKER_ARGS=(\n    # Share namespaces between all containers.\n    # This way we are even closer to run those tools like if they were installed."
  }
]