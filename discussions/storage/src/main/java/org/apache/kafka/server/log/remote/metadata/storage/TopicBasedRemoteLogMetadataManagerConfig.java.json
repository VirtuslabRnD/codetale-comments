[
  {
    "id" : "6bbce1dd-0638-4914-b49a-e1350c8d14f8",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-680441493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0df1dba-bf3e-4855-a33e-47a5745606a7",
        "parentId" : null,
        "authorId" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "body" : "Do we need this? It seems that it's easier to just duplicate the property for producer and consumer.",
        "createdAt" : "2021-05-27T23:26:54Z",
        "updatedAt" : "2021-05-28T01:23:55Z",
        "lastEditedBy" : "442b5138-0781-4001-8ac5-0593f2136d1c",
        "tags" : [
        ]
      },
      {
        "id" : "981a9907-316a-4005-a13d-ac5c63e70975",
        "parentId" : "a0df1dba-bf3e-4855-a33e-47a5745606a7",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "This is to avoid duplicate entries for both the producer and consumer. We added that in the KIP earlier. \r\nIf duplicating is the way we use at other places if any, I am fine with that.",
        "createdAt" : "2021-05-30T15:54:47Z",
        "updatedAt" : "2021-05-30T15:54:47Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      },
      {
        "id" : "1c5eccb3-efeb-4096-aef5-7bc6b268dbd0",
        "parentId" : "a0df1dba-bf3e-4855-a33e-47a5745606a7",
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "I had the same question. It appears better to just duplicate the properties.",
        "createdAt" : "2021-06-02T07:02:30Z",
        "updatedAt" : "2021-06-02T08:15:16Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "7843d24f-03c3-4555-9710-83cf841a8768",
        "parentId" : "a0df1dba-bf3e-4855-a33e-47a5745606a7",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "As we discussed offline, we see the benefit of keeping several common client config like security to be shared across producer and consumer props avoiding any copy/paste mistakes. \r\nUser has an option not to use common client configs and use the respective producer and consumer configs. ",
        "createdAt" : "2021-06-10T07:36:25Z",
        "updatedAt" : "2021-06-10T07:36:25Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +134,138 @@        for (Map.Entry<String, ?> entry : configs.entrySet()) {\n            String key = entry.getKey();\n            if (key.startsWith(REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX)) {\n                commonClientConfigs.put(key.substring(REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX.length()), entry.getValue());\n            } else if (key.startsWith(REMOTE_LOG_METADATA_PRODUCER_PREFIX)) {"
  },
  {
    "id" : "4a7afab5-5d43-4436-a13f-d94eea5fd824",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-681072534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2675701-373a-4378-80ad-fd7c76f61dac",
        "parentId" : null,
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Could you pls add a comment for this class?",
        "createdAt" : "2021-06-02T06:50:35Z",
        "updatedAt" : "2021-06-02T08:16:00Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "8df0e6ae-390e-4325-a276-5f69258e991c",
        "parentId" : "f2675701-373a-4378-80ad-fd7c76f61dac",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "Done",
        "createdAt" : "2021-06-10T17:33:03Z",
        "updatedAt" : "2021-06-10T17:33:03Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +38,42 @@ * This class defines the configuration of topic based {@link org.apache.kafka.server.log.remote.storage.RemoteLogMetadataManager} implementation.\n */\npublic final class TopicBasedRemoteLogMetadataManagerConfig {\n\n    public static final String REMOTE_LOG_METADATA_TOPIC_NAME = \"__remote_log_metadata\";"
  },
  {
    "id" : "3d25d4a4-486a-4c9a-8099-4e7302cedde2",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-681070116",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f7eeee1-aa14-4ef8-b49e-043048ea1e36",
        "parentId" : null,
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "It seems that we have internal topics specified in `org.apache.kafka.common.internals.Topic` class.\r\nDon't we want this new internal topic to be defined in the `Topic` class, together with other internal topics?",
        "createdAt" : "2021-06-02T07:04:58Z",
        "updatedAt" : "2021-06-02T08:15:16Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "03ecf549-dff0-4304-bd3c-8549ba3e5599",
        "parentId" : "8f7eeee1-aa14-4ef8-b49e-043048ea1e36",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "I plan to add this once RLMM is called from remote log layer classes. I wanted this change to be self contained for now.",
        "createdAt" : "2021-06-10T17:30:15Z",
        "updatedAt" : "2021-06-10T17:30:15Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +40,44 @@public final class TopicBasedRemoteLogMetadataManagerConfig {\n\n    public static final String REMOTE_LOG_METADATA_TOPIC_NAME = \"__remote_log_metadata\";\n\n    public static final String REMOTE_LOG_METADATA_TOPIC_REPLICATION_FACTOR_PROP = \"remote.log.metadata.topic.replication.factor\";"
  },
  {
    "id" : "4ee6e57c-9892-43ee-b357-477ca4d672a4",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-673833347",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73043677-053e-407d-8abb-57f5b12e8086",
        "parentId" : null,
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Hmm, why do you need this exclusion to be true?",
        "createdAt" : "2021-06-02T07:09:25Z",
        "updatedAt" : "2021-06-02T08:16:14Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 196,
    "diffHunk" : "@@ -1,1 +194,198 @@        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n        props.put(ConsumerConfig.EXCLUDE_INTERNAL_TOPICS_CONFIG, false);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());"
  },
  {
    "id" : "b98c22e2-f4aa-4325-ad1f-07bc8f0dc8f8",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-681070440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "570e4aae-7a0c-4273-afd3-09cf5da621cb",
        "parentId" : null,
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "Is this the timeout for how long you'd want the client to wait to consume the message that it produces to `__remote_log_metadata` topic? If yes, then don't we want this timeout to be unlimited i.e. we wait as long as it takes to consume the published event? ",
        "createdAt" : "2021-06-02T07:17:49Z",
        "updatedAt" : "2021-06-02T08:16:25Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "9af22595-e277-41fe-a553-283f0a8b1f02",
        "parentId" : "570e4aae-7a0c-4273-afd3-09cf5da621cb",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "We do not want this to be completely blocked as we want to release the remote log thread after a specific timeout in case of any intermittent issues so that other partitions tiring can proceed.  ",
        "createdAt" : "2021-06-10T17:30:37Z",
        "updatedAt" : "2021-06-10T17:30:37Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +62,66 @@            \"To avoid any data loss, this value should be more than the maximum retention period of any topic enabled with \" +\n            \"tiered storage in the cluster.\";\n    public static final String REMOTE_LOG_METADATA_CONSUME_WAIT_MS_DOC = \"The amount of time in milli seconds to wait for the local consumer to \" +\n            \"receive the published event.\";\n    public static final String REMOTE_LOG_METADATA_INITIALIZATION_RETRY_INTERVAL_MS_DOC = \"The retry interval in milli seconds for \" +"
  },
  {
    "id" : "f90eea9b-79dc-42ce-914c-a7c0f69cf7c3",
    "prId" : 10579,
    "prUrl" : "https://github.com/apache/kafka/pull/10579#pullrequestreview-681070482",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39faf759-23b4-4095-bde7-c991559a8a38",
        "parentId" : null,
        "authorId" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "body" : "`consumerProps` and `producerProps` are of type `Map`, therefore the `.toString()` is probably not readable. So you'd need to convert these into a comma-separated list sth like `K1=V1,K2=V2,...Kn=Vn`.",
        "createdAt" : "2021-06-02T07:19:37Z",
        "updatedAt" : "2021-06-02T08:16:35Z",
        "lastEditedBy" : "b4f52e78-c19e-46b4-b486-6da86e32e687",
        "tags" : [
        ]
      },
      {
        "id" : "052ec24c-5502-4b51-9519-aaf3b8c92a95",
        "parentId" : "39faf759-23b4-4095-bde7-c991559a8a38",
        "authorId" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "body" : "We are using HashMap for these instances and it prints k,v format. Are you suggesting that this map implementation may change as it is of type Map and need to put the right toString. We can change the reference type to HashMap for clarity if needed. ",
        "createdAt" : "2021-06-10T17:30:40Z",
        "updatedAt" : "2021-06-10T17:30:40Z",
        "lastEditedBy" : "403b8bdd-d152-4255-86a7-0bdb3d2b40a5",
        "tags" : [
        ]
      }
    ],
    "commit" : "99edb5d679feaaa72df291c00e73de4511208daa",
    "line" : 224,
    "diffHunk" : "@@ -1,1 +222,226 @@                \", initializationRetryMaxTimeoutMs=\" + initializationRetryMaxTimeoutMs +\n                \", initializationRetryIntervalMs=\" + initializationRetryIntervalMs +\n                \", consumerProps=\" + consumerProps +\n                \", producerProps=\" + producerProps +\n                '}';"
  }
]