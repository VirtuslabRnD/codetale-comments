[
  {
    "id" : "ea3e1660-854a-45e1-baf5-add029b4db88",
    "prId" : 15838,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/15838#pullrequestreview-53685109",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ecebc7b-a6d4-4cc7-99e5-146a4a2459a9",
        "parentId" : null,
        "authorId" : "55206695-bb42-4d72-886f-f5370a77363e",
        "body" : "We might want to remove `timestamps_to_ms` here, or add a pandas compatibility wrapper in pyarrow. Ultimately this is going away",
        "createdAt" : "2017-07-29T14:03:47Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "55206695-bb42-4d72-886f-f5370a77363e",
        "tags" : [
        ]
      },
      {
        "id" : "27517efa-1e4a-4d41-a012-8b255a94d66a",
        "parentId" : "7ecebc7b-a6d4-4cc7-99e5-146a4a2459a9",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "@wesm is there a JIRA link for this? maybe link it in #17102 so we don't forget to do this.",
        "createdAt" : "2017-08-01T22:27:58Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "39e24758-4410-4ffd-b4e2-e09507cd41e2",
        "parentId" : "7ecebc7b-a6d4-4cc7-99e5-146a4a2459a9",
        "authorId" : "55206695-bb42-4d72-886f-f5370a77363e",
        "body" : "added link to ARROW-622",
        "createdAt" : "2017-08-02T02:25:43Z",
        "updatedAt" : "2017-08-02T02:25:43Z",
        "lastEditedBy" : "55206695-bb42-4d72-886f-f5370a77363e",
        "tags" : [
        ]
      }
    ],
    "commit" : "f553a5fbce80b98c4a55bd6469859e8f8922b162",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +63,67 @@    def write(self, df, path, compression='snappy', **kwargs):\n        path, _, _ = get_filepath_or_buffer(path)\n        table = self.api.Table.from_pandas(df, timestamps_to_ms=True)\n        self.api.parquet.write_table(\n            table, path, compression=compression, **kwargs)"
  },
  {
    "id" : "8090defb-222a-4ecb-b760-2adabd346a1b",
    "prId" : 18155,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18155#pullrequestreview-74908961",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb7530b4-07b5-4c41-aa4f-c94d70b3693b",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "add a version added tag",
        "createdAt" : "2017-11-07T20:55:22Z",
        "updatedAt" : "2017-11-08T13:04:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a1234d8b-c486-4408-8cb3-c4476d693f3e",
        "parentId" : "fb7530b4-07b5-4c41-aa4f-c94d70b3693b",
        "authorId" : "43286cbe-b727-4437-8153-2f8d73977f69",
        "body" : "done",
        "createdAt" : "2017-11-07T21:11:11Z",
        "updatedAt" : "2017-11-08T13:04:26Z",
        "lastEditedBy" : "43286cbe-b727-4437-8153-2f8d73977f69",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b22c889ca4463d7c5ebcd3acbcf3e6067d0a1c2",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +189,193 @@    path : string\n        File path\n    columns: list, default=None\n        If not None, only these columns will be read from the file.\n"
  },
  {
    "id" : "c0a2564c-43c3-43b5-948b-3fe0c3bbe259",
    "prId" : 18155,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18155#pullrequestreview-75074293",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb396b39-e2ea-42d8-af15-36511c02e881",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "i’d like to pass thru kwargs as well; these won’t be specific names args just pass thru to the engine to validate\r\nfor both fp and pyarrow \r\ncould just be a simple test with row_groups",
        "createdAt" : "2017-11-08T11:53:36Z",
        "updatedAt" : "2017-11-08T13:04:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "e1b9de96-383c-413c-8348-ae10dfa09d64",
        "parentId" : "fb396b39-e2ea-42d8-af15-36511c02e881",
        "authorId" : "43286cbe-b727-4437-8153-2f8d73977f69",
        "body" : "Ok, i think it is good to pass explicit options like columns which are supported by both backends and also pass the kwargs to be able to provide additional engine specific kwargs.\r\n\r\nHave to look at the test case.",
        "createdAt" : "2017-11-08T11:57:12Z",
        "updatedAt" : "2017-11-08T13:04:26Z",
        "lastEditedBy" : "43286cbe-b727-4437-8153-2f8d73977f69",
        "tags" : [
        ]
      },
      {
        "id" : "110ebf69-9609-461e-9964-e34a57ba52c8",
        "parentId" : "fb396b39-e2ea-42d8-af15-36511c02e881",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok that’s fine\r\nreally want row_group support :) (next PR!)\r\nalso if u want: https://github.com/pandas-dev/pandas/issues/17102",
        "createdAt" : "2017-11-08T12:03:44Z",
        "updatedAt" : "2017-11-08T13:04:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b22c889ca4463d7c5ebcd3acbcf3e6067d0a1c2",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +79,83 @@    def read(self, path, columns=None):\n        path, _, _ = get_filepath_or_buffer(path)\n        return self.api.parquet.read_table(path, columns=columns).to_pandas()\n\n"
  },
  {
    "id" : "198bab78-3d01-4fb4-b865-15162dde527b",
    "prId" : 18629,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18629#pullrequestreview-81831445",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56e0e223-0385-4707-93ba-83a761c8efae",
        "parentId" : null,
        "authorId" : "94a17c08-0252-471b-a2a2-a32eb6cb15a9",
        "body" : "For fastparquet I haven't bothered reading the metadata to pull out the index columns since even if you do you still hit the `NotImplementedError`. I figure if fastparquet do add support for multi-indexes they might implement a solution similar to pyarrow so that the user doesn't have to introspect the metadata to reconstruct the correct DataFrame.",
        "createdAt" : "2017-12-07T12:08:33Z",
        "updatedAt" : "2017-12-11T17:00:04Z",
        "lastEditedBy" : "94a17c08-0252-471b-a2a2-a32eb6cb15a9",
        "tags" : [
        ]
      }
    ],
    "commit" : "0fbdc14ac336f3a29fe531fffd7b4b5b7c766691",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +198,202 @@        path, _, _ = get_filepath_or_buffer(path)\n        parquet_file = self.api.ParquetFile(path)\n        return parquet_file.to_pandas(columns=columns, **kwargs)\n\n"
  },
  {
    "id" : "6cb559f9-63cc-4050-bccc-e6ab2b2fb41b",
    "prId" : 19135,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/19135#pullrequestreview-89063202",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0bd6bc5-af7b-43db-90d0-a3c9d21ba5ec",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "add a comment on what is happening here",
        "createdAt" : "2018-01-16T11:24:56Z",
        "updatedAt" : "2018-01-17T10:47:14Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9dbc77cefd3eb53d96daaa99596765725ad8392e",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +196,200 @@        # Use tobytes() instead.\n\n        if is_s3_url(path):\n            # path is s3:// so we need to open the s3file in 'wb' mode.\n            # TODO: Support 'ab'"
  },
  {
    "id" : "bbb676b3-6050-4789-833b-d892086980cd",
    "prId" : 22266,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/22266#pullrequestreview-147847262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7a1a64c-8b3d-40b7-a499-e9b08081180c",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "add a versionadded ",
        "createdAt" : "2018-08-20T22:35:36Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dc53a19320162218671654d7a406f5777730ddc",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +263,267 @@        If ``True``, include the dataframe's index(es) in the file output. If\n        ``False``, they will not be written to the file. If ``None``, the\n        engine's default behavior will be used.\n\n        .. versionadded 0.24.0"
  },
  {
    "id" : "2364b58a-fc4b-459d-84fc-4cfd106cfd46",
    "prId" : 22266,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/22266#pullrequestreview-157055230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30d305aa-304d-45a5-95f1-96f19e499b22",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can u always pass this? and just set index= if it’s None or does that change things?",
        "createdAt" : "2018-09-05T13:30:32Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "0a4804bf-6eb8-4a7a-9922-4b570a3693a3",
        "parentId" : "30d305aa-304d-45a5-95f1-96f19e499b22",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "I am not sure if `preserve_index=None` is a valid value for pyarrow (at least not according to the docstring)",
        "createdAt" : "2018-09-05T14:29:44Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "9ccc5ee9-742e-4b7f-84e3-280162ffeb43",
        "parentId" : "30d305aa-304d-45a5-95f1-96f19e499b22",
        "authorId" : "50b69844-f7de-4554-9a4d-e8e8c4ea6836",
        "body" : "I'd rather avoid messing with pyarrow like that, as it's fairly finicky in my experience.",
        "createdAt" : "2018-09-19T23:01:24Z",
        "updatedAt" : "2018-09-19T23:11:48Z",
        "lastEditedBy" : "50b69844-f7de-4554-9a4d-e8e8c4ea6836",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dc53a19320162218671654d7a406f5777730ddc",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +114,118 @@        if index is None:\n            from_pandas_kwargs = {}\n        else:\n            from_pandas_kwargs = {'preserve_index': index}\n"
  },
  {
    "id" : "3615e552-69c3-4dc8-8692-e2e669d48523",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-169375055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05cb7e6d-77a2-4b84-a7cb-71022e581d83",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "What if a user does\r\n\r\n```python\r\ndf.to_parquet(\"/tmp/a\", engine=\"fastparquet\", partition_on=['foo'])\r\n```\r\n\r\nI think that would raise an error, since you've specified `partition_on` twice. It should use the user-provided `partition_on`.",
        "createdAt" : "2018-10-29T12:11:46Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "86c5c76a-ec8c-4e1a-ab3d-9574f1ff5e8b",
        "parentId" : "05cb7e6d-77a2-4b84-a7cb-71022e581d83",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "i feel using one argument for partitioning makes more sense. Why don't we raise an error, asking them to use partition_cols instead in that case",
        "createdAt" : "2018-10-29T12:30:51Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      },
      {
        "id" : "efacfa62-0fcc-45c3-b217-9559bac8e1c9",
        "parentId" : "05cb7e6d-77a2-4b84-a7cb-71022e581d83",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "This will break existing users code who are using partition on and fastparquet. We shouldn’t do that.\r\n\r\nIt’s fine to recommend a single keyword and document it, but we need to handle the old working way as well. \r\n\r\nWe can also raise an issue with fastparquet and pyarrow to standardize the interface.  ",
        "createdAt" : "2018-10-29T13:26:13Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "535ce29c-1b04-468d-abab-c35f9b5ae0c6",
        "parentId" : "05cb7e6d-77a2-4b84-a7cb-71022e581d83",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "make sense.. will handle it such that partition_on gets more priority than partition_cols with a warning",
        "createdAt" : "2018-10-29T15:34:01Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      },
      {
        "id" : "a8c2259f-33c9-4c4a-8d28-b6a330a53347",
        "parentId" : "05cb7e6d-77a2-4b84-a7cb-71022e581d83",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "I'm not sure it should even be a warning. If a warning is going to be emitted, then that should be done by fastparquet.",
        "createdAt" : "2018-10-29T15:48:25Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +192,196 @@        with catch_warnings(record=True):\n            self.api.write(path, df, compression=compression,\n                           write_index=index, partition_on=partition_cols,\n                           **kwargs)\n"
  },
  {
    "id" : "8d302a9c-0269-460f-8524-d9b868226199",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-171563593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "is this not defaulted pyarrow? if you don't specify what is the default? ",
        "createdAt" : "2018-10-29T12:46:00Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "c177d066-05ac-4d82-bd3d-1ae7db737519",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "this is for fastparquet. Default file_scheme is simple. In simple _metadata file will not be generated. _metadata file is necessary to perform a read on a directory in fastparquet",
        "createdAt" : "2018-10-29T15:23:15Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      },
      {
        "id" : "d4a18219-b61a-417d-8071-53d81e8d384e",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "body" : "To be specific, simple means one file only, and is not appropriate for dask. There is also Drill scheme, where the directory names are different from the Hive variant (*if* using directory partitioning, no difference otherwise). Spark defaults to the Hive format, it's a reasonable default in every case.",
        "createdAt" : "2018-10-29T16:01:08Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "tags" : [
        ]
      },
      {
        "id" : "10617c91-430a-4553-9dce-4a12b80f67bc",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "body" : "(the _metadata file is longer necessary for the fastparquet branch, actually, but it is preferred)",
        "createdAt" : "2018-10-29T16:07:39Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "tags" : [
        ]
      },
      {
        "id" : "791fcf48-51fa-4f5c-a840-dae2ce9821e3",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add a comment above this describing what you said above, e.g. for compat with fp",
        "createdAt" : "2018-10-30T12:32:01Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "4f0038cc-e7bb-434b-a6c7-c673d1ee9211",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Need a comment here sayings what's going on.",
        "createdAt" : "2018-11-05T12:05:05Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "ae6b1cfd-0f59-4c8d-a59d-c9fc7289e2dc",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "Default file_scheme for fastparquet is simple, which applies for a single file. \r\nWhen we go for storing partitioned parquet files in a directory, it is preferred to have a _metadata file along.\r\n\r\nFor compatibility, if a file_scheme is not provided, and engine is fastparquet, we can default to hive file scheme as, it provides the additional _metadata file.\r\n\r\n@martindurant  I am not able to read from the partitioned dataset when _metadata file is not present. I am on v0.1.6, and the error i get is that the _metadata file is missing.",
        "createdAt" : "2018-11-05T12:28:23Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      },
      {
        "id" : "91cee423-54f7-40a3-bf99-1f5400f846ee",
        "parentId" : "9e8783c3-a130-48c3-8a06-1e0a451936ab",
        "authorId" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "body" : "That is expected in 0.1.6, you would need to pass the whole list of data files rather than the root directory. This may be fixed in master.",
        "createdAt" : "2018-11-05T13:54:57Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +178,182 @@\n        if partition_cols is not None:\n            kwargs['file_scheme'] = 'hive'\n\n        if is_s3_url(path):"
  },
  {
    "id" : "c0e7ec8a-43a9-47a1-9299-19b796158fce",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-171677655",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6218b444-4924-48f5-8e8f-ce8803f48fb1",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Should check that `partition_cols` is None before doing this. We would want to raise on\r\n\r\n```python\r\ndf.to_parquet(engine='fastparquet', partition_cols=['a', 'b'], partition_on=['b', 'c'])\r\n```",
        "createdAt" : "2018-11-05T12:04:32Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "8bb290f7-b165-474e-bd8e-4ebf05a2a3c8",
        "parentId" : "6218b444-4924-48f5-8e8f-ce8803f48fb1",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "done",
        "createdAt" : "2018-11-05T17:47:00Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +175,179 @@                             \"partitioning data\")\n        elif 'partition_on' in kwargs:\n            partition_cols = kwargs.pop('partition_on')\n\n        if partition_cols is not None:"
  },
  {
    "id" : "6912cf6b-6ebd-4a3e-8bc8-ee0746049c15",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-171869150",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29292d95-220c-4d62-8c34-58eed1d6224e",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "versionchanged tag here",
        "createdAt" : "2018-11-06T04:00:32Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a1715124-3dc6-47f1-8655-b8006a6c1252",
        "parentId" : "29292d95-220c-4d62-8c34-58eed1d6224e",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "done",
        "createdAt" : "2018-11-06T05:36:01Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +221,225 @@    path : str\n        File path or Root Directory path. Will be used as Root Directory path\n        while writing a partitioned dataset.\n\n        .. versionchanged:: 0.24.0"
  }
]