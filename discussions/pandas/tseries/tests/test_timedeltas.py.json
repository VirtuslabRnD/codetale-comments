[
  {
    "id" : "2213d9ac-3115-4e63-8f3c-04252e8b3676",
    "prId" : 6810,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32e1745f-aae8-4445-baf6-f230f6ff7c5e",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this is a rounding issue yes?\n",
        "createdAt" : "2014-04-05T14:54:08Z",
        "updatedAt" : "2014-04-16T04:10:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "4d2c2219-2b2e-44fb-b793-5c1f9e847c39",
        "parentId" : "32e1745f-aae8-4445-baf6-f230f6ff7c5e",
        "authorId" : "080886f5-836c-4c01-b81c-efb474d91df7",
        "body" : "yes, Julian looked into the difference in rounding methods between pandas.compat.scipy.scoreatpercentile and numpy in a comment on #5824..  and also offered to update numpy.  do you think this hard-coded expect should be removed and expect whatever numpy.percentile returns, in case they do change?\n",
        "createdAt" : "2014-04-05T14:59:07Z",
        "updatedAt" : "2014-04-16T04:10:52Z",
        "lastEditedBy" : "080886f5-836c-4c01-b81c-efb474d91df7",
        "tags" : [
        ]
      },
      {
        "id" : "9000ada2-16f2-4555-adf5-9eef55b4391c",
        "parentId" : "32e1745f-aae8-4445-baf6-f230f6ff7c5e",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "hmm, I think this is ok to change it, sort of go with `np.percentile` results.\n",
        "createdAt" : "2014-04-05T15:12:51Z",
        "updatedAt" : "2014-04-16T04:10:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "948f6e95-e612-4489-a19b-69498cd190ca",
        "parentId" : "32e1745f-aae8-4445-baf6-f230f6ff7c5e",
        "authorId" : "4cf94c16-7468-4484-895b-55ac60b389e8",
        "body" : "can you do a fuzzy comparison instead of equality? (I guess as its an integers almost_equal does not work)\nI may still update numpy as this method saves a few precious cycles for small percentiles\n",
        "createdAt" : "2014-04-16T16:24:52Z",
        "updatedAt" : "2014-04-16T16:24:52Z",
        "lastEditedBy" : "4cf94c16-7468-4484-895b-55ac60b389e8",
        "tags" : [
        ]
      },
      {
        "id" : "b75b34a1-8e69-426c-8089-9b6083e92bfa",
        "parentId" : "32e1745f-aae8-4445-baf6-f230f6ff7c5e",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "@juliantaylor this pr replace our original method so using np.percentile now fully\nand ok with all numpy (incl numpy master)\n\nif u do make a change in numpy master then we can change the test (to more of a allclose one)\n",
        "createdAt" : "2014-04-16T19:13:45Z",
        "updatedAt" : "2014-04-16T19:13:45Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d89f513b5d6eb61941a162040f4694b8f03ffca",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +241,245 @@        result = td.quantile(.1)\n        # This properly returned a scalar.\n        expected = np.timedelta64(2599999999,'ns')\n        tm.assert_almost_equal(result, expected)\n"
  }
]