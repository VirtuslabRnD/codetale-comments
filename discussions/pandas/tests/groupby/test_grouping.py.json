[
  {
    "id" : "68258bc8-06f8-49a2-91ba-363fc7f6fb48",
    "prId" : 18057,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18057#pullrequestreview-73408447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38904311-f39b-403b-9479-8b274648cd5a",
        "parentId" : null,
        "authorId" : "51189123-86a2-400a-9762-6816882b6f12",
        "body" : "On a somewhat relevant point to my comment in <a href=\"https://github.com/pandas-dev/pandas/pull/18047#issuecomment-340659137\">#18047</a>, perhaps we need a built-in way to implement the `assert not` checks so that we avoid ugly regex like this.\r\n\r\nThat's something to think about for the long-run and not necessarily for this PR.",
        "createdAt" : "2017-11-01T08:23:39Z",
        "updatedAt" : "2017-11-01T08:23:58Z",
        "lastEditedBy" : "51189123-86a2-400a-9762-6816882b6f12",
        "tags" : [
        ]
      }
    ],
    "commit" : "5cefd93e47f19fd5fc95e8d922aed067ffdc404a",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +31,35 @@\n        pytest.raises(KeyError, g.__getitem__, ['A', 'C'])  # g[['A', 'C']]\n        with tm.assert_raises_regex(KeyError, '^[^A]+$'):\n            # A should not be referenced as a bad column...\n            # will have to rethink regex if you change message!"
  },
  {
    "id" : "713e2a01-6092-49c6-bac1-ccad98a3473f",
    "prId" : 28097,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28097#pullrequestreview-289363020",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3068435b-55c8-4f12-8067-1d82b3147152",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Hmm just thinking out loud but why do we think this output is valuable? Read through issue but I wonder if this shouldn't raise instead. Since column `B` is just an NA value - what is the value in making that \"groupable\"?",
        "createdAt" : "2019-09-16T01:42:19Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "24ebedba-3b9d-4e99-8fba-bbc25f0604b7",
        "parentId" : "3068435b-55c8-4f12-8067-1d82b3147152",
        "authorId" : "7627866b-49e8-48fc-9905-a5182558148d",
        "body" : "@WillAyd \r\nOf course, NA values are non groupable value.  So the logic which is what i added fills grouper variable with numpy nan considered NA value in Pandas. If some values are missing(not all values are missing) in a level of multiindex, fill another value in a level which is not NA value. \r\nLike this, I want to fill garbage value because there is no non-NA value. In this case, numpy nan.\r\nConsequently, I want a consistency. For example, \r\ndf = pd.DataFrame([[\"a\", None, \"x\", 10], [None, \"y\", None, 20]], columns=[\"A\", \"B\", \"C\", \"D\"]).set_index([\"A\",\"B\",\"C\"])\r\nresult = df.groupby(level=[\"A\",\"B\"]).sum()\r\nthis result variable is empty dataframe before what i made is added. So, what i added also makes sense?",
        "createdAt" : "2019-09-16T06:48:53Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "7627866b-49e8-48fc-9905-a5182558148d",
        "tags" : [
        ]
      },
      {
        "id" : "c4620605-150a-4b56-8e29-3ddf308ebe4c",
        "parentId" : "3068435b-55c8-4f12-8067-1d82b3147152",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Yea understood on the consistency but shouldn't these both raise then? Not sure why we would want to arbitrarily fill values for the user - @TomAugspurger I think you might have a differing opinion",
        "createdAt" : "2019-09-16T16:11:30Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "be88a55a-ceda-441f-a323-e7f169d1a7b1",
        "parentId" : "3068435b-55c8-4f12-8067-1d82b3147152",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "I'm happy to be overruled here @WillAyd. I don't think I understand the original issue that well.",
        "createdAt" : "2019-09-16T16:36:15Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "50a59faa-2aca-4aa3-8a98-c12121e89c6b",
        "parentId" : "3068435b-55c8-4f12-8067-1d82b3147152",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Hmm OK I think I'm back on board with this after thinking it over some more. This at the very least matches what you would get in more simple cases too:\r\n\r\n```python\r\n>>> df = pd.DataFrame({\"A\": [1, 1], \"B\": [np.nan, np.nan]})\r\n>>> df.groupby(\"B\").sum()\r\nEmpty DataFrame\r\nColumns: [A]\r\nIndex: []\r\n```",
        "createdAt" : "2019-09-17T15:43:12Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef08517703cdb61ba9fb6420a0f9797f9744f85d",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +635,639 @@        ).set_index([\"A\", \"B\"])\n        result = df.groupby(level=[\"A\", \"B\"]).sum()\n        expected = DataFrame(\n            data=[],\n            index=MultiIndex("
  },
  {
    "id" : "794ebff5-f8c8-47db-889e-91f4d85168c4",
    "prId" : 28097,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28097#pullrequestreview-302911704",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80d8016d-b332-48f6-9e3b-575c04020c32",
        "parentId" : null,
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "If I cast `df[\"B\"] = df[\"B\"].astype(\"datetime64\")` before doing the `set_index`, I get a different error on the groupby call (in master).  Should that be fixed by this PR?  If so, please test.\r\n\r\nside-note, I'd find this easier to follow in smaller steps:\r\n\r\n```\r\ndf = pd.DataFrame(...)\r\ndf = df.set_index([\"A\", \"B\"])\r\ngb = df.groupby(level=[\"A\", \"B\"])\r\nresult = gb.sum()\r\n```\r\n\r\nEspecially relevant as it is the `gb = ...` line that raises in master",
        "createdAt" : "2019-10-11T22:59:49Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "16e732df-d428-4b34-8a0f-8515de3b8020",
        "parentId" : "80d8016d-b332-48f6-9e3b-575c04020c32",
        "authorId" : "7627866b-49e8-48fc-9905-a5182558148d",
        "body" : "@jbrockmendel\r\nI'm bit confused. you `df[\"B\"] = df[\"B\"].astype(\"datetime64\")` means `df[\"B\"] = df[\"B\"].astype(\"datetime64[ns]\")` write?\r\nin master,\r\n`df = pd.DataFrame(...)`\r\n`df[\"B\"] = df[\"B\"].astype(\"datetime64[ns]\")`\r\n`df = df.set_index([\"A\", \"B\"])`\r\n`gb = df.groupby(level=[\"A\", \"B\"])`\r\nand\r\n`df = pd.DataFrame(...)`\r\n`df = df.set_index([\"A\", \"B\"])`\r\n`gb = df.groupby(level=[\"A\", \"B\"])`\r\nraise same IndexError :cannot do a non-empty take from an empty axes.",
        "createdAt" : "2019-10-13T14:29:36Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "7627866b-49e8-48fc-9905-a5182558148d",
        "tags" : [
        ]
      },
      {
        "id" : "aa31dc85-91b9-4f50-853b-d05173ea9592",
        "parentId" : "80d8016d-b332-48f6-9e3b-575c04020c32",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> I'm bit confused. you df[\"B\"] = df[\"B\"].astype(\"datetime64\") means df[\"B\"] = df[\"B\"].astype(\"datetime64[ns]\") write?\r\n\r\nYes, I meant to write `\"datetime64[ns]\"` and not just `\"datetime64\"`.\r\n\r\n> raise same IndexError\r\n\r\nHuh, not sure how I got to a different error.  My bad.",
        "createdAt" : "2019-10-16T22:22:52Z",
        "updatedAt" : "2019-10-25T04:59:43Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef08517703cdb61ba9fb6420a0f9797f9744f85d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +632,636 @@        # issue 20519\n        df = DataFrame(\n            [[\"x\", np.nan, 10], [None, np.nan, 20]], columns=[\"A\", \"B\", \"C\"]\n        ).set_index([\"A\", \"B\"])\n        result = df.groupby(level=[\"A\", \"B\"]).sum()"
  }
]