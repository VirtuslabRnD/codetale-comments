[
  {
    "id" : "b1b35d3f-f859-49aa-a27c-9c494444c029",
    "prId" : 16150,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/16150#pullrequestreview-35056228",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58ee3607-280b-4434-b414-582187929db9",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "do we have a skip if s3fs is not installed?\r\n",
        "createdAt" : "2017-04-27T09:17:34Z",
        "updatedAt" : "2017-04-27T09:17:46Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "31fff4d5-fea3-40b4-a211-2a77fe927380",
        "parentId" : "58ee3607-280b-4434-b414-582187929db9",
        "authorId" : "51189123-86a2-400a-9762-6816882b6f12",
        "body" : "Absolutely.  There's a `setUp` method in this test class which skips on that exact condition.",
        "createdAt" : "2017-04-27T09:18:47Z",
        "updatedAt" : "2017-04-27T09:18:55Z",
        "lastEditedBy" : "51189123-86a2-400a-9762-6816882b6f12",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2efe18a95d0680d7f47766a6f1701dd2172c8bb",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +183,187 @@\n        # boto3 is a dependency of s3fs\n        import boto3\n        client = boto3.client(\"s3\")\n"
  },
  {
    "id" : "3d623ac9-9f74-4db2-8de6-baea55643eea",
    "prId" : 17388,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17388#pullrequestreview-60470323",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "441843df-a1fc-436d-8297-e78a80e89e4b",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this becomes inline when u use parametrize",
        "createdAt" : "2017-09-04T21:56:49Z",
        "updatedAt" : "2017-09-14T02:26:48Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "8f149d8e5ed8e5ae6e1bb7242757bd714fb472b6",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +38,42 @@    ]\n\n    def add_tips_files(bucket_name):\n        for s3_key, file_name in test_s3_files:\n            with open(file_name, 'rb') as f:"
  },
  {
    "id" : "e4b96815-49ac-4573-8a94-7b688b9782d6",
    "prId" : 20409,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/20409#pullrequestreview-104965890",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3728a465-fa81-4f83-8fa0-2ba5facd6bb1",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "@martindurant does this seem like a reasonable way to test that `read_csv(key, nrows=5)` only triggers S3FS reading part of the object? Do you know of a better way, that's perhaps less reliant on the internals of S3FS?",
        "createdAt" : "2018-03-19T12:20:57Z",
        "updatedAt" : "2018-03-22T19:45:09Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "18a88db6-c732-4096-ad2b-4b2ffe03e813",
        "parentId" : "3728a465-fa81-4f83-8fa0-2ba5facd6bb1",
        "authorId" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "body" : "I'm afraid I don't have a better method for you, s3fs doesn't keep a log of transactions in any data structure you could access, and the s3file used for the download will have been cleaned up as soon as read_csv is done with it.",
        "createdAt" : "2018-03-19T13:30:52Z",
        "updatedAt" : "2018-03-22T19:45:09Z",
        "lastEditedBy" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "tags" : [
        ]
      },
      {
        "id" : "28b63f00-db8e-491f-95b4-d3bb24738e00",
        "parentId" : "3728a465-fa81-4f83-8fa0-2ba5facd6bb1",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Hmm OK. Do you know if moto keeps a record anywhere?\r\n\r\nI dislike this test since s3fs adding an additional `logger.debug` anywhere, or changing the log message, default bytes size, etc. will break it.\r\n\r\nboto also has a callback mechanism on `download_file`, but I don't see that option for `get_object`. If I can't figure out a way to get that working, I'll try to make the test using the logger a bit less fragile.",
        "createdAt" : "2018-03-19T13:37:02Z",
        "updatedAt" : "2018-03-22T19:45:09Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "74fc9989-e4ef-4185-b030-9cc27e491150",
        "parentId" : "3728a465-fa81-4f83-8fa0-2ba5facd6bb1",
        "authorId" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "body" : "Certainly you could look through all log messages captured, not just the last one. Note that you *do* have access to the exact s3filesystem in S3FileSystem._singleton[0], but I don't see that that helps you in this case.\r\n\r\nYou could maybe patch `S3File.__exit__` to store the values of `self.loc` and `self.end`?",
        "createdAt" : "2018-03-19T13:46:29Z",
        "updatedAt" : "2018-03-22T19:45:09Z",
        "lastEditedBy" : "91bd3e12-470c-4417-ac08-5f387012a9be",
        "tags" : [
        ]
      }
    ],
    "commit" : "69adc3dc5dc140809f4f783b5fb50907d0fca454",
    "line" : 120,
    "diffHunk" : "@@ -1,1 +198,202 @@            Body=buf)\n\n        with caplog.at_level(logging.DEBUG, logger='s3fs.core'):\n            read_csv(\"s3://pandas-test/large-file.csv\", nrows=5)\n            # log of fetch_range (start, stop)"
  },
  {
    "id" : "355e88ed-04ad-4e80-aecf-16acadc46fe1",
    "prId" : 29573,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29573#pullrequestreview-316585999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b336d981-a145-4ee6-bca5-50988369c921",
        "parentId" : null,
        "authorId" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "body" : "Looks like this is what the test failures are related to",
        "createdAt" : "2019-11-13T21:58:44Z",
        "updatedAt" : "2019-11-14T19:31:15Z",
        "lastEditedBy" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "tags" : [
        ]
      }
    ],
    "commit" : "abed616c873bcf21cfdd842ab23ec93bbd23824f",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +200,204 @@        # If we don't clear this cache, we saw `GetObject operation: Forbidden`.\n        # Presumably the s3fs instance is being cached, with the directory listing\n        # from *before* we add the large-file.csv in the pandas-test bucket.\n        s3fs.S3FileSystem.clear_instance_cache()\n"
  },
  {
    "id" : "6323c3de-653e-40d3-9adc-4729e25752b1",
    "prId" : 33645,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/33645#pullrequestreview-396931811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e623f45b-3654-42ff-aa95-8b1a40f6934c",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Does this need an importorskip, or do we raise prior to importing the engine?",
        "createdAt" : "2020-04-20T11:28:57Z",
        "updatedAt" : "2020-04-21T01:43:52Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "3e028324-556c-42dc-a5df-3a6d1ffdf86d",
        "parentId" : "e623f45b-3654-42ff-aa95-8b1a40f6934c",
        "authorId" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "body" : "Added an importskip. Would raise ImportError if PyArrow or fastparquet isnâ€™t installed.",
        "createdAt" : "2020-04-20T17:15:52Z",
        "updatedAt" : "2020-04-21T01:43:52Z",
        "lastEditedBy" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "tags" : [
        ]
      },
      {
        "id" : "793fcc58-93b7-407c-a9ad-4df7f324976a",
        "parentId" : "e623f45b-3654-42ff-aa95-8b1a40f6934c",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add the decorator version instead ",
        "createdAt" : "2020-04-20T22:12:47Z",
        "updatedAt" : "2020-04-21T01:43:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "65c331ba-cc7c-4898-8057-adbcacc9637e",
        "parentId" : "e623f45b-3654-42ff-aa95-8b1a40f6934c",
        "authorId" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "body" : "have done - and changed other importerskip in this file",
        "createdAt" : "2020-04-21T01:44:57Z",
        "updatedAt" : "2020-04-21T01:44:58Z",
        "lastEditedBy" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "tags" : [
        ]
      }
    ],
    "commit" : "7bd1c9fc96627a65dc70ed64f10ff2740a13c1df",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +179,183 @@    @td.skip_if_no(\"pyarrow\")\n    def test_write_s3_parquet_fails(self, tips_df):\n        # GH 27679\n        with pytest.raises(\n            FileNotFoundError, match=\"The specified bucket does not exist\""
  },
  {
    "id" : "11828ec4-119b-48ce-bfc6-250e042961e2",
    "prId" : 33645,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/33645#pullrequestreview-396932745",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e461593c-93e0-40ee-a50b-782af75c76ea",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you give a comment on what this test is testing (credentials / invalid path etc)",
        "createdAt" : "2020-04-20T22:12:20Z",
        "updatedAt" : "2020-04-21T01:43:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "f6016f4e-3e1f-4cfb-9b18-d14c96a86997",
        "parentId" : "e461593c-93e0-40ee-a50b-782af75c76ea",
        "authorId" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "body" : "Good point - added ",
        "createdAt" : "2020-04-21T01:48:11Z",
        "updatedAt" : "2020-04-21T01:48:12Z",
        "lastEditedBy" : "ebd948a0-48ff-4dbe-a0c8-476953d697fa",
        "tags" : [
        ]
      }
    ],
    "commit" : "7bd1c9fc96627a65dc70ed64f10ff2740a13c1df",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +161,165 @@\n    def test_read_s3_fails(self):\n        with pytest.raises(IOError):\n            read_csv(\"s3://nyqpug/asdf.csv\")\n"
  }
]