[
  {
    "id" : "20736d52-0e46-48d4-ad24-69d1a00934dd",
    "prId" : 24954,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/24954#pullrequestreview-196814735",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0969beff-8f9e-45fb-90b1-73e8e8d88088",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "So do we even need this object fallback loop?",
        "createdAt" : "2019-01-26T23:06:41Z",
        "updatedAt" : "2019-02-04T09:53:49Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "736a65a9-da89-43a2-88ba-adf6ae141f71",
        "parentId" : "0969beff-8f9e-45fb-90b1-73e8e8d88088",
        "authorId" : "7e74fb24-2f96-4cb7-8b24-bacafb9fec58",
        "body" : "not for group_add and everything worked fine until now.\r\nstill it seemed like a bug.",
        "createdAt" : "2019-01-27T07:15:47Z",
        "updatedAt" : "2019-02-04T09:53:49Z",
        "lastEditedBy" : "7e74fb24-2f96-4cb7-8b24-bacafb9fec58",
        "tags" : [
        ]
      }
    ],
    "commit" : "937e44cb2aca62ffb828bd8c05d976b4630fb1c8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +381,385 @@            for dt in [dtype_str, 'object']:\n                f = getattr(libgroupby, \"{fname}_{dtype_str}\".format(\n                    fname=fname, dtype_str=dt), None)\n                if f is not None:\n                    return f"
  },
  {
    "id" : "6d0cf852-e0f1-447a-b65e-ec66269ba92a",
    "prId" : 27683,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/27683#pullrequestreview-270719648",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "52cf4aa0-621e-4d48-93a5-d923ead1cdf5",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you move the is_datetimelike and is_numeric checks up here and de-duplicate as needed",
        "createdAt" : "2019-08-04T22:01:51Z",
        "updatedAt" : "2019-08-04T23:52:02Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "669d02b1-7ae2-49d5-8787-9c4895619c13",
        "parentId" : "52cf4aa0-621e-4d48-93a5-d923ead1cdf5",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "done.  not much de-duplication available.  in another pass we can separate out some of the casting from the everything-else and see if there is de-duplication available in algos or something",
        "createdAt" : "2019-08-04T23:53:07Z",
        "updatedAt" : "2019-08-04T23:53:07Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "935d945d-85d0-43ad-93be-7dd4351e1b58",
        "parentId" : "52cf4aa0-621e-4d48-93a5-d923ead1cdf5",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok fair, that routine likely needs some cleaning at some point",
        "createdAt" : "2019-08-05T11:57:01Z",
        "updatedAt" : "2019-08-05T11:57:01Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "e05309718ec009d7b0cd79c6b75dac751e143924",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +483,487 @@            #  2D EA is allowed.\n            values = values.view(\"M8[ns]\")\n\n        is_datetimelike = needs_i8_conversion(values.dtype)\n        is_numeric = is_numeric_dtype(values.dtype)"
  },
  {
    "id" : "4eaff2a3-a3ce-467a-9038-16d162603a48",
    "prId" : 28198,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28198#pullrequestreview-282251785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Is the type(s) of exceptions that raise this not well defined?",
        "createdAt" : "2019-08-28T18:49:25Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "886418c0-0507-4da9-b215-9b53186e85a9",
        "parentId" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "cython raises this (with a message matching this pattern) if we pass a non-ndarray to something expected an ndarray.  im not aware of any other cases we actually want to let pass here",
        "createdAt" : "2019-08-28T19:37:10Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "78f87f1a-7508-45f1-99a4-7c29b1209352",
        "parentId" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "I assume you saw other non-Cython TypeErrors show up here then?",
        "createdAt" : "2019-08-28T22:23:55Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "4517484c-8776-434e-bbe2-dd48a39edf21",
        "parentId" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "if we dont catch TypeError at all, the only tests that fail are ones where apply_frame_axis0 is raising because it expects an ndarray",
        "createdAt" : "2019-08-28T23:09:22Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "00f9cf10-34d3-40a9-8546-fe221d817852",
        "parentId" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "I may have asked this wrong but I don't think we are on the same page. So I was thinking to keep catching `TypeError` but was questioning if we need the conditional block therein, as it diverges slightly from the pre-existing behavior.",
        "createdAt" : "2019-08-30T17:04:20Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "84daed36-e3f8-4ed1-9195-6a430a874216",
        "parentId" : "576847a2-51ab-4a8d-b8b6-892a9146baa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> if we need the conditional block therein, as it diverges slightly from the pre-existing behavior.\r\n\r\nChanging the behavior is intentional.  ATM we are `pass`ing on everything, and I want to `pass` on a narrow set of `TypeError`s.  ",
        "createdAt" : "2019-08-30T21:23:47Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "77d6e5d2ad2cd06db12d89bbdd72d11304ecce58",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +214,218 @@                pass\n            except TypeError as err:\n                if \"Cannot convert\" in str(err):\n                    # via apply_frame_axis0 if we pass a non-ndarray\n                    pass"
  },
  {
    "id" : "55020299-3334-4cda-ba31-5605d713b98a",
    "prId" : 28198,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28198#pullrequestreview-282717022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "735697fc-a929-48fc-bd68-8ac7519fb456",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "looks fine, does this change any perf? IOW this looks like this is now taking a path that previously we raised (and then likely did an .apply on)",
        "createdAt" : "2019-09-02T20:55:38Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "e442d9eb-8e57-49ea-81bb-2208989de2c3",
        "parentId" : "735697fc-a929-48fc-bd68-8ac7519fb456",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "Not sure.  Between this, #27909, and a not-yet-pushed branch that fixes incorrect exception handling in cython_agg_block, I'm pretty sure we'll end up falling back to python-space less often, but it isn't obvious what the individual changes affect perf-wise.",
        "createdAt" : "2019-09-02T23:54:06Z",
        "updatedAt" : "2019-09-07T17:53:13Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "77d6e5d2ad2cd06db12d89bbdd72d11304ecce58",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +216,220 @@                if \"Cannot convert\" in str(err):\n                    # via apply_frame_axis0 if we pass a non-ndarray\n                    pass\n                else:\n                    raise"
  },
  {
    "id" : "65728d0f-18d4-4a76-8c70-45539e80c29a",
    "prId" : 28634,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28634#pullrequestreview-312150389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ca6c1b8-94fa-4360-b907-03d6167aa284",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add some comments here on what is going on",
        "createdAt" : "2019-11-04T14:05:16Z",
        "updatedAt" : "2019-11-07T14:18:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "cce3fdb5-cacf-4e40-a941-b232bb570d2c",
        "parentId" : "0ca6c1b8-94fa-4360-b907-03d6167aa284",
        "authorId" : "50a8f1f9-e426-4547-baa9-0c028b12e95f",
        "body" : "ok, I added it. it is inspired by here:\r\nhttps://github.com/pandas-dev/pandas/blob/6cc82344fb319032465d6ee4e3d1c02991ef42c3/pandas/core/groupby/generic.py#L644-L646\r\nthat means get boundaries of ids. In my case, it would be unique result indices which is equivalent to boundaries of result indices.\r\n\r\nI have numberlessly tested along with asv and timeit. as a result, I use bins[1:] != bins[:-1] instead of np.diff for the performance due to their dtype difference.\r\n\r\nIt was quite hard that measure the performance as it fluctuates every time in my environment. so I ran it again and again even though it takes 6~8 hours. several groups fluctuate from 0.5 ~ 1.8 but it looks like \"BENCHMARKS NOT SIGNIFICANTLY CHANGED.\" I'm quite sure that this change won't decrease performance.\r\n\r\n**EDIT: I think that they fluctuate as they are too trivial to compute therefore a few ns difference affects significantly.**",
        "createdAt" : "2019-11-06T01:37:35Z",
        "updatedAt" : "2019-11-07T14:18:52Z",
        "lastEditedBy" : "50a8f1f9-e426-4547-baa9-0c028b12e95f",
        "tags" : [
        ]
      }
    ],
    "commit" : "368311c9adbaf2bef9764fd001a8e3f3340701e1",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +771,775 @@    def recons_codes(self):\n        # get unique result indices, and prepend 0 as groupby starts from the first\n        return [np.r_[0, np.flatnonzero(self.bins[1:] != self.bins[:-1]) + 1]]\n\n    @cache_readonly"
  },
  {
    "id" : "dea92ac0-0836-47b8-b8d0-cce6b42998cb",
    "prId" : 29060,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29060#pullrequestreview-303577917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37f0125d-f105-4680-875b-0c1b76e4136e",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "future PR should push this to pandas/core/dtypes/cast.py and just call here (maybe make ensure_float64_or_complex)",
        "createdAt" : "2019-10-17T21:57:37Z",
        "updatedAt" : "2019-10-17T21:57:55Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "32ac0a82-da6f-4692-bc6c-715db201a54c",
        "parentId" : "37f0125d-f105-4680-875b-0c1b76e4136e",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "yah.  i think there was some discussion of a one-pass variant of lib.infer_dtype that would go well with that",
        "createdAt" : "2019-10-17T22:05:18Z",
        "updatedAt" : "2019-10-17T22:05:18Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "6d23acec-ba82-4b63-acfd-0dd18909ee1a",
        "parentId" : "37f0125d-f105-4680-875b-0c1b76e4136e",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "great",
        "createdAt" : "2019-10-17T22:16:52Z",
        "updatedAt" : "2019-10-17T22:16:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "39ba0179ff67e0c6737d2048cefd206795d114ad",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +530,534 @@                    values = ensure_float64(values)\n                except TypeError:\n                    if lib.infer_dtype(values, skipna=False) == \"complex\":\n                        values = values.astype(complex)\n                    else:"
  },
  {
    "id" : "4ed52607-b049-42b8-ad2b-db733b7ebebb",
    "prId" : 29124,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29124#pullrequestreview-310789545",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3dd12903-b791-45a2-a9dc-bd2730e9f9c4",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "we should make a 1d and 2d version of this and just branch on the calling function to avoid a bunch of special case branches, prob post this PR",
        "createdAt" : "2019-11-02T20:35:13Z",
        "updatedAt" : "2019-11-19T22:18:55Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "c1d82146-7704-4d14-b68b-d9f1015217dd",
        "parentId" : "3dd12903-b791-45a2-a9dc-bd2730e9f9c4",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Yea same comment on ohlc. When the dust settles and we get block management out of GroupBy I think I'll just rip that out of these methods so we can simplify further",
        "createdAt" : "2019-11-02T21:35:45Z",
        "updatedAt" : "2019-11-19T22:18:55Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      }
    ],
    "commit" : "51b805050e7dfd1a582a7997aa7790482bde0a50",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +430,434 @@        Returns the values of a cython operation as a Tuple of [data, names].\n\n        Names is only useful when dealing with 2D results, like ohlc\n        (see self._name_functions).\n        \"\"\""
  },
  {
    "id" : "ff3f89f0-6f56-49c4-a7db-49f76e342150",
    "prId" : 29124,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29124#pullrequestreview-318030173",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4676c74e-70dd-47c3-98b0-317a3bfeb7a8",
        "parentId" : null,
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "are you sure `Optional[List[str]]` is right?  I expected something like `List[Optional[Hashable]]`.",
        "createdAt" : "2019-11-17T16:33:41Z",
        "updatedAt" : "2019-11-19T22:18:55Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "59f55a86-0d31-41c1-9f76-92472420d078",
        "parentId" : "4676c74e-70dd-47c3-98b0-317a3bfeb7a8",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "oh, its only for ohlc.  never mind",
        "createdAt" : "2019-11-17T16:34:00Z",
        "updatedAt" : "2019-11-19T22:18:55Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "51b805050e7dfd1a582a7997aa7790482bde0a50",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +426,430 @@    def _cython_operation(\n        self, kind: str, values, how: str, axis, min_count: int = -1, **kwargs\n    ) -> Tuple[np.ndarray, Optional[List[str]]]:\n        \"\"\"\n        Returns the values of a cython operation as a Tuple of [data, names]."
  },
  {
    "id" : "08a50028-c69a-4239-9f3f-3bab8d105372",
    "prId" : 29144,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29144#pullrequestreview-305498576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "@jbrockmendel the whole block is now basically an `except (..): pass` (so I could make it much shorter), but you might have put in those specific checks as pointers to what to clean up later? ",
        "createdAt" : "2019-10-22T13:52:25Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "65493795-7826-49aa-ae65-ab1c240f0a08",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "so something is being done with a DecimalArray that raises a TypeError?  and i guess by not-catching it here it is getting caught somewhere above that isn't doing re-casting appropriately?  can we track down where that is?",
        "createdAt" : "2019-10-22T15:32:34Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "561cfcee-7bec-47dd-873e-2e3e388723e9",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "It looks like in _aggregate_series_fast there is a call to libreduction that tries to assign this DecimalArray to a name that libreduction has typed as an ndarray, which raises TypeError",
        "createdAt" : "2019-10-22T15:37:05Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "3040c635-2541-4235-b2cb-37d4149b1170",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "But that is expected I think?",
        "createdAt" : "2019-10-22T16:45:12Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "3b1b6c0b-d83d-4712-a1f5-b6a63e8b47ff",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "we get to decide what is \"expected\"; maybe i dont understand what you're getting at",
        "createdAt" : "2019-10-22T17:06:34Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "aee71c08-62a9-471f-9ad5-c50bf7903545",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Well, we try the fast path, and if that fails, we go for the slow path. So here it fails, so we choose the slow path. That is how I understand that it is currently designed. ",
        "createdAt" : "2019-10-22T17:23:23Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "05967a3f-f3c1-42a7-afb6-bd0befbba850",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "so if we fix the issue in libreduction, there's a chance that the fast path will work",
        "createdAt" : "2019-10-22T19:46:19Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "7c502a7b-2ee6-4840-b2cd-b23262580b90",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "libreduction is not meant to work for all cases, eg if the values is not an ndarray. Yes, we could handle that differently (eg check in advance if it should work), but that is not the approach that is currently taken. I would prefer to limit the scope of this PR to adding the test cases and restoring the old behaviour with a minimal change.",
        "createdAt" : "2019-10-22T19:49:25Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "7fa535db-1071-4a3f-a7ae-0512ed927027",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "OK, how about add the test and xfail it.  i'll get to it shortly",
        "createdAt" : "2019-10-22T19:53:12Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "eee01e7a-4b53-47c5-82f1-e06c07d0b062",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "If you'll get to it shortly, how about merging this (with further edits based on feedback of course), and at least fixing the regression on master? ",
        "createdAt" : "2019-10-22T19:55:32Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "56b9a6f7-e7d6-4ccf-9ed5-f9f669f136f7",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "To clarify: I would personally prefer to merge this without xfail to have the coverage on master. You're doing other PRs cleaning things up in groupby, and it would be good to ensure this keeps working",
        "createdAt" : "2019-10-22T19:58:51Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "27e86cba-c082-4fa2-93de-63679d472c8b",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "fair enough",
        "createdAt" : "2019-10-22T20:04:40Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "8ab3424a-2e68-4f3e-a363-2a3b786a90ca",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "actually, can you do the same `str(err)` checking so that we only let through the relevant TypeErrors?  One of the other PRs afoot is specifically targeting other TypeErrors",
        "createdAt" : "2019-10-22T20:06:07Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "7e1ec13c-56c4-45db-9014-f55d3473b198",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "That's an error message coming from another library though (cython?). Do we have guarantee that that is stable? \r\n(the other two errors that are catched that way are raised by our own code in reduction.pyx)",
        "createdAt" : "2019-10-22T20:14:37Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "602ec7b1-75ee-4e4a-a72b-bca0fb7c9af2",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> Do we have guarantee that that is stable?\r\n\r\nIf nothing else, you can check that both \"ndarray\" and \"DecimalArray\" are present.  I'm sure you can figure something out.\r\n",
        "createdAt" : "2019-10-22T20:37:17Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "234c4ea6-0450-4564-ae7e-54466fdf5be6",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "This is not only for DecimalArray, but for any kind of internal/external EA. ",
        "createdAt" : "2019-10-22T20:47:44Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "8c98b9a1-1328-44ab-8905-aa728fef5f29",
        "parentId" : "492f74d7-621a-4876-a2de-f7b44e11cbcb",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "But can add the check for just ndarray. ",
        "createdAt" : "2019-10-22T20:48:51Z",
        "updatedAt" : "2019-10-23T14:54:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "83535c744532d1fd857f94cd143a2137aa4aebb0",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +676,680 @@            if \"ndarray\" in str(err):\n                # raised in libreduction if obj's values is no ndarray\n                pass\n            else:\n                raise"
  },
  {
    "id" : "82a34f6a-fc4c-4fa1-89ec-8a334cec510d",
    "prId" : 29186,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29186#pullrequestreview-307221754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e963c76-c078-412e-a400-c0b16f805721",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "This is done in the code calling this (via `agg_series`):\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/82df98a04cea9ebb84df2a1271dc1a23f55212ba/pandas/core/groupby/groupby.py#L899-L905\r\n\r\n",
        "createdAt" : "2019-10-25T13:57:05Z",
        "updatedAt" : "2019-10-25T13:57:13Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "f48c9ff12116d70568e99c9334826a3f3ab9f7c7",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +727,731 @@\n        result = lib.maybe_convert_objects(result, try_float=0)\n        # TODO: try_cast back to EA?\n        return result, counts\n"
  },
  {
    "id" : "88163be6-b673-4573-8c94-a0edfaa7fc64",
    "prId" : 29186,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29186#pullrequestreview-307221754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b87f5a79-b7a7-45e1-8bad-38eaa7d28516",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Do you know why it is working for datetimes?",
        "createdAt" : "2019-10-25T13:57:08Z",
        "updatedAt" : "2019-10-25T13:57:13Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "f48c9ff12116d70568e99c9334826a3f3ab9f7c7",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +664,668 @@            # _aggregate_series_fast would raise TypeError when\n            #  calling libreduction.Slider\n            # TODO: is the datetime64tz case supposed to go through here?\n            return self._aggregate_series_pure_python(obj, func)\n"
  },
  {
    "id" : "d087f031-5a03-4e57-b72d-5b5c73e18dc9",
    "prId" : 29195,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29195#pullrequestreview-307178095",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "614a5950-1d26-4b74-8a4f-276d6286de32",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Do you generally know of a reason why we have `_has_complex_internals` as a Index property? I think only changed for a MultiIndex and only applicable in groupby space.\r\n\r\nMight be easier and clearer to just do a isinstance(..., MultiIndex)",
        "createdAt" : "2019-10-23T21:35:03Z",
        "updatedAt" : "2019-10-23T21:35:03Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "d59497e8-14eb-43cc-a5e3-daca1c18128b",
        "parentId" : "614a5950-1d26-4b74-8a4f-276d6286de32",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "I'm not aware of the history there no.",
        "createdAt" : "2019-10-23T22:11:27Z",
        "updatedAt" : "2019-10-23T22:11:27Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "e6b5d344-db59-451d-bf93-38bf3f78874f",
        "parentId" : "614a5950-1d26-4b74-8a4f-276d6286de32",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Cool; just asking - probably a historical relic.\r\n\r\nHaven't gone too deep on this one yet but will file comments (most likely) tomorrow",
        "createdAt" : "2019-10-23T22:16:44Z",
        "updatedAt" : "2019-10-23T22:16:44Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "d2c3bc9e-6a64-4778-bb69-f0580526b74a",
        "parentId" : "614a5950-1d26-4b74-8a4f-276d6286de32",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "_has_complex_internals predates me :->",
        "createdAt" : "2019-10-25T12:46:23Z",
        "updatedAt" : "2019-10-25T12:46:23Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "226937436becacbc0b466256bcab6fc99667d3cf",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +201,205 @@            # with MultiIndex, apply_frame_axis0 would raise InvalidApply\n            # TODO: can we make this check prettier?\n            and not splitter._get_sorted_data().index._has_complex_internals\n        ):\n            try:"
  },
  {
    "id" : "b923c988-b472-4bd2-a32f-7d28b92ba5d6",
    "prId" : 29261,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29261#pullrequestreview-308814259",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05c67f30-d7ba-4341-b923-16c558927bda",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I would move this to the Splittler class something like\r\n\r\n```\r\n@cache_only\r\ndef has_extension_array(self):\r\n     return self.data.dtypes.apply(...)\r\n```\r\n\r\nand can handle this on Series & Frame splitter",
        "createdAt" : "2019-10-29T20:28:53Z",
        "updatedAt" : "2019-11-02T15:30:10Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "9b2ad343-81b0-407e-8ad5-9d75433a33e7",
        "parentId" : "05c67f30-d7ba-4341-b923-16c558927bda",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "yah, this function is definitely getting refactored in a later pass.  id like to get the exceptions sorted out before trying to decide about the refactor",
        "createdAt" : "2019-10-29T20:32:27Z",
        "updatedAt" : "2019-11-02T15:30:10Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "52d781e88f250de0cffa5482c52a4e37251c83c3",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +142,146 @@\n        sdata = splitter._get_sorted_data()\n        if sdata.ndim == 2 and np.any(sdata.dtypes.apply(is_extension_array_dtype)):\n            # calling splitter.fast_apply will raise TypeError via apply_frame_axis0\n            #  if we pass EA instead of ndarray"
  },
  {
    "id" : "23c63669-3d49-46ae-a647-9af03eea1fbe",
    "prId" : 29327,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29327#pullrequestreview-310705770",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d47fdf38-121b-4e46-a014-845e06ab9f95",
        "parentId" : null,
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "i think this edit is unrelated, snuck in on accident",
        "createdAt" : "2019-11-01T21:31:21Z",
        "updatedAt" : "2019-11-02T02:37:08Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "48decb634e58c4037e9daab0d0d17c3290494767",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +791,795 @@\n\ndef _is_indexed_like(obj, axes) -> bool:\n    if isinstance(obj, Series):\n        if len(axes) > 1:"
  },
  {
    "id" : "13aa82d9-9e0b-4ef7-b248-f4b8a47fa4ac",
    "prId" : 29456,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29456#pullrequestreview-316199508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17beec20-013f-4616-9a3b-1af2f6f6704a",
        "parentId" : null,
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "why is this needed?\r\n\r\nshouldn't need to add a type annotation here. maybe the return type of `_get_sorted_data` needs to be added.",
        "createdAt" : "2019-11-10T17:55:23Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "d702b1fe-bd75-4eb9-bf35-f053e69e8d92",
        "parentId" : "17beec20-013f-4616-9a3b-1af2f6f6704a",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "_get_sorted_data return type is annotated, but mypy complains without this",
        "createdAt" : "2019-11-10T17:59:37Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "3947f443-3ee4-43e7-a188-6079efd61646",
        "parentId" : "17beec20-013f-4616-9a3b-1af2f6f6704a",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can update to py3.6 syntax in a followon",
        "createdAt" : "2019-11-12T23:45:36Z",
        "updatedAt" : "2019-11-12T23:45:36Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "b5289b6d-d151-4d98-9e6a-c9af01e08f55",
        "parentId" : "17beec20-013f-4616-9a3b-1af2f6f6704a",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "no longer needed after https://github.com/pandas-dev/pandas/pull/28339/commits/e6c5f5a31e5a5912bd572e08f03756cbc075752c",
        "createdAt" : "2019-11-13T12:12:09Z",
        "updatedAt" : "2019-11-13T12:12:10Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d3d4850150a0b39db41db3d10027c0cd0482d9f",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +154,158 @@        result_values = None\n\n        sdata = splitter._get_sorted_data()  # type: FrameOrSeries\n        if sdata.ndim == 2 and np.any(sdata.dtypes.apply(is_extension_array_dtype)):\n            # calling splitter.fast_apply will raise TypeError via apply_frame_axis0"
  },
  {
    "id" : "8064a74d-b481-4a59-bffa-9470519d5951",
    "prId" : 29456,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29456#pullrequestreview-316198605",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "parentId" : null,
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "why is NDFrame used? is _chop not generic? should DataSplitter be a generic class?",
        "createdAt" : "2019-11-10T18:02:09Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "04ba87f6-2441-4a95-bb51-e9f837036ddf",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "I dont understand the question.  Is \"generic class\" meaningfully different from \"base class\"?  NDFrame is used because one subclass returns Series and the other returns DataFrame",
        "createdAt" : "2019-11-10T18:05:16Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "0f5ca9f9-622c-44bc-a39d-73662894a249",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "`DataSplitter.__init__` accepts `FrameOrSeries`. do we need to persist this type thoughout the class. i.e. make DataSplitter a generic class. see https://mypy.readthedocs.io/en/latest/generics.html#defining-generic-classes",
        "createdAt" : "2019-11-10T18:11:14Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "f6d3d6fe-358b-4787-b598-5b36ce3cbc20",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "so looking at the definition of _chop in the derived classes, i'm guessing this abstractmethod should be typed as \r\n```\r\n def _chop(self, sdata: FrameOrSeries, slice_obj: slice) -> FrameOrSeries:\r\n```",
        "createdAt" : "2019-11-10T18:25:39Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "2a310e51-2170-43c1-abc1-d674c9f74975",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "Using FrameOrSeries here produces complaints:\r\n\r\n```\r\npandas/core/groupby/ops.py:879: error: Argument 1 of \"_chop\" is incompatible with supertype \"DataSplitter\"; supertype defines the argument type as \"FrameOrSeries\"\r\npandas/core/groupby/ops.py:879: error: Return type \"Series\" of \"_chop\" incompatible with return type \"FrameOrSeries\" in supertype \"DataSplitter\"\r\npandas/core/groupby/ops.py:891: error: Argument 1 of \"_chop\" is incompatible with supertype \"DataSplitter\"; supertype defines the argument type as \"FrameOrSeries\"\r\npandas/core/groupby/ops.py:891: error: Return type \"DataFrame\" of \"_chop\" incompatible with return type \"FrameOrSeries\" in supertype \"DataSplitter\"\r\n```\r\n\r\nI'm getting close to saying \"screw it\" when dealing with this type of error.",
        "createdAt" : "2019-11-10T19:48:56Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "cb8d1bfb-5378-4c46-8c61-e8ab7e931f94",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "fair enough. probably best to remove the type annotation here then for now. Having one method return FrameOrSeries and another NDFrame seems inconsistent.",
        "createdAt" : "2019-11-10T19:52:42Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "24c2ac0d-50d0-440d-a8a8-e459445e8ffd",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "I think `NDFrame` is correct here; this function isn't generic in the base class rather the subclasses override with the appropriate object",
        "createdAt" : "2019-11-10T19:53:06Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "5a7dd816-e99c-4bc8-80a0-cb2cd999c642",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "mypy won't be looking at the derived classes when it performs type checking. it'll be looking at the type hints on the base class when it checks other methods in the base class.\r\n\r\nthe abstractmethod should be generic since that is how the derived classes are typed Series -> Series and DataFrame -> DataFrame.\r\n",
        "createdAt" : "2019-11-10T19:58:01Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "e29c8ce9-5d4e-4bc6-8d13-66448e2575ab",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "I think we are mixing a few different paradigms here. The subclasses should probably be annotated with the type respective to the class, rather than using the TypeVar, i.e. you would never parametrize a `SeriesSplitter` with a DataFrame - it exclusively deals with Series objects",
        "createdAt" : "2019-11-10T20:02:46Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "bdd918c6-3ad8-4645-bde4-3fa35c3c89e4",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "> you would never parametrize a `SeriesSplitter` with a DataFrame - it exclusively deals with Series objects\r\n\r\ncorrect. but if a method of the base class is not overridden then the Series type in the derived class will become an NDFrame type after calling that method in the base class.",
        "createdAt" : "2019-11-10T20:07:24Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "c08285ed-3662-407e-85c8-792fa310bea1",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> I think we are mixing a few different paradigms here.\r\n\r\nThere are some annotations in this PR that make it easier to reason about this code while reading it.  The annotations in this sub-thread are not among them, so I do not particularly care about them.  Let's focus for now on a minimal change needed to get this merged, as there are more bugfix PRs waiting in the wings.",
        "createdAt" : "2019-11-10T20:14:25Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "20266dd1-e8a2-4c61-a076-7f80f0a6d8a4",
        "parentId" : "ca4e3447-f5fd-4962-a830-823b9c269fa6",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "https://github.com/pandas-dev/pandas/pull/28339/commits/e6c5f5a31e5a5912bd572e08f03756cbc075752c fixes this.",
        "createdAt" : "2019-11-13T12:10:26Z",
        "updatedAt" : "2019-11-13T12:10:26Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d3d4850150a0b39db41db3d10027c0cd0482d9f",
    "line" : 161,
    "diffHunk" : "@@ -1,1 +896,900 @@        return self.data.take(self.sort_idx, axis=self.axis)\n\n    def _chop(self, sdata, slice_obj: slice) -> NDFrame:\n        raise AbstractMethodError(self)\n"
  },
  {
    "id" : "eb33d33b-05eb-4be1-8744-9e27f979da30",
    "prId" : 29456,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29456#pullrequestreview-314632468",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bb615f4-8c22-4186-a030-149c9bc2e162",
        "parentId" : null,
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "should this be Series?",
        "createdAt" : "2019-11-10T18:05:27Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      },
      {
        "id" : "49eb8172-943c-4c43-bf7a-269e57da7038",
        "parentId" : "5bb615f4-8c22-4186-a030-149c9bc2e162",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "im pretty sure this is correct as-is",
        "createdAt" : "2019-11-10T18:12:17Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "3db6bf78-a822-4f1f-a44a-c6a36220ad6e",
        "parentId" : "5bb615f4-8c22-4186-a030-149c9bc2e162",
        "authorId" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "body" : "ahh ok, had the class FrameSplitter hidden and just saw the class SeriesSplitter above. I guess sdata doesn't mean series data then.",
        "createdAt" : "2019-11-10T18:19:38Z",
        "updatedAt" : "2019-11-12T19:59:49Z",
        "lastEditedBy" : "554ba0f6-6e6a-40c3-98e0-1a6cc4a8e1c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d3d4850150a0b39db41db3d10027c0cd0482d9f",
    "line" : 176,
    "diffHunk" : "@@ -1,1 +913,917 @@        return libreduction.apply_frame_axis0(sdata, f, names, starts, ends)\n\n    def _chop(self, sdata: DataFrame, slice_obj: slice) -> DataFrame:\n        if self.axis == 0:\n            return sdata.iloc[slice_obj]"
  },
  {
    "id" : "9c38824a-f3d2-4e34-8712-eaf47566c350",
    "prId" : 29500,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29500#pullrequestreview-314584209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cf2f437-bc07-4701-a321-fce344c834de",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Hmm should we not just fix `_aggregate_series_fast` to not raise in that case then? Hoping to avoid special casing like this in any groupby functions",
        "createdAt" : "2019-11-10T00:27:11Z",
        "updatedAt" : "2019-11-12T19:51:28Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "58effed0-9981-47f7-9bab-83068da50f95",
        "parentId" : "0cf2f437-bc07-4701-a321-fce344c834de",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> Hoping to avoid special casing like this in any groupby functions\r\n\r\nAgreed on the goal.  ATM this is the best way to make progress towards that goal.  In particular, making this explicit here is much clearer than catching the ValueError with the particular message on L600.\r\n\r\n> should we not just fix _aggregate_series_fast to not raise in that case then? \r\n\r\n#29499 does something along those lines.",
        "createdAt" : "2019-11-10T00:41:59Z",
        "updatedAt" : "2019-11-12T19:51:28Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "38067edeb69915b07c29d0016e3368a5477f39e3",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +606,610 @@\n        if len(obj) == 0:\n            # SeriesGrouper would raise if we were to call _aggregate_series_fast\n            return self._aggregate_series_pure_python(obj, func)\n"
  },
  {
    "id" : "bde6434c-0761-4e78-995a-8f6f3e155ebf",
    "prId" : 29641,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29641#pullrequestreview-318440495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5cfb63fd-3ebb-4f3e-b602-c8a90770e0a8",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Why is this actually needed? For any later iteration, the len-1 `res` is just assigned below with `result[label] = res`, so why does it need to be unpacked for the first group?",
        "createdAt" : "2019-11-18T07:43:40Z",
        "updatedAt" : "2019-11-18T07:44:26Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "83f547f9-f1a9-4b8d-b360-8bba149a10c3",
        "parentId" : "5cfb63fd-3ebb-4f3e-b602-c8a90770e0a8",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "We might be able to get rid of this, but at this stage the goal is just to make the behavior match libreduction._extract_result",
        "createdAt" : "2019-11-18T15:12:42Z",
        "updatedAt" : "2019-11-18T15:12:43Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "4f482ebd-f078-46f8-84fe-2fa2bed80bf4",
        "parentId" : "5cfb63fd-3ebb-4f3e-b602-c8a90770e0a8",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "But in the cython version that calls `_extract_result`, this is done for each group, not just the first (so in that sense it still doesn't match that)",
        "createdAt" : "2019-11-18T15:35:17Z",
        "updatedAt" : "2019-11-18T15:35:18Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "3c8a4093-a932-48dc-9f88-b781b874b453",
        "parentId" : "5cfb63fd-3ebb-4f3e-b602-c8a90770e0a8",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : ">  But in the cython version that calls _extract_result, this is done for each group, not just the first (so in that sense it still doesn't match that)\r\n\r\nThis is correct.  The more closely matching behavior is that only the first group is checked for array-like (there's also a discrepancy in what types of arraylikes are checked)  (there's  also^2 a discrepancy in that Reducer.get_result does a `res = res.values` check that is similar to _extract_result but not quite the same)",
        "createdAt" : "2019-11-18T15:59:36Z",
        "updatedAt" : "2019-11-18T15:59:36Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "d542515e3c1d77d1cf37c3008224c83406bb8edb",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +664,668 @@                        # TODO: use `.item()` if/when we un-deprecate it.\n                        # For non-Series we could just do `res[0]`\n                        res = next(iter(res))\n                    else:\n                        raise ValueError(\"Function does not reduce\")"
  }
]