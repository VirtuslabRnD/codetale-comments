[
  {
    "id" : "353f0e7b-8c51-4089-b3f3-da652216d41b",
    "prId" : 4073,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21e38615-683a-4ac3-924d-44f466159f54",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "boy - guess was not thinking when I originally wrote that\n",
        "createdAt" : "2013-06-28T14:57:00Z",
        "updatedAt" : "2013-06-28T16:00:01Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "ec43b1ed-aad0-431e-aa37-ebf4d6ceca23",
        "parentId" : "21e38615-683a-4ac3-924d-44f466159f54",
        "authorId" : "5c239b83-5a68-467b-a3f8-113a0fc494dc",
        "body" : "still worked tho...strange since enumerate composed with range should yield a tuple thus accessing the diagonal of the mask (in this case)...seems like that would have broken things (in a more general way)\n",
        "createdAt" : "2013-06-28T15:01:20Z",
        "updatedAt" : "2013-06-28T16:00:01Z",
        "lastEditedBy" : "5c239b83-5a68-467b-a3f8-113a0fc494dc",
        "tags" : [
        ]
      },
      {
        "id" : "594c1684-257b-4836-859b-009362392cc3",
        "parentId" : "21e38615-683a-4ac3-924d-44f466159f54",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok if your fix worked grrat\n",
        "createdAt" : "2013-06-28T15:06:41Z",
        "updatedAt" : "2013-06-28T16:00:01Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "3bac1816bac4be72ef2be7ab305eaea081604c2f",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +578,582 @@        axis = cond.ndim - 1\n        cond = cond.swapaxes(axis, 0)\n        mask = np.array([cond[i].all() for i in xrange(cond.shape[0])],\n                        dtype=bool)\n"
  },
  {
    "id" : "8fbd2cfb-8de0-46c3-8878-469f4114cdb5",
    "prId" : 4313,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9aca9b9b-d313-4dee-af2a-294815501cb3",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "use a date_formatter function (like above); you don't need to handle nulls here as that is already handled in the imask (eg you will get NO nulls in the list comprehension)\n",
        "createdAt" : "2013-10-09T12:05:35Z",
        "updatedAt" : "2013-10-12T05:11:18Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce669d6f295f7ece6223535c75c5012cb3c553c1",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1410,1414 @@        rvalues[mask] = na_rep\n        imask = (-mask).ravel()\n\n        if date_format is None:\n            date_formatter = lambda x: Timestamp(x)._repr_base"
  },
  {
    "id" : "7c96ed60-01e0-4f32-9c4f-002739ab6235",
    "prId" : 4756,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "040aeb6b-3d5c-4bae-90f6-fc7a3c675d8f",
        "parentId" : null,
        "authorId" : "5c239b83-5a68-467b-a3f8-113a0fc494dc",
        "body" : "Should there be tests for negative slices? Or are those somewhere else?\n",
        "createdAt" : "2013-09-05T20:16:34Z",
        "updatedAt" : "2013-09-06T01:16:11Z",
        "lastEditedBy" : "5c239b83-5a68-467b-a3f8-113a0fc494dc",
        "tags" : [
        ]
      }
    ],
    "commit" : "caa370374b1c495e4d998ae1e11c1561fcbac511",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +568,572 @@                if start is None:\n                    start = 0\n                elif start < 0:\n                    start += l\n                if stop is None or stop > l:"
  },
  {
    "id" : "afa83aa1-3d4e-4497-af81-7c8a67918c68",
    "prId" : 5270,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8380833d-0a99-4261-9828-7600995fc64a",
        "parentId" : null,
        "authorId" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "body" : "What do you think of: `Length mismatch: Existing axis has %d elements, new values have %d elements`? Might be clearer.\n",
        "createdAt" : "2013-10-20T20:23:18Z",
        "updatedAt" : "2013-10-20T20:23:18Z",
        "lastEditedBy" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c502a2faf8a8fd2200f2ad076b5b3f76d8c38e9",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1882,1886 @@\n        if check_axis and len(value) != len(cur_axis):\n            raise ValueError('Length mismatch: Expected %d elements, got %d elements'\n                            % (len(cur_axis), len(value)))\n"
  },
  {
    "id" : "d768dcdb-0889-4092-a3fd-8af466f44b3e",
    "prId" : 5283,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a84f10c-5d51-4d58-b7de-8892c718d417",
        "parentId" : null,
        "authorId" : "49cb7e4b-934a-4329-961e-4089057c4185",
        "body" : "I just want to record this here, since my thoughts on this matter have been so muddled:\n\n`np.array_equal` treats NaNs in object arrays as equal:\n\n```\n>>> np.array_equal(np.array([np.nan], dtype='O'), np.array([np.nan], dtype='O'))\nTrue\n```\n\nso object arrays do not need to be special-cased, `ObjectBlock.equals` does not need to be defined, and `ObjectBlock.equals` can defer to `Block.equals`. Only `FloatBlocks` and `ComplexBlocks` need to define their own `equals` method, since, for example,\n\n```\n>>> np.array_equal(np.array([np.nan], dtype='<f4'), np.array([np.nan], dtype='<f4'))\nFalse\n>>> np.array_equal(np.array([np.nan], dtype='complex128'), np.array([np.nan], dtype='complex128'))\nFalse\n```\n\nThankfully, `np.array_equal` also treats `NaT`s as equal:\n\n```\n>>> np.array_equal(np.array([np.datetime64('nat')]), np.array([np.datetime64('nat')]))\nTrue\n```\n\n`NaNs` can not exist in `bool` arrays:\n\n```\n>>> np.array([np.nan], dtype='bool')\narray([ True], dtype=bool)\n```\n\nor can `NaN`s exist in timedeltas:\n\n```\n>>> np.timedelta64(np.nan,'D')\nValueError: Could not convert object to NumPy timedelta\n```\n\nso `np.array_equal` should work as usual for these kinds of values.\n",
        "createdAt" : "2014-01-21T22:02:12Z",
        "updatedAt" : "2014-01-24T21:01:32Z",
        "lastEditedBy" : "49cb7e4b-934a-4329-961e-4089057c4185",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f26fbc915e2759e0bcadaa93cb00610297e6a7e",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1124,1128 @@    def equals(self, other):\n        if self.dtype != other.dtype or self.shape != other.shape: return False\n        return np.array_equal(self.values, other.values)\n\n"
  },
  {
    "id" : "bd67c065-e868-4c03-a042-063933d964af",
    "prId" : 5283,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1aa2b2f8-6b2d-4449-8753-d2e4f979c9cd",
        "parentId" : null,
        "authorId" : "49cb7e4b-934a-4329-961e-4089057c4185",
        "body" : "The example you gave did indeed break the code. I've added your example to test_internals.py and am handling this case by sorting the blocks according to their `ref_locs`.\n",
        "createdAt" : "2014-01-23T04:18:45Z",
        "updatedAt" : "2014-01-24T21:01:32Z",
        "lastEditedBy" : "49cb7e4b-934a-4329-961e-4089057c4185",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f26fbc915e2759e0bcadaa93cb00610297e6a7e",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +4025,4029 @@            dtype = blocks[0].dtype\n\n        if not items.is_unique:\n            blocks = sorted(blocks, key=lambda b: b.ref_locs.tolist())\n"
  },
  {
    "id" : "8ea2a7f4-3200-4a36-bbd5-74b2f4e11ed7",
    "prId" : 6745,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/6745#pullrequestreview-404356698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98f9361b-96ab-4b99-a908-22099cbb6816",
        "parentId" : null,
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "@jreback long-shot any idea if this FIXME is still needed or what it would take to address?",
        "createdAt" : "2020-05-01T14:04:27Z",
        "updatedAt" : "2020-05-01T14:04:27Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "54540c7c-936b-4796-aa8a-a9376cfbdf9f",
        "parentId" : "98f9361b-96ab-4b99-a908-22099cbb6816",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "no idea\nsorry ",
        "createdAt" : "2020-05-01T16:33:12Z",
        "updatedAt" : "2020-05-01T16:33:12Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "6992041c-ba75-4719-8781-81d335c1cb01",
        "parentId" : "98f9361b-96ab-4b99-a908-22099cbb6816",
        "authorId" : "413be534-cedb-4df7-abda-cde26db33acd",
        "body" : "This PR is sure quite a trip down the memory lane :) \r\n\r\nUnfortunately, I don't quite remember what was the problem with pytables serialisation here, but looks like mgr_locs are returned in ascending order from `lib.get_blkno_indexers` anyway, so it's likely that the FIXME is not needed anymore.",
        "createdAt" : "2020-05-01T19:33:53Z",
        "updatedAt" : "2020-05-01T19:33:54Z",
        "lastEditedBy" : "413be534-cedb-4df7-abda-cde26db33acd",
        "tags" : [
        ]
      }
    ],
    "commit" : "f51235aef9bbb50632b569d9e0c104816e5e31a0",
    "line" : 2950,
    "diffHunk" : "@@ -1,1 +2863,2867 @@        #\n        # FIXME: mgr_groupby_blknos must return mgr_locs in ascending order,\n        # pytables serialization will break otherwise.\n        blocks = []\n        for blkno, mgr_locs in _get_blkno_placements(blknos, len(self.blocks),"
  },
  {
    "id" : "ba7a2f2c-5a26-489b-8419-2f1f085ea0d9",
    "prId" : 7370,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0813edea-72c8-4933-898c-8f51cc79fde3",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "why don't you add a version tag instead, this seems kind of odd to do it this way\n",
        "createdAt" : "2014-06-18T20:54:48Z",
        "updatedAt" : "2014-07-01T04:31:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "4e7b5f80-76ab-490e-9ba0-25506fcd0ff0",
        "parentId" : "0813edea-72c8-4933-898c-8f51cc79fde3",
        "authorId" : "413be534-cedb-4df7-abda-cde26db33acd",
        "body" : "There's an \"upcoming\" version tag, as in the first stable version having this serialization format, serving as a key into this dictionary. Or do you mean something else?\n",
        "createdAt" : "2014-06-18T21:12:29Z",
        "updatedAt" : "2014-07-01T04:31:26Z",
        "lastEditedBy" : "413be534-cedb-4df7-abda-cde26db33acd",
        "tags" : [
        ]
      },
      {
        "id" : "feb160dd-8242-4934-a4ec-77dc73c83e69",
        "parentId" : "0813edea-72c8-4933-898c-8f51cc79fde3",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "no I meant having the version as the _key_ was odd, why not just as a key-value in the dict, e.g. `version : '0.14.1'`\n",
        "createdAt" : "2014-06-18T21:13:51Z",
        "updatedAt" : "2014-07-01T04:31:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "65bbf9ec-cdef-498f-a272-59839b22b041",
        "parentId" : "0813edea-72c8-4933-898c-8f51cc79fde3",
        "authorId" : "413be534-cedb-4df7-abda-cde26db33acd",
        "body" : "I figured, something like this:\n\n``` python\nfor ver in list(supported_versions):\n    if ver in state:\n        setstate_ver(state[ver])\n```\n\nwould be easier on the eye than:\n\n``` python\nfor ver in list(supported_versions):\n     for d in state.values():\n        if d['version'] == ver:\n            setstate(d)\n            break\n```\n\nBut it's not a strong opinion, rather a gut feeling. If you insist, I'll make the version a dictionary element again.\n",
        "createdAt" : "2014-06-18T21:25:04Z",
        "updatedAt" : "2014-07-01T04:31:26Z",
        "lastEditedBy" : "413be534-cedb-4df7-abda-cde26db33acd",
        "tags" : [
        ]
      },
      {
        "id" : "dd19d504-efff-42aa-b59b-973873e9068b",
        "parentId" : "0813edea-72c8-4933-898c-8f51cc79fde3",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok, either way is fine. Just trying to make it easy on future versions.\n",
        "createdAt" : "2014-06-18T21:32:55Z",
        "updatedAt" : "2014-07-01T04:31:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9761d1331694620de13afdd7c70315203ef510a",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +2055,2059 @@        axes_array = [ax for ax in self.axes]\n\n        extra_state = {\n            '0.14.1': {\n                'axes': axes_array,"
  },
  {
    "id" : "103b9bbd-703c-452e-b919-fa77c4e8bd36",
    "prId" : 10179,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0f94c83-5a97-44d0-81ef-106ee3dc6bb0",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "Instead of this, I think change line 4129 (`get_empty_dtype_na`) to have it return `np.dtype(np.object_)` for 'category' (this is ONLY for the empty dtype). Then remove the 'is_categorical' check above. This may break other things though, which will need attention. \n",
        "createdAt" : "2015-05-21T13:24:16Z",
        "updatedAt" : "2015-06-27T15:27:46Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "023fc371cc900e28cffaf7b8c436b23f80e22f40",
    "line" : null,
    "diffHunk" : "@@ -1,1 +4405,4409 @@            fill_value = upcasted_na\n\n            if self.is_null and not getattr(self.block,'is_categorical',None):\n                missing_arr = np.empty(self.shape, dtype=empty_dtype)\n                if np.prod(self.shape):"
  },
  {
    "id" : "0472a093-c7c7-46bd-bfca-858423c9931e",
    "prId" : 11153,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62aecf51-6ac8-4843-8a97-c51f3cbfb4fa",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you don't need to test this because you know `inplace`, e.g. just use an if?\n",
        "createdAt" : "2015-09-20T00:26:26Z",
        "updatedAt" : "2015-09-20T00:26:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "6e73e502-d39c-4497-a965-570ed60baa80",
        "parentId" : "62aecf51-6ac8-4843-8a97-c51f3cbfb4fa",
        "authorId" : "2bab095f-50fb-401e-ab9e-c09e00e2b00c",
        "body" : "I added `mask.any()` condition to handle the case when the block contains no `Nan`. In this case:\n- We can return the block as it is. \n- Don't want to coerce data to `object` even if the fill value is `object`.\n- `DatetimeTZBlock` can perform inplace op in this case. Otherwise can't because it's internal value is `DatetimeIndex`.\n\nLet me do a follow-up if I do something wrong.\n",
        "createdAt" : "2015-09-20T21:07:23Z",
        "updatedAt" : "2015-09-20T21:07:23Z",
        "lastEditedBy" : "2bab095f-50fb-401e-ab9e-c09e00e2b00c",
        "tags" : [
        ]
      },
      {
        "id" : "45ac8689-495d-4e5d-85b3-2e105f226cb2",
        "parentId" : "62aecf51-6ac8-4843-8a97-c51f3cbfb4fa",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "hah...i already merged. the code looked reasonable.\n\nhave a look and see if anything needs cleaning (or not ok too).\n\nthanks!\n",
        "createdAt" : "2015-09-20T21:18:34Z",
        "updatedAt" : "2015-09-20T21:18:34Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7c705a99a634c69bc5e7a1af09e2445ea73300b",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1960,1964 @@            try:\n                return self._fillna_mask(mask, value, inplace=inplace)\n            except TypeError:\n                pass\n            # _fillna_mask raises TypeError when it fails"
  },
  {
    "id" : "ff2b25c7-2556-4e4a-a4b9-a9f8895af83d",
    "prId" : 13766,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/13766#pullrequestreview-32447102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bf318d9-d46c-4ed8-8b3b-cbb7775ef9ed",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this shoukd be in a rename method in Index\nMI should also just iterate in the levels and call rename on that Index\n\nshould not be in internals \n",
        "createdAt" : "2016-07-23T16:39:10Z",
        "updatedAt" : "2017-04-18T08:01:30Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "3aea4274-7af3-417b-8629-27e04cacddd2",
        "parentId" : "5bf318d9-d46c-4ed8-8b3b-cbb7775ef9ed",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Well, that's how rename is implemented at the moment .. \nAnd AFAIK there is not a rename method on Index itself? (there is, but that is to change the name attribute, so something else)\n",
        "createdAt" : "2016-07-24T18:25:04Z",
        "updatedAt" : "2017-04-18T08:01:30Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "4f967ae0-2c6f-49c7-b297-060085884751",
        "parentId" : "5bf318d9-d46c-4ed8-8b3b-cbb7775ef9ed",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "no I mean move it there \nmuch cleaner to do it\n",
        "createdAt" : "2016-07-24T18:30:28Z",
        "updatedAt" : "2017-04-18T08:01:30Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "c57d2388-a9dd-42bd-b00d-4bb35e42b677",
        "parentId" : "5bf318d9-d46c-4ed8-8b3b-cbb7775ef9ed",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "So I mean this comment. Do you mean it would be cleaner to have a method on Index/MultiIndex itself that does this renaming? \r\nI can agree with that, but the problem is that there already is a 'rename' method which renames the `names` of a multi index (it could of course also be a private method)\r\n\r\nBut my preference is to leave the existing implementation intact in this PR (I just expanded the existing method a bit).",
        "createdAt" : "2017-04-12T16:49:04Z",
        "updatedAt" : "2017-04-18T08:01:30Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "3edc3c99-62e6-432f-8065-f1964ae0b479",
        "parentId" : "5bf318d9-d46c-4ed8-8b3b-cbb7775ef9ed",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "yes I mean move this to ``MultiIndex``, and create a corresponding (private is fine) one for ``Index``. ideally it *would* be ``rename``, but I guess has to be a private method.",
        "createdAt" : "2017-04-12T17:49:33Z",
        "updatedAt" : "2017-04-18T08:01:30Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "1915696904aeb661c3d6b3a4f5350a02f13a03fb",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +4747,4751 @@    if isinstance(index, MultiIndex):\n        if level is not None:\n            items = [tuple(func(y) if i == level else y\n                           for i, y in enumerate(x)) for x in index]\n        else:"
  },
  {
    "id" : "8bc4452f-c882-41ab-b5b4-1d62780b289d",
    "prId" : 14536,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14536#pullrequestreview-6364158",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0fdbcc4f-aed8-4f5d-8273-4ad18c132ee0",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "from pandas.types.common import is_scalar\n",
        "createdAt" : "2016-10-30T13:54:45Z",
        "updatedAt" : "2016-11-01T10:40:28Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd247b49d5a99f148f2b9cd45af270d17d21c7f",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1317,1321 @@\n        def _nanpercentile1D(values, mask, q, **kw):\n            values = values[~mask]\n\n            if len(values) == 0:"
  },
  {
    "id" : "71473bc4-5088-490f-91d5-72f14924a801",
    "prId" : 14536,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14536#pullrequestreview-6807018",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "446d3af6-0fcf-475d-9622-7bac8a6e202a",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I might move some of this to  to `pandas.core.nanops` (though  you might have to move slightly more as that takes axis arg). Its esentially what you are doing here, but in a slightly more general framework. call it `nanquantile` (or `nanpercentile`)\n",
        "createdAt" : "2016-10-30T13:57:27Z",
        "updatedAt" : "2016-11-01T10:40:28Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "2c692712-6841-4617-9ee7-b0abd405b8a8",
        "parentId" : "446d3af6-0fcf-475d-9622-7bac8a6e202a",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "The reason I did not put it there initially, was because this is less general as the current functions in the `nanops` module. For example, I pass here the `mask` alongside the values because datetimelike values are already converted to integers at this point (where the NaTs are filled) because `np.percentile` cannot deal with datetime-like values\n",
        "createdAt" : "2016-10-30T17:52:35Z",
        "updatedAt" : "2016-11-01T10:40:28Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "20ee1786-9f18-42dd-8965-d8c7b2aaa7e4",
        "parentId" : "446d3af6-0fcf-475d-9622-7bac8a6e202a",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "@jreback Opinion about this?\n",
        "createdAt" : "2016-11-02T11:28:22Z",
        "updatedAt" : "2016-11-02T11:28:22Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "a22496d5-a12c-4895-b6b2-464d9452582b",
        "parentId" : "446d3af6-0fcf-475d-9622-7bac8a6e202a",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I meant move ALL of this; the nanops do everything (based on dtype), are basically ufuncs per-dtype. Its ok for now if you want to merge (to fix the bug). But let's open a new issue to move this code. All of the rest of it is there (for other ops). We don't _do_ very much inside the block managers, mainly just assemble blocks, actual calculations are pushed to other routines (numpy or pandas)\n",
        "createdAt" : "2016-11-02T11:35:50Z",
        "updatedAt" : "2016-11-02T11:35:51Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "69f22349-08f5-48de-81f7-e84d8605a817",
        "parentId" : "446d3af6-0fcf-475d-9622-7bac8a6e202a",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "sounds good, will open a new issue (and one for the failing empty ones as well)\n",
        "createdAt" : "2016-11-02T12:59:17Z",
        "updatedAt" : "2016-11-02T12:59:17Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd247b49d5a99f148f2b9cd45af270d17d21c7f",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +1325,1329 @@                    return np.array([self._na_value] * len(q),\n                                    dtype=values.dtype)\n\n            return np.percentile(values, q, **kw)\n"
  },
  {
    "id" : "2ad2ecd0-9de8-482f-97ed-54bf6164d6f7",
    "prId" : 14967,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14967#pullrequestreview-14293303",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2337b90-fdea-45e1-a39e-ced094de9cea",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you check the errors in ['raise', 'ignore'] at the beginning of the function and raise a ValueError otherwise (and add a test for this)",
        "createdAt" : "2016-12-23T00:09:59Z",
        "updatedAt" : "2017-01-03T20:52:56Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "ff9a2334-84b8-4bc3-8e9e-2efcdd325616",
        "parentId" : "a2337b90-fdea-45e1-a39e-ced094de9cea",
        "authorId" : "7fd30c76-727b-4746-bf1c-c9571ce401e1",
        "body" : "Sure, there are two 'public' `astype(...)` methods: \r\n\r\n- `NDFrame.astype(...)` in `pandas/core/generic.py`\r\n- `Block.astype(...)` in `pandas/core/internals.py`\r\n\r\nIn addition there is a 'protected' `Block._astype(...)` method in  \r\n`pandas/core/internals.py`. Should I only put the checks in the 'public' \r\nmethods?\r\n\r\nBearing in mind that the `raise_on_error` kwarg is going to be deprecated for\r\n`DataFrame.where()` and replaced with the `errors` kwarg it would make sense to\r\nput the code that checks the validity of the arguments in one place. Do we have \r\nany existing code where we put such validity checking functions/methods?\r\n\r\nI notice that both `NDFrame` & `Block` inherit from `PandasObject` but, I'm not \r\nsure that this is the correct thing to do. Should I put a function in \r\n`pandas/core/base.py`?  ",
        "createdAt" : "2016-12-23T11:34:13Z",
        "updatedAt" : "2017-01-03T20:52:56Z",
        "lastEditedBy" : "7fd30c76-727b-4746-bf1c-c9571ce401e1",
        "tags" : [
        ]
      },
      {
        "id" : "d20e6285-cd14-42aa-8ed5-a59fd0d5ed25",
        "parentId" : "a2337b90-fdea-45e1-a39e-ced094de9cea",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "Block is completely internal\r\nu can put the check there\r\n\r\nwe have centralized checks but no need in this case \r\n\r\nout in _astype as that's where it's actually used \r\nparameter validation is best down where it's actually ",
        "createdAt" : "2016-12-23T12:06:01Z",
        "updatedAt" : "2017-01-03T20:52:56Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "b174e6f4dec2faa3eaf9124dc694c3fd92e1a890",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +461,465 @@\n    def _astype(self, dtype, copy=False, errors='raise', values=None,\n                klass=None, mgr=None, **kwargs):\n        \"\"\"\n        Coerce to the new type (if copy=True, return a new copy)"
  },
  {
    "id" : "f1ec96c3-cf41-4a2f-8dd1-da94e724734a",
    "prId" : 16015,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/16015#pullrequestreview-63811512",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6d1e3fa-11a5-4f97-8bfd-5c54ee8663f5",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "hmm, this seems to contract the\r\n\r\n``elif is_categorical_dtype(dtype)``\r\n\r\nIOW we DO allow ``CategoricalDtype``, just not ``Categorical/CategoricalIndex`` here\r\n\r\nyou can just use ``pandas_dtype`` I think",
        "createdAt" : "2017-09-09T17:41:58Z",
        "updatedAt" : "2017-09-23T16:33:31Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "fa80926d-1d39-4893-86e1-9f519dc824ae",
        "parentId" : "c6d1e3fa-11a5-4f97-8bfd-5c54ee8663f5",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Some test was failing without this earlier. I'll see if I can revert it and figure out what was going on.",
        "createdAt" : "2017-09-09T23:04:16Z",
        "updatedAt" : "2017-09-23T16:33:31Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "24572d99-e830-45a7-b287-bd7cb3175e8c",
        "parentId" : "c6d1e3fa-11a5-4f97-8bfd-5c54ee8663f5",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Ah, this is to disallow passing in the class `CategoricalDtype`, instead of an instance. Without the check, you get an object dtype when (incorrectly) passing `CategoricalDtype` (not an instance)\r\n\r\n```python\r\nIn [17]: pd.Series([1, 2]).astype(CategoricalDtype)\r\nOut[17]:\r\n0    1\r\n1    2\r\ndtype: object\r\n```\r\n",
        "createdAt" : "2017-09-19T21:37:33Z",
        "updatedAt" : "2017-09-23T16:33:32Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "43f90cc13786b57b89709cdb7dd8d2c023adaee6",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +140,144 @@        returns a boolean if we are a categorical\n        \"\"\"\n        if dtype is Categorical or dtype is CategoricalDtype:\n            # this is a pd.Categorical, but is not\n            # a valid type for astypeing"
  },
  {
    "id" : "7601171f-c54b-4e21-9f0a-35e116469822",
    "prId" : 16015,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/16015#pullrequestreview-63811628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12b07130-651c-4c45-9c88-76f89c6a9d2d",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I think let's deprecate this",
        "createdAt" : "2017-09-09T17:42:27Z",
        "updatedAt" : "2017-09-23T16:33:31Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "ce4110b9-ba4a-4bd9-a86a-bf5b4523892b",
        "parentId" : "12b07130-651c-4c45-9c88-76f89c6a9d2d",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Will raise a followup issue.",
        "createdAt" : "2017-09-19T21:37:55Z",
        "updatedAt" : "2017-09-23T16:33:32Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "43f90cc13786b57b89709cdb7dd8d2c023adaee6",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +555,559 @@                                \"`dtype=CategoricalDtype(categories, ordered)`\"\n                                \" instead.\")\n            kwargs = kwargs.copy()\n            categories = getattr(dtype, 'categories', None)\n            ordered = getattr(dtype, 'ordered', False)"
  },
  {
    "id" : "0cc20eb7-daf0-41f3-bfa1-5e9f728d8083",
    "prId" : 17728,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17728#pullrequestreview-67675466",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d8f93fa-63c1-4879-884d-bb96def3b83b",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "a mouthful!\r\n\r\ncan you put blank lines in between statements",
        "createdAt" : "2017-10-06T13:58:28Z",
        "updatedAt" : "2017-10-10T23:27:16Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb5a100b314d7f19dda19bfb5ef0889ac3dd5e36",
    "line" : 160,
    "diffHunk" : "@@ -1,1 +5203,5207 @@    \"\"\"\n    return (\n        # all blocks need to have the same type\n        all([type(ju.block) is type(join_units[0].block) for ju in join_units]) and  # noqa\n        # no blocks that would get missing values (can lead to type upcasts)"
  },
  {
    "id" : "4813a52e-7d91-4407-a604-b42d27fe36d7",
    "prId" : 17728,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17728#pullrequestreview-68705284",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a1f39e8-e0f8-4d44-86c0-72cd698b597e",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "actually you could combine all of these ``concat_same_type`` into a single routine  if you did this\r\n\r\n```\r\ndef concat_same_type(self, to_concat, placement=None)\r\n       \"\"\"\r\n       Concatenate list of single blocks of the same type.\r\n       \"\"\"\r\n        values = self._concatenator([blk.values for blk in to_concat], axis=self.ndim - 1)\r\n        return self.make_block_same_class(\r\n            values, placement=placement or slice(0, len(values), 1))\r\n```\r\n\r\nThen add to Block\r\n```\r\n_concatenator = np.concatenate\r\n```\r\nCategorical\r\n```\r\n_concatnator = _concat._concat_categorical\r\n```\r\n\r\netc",
        "createdAt" : "2017-10-10T03:38:19Z",
        "updatedAt" : "2017-10-10T23:27:16Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "cf443fe4-c5f6-4f96-92e7-5f0f373c9388",
        "parentId" : "5a1f39e8-e0f8-4d44-86c0-72cd698b597e",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Ah, that would actually be nice. The only problem with this is that (for the reasons that I had the if/else statements originally) `self.make_block_same_class` will not always work. Eg ``_concat_categorical`` can return both categorical values as object values, and depending on that should return a CategoricalBlock or another type of Block. ",
        "createdAt" : "2017-10-10T07:25:52Z",
        "updatedAt" : "2017-10-10T23:27:16Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "4237039d-d796-4ea9-a70b-b0da492c480a",
        "parentId" : "5a1f39e8-e0f8-4d44-86c0-72cd698b597e",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "so for categorical block override; otherwise u end up repeating lots of code",
        "createdAt" : "2017-10-10T18:33:20Z",
        "updatedAt" : "2017-10-10T23:27:16Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a3f3c10a-70cb-402e-91be-a4d4f0d7b264",
        "parentId" : "5a1f39e8-e0f8-4d44-86c0-72cd698b597e",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "but need to overwrite for Datetimetz as well, so then end up with almost as many overridden ones as now (only for Sparse it would not be needed then). ",
        "createdAt" : "2017-10-10T22:23:50Z",
        "updatedAt" : "2017-10-10T23:27:16Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "2d2eade4-3801-405e-b222-e2b4cb0b2b47",
        "parentId" : "5a1f39e8-e0f8-4d44-86c0-72cd698b597e",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this is still repeatting way too much code. you can just do it this way\r\n\r\nin Block\r\n```\r\ndef concat_same_type(self, to_concat, constructor=None, placement=None):\r\n     values = self._concatenator(......)\r\n    if constructor is None:\r\n        constructor = make_block\r\n      return constructor(....)\r\n```\r\n\r\nthen where needed\r\n\r\n```\r\ndef concat_same_type(.......):\r\n      return super(Categorical, self).concat_same_type(....., constructor=self.make_block_same_class)\r\n```\r\n\r\nthat way for an overriden class you are not repeating evertyhing.",
        "createdAt" : "2017-10-11T18:25:03Z",
        "updatedAt" : "2017-10-11T18:25:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb5a100b314d7f19dda19bfb5ef0889ac3dd5e36",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +316,320 @@        return _merge_blocks([self, other])\n\n    def concat_same_type(self, to_concat, placement=None):\n        \"\"\"\n        Concatenate list of single blocks of the same type."
  },
  {
    "id" : "a0ab421d-ce27-4405-a72b-a3046112363f",
    "prId" : 17728,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17728#pullrequestreview-68549530",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc220429-1305-4252-be25-e62bfb8bde79",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "could some of this logic be moreve to concaty_same_type?",
        "createdAt" : "2017-10-10T23:54:47Z",
        "updatedAt" : "2017-10-10T23:54:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "3a2ba184-e871-4212-81c6-15d146fc1ca1",
        "parentId" : "cc220429-1305-4252-be25-e62bfb8bde79",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Which logic do you mean exactly? \r\nFor now, I coded `concat_same_type` such that is assumes only blocks of the same type are passed (so I don't do the checking there, but before the method is called)",
        "createdAt" : "2017-10-11T09:53:02Z",
        "updatedAt" : "2017-10-11T09:53:02Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb5a100b314d7f19dda19bfb5ef0889ac3dd5e36",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +4575,4579 @@            blocks = [obj.blocks[0] for obj in non_empties]\n\n            if all([type(b) is type(blocks[0]) for b in blocks[1:]]):  # noqa\n                new_block = blocks[0].concat_same_type(blocks)\n            else:"
  },
  {
    "id" : "de766c1d-ed66-49ec-8264-b9117a85df87",
    "prId" : 18458,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18458#pullrequestreview-79013811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6625efb-779f-4484-b21b-4eee1f3e24bf",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "change this to ``transpose`` instead. should be straightforward from here.",
        "createdAt" : "2017-11-25T23:09:28Z",
        "updatedAt" : "2017-11-26T12:02:14Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "16bcc1c9-0fb3-4bf4-85f1-c2a07f3cad44",
        "parentId" : "f6625efb-779f-4484-b21b-4eee1f3e24bf",
        "authorId" : "c2e7df75-d1fb-42be-9205-186b46cef3d7",
        "body" : "Thanks a lot, ``transpose`` is of course much better than ``axis``.\r\n\r\nThe issue was actually in the ``if len(self.blocks) == 0:`` block, as the empty array also must be transposed. \r\n\r\nEverything is green now locally and I've pushed that upstream.",
        "createdAt" : "2017-11-26T00:04:24Z",
        "updatedAt" : "2017-11-26T12:02:14Z",
        "lastEditedBy" : "c2e7df75-d1fb-42be-9205-186b46cef3d7",
        "tags" : [
        ]
      }
    ],
    "commit" : "48e1fc84811aba2831c38f2db20102bdf8ed8c4e",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +3697,3701 @@        if self._is_single_block or not self.is_mixed_type:\n            arr = mgr.blocks[0].get_values()\n        else:\n            arr = mgr._interleave()\n"
  },
  {
    "id" : "6ea81ec8-9c2d-4e52-9955-be6110b23be4",
    "prId" : 18710,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18710#pullrequestreview-82696842",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2ef9a6d-fdc1-4a4e-9e38-a68f182d067f",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I don't think you need all of this logic, wouldn't\r\n\r\n```\r\nvalues = self.values.astype(dtype, copy=copy)\r\n\r\nreturn self.make_block(values, dtype=dtype)\r\n```\r\nbe enough (if values is a Categorical already or dtype is a CDT, it will infer correctly, and if its not it will as well).",
        "createdAt" : "2017-12-10T14:54:46Z",
        "updatedAt" : "2017-12-13T03:37:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "eb0358fe-b4cc-4b8d-9968-238fac489300",
        "parentId" : "d2ef9a6d-fdc1-4a4e-9e38-a68f182d067f",
        "authorId" : "7545b4d7-157f-47c4-b7f8-18bf358d429c",
        "body" : "I don't think that quite works, since `self.values` can be a different object depending on what `self` is: if `self` is already categorical, then `self.values` is a `Categorical`, otherwise `self.values` is a numpy array.\r\n\r\nIn the numpy case, `self.values.astype` raises `TypeError: data type not understood` when a `CDT` is passed as the dtype.\r\n\r\nLikewise, `self.make_block(Categorical(self.values, dtype=dtype))` also doesn't work by itself.  In the `Categorical` case, the constructor ignores the `dtype` parameter when the input data is already `Categorical`, so no update occurs.\r\n\r\nSeems like the two paths are necessary?  Or am I overlooking something?",
        "createdAt" : "2017-12-11T22:36:30Z",
        "updatedAt" : "2017-12-13T03:37:26Z",
        "lastEditedBy" : "7545b4d7-157f-47c4-b7f8-18bf358d429c",
        "tags" : [
        ]
      },
      {
        "id" : "4cc804b4-607d-4c63-8168-bb54795f5733",
        "parentId" : "d2ef9a6d-fdc1-4a4e-9e38-a68f182d067f",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok seems reasonable then",
        "createdAt" : "2017-12-12T01:31:17Z",
        "updatedAt" : "2017-12-13T03:37:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "6702f909d2843cf6c0923c9392af59eaf43981d2",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +594,598 @@                dtype = CategoricalDtype(categories, ordered)\n\n            if is_categorical_dtype(self.values):\n                # GH 10696/18593: update an existing categorical efficiently\n                return self.make_block(self.values.astype(dtype, copy=copy))"
  }
]