[
  {
    "id" : "433a1401-2df1-49aa-a07c-1db6c1ba49c5",
    "prId" : 19306,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/19306#pullrequestreview-89978348",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5931e44-a443-41a8-ab4b-ef0f56d64329",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you don't like reduce?",
        "createdAt" : "2018-01-18T23:49:08Z",
        "updatedAt" : "2018-01-19T17:20:52Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "8dc23445-7e59-4b41-a703-0e7f14c5f517",
        "parentId" : "e5931e44-a443-41a8-ab4b-ef0f56d64329",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "I try to avoid overlap with built-in names.",
        "createdAt" : "2018-01-19T00:15:51Z",
        "updatedAt" : "2018-01-19T17:20:52Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "a63da0fc920599bce8d132c3bd899e249cc125fc",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +-1,3 @@# -*- coding: utf-8 -*-\n# cython: profile=False\nfrom distutils.version import LooseVersion"
  },
  {
    "id" : "fd803313-cc52-4962-8c16-0a0314515d54",
    "prId" : 19306,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/19306#pullrequestreview-90339081",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3afa4278-9839-4567-8e0b-cf01aed89d99",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "remove this, and instead where ``.reduce()`` is called you can do this on the python side.",
        "createdAt" : "2018-01-19T21:55:30Z",
        "updatedAt" : "2018-01-19T21:57:49Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "f9b656eb-2d7e-4466-aabc-a0b4ff585dd1",
        "parentId" : "3afa4278-9839-4567-8e0b-cf01aed89d99",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "We'd also need to do that everywhere SeriesGrouper.get_result or SeriesBinGrouper.get_result is called.  What's the upside that makes the duplicated code worthwhile?",
        "createdAt" : "2018-01-19T23:15:14Z",
        "updatedAt" : "2018-01-19T23:15:14Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      },
      {
        "id" : "6f7fab39-f71e-4292-a1e4-3e573c1905f8",
        "parentId" : "3afa4278-9839-4567-8e0b-cf01aed89d99",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this completely removes this module from the import time dependency chain.\r\n\r\nyou *could* do this in the top-level function ``reduce()`` I suppose (inside the function)",
        "createdAt" : "2018-01-21T15:42:51Z",
        "updatedAt" : "2018-01-21T15:42:51Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "8eba03ff-628a-453a-8286-fe3eb1df6988",
        "parentId" : "3afa4278-9839-4567-8e0b-cf01aed89d99",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "or could expose ``maybe_convert_objects`` in a pxd and then call it directly in cython (but that actually puts this back in the dep chain).",
        "createdAt" : "2018-01-21T15:44:13Z",
        "updatedAt" : "2018-01-21T15:44:13Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "9274b9ad-50c9-4c9b-88a0-e1af143ca0a4",
        "parentId" : "3afa4278-9839-4567-8e0b-cf01aed89d99",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "> you could do this in the top-level function reduce() I suppose (inside the function)\r\n\r\nThat would be better than trying to do it after every place in the code-base where the function is called.  But note that `reduce` is not the only part of this module that is used externally, so we'd need to do this run-time import in three places in this module.\r\n\r\nSince the dependency is one-way and not a c-dep, I don't see a huge downside to the import-time import of maybe_convert_objects.",
        "createdAt" : "2018-01-21T17:43:45Z",
        "updatedAt" : "2018-01-21T17:43:45Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "a63da0fc920599bce8d132c3bd899e249cc125fc",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +18,22 @@\ncimport util\nfrom lib import maybe_convert_objects\n\nis_numpy_prior_1_6_2 = LooseVersion(np.__version__) < '1.6.2'"
  },
  {
    "id" : "14edd9b9-35d6-45ea-b450-8921e1751c9c",
    "prId" : 19360,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/19360#pullrequestreview-90888449",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "406391cd-4ca6-480f-b3cb-93e75b28cbe6",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "could do PyListCheck here",
        "createdAt" : "2018-01-23T10:56:07Z",
        "updatedAt" : "2018-01-23T10:57:06Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "c51a68d5-1834-4bf7-b0bf-561354bc07cb",
        "parentId" : "406391cd-4ca6-480f-b3cb-93e75b28cbe6",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "or change the other below, I find this slightly non-idiomatic",
        "createdAt" : "2018-01-23T10:56:45Z",
        "updatedAt" : "2018-01-23T10:57:06Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "f2eb25f9-94ab-4cec-a31f-7b2d7a6c221d",
        "parentId" : "406391cd-4ca6-480f-b3cb-93e75b28cbe6",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "It looks like cython automatically converts to `PyList_Check`.\r\n\r\nAgreed on a lot of the idiomatic point.  There's a lot of built-up debris in _libs.",
        "createdAt" : "2018-01-23T16:25:49Z",
        "updatedAt" : "2018-01-23T16:25:49Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "77bbcf42bda687777ae87a50b7fc7eea63f14f30",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +26,30 @@\n    if (util.is_array(obj) or\n            isinstance(obj, list) and len(obj) == cnt or\n            getattr(obj, 'shape', None) == (cnt,)):\n        raise ValueError('function does not reduce')"
  },
  {
    "id" : "1cc4c26d-c01b-4ad2-a0ae-61f37845a912",
    "prId" : 24748,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/24748#pullrequestreview-206317432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9e47104-617b-4244-b19b-3da3e87200f4",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "blank line here",
        "createdAt" : "2019-02-21T14:01:11Z",
        "updatedAt" : "2019-03-26T03:47:22Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "ecb7294a21802382edf8de890179db4c02fccc91",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +527,531 @@                raise InvalidApply('Let this error raise above us')\n\n            # Need to infer if low level index slider will cause segfaults\n            require_slow_apply = i == 0 and piece is chunk\n            try:"
  },
  {
    "id" : "8e7900b9-888c-47bd-9008-3f704afc2413",
    "prId" : 24748,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/24748#pullrequestreview-218652647",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e84ed85f-7db4-4611-b587-9684a290d4f8",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Might be overlooking but when would this ever be False?",
        "createdAt" : "2019-02-28T00:04:26Z",
        "updatedAt" : "2019-03-26T03:47:22Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "c3ffbf82-a073-491c-8f96-00a3a57736de",
        "parentId" : "e84ed85f-7db4-4611-b587-9684a290d4f8",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "fixed up",
        "createdAt" : "2019-03-26T01:01:44Z",
        "updatedAt" : "2019-03-26T03:47:22Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "ecb7294a21802382edf8de890179db4c02fccc91",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +542,546 @@            # take the slow path to not risk segfaults\n            # we have already computed the first piece\n            if require_slow_apply:\n                break\n    finally:"
  },
  {
    "id" : "75c351ac-d429-4a5d-b81b-23b34322389d",
    "prId" : 26421,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/26421#pullrequestreview-239949508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44602399-fe95-4fa2-8a70-e9a9007b7994",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Would this be better-suited for `pandas._libs.util`? Or keep here since this is the only file using it and it's temporary?",
        "createdAt" : "2019-05-20T13:13:30Z",
        "updatedAt" : "2019-05-20T13:14:11Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "fbe2e8d4-d8e8-4f9b-b611-8a55c318f174",
        "parentId" : "44602399-fe95-4fa2-8a70-e9a9007b7994",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Yes, exactly for those reasons (It's only used here, and should be removed again once we get rid of this deprecation), I would keep it here (it's not mean to be a general utility)",
        "createdAt" : "2019-05-20T13:18:11Z",
        "updatedAt" : "2019-05-20T13:18:27Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "2a792a42-6796-47a7-8e3f-9f7aaa032296",
        "parentId" : "44602399-fe95-4fa2-8a70-e9a9007b7994",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this is not the right location not should be in util\r\nyour argument is not correct ; just because we eventually will remove it does not mean it should. it be with similar code\r\n",
        "createdAt" : "2019-05-21T10:10:25Z",
        "updatedAt" : "2019-05-21T10:13:19Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb3aebee281862a8680eaab3260570b1c31c12f7",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +29,33 @@\n\ncdef bint _is_sparse_array(object obj):\n    # TODO can be removed one SparseArray.values is removed (GH26421)\n    if hasattr(obj, '_subtyp'):"
  },
  {
    "id" : "964c5ac4-9d74-4879-9470-64ca9c2afcb9",
    "prId" : 26421,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/26421#pullrequestreview-239949508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f668a1a7-5eba-43be-bacb-77cdb53bd3e7",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this idiom should be getattr",
        "createdAt" : "2019-05-21T10:10:59Z",
        "updatedAt" : "2019-05-26T15:02:26Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb3aebee281862a8680eaab3260570b1c31c12f7",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +31,35 @@cdef bint _is_sparse_array(object obj):\n    # TODO can be removed one SparseArray.values is removed (GH26421)\n    if hasattr(obj, '_subtyp'):\n        if obj._subtyp == 'sparse_array':\n            return True"
  },
  {
    "id" : "2cd82d15-cc39-419b-b41f-90e2829870fe",
    "prId" : 28662,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28662#pullrequestreview-305187474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e28e1b3c-3641-4613-b34d-d8678c3ffa3b",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add a comment here on what is going on",
        "createdAt" : "2019-10-22T13:05:00Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "882440bd0eadd2a21dfa2b78815f5727d5aaecba",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +500,504 @@                pass\n\n            if not is_scalar(piece):\n                # Need to copy data to avoid appending references\n                if hasattr(piece, \"copy\"):"
  },
  {
    "id" : "f3668c3a-6356-42d3-bd31-9779ead16cd2",
    "prId" : 28662,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/28662#pullrequestreview-314641386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I think you can *just* call ``copy(piece)`` here, no?",
        "createdAt" : "2019-10-25T13:01:18Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "3e6f3153-5901-46a2-86f5-22de1ef47af6",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "body" : "I had tried that originally but was getting some odd test failures elsewhere in the code base, not quite sure what the issue was",
        "createdAt" : "2019-10-25T23:34:31Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "tags" : [
        ]
      },
      {
        "id" : "f1c9f139-b23b-4841-a099-de702119009c",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok let’s try to track that down then ",
        "createdAt" : "2019-10-25T23:36:18Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a961f5f3-77f5-4c14-ad3a-0b739bcbe14e",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "@dsaxton any update on that? I think we are close on this PR",
        "createdAt" : "2019-11-08T00:56:18Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "2b33eeac-5211-4771-9979-3273ed7e11e7",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "body" : "> @dsaxton any update on that? I think we are close on this PR\r\n\r\nOne of the issues is with this test: https://github.com/pandas-dev/pandas/blob/master/pandas/tests/groupby/test_groupby.py#L944\r\n\r\nIf we just try a straight `copy` then we get this output:\r\n\r\n```python\r\n[ins] In [4]:     df = DataFrame({\"key\": [1, 1, 1, 2, 2, 2, 3, 3, 3], \"value\": range(9)}) \r\n         ...:  \r\n         ...:     result1 = df.groupby(\"key\", group_keys=True).apply(lambda x: x[:].key) \r\n         ...:     result2 = df.groupby(\"key\", group_keys=True).apply(lambda x: x.key)                                                                                             \r\n\r\n[ins] In [5]: result1                                                                                                                                                             \r\nOut[5]: \r\nkey   \r\n1    0    1\r\n     1    1\r\n     2    1\r\n2    3    2\r\n     4    2\r\n     5    2\r\n3    6    3\r\n     7    3\r\n     8    3\r\nName: key, dtype: int64\r\n\r\n[ins] In [6]: result2                                                                                                                                                             \r\nOut[6]: \r\nkey  0  1  2\r\nkey         \r\n1    1  1  1\r\n2    2  2  2\r\n3    3  3  3\r\n```\r\n\r\nTo be honest I'm not really sure what's going on here.",
        "createdAt" : "2019-11-09T16:21:24Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "tags" : [
        ]
      },
      {
        "id" : "b6f3a22a-a357-4edd-b9a8-28abcabdbd8a",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Pretty strange. Is that the only failure?",
        "createdAt" : "2019-11-09T19:11:06Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "ef35efd6-0670-484a-a9fd-950d9248c508",
        "parentId" : "a5a69907-a2ca-4b9d-9baf-4a7222354350",
        "authorId" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "body" : "There are actually four test failures (at least in `/tests/groupby/`), full output is below:\r\n\r\n<details>\r\n<summary>Test output</summary>\r\n\r\n```\r\n==================================================================================== FAILURES ====================================================================================\r\n_________________________________________________________________________ test_no_mutate_but_looks_like __________________________________________________________________________\r\n\r\n    def test_no_mutate_but_looks_like():\r\n    \r\n        # GH 8467\r\n        # first show's mutation indicator\r\n        # second does not, but should yield the same results\r\n        df = DataFrame({\"key\": [1, 1, 1, 2, 2, 2, 3, 3, 3], \"value\": range(9)})\r\n    \r\n        result1 = df.groupby(\"key\", group_keys=True).apply(lambda x: x[:].key)\r\n        result2 = df.groupby(\"key\", group_keys=True).apply(lambda x: x.key)\r\n>       assert_series_equal(result1, result2)\r\n\r\ntest_groupby.py:956: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nleft = key   \r\n1    0    1\r\n     1    1\r\n     2    1\r\n2    3    2\r\n     4    2\r\n     5    2\r\n3    6    3\r\n     7    3\r\n     8    3\r\nName: key, dtype: int64\r\nright = key  0  1  2\r\nkey         \r\n1    1  1  1\r\n2    2  2  2\r\n3    3  3  3, cls = <class 'pandas.core.series.Series'>\r\n\r\n    def _check_isinstance(left, right, cls):\r\n        \"\"\"\r\n        Helper method for our assert_* methods that ensures that\r\n        the two objects being compared have the right type before\r\n        proceeding with the comparison.\r\n    \r\n        Parameters\r\n        ----------\r\n        left : The first object being compared.\r\n        right : The second object being compared.\r\n        cls : The class type to check against.\r\n    \r\n        Raises\r\n        ------\r\n        AssertionError : Either `left` or `right` is not an instance of `cls`.\r\n        \"\"\"\r\n    \r\n        err_msg = \"{name} Expected type {exp_type}, found {act_type} instead\"\r\n        cls_name = cls.__name__\r\n    \r\n        if not isinstance(left, cls):\r\n            raise AssertionError(\r\n                err_msg.format(name=cls_name, exp_type=cls, act_type=type(left))\r\n            )\r\n        if not isinstance(right, cls):\r\n            raise AssertionError(\r\n>               err_msg.format(name=cls_name, exp_type=cls, act_type=type(right))\r\n            )\r\nE           AssertionError: Series Expected type <class 'pandas.core.series.Series'>, found <class 'pandas.core.frame.DataFrame'> instead\r\n\r\n../../util/testing.py:393: AssertionError\r\n______________________________________________________________________________ test_transform_axis _______________________________________________________________________________\r\n\r\ntsframe =                    A         B         C         D\r\n2000-01-03 -0.067269  0.149908 -1.327568 -1.372986\r\n2000-01-04 -1.34....122833  0.392259\r\n2000-02-10 -0.765270 -0.621285 -0.145734  0.185360\r\n2000-02-11 -0.515518  0.155501 -1.637690 -0.447299\r\n\r\n    def test_transform_axis(tsframe):\r\n    \r\n        # make sure that we are setting the axes\r\n        # correctly when on axis=0 or 1\r\n        # in the presence of a non-monotonic indexer\r\n        # GH12713\r\n    \r\n        base = tsframe.iloc[0:5]\r\n        r = len(base.index)\r\n        c = len(base.columns)\r\n        tso = DataFrame(\r\n            np.random.randn(r, c), index=base.index, columns=base.columns, dtype=\"float64\"\r\n        )\r\n        # monotonic\r\n        ts = tso\r\n        grouped = ts.groupby(lambda x: x.weekday())\r\n        result = ts - grouped.transform(\"mean\")\r\n>       expected = grouped.apply(lambda x: x - x.mean())\r\n\r\ntest_transform.py:181: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../../core/groupby/groupby.py:726: in apply\r\n    result = self._python_apply_general(f)\r\n../../core/groupby/groupby.py:745: in _python_apply_general\r\n    keys, values, not_indexed_same=mutated or self.mutated\r\n../../core/groupby/generic.py:1159: in _wrap_applied_output\r\n    return self._concat_objects(keys, values, not_indexed_same=not_indexed_same)\r\n../../core/groupby/groupby.py:954: in _concat_objects\r\n    result = result.reindex(ax, axis=self.axis)\r\n../../util/_decorators.py:235: in wrapper\r\n    return func(*args, **kwargs)\r\n../../core/frame.py:3889: in reindex\r\n    return super().reindex(**kwargs)\r\n../../core/generic.py:4599: in reindex\r\n    axes, level, limit, tolerance, method, fill_value, copy\r\n../../core/frame.py:3777: in _reindex_axes\r\n    index, method, copy, level, fill_value, limit, tolerance\r\n../../core/frame.py:3799: in _reindex_index\r\n    allow_dups=False,\r\n../../core/generic.py:4662: in _reindex_with_indexers\r\n    copy=copy,\r\n../../core/internals/managers.py:1247: in reindex_indexer\r\n    self.axes[axis]._can_reindex(indexer)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = DatetimeIndex(['2000-01-07', '2000-01-07', '2000-01-07', '2000-01-07',\r\n               '2000-01-07'],\r\n              dtype='datetime64[ns]', freq='B')\r\nindexer = array([-1, -1, -1, -1,  0,  1,  2,  3,  4])\r\n\r\n    def _can_reindex(self, indexer):\r\n        \"\"\"\r\n        Check if we are allowing reindexing with this particular indexer.\r\n    \r\n        Parameters\r\n        ----------\r\n        indexer : an integer indexer\r\n    \r\n        Raises\r\n        ------\r\n        ValueError if its a duplicate axis\r\n        \"\"\"\r\n    \r\n        # trying to reindex on an axis with duplicates\r\n        if not self.is_unique and len(indexer):\r\n>           raise ValueError(\"cannot reindex from a duplicate axis\")\r\nE           ValueError: cannot reindex from a duplicate axis\r\n\r\n../../core/indexes/base.py:3279: ValueError\r\n____________________________________________________________________________ test_dispatch_transform _____________________________________________________________________________\r\n\r\ntsframe =                    A         B         C         D\r\n2000-01-03 -1.100038  1.084505 -0.110031  1.207958\r\n2000-01-04 -0.62....396718 -0.787098\r\n2000-02-10  0.287868 -0.340750  0.240605  2.051640\r\n2000-02-11 -0.384174  1.275258 -0.477559  0.907368\r\n\r\n    def test_dispatch_transform(tsframe):\r\n        df = tsframe[::5].reindex(tsframe.index)\r\n    \r\n        grouped = df.groupby(lambda x: x.month)\r\n    \r\n>       filled = grouped.fillna(method=\"pad\")\r\n\r\ntest_transform.py:315: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../../core/groupby/groupby.py:628: in wrapper\r\n    return self.apply(curried)\r\n../../core/groupby/groupby.py:726: in apply\r\n    result = self._python_apply_general(f)\r\n../../core/groupby/groupby.py:745: in _python_apply_general\r\n    keys, values, not_indexed_same=mutated or self.mutated\r\n../../core/groupby/generic.py:1159: in _wrap_applied_output\r\n    return self._concat_objects(keys, values, not_indexed_same=not_indexed_same)\r\n../../core/groupby/groupby.py:936: in _concat_objects\r\n    result = concat(values, axis=self.axis)\r\n../../core/reshape/concat.py:256: in concat\r\n    return op.get_result()\r\n../../core/reshape/concat.py:471: in get_result\r\n    mgrs_indexers, self.new_axes, concat_axis=self.axis, copy=self.copy\r\n../../core/internals/managers.py:2048: in concatenate_block_managers\r\n    return BlockManager(blocks, axes)\r\n../../core/internals/managers.py:143: in __init__\r\n    self._verify_integrity()\r\n../../core/internals/managers.py:345: in _verify_integrity\r\n    construction_error(tot_items, block.shape[1:], self.axes)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ntot_items = 4, block_shape = (30,)\r\naxes = [Index(['A', 'B', 'C', 'D'], dtype='object'), DatetimeIndex(['2000-02-01', '2000-02-02', '2000-02-03', '2000-02-04',\r\n ...000-02-08', '2000-02-09',\r\n               '2000-02-10', '2000-02-11'],\r\n              dtype='datetime64[ns]', freq=None)]\r\ne = None\r\n\r\n    def construction_error(tot_items, block_shape, axes, e=None):\r\n        \"\"\" raise a helpful message about our construction \"\"\"\r\n        passed = tuple(map(int, [tot_items] + list(block_shape)))\r\n        # Correcting the user facing error message during dataframe construction\r\n        if len(passed) <= 2:\r\n            passed = passed[::-1]\r\n    \r\n        implied = tuple(len(ax) for ax in axes)\r\n        # Correcting the user facing error message during dataframe construction\r\n        if len(implied) <= 2:\r\n            implied = implied[::-1]\r\n    \r\n        if passed == implied and e is not None:\r\n            raise e\r\n        if block_shape[0] == 0:\r\n            raise ValueError(\"Empty data passed with indices specified.\")\r\n        raise ValueError(\r\n>           \"Shape of passed values is {0}, indices imply {1}\".format(passed, implied)\r\n        )\r\nE       ValueError: Shape of passed values is (30, 4), indices imply (18, 4)\r\n\r\n../../core/internals/managers.py:1708: ValueError\r\n______________________________________________________________________ test_groupby_selection_with_methods _______________________________________________________________________\r\n\r\ndf =               A      B         C         D\r\n2014-01-01  foo    one -0.258062 -0.381800\r\n2014-01-02  bar    one  0.928351...6  bar    two  0.771773  1.504767\r\n2014-01-07  foo    one -0.786105  2.548049\r\n2014-01-08  foo  three -1.368690  1.008265\r\n\r\n    def test_groupby_selection_with_methods(df):\r\n        # some methods which require DatetimeIndex\r\n        rng = date_range(\"2014\", periods=len(df))\r\n        df.index = rng\r\n    \r\n        g = df.groupby([\"A\"])[[\"C\"]]\r\n        g_exp = df[[\"C\"]].groupby(df[\"A\"])\r\n        # TODO check groupby with > 1 col ?\r\n    \r\n        # methods which are called as .foo()\r\n        methods = [\r\n            \"count\",\r\n            \"corr\",\r\n            \"cummax\",\r\n            \"cummin\",\r\n            \"cumprod\",\r\n            \"describe\",\r\n            \"rank\",\r\n            \"quantile\",\r\n            \"diff\",\r\n            \"shift\",\r\n            \"all\",\r\n            \"any\",\r\n            \"idxmin\",\r\n            \"idxmax\",\r\n            \"ffill\",\r\n            \"bfill\",\r\n            \"pct_change\",\r\n            \"tshift\",\r\n        ]\r\n    \r\n        for m in methods:\r\n>           res = getattr(g, m)()\r\n\r\ntest_whitelist.py:367: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../../core/groupby/groupby.py:628: in wrapper\r\n    return self.apply(curried)\r\n../../core/groupby/groupby.py:726: in apply\r\n    result = self._python_apply_general(f)\r\n../../core/groupby/groupby.py:745: in _python_apply_general\r\n    keys, values, not_indexed_same=mutated or self.mutated\r\n../../core/groupby/generic.py:1159: in _wrap_applied_output\r\n    return self._concat_objects(keys, values, not_indexed_same=not_indexed_same)\r\n../../core/groupby/groupby.py:936: in _concat_objects\r\n    result = concat(values, axis=self.axis)\r\n../../core/reshape/concat.py:256: in concat\r\n    return op.get_result()\r\n../../core/reshape/concat.py:471: in get_result\r\n    mgrs_indexers, self.new_axes, concat_axis=self.axis, copy=self.copy\r\n../../core/internals/managers.py:2048: in concatenate_block_managers\r\n    return BlockManager(blocks, axes)\r\n../../core/internals/managers.py:143: in __init__\r\n    self._verify_integrity()\r\n../../core/internals/managers.py:345: in _verify_integrity\r\n    construction_error(tot_items, block.shape[1:], self.axes)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ntot_items = 1, block_shape = (8,)\r\naxes = [Index(['C'], dtype='object'), DatetimeIndex(['2014-01-01', '2014-01-03', '2014-01-05', '2014-01-07',\r\n               '...014-01-03', '2014-01-05',\r\n               '2014-01-07', '2014-01-08'],\r\n              dtype='datetime64[ns]', freq=None)]\r\ne = None\r\n\r\n    def construction_error(tot_items, block_shape, axes, e=None):\r\n        \"\"\" raise a helpful message about our construction \"\"\"\r\n        passed = tuple(map(int, [tot_items] + list(block_shape)))\r\n        # Correcting the user facing error message during dataframe construction\r\n        if len(passed) <= 2:\r\n            passed = passed[::-1]\r\n    \r\n        implied = tuple(len(ax) for ax in axes)\r\n        # Correcting the user facing error message during dataframe construction\r\n        if len(implied) <= 2:\r\n            implied = implied[::-1]\r\n    \r\n        if passed == implied and e is not None:\r\n            raise e\r\n        if block_shape[0] == 0:\r\n            raise ValueError(\"Empty data passed with indices specified.\")\r\n        raise ValueError(\r\n>           \"Shape of passed values is {0}, indices imply {1}\".format(passed, implied)\r\n        )\r\nE       ValueError: Shape of passed values is (8, 1), indices imply (10, 1)\r\n\r\n../../core/internals/managers.py:1708: ValueError\r\n================================================== 4 failed, 3401 passed, 2 skipped, 22 xfailed, 2 xpassed in 203.24s (0:03:23) ==================================================\r\n```\r\n\r\n</details>",
        "createdAt" : "2019-11-10T21:10:54Z",
        "updatedAt" : "2019-12-30T21:51:08Z",
        "lastEditedBy" : "c450dd54-d24d-43a8-b896-c2c9af46ca18",
        "tags" : [
        ]
      }
    ],
    "commit" : "882440bd0eadd2a21dfa2b78815f5727d5aaecba",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +505,509 @@                    piece = piece.copy(deep=\"all\")\n                else:\n                    piece = copy(piece)\n\n            results.append(piece)"
  },
  {
    "id" : "5b48b76f-0a6f-45e0-b3c0-f4218b1cf034",
    "prId" : 29100,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29100#pullrequestreview-304222990",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d7751f8-734d-4ee6-a196-c7b7edfbe912",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "does this work with Categorical otherwise (the BinGrouper)? do we need tests here?\r\n",
        "createdAt" : "2019-10-19T17:15:07Z",
        "updatedAt" : "2019-10-19T20:57:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "77721778-37f5-4b29-87cc-c65960da9d79",
        "parentId" : "7d7751f8-734d-4ee6-a196-c7b7edfbe912",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "we have tests that get here with Categorical and IntegerArray.",
        "createdAt" : "2019-10-19T17:18:28Z",
        "updatedAt" : "2019-10-19T20:57:25Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f1705d5515a65aa93981378e8a4da1ed3490177",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +205,209 @@        values = series.values\n        if util.is_array(values) and not values.flags.c_contiguous:\n            # e.g. Categorical has no `flags` attribute\n            values = values.copy('C')\n        self.arr = values"
  },
  {
    "id" : "01978d98-4a88-4b24-9000-42329b606713",
    "prId" : 29494,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29494#pullrequestreview-314527571",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45a7dfe7-fcf3-411f-adb9-cced22906509",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Any reason not to do an isinstance check here? Not a strong blocker usage is mixed; might be nice to settle on one way of doing this",
        "createdAt" : "2019-11-09T00:49:32Z",
        "updatedAt" : "2019-11-13T00:02:46Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "0e034487-941e-498a-b082-eb23cf5b68e2",
        "parentId" : "45a7dfe7-fcf3-411f-adb9-cced22906509",
        "authorId" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "body" : "because we're in cython and dont want to import non-cython",
        "createdAt" : "2019-11-09T00:55:51Z",
        "updatedAt" : "2019-11-13T00:02:46Z",
        "lastEditedBy" : "adf621f1-4745-479a-a1fc-dc14046a3f4b",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d24a18e4662a7f6e6a642420fe95bc2597e6352",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +626,630 @@    if labels is not None:\n        # Caller is responsible for ensuring we don't have MultiIndex\n        assert labels.nlevels == 1\n\n        # pass as an ndarray/ExtensionArray"
  },
  {
    "id" : "de8b346f-b82a-4191-9b7b-5fb33a9c381a",
    "prId" : 29628,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29628#pullrequestreview-317989130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8dead70-d12b-4e7d-9538-2d4ce126c305",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "i would return a tuple(res, intitialized) here, less c-like i think is good generally (and this likely doesn't make it differetnt perf wise as this is object anyhow)",
        "createdAt" : "2019-11-16T21:09:58Z",
        "updatedAt" : "2019-11-17T16:01:04Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "2439078e04b4dba909fc54fbcebbc482051b00fa",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +190,194 @@        return cached_typ, cached_ityp\n\n    cdef inline object _apply_to_group(self,\n                                       object cached_typ, object cached_ityp,\n                                       Slider islider, Slider vslider,"
  },
  {
    "id" : "9f55b220-6f58-4c77-93c0-2d6c13871f04",
    "prId" : 29628,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/29628#pullrequestreview-317989130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "039fcfaa-0e01-44a0-86b6-b1892a29dd27",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add some sort of doc-string",
        "createdAt" : "2019-11-16T21:10:08Z",
        "updatedAt" : "2019-11-17T16:01:04Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "2439078e04b4dba909fc54fbcebbc482051b00fa",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +197,201 @@        Call self.f on our new group, then update to the next group.\n        \"\"\"\n        cached_ityp._engine.clear_mapping()\n        res = self.f(cached_typ)\n        res = _extract_result(res)"
  },
  {
    "id" : "3e5858ce-b1da-4854-b4ef-7f610a2ebec0",
    "prId" : 31613,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/31613#pullrequestreview-353396632",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb897a6a-b439-4c40-84ba-d38bfa0baf81",
        "parentId" : null,
        "authorId" : "96febc42-f659-4fe2-8e4e-2abe86f95dab",
        "body" : "Is this something we should perform benchmarking before merging?",
        "createdAt" : "2020-02-04T08:46:16Z",
        "updatedAt" : "2020-05-27T12:48:32Z",
        "lastEditedBy" : "96febc42-f659-4fe2-8e4e-2abe86f95dab",
        "tags" : [
        ]
      },
      {
        "id" : "b36eb8ec-f423-4dc6-bfef-eade50f98da0",
        "parentId" : "cb897a6a-b439-4c40-84ba-d38bfa0baf81",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this is cheap",
        "createdAt" : "2020-02-05T00:26:18Z",
        "updatedAt" : "2020-05-27T12:48:32Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5ac6ac972807e827a2554403ac99d2612547840",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +503,507 @@            require_slow_apply = i == 0 and piece is chunk\n            try:\n                if not piece.index.equals(chunk.index):\n                    mutated = True\n            except AttributeError:"
  }
]