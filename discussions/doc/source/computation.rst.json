[
  {
    "id" : "3f397c45-ddb9-4cc1-94ff-35143ce8f161",
    "prId" : 6909,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43fb90aa-ddbc-4f91-a286-2411c29dd497",
        "parentId" : null,
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "This was a bit confusing about whether the filling happens before or after calculating the pct_change.\n\nAs an aside, I don't really like this argument. Probably better to do `df.fillna().pct_change()`, but oh well.\n",
        "createdAt" : "2014-04-18T14:56:42Z",
        "updatedAt" : "2014-04-21T13:47:26Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee61d655e80b026ab534cdd6d37a95a10c34ba42",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +29,33 @@``Series``, ``DataFrame``, and ``Panel`` all have a method ``pct_change`` to compute the\npercent change over a given number of periods (using ``fill_method`` to fill\nNA/null values *before* computing the percent change).\n\n.. ipython:: python"
  },
  {
    "id" : "2965f8b0-e5bc-4ee1-9ced-7ba25d9c79f9",
    "prId" : 11603,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "parentId" : null,
        "authorId" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "body" : "Maybe `min_periods` should be on the `mean` method instead of in the `rolling` call? I see `min_periods` as describing the specific aggregation, not the generic type of window. For example, `min_periods` wouldn't apply to a generic function used in `.aggregate`.\n",
        "createdAt" : "2015-11-25T22:58:29Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "tags" : [
        ]
      },
      {
        "id" : "675921cf-bd96-49ac-a28b-b7609c080f2e",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "no `min_periods` is applicable to ALL methods actually.\n",
        "createdAt" : "2015-11-25T23:01:49Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "ef699122-eab7-46fc-b47c-bbae9aae862e",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "side issue is that we _could_ accept `kwargs` to the methods which override, but I think this would require some usecases / thought (not sure how error prone that weould be).\n\nI am actually trying NOT to depart from the ideas in the existing API (meaning parameters) and such with this PR.\n",
        "createdAt" : "2015-11-25T23:02:38Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a674431b-ceed-441d-a360-b0839da7b877",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "body" : "Well, this parameter could just as easily be saved on the `Rolling` object or specified in the method. `min_periods` would work just as easily on the standard `DataFrame.mean` method as it does on rolling objects.\n\nDoes `min_periods` really apply to arbitrarily aggregated results? Hmm....\n",
        "createdAt" : "2015-11-25T23:08:31Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "tags" : [
        ]
      },
      {
        "id" : "0a054358-d370-4daa-9032-a143c57c7083",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "9a02979e-c4f1-4331-a494-893a9f45d4c5",
        "body" : "The way I've done this for xray is that `min_periods` goes in the `rolling` method and `*args` and `**kwargs` that go to the reduce method (e.g. `mean`) go in the individual method calls. \n",
        "createdAt" : "2015-11-25T23:10:41Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "9a02979e-c4f1-4331-a494-893a9f45d4c5",
        "tags" : [
        ]
      },
      {
        "id" : "dca37539-c2f6-4272-a2a9-d2b223af0850",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "so you have `**kwargs` accepted to the `.rolling(...)` as well?\n\nhmm, I agree could be useful, but then how to you know when an invalid paramater is passed?\n\ne.g. say they misspelled `stdfoo` (instead of `std`)? \nthat's why explict paramaters are better\n",
        "createdAt" : "2015-11-25T23:13:19Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "2272a944-f8d1-436d-ab5f-8825d1dd3552",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "body" : "I don't like accepting arguments in both places. That seems unpythonic to me. Rather, I would prefer:\n- `.rolling(...)` gets arguments that define the window\n- `.mean(...)` gets arguments that define the aggregation\n",
        "createdAt" : "2015-11-25T23:19:28Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "tags" : [
        ]
      },
      {
        "id" : "02fac0d0-957e-4bf3-85d1-dccadc21274c",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "and that's how it is. very few parameters are included in the aggregator functions. The reason is again multiple aggregations, you generally want to simply construct and object then apply multiple aggregations to it is a very natural idiom.\n",
        "createdAt" : "2015-11-25T23:21:32Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "51494dd3-fcf9-4c07-a83c-13d7846e7ea2",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "9a02979e-c4f1-4331-a494-893a9f45d4c5",
        "body" : "> so you have **kwargs accepted to the .rolling(...) as well?\n\nNope.  I only accept `min_periods`, `center` (tick label location), and `freq` as arguments to the rolling method.  The dimension/window comes in via a `**kwarg` such as `time=24`.  That approach will be up for debate.\n",
        "createdAt" : "2015-11-25T23:57:27Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "9a02979e-c4f1-4331-a494-893a9f45d4c5",
        "tags" : [
        ]
      },
      {
        "id" : "2b547333-352b-429c-84c1-1b69ae7ff98f",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "just fixed this (as the actual Window functions are sort of a special case....)\n\n```\nIn [5]: r = Series(np.random.randn(100)).rolling(window=10,min_periods=1,win_type='gaussian')\n\nIn [6]: r.aggregate([lambda x: x.mean(std=10), lambda x: x.mean(std=.01)])\nOut[6]: \n    <lambda>  <lambda>\n0   0.596031       NaN\n1  -0.201905       NaN\n2  -0.151369       NaN\n3  -0.610146       NaN\n4  -0.582432  0.596031\n..       ...       ...\n95  0.196580 -0.247233\n96  0.263148  0.818896\n97  0.140441  1.559132\n98  0.142004  1.021733\n99 -0.031965 -0.022068\n\n[100 rows x 2 columns]\n\n```\n",
        "createdAt" : "2015-11-26T00:00:29Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "5527325b-2286-4bb4-841b-43cb37a19477",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you can of course use actual functions and the names will be correct\n",
        "createdAt" : "2015-11-26T00:00:52Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "93d67121-0e7f-4df2-b48d-3bff183da95a",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "body" : "AFAIT, we only use `min_periods` on specific aggregation methods, not the generic `.aggregate` for user defined functions. I get that it could be convenient to accept it in `.rolling(...)` but it really does feel like an aggregation specific option to me.\n",
        "createdAt" : "2015-11-26T00:20:16Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "tags" : [
        ]
      },
      {
        "id" : "f29c272c-1580-48df-8c16-553d059be1ba",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "its part of the `window` specification actaully, so its in the correct place. `.aggregate` is just a convenience way of doing things. \n\nThe only parameter I have some reservations about is actually `how`\n\ne.g.\n\n`Rolling(window=2,freq='D').min(how='min')` (`how` is defaulted). So I have to do the resampling NOT at `Rolling` creation time, but at function evaluation time, so in reality `freq` and `how` are bound together (e.g. `how` is passed to `.resample` if `.freq` is defined as well).\n\nThe reason for this:\n\n`def max(how='max')` and `def median(how='median`)`.\n\nI don't find an easy way to conditionally define how.\n",
        "createdAt" : "2015-11-26T00:25:03Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "d0816e46-6c72-49ec-9e32-7e5c0fee71a7",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "body" : "Maybe use `how=None` for `.rolling(...)` and then change the default based on the aggregation method? Slightly magical but still pretty reasonable I think.\n",
        "createdAt" : "2015-11-26T00:29:21Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "40104112-cdcf-4812-8f95-b502b40e346d",
        "tags" : [
        ]
      },
      {
        "id" : "4723ef69-f6d6-4e7f-b8a1-c99c791bafc6",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "body" : "Sorry if this is in the wrong place but I couldnt find a better place to ask this question:\nWhen will pandas 0.18 be available? reason I am asking I think I may have found a bug with the rolling_min function, when applied on a forward looking basis. Since the window functions seem to be completely overhauled in the new release, I would want to retest it in the new version before reporting the bug.\n",
        "createdAt" : "2016-01-16T18:03:51Z",
        "updatedAt" : "2016-01-16T18:03:51Z",
        "lastEditedBy" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "tags" : [
        ]
      },
      {
        "id" : "3730f8e3-364e-4fb5-a16f-63b2880cb55f",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "a few weeks - but it's back compat so if you think u found a bug then pls open a report\n",
        "createdAt" : "2016-01-16T18:07:21Z",
        "updatedAt" : "2016-01-16T18:07:21Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "06bc4c83-512a-44a2-a44c-b9933757e696",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "body" : "Ok sounds good, I will prepare a bug report - but where do I submit it? sorry, new to this.\n",
        "createdAt" : "2016-01-17T15:58:52Z",
        "updatedAt" : "2016-01-17T15:58:52Z",
        "lastEditedBy" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "tags" : [
        ]
      },
      {
        "id" : "ba2a31fc-f507-481a-9e5e-ea5fa176b2d2",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "http://pandas.pydata.org/pandas-docs/stable/contributing.html\n",
        "createdAt" : "2016-01-17T16:03:37Z",
        "updatedAt" : "2016-01-17T16:03:37Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "61f1b8fe-49fd-4c03-831f-9b30e1f15ea2",
        "parentId" : "95e68770-4a97-4c66-813f-a983b99b6223",
        "authorId" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "body" : "Added an issue,  #12073. I feel like this one requires expert level 100000. Good luck! ;)\n",
        "createdAt" : "2016-01-17T18:46:08Z",
        "updatedAt" : "2016-01-17T18:46:08Z",
        "lastEditedBy" : "c9bd89d6-f494-4700-9918-ff304aa59d2d",
        "tags" : [
        ]
      }
    ],
    "commit" : "1890a88d4d1b2926e45f631330f6191642bef773",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +242,246 @@\n- ``window``: size of moving window\n- ``min_periods``: threshold of non-null data points to require (otherwise\n  result is NA)\n- ``center``: boolean, whether to set the labels at the center (default is False)"
  },
  {
    "id" : "bafb088c-0101-4cc0-9cba-20a6e94a81cc",
    "prId" : 11603,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d144cb9a-d7b8-4382-8fa0-2adc43351cae",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Maybe also add `center` in the list below?\n",
        "createdAt" : "2015-12-15T08:52:33Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "4d802e30-32a6-4428-b387-b1445ad6cef3",
        "parentId" : "d144cb9a-d7b8-4382-8fa0-2adc43351cae",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "done\n",
        "createdAt" : "2015-12-15T11:51:36Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "1890a88d4d1b2926e45f631330f6191642bef773",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +239,243 @@\nGenerally these methods all have the same interface. They all\naccept the following arguments:\n\n- ``window``: size of moving window"
  },
  {
    "id" : "c77ca930-0364-4359-9070-4820e1b34d64",
    "prId" : 11603,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b226ee7-aba6-46f0-ace1-31d194572c92",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "I think the nested dict is to be able to pass keys to use as the column names for the different functions while still applying different functions to different columns? (as now it is not clear what the difference is from _\"By passing a dict to `aggregate` you can apply a different aggregation to the columns of a DataFrame:\"_ some lines above)\n",
        "createdAt" : "2015-12-15T09:17:17Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "ace0f80e-d7c9-4102-89ce-99338b8dcf32",
        "parentId" : "8b226ee7-aba6-46f0-ace1-31d194572c92",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "we do this for groupby now\n\n```\nIn [7]:    df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n   ...:                              'foo', 'bar', 'foo', 'foo'],\n   ...:                       'B' : ['one', 'one', 'two', 'three',\n   ...:                              'two', 'two', 'one', 'three'],\n   ...:                       'C' : np.random.randn(8),\n   ...:                       'D' : np.random.randn(8)})\n\nIn [12]: df\nOut[12]: \n     A      B         C         D\n0  foo    one  0.952947  0.073875\n1  bar    one -0.572624 -2.266642\n2  foo    two -2.131477 -1.925049\n3  bar  three -0.994148 -0.635505\n4  foo    two  1.925770  0.152768\n5  bar    two  0.826862 -0.320888\n6  foo    one  0.313537 -0.420630\n7  foo  three  0.549680  0.601519\n\nIn [13]: df.groupby(['A','B']).agg({'C' : { 'sum' }, 'D' : { 'mean' }})\nOut[13]: \n                  C         D\n                sum      mean\nA   B                        \nbar one   -0.572624 -2.266642\n    three -0.994148 -0.635505\n    two    0.826862 -0.320888\nfoo one    1.266484 -0.173378\n    three  0.549680  0.601519\n    two   -0.205708 -0.886140\n\nIn [14]: df.groupby(['A','B']).agg({'C' : { 'rc' : 'sum' }, 'D' : { 'rd' : 'mean' }})\nOut[14]: \n                  C         D\n                 rc        rd\nA   B                        \nbar one   -0.572624 -2.266642\n    three -0.994148 -0.635505\n    two    0.826862 -0.320888\nfoo one    1.266484 -0.173378\n    three  0.549680  0.601519\n    two   -0.205708 -0.886140\n```\n",
        "createdAt" : "2015-12-15T12:19:36Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "4831b6d1-31c0-4efb-b8c8-0ce795dccf2a",
        "parentId" : "8b226ee7-aba6-46f0-ace1-31d194572c92",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "yes, but that is the use case explained some lines above (L534 in the diff), it is not clear from the explanation what is different here (the fact that, by using a nested dict, you specify the name that should be used for the resulting column of that function)\n",
        "createdAt" : "2015-12-15T12:23:56Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "8c78596a-b024-4dca-894b-ab5e47b8a559",
        "parentId" : "8b226ee7-aba6-46f0-ace1-31d194572c92",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "yes we can certainly discuss in the other issue #9052. I agree this is a bit magical. Actually now that things are centralized it is easy to fix/change this (maybe eliminate it).\n",
        "createdAt" : "2015-12-15T12:40:19Z",
        "updatedAt" : "2015-12-19T13:51:47Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "1890a88d4d1b2926e45f631330f6191642bef773",
    "line" : 438,
    "diffHunk" : "@@ -1,1 +545,549 @@   r.agg({'A' : 'sum', 'B' : 'std'})\n\nFurthermore you can pass a nested dict to indicate different aggregations on different columns.\n\n.. ipython:: python"
  },
  {
    "id" : "f9b82e6f-3a93-455a-8b66-2493116b39a3",
    "prId" : 13740,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32654307-0dbd-4366-9c65-8492133549b4",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "do we still have `*` imports anywhere? (otherwise this _should_ have broken)\n",
        "createdAt" : "2016-07-21T10:47:56Z",
        "updatedAt" : "2016-07-21T12:18:44Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "5fd3c3f6-e3a0-4323-9ac7-95ba5e89bf2e",
        "parentId" : "32654307-0dbd-4366-9c65-8492133549b4",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "It _was_ broken :-) (as I noticed in the travis doc build log, otherwise I wouldn't have catched this)\n",
        "createdAt" : "2016-07-21T10:50:38Z",
        "updatedAt" : "2016-07-21T12:18:44Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "fa5cbf51-e2d6-4015-ba7c-a0ee6860960a",
        "parentId" : "32654307-0dbd-4366-9c65-8492133549b4",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "haha, makes sense! good that these raise (though didn't seem to fail the travis build) :<\n",
        "createdAt" : "2016-07-21T10:52:39Z",
        "updatedAt" : "2016-07-21T12:18:44Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "6700d658-0814-4ee9-8969-70e25c399361",
        "parentId" : "32654307-0dbd-4366-9c65-8492133549b4",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "no, currently the travis build does not fail for such errors. But in principle we could do a search for certain patterns in the doc build log and let travis fail based on that\n",
        "createdAt" : "2016-07-21T11:06:11Z",
        "updatedAt" : "2016-07-21T12:18:44Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "0460f52224d1554480a0b62b3b284996b9486051",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +430,434 @@\n   dft = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n                      index = pd.Index([pd.Timestamp('20130101 09:00:00'),\n                                        pd.Timestamp('20130101 09:00:02'),\n                                        pd.Timestamp('20130101 09:00:03'),"
  }
]