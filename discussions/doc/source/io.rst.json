[
  {
    "id" : "3acc8620-49bc-4227-a376-9200429a1185",
    "prId" : 4857,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23213b52-b674-482c-9e7a-b019cc198960",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I think they are all optional right? and aren't you making xlsxwriter the default now?\n",
        "createdAt" : "2013-09-16T21:39:39Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "a2b7da3a-694a-4b74-a9b3-a567f85cffe4",
        "parentId" : "23213b52-b674-482c-9e7a-b019cc198960",
        "authorId" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "body" : "I guess we need to edit the default settings to check if xlsxwriter or openpyxl is installed.  Not sure if we could neaten this up with some importlib magic or something...\n\ni.e.: \n\n``` python\nxlsx_set = False\ntry:\n    import xlsxwriter\n    if not xlsx_set:\n        set_option('io.excel.xlsx.writer', 'xlsxwriter')\n        xlsx_set = True\nexcept ImportError:\n    pass\ntry:\n    import openpyxl\n    if not xlsx_set:\n        set_option('io.excel.xlsx.writer', 'openpyxl')\n        xlsx_set = True\nexcept ImportError:\n    pass\n    # etc\n```\n\nAnd we can decide on order later.  I think only openpyxl supports `.xlsm` files. It also may be the case that xlwt supports xlsx files.  If so, it would be trivial to add it here.\n",
        "createdAt" : "2013-09-16T21:50:15Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "tags" : [
        ]
      },
      {
        "id" : "b5c507bf-bce0-4960-a30a-26f1fb22df7b",
        "parentId" : "23213b52-b674-482c-9e7a-b019cc198960",
        "authorId" : "56bacb42-5a21-41c7-bce7-c4ce57a99717",
        "body" : "They are all optional but openpyxl is the default for xlsx and xlwt is the default for xls insofar as they are the default classes bound to the file extensions.\n\nAnd it wasn't my intention to make xlsxwriter the default. It is probably best to see if people use it or prefer it as a default for a release or two.\n",
        "createdAt" : "2013-09-16T21:59:33Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "56bacb42-5a21-41c7-bce7-c4ce57a99717",
        "tags" : [
        ]
      },
      {
        "id" : "f57e952e-f2a5-49ff-b56d-93c3ba7a003b",
        "parentId" : "23213b52-b674-482c-9e7a-b019cc198960",
        "authorId" : "56bacb42-5a21-41c7-bce7-c4ce57a99717",
        "body" : "Just to reiterate, I don't think it is worth changing the current behaviour of the (optional) defaults. At least not in 0.13. If it proves to be popular and robust we can consider that for 0.14.\n",
        "createdAt" : "2013-09-17T10:43:41Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "56bacb42-5a21-41c7-bce7-c4ce57a99717",
        "tags" : [
        ]
      },
      {
        "id" : "c8f42109-a4cc-4203-85e5-2f42f2a6c5ce",
        "parentId" : "23213b52-b674-482c-9e7a-b019cc198960",
        "authorId" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "body" : "@jmcnamara keep in mind that you have to explicitly choose to install xlsxwriter to have this work - so it's not that big of a deal. `xlsxwriter` isn't in the major prepackaged distributions (enthought, anaconda, python(x,y), winpython, etc), so there's a low probability for people to be surprised.\n",
        "createdAt" : "2013-09-17T11:26:12Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "tags" : [
        ]
      },
      {
        "id" : "7c1837dd-558b-4fc9-a028-2a2383fe47ce",
        "parentId" : "23213b52-b674-482c-9e7a-b019cc198960",
        "authorId" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "body" : "I think this is fine for now.\n",
        "createdAt" : "2013-09-20T21:54:42Z",
        "updatedAt" : "2013-09-22T22:43:13Z",
        "lastEditedBy" : "6f890fbc-4bdf-4397-95eb-a8225d4af04f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b0c290f4879a542b027b4c36a922f5ae2216ed5a",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +1694,1698 @@2. the filename extension (via the default specified in config options)\n\nBy default ``pandas`` only supports\n`openpyxl <http://packages.python.org/openpyxl/>`__ as a writer for ``.xlsx``\nand ``.xlsm`` files and `xlwt <http://www.python-excel.org/>`__ as a writer for"
  },
  {
    "id" : "c5abb56a-7e91-49b7-8b5f-45c2029eee16",
    "prId" : 6021,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "904e3d8d-d10b-4501-9696-725f1543c142",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "foo.csv has been removed before (under 'Specifying date columns'), so you will have to move that remove below this.\n",
        "createdAt" : "2014-01-24T07:40:47Z",
        "updatedAt" : "2014-01-24T07:40:47Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "879f270c120a2c0f63de449ab6fd1bcff2628175",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +531,535 @@\n   # Try to infer the format for the index column\n   df = pd.read_csv('foo.csv', index_col=0, parse_dates=True,\n                    infer_datetime_format=True)\n"
  },
  {
    "id" : "a072aef3-aef5-4ef4-8c65-d6bcd3206dda",
    "prId" : 6021,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06069c07-4d29-43a8-aa40-6888eb34905a",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Can you make a list of this? (just `-` before each), or otherwise a code-block, as you like (but just one enter will be disregarded by Sphinx)\n",
        "createdAt" : "2014-01-24T07:41:44Z",
        "updatedAt" : "2014-01-24T07:41:44Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "879f270c120a2c0f63de449ab6fd1bcff2628175",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +522,526 @@\"12/30/2011 00:00:00\"\n\"30/Dec/2011 00:00:00\"\n\"30/December/2011 00:00:00\"\n\n`infer_datetime_format` is sensitive to `dayfirst`.  With `dayfirst=True`, it"
  },
  {
    "id" : "139d32a0-0aea-4402-a673-4ae69c5db915",
    "prId" : 6021,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04bd4206-0f64-4def-a3d3-034834f5a276",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "In the previous sections, parse_dates is always written with double backtick quotation (```parse_dates```). This will render as code, while single backtick as italic.\n",
        "createdAt" : "2014-01-24T07:43:51Z",
        "updatedAt" : "2014-01-24T07:43:51Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "879f270c120a2c0f63de449ab6fd1bcff2628175",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +504,508 @@Inferring Datetime Format\n~~~~~~~~~~~~~~~~~~~~~~~~~\nIf you have `parse_dates` enabled for some or all of your columns, and your\ndatetime strings are all formatted the same way, you may get a large speed\nup by setting `infer_datetime_format=True`.  If set, pandas will attempt"
  },
  {
    "id" : "0d81a24e-e850-466c-bdbd-5af1b13c45fd",
    "prId" : 6576,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb9b7f8e-f3f9-409d-b22f-c639f370b152",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you remove the leading spaces here\n",
        "createdAt" : "2014-03-11T11:46:05Z",
        "updatedAt" : "2014-03-12T04:49:46Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "64787771-b7e8-48fa-bf38-25aa1367ebf0",
        "parentId" : "eb9b7f8e-f3f9-409d-b22f-c639f370b152",
        "authorId" : "05966bcf-6059-4f72-8d7c-d93433335047",
        "body" : "I changed this to bullet point. Looks like the other bullet point sections use leading spaces.\n",
        "createdAt" : "2014-03-11T14:22:08Z",
        "updatedAt" : "2014-03-12T04:49:46Z",
        "lastEditedBy" : "05966bcf-6059-4f72-8d7c-d93433335047",
        "tags" : [
        ]
      },
      {
        "id" : "b456a8e4-9297-40f0-a629-c0b95285d0bd",
        "parentId" : "eb9b7f8e-f3f9-409d-b22f-c639f370b152",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "It's OK like this\n",
        "createdAt" : "2014-03-11T14:25:34Z",
        "updatedAt" : "2014-03-12T04:49:46Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "a0e38688-1f19-48a1-b3e0-416241464d0a",
        "parentId" : "eb9b7f8e-f3f9-409d-b22f-c639f370b152",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "yep..that's fine...\n",
        "createdAt" : "2014-03-11T15:20:55Z",
        "updatedAt" : "2014-03-12T04:49:46Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be379f013f275b58c9ee6c04669ab7919ff728f",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1848,1852 @@\n- Pass a string to refer to the name of a particular sheet in the workbook.\n- Pass an integer to refer to the index of a sheet. Indices follow Python \n  convention, beginning at 0.\n- The default value is ``sheet_name=0``. This reads the first sheet."
  },
  {
    "id" : "79d1b9ee-72dc-47c7-a060-ad7c947159a1",
    "prId" : 6889,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aef087a5-ffdc-4ed5-8deb-8151913b9b70",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you update the skip_footer/dtype in io.parsers.rst (at the top where the arguments are laid out) for the same way you did in the doc-strings?\n",
        "createdAt" : "2014-04-23T20:11:06Z",
        "updatedAt" : "2014-04-23T21:41:01Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "f45b7143991df96c85a1b9860a7674c3b3f2a91e",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +277,281 @@    df = pd.read_csv(StringIO(data), dtype={'b': object, 'c': np.float64})\n    df.dtypes\n\n.. note::\n    The ``dtype`` option is currently only supported by the C engine."
  },
  {
    "id" : "567c0d81-2862-4c7c-9ad4-3ab35fba2724",
    "prId" : 6937,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28ebc67c-9578-4db5-b118-97cc3e9d0743",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "pandas.io.read_gbq -> pandas.read_gbq\n",
        "createdAt" : "2014-06-10T07:22:25Z",
        "updatedAt" : "2014-06-29T21:22:19Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd5b6e97108b02f70e5c101eaf04401b8d5315b6",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +3381,3385 @@\nAs an example, suppose you want to load all data from an existing BigQuery \ntable : `test_dataset.test_table` into a DataFrame using the :func:`~pandas.io.read_gbq` \nfunction.\n"
  },
  {
    "id" : "b84d7899-0c61-4a6a-b546-485ac6307775",
    "prId" : 6937,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45c24584-2a18-4404-8d58-cd60f617f078",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "and is it then appended? (not fully clear to me, previously you had fail/replace/append, now only one default action?)\n",
        "createdAt" : "2014-06-10T07:31:47Z",
        "updatedAt" : "2014-06-29T21:22:19Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "4c97d70b-0dc9-4f78-a935-bc1247971aaf",
        "parentId" : "45c24584-2a18-4404-8d58-cd60f617f078",
        "authorId" : "661a0526-88d1-45b3-bba2-ca16313d3f2c",
        "body" : "The other actions were a benefit of relying on bq.py in the past. While possible to do strictly with the API, it's a lot of code for very little benefit. The data is strictly appended which was, at least in our experience, the most common use case.\n",
        "createdAt" : "2014-06-11T05:01:38Z",
        "updatedAt" : "2014-06-29T21:22:19Z",
        "lastEditedBy" : "661a0526-88d1-45b3-bba2-ca16313d3f2c",
        "tags" : [
        ]
      },
      {
        "id" : "51451d17-14d4-4164-8449-457985963f25",
        "parentId" : "45c24584-2a18-4404-8d58-cd60f617f078",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Ah, I missed the rather obvious \"you can _append_ data using to_gbq()\" part.\n\nSo OK, no problem here. But maybe add it more explicitely in the docstring of `to_gbq` as well?\n",
        "createdAt" : "2014-06-11T20:22:39Z",
        "updatedAt" : "2014-06-29T21:22:19Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd5b6e97108b02f70e5c101eaf04401b8d5315b6",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +3411,3415 @@Google streaming API which requires that your destination table exists in\nBigQuery. Given the BigQuery table already exists, your DataFrame should\nmatch the destination table in column order, structure, and data types. \nDataFrame indexes are not supported. By default, rows are streamed to \nBigQuery in chunks of 10,000 rows, but you can pass other chuck values "
  },
  {
    "id" : "805e7153-c03e-4694-883e-11d0d2b8068d",
    "prId" : 9601,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e28786be-df6f-46ff-b66d-8b714c1def68",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "There needs to be a blank line between the `.. ipython:: python` (directive command) and the actual code content\n",
        "createdAt" : "2015-03-06T12:52:43Z",
        "updatedAt" : "2015-03-06T13:00:00Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "08297e62945626c25413257d5a38c366d047aea6",
    "line" : null,
    "diffHunk" : "@@ -1,1 +3839,3843 @@.. ipython:: python\n\n  reader = pd.read_stata('stata.dta', chunksize=3)\n  for df in reader:\n      print(df.shape)"
  },
  {
    "id" : "1a82335d-5669-4dfc-abd4-e2c3cb6e5b5c",
    "prId" : 9711,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fbf5afff-c023-4c0a-8833-299449d041d7",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you need `.. ipython: :python` around each of these blocks to have it exectue, or probably better `.. code-block` to have it look like code but not execute\n",
        "createdAt" : "2015-06-15T11:16:12Z",
        "updatedAt" : "2015-08-14T08:03:58Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "4694a428fd63e971159fffea4559e589088881e9",
    "line" : null,
    "diffHunk" : "@@ -1,1 +4147,4151 @@.. code-block:: python\n\n    df = pd.read_sas('sas_xport.xpt')\n\nObtain an iterator and read an XPORT file 100,000 lines at a time:"
  },
  {
    "id" : "3d731c11-490b-4f0e-aba0-8b7bd5b3a865",
    "prId" : 10069,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "This is only true for when using compression, IIRC.\n",
        "createdAt" : "2015-05-06T15:10:16Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "d44bee17-7691-4674-8c39-b67f4c94f584",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "body" : "the \"stores need to be rewritten\" part?  I rewrote the test table uncompressed in the old version and querying in the new version does not return all rows.  I think it needs to be done regardless.\n",
        "createdAt" : "2015-05-06T15:21:30Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "tags" : [
        ]
      },
      {
        "id" : "063c8047-06e1-449b-911b-3944a6376bf4",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "oh, ok. I just wanted to make it as specific as possible. This sounds like its ALWAYS a bug. IIRC I think you actually have to specify `start` or `stop` when you query. (e.g. your query needs to be something like: `s.select('df',where='.....',start=10)`, right? (iow it has to be a chunked query)\n",
        "createdAt" : "2015-05-06T15:28:20Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "e3bfa90a-9100-4944-8e73-a0853686fa96",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "body" : "It doesn't need to be chunked.  My sample was just s.select('df', where=Term(...)).  I tried to make it non-specific by \"may appear.\"\n",
        "createdAt" : "2015-05-06T15:31:18Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "tags" : [
        ]
      },
      {
        "id" : "8380f097-9a0c-4c23-b524-b697f27b9cf3",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "hmm, ok, that's fine then.\n",
        "createdAt" : "2015-05-06T15:38:44Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "d2dd5add-11e0-412a-8a18-f3ee121fe601",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "body" : "Since this is such a nuanced bug, I think it would be worth making 3.2 a requirement once that is officially out.\n",
        "createdAt" : "2015-05-06T15:46:50Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "e4cf42f5-ae7f-4a31-b7fb-d8c96a5a33ff",
        "tags" : [
        ]
      },
      {
        "id" : "da452891-dda3-44a4-8254-7f6068331dd3",
        "parentId" : "5d316876-11ed-40e9-a665-38ea4733f5b4",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "sure, let's make an issue for 0.17.0 for that, maybe now just update install.rst to say highly recommened to use 3.2\n",
        "createdAt" : "2015-05-06T15:53:15Z",
        "updatedAt" : "2015-05-06T17:26:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "61fae01fb757a30d494a523b3dc71eb7ffe1487f",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2368,2372 @@   \n   There is a ``PyTables`` indexing bug which may appear when querying stores using an index.  If you see a subset of results being returned, upgrade to ``PyTables`` >= 3.2.  Stores created previously will need to be rewritten using the updated version.\n\n.. ipython:: python\n   :suppress:"
  },
  {
    "id" : "dc2a3fe2-894c-4662-a98e-1a5f6ac4db67",
    "prId" : 10097,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5e03b89-e8eb-40e9-99ca-f4ac8960d0fc",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "say you can pass the `dropna=True` to get the previous behavior\n\nI see you did below, so nvm.\n",
        "createdAt" : "2015-07-30T18:08:17Z",
        "updatedAt" : "2015-07-31T18:00:57Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "2377b5c1aafa33fb5a3fb3966e0bb16b8bcd2c6a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2414,2418 @@\n   As of version 0.17.0, ``HDFStore`` will not drop rows that have all missing values by default. Previously, if all values (except the index) were missing, ``HDFStore`` would not write those rows to disk. \n\n.. ipython:: python\n   :suppress:"
  },
  {
    "id" : "9293964a-01bc-4754-aae9-6560f2222be1",
    "prId" : 10376,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d57dcb10-314f-472d-8197-94134e086e27",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add a reference here (so we can link to it)\n",
        "createdAt" : "2015-06-20T07:47:42Z",
        "updatedAt" : "2015-06-20T16:11:04Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "92203096ceba0cfea72bb28d434f34f58e68bb0a",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +2184,2188 @@\n   df.to_excel('path_to_file.xlsx', sheet_name='Sheet1')\n\nWriting Excel Files to Memory\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
  },
  {
    "id" : "0df60c2d-7df0-44e6-83dc-39fd1d8ad335",
    "prId" : 10857,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da8514ce-6ccd-47d2-b834-e15cbec48b6b",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "or you have to make this a static `code-block` like the others, or you have to remove the output (but I would go for the code-block, since all the others are that as well)\n",
        "createdAt" : "2015-09-10T07:53:02Z",
        "updatedAt" : "2015-09-13T16:30:46Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "da6e6249-1d3d-4765-9df8-6ba9d2ffd642",
        "parentId" : "da8514ce-6ccd-47d2-b834-e15cbec48b6b",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "or maybe better is to use `.. ipython::` instead of `.. ipython:: python`, then the code is not executed, but the formatting is more similar (`.. code-block:: python` does look a bit different)\n",
        "createdAt" : "2015-09-10T07:54:54Z",
        "updatedAt" : "2015-09-13T16:30:46Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "2622cb313072f3a02c0c8752a0496a518eb057b1",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +4020,4024 @@Assume we want to write a DataFrame ``df`` into a BigQuery table using :func:`~pandas.DataFrame.to_gbq`.\n\n.. ipython:: python\n\n   df = pd.DataFrame({'my_string': list('abc'),"
  },
  {
    "id" : "59e7c4b2-1905-4dbb-b71d-c285dffaf0ec",
    "prId" : 10857,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46dc4d7f-b8ef-4ca2-a883-129328843a31",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "in case of using a code-block, a `In [3]` should be added here\n",
        "createdAt" : "2015-09-10T07:53:37Z",
        "updatedAt" : "2015-09-13T16:30:46Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "2622cb313072f3a02c0c8752a0496a518eb057b1",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +4022,4026 @@.. ipython:: python\n\n   df = pd.DataFrame({'my_string': list('abc'),\n                      'my_int64': list(range(1, 4)),\n                      'my_float64': np.arange(4.0, 7.0),"
  },
  {
    "id" : "1bb0da69-5a03-4dc7-8479-e7d6c559a959",
    "prId" : 10967,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "427a9695-7267-454f-819e-228594e3be28",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "ok for now, but maybe make this have sub-sections to make this a bit easier to navigate \n",
        "createdAt" : "2015-09-09T12:02:54Z",
        "updatedAt" : "2015-09-09T12:02:54Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "98405f043e619683288f3e28cb1d5140a4252d12",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1990,1994 @@'''''''''''''''''''\n\n.. versionadded:: 0.17\n\n``read_excel`` can read a ``MultiIndex`` index, by passing a list of columns to ``index_col``"
  },
  {
    "id" : "c9b971df-7bd1-4577-976c-1276d259582c",
    "prId" : 13575,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1e99214-a74d-4d2b-9cb4-695918a7cc70",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add a version added tag for these\n",
        "createdAt" : "2016-07-20T21:41:55Z",
        "updatedAt" : "2016-07-21T12:50:14Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "5cb8243f2dd31cc2155627f29cfc89bbf6d4b84b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1961,1965 @@\nSpecify values that should be converted to NaN\n\n.. code-block:: python\n"
  },
  {
    "id" : "8af719d3-717a-4d8c-b6a5-1302358d1b4f",
    "prId" : 14295,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14295#pullrequestreview-8710731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4a4b986-2c25-4b9e-bc46-adbed6933a55",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I think you need a blank line here (to avoid warnings)\n",
        "createdAt" : "2016-11-15T22:23:07Z",
        "updatedAt" : "2016-11-25T20:36:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "3abb0bd6e46e78557c1fd480ac173881dc5d530b",
    "line" : null,
    "diffHunk" : "@@ -1,1 +479,483 @@  .. versionadded:: 0.20.0 support for the Python parser.\n\n     The ``dtype`` option is supported by the 'python' engine\n\n.. note::"
  },
  {
    "id" : "5ccdd163-d86f-4891-9847-70d845195dc2",
    "prId" : 14904,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14904#pullrequestreview-20359152",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "65b1d04d-d7eb-4ae5-b384-cb1e5eeea887",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you *may* want a ref tag here ",
        "createdAt" : "2017-02-06T20:21:26Z",
        "updatedAt" : "2017-03-04T11:46:35Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fac34ce6c646407111c09a942cbd195b6cbf590",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +2034,2038 @@  df.to_json(orient='records', lines=True)\n\n\n.. _io.table_schema:\n"
  },
  {
    "id" : "9c7a0ed3-23ec-4d40-b894-aeff1e2e724c",
    "prId" : 14904,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/14904#pullrequestreview-20359152",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a595709-463b-48c1-b256-a47cb4179fad",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "``orient='table'``",
        "createdAt" : "2017-02-06T20:21:43Z",
        "updatedAt" : "2017-03-04T11:46:35Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fac34ce6c646407111c09a942cbd195b6cbf590",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +2044,2048 @@`Table Schema`_ is a spec for describing tabular datasets as a JSON\nobject. The JSON includes information on the field names, types, and\nother attributes. You can use the orient ``table`` to build\na JSON string with two fields, ``schema`` and ``data``.\n"
  },
  {
    "id" : "6d718a60-1f8c-4242-8ff6-10719dff9c30",
    "prId" : 15637,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/15637#pullrequestreview-26154396",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a420427d-102b-4f34-a8ea-496f6cebae52",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "same line in v0.20.0.txt as well :>",
        "createdAt" : "2017-03-09T21:55:10Z",
        "updatedAt" : "2017-03-09T22:00:28Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ab711662d76d963014f3dcd9071e6891fcc7491",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +3097,3101 @@.. ipython:: python\n   :suppress:\n\n   import os\n   os.remove(\"data.pkl.compress\")"
  },
  {
    "id" : "866a3fb1-2913-4e42-b8e6-a20eb8807918",
    "prId" : 15838,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/15838#pullrequestreview-52611848",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cb20fef-3e87-4852-b185-98ed681819bf",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "This raises an error, since categorical is not supported by pyarrow?",
        "createdAt" : "2017-07-27T07:38:45Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "c5d1db2a-373f-43a9-a803-d7a0a7135a54",
        "parentId" : "0cb20fef-3e87-4852-b185-98ed681819bf",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "https://issues.apache.org/jira/browse/ARROW-1285\r\n(and going to remove the cat; we test this but docs didn't get updated)",
        "createdAt" : "2017-07-27T10:08:03Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "f553a5fbce80b98c4a55bd6469859e8f8922b162",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +4601,4605 @@.. ipython:: python\n\n   df.to_parquet('example_pa.parquet', engine='pyarrow')\n   df.to_parquet('example_fp.parquet', engine='fastparquet')\n"
  },
  {
    "id" : "66b8fbf4-7aa1-4134-b6ab-2dc1b34b1056",
    "prId" : 15838,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/15838#pullrequestreview-52576290",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5902b042-57eb-497b-8f2b-3ccc8c888eea",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Looking at the tests, there seem to be some differences at what data types they support? If that is correct, we should maybe mention it here ?",
        "createdAt" : "2017-07-27T07:39:50Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "f553a5fbce80b98c4a55bd6469859e8f8922b162",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +4580,4584 @@.. note::\n\n   These engines are very similar and should read/write nearly identical parquet format files.\n   These libraries differ by having different underlying dependencies (``fastparquet`` by using ``numba``, while ``pyarrow`` uses a c-library).\n"
  },
  {
    "id" : "24b07696-4f97-4042-ad85-1ef5e2d72995",
    "prId" : 15838,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/15838#pullrequestreview-52576290",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92c43eb8-815a-4404-914b-313945a85f92",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "This also fails because fastparquet is not installed in the doc build. \r\nBut maybe rather than adding it to the doc build, maybe we can make this a code block? (just showing how to specify the engine) To not further burden the doc build with more dependencies (pyarrow is already included for feather)",
        "createdAt" : "2017-07-27T07:42:34Z",
        "updatedAt" : "2017-08-01T22:28:31Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "f553a5fbce80b98c4a55bd6469859e8f8922b162",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +4602,4606 @@\n   df.to_parquet('example_pa.parquet', engine='pyarrow')\n   df.to_parquet('example_fp.parquet', engine='fastparquet')\n\nRead from a parquet file."
  },
  {
    "id" : "c4993c3f-44f3-4b2a-aa09-1f8fa9e0c4ff",
    "prId" : 16355,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/16355#pullrequestreview-42269969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82a11307-2436-478a-adfe-a295df96bd73",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I think let's change the defaults to ``complevel=None``, ``complib=None``.\r\n\r\nIf then complevel is not None and > 0 you can set complib to zlib (if it not defined)\r\nif complib is not None and complevel is not 0 then you set the filter.",
        "createdAt" : "2017-06-06T10:38:39Z",
        "updatedAt" : "2017-06-13T11:33:21Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "af7ecbfa37525d646e04a2d7557feddd97c5a0b3",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +4070,4074 @@control compression: ``complevel`` and ``complib``.\n\n``complevel`` specifies if and how hard data is to be compressed.\n              ``complevel=0`` and ``complevel=None`` disables\n              compression and ``0<complevel<10`` enables compression."
  },
  {
    "id" : "2d4a433f-98e7-432b-b9b8-418b67b781a3",
    "prId" : 17303,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17303#pullrequestreview-58347576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7484b57-1a12-4d8b-9c45-824147ae70e3",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "actually, we could make these an ipython block (so they *would* run)",
        "createdAt" : "2017-08-23T23:18:37Z",
        "updatedAt" : "2017-09-26T03:29:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "36602b3a-da50-40dc-b244-e0a59e659a44",
        "parentId" : "a7484b57-1a12-4d8b-9c45-824147ae70e3",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "I wouldn't do that, building the docs already takes a long time",
        "createdAt" : "2017-08-24T08:51:04Z",
        "updatedAt" : "2017-09-26T03:29:05Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "02e0d900-37e2-4ffb-9ca2-40c4ba5235c8",
        "parentId" : "a7484b57-1a12-4d8b-9c45-824147ae70e3",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "we actually do this in various sections. And the incremental time is quite small here.",
        "createdAt" : "2017-08-24T10:09:37Z",
        "updatedAt" : "2017-09-26T03:29:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "bf7228c5-b4f5-4228-ad55-093ce669bf17",
        "parentId" : "a7484b57-1a12-4d8b-9c45-824147ae70e3",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "It's true we have them in some places, but I suppose it are a lot smaller timings. \r\nThe extra time here is not small. Timing only writing ones that already existed takes 1min30 on my laptop, and then this PR even added more cases and you also have the reading. So this will add maybe like 3 to 5 min to the doc build. Which is IMO not worth it.",
        "createdAt" : "2017-08-24T11:22:47Z",
        "updatedAt" : "2017-09-26T03:29:05Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "1ecdf3f101fb57f446010b880b75a1c495b50241",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +5231,5235 @@.. code-block:: ipython\n\n   In [14]: %timeit test_sql_write(df)\n   2.37 s ± 36.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
  },
  {
    "id" : "f9109ec0-c516-4c3d-a57c-e3a4f4bd88d2",
    "prId" : 17420,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17420#pullrequestreview-60474910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee6b68bd-4ead-49f5-b011-6dbf24170df8",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "this is good.",
        "createdAt" : "2017-09-04T23:48:32Z",
        "updatedAt" : "2017-09-05T00:40:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "b3d1ea129d17d3b5f42b30416c865d58abdfde56",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +3071,3075 @@   and `here <http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0150-refactoring>`__\n   for some examples of compatibility-breaking changes. See\n   `this question <http://stackoverflow.com/questions/20444593/pandas-compiled-from-source-default-pickle-behavior-changed>`__\n   for a detailed explanation.\n"
  },
  {
    "id" : "fa6e46be-f163-494b-baec-abe3bc4836ba",
    "prId" : 17420,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/17420#pullrequestreview-60476851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d29e1d92-1b0a-4405-b8fd-d20c9ecc3b0a",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "is this just underlyined in the diff?",
        "createdAt" : "2017-09-04T23:48:50Z",
        "updatedAt" : "2017-09-05T00:40:25Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "4cefcde8-895f-463c-8163-01795759d227",
        "parentId" : "d29e1d92-1b0a-4405-b8fd-d20c9ecc3b0a",
        "authorId" : "c2e7df75-d1fb-42be-9205-186b46cef3d7",
        "body" : "There no underline here: https://github.com/topper-123/pandas/blob/15e94c4aad7065db86e713e219aed94b6a80d800/doc/source/io.rst. a bit weird, but my  guess is that it's ok\r\n\r\nCan't see anything stand out locally either.",
        "createdAt" : "2017-09-05T00:33:18Z",
        "updatedAt" : "2017-09-05T00:40:25Z",
        "lastEditedBy" : "c2e7df75-d1fb-42be-9205-186b46cef3d7",
        "tags" : [
        ]
      }
    ],
    "commit" : "b3d1ea129d17d3b5f42b30416c865d58abdfde56",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +3140,3144 @@-------\n\npandas supports the ``msgpack`` format for\nobject serialization. This is a lightweight portable binary format, similar\nto binary JSON, that is highly space efficient, and provides good performance"
  },
  {
    "id" : "794a04c7-68e2-4b00-a753-27793c49baa2",
    "prId" : 18042,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18042#pullrequestreview-73032486",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05f8c2d9-6069-47ff-9cad-3aa1553ea5c3",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I would put a paragraph break here, its pretty long.",
        "createdAt" : "2017-10-31T01:15:01Z",
        "updatedAt" : "2017-11-30T14:25:12Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "04ee499e10a21518e7c4ebc66b5a212bfb72666b",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +109,113 @@  are inferred from the first line of the file, if column names are\n  passed explicitly then the behavior is identical to\n  ``header=None``. Explicitly pass ``header=0`` to be able to replace\n  existing names.\n"
  },
  {
    "id" : "0db887f2-f67e-4597-9302-648df5b46e5f",
    "prId" : 18155,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/18155#pullrequestreview-75233524",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7577ffe2-ccf3-4e3b-9e68-431481b5aac0",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "in next PR, can you add a version added tag here (for 0.21.1)",
        "createdAt" : "2017-11-08T20:11:08Z",
        "updatedAt" : "2017-11-08T20:11:08Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b22c889ca4463d7c5ebcd3acbcf3e6067d0a1c2",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +4541,4545 @@Read only certain columns of a parquet file. \n\n.. ipython:: python\n\n   result = pd.read_parquet('example_pa.parquet', engine='pyarrow', columns=['a', 'b'])"
  },
  {
    "id" : "b7575175-c1c7-4965-a102-2ee9c83e15f0",
    "prId" : 19260,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/19260#pullrequestreview-88961570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d68391ad-de35-4a8b-9f7a-9a93605c4db0",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "nice!",
        "createdAt" : "2018-01-16T00:44:57Z",
        "updatedAt" : "2018-01-17T05:22:54Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "63faf8d7c8096f3cb99f20106a2dfcba7dadf34e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +216,220 @@keep_default_na : boolean, default ``True``\n  Whether or not to include the default NaN values when parsing the data.\n  Depending on whether `na_values` is passed in, the behavior is as follows:\n\n  * If `keep_default_na` is True, and `na_values` are specified, `na_values`"
  },
  {
    "id" : "bfa6311d-b0f5-4405-8888-0ee2902276bb",
    "prId" : 21109,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/21109#pullrequestreview-126804395",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "606a7347-23d8-4a98-a458-6657c83c7e3d",
        "parentId" : null,
        "authorId" : "5f34c5f9-b309-4032-bd6e-1f14b864aae4",
        "body" : "All above changes were to `MultiIndex` - here `multi-index`?",
        "createdAt" : "2018-06-07T14:25:47Z",
        "updatedAt" : "2018-06-07T14:29:43Z",
        "lastEditedBy" : "5f34c5f9-b309-4032-bd6e-1f14b864aae4",
        "tags" : [
        ]
      }
    ],
    "commit" : "d929098822a10afa5a9e6f728be72ff56d9c5e29",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +2357,2361 @@Specify a header row (by default ``<th>`` or ``<td>`` elements located within a\n``<thead>`` are used to form the column index, if multiple rows are contained within\n``<thead>`` then a multi-index is created); if specified, the header row is taken\nfrom the data minus the parsed header elements (``<th>`` elements).\n"
  },
  {
    "id" : "91087e19-c57b-4e36-89d6-d8fb128829f6",
    "prId" : 21401,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/21401#pullrequestreview-167637939",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "933f5ddf-717e-4547-bdc8-b99ef7e850ef",
        "parentId" : null,
        "authorId" : "afb6040e-4d88-4b84-baf3-5385ad75eea3",
        "body" : "I realise this is just an example, but isn't this piece vulnerable to SQL injection? the[`psycopg2.sql`](http://initd.org/psycopg/docs/sql.html) module has an [`Identifier`](http://initd.org/psycopg/docs/sql.html#psycopg2.sql.Identifier) object designed to handle SQL identifiers appropriately. See also [Example 41-1. Quoting Values In Dynamic Queries](https://www.postgresql.org/docs/9.6/static/plpgsql-statements.html#PLPGSQL-QUOTE-LITERAL-EXAMPLE).",
        "createdAt" : "2018-08-01T11:35:06Z",
        "updatedAt" : "2018-12-27T23:51:12Z",
        "lastEditedBy" : "afb6040e-4d88-4b84-baf3-5385ad75eea3",
        "tags" : [
        ]
      },
      {
        "id" : "84a0288c-57b0-4013-b15f-2adb8af8489f",
        "parentId" : "933f5ddf-717e-4547-bdc8-b99ef7e850ef",
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "@dahlbaek no expert on this, but if you could provide the code that you would replace it with to make it more robust, that would certainly be welcome!",
        "createdAt" : "2018-10-23T21:14:28Z",
        "updatedAt" : "2018-12-27T23:51:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ce379e83e4eba68d24d194083b512557ffad1d",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +5035,5039 @@\n          sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(\n              table_name, columns)\n          cur.copy_expert(sql=sql, file=s_buf)\n"
  },
  {
    "id" : "3da74cf6-d695-4eaf-9664-89175894ae13",
    "prId" : 21401,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/21401#pullrequestreview-188366500",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "Is there a reason you are not using `to_csv` here? It should be possible to write to a buffer with that as well.\r\n\r\nFurther, I think it would be good to actually run the code of this example, to make sure it works. We could either add it as a test case, or either actually run it in the documentation build (by applying it on a small example dataframe)",
        "createdAt" : "2018-10-23T21:12:49Z",
        "updatedAt" : "2018-12-27T23:51:12Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      },
      {
        "id" : "a3e381ad-62b2-4095-8697-773542c4d594",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "a519604c-dfec-4766-8d68-e4ba814d2c37",
        "body" : "My understanding is that `to_csv()` is a higher level function do a bunch of data conversions. \r\nAt this point when this function is called `data_iter` has already passed trough pandas data conversions...",
        "createdAt" : "2018-12-26T19:42:30Z",
        "updatedAt" : "2018-12-27T23:51:12Z",
        "lastEditedBy" : "a519604c-dfec-4766-8d68-e4ba814d2c37",
        "tags" : [
        ]
      },
      {
        "id" : "64d7a0e8-c5c0-4685-a172-9e37a8b8b5ed",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "I agree this needs testing.",
        "createdAt" : "2018-12-27T00:28:46Z",
        "updatedAt" : "2018-12-27T23:51:12Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "76fd344e-3281-401c-b835-90e4661a145a",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Are we fixing this before merging? I can push a commit if we want.",
        "createdAt" : "2018-12-28T20:13:20Z",
        "updatedAt" : "2018-12-28T20:15:14Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "d18db75c-360f-439b-9e5c-224908078293",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "eb0b5a98-1084-4e61-8414-5fb19728b91f",
        "body" : "@TomAugspurger fix as in use `to_csv` instead? Sure go for it!",
        "createdAt" : "2018-12-28T20:27:09Z",
        "updatedAt" : "2018-12-28T20:27:09Z",
        "lastEditedBy" : "eb0b5a98-1084-4e61-8414-5fb19728b91f",
        "tags" : [
        ]
      },
      {
        "id" : "e0ebe74d-0b8c-449d-8ac0-19f7ee71c574",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Started out as that, but this is kind of a can of worms to actually run this example. We would need to actually create a Postgres database. I'll see if something similar exists for sqlite.",
        "createdAt" : "2018-12-28T20:31:45Z",
        "updatedAt" : "2018-12-28T20:31:46Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "cd11fcea-cb9f-4106-9a2d-51e0be542a99",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "Actually nevermind, this is tested below and we don't actually have a DataFrame here we have a `chunk_iter`. It's not clear to me, but that seems to be a list of arrays, one per column, chunk pair?",
        "createdAt" : "2018-12-28T20:42:16Z",
        "updatedAt" : "2018-12-28T20:42:16Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "a148487b-0a8f-4929-b6fc-22e1591a1862",
        "parentId" : "37086714-aa18-422c-8958-10cd4d12a65f",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "So +1 to merging as is.",
        "createdAt" : "2018-12-28T20:43:48Z",
        "updatedAt" : "2018-12-28T20:43:48Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ce379e83e4eba68d24d194083b512557ffad1d",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +5026,5030 @@          writer = csv.writer(s_buf)\n          writer.writerows(data_iter)\n          s_buf.seek(0)\n\n          columns = ', '.join('\"{}\"'.format(k) for k in keys)"
  },
  {
    "id" : "b47a7bbd-99b0-4cea-9c41-355893fddd1f",
    "prId" : 22266,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/22266#pullrequestreview-147847262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e689ffd3-5dad-4cfd-96b5-61b1e64e9584",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "don't say see below, just say you can pass ``index=False``",
        "createdAt" : "2018-08-20T22:33:20Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "669ac73c-e3f7-4aa9-8b19-bb63e532a4a7",
        "parentId" : "e689ffd3-5dad-4cfd-96b5-61b1e64e9584",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you can add a ref to the Index section if you want",
        "createdAt" : "2018-08-20T22:33:34Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dc53a19320162218671654d7a406f5777730ddc",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +4570,4574 @@Several caveats.\n\n* Duplicate column names and non-string columns names are not supported.\n* The ``pyarrow`` engine always writes the index to the output, but ``fastparquet`` only writes non-default\n  indexes. This extra column can cause problems for non-Pandas consumers that are not expecting it. You can"
  },
  {
    "id" : "e8985677-2bdd-47a2-a22d-962c0c1f16fb",
    "prId" : 22266,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/22266#pullrequestreview-157057174",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b30c671-fa3e-4106-abc8-7582a3bb018f",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "not really sure you need this doc section at all. ``index=False`` is a pretty common option in pandas.",
        "createdAt" : "2018-08-20T22:34:02Z",
        "updatedAt" : "2018-09-19T23:09:03Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "b9c7e35f-433e-45e6-8c5e-ab2807aeecff",
        "parentId" : "9b30c671-fa3e-4106-abc8-7582a3bb018f",
        "authorId" : "50b69844-f7de-4554-9a4d-e8e8c4ea6836",
        "body" : "True, but the goal of this section is mostly to illustrate use cases and how engines differ.",
        "createdAt" : "2018-09-19T23:11:00Z",
        "updatedAt" : "2018-09-19T23:11:01Z",
        "lastEditedBy" : "50b69844-f7de-4554-9a4d-e8e8c4ea6836",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dc53a19320162218671654d7a406f5777730ddc",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +4639,4643 @@\nHandling Indexes\n''''''''''''''''\n\nSerializing a ``DataFrame`` to parquet may include the implicit index as one or"
  },
  {
    "id" : "924b86e2-a4d8-4622-8e5a-1081d8d22df7",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-171869193",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a088bb5c-0696-4e27-a5fc-09c716fee661",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "add a versionadded directive here",
        "createdAt" : "2018-11-06T03:57:10Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "14d7c24e-93a2-4d88-a792-89bc5729e3a6",
        "parentId" : "a088bb5c-0696-4e27-a5fc-09c716fee661",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "done",
        "createdAt" : "2018-11-06T05:36:19Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +4670,4674 @@\nPartitioning Parquet files\n''''''''''''''''''''''''''\n\n.. versionadded:: 0.24.0"
  },
  {
    "id" : "a022192e-f556-4c18-bb54-576711b88411",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-172220487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f18f2637-7d61-4f90-b0af-6174db287f3d",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "you could do execute ``tree`` on this i think rather than hardcoding.\r\n\r\nadd anotther block affter with a ``:suppress:`` directive to clean up.",
        "createdAt" : "2018-11-06T03:58:29Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "b6d0d007-e35f-4c70-9bb2-86e46403e8c6",
        "parentId" : "f18f2637-7d61-4f90-b0af-6174db287f3d",
        "authorId" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "body" : "done",
        "createdAt" : "2018-11-06T05:36:13Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "321231c6-6642-4125-90a1-bdf4e9e4a005",
        "tags" : [
        ]
      },
      {
        "id" : "622e6371-c3e0-4307-a0b9-2249af71285f",
        "parentId" : "f18f2637-7d61-4f90-b0af-6174db287f3d",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "I don't think `tree` is standard on posix, and it wouldn't be available on windows, so OK with hardcoding.",
        "createdAt" : "2018-11-06T20:35:49Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +4685,4689 @@Columns are partitioned in the order they are given. The partition splits are\ndetermined by the unique values in the partition columns.\nThe above example creates a partitioned dataset that may look like:\n\n.. code-block:: text"
  },
  {
    "id" : "95d9ed4e-1a53-4b88-a7d2-8c37ef6e03bd",
    "prId" : 23321,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23321#pullrequestreview-173053450",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92503996-aa22-4542-96d7-82cf96fd1296",
        "parentId" : null,
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Can we be more specific about the exception here? I believe this could just be an `OSError` or `FileNotFoundError` depending on version. Would rather catch those so that this doesn't end up catching things it doesn't mean to during the doc build process",
        "createdAt" : "2018-11-08T15:43:08Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "0cc5bfc3-d402-4698-8c25-116854072d00",
        "parentId" : "92503996-aa22-4542-96d7-82cf96fd1296",
        "authorId" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "body" : "I think the point is that we never want this to fail ",
        "createdAt" : "2018-11-08T16:25:56Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "21b82015-4bfc-4f74-bfca-586973dad2cd",
        "tags" : [
        ]
      },
      {
        "id" : "a2354ebf-add2-486a-8b1e-345f63c35ac2",
        "parentId" : "92503996-aa22-4542-96d7-82cf96fd1296",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "Hmm OK. No concern around it catching exceptions that it shouldn't though?",
        "createdAt" : "2018-11-08T16:31:16Z",
        "updatedAt" : "2018-11-10T05:30:17Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b455473733352e10c321d4f08b9fadc286b4c84",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +4703,4707 @@   try:\n       rmtree('test')\n   except Exception:\n       pass\n"
  },
  {
    "id" : "b92be0ae-c7a3-45cb-a59f-1f5cc0dcb200",
    "prId" : 23544,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23544#pullrequestreview-173070057",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3a996c2-cfe9-4737-a8e0-025a77b7da5a",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "need a versionadded / changed here? or is this just added documentation?",
        "createdAt" : "2018-11-08T13:14:29Z",
        "updatedAt" : "2018-11-11T10:39:23Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "ddfba640-def3-4e8b-9b5b-e2239154953a",
        "parentId" : "f3a996c2-cfe9-4737-a8e0-025a77b7da5a",
        "authorId" : "51189123-86a2-400a-9762-6816882b6f12",
        "body" : "Ah, good point.  It should have version added tags.",
        "createdAt" : "2018-11-08T17:01:24Z",
        "updatedAt" : "2018-11-11T10:39:23Z",
        "lastEditedBy" : "51189123-86a2-400a-9762-6816882b6f12",
        "tags" : [
        ]
      }
    ],
    "commit" : "a36aa76e4cef63ca969b322591e0671a0f852664",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +2879,2883 @@.. versionadded:: 0.24\n\nIf ``usecols`` is a list of strings, it is assumed that each string corresponds\nto a column name provided either by the user in ``names`` or inferred from the\ndocument header row(s). Those strings define which columns will be parsed:"
  },
  {
    "id" : "1a000913-d900-4c39-8434-1f50250a0318",
    "prId" : 23544,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23544#pullrequestreview-173658273",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e19ec96a-8564-4d30-8b7c-5e3768c590c4",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can u show an example using the excel syntax for cols as well",
        "createdAt" : "2018-11-10T04:29:09Z",
        "updatedAt" : "2018-11-11T10:39:23Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "6f8abce9-3cf2-4661-97cf-0f8897583b7e",
        "parentId" : "e19ec96a-8564-4d30-8b7c-5e3768c590c4",
        "authorId" : "51189123-86a2-400a-9762-6816882b6f12",
        "body" : "Done.",
        "createdAt" : "2018-11-10T10:59:40Z",
        "updatedAt" : "2018-11-11T10:39:23Z",
        "lastEditedBy" : "51189123-86a2-400a-9762-6816882b6f12",
        "tags" : [
        ]
      }
    ],
    "commit" : "a36aa76e4cef63ca969b322591e0671a0f852664",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +2887,2891 @@    read_excel('path_to_file.xls', 'Sheet1', usecols=['foo', 'bar'])\n\nElement order is ignored, so ``usecols=['baz', 'joe']`` is the same as ``['joe', 'baz']``.\n\n.. versionadded:: 0.24"
  },
  {
    "id" : "7e21e9c3-dd68-41e6-a971-e06319e17709",
    "prId" : 23715,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23715#pullrequestreview-182984668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2627f1f7-0be2-4ef6-a095-f011d9a2f198",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "can you add a versionadded",
        "createdAt" : "2018-12-09T16:18:43Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f3e058029abae99d436bf7def57179219aaca2f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2599,2603 @@The ``render_links`` argument provides the ability to add hyperlinks to cells\nthat contain URLs.\n\n.. versionadded:: 0.24\n"
  },
  {
    "id" : "a8f4510b-1440-4081-a7dd-4677d9202916",
    "prId" : 23715,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23715#pullrequestreview-182984922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f7c2ff15-e5cd-4794-b387-33dae92bc77d",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "is this long (the rendereing), if so, use .head(5)",
        "createdAt" : "2018-12-09T16:19:08Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "0379c05d-bb49-4d29-b8eb-6955e47538a1",
        "parentId" : "f7c2ff15-e5cd-4794-b387-33dae92bc77d",
        "authorId" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "body" : "Just two rows :)",
        "createdAt" : "2018-12-09T16:25:36Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f3e058029abae99d436bf7def57179219aaca2f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +2607,2611 @@       'name': ['Python', 'Pandas'],\n       'url': ['https://www.python.org/', 'http://pandas.pydata.org']})\n   print(url_df.to_html(render_links=True))\n\n.. ipython:: python"
  },
  {
    "id" : "c1219938-7584-4ea1-aa06-de73cf08e250",
    "prId" : 23715,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/23715#pullrequestreview-184177474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c9c48fc2-ecce-4e58-a142-186c56bf5ea9",
        "parentId" : null,
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "what is this for?",
        "createdAt" : "2018-12-09T16:19:56Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      },
      {
        "id" : "0d15bd14-8559-46a9-b463-b744bd77c433",
        "parentId" : "c9c48fc2-ecce-4e58-a142-186c56bf5ea9",
        "authorId" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "body" : "This runs the write_html() call without including its input or output in the notebook cells that appear in the doc. This makes available the static file rendered on line 2625.\r\n\r\nI copied a pattern used elsewhere in this file, example \"bold_rows\" section, starting line 2584.",
        "createdAt" : "2018-12-09T16:29:54Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "tags" : [
        ]
      },
      {
        "id" : "f74c9818-892c-4e7e-93ba-666134416783",
        "parentId" : "c9c48fc2-ecce-4e58-a142-186c56bf5ea9",
        "authorId" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "body" : "What's the downside of just printing it? I think creating files like this is hard to keep track of within our codebase so less than ideal",
        "createdAt" : "2018-12-11T18:12:46Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "5e8c5ef2-940b-436e-9c5f-98ae5460128c",
        "tags" : [
        ]
      },
      {
        "id" : "02b0b8c3-1f19-40a5-9e86-b7316e250be8",
        "parentId" : "c9c48fc2-ecce-4e58-a142-186c56bf5ea9",
        "authorId" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "body" : "The generated HTML is also printed in a notebook cell. The lines pointed out by @jreback write that HTML to a separate file that can be rendered.\r\n\r\nHere's what it looks like after building:\r\n\r\n![image](https://user-images.githubusercontent.com/8574029/49829597-b1a7cb00-fd43-11e8-96ff-4a54bb7f1ea1.png)\r\n\r\nThat said, if having the rendered sample is not worth the overhead of the extra file, I'm happy to remove.",
        "createdAt" : "2018-12-11T20:53:29Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "bccfdba6-bb92-4a63-b352-09fe251bdaf5",
        "tags" : [
        ]
      },
      {
        "id" : "49800274-f52e-4605-a8cf-cca530c9a623",
        "parentId" : "c9c48fc2-ecce-4e58-a142-186c56bf5ea9",
        "authorId" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "body" : "hmm i am not sure we actually need to show the html, showing the rendered version is enough. but since we are doing it for all of these, ok",
        "createdAt" : "2018-12-12T13:32:12Z",
        "updatedAt" : "2018-12-13T05:33:05Z",
        "lastEditedBy" : "7086d5c0-382b-4c41-b70d-144a07643f71",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f3e058029abae99d436bf7def57179219aaca2f",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +2612,2616 @@   :suppress:\n\n   write_html(url_df, 'render_links', render_links=True)\n\nHTML:"
  },
  {
    "id" : "6fa722e3-e420-433f-9036-525f48ee19f5",
    "prId" : 24298,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/24298#pullrequestreview-185371713",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88e1953d-9de0-4199-8ee2-12f9895c06ec",
        "parentId" : null,
        "authorId" : "b0c8ea7f-389d-4305-8e0a-a1a394b9fcc2",
        "body" : "out of curiosity, what `fh` stands for? file handler? I'm used to `f` or `fd` for file descriptor.",
        "createdAt" : "2018-12-16T00:50:32Z",
        "updatedAt" : "2018-12-17T13:28:04Z",
        "lastEditedBy" : "b0c8ea7f-389d-4305-8e0a-a1a394b9fcc2",
        "tags" : [
        ]
      },
      {
        "id" : "486a2be0-e06a-4cc3-b8e3-aa07120ecaa6",
        "parentId" : "88e1953d-9de0-4199-8ee2-12f9895c06ec",
        "authorId" : "51189123-86a2-400a-9762-6816882b6f12",
        "body" : "fh = file handler ",
        "createdAt" : "2018-12-16T01:06:51Z",
        "updatedAt" : "2018-12-17T13:28:04Z",
        "lastEditedBy" : "51189123-86a2-400a-9762-6816882b6f12",
        "tags" : [
        ]
      }
    ],
    "commit" : "cf1e3d32ecaa1d865aa5df4a45c065e31ca18246",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1866,1870 @@\n   with open('test.json') as fh:\n       print(fh.read())\n\nFallback Behavior"
  },
  {
    "id" : "03ad3592-3d1d-4868-ae52-b8f6f32cb8c0",
    "prId" : 24438,
    "prUrl" : "https://github.com/pandas-dev/pandas/pull/24438#pullrequestreview-188687444",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6ed4716-3e6a-4ed4-932c-b7313779c1b7",
        "parentId" : null,
        "authorId" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "body" : "same here",
        "createdAt" : "2019-01-02T14:14:50Z",
        "updatedAt" : "2019-01-02T14:14:53Z",
        "lastEditedBy" : "cc7022b2-2831-4c63-a4da-d18b0d342508",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2043d732b3e192c919f563fb98860c2cb6b49c5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +4880,4884 @@If you want to manage your own connections you can pass one of those instead:\n\n.. ipython:: python\n\n   with engine.connect() as conn, conn.begin():"
  }
]