[
  {
    "id" : "90c184db-b5c6-4d91-b2fc-1414ea9019e9",
    "prId" : 27185,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14f2d5f0-9475-4287-b201-cd76091024a5",
        "parentId" : null,
        "authorId" : "109e4fe5-4b7d-49ac-a32f-b25103830bbf",
        "body" : "Is this equation sufficient? Looking at some sample num_node values:\n\n1 node -> 80 + 1_0.5 = 80.5m\n10 nodes -> 80 + 10_0.5 = 85m\n100 nodes -> 80 + 100*0.5 = 130m\n1000 nodes -> 80 + 1000 \\* 0.5 => 580m\n\nThe delta between 10 and 100 nodes is roughly 45m (is that enough?), while from 100 to 1000 is only 450m, which doesn't seem enough. I wonder if we need to have adjustments for various \"tiers\" of nodes.\n",
        "createdAt" : "2016-06-14T17:52:38Z",
        "updatedAt" : "2016-06-15T11:35:34Z",
        "lastEditedBy" : "109e4fe5-4b7d-49ac-a32f-b25103830bbf",
        "tags" : [
        ]
      },
      {
        "id" : "fee70127-f03f-4951-ad9f-1f86f275190e",
        "parentId" : "14f2d5f0-9475-4287-b201-cd76091024a5",
        "authorId" : "24302707-9254-48df-89a5-cbcc349462b8",
        "body" : "Yes - it's good enough. In fact, we used to have 100m even for 1000nodes in 1.2 release, and it was somehow working.\n",
        "createdAt" : "2016-06-14T18:16:47Z",
        "updatedAt" : "2016-06-15T11:35:34Z",
        "lastEditedBy" : "24302707-9254-48df-89a5-cbcc349462b8",
        "tags" : [
        ]
      },
      {
        "id" : "47b22043-e5d6-4e48-9b5b-80ca52270e49",
        "parentId" : "14f2d5f0-9475-4287-b201-cd76091024a5",
        "authorId" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "body" : "cc @mwielgus \n",
        "createdAt" : "2016-06-14T18:34:13Z",
        "updatedAt" : "2016-06-15T11:35:34Z",
        "lastEditedBy" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "tags" : [
        ]
      },
      {
        "id" : "e9a91bfc-5057-49a7-8c6b-fcf1066f4ad0",
        "parentId" : "14f2d5f0-9475-4287-b201-cd76091024a5",
        "authorId" : "109e4fe5-4b7d-49ac-a32f-b25103830bbf",
        "body" : "Note that the limits were used for scheduling, but not strictly enforced (ContainerVM didn't support it). The new GCI nodes should be enforcing it, so this may need to be checked and perhaps revised.\n",
        "createdAt" : "2016-06-15T16:49:58Z",
        "updatedAt" : "2016-06-15T16:49:58Z",
        "lastEditedBy" : "109e4fe5-4b7d-49ac-a32f-b25103830bbf",
        "tags" : [
        ]
      }
    ],
    "commit" : "8617f70addbb38deb64c4219867e61b5551eca3e",
    "line" : null,
    "diffHunk" : "@@ -1,1 +13,17 @@{% if num_nodes >= 0 -%}\n  {% set metrics_memory = (200 + num_nodes * metrics_memory_per_node)|string + \"Mi\" -%}\n  {% set metrics_cpu = (80 + num_nodes * metrics_cpu_per_node)|string + \"m\" -%}\n  {% set eventer_memory = (200 * 1024 + num_nodes * eventer_memory_per_node)|string + \"Ki\" -%}\n  {% set nanny_memory = (90 * 1024 + num_nodes * nanny_memory_per_node)|string + \"Ki\" -%}"
  },
  {
    "id" : "f7706f77-454c-44df-be01-eff43a29723b",
    "prId" : 22940,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "871a6179-4b88-4c8d-bf06-aa515a67848b",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Are we increasing the memory requirement for heapster pod as a whole? \n",
        "createdAt" : "2016-03-14T18:33:09Z",
        "updatedAt" : "2016-03-14T19:00:47Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "fa46ee45-11da-44fc-a9c4-f074dbb2b19d",
        "parentId" : "871a6179-4b88-4c8d-bf06-aa515a67848b",
        "authorId" : "ab8bc7c5-233d-47c1-b03a-767fb930c021",
        "body" : "Yes. Just in case. \nFor 1000 node cluster we are able to operate without any sink at 2-2.3gb (with 30k pause and 2k system pods). GKE http output creation consumes +400MB.  That brings us to 2.75. If couple events occur at once: scraping, gke scraping and pod relist then the temporary memory consumption can be bigger. So to be on the VERY safe side I decided to go with 4 multpilier.\n\nAs we did a lot of noise (=events) during the tests it became apparent that Eventer should also have more memory. List that happens inside of watch consumes _LOTS_ of memory (we will try to get rid of it just after 1.2).\n",
        "createdAt" : "2016-03-14T18:54:07Z",
        "updatedAt" : "2016-03-14T19:00:47Z",
        "lastEditedBy" : "ab8bc7c5-233d-47c1-b03a-767fb930c021",
        "tags" : [
        ]
      }
    ],
    "commit" : "6123df9992c6a23e27403adfbc702243a22c192d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +3,7 @@{% set num_nodes = pillar.get('num_nodes', -1) -%}\n{% if num_nodes >= 0 -%}\n  {% set metrics_memory = (200 + num_nodes * 4)|string + \"Mi\" -%}\n  {% set eventer_memory = (200000 + num_nodes * 500)|string + \"Ki\" -%}\n{% endif -%}"
  },
  {
    "id" : "7ba728a8-87be-4481-878a-40da7bc955dc",
    "prId" : 22940,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "02ab5a4b-dfed-42a8-9e80-8b42e41ef0a9",
        "parentId" : null,
        "authorId" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "body" : "/s/200000/200*1024\n",
        "createdAt" : "2016-03-14T20:57:32Z",
        "updatedAt" : "2016-03-14T20:57:32Z",
        "lastEditedBy" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "tags" : [
        ]
      }
    ],
    "commit" : "6123df9992c6a23e27403adfbc702243a22c192d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +4,8 @@{% if num_nodes >= 0 -%}\n  {% set metrics_memory = (200 + num_nodes * 4)|string + \"Mi\" -%}\n  {% set eventer_memory = (200000 + num_nodes * 500)|string + \"Ki\" -%}\n{% endif -%}\n"
  },
  {
    "id" : "5871ef5b-e783-4ce7-aee0-2b66f0d397ca",
    "prId" : 22893,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "parentId" : null,
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "If you just specify limits, request should be set from limits.\n",
        "createdAt" : "2016-03-17T02:34:55Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "f5732817-9476-4bf6-a6a4-0e7015a9905c",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "#18216 added requests to all addons.\n",
        "createdAt" : "2016-03-17T18:31:40Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "593c61b5-0a44-4fe5-aef5-a5486b464981",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "body" : "One of the [config best practices](http://kubernetes.io/docs/user-guide/config-best-practices/) is:\n\n> Donâ€™t specify default values unnecessarily, in order to simplify and minimize configs, and to reduce error. \n\nI don't really understand the argument behind #18216 but it seems to violate that best practice.\n",
        "createdAt" : "2016-03-17T19:52:15Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "tags" : [
        ]
      },
      {
        "id" : "d8fcbdf1-e5d9-44ba-9b7f-12bae2019ef3",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "body" : "Then why don't we do this for other singletons (e.g., heapster itself)?\n",
        "createdAt" : "2016-03-17T20:26:27Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "tags" : [
        ]
      },
      {
        "id" : "d9638ef3-1cf0-4543-baab-e694d5b00945",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "body" : "Because of #18216. Can you explain why this is important @gmarek? Here's the defaulting code https://github.com/kubernetes/kubernetes/blob/master/pkg/api/v1/defaults.go#L99-L116\n",
        "createdAt" : "2016-03-17T21:28:31Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "tags" : [
        ]
      },
      {
        "id" : "4ae82ae8-ab5f-4bc5-9db1-56bb108edd81",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "body" : "When we were designing QoS we decided to have this defaulting as a backward compatibility feature. I didn't had impression that it's there to stay forever, so I think we should have requests explicit. Generally all those QoS stuff is really confusing as it is today. @piosz \n",
        "createdAt" : "2016-03-17T22:20:38Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "tags" : [
        ]
      },
      {
        "id" : "d81631e1-348a-416f-ae77-b277b146bffd",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "body" : "Interesting: I didn't know about that default behavior. It actually conflicts with the addon-resizer, which explicitly sets requests=limits to keep its dependents in the guaranteed class. The addon-resizer also performs an update on any _qualitative_ difference (e.g., requests being expected but not found). This would manifest as a single deployment update at startup.\n\nIt feels weird to add a flag to disregard requests, but we'll need to if we want to utilize this default behavior. But since literally all of our addons specify both requests and limits, why don't I cut an issue for 1.3 to rectify both the pod_nanny and all of our addon yamls with best practices?\n",
        "createdAt" : "2016-03-18T19:01:33Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "tags" : [
        ]
      },
      {
        "id" : "f9bc19d6-a46d-4758-8ca2-347cbbfb18e2",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "body" : "SGTM\n",
        "createdAt" : "2016-03-18T19:04:39Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "tags" : [
        ]
      },
      {
        "id" : "2cbba4e2-aad4-4f29-83fc-40c01822aa76",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "body" : "This is another proof that the current state is confusing. We should work on that at some point.\n",
        "createdAt" : "2016-03-18T19:50:36Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "3c437914-616b-4cfb-88a0-28dc812ff2b2",
        "tags" : [
        ]
      },
      {
        "id" : "96ae5584-c49a-46e8-b4d5-10545d4d3ca6",
        "parentId" : "0231402d-f62f-4806-bfe4-4d1f6337a2b7",
        "authorId" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "body" : "Opened #23229\n",
        "createdAt" : "2016-03-19T00:16:46Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "tags" : [
        ]
      }
    ],
    "commit" : "81ba98ae5d7fe46fa5c0fd01066efa01f604e4e9",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +70,74 @@          name: heapster-nanny\n          resources:\n            limits:\n              cpu: 50m\n              memory: 100Mi"
  },
  {
    "id" : "4ffe0097-7620-47b8-8382-3529b82f41f9",
    "prId" : 22893,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e5b2bc6-8408-4313-98a7-3b99a123d501",
        "parentId" : null,
        "authorId" : "7be32503-562e-4caa-838d-bba025e626b5",
        "body" : "Since this only has 1 replica, you might consider the Recreate update policy. The default is RollingUpdate.\n",
        "createdAt" : "2016-03-17T02:36:38Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "7be32503-562e-4caa-838d-bba025e626b5",
        "tags" : [
        ]
      },
      {
        "id" : "c64bc969-87c0-4dbc-9976-671f65a09608",
        "parentId" : "3e5b2bc6-8408-4313-98a7-3b99a123d501",
        "authorId" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "body" : "Interesting idea. The code for the container in question lives in contrib/addon-resizer, where that would be an easy (1-line) change. I'll definitely consider it.\n",
        "createdAt" : "2016-03-17T20:29:07Z",
        "updatedAt" : "2016-03-22T20:47:18Z",
        "lastEditedBy" : "6c7e5fb3-9a32-484a-be21-c70b4d00de52",
        "tags" : [
        ]
      }
    ],
    "commit" : "81ba98ae5d7fe46fa5c0fd01066efa01f604e4e9",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +18,22 @@    kubernetes.io/cluster-service: \"true\"\nspec:\n  replicas: 1\n  selector:\n    matchLabels:"
  },
  {
    "id" : "d636416d-8252-40c7-a0a4-fce4977ddeff",
    "prId" : 14559,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "96123330-0608-4792-9898-d016b4ecd032",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "I'm not sure if GCM can handle a 1 minute frequency. Have you thought of GCM default quota limitations?\n",
        "createdAt" : "2015-09-25T16:15:28Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "b07b2b10-c59d-4e9e-bf03-431e9493f44c",
        "parentId" : "96123330-0608-4792-9898-d016b4ecd032",
        "authorId" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "body" : "IIUC quota limitations are not about the frequency of writes but rather amount of data in terms of number of datapoints (https://github.com/kubernetes/heapster/blob/master/sinks/gcm/core.go#L223).\n",
        "createdAt" : "2015-09-28T13:37:48Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "tags" : [
        ]
      },
      {
        "id" : "029b629d-b095-41b0-a118-58171823a6dc",
        "parentId" : "96123330-0608-4792-9898-d016b4ecd032",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "As long as you have tested this change for a day with GCM, I'm happy to merge this. \n",
        "createdAt" : "2015-09-28T16:58:27Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "b79b85dc-dc67-4965-a3aa-e5e4c34cd877",
        "parentId" : "96123330-0608-4792-9898-d016b4ecd032",
        "authorId" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "body" : "Will do it. Alternatively we use googleinfluxdb monitoring level in our autoscaling e2e tests.\n",
        "createdAt" : "2015-09-28T18:40:55Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "tags" : [
        ]
      },
      {
        "id" : "a0c1c387-41eb-43e3-8f74-eae21d8cdfc0",
        "parentId" : "96123330-0608-4792-9898-d016b4ecd032",
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Do these tests run for a day? I have seen quota issues only after 16+\nhours.\n\nOn Mon, Sep 28, 2015 at 11:41 AM, Piotr Szczesniak <notifications@github.com\n\n> wrote:\n> \n> In\n> cluster/addons/cluster-monitoring/googleinfluxdb/heapster-controller-combined.yaml\n> https://github.com/kubernetes/kubernetes/pull/14559#discussion_r40588758\n> :\n> \n> > @@ -32,7 +32,8 @@ spec:\n> >              - --sink=gcl\n> >              - --sink=gcmautoscaling\n> \n> Will do it. Alternatively we use googleinfluxdb monitoring level in our\n> autoscaling e2e tests.\n> \n> â€”\n> Reply to this email directly or view it on GitHub\n> https://github.com/kubernetes/kubernetes/pull/14559/files#r40588758.\n",
        "createdAt" : "2015-09-28T19:36:47Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      }
    ],
    "commit" : "94080973b1dc3c649c48404590d2a7cebe77a07c",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +31,35 @@            - --source=kubernetes:''\n            - --sink=gcl\n            - --sink=gcmautoscaling\n            - --sink=influxdb:http://monitoring-influxdb:8086\n            - --stats_resolution=30s"
  },
  {
    "id" : "8e002111-5010-4e1d-885f-5e5ae3c320c0",
    "prId" : 14559,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb674e2b-710a-49af-a1be-29c48ed9b7f1",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "Why change stats resolution?\n",
        "createdAt" : "2015-09-25T16:15:39Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "9cf516dc-ff35-4128-93dc-5fdcf1fd40ca",
        "parentId" : "bb674e2b-710a-49af-a1be-29c48ed9b7f1",
        "authorId" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "body" : "Same as above.\n",
        "createdAt" : "2015-09-28T13:34:55Z",
        "updatedAt" : "2015-10-05T07:53:25Z",
        "lastEditedBy" : "a6ca7669-677e-4e8d-80cf-83cbff3b4216",
        "tags" : [
        ]
      }
    ],
    "commit" : "94080973b1dc3c649c48404590d2a7cebe77a07c",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +33,37 @@            - --sink=gcmautoscaling\n            - --sink=influxdb:http://monitoring-influxdb:8086\n            - --stats_resolution=30s\n            - --sink_frequency=1m\n          volumeMounts:"
  },
  {
    "id" : "f53664e3-cdba-4cfb-9d4f-7a3a8b3dd473",
    "prId" : 9309,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c7b51cc-3ef2-4cf9-94b0-3fc552cb7b30",
        "parentId" : null,
        "authorId" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "body" : "This will result in events being pushed to both influxdb and GCL. Shall we update heapster to make events optional in influxdb?\n",
        "createdAt" : "2015-06-08T16:50:31Z",
        "updatedAt" : "2015-06-08T16:50:31Z",
        "lastEditedBy" : "c4b970b3-3b9c-4773-bc9b-f8d005b15fd1",
        "tags" : [
        ]
      },
      {
        "id" : "159f416e-ed81-433f-b4f2-90a7b5ed94a0",
        "parentId" : "6c7b51cc-3ef2-4cf9-94b0-3fc552cb7b30",
        "authorId" : "8e448017-7838-493d-a424-33cada0da657",
        "body" : "Yep, that's a good idea. Opened up GoogleCloudPlatform/heapster/issues/321\n",
        "createdAt" : "2015-06-08T21:06:05Z",
        "updatedAt" : "2015-06-08T21:06:05Z",
        "lastEditedBy" : "8e448017-7838-493d-a424-33cada0da657",
        "tags" : [
        ]
      }
    ],
    "commit" : "a839f47d4a782669d20561a52144eade835a38e5",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +26,30 @@            - /heapster\n            - --source=kubernetes:https://kubernetes\n            - --sink=gcl\n            - --sink=influxdb:http://monitoring-influxdb:8086\n            - --poll_duration=2m"
  }
]