[
  {
    "id" : "4e2dca83-8c62-4cc2-a95f-a5c9ec45b05e",
    "prId" : 57157,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/57157#pullrequestreview-83297248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7d486cb-cd10-4263-9c81-54874d426dee",
        "parentId" : null,
        "authorId" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "body" : "you can do `grep -q` to not print anything",
        "createdAt" : "2017-12-13T19:53:17Z",
        "updatedAt" : "2017-12-13T19:56:14Z",
        "lastEditedBy" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "tags" : [
        ]
      }
    ],
    "commit" : "98372d664d89287295403675f3a2eae93f855f84",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +102,106 @@    iptables -A INPUT -p ICMP -j ACCEPT\n  fi\n  if iptables -L FORWARD | grep \"Chain FORWARD (policy DROP)\" > /dev/null; then\n    echo \"Add rules to accept all forwarded TCP/UDP/ICMP packets\"\n    iptables -A FORWARD -p TCP -j ACCEPT"
  },
  {
    "id" : "40343ef3-46a7-4cdf-aa81-0ad2a95cdf3a",
    "prId" : 57157,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/57157#pullrequestreview-83297248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6eb420ff-9aed-40b2-bec8-016ec3ed9889",
        "parentId" : null,
        "authorId" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "body" : "`grep -q`\r\n\r\niptables -n -L?",
        "createdAt" : "2017-12-13T19:53:29Z",
        "updatedAt" : "2017-12-13T19:56:14Z",
        "lastEditedBy" : "b714f738-aa05-4f49-a624-eaaf3e0cbb70",
        "tags" : [
        ]
      }
    ],
    "commit" : "98372d664d89287295403675f3a2eae93f855f84",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +96,100 @@\n  # We need to add rules to accept all TCP/UDP/ICMP packets.\n  if iptables -L INPUT | grep \"Chain INPUT (policy DROP)\" > /dev/null; then\n    echo \"Add rules to accept all inbound TCP/UDP/ICMP packets\"\n    iptables -A INPUT -p TCP -j ACCEPT"
  },
  {
    "id" : "cca2af40-8e4e-4072-a49d-ca7e165003b7",
    "prId" : 32886,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/32886#pullrequestreview-424513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "749b9806-d6d4-4f0c-aa79-f3e745bb3d95",
        "parentId" : null,
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "Also please comb through docs to ensure that we're not infringing on a subnet that we previously didn't infringe on. see: https://cloud.google.com/compute/docs/vm-ip-addresses and https://cloud.google.com/compute/docs/networking#subnet_network \n",
        "createdAt" : "2016-09-16T19:27:14Z",
        "updatedAt" : "2016-09-16T20:42:12Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      },
      {
        "id" : "e74e6280-f54f-4eda-b5dc-fd071ce61b15",
        "parentId" : "749b9806-d6d4-4f0c-aa79-f3e745bb3d95",
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "a better thing to do in the longer term might be to just bite off a chunk of the cluster-cidr, at least we're sure we own that\n",
        "createdAt" : "2016-09-16T19:33:56Z",
        "updatedAt" : "2016-09-16T20:42:12Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      },
      {
        "id" : "1f4c0a0e-d4fb-42b7-83ea-650904d7b9bc",
        "parentId" : "749b9806-d6d4-4f0c-aa79-f3e745bb3d95",
        "authorId" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "body" : "yeah, do we expect this CIDR ro be \"real\"?  Is it in the master Node object?  Does it have a GCE route?  It is conspicuously made-up and un-dynamic.\n\nWhat happens if I have 2 clusters with 2 masters?  I don't know the history of this logic, but it has a smell to it...\n",
        "createdAt" : "2016-09-16T19:58:47Z",
        "updatedAt" : "2016-09-16T20:42:12Z",
        "lastEditedBy" : "f87fe7d3-581c-4cb6-b17e-b807c6f2c789",
        "tags" : [
        ]
      },
      {
        "id" : "a0a29375-8c90-4957-a722-415f74dba488",
        "parentId" : "749b9806-d6d4-4f0c-aa79-f3e745bb3d95",
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "for now the cidr is not real. actually i think the master node is assigned a /24 because the node controller doesn't know any better (and this is real, it has a route), but we just use this hardcoded one. \n\nI was worried about a case like proxy/exec/logs where the master might use the internal ip of some node, and if that collides with fluents ip because of operation error (not an issue on platforms that use external ip like gke).  \n\nhttps://github.com/kubernetes/kubernetes/issues/32900\n",
        "createdAt" : "2016-09-16T20:41:50Z",
        "updatedAt" : "2016-09-16T20:42:12Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "879a2dcdbd415638b8770a43d0f9fd8cd2899836",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +969,973 @@  roles:\n    - kubernetes-pool\n  cbr-cidr: 10.123.45.0/29\n  cloud: gce\n  api_servers: '${KUBERNETES_MASTER_NAME}'"
  },
  {
    "id" : "f04b2bb9-c798-427b-a1c7-51ee9bb7d208",
    "prId" : 32886,
    "prUrl" : "https://github.com/kubernetes/kubernetes/pull/32886#pullrequestreview-458506",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0067c7c0-763a-4841-a8aa-86471040b863",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "I'm not clear on why this has to change. This case is for when the master is part of the cluster (e.g. the CIDR should start as a /30 and then get changed to a /24 CIDR allocated by the node controller). The block below is for a master that isn't registered and allocates `10.246.0.0/24` by default. \n",
        "createdAt" : "2016-09-17T06:30:37Z",
        "updatedAt" : "2016-09-17T06:31:34Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "6cbd124a-1255-4ac1-bb78-8eb80b3569d8",
        "parentId" : "0067c7c0-763a-4841-a8aa-86471040b863",
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "What you described is the desired behavior. If we were using the /24 we wouldn't have the bug this is trying to fix (or, we would be hitting it on the first container on any node). \n\nIt's possible we started hitting some race condition when we moved the master to gci where the cni config got written out with the wrong pod-cidr and we just didn't care till now. \n\nthe kubelet sets pod cidr straight out the gate: https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kubelet.go#L645, and we don't really allow it to change because that requires a restart of all containers on the bridge (previously, with CNI it's different but we decided as a policy that it shouldn't change). \n\nI didn't dig too deep into the regression but vaguely remember the --pod-cidr reflecting in the bridge even in 1.3\n",
        "createdAt" : "2016-09-17T07:23:46Z",
        "updatedAt" : "2016-09-17T07:34:05Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      },
      {
        "id" : "b1de6a76-1503-45aa-af68-2ce733133f8d",
        "parentId" : "0067c7c0-763a-4841-a8aa-86471040b863",
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "I also think that 1.3 was the first release where we registered the master into the cluster. So 1.2 --> 1.3 upgrades went from the master being standalone to the master being registered. And 1.3 --> 1.4 is the first upgrade where the master was registered before and after the upgrades. It's possible that there is a bug with the master node registration during upgrades that is causing the CIDR not to be set properly by the kubelet. \n",
        "createdAt" : "2016-09-17T15:07:34Z",
        "updatedAt" : "2016-09-17T15:07:35Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      }
    ],
    "commit" : "879a2dcdbd415638b8770a43d0f9fd8cd2899836",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +950,954 @@    cat <<EOF >>/etc/salt/minion.d/grains.conf\n  kubelet_api_servers: '${KUBELET_APISERVER}'\n  cbr-cidr: 10.123.45.0/29\nEOF\n  else"
  },
  {
    "id" : "a335a7d3-1a9b-449e-a7a3-bc8baf65966a",
    "prId" : 29786,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "404bb56d-2fb2-4993-906f-9abeadfa3b07",
        "parentId" : null,
        "authorId" : "df06b0d6-fd6c-44d1-8008-efeaccd16cd5",
        "body" : "Why do you change this line?\n",
        "createdAt" : "2016-07-30T00:38:10Z",
        "updatedAt" : "2016-07-30T14:01:54Z",
        "lastEditedBy" : "df06b0d6-fd6c-44d1-8008-efeaccd16cd5",
        "tags" : [
        ]
      },
      {
        "id" : "f55314f3-0dee-4371-bb15-e6aed500e33b",
        "parentId" : "404bb56d-2fb2-4993-906f-9abeadfa3b07",
        "authorId" : "c929c906-4dfb-433b-9bc7-1b4b05c176f8",
        "body" : "There was an error. Please not that we set KUBERNETES_MASTER_NAME in [common.sh](https://github.com/kubernetes/kubernetes/blob/master/cluster/common.sh#L544). In effect, variable `master_name` had incorrect value in salt config (was empty).\n",
        "createdAt" : "2016-07-30T14:06:40Z",
        "updatedAt" : "2016-07-30T14:06:40Z",
        "lastEditedBy" : "c929c906-4dfb-433b-9bc7-1b4b05c176f8",
        "tags" : [
        ]
      },
      {
        "id" : "5b4e0cf2-4b53-4e00-a947-92ec0413a981",
        "parentId" : "404bb56d-2fb2-4993-906f-9abeadfa3b07",
        "authorId" : "c929c906-4dfb-433b-9bc7-1b4b05c176f8",
        "body" : "Salt variable `master_name` is only used to create name of PV for influxdb, that's why this problem  remained unnoticed for so long.\n",
        "createdAt" : "2016-07-30T14:10:03Z",
        "updatedAt" : "2016-07-30T14:10:03Z",
        "lastEditedBy" : "c929c906-4dfb-433b-9bc7-1b4b05c176f8",
        "tags" : [
        ]
      },
      {
        "id" : "ae20207a-52d7-4d04-896a-fb53581ad04f",
        "parentId" : "404bb56d-2fb2-4993-906f-9abeadfa3b07",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "The use of `master_name` doesn't work in common code, in the general case. The master may not be resolvable even on itself, and this is just not true on AWS:\n\n```\nadmin@ip-172-20-0-9:~$ ping kubernetes-master\nping: unknown host kubernetes-master\n```\n\nI'd like to rip out these pillars completely, and the use in the influxdb PetSet, where it's only used as a uniquifier (instance-prefix is a fine uniquifier).\n",
        "createdAt" : "2016-08-03T23:20:41Z",
        "updatedAt" : "2016-08-04T06:11:48Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "e4d47805-d148-42a3-9024-062886bb9456",
        "parentId" : "404bb56d-2fb2-4993-906f-9abeadfa3b07",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "And yes, on something like `kops` we might have a hard requirement on DNS, but that's not true on all deployments yet.\n",
        "createdAt" : "2016-08-03T23:21:27Z",
        "updatedAt" : "2016-08-03T23:21:27Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "657b30ccf673efc5fc79d0ca90feecfe5ac7de22",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +453,457 @@manifest_url: '$(echo \"${MANIFEST_URL:-}\" | sed -e \"s/'/''/g\")'\nmanifest_url_header: '$(echo \"${MANIFEST_URL_HEADER:-}\" | sed -e \"s/'/''/g\")'\nmaster_name: '$(echo \"${KUBERNETES_MASTER_NAME:-}\" | sed -e \"s/'/''/g\")'\nnum_nodes: $(echo \"${NUM_NODES:-}\" | sed -e \"s/'/''/g\")\ne2e_storage_test_environment: '$(echo \"$E2E_STORAGE_TEST_ENVIRONMENT\" | sed -e \"s/'/''/g\")'"
  },
  {
    "id" : "fec96f71-d40a-494a-b0ae-9a99649ce768",
    "prId" : 29426,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea1263a2-83f7-4133-b03f-e2bff4c4efea",
        "parentId" : null,
        "authorId" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "body" : "are either of these files used in aws?\n",
        "createdAt" : "2016-07-22T22:46:45Z",
        "updatedAt" : "2016-07-22T22:46:45Z",
        "lastEditedBy" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "tags" : [
        ]
      },
      {
        "id" : "6dff7f82-6bac-4b20-a874-edb9761710ba",
        "parentId" : "ea1263a2-83f7-4133-b03f-e2bff4c4efea",
        "authorId" : "8fc8f958-3c0e-47dd-a0fb-b8cc483b4efb",
        "body" : "configure-vm definitely is: https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/configure-vm.sh#L21\n\nI was thinking about this though...\n\n1.5 GB  in 80 seconds is about 20 MB/second.    300 seconds is about 5 MB / second.  I would argue we probably shouldn't treat anything over 1MB/s as an error, but a 1500 second timeout just feels ridiculous.  The right answer is to make the download smaller (or skip it entirely), but in the meantime...\n",
        "createdAt" : "2016-07-23T01:32:20Z",
        "updatedAt" : "2016-07-23T01:32:20Z",
        "lastEditedBy" : "8fc8f958-3c0e-47dd-a0fb-b8cc483b4efb",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb3483eabaad739c746a67a22ce2da5579c7f01c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +167,171 @@      local file=\"${url##*/}\"\n      rm -f \"${file}\"\n      if ! curl -f --ipv4 -Lo \"${file}\" --connect-timeout 20 --max-time 300 --retry 6 --retry-delay 10 \"${url}\"; then\n        echo \"== Failed to download ${url}. Retrying. ==\"\n      elif [[ -n \"${hash}\" ]] && ! validate-hash \"${file}\" \"${hash}\"; then"
  },
  {
    "id" : "635be6b2-ed25-4465-8970-68f149880bea",
    "prId" : 29284,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3475b434-3602-4b59-9297-5c158da06938",
        "parentId" : null,
        "authorId" : "df06b0d6-fd6c-44d1-8008-efeaccd16cd5",
        "body" : "Should't this use `INITIAL_ETCD_CLUSTER` var?\n",
        "createdAt" : "2016-07-30T00:42:02Z",
        "updatedAt" : "2016-07-30T00:42:02Z",
        "lastEditedBy" : "df06b0d6-fd6c-44d1-8008-efeaccd16cd5",
        "tags" : [
        ]
      }
    ],
    "commit" : "827ee794d6ff52fc36152803b3e88ecf71e6cd92",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +457,461 @@e2e_storage_test_environment: '$(echo \"$E2E_STORAGE_TEST_ENVIRONMENT\" | sed -e \"s/'/''/g\")'\nkube_uid: '$(echo \"${KUBE_UID}\" | sed -e \"s/'/''/g\")'\ninitial_etcd_cluster: '$(echo \"${KUBERNETES_MASTER_NAME:-}\" | sed -e \"s/'/''/g\")'\nEOF\n    if [ -n \"${KUBELET_PORT:-}\" ]; then"
  },
  {
    "id" : "be2f3f4e-da83-49f6-a549-632e777e3ce0",
    "prId" : 23603,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6bce833-dcc5-46a9-a29a-f72732b96c6e",
        "parentId" : null,
        "authorId" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "body" : "Do you plan to delete the rest in a later PR?\n",
        "createdAt" : "2016-03-30T18:01:08Z",
        "updatedAt" : "2016-03-30T18:01:08Z",
        "lastEditedBy" : "020e031c-c298-4e7e-a533-9a04439c203c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a821a473dadc08b8f82f623a5179b904f9474d4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +586,590 @@    # change to detect the existence of this file, kill any deleted\n    # old tokens and add any new tokens (to handle the upgrade case).\n    local -r service_accounts=(\"system:scheduler\" \"system:controller_manager\" \"system:logging\" \"system:monitoring\")\n    for account in \"${service_accounts[@]}\"; do\n      token=$(dd if=/dev/urandom bs=128 count=1 2>/dev/null | base64 | tr -d \"=+/\" | dd bs=32 count=1 2>/dev/null)"
  },
  {
    "id" : "29fed047-01a9-4535-9bc6-1b02f0eebc62",
    "prId" : 22234,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f082754a-8f60-4063-9feb-07f7b03a3cd9",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "why is the for loop wrapped in a while loop? It seems like this function will run forever now rather than \"bust\"\n",
        "createdAt" : "2016-03-01T03:59:18Z",
        "updatedAt" : "2016-03-01T17:59:46Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "01413264-61bd-4bc8-93d6-12bf0b2a2dab",
        "parentId" : "f082754a-8f60-4063-9feb-07f7b03a3cd9",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "I can rename it if you want, but the old function actually had the had same behavior. The old behavior is essentially to block inside the `curl` for some period of time doing retries (6, to be precise), then come up for air and `echo` so you'd see something in the logs - otherwise it wasn't clear what was failing. I kept the retry behavior because it's relatively sane - it'll pound on one geo for a minute or two and then fall to another in a round-robin. There are more complicated options we can consider at some point, like trying one download of the first URL first, then trying them all with retries in parallel (sort of like how IPv4 to IPv6 is handled).\n\nBut it's actually always been infinite. There's nothing to do if we can't get the release or the Salt tar down.\n",
        "createdAt" : "2016-03-01T16:54:50Z",
        "updatedAt" : "2016-03-01T17:59:46Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "5a031bf52c988686db49815bf2ce09b21c27239b",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +150,154 @@\n  urls=( $* )\n  while true; do\n    for url in \"${urls[@]}\"; do\n      local file=\"${url##*/}\""
  },
  {
    "id" : "2da7912b-d6c5-4978-8496-680953aee589",
    "prId" : 17580,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa0e5a9e-aaf1-4698-8714-c261c48775ed",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "was this print statement just for debugging or did you intend to leave it in permanently?\n",
        "createdAt" : "2015-11-20T19:59:54Z",
        "updatedAt" : "2015-12-08T22:19:45Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "0c3a5b80-7c38-4bcf-a5c9-995db82afccb",
        "parentId" : "aa0e5a9e-aaf1-4698-8714-c261c48775ed",
        "authorId" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "body" : "This is required. I need to export these vars because I need them in `kubernetes/saltbase/install.sh`. Before the quoting changes I don't think this was working as expected either\n",
        "createdAt" : "2015-11-20T21:18:50Z",
        "updatedAt" : "2015-12-08T22:19:45Z",
        "lastEditedBy" : "392f7c7a-6820-4848-94e2-2b8e009fec9d",
        "tags" : [
        ]
      }
    ],
    "commit" : "4ace8280a0bbd50b93e7514ea662de7719e5dc8f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +83,87 @@for k,v in yaml.load(sys.stdin).iteritems():\n  print \"\"\"readonly {var}={value}\"\"\".format(var = k, value = pipes.quote(str(v)))\n  print \"\"\"export {var}\"\"\".format(var = k)\n  ' < \"\"\"${kube_env_yaml}\"\"\")\"\n}"
  },
  {
    "id" : "09284b5e-182e-4976-835b-6fdcc37a47f5",
    "prId" : 10050,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c7a5d8b-d23a-4bf3-b466-eab654ec3e13",
        "parentId" : null,
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "Will this case will also be hit when launching released versions (e.g. running `get.k8s.io | bash`)?\n",
        "createdAt" : "2015-06-18T20:12:56Z",
        "updatedAt" : "2015-06-18T20:37:16Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "73b32beb-9dbf-42fc-9f49-52902ed27ddc",
        "parentId" : "1c7a5d8b-d23a-4bf3-b466-eab654ec3e13",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "No, that's yet another path. Fix incoming.\n",
        "createdAt" : "2015-06-18T20:28:07Z",
        "updatedAt" : "2015-06-18T20:37:16Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "52e6bddd-1438-410a-aeb6-5b86ec19f7b2",
        "parentId" : "1c7a5d8b-d23a-4bf3-b466-eab654ec3e13",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "Correction: I think this pull works for that script. What it doesn't do is handle the upgrade/pull case correctly (the `common.sh` path).\n",
        "createdAt" : "2015-06-18T20:35:07Z",
        "updatedAt" : "2015-06-18T20:37:16Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "d8da39ecd0a253ddb03670c5ba7a67408318e6a9",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +447,451 @@  # optimization.\n\n  # TODO(zmerlynn): This may not be set yet by everyone (GKE).\n  if [[ -z \"${SERVER_BINARY_TAR_HASH:-}\" ]]; then\n    echo \"Downloading binary release sha1 (not found in env)\""
  },
  {
    "id" : "5da61bcf-895e-4650-8728-27f7968387a1",
    "prId" : 8232,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38f48669-3aec-4fef-90a4-b74c92649f2f",
        "parentId" : null,
        "authorId" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "body" : "For my own understanding, how long do we expect this to take/does it usually take?\n",
        "createdAt" : "2015-05-15T17:10:53Z",
        "updatedAt" : "2015-05-15T17:10:53Z",
        "lastEditedBy" : "395f4f9a-98be-4485-b436-51f0897d7c9f",
        "tags" : [
        ]
      },
      {
        "id" : "032ad464-0ac5-40c9-83d5-c15d0c047ddb",
        "parentId" : "38f48669-3aec-4fef-90a4-b74c92649f2f",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "This was instantaneous when I tested it. I'm not actually entirely sure of my theory, but it's about the only thing that would explain what happened in that bug.\n",
        "createdAt" : "2015-05-15T17:18:14Z",
        "updatedAt" : "2015-05-15T17:18:14Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "06c22c699a8cced0ad7c9f7d8eea7186a2864543",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +29,33 @@  # and it's just not worth doing a whole lot of startup work if this\n  # isn't ready yet.)\n  until getent hosts metadata.google.internal &>/dev/null; do\n    echo 'Waiting for functional DNS (trying to resolve metadata.google.internal)...'\n    sleep 3"
  },
  {
    "id" : "1a74a164-0937-4d7c-9adb-a75168fda08a",
    "prId" : 8071,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1c1baf2-32d2-4835-98c9-c02ee921d6e6",
        "parentId" : null,
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "BTW, I realized that `nounset` is, in fact, set throughout here. I think `create-salt-pillar` just doesn't trip it because each of those `$()` blocks is actually a subshell.\n",
        "createdAt" : "2015-05-14T17:22:41Z",
        "updatedAt" : "2015-05-14T18:59:26Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "6e437fce-bf55-464d-88f3-268ab0e7a1bd",
        "parentId" : "c1c1baf2-32d2-4835-98c9-c02ee921d6e6",
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "Makes sense, but that sucks that the subshell doesn't inherit the `nounset` since it would then cause the `noerr` clause to be hit here and we could discover when one of these vars isn't being set as desired. Guess we'll just have to use our eyes instead. \n",
        "createdAt" : "2015-05-14T18:53:12Z",
        "updatedAt" : "2015-05-14T18:59:26Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ab41db7ea3c7e167cbb72a307d1b9c200f8f195",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +243,247 @@dns_domain: '$(echo \"$DNS_DOMAIN\" | sed -e \"s/'/''/g\")'\nadmission_control: '$(echo \"$ADMISSION_CONTROL\" | sed -e \"s/'/''/g\")'\nEOF\n}\n"
  },
  {
    "id" : "ac88a64e-02fa-4703-bebf-d58ab9df734c",
    "prId" : 7984,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "811a0e01-24de-4792-bd38-12e368788cc7",
        "parentId" : null,
        "authorId" : "3cd3a661-80f4-45b3-bae0-5a78fbaedc59",
        "body" : "Any thoughts on this? I'm giving cbr0 a garbage range (same on all nodes) at startup. This was easier than letting docker initially start up with docker0 and then adjusting docker's init args.\n\nI think this would let docker schedule 1 pod (10.123.45.2) before cbr0 actually gets set up after kubelet runs. This will blackhole traffic from this node to that range for a brief amount of time at startup, so if some pre-kubelet step happened to need to talk to 10.123.45.{0-3}, this would break it.\n\nOnce kubelet runs in a pod, do we need it to have an actually routable IP assigned by docker, or is it just going to use the host IP?\n\nI'd love to hear suggestions on a better way to do this if anybody has ideas.\n",
        "createdAt" : "2015-05-12T17:16:59Z",
        "updatedAt" : "2015-05-13T06:00:59Z",
        "lastEditedBy" : "3cd3a661-80f4-45b3-bae0-5a78fbaedc59",
        "tags" : [
        ]
      },
      {
        "id" : "d5621f0b-09b1-420b-95be-e6eac4359b2a",
        "parentId" : "811a0e01-24de-4792-bd38-12e368788cc7",
        "authorId" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "body" : "I think both kubelet and kube-proxy are going to use host network even they are running as container. I am not concerning about kubelet and kube-proxy. But I do concern about master components. Today we are running them in a pod by using host networking, but in the future for HA master, we cannot use host networking for them. In this case, we might allocate ip for to-be-deprecated ip range here. But this doesn't break today's model, and we can iterate this latter, I think. \n",
        "createdAt" : "2015-05-12T20:27:32Z",
        "updatedAt" : "2015-05-13T06:00:59Z",
        "lastEditedBy" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "tags" : [
        ]
      },
      {
        "id" : "f671873f-45b0-446d-9ae3-20f19ce3e428",
        "parentId" : "811a0e01-24de-4792-bd38-12e368788cc7",
        "authorId" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "body" : "But this might break any file-based pod which created by kubelet before we reconfig cbr0?\n",
        "createdAt" : "2015-05-12T20:30:00Z",
        "updatedAt" : "2015-05-13T06:00:59Z",
        "lastEditedBy" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "tags" : [
        ]
      },
      {
        "id" : "360ed022-c45d-4954-94e6-f565af7874de",
        "parentId" : "811a0e01-24de-4792-bd38-12e368788cc7",
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "Here's I imagine it would work: A pod created via manifest will have a black-holed IP address until kubelet flips crb0 and then kicks docker. Docker will kill the container, and when it restarts kubelet should restart the pod, at which point it should get a routable IP from docker. \n\nDoes that sound correct?\n",
        "createdAt" : "2015-05-12T22:18:58Z",
        "updatedAt" : "2015-05-13T06:00:59Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "c36ab4e2-c49a-48ef-b821-e03e2c5e227c",
        "parentId" : "811a0e01-24de-4792-bd38-12e368788cc7",
        "authorId" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "body" : "Ahh, I forget during after crb0 configuration, we restart docker. Yes, it works here. \n",
        "createdAt" : "2015-05-12T22:28:06Z",
        "updatedAt" : "2015-05-13T06:00:59Z",
        "lastEditedBy" : "a6409368-42e0-44a9-bf79-9d3042ac3b65",
        "tags" : [
        ]
      }
    ],
    "commit" : "31ea7d12954126d5d9cb95011dec4bd7ed60fa06",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +386,390 @@  roles:\n    - kubernetes-pool\n  cbr-cidr: 10.123.45.0/30\n  cloud: gce\nEOF"
  },
  {
    "id" : "0cd6346b-a9e6-426e-849e-95434c8dc1a7",
    "prId" : 6618,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bde4439-76f4-4ff7-a8d1-385b1b5a2d96",
        "parentId" : null,
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "If I'm being pedantic, this has to handle the upgrade case. See the note on line 273/267 below.\n",
        "createdAt" : "2015-04-16T19:12:15Z",
        "updatedAt" : "2015-04-22T18:11:46Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "548bf8b5-490e-46b1-8415-48ae05c33888",
        "parentId" : "1bde4439-76f4-4ff7-a8d1-385b1b5a2d96",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "Maybe this should actually be split up into a token directory and reassembled here? (Like how .conf files are done with foo.d/\\* directories?). Just a random thought so that any future upgrades are less obnoxious.\n",
        "createdAt" : "2015-04-16T19:16:29Z",
        "updatedAt" : "2015-04-22T18:11:46Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "b36d1bc0-d34c-4c40-87e8-1ccbd6824f8b",
        "parentId" : "1bde4439-76f4-4ff7-a8d1-385b1b5a2d96",
        "authorId" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "body" : "I think your suggestions are orthogonal to this PR (seeing as how the token file already has many files with the service account tokens) but they are good points. Since we don't yet support upgrade, I'm leaning towards leaving this as a breaking change between 0.15.0 and 0.16.0. \n",
        "createdAt" : "2015-04-17T23:27:18Z",
        "updatedAt" : "2015-04-22T18:11:46Z",
        "lastEditedBy" : "c2b5c827-efcd-438f-8db5-52d917b1cde9",
        "tags" : [
        ]
      },
      {
        "id" : "2b6485de-7305-409a-96fa-6ed90edab2bd",
        "parentId" : "1bde4439-76f4-4ff7-a8d1-385b1b5a2d96",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "SGTM\n",
        "createdAt" : "2015-04-20T22:13:57Z",
        "updatedAt" : "2015-04-22T18:11:46Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc45f7f9e6b64c2388ca3f2c91e076afcad119b2",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +262,266 @@    (umask 077;\n      echo \"${KUBE_BEARER_TOKEN},admin,admin\" > \"${KNOWN_TOKENS_FILE}\";\n      echo \"${KUBELET_TOKEN},kubelet,kubelet\" >> \"${KNOWN_TOKENS_FILE}\")\n\n    mkdir -p /srv/salt-overlay/salt/kubelet"
  },
  {
    "id" : "3fb6a728-4b4f-4bce-a5ae-8a90ee056898",
    "prId" : 6427,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d09c2a7-885f-4795-8987-3fb82a2b421a",
        "parentId" : null,
        "authorId" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "body" : "I find it super helpful when functions list \"assumed vars\" and \"set vars.\" I'm definitely not asking you to re-audit the whole file, but could you maybe add a note that `create-salt-auth` should be called first to set `$KUBELET_TOKEN`?\n",
        "createdAt" : "2015-04-04T22:23:27Z",
        "updatedAt" : "2015-04-06T15:35:24Z",
        "lastEditedBy" : "e7e1d709-e9c3-47a5-91f2-ed86958679e2",
        "tags" : [
        ]
      },
      {
        "id" : "64c7256d-4dc6-481e-9060-8c4ae38468a8",
        "parentId" : "2d09c2a7-885f-4795-8987-3fb82a2b421a",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "That's actually not true. `create-salt-auth` requires KUBELET_TOKEN on first boot, but otherwise it doesn't actually generate it. I'll document the pre-rereqs.\n",
        "createdAt" : "2015-04-05T17:43:34Z",
        "updatedAt" : "2015-04-06T15:35:24Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      },
      {
        "id" : "fbe688db-d33e-4501-b218-badbf8793b5d",
        "parentId" : "2d09c2a7-885f-4795-8987-3fb82a2b421a",
        "authorId" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "body" : "Done\n",
        "createdAt" : "2015-04-05T17:46:52Z",
        "updatedAt" : "2015-04-06T15:35:24Z",
        "lastEditedBy" : "a92f8f9e-31fd-4510-b4d9-3553f7025485",
        "tags" : [
        ]
      }
    ],
    "commit" : "616c6be65378347e6225947acef203dc8ea9a498",
    "line" : null,
    "diffHunk" : "@@ -1,1 +251,255 @@# files exist on the master-pd and should never be touched again\n# (except perhaps an additional service account, see NB below.)\nfunction create-salt-auth() {\n  local -r htpasswd_file=\"/srv/salt-overlay/salt/nginx/htpasswd\"\n"
  }
]