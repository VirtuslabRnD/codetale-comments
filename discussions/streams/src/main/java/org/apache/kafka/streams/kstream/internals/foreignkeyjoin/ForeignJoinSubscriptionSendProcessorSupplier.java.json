[
  {
    "id" : "61eb2ef6-efd0-4ae1-9b5b-5c4945c0cede",
    "prId" : 5527,
    "prUrl" : "https://github.com/apache/kafka/pull/5527#pullrequestreview-281568005",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1255144c-447c-4ee1-aae7-78513e3440d3",
        "parentId" : null,
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Should this be sent only when the old and new key do not match?",
        "createdAt" : "2019-08-28T22:07:33Z",
        "updatedAt" : "2019-10-02T17:56:32Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "f5d90eaf-f439-4867-b653-d0dd65e6bea0",
        "parentId" : "1255144c-447c-4ee1-aae7-78513e3440d3",
        "authorId" : "d8d11f3d-4fbd-4882-a206-bfece798cdcd",
        "body" : "I believe we chose this because with a regular join we propagate the same output value for each event sent in. If there are N events with the same old and new state, we output N joined events, even if they are the same.\r\n\r\nIf we do not send when oldKey == newKey, then we swallow + hide the event.",
        "createdAt" : "2019-08-29T15:33:33Z",
        "updatedAt" : "2019-10-02T17:56:32Z",
        "lastEditedBy" : "d8d11f3d-4fbd-4882-a206-bfece798cdcd",
        "tags" : [
        ]
      },
      {
        "id" : "4047cf25-3023-494c-8bd6-a22facbfa294",
        "parentId" : "1255144c-447c-4ee1-aae7-78513e3440d3",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "üëçMakes sense.\r\n\r\nMy understanding is that sending an output even for each input is best effort, e.g. the output event is not emitted if the hash changes more quickly than the updates get through the RHS.",
        "createdAt" : "2019-08-29T16:08:32Z",
        "updatedAt" : "2019-10-02T17:56:32Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e1b6a1a41c8e05ff009ad988b705baeb42800ad",
    "line" : 95,
    "diffHunk" : "@@ -1,1 +93,97 @@                        //and LEFT join.\n                    }\n                    context().forward(newForeignKey, new SubscriptionWrapper<>(currentHash, PROPAGATE_NULL_IF_NO_FK_VAL_AVAILABLE, key));\n                } else {\n                    //A simple propagatable delete. Delete from the state store and propagate the delete onwards."
  },
  {
    "id" : "0dccf4b1-8c38-4ee1-9f52-63392a22f6ed",
    "prId" : 8061,
    "prUrl" : "https://github.com/apache/kafka/pull/8061#pullrequestreview-355390291",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70c4c730-03f7-4862-bd3e-d09036eb6730",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "In addition to the other issues I've pointed out, we also have a few places where we didn't account for nullability in the processors themselves.",
        "createdAt" : "2020-02-07T19:42:24Z",
        "updatedAt" : "2020-02-09T21:28:58Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cc13e38696e382a69943a86d77dcdb5826d1ce8",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +80,84 @@            if (valueSerializer == null) {\n                valueSerializer = (Serializer<V>) context.valueSerde().serializer();\n            }\n            droppedRecordsSensor = TaskMetrics.droppedRecordsSensorOrSkippedRecordsSensor(\n                Thread.currentThread().getName(),"
  }
]