[
  {
    "id" : "bed36c42-c8fc-4c2b-bd0e-ffbc5b495eb6",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-286979175",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2137b81-07de-4e3e-a4ba-03388919f344",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We can infer which rebalance protocol is used by reading on the `UPGRADE_FROM` config at the caller (i.e. at the StreamThread). See my other comments.",
        "createdAt" : "2019-09-11T18:48:10Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +36,40 @@    private final Logger log;\n\n    StreamsRebalanceListener(final Time time,\n        final TaskManager taskManager,\n        final StreamThread streamThread,"
  },
  {
    "id" : "af74be39-0e14-4530-8d66-76ea72c9a77a",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-288292448",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60c8094a-68e8-4328-88b8-8d239a1ebadc",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We cannot rely on the rebalance protocol from `setRebalanceProtocol` in task manager to determine the logic, since during a rebalance, one can send with two supported protocol but the `EAGER` protocol is still used --- only the leader knows which protocol is used when doing the assignment.\r\n\r\nAt the moment it is almost impossible to let the listener know which protocol was exactly used (not what protocol was supported); but on the other hand I feel may be it is not necessary as well: If the COOPERATIVE protocol is used, then we are effectively suspend tasks in onPartitionRevoked, and then immediately close those suspended tasks in onPartitionsAssigned since they are called consecutively in `onJoinComplete`, and no one would ever be resumed at all (i.e. that `resumeSuspended` call would always be no-op with no passed in task parameters).\r\n\r\nSo I'd suggest we make the listener to also be agnostic to the rebalance protocol, and just follow the current logic of suspending resuming, and we can even see if we could in later releases remove the whole suspending/resuming all together regardless of the protocols.",
        "createdAt" : "2019-09-11T20:27:02Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "9fa1184a-2cc2-43b9-bb73-9d7895e4377c",
        "parentId" : "60c8094a-68e8-4328-88b8-8d239a1ebadc",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Resolving this, refactored to make the listener and taskManager protocol agnostic",
        "createdAt" : "2019-09-13T23:48:58Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +47,51 @@\n    @Override\n    public void onPartitionsAssigned(final Collection<TopicPartition> assignedPartitions) {\n        log.debug(\"Current state {}: assigned partitions {} at the end of consumer rebalance.\\n\" +\n                \"\\tpreviously assigned active tasks: {}\\n\" +"
  },
  {
    "id" : "0833205a-055e-46b6-981d-bd54a28baf1c",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-292075683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "68980ead-80cc-4ddd-9e36-dbb85d5b99f2",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Are there unit tests for the `StreamsRebalanceListener`? If yes, it would make sense to extract them to its own class `StreamsRebalanceListenerTest`.",
        "createdAt" : "2019-09-12T10:24:27Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "26acc53b-cbdd-485c-a2c6-fc0d516303e3",
        "parentId" : "68980ead-80cc-4ddd-9e36-dbb85d5b99f2",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "It doesn't really make sense to test the rebalance listener on its own, ie outside the context of a StreamThread and TaskManager, so it's pretty much covered in TaskManagerTest and StreamThreadTest (plus some system tests, ie for version probing)",
        "createdAt" : "2019-09-16T21:08:13Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e9349802-046a-437d-83ee-845dba2ecd4c",
        "parentId" : "68980ead-80cc-4ddd-9e36-dbb85d5b99f2",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I cannot see how a unit test for the rebalance listener does not make sense. I would rather unit test the listener in isolation and then mock it in the other unit tests.",
        "createdAt" : "2019-09-19T17:52:22Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "828c5005-8788-46c9-93be-6e3dd7db1e71",
        "parentId" : "68980ead-80cc-4ddd-9e36-dbb85d5b99f2",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "There may be further changes to the rebalance listener once we turn on cooperative, if it is alright I'll add the tests in the follow-up PR",
        "createdAt" : "2019-09-23T21:53:52Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +29,33 @@import org.slf4j.Logger;\n\npublic class StreamsRebalanceListener implements ConsumerRebalanceListener {\n\n    private final Time time;"
  },
  {
    "id" : "ddc1b738-52fd-42b8-a719-0c4d45c2b208",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-288988060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "51043e0d-21bc-47ef-99c7-ca426ce064f7",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "See my other comment: I feel it's cleaner to execute `closeSuspendedActiveTasks` that and `closeStandbyTasks` differently.",
        "createdAt" : "2019-09-13T22:03:43Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "aab2721c-0f7f-43fb-814a-4effeee7ab39",
        "parentId" : "51043e0d-21bc-47ef-99c7-ca426ce064f7",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Done",
        "createdAt" : "2019-09-17T02:17:44Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +81,85 @@                revokedStandbyPartitions = taskManager.closeRevokedStandbyTasks();\n                taskManager.closeRevokedSuspendedTasks();\n                taskManager.createTasks(assignedPartitions);\n            }\n        } catch (final Throwable t) {"
  },
  {
    "id" : "94b81df7-d6cc-4d6b-a9c9-2e9228c3d363",
    "prId" : 8190,
    "prUrl" : "https://github.com/apache/kafka/pull/8190#pullrequestreview-366112254",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95470cef-6a47-47fd-832d-0b8638651508",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We need to put this out of the loop since if we get an error code, we should still set the flag so that thread can complete shutdown.",
        "createdAt" : "2020-02-28T01:33:19Z",
        "updatedAt" : "2020-02-28T01:34:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "84791c9a2da624b9d0c9dcffef2d0a4eb5e6d560",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +54,58 @@        }\n\n        taskManager.handleRebalanceComplete();\n    }\n"
  },
  {
    "id" : "e5086812-fc8e-4c94-b25b-4edd7c5d0091",
    "prId" : 9446,
    "prUrl" : "https://github.com/apache/kafka/pull/9446#pullrequestreview-510671508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc7bfda2-50c5-42e4-a9f9-bfc10146db3f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Hey @ableegoldman , I just looked into this, and it appears that this is the only place that the error code would be read and thrown as an exception to kill the thread, right?\r\n\r\nIf so, then it looks like older clients are looking specifically for the error code to be `== AssignorError.INCOMPLETE_SOURCE_TOPIC_METADATA.code()`, and they'd interpret any other code as \"looks good\" and proceed with PARTITIONS_ASSIGNED.\r\n\r\nMaybe there's nothing we can do about it now, but perhaps we should put in a block to future-proof this code by adding an `else if (assignmentErrorCode.get() != 0) { throw new TaskAssignmentException(\"Unknown error code: \"+assignmentErrorCode.get()) }` ?\r\n\r\nOr is this already handled in some other way I'm not seeing?",
        "createdAt" : "2020-10-16T15:53:40Z",
        "updatedAt" : "2020-10-21T02:21:26Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "c3623561-b887-45d6-95c2-842061775f1a",
        "parentId" : "fc7bfda2-50c5-42e4-a9f9-bfc10146db3f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "+1 on future proofing this",
        "createdAt" : "2020-10-16T17:26:48Z",
        "updatedAt" : "2020-10-21T02:21:26Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "354ba3d3-e614-43bc-8bbb-dd166e46766b",
        "parentId" : "fc7bfda2-50c5-42e4-a9f9-bfc10146db3f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Ooh, but we did use to have a VERSION_PROBING error code that had value `2`. So we should skip that and go right to `3`, thanks for reminding me",
        "createdAt" : "2020-10-16T17:33:05Z",
        "updatedAt" : "2020-10-21T02:21:26Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "69b543cad9c4142675f44e6e01c7e562be34ebda",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +64,68 @@            log.error(\"Received unknown error code {}\", assignmentErrorCode.get());\n            throw new TaskAssignmentException(\"Hit an unrecognized exception during rebalance\");\n        }\n\n        streamThread.setState(State.PARTITIONS_ASSIGNED);"
  },
  {
    "id" : "8dffeec3-eebd-44cc-875d-d1e0c08f429c",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-524679504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e953d30d-4fbc-482a-ad61-a14fa719fe0f",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Unit tests for this case are missing.",
        "createdAt" : "2020-11-05T13:20:37Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "1042374b-6ade-41ff-9938-767087d29747",
        "parentId" : "e953d30d-4fbc-482a-ad61-a14fa719fe0f",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "added unit test",
        "createdAt" : "2020-11-05T21:17:19Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +63,67 @@            taskManager.handleRebalanceComplete();\n            throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n            log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown the application\");\n            taskManager.handleRebalanceComplete();"
  },
  {
    "id" : "2a925aea-8b8a-45d5-83d8-a375c80a6fc4",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-530218086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60433c0f-1f20-45e8-9fad-6d67232bece6",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "It probably doesn't matter too much since `handleRebalanceComplete` doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.",
        "createdAt" : "2020-11-06T02:20:24Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "c5982c2b-c134-45cb-8e65-926d1c1af3ad",
        "parentId" : "60433c0f-1f20-45e8-9fad-6d67232bece6",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We can do that, it doesn't seem make difference which order it is called. However if it is not called it will get stuck continually rebalancing. We return because setting the state to partitions assigned will cause an error",
        "createdAt" : "2020-11-06T15:51:21Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "85976179-6282-41a4-b3b8-aaf6d7f4976b",
        "parentId" : "60433c0f-1f20-45e8-9fad-6d67232bece6",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "For the same reason I had to add to the other cases as the close from the new handler will not finish otherwise",
        "createdAt" : "2020-11-13T23:49:17Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +65,69 @@        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n            log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown the application\");\n            taskManager.handleRebalanceComplete();\n            streamThread.shutdownToError();\n            return;"
  },
  {
    "id" : "a1a22068-e288-42ee-812d-122e18cbfbfc",
    "prId" : 10311,
    "prUrl" : "https://github.com/apache/kafka/pull/10311#pullrequestreview-611245967",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93edbbc6-f310-4479-80f8-6339ffd1b0c8",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "do we need to be concerned about the oder these execute?",
        "createdAt" : "2021-03-13T00:05:01Z",
        "updatedAt" : "2021-03-13T00:14:41Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "f36e8e8b-95f5-463d-9d68-ababf4486de7",
        "parentId" : "93edbbc6-f310-4479-80f8-6339ffd1b0c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I think this is the correct order (assuming you mean the order of `streamThread.setState(State.PARTITIONS_REVOKED) != null` relative to `streamThread.state() == State.PENDING_SHUTDOWN`?) -- if the thread is not in PENDING_SHUTDOWN when it reaches this line, the first condition should return true, which is what we want even if it does get transitioned to PENDING_SHUTDOWN immediately after the transition to PARTITIONS_REVOKED.",
        "createdAt" : "2021-03-13T00:18:03Z",
        "updatedAt" : "2021-03-13T00:18:03Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "513ef98893a8c8e8216e410a53ec694d2ad9a2f1",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +90,94 @@        // We need to still invoke handleRevocation if the thread has been told to shut down, but we shouldn't ever\n        // transition away from PENDING_SHUTDOWN once it's been initiated (to anything other than DEAD)\n        if ((streamThread.setState(State.PARTITIONS_REVOKED) != null || streamThread.state() == State.PENDING_SHUTDOWN) && !partitions.isEmpty()) {\n            final long start = time.milliseconds();\n            try {"
  }
]