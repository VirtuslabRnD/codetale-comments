[
  {
    "id" : "973f242c-f1d8-45d1-b8d0-bee5ceff8623",
    "prId" : 4998,
    "prUrl" : "https://github.com/apache/kafka/pull/4998#pullrequestreview-119274280",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4f9d465-bc74-41c0-88f9-b7bdd574afb1",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Update the above TODO with only admin client left.",
        "createdAt" : "2018-05-10T22:55:59Z",
        "updatedAt" : "2018-05-15T16:31:43Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c857b9a7f14178e17b0a647af540b7af3bed2cf",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +388,392 @@        final Map<MetricName, Metric> result = new LinkedHashMap<>();\n        for (final StreamThread thread : threads) {\n            result.putAll(thread.producerMetrics());\n            result.putAll(thread.consumerMetrics());\n        }"
  },
  {
    "id" : "39f846d4-b8e9-447a-9f0b-40b15b894678",
    "prId" : 5682,
    "prUrl" : "https://github.com/apache/kafka/pull/5682#pullrequestreview-161804660",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang @bbejeck @vvcephei Should we change this to \"zero or negative\" ? Comparing the implementation, passing in a negative timestamp will \"expire\" the timeout even without checking the state transition at all and return immediately (with `false`) even if the state transition was successful.",
        "createdAt" : "2018-09-30T21:04:48Z",
        "updatedAt" : "2018-10-04T14:34:18Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "92810b3b-f3ad-4b4d-86fe-17c58b71a260",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I'm fine with those semantics, maybe we can make a Jira.\r\n\r\nThinking about it more, though, wouldn't it make more sense to:\r\n* reject negative numbers\r\n* make 0 just signal and return immediately (after checking the state once)\r\n* if I want to wait \"forever\", I can use `ofYears(1)` or `ofMillis(Long.MAX_VALUE)` or some other intuitively \"long enough to be forever\" value instead of a magic value.\r\n\r\nRegardless, I agree the current behavior is a little weird, and I'd be in favor of a Jira/KIP to revise it.",
        "createdAt" : "2018-10-01T14:34:28Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a3542d14-99af-441d-a421-f7ef9d5e353c",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Overall I'm ok with the semantics.\r\n \r\nBut my first instinct of a timeout of `0` implies shutdown immediately with no wait and blocking forever takes a value of `Long.MAX_VALUE`.\r\n\r\nIn short, I'm +1 as well on revising the behavior. ",
        "createdAt" : "2018-10-01T21:13:46Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "1e17e274-693c-44fd-a1ac-1a6c21dbc050",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Created: https://issues.apache.org/jira/browse/KAFKA-7477",
        "createdAt" : "2018-10-03T20:17:52Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0b290fa4-a871-4627-bea8-15eb72f3ac42",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think, we should fix this in 2.1 -- I am suggestion this, because we could use the new semantics for `close(Duration)` only and stay with old semantics for `close(long, TimeUnit)` -- if we don't so this, it would be an backward incompatible change and thus we could only do it in `3.0.0.`.",
        "createdAt" : "2018-10-03T22:21:12Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ec5da148-c2a0-44ff-ab14-f8ec70ebc79b",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@nizhikov Are you willing for address 7477 in this PR? If not, it's also fine and we do a follow up PR. However, it should be part of the KIP description. Could you update the KIP accordingly?",
        "createdAt" : "2018-10-03T22:56:34Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "50e8fcfa-d762-4039-a9ab-c8507d421a18",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "@mjsax I'll take care of KAFKA-7477 in follow up PR.\r\n\r\n[KIP-358](https://cwiki.apache.org/confluence/display/KAFKA/KIP-358%3A+Migrate+Streams+API+to+Duration+instead+of+long+ms+times) updated. Please, see, \"Proposed Changes\" section.",
        "createdAt" : "2018-10-04T09:59:13Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      },
      {
        "id" : "be0561a0-b6e6-4fc0-8f58-b0e62a025738",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Did you start working on KAFKA-7477 already @nizhikov ?",
        "createdAt" : "2018-10-04T16:43:20Z",
        "updatedAt" : "2018-10-04T16:43:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "94812d04-dd5a-46ff-a1ed-b5ed5ea3ac2b",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "As far as I can understand thus fix is trivial.\r\nI'm planning to provide PR in a 24 hour after this PR finish. Is it OK?",
        "createdAt" : "2018-10-04T18:49:40Z",
        "updatedAt" : "2018-10-04T18:49:40Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      },
      {
        "id" : "32d9f463-8a83-45c9-b0ca-50729bcc4d85",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Wouldn't call it trivial, but sure, this sound good! Thanks a lot. Just want to make sure we get it on time to not miss code freeze deadline. Thanks a lot!",
        "createdAt" : "2018-10-04T20:50:39Z",
        "updatedAt" : "2018-10-04T20:50:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5210f9fff117c695cb1f3024c94eff7f49599a6a",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +903,907 @@     * Shutdown this {@code KafkaStreams} by signaling all the threads to stop, and then wait up to the timeout for the\n     * threads to join.\n     * A {@code timeout} of 0 means to wait forever.\n     *\n     * @param timeout  how long to wait for the threads to shutdown"
  },
  {
    "id" : "6925f1d7-d3cf-492c-b1ec-485f6af6670c",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-171455665",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add a new test to `KafkaStreamsTest` to check that no directory is created for this case",
        "createdAt" : "2018-11-04T03:11:28Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "727e1382-96ab-42a4-a6d2-e5cec7625d20",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "For the above case, `TopologyDiskAccessTest` class is added.  `KafkaStreamsTest` tests only the KafkaStreams logic (It doesn't create any topology which is required for the above case). ",
        "createdAt" : "2018-11-04T09:39:17Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      },
      {
        "id" : "a25b8e84-589f-45c9-b1c0-882be39d9cb8",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "> KafkaStreamsTest tests only the KafkaStreams logic\r\n\r\nWell, because `KafkaStreams` is responsible to create/or-not-crate the directory, this is part of `KafkaStreams` logic, isn't it? Thus, IMHO we should test this behavior in `KafkaStreamsTest`. Nothing prevents you create any topology in the test for this.\r\n\r\nAlso, `TopologyDisAccessTest` does not use `KafkaStreams` but `TopologyTestDriver` and thus, does not cover this code path.",
        "createdAt" : "2018-11-04T17:33:33Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "710a3047-0d47-43ea-a668-7b171c2b4292",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "Agree, moved the test cases to `KafkaStreamsTest`.",
        "createdAt" : "2018-11-05T08:50:29Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +675,679 @@        final ProcessorTopology globalTaskTopology = internalTopologyBuilder.buildGlobalStateTopology();\n        final long cacheSizePerThread = totalCacheSize / (threads.length + (globalTaskTopology == null ? 0 : 1));\n        final boolean createStateDirectory = taskTopology.hasPersistentLocalStore() ||\n                (globalTaskTopology != null && globalTaskTopology.hasPersistentGlobalStore());\n"
  },
  {
    "id" : "ff999106-4702-482d-9d9e-865509cb6048",
    "prId" : 5747,
    "prUrl" : "https://github.com/apache/kafka/pull/5747#pullrequestreview-162648793",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We cannot change the semantics of exiting `close(long, TimeUnit)` -- this would be a backward incompatible change. We can only change the semantics for the new `close(Duration)` method.\r\n\r\nWe also should point out the different semantics in L830:\r\n```\r\n@deprecated Use {@link #close(Duration)} instead; note, that {@link #close(Duration)} has different semantics and does not block on zero, e.g., `Duration.ofMillis(0)`.",
        "createdAt" : "2018-10-05T17:43:46Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a25aa812-456a-4bf7-8df8-ae6cc0bb6f46",
        "parentId" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Seems this comment was not addressed yet.",
        "createdAt" : "2018-10-08T21:22:51Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "bc039738-a625-434d-bb03-24a3d2e12bd4",
        "parentId" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "Fixed.",
        "createdAt" : "2018-10-08T21:38:57Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      }
    ],
    "commit" : "d055d3e380704470a874bc477902c3a649298717",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +819,823 @@     * A {@code timeout} of 0 means to wait forever.\n     *\n     * @param timeout  how long to wait for the threads to shutdown. Can't be negative. If {@code timeout=0} just checking the state and return immediately.\n     * @param timeUnit unit of time used for timeout\n     * @return {@code true} if all threads were successfully stopped&mdash;{@code false} if the timeout was reached"
  },
  {
    "id" : "fd1beb28-1761-41fb-ae2f-7aef82650f87",
    "prId" : 5954,
    "prUrl" : "https://github.com/apache/kafka/pull/5954#pullrequestreview-179629376",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@ijuma Removed the `SuppressWarning` annotation and rewrote the code. Also have a PR for 2.1 branch: https://github.com/apache/kafka/pull/5963 for this fix.",
        "createdAt" : "2018-11-28T21:09:28Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "04044a72-350f-4a0a-a731-4aac7c11ba6f",
        "parentId" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We translate old default of zero to Long.MAX_VALUE within deprecated `close(final long timeout, final TimeUnit timeUnit)` -- we can call `private close()` directly instead.",
        "createdAt" : "2018-11-28T21:12:29Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8a5b63df-586a-4585-82e4-2b2afc40f6f6",
        "parentId" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Thanks, this looks better.",
        "createdAt" : "2018-11-29T05:01:39Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9c692fa9804850c0cdd372d825db005bf3851f8",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +808,812 @@     */\n    public void close() {\n        close(Long.MAX_VALUE);\n    }\n"
  },
  {
    "id" : "978f0d8a-e9b5-4d0d-a782-1239d7a8c4d9",
    "prId" : 5963,
    "prUrl" : "https://github.com/apache/kafka/pull/5963#pullrequestreview-179518887",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5dce7be0-b76c-481b-9820-7f3ffd012c20",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We translate old default of zero to Long.MAX_VALUE within deprecated `close(final long timeout, final TimeUnit timeUnit)` -- we can call `private close()` directly instead.",
        "createdAt" : "2018-11-28T21:11:57Z",
        "updatedAt" : "2018-11-28T21:11:57Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "65462041543d7f9f12ffa5fab6c0bcc45403e83d",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +811,815 @@     */\n    public void close() {\n        close(Long.MAX_VALUE);\n    }\n"
  },
  {
    "id" : "3213f5d7-b9f5-42ec-86eb-ddf58739cef1",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-184656205",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f18710d-807b-4baa-8129-80ee7dc3843f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for 1).",
        "createdAt" : "2018-12-09T23:22:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "1f09a998-9753-4c8a-b92a-4d6fa3a1772d",
        "parentId" : "5f18710d-807b-4baa-8129-80ee7dc3843f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't get why we need this? `onChange()` is `synchronized`, so how can a race condition happen?",
        "createdAt" : "2018-12-13T14:08:22Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 175,
    "diffHunk" : "@@ -1,1 +395,399 @@        private GlobalStreamThread.State globalThreadState;\n        // this lock should always be held before the state lock\n        private final Object threadStatesLock;\n\n        StreamStateListener(final Map<Long, StreamThread.State> threadState,"
  },
  {
    "id" : "3882b8bc-8648-4081-a40c-e511db48f44e",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-185286174",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for 1) as well: we allow REBALANCE -> REBALANCE and RUNNING -> RUNNING because of the deferred check.",
        "createdAt" : "2018-12-09T23:24:08Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4a91920c-3466-4260-9c29-2fbeca41a6f6",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just looking at this, it seems we need to assign `oldState = state` after we go the lock?",
        "createdAt" : "2018-12-13T13:55:37Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "296baa8c-a29c-47ab-8c02-51155629d3ff",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Also below, when calling `stateListener.onChange(state, oldState);` -- would we need to call `stateListener.onChange(newState, oldState);` instead? Otherwise, `state` could change before we do the callback because the lock is released already.\r\n\r\n",
        "createdAt" : "2018-12-13T13:56:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fcf7a0f8-d100-48d4-a2bb-7473616e50fe",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I cannot follow here. Why would this happen? Similar for RUNNING?",
        "createdAt" : "2018-12-13T14:05:41Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d0f9d087-e20d-4cd1-8c73-cb127f9ee51a",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Re first two comments: good call, lgtm.\r\n\r\nRe last comment: REBALANCING -> REBALANCING is quite normal, note that before this PR we check this before calling `setState(State.REBALANCING);` so this is prevented, but part of this fix is to move the logic that needs to access the state into a single place (here). Similarly RUNNING -> RUNNING is possible during starting up phase, where we first set the instance state to RUNNING directly to avoid it transit from CREATED -> REBALANCING, and then when threads are starting, it is possible that `maybeSetRunning` went through and hence calls `setState(RUNNING)` again.",
        "createdAt" : "2018-12-14T21:09:58Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +252,256 @@                // will be refused but we do not throw exception here, to allow idempotent close calls\n                return false;\n            } else if (state == State.REBALANCING && newState == State.REBALANCING) {\n                // when the state is already in REBALANCING, it should not transit to REBALANCING\n                return false;"
  },
  {
    "id" : "3af27371-8d50-4ae3-a3c3-287c33ec2540",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-183000687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81eed83d-de45-4312-9d03-20ec2d2e082f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This one-liner is for 2).",
        "createdAt" : "2018-12-09T23:24:36Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 210,
    "diffHunk" : "@@ -1,1 +426,430 @@            // state can be transferred to RUNNING if all threads are either RUNNING or DEAD\n            for (final StreamThread.State state : threadState.values()) {\n                if (state != StreamThread.State.RUNNING && state != StreamThread.State.DEAD) {\n                    return;\n                }"
  },
  {
    "id" : "7cb0566d-4b87-47e8-b5de-e66e67ad3c4d",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-185282740",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a590d369-4518-43b2-9cff-536e6386f5c6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Does it make sense to set the instance to RUNNING if all threads are DEAD ?",
        "createdAt" : "2018-12-13T13:21:11Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "38c58a07-ff20-4981-ba68-ed0a28195c79",
        "parentId" : "a590d369-4518-43b2-9cff-536e6386f5c6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note this is triggered only when a thread transited to RUNNING.\r\n\r\nWhen all threads are DEAD, by the time the last thread transited to DEAD the `maybeSetError` will proceed and the state will transit to ERROR.",
        "createdAt" : "2018-12-14T20:58:37Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 207,
    "diffHunk" : "@@ -1,1 +424,428 @@         */\n        private void maybeSetRunning() {\n            // state can be transferred to RUNNING if all threads are either RUNNING or DEAD\n            for (final StreamThread.State state : threadState.values()) {\n                if (state != StreamThread.State.RUNNING && state != StreamThread.State.DEAD) {"
  },
  {
    "id" : "46f0327d-6f21-4dc0-bd6e-0c8e17167446",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189542384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e75185e-ecad-4265-82ae-45d344ed785c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "With the state transitions changes for `StreamThread` is this still possible?",
        "createdAt" : "2018-12-19T09:40:03Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3f9d1d61-a0a6-4ba3-b9e3-94121d792fa0",
        "parentId" : "4e75185e-ecad-4265-82ae-45d344ed785c",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good point, I can remove it here.",
        "createdAt" : "2019-01-04T21:53:34Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +256,260 @@                return false;\n//            } else if (state == State.RUNNING && newState == State.RUNNING) {\n                // when the state is already in RUNNING, it should not transit to RUNNING\n                // this can happen during starting up\n//                return false;"
  },
  {
    "id" : "ebcbb2c3-5331-44b5-bc24-e2143bf92711",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189509479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81951a80-c33d-45bd-b259-c41be193ed3d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need `threadStateLock`? Can't we use `this`?",
        "createdAt" : "2018-12-19T09:43:40Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f9445e7e-ea74-42db-850e-926fadfde2e1",
        "parentId" : "81951a80-c33d-45bd-b259-c41be193ed3d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We can; but since we have a `stateLock` already I want to distinguish it with another dedicated object.",
        "createdAt" : "2019-01-04T20:03:25Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 242,
    "diffHunk" : "@@ -1,1 +445,449 @@                                          final ThreadStateTransitionValidator abstractNewState,\n                                          final ThreadStateTransitionValidator abstractOldState) {\n            synchronized (threadStatesLock) {\n                // StreamThreads first\n                if (thread instanceof StreamThread) {"
  },
  {
    "id" : "5f3155d9-4fd0-4db7-8d50-3bfc38a3a225",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189510538",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c68db677-5dd7-43bb-917e-efd9028596f0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If we want to encapsulate state handling at instance/thread level, maybe rewrite this to:\r\n```\r\nif (newState == GlobalStreamThread.State.DEAD) {\r\n    setState(State.ERROR);\r\n    log.error(\"Global thread has died. The instance will be in error state and should be closed.\");\r\n}\r\n```\r\n\r\nGlobalStreamThread would call this method only once anyway, and `setState()` should handle idempotent `setState(State.ERROR)` internally?",
        "createdAt" : "2018-12-19T09:51:04Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b4d7031f-57dd-4e7e-a60d-8193b96c96ea",
        "parentId" : "c68db677-5dd7-43bb-917e-efd9028596f0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I can do that, but I need to let `State.ERROR` transit to `State.ERROR` (currently it is not allowed, and hence will cause illegal state exception). Will do that.",
        "createdAt" : "2019-01-04T20:06:58Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 263,
    "diffHunk" : "@@ -1,1 +466,470 @@                    if (newState == GlobalStreamThread.State.DEAD) {\n                        setState(State.ERROR);\n                        log.error(\"Global thread has died. The instance will be in error state and should be closed.\");\n                    }\n                }"
  },
  {
    "id" : "1cd4e424-e639-4c62-ab64-25fd5c13710f",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189512662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9365ee7-fbe7-4def-9293-29b7c697a9be",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure if this holds. Don't we need to block state transitions while we cleanup is running?",
        "createdAt" : "2018-12-19T09:54:14Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2288ce29-5f71-434b-90af-7839cc75fd32",
        "parentId" : "e9365ee7-fbe7-4def-9293-29b7c697a9be",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`stateDirectory.cleanRemovedTasks(cleanupDelay);` itself have synchronization barriers as well, so we do not need to have the whole function in `synchronized(stateLock)`; and in that case, just locking `stateLock` for reading its value does not bring any additional guarantees.",
        "createdAt" : "2019-01-04T20:14:10Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 286,
    "diffHunk" : "@@ -1,1 +791,795 @@            final Long cleanupDelay = config.getLong(StreamsConfig.STATE_CLEANUP_DELAY_MS_CONFIG);\n            stateDirCleaner.scheduleAtFixedRate(() -> {\n                // we do not use lock here since we only read on the value and act on it\n                if (state == State.RUNNING) {\n                    stateDirectory.cleanRemovedTasks(cleanupDelay);"
  },
  {
    "id" : "8e6a0b59-271a-4b46-8bbf-03437c1e7d4e",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189514003",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "688c09f2-dfbb-4dcc-9487-e03cc74ab8b8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we want to disallow calling `start()` twice? Could be idempotent no-op, too.",
        "createdAt" : "2018-12-19T09:55:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3826ab16-f13b-4a52-8db5-5e32154fb561",
        "parentId" : "688c09f2-dfbb-4dcc-9487-e03cc74ab8b8",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good question.. this was added at the very beginning when we try to fix a few state transition bugs, and one of them as calling start() twice which may re-create threads etc. Arguably we can still allow calling it twice while making second / future calls no-op.\r\n\r\nI'd suggest we leave it as a separate improvement.",
        "createdAt" : "2019-01-04T20:18:22Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 298,
    "diffHunk" : "@@ -1,1 +797,801 @@            }, cleanupDelay, cleanupDelay, TimeUnit.MILLISECONDS);\n        } else {\n            throw new IllegalStateException(\"The client is either already started or already stopped, cannot re-start\");\n        }\n    }"
  },
  {
    "id" : "fa3ee244-7af9-4c1a-b9c0-4ea6ff0e6f1d",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-198331265",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f9b44ac-99e3-489a-93d3-28ebf107af9d",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "why not go ahead and do this now?",
        "createdAt" : "2019-01-30T22:04:59Z",
        "updatedAt" : "2019-01-30T22:04:59Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +381,385 @@            // admin client is shared, so we can actually move it\n            // to result.putAll(adminClient.metrics()).\n            // we did it intentionally just for flexibility.\n            result.putAll(thread.adminClientMetrics());\n        }"
  },
  {
    "id" : "0830f5d5-da3f-4fe1-8170-fe221f75f7cc",
    "prId" : 6461,
    "prUrl" : "https://github.com/apache/kafka/pull/6461#pullrequestreview-215916722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05efc1ce-4b69-4048-97bb-f21cead50783",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: empty line after 657 here.",
        "createdAt" : "2019-03-19T00:40:51Z",
        "updatedAt" : "2019-04-20T01:33:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "355ddd92a45fc8c65cdb5893cee7dd161075d843",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +655,659 @@            }\n        }\n    }\n\n    private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,"
  },
  {
    "id" : "a4263d1c-80fb-4a1d-b626-835b9507125a",
    "prId" : 6468,
    "prUrl" : "https://github.com/apache/kafka/pull/6468#pullrequestreview-215893734",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c204ba4-54e1-4e57-b196-942088ecee5f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a minor cleanup piggy-backed in this PR: since in `setState` we already exclude `ERROR` to transit to itself so that the user's registered listener is triggered multiple times necessarily, we can actually exclude this transition all together in the diagram.",
        "createdAt" : "2019-03-18T23:01:52Z",
        "updatedAt" : "2019-03-19T04:30:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7449162b09d8bca28d3cef40e03421a7c33d43c6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +192,196 @@     */\n    public enum State {\n        CREATED(1, 3), REBALANCING(2, 3, 5), RUNNING(1, 3, 5), PENDING_SHUTDOWN(4), NOT_RUNNING, ERROR(3);\n\n        private final Set<Integer> validTransitions = new HashSet<>();"
  },
  {
    "id" : "e755c4d3-421f-43e6-b0fe-2c02e160f6de",
    "prId" : 6884,
    "prUrl" : "https://github.com/apache/kafka/pull/6884#pullrequestreview-270272845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d7dca36f-adba-490a-8b1d-399a5745ad2e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The FSM change on this and StreamThread is a quick fix due to onPartitionsRevoked not being triggered as always now. When we made the change on StreamsPartitionAssignor in a follow-up PR we should refactor this FSM further. cc @ableegoldman ",
        "createdAt" : "2019-08-02T16:19:14Z",
        "updatedAt" : "2019-08-08T21:28:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6041a792f58b0b9a38983a60e052e9018319a6e6",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +195,199 @@    //       state diagram more thoroughly after we refactor StreamsPartitionAssignor to support COOPERATIVE\n    public enum State {\n        CREATED(1, 2, 3), REBALANCING(2, 3, 5), RUNNING(1, 2, 3, 5), PENDING_SHUTDOWN(4), NOT_RUNNING, ERROR(3);\n\n        private final Set<Integer> validTransitions = new HashSet<>();"
  },
  {
    "id" : "b896f773-7a6f-46a7-84b9-7450ca6bfd1b",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-292070339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b139456-6836-4166-be2b-0947d0bfaa52",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "It's not necessary to add the transition CREATED -> RUNNING because we always go through REBALANCING first in `KafkaStreams#start`",
        "createdAt" : "2019-09-23T21:41:13Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +191,195 @@     */\n    public enum State {\n        CREATED(1, 3),          // 0\n        REBALANCING(2, 3, 5),   // 1\n        RUNNING(1, 2, 3, 5),    // 2"
  },
  {
    "id" : "437a5b7b-e9f7-4015-83f7-746a913167e0",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-294840947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b042124-5cdb-4b4b-955b-8dbce3b60178",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Here I add the instance-level metrics.",
        "createdAt" : "2019-09-30T09:09:25Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +686,690 @@        log.info(\"Kafka Streams version: {}\", ClientMetrics.version());\n        log.info(\"Kafka Streams commit ID: {}\", ClientMetrics.commitId());\n\n        // re-write the physical topology according to the config\n        internalTopologyBuilder.rewriteTopology(config);"
  },
  {
    "id" : "b4beae1c-aed8-4da3-8388-6daa4e607197",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-294840947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b97435a-bf9e-4b39-9564-61cc34f2e8cf",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "`StreamsMetricsImpl` is now created at client level and not on thread level anymore.",
        "createdAt" : "2019-09-30T09:10:11Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +677,681 @@        metrics = new Metrics(metricConfig, reporters, time);\n        streamsMetrics =\n            new StreamsMetricsImpl(metrics, clientId, config.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG));\n        streamsMetrics.setRocksDBMetricsRecordingTrigger(rocksDBMetricsRecordingTrigger);\n        ClientMetrics.addVersionMetric(streamsMetrics);"
  },
  {
    "id" : "323f4fec-9d03-4cdd-a5e2-5938cf78cb6c",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-296093410",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d540661d-a966-45be-b73d-f49e2a82f59f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just going out on a limb here... should we also log the topology description here?",
        "createdAt" : "2019-10-02T04:13:36Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "3b62d30b-ba10-4cb3-9d36-2ad4674894d7",
        "parentId" : "d540661d-a966-45be-b73d-f49e2a82f59f",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I thought, we already do, but I couldn't find any output in a log file that I have locally. I would be in favour of logging the topology because it helps us during on-call. On the other hand, it may pollute the logs. Anyways, could we postpone this discussion to after the release?",
        "createdAt" : "2019-10-02T08:48:14Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +685,689 @@        ClientMetrics.addStateMetric(streamsMetrics, (metricsConfig, now) -> state);\n        log.info(\"Kafka Streams version: {}\", ClientMetrics.version());\n        log.info(\"Kafka Streams commit ID: {}\", ClientMetrics.commitId());\n\n        // re-write the physical topology according to the config"
  },
  {
    "id" : "de75a4de-e6e3-4806-9348-a11d95a20a3e",
    "prId" : 7417,
    "prUrl" : "https://github.com/apache/kafka/pull/7417#pullrequestreview-295745318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08dff732-6c58-4a89-9459-a6f8d14103f4",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "maybe instead to check that `rocksDBMetricsRecordingTriggerThread` is `null` instead? Here and elsewhere.",
        "createdAt" : "2019-10-01T15:15:16Z",
        "updatedAt" : "2019-10-01T17:20:44Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "cbb82b82-fb21-4e9c-b458-0c20e8a8f5af",
        "parentId" : "08dff732-6c58-4a89-9459-a6f8d14103f4",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Agreed!",
        "createdAt" : "2019-10-01T17:03:46Z",
        "updatedAt" : "2019-10-01T17:20:44Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a3fd4f3c9a945fe9e1a4ed8bdb99c567f0e199b",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +769,773 @@    private static ScheduledExecutorService maybeCreateRocksDBMetricsRecordingService(final String clientId,\n                                                                                      final StreamsConfig config) {\n        if (RecordingLevel.forName(config.getString(METRICS_RECORDING_LEVEL_CONFIG)) == RecordingLevel.DEBUG) {\n            return Executors.newSingleThreadScheduledExecutor(r -> {\n                final Thread thread = new Thread(r, clientId + \"-RocksDBMetricsRecordingTrigger\");"
  },
  {
    "id" : "d6debeb9-2b72-435d-9f1c-04af0110f6fb",
    "prId" : 7483,
    "prUrl" : "https://github.com/apache/kafka/pull/7483#pullrequestreview-301593928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5da74218-2321-42d4-9516-3afe4b351e0f",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I like the addition, we can reuse this when they inevitably do something else we'll need to warn our users about ðŸ˜œ ",
        "createdAt" : "2019-10-14T23:55:55Z",
        "updatedAt" : "2019-10-14T23:56:19Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "07769af5eeca7e9cc35580637706882528c77cc7",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +792,796 @@    }\n\n    private static void maybeWarnAboutCodeInRocksDBConfigSetter(final Logger log,\n                                                                final StreamsConfig config) {\n        if (config.getClass(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG) != null) {"
  },
  {
    "id" : "ac0cd778-e574-413e-8b71-539b44c556a1",
    "prId" : 7961,
    "prUrl" : "https://github.com/apache/kafka/pull/7961#pullrequestreview-344136818",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "@vvcephei @brary I actually have a concern with this overestimation.. Let's take a typical streams deployment with num_standby_replicas =1 ... During the time period, where the lag is fetched when a standby changelog partition is assigned but has not yet processed any events, we will report a really high value that may not lead to IQs being failed (since the store is deemed laggy).. Given a caller that periodically fetches the positions every few seconds would have a non-zero past value already, wonder if it makes sense to not report this partition instead.. i.e we only report lags on store partitions which have begun consumption..  At least for ksqlDB, I am thinking servers can track easily when lag was reported for a given store partition, given server and decide on using that value based on how recently it was updated..  But the values we receive won't be 'jumpy'. End of the day, I am also theorizing how this will behave.. So this is more about which way we want to bias. \r\n\r\n\r\nAcross the cluster, this time period will not in sync with each other and can happen differently. So not sure if this will in-fact provide correct relative order.. ",
        "createdAt" : "2020-01-15T01:40:18Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "9cdb0f54-4372-41c3-a6a8-31d03ef4ee6a",
        "parentId" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks for bringing this up. I'm not totally sure I follow, though...\r\n\r\nLet's say the partition in question has an end offset of 100 and a true \"earliest\" offset of 90 (due to compaction). If an instance has this partition assigned but has not yet recorded any position, we'd report its lag as 100. Another instance that has started processing but only processed one record would be reported with a lag of 9. This doesn't accurately represent the amount-of-work difference between the two instances (which is actually only one record, though the difference in lags is 91), but it _does_ correctly state that the second instance is ahead of the first in freshness.\r\n\r\nI also seems reasonable to not report a lag at all for not-yet-started stores, but then you have to handle the special case in client-side code. I.e., the metadata API would tell you that this instance owns a store, but then there's no lag reported, so maybe there was a rebalance and we lost the store, or maybe we do own the store, but haven't started processing yet... It still seems simpler to me to say \"woah, that lag is really big, like it's lagging by 100% of the topic, maybe I won't query this store\" if I don't want to query really stale data, versus handling the special case to reach the same conclusion.\r\n\r\nRealistically, even if we are still restoring, but the store is still behind by a year (for example), you _still_ wouldn't want to return the results, but rather would have _some_ heuristic of how stale is ok and how stale is too much, which would be able to handle this math just as easily either way.\r\n\r\nOne other thought is that offset values can still be jumpy, due to compaction. So there's nothing to say that there are any records at all between offset 5 and offset 9999. Maybe this is contributing to my feeling that it's ok to just gloss over this case.",
        "createdAt" : "2020-01-16T03:44:46Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2c783e81-5cdd-4ef6-8df6-494838a17d44",
        "parentId" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : ">but it does correctly state that the second instance is ahead of the first in freshness.\r\n\r\nFair. Your argument is if you have not begun work, then you would be behind another instance that has begun work.. \r\n\r\n>reasonable to not report a lag at all for not-yet-started stores, but then you have to handle the special case in client-side code.\r\n\r\nthe client code is going to have to use some mechanism to \"fence\" really bad lag.. i.e full restorations.. My concern was that if we hit this race condition, you would suddenly see a jump to \"oh this replica needs to fully restore\" and then back to the actual lag..\r\n\r\n>One other thought is that offset values can still be jumpy, due to compaction.\r\n\r\nI did think about this a bit.. I think what we have here would work fairly well in the common case, where the active and standby are apart by lag within the `uncompacted` portion of the changelog topic.. \r\n\r\n> So there's nothing to say that there are any records at all between offset 5 and offset 9999.\r\nOnce beyond that, since we just rely on the latest lag value, this is okay.. if there are no records, the restoration will be faster than expected.. but as a relative metric, it's still good.. \r\n\r\nIn all, I am okay sticking with this behavior for now.. We can revisit based on real world experience.. and really build a solid solid implementation in the next month or so.. ",
        "createdAt" : "2020-01-16T18:50:31Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      }
    ],
    "commit" : "026b9dd5f36a78839a5e628cd51d2e98f91313e9",
    "line" : 90,
    "diffHunk" : "@@ -1,1 +1272,1276 @@        log.debug(\"Current end offsets :{}\", allEndOffsets);\n        for (final Map.Entry<TopicPartition, ListOffsetsResultInfo> entry : allEndOffsets.entrySet()) {\n            // Avoiding an extra admin API lookup by computing lags for not-yet-started restorations\n            // from zero instead of the real \"earliest offset\" for the changelog.\n            // This will yield the correct relative order of lagginess for the tasks in the cluster,"
  },
  {
    "id" : "c9dcf1b1-8759-479e-a4bd-9aa1d56393ce",
    "prId" : 7961,
    "prUrl" : "https://github.com/apache/kafka/pull/7961#pullrequestreview-343995216",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "is there a notion of `experimental` APIs in streams? (like some other apache projects like Spark have) I think we can mark this experimental if so, setting the expectations with the user for the next release. ",
        "createdAt" : "2020-01-15T15:56:04Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "e7507d4b-64be-4820-a737-18466d0af29e",
        "parentId" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "There's not. There's \"interface: evolving\", but I think it's only for... interfaces. We already say in the javadoc that the returned values are estimates, so I think we've created enough wiggle room in the correctness of the returned lags. As to whether the method signature itself might change in the future, we'll just have to go the normal route of deprecating and replacing if we want to change it.",
        "createdAt" : "2020-01-15T22:26:18Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "fc91ffaa-7ea8-4b9e-82eb-cbc32679e479",
        "parentId" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "Okay.. lets stick to what we have. ",
        "createdAt" : "2020-01-16T15:25:04Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      }
    ],
    "commit" : "026b9dd5f36a78839a5e628cd51d2e98f91313e9",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +1228,1232 @@     * @return map of store names to another map of partition to {@link LagInfo}s\n     */\n    public Map<String, Map<Integer, LagInfo>> allLocalStorePartitionLags() {\n        final long latestSentinel = -2L;\n        final Map<String, Map<Integer, LagInfo>> localStorePartitionLags = new TreeMap<>();"
  },
  {
    "id" : "370599a0-cfa9-43db-bac3-3bff06d9f7cf",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350590717",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d25acf1c-9ca1-4f9a-b4a8-8b294be83767",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add a `@deprecated` annotation to the JavaDocs:\r\n```\r\n@depreated since 2.5 release; use {@link #store(StoreQueryParams)} instead\r\n``` ",
        "createdAt" : "2020-01-29T22:59:57Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5b6e23e5-a3c0-464c-92df-4f7c0869e8e9",
        "parentId" : "d25acf1c-9ca1-4f9a-b4a8-8b294be83767",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-01-30T05:38:15Z",
        "updatedAt" : "2020-01-30T05:38:15Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1164,1168 @@    /**\n     * @deprecated since 2.5 release; use {@link #store(StoreQueryParams)}  instead\n     */\n    @Deprecated\n    public <T> T store(final String storeName, final QueryableStoreType<T> queryableStoreType) {"
  },
  {
    "id" : "90495dc3-fa5e-446d-bc56-386cd5a730f0",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350589051",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc99487d-cc71-4153-a917-758cbe093349",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should not explain how `StoreQueryParams` works -- this should to into `StoreQueryParams` JavaDocs -- we should just keep the first sentence of the paragraph.",
        "createdAt" : "2020-01-29T23:02:20Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c8432817-732f-45d1-a79c-f0cc082d7a64",
        "parentId" : "dc99487d-cc71-4153-a917-758cbe093349",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-01-30T05:30:58Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +1174,1178 @@     * StoreQueryParams need required parameters to be set, which are {@code storeName} and if\n     * type is accepted by the provided {@link QueryableStoreType#accepts(StateStore) queryableStoreType}.\n     * The returned object can be used to query the {@link StateStore} instances.\n     *\n     * @param storeQueryParams   to set the optional parameters to fetch type of stores user wants to fetch when a key is queried"
  },
  {
    "id" : "f93bfab2-e11a-4e6b-bc0f-afb74ef7c137",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-351884501",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Nit: I would remove this sentence. Should be part of the JavaDocs of `StoreQueryParams`.",
        "createdAt" : "2020-01-30T07:12:36Z",
        "updatedAt" : "2020-01-30T07:43:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "10e1c4af-1891-45cd-af2c-b9619355b4af",
        "parentId" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-02-01T09:55:41Z",
        "updatedAt" : "2020-02-01T09:55:42Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      },
      {
        "id" : "f6a770c3-b994-4e60-9c94-5b763ba16857",
        "parentId" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-02-01T13:31:02Z",
        "updatedAt" : "2020-02-01T13:31:02Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +1173,1177 @@     * Get a facade wrapping the local {@link StateStore} instances with the provided {@link StoreQueryParams}.\n     * StoreQueryParams need required parameters to be set, which are {@code storeName} and if\n     * type is accepted by the provided {@link QueryableStoreType#accepts(StateStore) queryableStoreType}.\n     * The returned object can be used to query the {@link StateStore} instances.\n     *"
  },
  {
    "id" : "c7d6600f-5220-4348-b0ab-1f7e1646e40d",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350616789",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddfc3af3-d14b-4c0f-b653-29c296148d75",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: remove `optional` the object is used to set mandatory and optional parameters. Overall it reads a little bit complicated. Not sure atm how to improve it. Maybe @vinothchandar or @vvcephei have some ideas?",
        "createdAt" : "2020-01-30T07:16:52Z",
        "updatedAt" : "2020-01-30T07:43:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1176,1180 @@     * The returned object can be used to query the {@link StateStore} instances.\n     *\n     * @param storeQueryParams   to set the optional parameters to fetch type of stores user wants to fetch when a key is queried\n     * @return A facade wrapping the local {@link StateStore} instances\n     * @throws InvalidStateStoreException if Kafka Streams is (re-)initializing or a store with {@code storeName} and"
  },
  {
    "id" : "6b47ba5d-5b2f-4281-a4c1-09da7d4db2e5",
    "prId" : 8252,
    "prUrl" : "https://github.com/apache/kafka/pull/8252#pullrequestreview-379045307",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "36e18362-048c-4c88-b7d3-4f4396f8aa76",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The fact that this is static and has nothing in particular to do with the KafkaStreams class indicates that it probably belongs in a util class for use by KafkaStreams and StreamsPartitionAssignor.",
        "createdAt" : "2020-03-20T20:40:50Z",
        "updatedAt" : "2020-03-20T23:32:09Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "7e8b8621-226f-46f6-b8aa-cc171f8d00b7",
        "parentId" : "36e18362-048c-4c88-b7d3-4f4396f8aa76",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Ack",
        "createdAt" : "2020-03-20T22:25:01Z",
        "updatedAt" : "2020-03-20T23:32:09Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "67f96230-5254-446b-9f68-b8b6de1ed992",
        "parentId" : "36e18362-048c-4c88-b7d3-4f4396f8aa76",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "See https://github.com/apache/kafka/pull/8328",
        "createdAt" : "2020-03-22T20:42:55Z",
        "updatedAt" : "2020-03-22T20:42:56Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3dc2a52378efe7bb111982c725760bb4e7a1e9d",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +1262,1266 @@        }\n        return endOffsets;\n    }\n}"
  },
  {
    "id" : "df24efd1-1612-45c7-9d24-7edc677022e2",
    "prId" : 8371,
    "prUrl" : "https://github.com/apache/kafka/pull/8371#pullrequestreview-385974814",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "227e5ee2-9c33-4c0d-a6c7-c9119a2fc2e4",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Bummer that `Stream.count` forces us to round-trip through a long, but whatever.",
        "createdAt" : "2020-04-01T21:50:39Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "325f0a4e5b38f0cdd495629577cba64c9857b98c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +764,768 @@\n        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n            Math.toIntExact(Arrays.stream(threads).filter(thread -> thread.state().isAlive()).count()));\n\n        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);"
  },
  {
    "id" : "e8092b76-fd78-4116-a1c6-a531a708a4df",
    "prId" : 8371,
    "prUrl" : "https://github.com/apache/kafka/pull/8371#pullrequestreview-387093440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c99f8df-b740-4642-9356-4c11c9105364",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: Please add verifications or unit tests to verify the values measured by this metric in `KafkaStreamsTest`.",
        "createdAt" : "2020-04-03T10:14:17Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "325f0a4e5b38f0cdd495629577cba64c9857b98c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +764,768 @@\n        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n            Math.toIntExact(Arrays.stream(threads).filter(thread -> thread.state().isAlive()).count()));\n\n        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);"
  },
  {
    "id" : "24cfd7c6-c6ce-4621-ba79-07c25332cc77",
    "prId" : 8679,
    "prUrl" : "https://github.com/apache/kafka/pull/8679#pullrequestreview-414745406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4a2a97d7-e955-4d93-b059-edae97d167cc",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure if this update is necessary. This method is deprecated itself.",
        "createdAt" : "2020-05-17T02:57:38Z",
        "updatedAt" : "2020-05-21T21:48:53Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b0903f78-1436-4b48-be7e-c2bffa0736b6",
        "parentId" : "4a2a97d7-e955-4d93-b059-edae97d167cc",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Might as well make this update, since we may remove the methods at different times.",
        "createdAt" : "2020-05-19T19:13:34Z",
        "updatedAt" : "2020-05-21T21:48:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfcb6a3dce9ea006c43ddc1d502eccb07f879c10",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1082,1086 @@     * If a {@link StreamPartitioner custom partitioner} has been\n     * {@link ProducerConfig#PARTITIONER_CLASS_CONFIG configured} via {@link StreamsConfig} or\n     * {@link KStream#repartition(Repartitioned)}, or if the original {@link KTable}'s input\n     * {@link StreamsBuilder#table(String) topic} is partitioned differently, please use\n     * {@link #metadataForKey(String, Object, StreamPartitioner)}."
  },
  {
    "id" : "e2bb9d53-659e-46e4-a35f-72e7fc4e0ab0",
    "prId" : 8738,
    "prUrl" : "https://github.com/apache/kafka/pull/8738#pullrequestreview-420535963",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce337cdf-ab85-4afb-bd49-e7ed776eb929",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Can we please update the JavaDocs of `allLocalStorePartitionLags` to state that a `StreamsException` could be thrown?",
        "createdAt" : "2020-05-28T22:13:33Z",
        "updatedAt" : "2020-05-28T22:27:43Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "872cfb5b-209f-4808-ba76-a16f6306bf0d",
        "parentId" : "ce337cdf-ab85-4afb-bd49-e7ed776eb929",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "ack, done",
        "createdAt" : "2020-05-28T22:27:44Z",
        "updatedAt" : "2020-05-28T22:27:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "f7aad3ae9d2dbce77fe3e2ec2957298d466fb003",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1248,1252 @@\n        log.debug(\"Current changelog positions: {}\", allChangelogPositions);\n        final Map<TopicPartition, ListOffsetsResultInfo> allEndOffsets = fetchEndOffsets(allPartitions, adminClient);\n        log.debug(\"Current end offsets :{}\", allEndOffsets);\n"
  },
  {
    "id" : "b5e0cf2b-2529-4ddb-ac81-8168d063a8c7",
    "prId" : 9060,
    "prUrl" : "https://github.com/apache/kafka/pull/9060#pullrequestreview-453826490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15cd0265-0160-4ceb-b44f-f3f8cfb702a7",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Minor side fix: `fetchEndOffset` can never throw `TimeoutException` because it catches all `RuntimeException` and convert them into `StreamsException` already",
        "createdAt" : "2020-07-23T04:16:07Z",
        "updatedAt" : "2020-08-05T21:30:01Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "05b0faa5a146de6ec33784db87cf24c8ea1b6232",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1249,1253 @@        log.debug(\"Current changelog positions: {}\", allChangelogPositions);\n        final Map<TopicPartition, ListOffsetsResultInfo> allEndOffsets;\n        allEndOffsets = fetchEndOffsets(allPartitions, adminClient);\n        log.debug(\"Current end offsets :{}\", allEndOffsets);\n"
  },
  {
    "id" : "ced9aa2d-edb8-4238-a07a-57a3123c82df",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-532371490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Wouldn't it also be possible to start a shutdown thread here which closes the client without timeout? I think the other shutdown thread in close is rather useless (or I do simply not get its value).",
        "createdAt" : "2020-11-04T17:18:01Z",
        "updatedAt" : "2020-11-18T03:39:13Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "b6ff35d0-8043-49ab-af73-5430a3ee4607",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "It might be but I do not think that it is necessary",
        "createdAt" : "2020-11-05T18:15:40Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "fb77e116-895b-4d3c-b5db-152b36a691b7",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Why not? It would be much cleaner. We would close all stuff like admin client and the metrics, remove the client metrics and set the state to NOT_RUNNING which is not necessarily done with timeout zero (probably not because of the death lock). Additionally, we would get an nice info debug saying `Streams client stopped completely` instead of `Streams client cannot stop completely within the timeout`. ;-)",
        "createdAt" : "2020-11-05T18:25:11Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "32378cfc-4819-4b9c-8ebb-af14e582022f",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "My last comment is not true! Sorry! Everything alright!",
        "createdAt" : "2020-11-05T18:49:19Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "784487cb-c52f-4db7-994e-2ff3cfe83cf3",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I still have a question here. Since the stream thread is alive when it calls `close()` there will not be a deadlock anymore. So, why do we call `close()` with duration zero?",
        "createdAt" : "2020-11-13T16:00:23Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "ac88b3f5-7303-47bc-a529-37589f6445a9",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "we should be able to change it to `close()`",
        "createdAt" : "2020-11-13T16:56:55Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "006dbfdb-4be0-4405-9cb5-5c8a2320a3da",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think I'd personally still prefer the non-blocking version. It seems better to avoid blocking indefinitely when a thread is trying to shut itself down due to some unknown exception (or error).",
        "createdAt" : "2020-11-16T17:30:29Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a10a214d-e6d9-4b6d-b469-627cea10e951",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "> Since the stream thread is alive when it calls close() there will not be a deadlock anymore. So, why do we call close() with duration zero\r\n\r\n@cadonna can you clarify? I thought we would still be in danger of deadlock if we use the blocking `close()`, since `close()` will not return until every thread has joined but the StreamThread that called `close()` would be stuck in this blocking call and thus never stop/join",
        "createdAt" : "2020-11-17T01:03:03Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "358f481b-7552-42a3-8221-b922719dcc2f",
        "parentId" : "3edefb36-63a8-427c-8e56-2c1d20b7399a",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : ">  I thought we would still be in danger of deadlock if we use the blocking close(), since close() will not return until every thread has joined but the StreamThread that called close() would be stuck in this blocking call and thus never stop/join\r\n\r\nOK, I think you are right. I focused too much on \r\n\r\n```\r\nif (!thread.isRunning()) {\r\n    thread.join();\r\n}\r\n```\r\n\r\nwithout considering that before the stream threads are shutdown which makes them not running.\r\n\r\nIn the meantime, I understood a bit better the motivation of the shutdown thread in `close()`. The shutdown thread ensures that the timeout is still consiered in case `close()` is called by a stream thread. I think we should revisit it. But that is outside the scope of this PR.\r\n\r\nTo unblock this PR, I am fine with `close(Duration.Zero)`, but I have the feeling we could do better.",
        "createdAt" : "2020-11-17T13:41:49Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 135,
    "diffHunk" : "@@ -1,1 +438,442 @@                        \"and the registered exception handler opted to \" + action + \".\" +\n                        \" The streams client is going to shut down now. \", throwable);\n                close(Duration.ZERO);\n                break;\n            case SHUTDOWN_APPLICATION:"
  },
  {
    "id" : "81a38589-88b6-4d69-9d85-f28df81f490f",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-530218086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cebe2920-2fcb-48a8-a630-c2bfcb4c9943",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Just curious, what's the motivation for doing it like this vs just immediately throwing the exception?",
        "createdAt" : "2020-11-13T03:55:34Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "78536d64-ae80-4d3b-8af1-474cded35567",
        "parentId" : "cebe2920-2fcb-48a8-a630-c2bfcb4c9943",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We have to do the casting in order to throw the exception. Otherwise the compiler complains about checked vs unchecked exceptions",
        "createdAt" : "2020-11-13T16:42:18Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +420,424 @@            } else {\n                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n            }\n        } else {\n            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);"
  },
  {
    "id" : "c5dc42dc-639e-43f0-8c45-e96a80c8f705",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-533070933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b38c4396-bc58-40ab-95d2-cebf77109dba",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I think it makes more sense to transition to ERROR in this case than to NOT_RUNNING. But let's put this on file with the other FSM-related work planned for following PRs",
        "createdAt" : "2020-11-18T01:32:09Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e0827a23-cbf8-4261-8888-dfb73e27baaa",
        "parentId" : "b38c4396-bc58-40ab-95d2-cebf77109dba",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I am on the fence about this. I do think its would be consistent to be not running but also it did shutdown cleanly. We made this choice when ERROR still meant all threads had died and that is not true now. In the end I just went with what we had in the KIP rather than try to change it. Though I could be swayed to leave this in ERROR.",
        "createdAt" : "2020-11-18T02:46:55Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "e8f86d91-2938-4b67-aeca-db46773306dc",
        "parentId" : "b38c4396-bc58-40ab-95d2-cebf77109dba",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "That's fair. I guess I was thinking less about the inherent meaning of ERROR vs NOT_RUNNING, and more about not behaving differently in this special case. ie if there _are_ still StreamThreads running when a user selects SHUTDOWN_APPLICATION, then we ultimately transition to ERROR. So it strikes me as a bit odd to transition to NOT_RUNNING just because we didn't happen to have any threads left.",
        "createdAt" : "2020-11-18T03:06:40Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +450,454 @@                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n                            \" Currently there are no running threads so will now close the client.\");\n                    close(Duration.ZERO);\n                } else {\n                    for (final StreamThread streamThread : threads) {"
  },
  {
    "id" : "e3895768-4953-4039-a1a4-b77d0105e34d",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-533063223",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a616c203-6eb9-4879-8332-0eddebbb1755",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Why do we shut down the global thread only after all stream threads have completed their shutdown? Seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. Can you try this out in the followup PR?",
        "createdAt" : "2020-11-18T01:43:12Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "de678e00-9d98-4f2a-935d-24e52ecfa2b2",
        "parentId" : "a616c203-6eb9-4879-8332-0eddebbb1755",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "You are right I think. I just copied from the normal close method because I knew it worked. In a follow up we can maybe change both of these. Do you think that there should be a ak ticket to track it?",
        "createdAt" : "2020-11-18T02:44:07Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "60e028fa-8998-4b09-b2ed-a04ac978f514",
        "parentId" : "a616c203-6eb9-4879-8332-0eddebbb1755",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Eh, I wouldn't bother with an AK ticket if this will be tackled in the next PR. I'll just make a list of all the minor followup work somewhere to keep track",
        "createdAt" : "2020-11-18T02:59:37Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 278,
    "diffHunk" : "@@ -1,1 +1057,1061 @@            if (globalStreamThread != null) {\n                globalStreamThread.shutdown();\n            }\n\n            if (globalStreamThread != null && !globalStreamThread.stillRunning()) {"
  },
  {
    "id" : "2ac03ab9-76e2-4e76-ac17-2eca90a3964f",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-533947936",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "065551b6-4294-46f5-b103-456c2a87e6d0",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I just realized that this is going to be a problem with the way the ERROR state is being used. IF we `closeToError` then we transition to ERROR and shut down, however `ERROR -> PENDING_SHUTDOWN` is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls `close()`. And note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to ERROR it immediately invokes close (because that's what you should do with the current semantics)\r\nJust another thing that I think we can fix with some minor rewiring of the FSM. ",
        "createdAt" : "2020-11-18T02:14:15Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "f250495a-6564-4ae1-b592-c0111ee9ea34",
        "parentId" : "065551b6-4294-46f5-b103-456c2a87e6d0",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "This is currently the plan to remove that transition. It is pretty much the only change we plan to make to the FSM.",
        "createdAt" : "2020-11-18T02:47:48Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "202c939e-dab2-4b5c-838a-91c63f59411a",
        "parentId" : "065551b6-4294-46f5-b103-456c2a87e6d0",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "WDYT about having both NOT_RUNNING and ERROR go through PENDING_SHUTDOWN, rather than just transitioning directly and permanently to ERROR? At a high level I think it just makes sense for ERROR and NOT_RUNNING to be symmetric. Also any benefit to having an intermediate PENDING_SHUTDOWN for the NOT_RUNNING case presumably applies to the ERROR case as well. eg, it indicates whether Streams has completed its shutdown or not: users know that an app in PENDING_SHUTDOWN should never be killed, its only safe to do so once it reaches NOT_RUNNING. We should provide the same functionality and only transition to ERROR after the shutdown is complete",
        "createdAt" : "2020-11-18T03:30:18Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "3587ce58-69ea-4882-822b-04c4910e0951",
        "parentId" : "065551b6-4294-46f5-b103-456c2a87e6d0",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I do think that Error should not have direct transition. However I don't like using `PENDING_SHUTDOWN` , mostly because we can already distinguish between the two states and it would be best to inform right away. Also it could be a problem if we went to set Error and some how it went from PENDING_SHUTDOWN to NOT_RUNNING. I am in favor of adding something like `PENDING_ERROR` just to be more precise. ",
        "createdAt" : "2020-11-18T16:08:54Z",
        "updatedAt" : "2020-11-18T16:08:55Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "dbfd96dd-6ca1-4053-9890-9067d0bd0104",
        "parentId" : "065551b6-4294-46f5-b103-456c2a87e6d0",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Sounds reasonable",
        "createdAt" : "2020-11-18T22:53:15Z",
        "updatedAt" : "2020-11-18T22:53:16Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 311,
    "diffHunk" : "@@ -1,1 +1079,1083 @@\n    private boolean close(final long timeoutMs) {\n        if (!setState(State.PENDING_SHUTDOWN)) {\n            // if transition failed, it means it was either in PENDING_SHUTDOWN\n            // or NOT_RUNNING already; just check that all threads have been stopped"
  },
  {
    "id" : "74dee426-9bcc-4f86-ba35-dde50631b2f6",
    "prId" : 9572,
    "prUrl" : "https://github.com/apache/kafka/pull/9572#pullrequestreview-528291607",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cefb307b-46c9-4eb7-b899-8f15c1ff2838",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "IMO, the code would be easier navigable if you inline this method. Without the removed check, there is not really a reason to have a method here.",
        "createdAt" : "2020-11-11T10:06:42Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "c702d0a3-68d3-4d85-8466-e4205737e2da",
        "parentId" : "cefb307b-46c9-4eb7-b899-8f15c1ff2838",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I think I agree with you. fixed",
        "createdAt" : "2020-11-11T15:44:53Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b69b6b256f77448097a144f5f9ef0e14fed1445f",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +902,906 @@    private long getCacheSizePerThread(final int numStreamThreads) {\n        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n    }\n\n    private void resizeThreadCache(final int numStreamThreads) {"
  },
  {
    "id" : "ef114a9d-e6af-46c2-a3b1-ca48228fa824",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-534724201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dbe325a2-f864-4cf9-90bc-783484ea5c57",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Where is the stream thread started?",
        "createdAt" : "2020-11-19T17:53:55Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "43136ddc-4393-4e70-8d35-f96f15fa54bc",
        "parentId" : "dbe325a2-f864-4cf9-90bc-783484ea5c57",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "right before the positive return :)",
        "createdAt" : "2020-11-19T18:17:00Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 226,
    "diffHunk" : "@@ -1,1 +960,964 @@        }\n        return threads.size() + 1;\n    }\n\n    private long getCacheSizePerThread(final int numStreamThreads) {"
  },
  {
    "id" : "c973a9c8-1ea1-4e31-a8e0-fe3bb51352ee",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-535639961",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "542a202a-db13-45cc-b96d-101f1d09894c",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Additionally to the unit tests that you wrote, I think we also need integration tests.",
        "createdAt" : "2020-11-19T20:26:10Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "fe43e36f-371f-41bb-9f00-3ffb7b178362",
        "parentId" : "542a202a-db13-45cc-b96d-101f1d09894c",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "you are right, Ill add one",
        "createdAt" : "2020-11-19T23:41:53Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "47aefb3f-f5b5-42e4-b427-ca8703342ed7",
        "parentId" : "542a202a-db13-45cc-b96d-101f1d09894c",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "@cadonna added",
        "createdAt" : "2020-11-20T17:37:51Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 190,
    "diffHunk" : "@@ -1,1 +924,928 @@     * @return name of the added stream thread or empty if a new stream thread could not be added\n     */\n    public Optional<String> addStreamThread() {\n        synchronized (changeThreadCount) {\n            if (isRunningOrRebalancing()) {"
  },
  {
    "id" : "268ed590-9d64-4fdd-95e5-09f284e6024c",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-542176493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6bb0ec41-ae2d-4c06-8134-b30947e2fb2a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit. remove unnecessary `this.`",
        "createdAt" : "2020-12-01T02:10:09Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d58c5342-31f1-45e7-942b-e67f60c364c9",
        "parentId" : "6bb0ec41-ae2d-4c06-8134-b30947e2fb2a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "the `this.` is necessary. the parameter is the same name",
        "createdAt" : "2020-12-01T16:55:02Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "9dac006a-09b4-4970-be7d-193b4fc3429f",
        "parentId" : "6bb0ec41-ae2d-4c06-8134-b30947e2fb2a",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ah. Was missing that as you assign `handler` that is not a `StreamsUncaughtExceptionHandler` but a `Consumer<Throwable>`...",
        "createdAt" : "2020-12-01T18:21:46Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +408,412 @@        synchronized (stateLock) {\n            if (state == State.CREATED) {\n                this.streamsUncaughtExceptionHandler = handler;\n                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n                for (final StreamThread thread : threads) {"
  },
  {
    "id" : "e5e3cc3e-18f6-4126-8735-81a241e2b22f",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-542177485",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27a41931-2640-4c88-9c19-4b6885dadf3c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Can we create the `StreamStateListener` before we call `createStreamThread` and do `setStateListener` within `createStreamThread` ? If yes, we also don't need to call `setStateListener` within `addStreamThread`",
        "createdAt" : "2020-12-01T02:20:24Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "87c67861-6f2f-41c1-b733-76914168e5d8",
        "parentId" : "27a41931-2640-4c88-9c19-4b6885dadf3c",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "good idea. I don't know why the `SteamStateListener` is created after the stream threads are made but it seems to work.",
        "createdAt" : "2020-12-01T17:06:07Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "b0d5c8bb-fd97-4da6-8637-5f72641c04d5",
        "parentId" : "27a41931-2640-4c88-9c19-4b6885dadf3c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Maybe we had some cyclic dependency at some point in the past? Not sure.",
        "createdAt" : "2020-12-01T18:23:02Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 130,
    "diffHunk" : "@@ -1,1 +867,871 @@        threadState = new HashMap<>(numStreamThreads);\n        storeProviders = new ArrayList<>();\n        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n        if (hasGlobalTopology) {\n            globalStreamThread.setStateListener(streamStateListener);"
  },
  {
    "id" : "4caed7ca-4fba-418c-ad72-b813ae24d4fb",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-542209403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e6f6ce0-42c0-4ab3-9ad7-3064c83e0c62",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we compute the names from scratch, but not incrementally maintain them as member variable?",
        "createdAt" : "2020-12-01T02:25:11Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "0a3bc616-7d1a-41e4-aaf5-d630136ad643",
        "parentId" : "3e6f6ce0-42c0-4ab3-9ad7-3064c83e0c62",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "As threads are removed we want to reuse those names, so incrementing would not work for us. Maybe there is away to store a next name, but then the logic would have to be spread out in a few places and I prefer to just compute a few names.",
        "createdAt" : "2020-12-01T17:22:00Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "299f8ab1-deb8-43ed-beb8-1348804535bc",
        "parentId" : "3e6f6ce0-42c0-4ab3-9ad7-3064c83e0c62",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "That is not what I meant. But it might not matter much anyway.\r\n\r\nWhile we need to loop over all used names in L951 below to reuse, we don't need to compute `names` from scratch but would just modify `names` each time we add/remove a thread. But it's not perf-critical so re-doing the computation is fine, too.",
        "createdAt" : "2020-12-01T18:30:03Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "99d87d53-346a-427c-8d77-d5f516ca84da",
        "parentId" : "3e6f6ce0-42c0-4ab3-9ad7-3064c83e0c62",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I'll remove a few of the unnecessary `+` operations then",
        "createdAt" : "2020-12-01T19:13:46Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 214,
    "diffHunk" : "@@ -1,1 +948,952 @@\n    private int getNextThreadIndex() {\n        final HashSet<String> names = new HashSet<>();\n        for (final StreamThread streamThread: threads) {\n            names.add(streamThread.getName());"
  },
  {
    "id" : "f3604d2d-8781-4fb6-b4ae-72279d33b6f5",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-544286042",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9010e099-8469-4bf9-846c-c1e32e0aac55",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Sorry to bother you again with the synchronization on the `stateLock`, but could you explain why we still need it after we synchronize on `newThread`?",
        "createdAt" : "2020-12-03T16:41:36Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "6a92283e-5392-4ad2-90ce-ecf0c90f95a5",
        "parentId" : "9010e099-8469-4bf9-846c-c1e32e0aac55",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Well newThread only syncs the addThread method. There is still the race condition between the second check of is running and starting the thread. It seems like a bad idea to leave that open as it could cause thread state changes when there shouldn't be. Starting the thread is relatively low cost so this shouldn't have much impact perf wise.",
        "createdAt" : "2020-12-03T18:14:12Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "7fe541f6-9006-4adb-89ab-51d6fe368613",
        "parentId" : "9010e099-8469-4bf9-846c-c1e32e0aac55",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Expanding on this, the problem in the shutdown thread. When the join only waits for alive threads, and to be alive the thread needs to be started. \r\n\r\nSo if in between the check and the start thread another thread transitions the state to NOT_RUNNING the thread will not join in the shutdown thread. Then when it continues it will start as it passed the check and we will have a thread running after the client is shutdown.\r\n\r\nThis would be extremely though race condition to find or reproduce so best to just avoid it.",
        "createdAt" : "2020-12-03T19:04:04Z",
        "updatedAt" : "2020-12-03T19:19:50Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +931,935 @@                resizeThreadCache(cacheSizePerThread);\n                final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n                synchronized (stateLock) {\n                    if (isRunningOrRebalancing()) {\n                        streamThread.start();"
  },
  {
    "id" : "b3dc5f27-b062-42fc-803c-511fd712c3c7",
    "prId" : 9615,
    "prUrl" : "https://github.com/apache/kafka/pull/9615#pullrequestreview-545227155",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e14a4b22-0b96-43cf-84c8-a09ae9718209",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need this new lock-object? Would it not be simpler to just reuse `stateLock` ?",
        "createdAt" : "2020-12-04T18:11:50Z",
        "updatedAt" : "2020-12-04T18:13:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "250abf5f-ef69-40f1-a927-caa1d8ec562b",
        "parentId" : "e14a4b22-0b96-43cf-84c8-a09ae9718209",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We thought it would be better use a separate lock because it is serving a different purpose. It will also use used in remove thread. It might be simpler to reuse the statelock but I donâ€™t think that would be cleaner. We are really locking on the thread cache access and the thread indexes",
        "createdAt" : "2020-12-04T19:11:13Z",
        "updatedAt" : "2020-12-04T19:11:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "af3e5674f77037796801afcd445e126c1aa7f6b0",
    "line" : 191,
    "diffHunk" : "@@ -1,1 +925,929 @@     */\n    public Optional<String> addStreamThread() {\n        synchronized (changeThreadCount) {\n            if (isRunningOrRebalancing()) {\n                final int threadIdx = getNextThreadIndex();"
  },
  {
    "id" : "31acbddb-6f41-405c-8800-3c94a853f143",
    "prId" : 9695,
    "prUrl" : "https://github.com/apache/kafka/pull/9695#pullrequestreview-547378880",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a44b205-239e-4151-a1d5-eb496f7b709b",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Same here, let's log a warning",
        "createdAt" : "2020-12-08T01:11:24Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "60dc24ac-dcdf-44b6-93a8-6b3d337983b4",
        "parentId" : "5a44b205-239e-4151-a1d5-eb496f7b709b",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I will log it on both empty returns",
        "createdAt" : "2020-12-08T16:34:02Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0ebbdbc44ffe154d5bff5ef93ec3d16748b380c",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +988,992 @@     */\n    public Optional<String> removeStreamThread() {\n        if (isRunningOrRebalancing()) {\n            synchronized (changeThreadCount) {\n                for (final StreamThread streamThread : threads) {"
  },
  {
    "id" : "29731579-c275-4b5e-8349-fd6b5b94a1ff",
    "prId" : 9695,
    "prUrl" : "https://github.com/apache/kafka/pull/9695#pullrequestreview-563105656",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I know Bruno brought this up already and maybe I just missed the resolution in the previous comments, but: should we allow a StreamThread to remove itself? Originally I was thinking \"no\" but I was just thinking about what be the expected behavior from this method when called from a StreamThread, and I actually think we should consider ONLY removing the calling thread.\r\nI get the sense that users will interpret `removeStreamThread()` when called from a Thread as essentially saying \"shutdown this thread\", not \"remove some random thread\". WDYT?",
        "createdAt" : "2021-01-06T22:44:36Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "aa315ec3-e1f2-4cd2-b8c7-cc968443c5ee",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I think we should assert one or the other at least, ie we only ever remove the current thread or we only ever remove a different thread. And document this clearly of course ðŸ™‚ ",
        "createdAt" : "2021-01-06T22:47:28Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "6c9a83fb-8214-4ee4-8ab8-885c4566dba3",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We want to avoid removing the calling thread because the idea is that the call will block until thread is gone. This is best for the cache resizing too. However I do not like the idea of not letting a thread remove itself because, if we have one stream thread left not letting that thread remove it self (maybe leaving a global thread) this seems incomplete. If we need to make this more structured maybe we only remove itself if is the only thread running? that should make the cache and blocking issue less of a problem. How does that sound?",
        "createdAt" : "2021-01-06T22:52:52Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "274f7576-a06b-4523-8c8a-8fb724e06de5",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "@ableegoldman I don't know about only letting it remove its self. Not only stream threads can call this. ",
        "createdAt" : "2021-01-06T22:55:32Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "4e377c35-1a4b-4cf8-9cea-5dd68ca9efb1",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Sorry, my suggestion was vaguely worded. I meant that we should only let a StreamThread remove itself, if we detect that `removeThread` has been called by a StreamThread (which should be possible). If it's called by something else, then yes we should just pick a random thread to remove. I think that addresses your concern in the first sentence of your reply, but let me know if I'm misinterpreting it.\r\n\r\n>I do not like the idea of not letting a thread remove itself because, if we have one stream thread left not letting that thread remove it self (maybe leaving a global thread) this seems incomplete.\r\n\r\nThat's a good point. In that case I would advocate for _only_ letting a StreamThread remove itself. Do you see any problems with that?",
        "createdAt" : "2021-01-06T23:02:12Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b189406c-6a5e-4414-8431-358b45c286d2",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "well there is the issue of the cache resize. Which we wait until thread is dead before changing the cache size. We can not do that when a thread removes itself which makes it possible for OOM. (https://github.com/apache/kafka/pull/9695#discussion_r538921676) so it think it would be best to avoid removing itself if possible. unless it is the last thread",
        "createdAt" : "2021-01-06T23:14:18Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "6434509a-ff31-42f6-8cd8-d51a6f6e0141",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "So we should try removing any other thread, if one exists, and only allow to remove the current thread if it's the last one? That sounds reasonable, let's go with that",
        "createdAt" : "2021-01-06T23:27:54Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e354051a-51f3-4812-a8ad-8627ff3afe96",
        "parentId" : "60174b86-7a72-492c-9671-63d9f94d224a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "cool I'll make those changes. Basically a thread can only remove itself if it is the only thread left",
        "createdAt" : "2021-01-06T23:30:03Z",
        "updatedAt" : "2021-01-07T20:08:38Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0ebbdbc44ffe154d5bff5ef93ec3d16748b380c",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +993,997 @@                    if (streamThread.isAlive() && (!streamThread.getName().equals(Thread.currentThread().getName()) || threads.size() == 1)) {\n                        streamThread.shutdown();\n                        if (!streamThread.getName().equals(Thread.currentThread().getName())) {\n                            streamThread.waitOnThreadState(StreamThread.State.DEAD);\n                        }"
  },
  {
    "id" : "77ef48ea-ca69-4df5-9f57-9fe369b3fa3b",
    "prId" : 9695,
    "prUrl" : "https://github.com/apache/kafka/pull/9695#pullrequestreview-565479750",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d8fae95-058a-46c2-ac11-529cda01ef67",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I guess technically this might not work if we have only one live thread left, but other dead threads still in the list -- in that case we might skip over the live thread when we really should have removed it. I'm not sure how much of a problem this would really be, just wanted to point it out.",
        "createdAt" : "2021-01-06T23:54:06Z",
        "updatedAt" : "2021-01-07T20:08:38Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b9862357-1346-4c27-8f19-6fc087750ba6",
        "parentId" : "1d8fae95-058a-46c2-ac11-529cda01ef67",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We don't keep the dead threads in this list. When a thread dies we remove it form the list and updated the number of dead threads metric.",
        "createdAt" : "2021-01-07T00:38:19Z",
        "updatedAt" : "2021-01-07T20:08:38Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "238c64c0-c22e-4dc2-adef-5c60df187947",
        "parentId" : "1d8fae95-058a-46c2-ac11-529cda01ef67",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Then why check `isAlive()` here at all? (I'm not necessarily requesting changes here, just trying to understand)",
        "createdAt" : "2021-01-07T02:44:56Z",
        "updatedAt" : "2021-01-07T20:08:38Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e39ea204-2212-4548-bfd1-be3e635954f9",
        "parentId" : "1d8fae95-058a-46c2-ac11-529cda01ef67",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "there is a very small window between when thread dies with the old handler and when it is removed from the the list. So we have to check to make sure for now",
        "createdAt" : "2021-01-11T15:44:13Z",
        "updatedAt" : "2021-01-11T15:44:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0ebbdbc44ffe154d5bff5ef93ec3d16748b380c",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +991,995 @@            synchronized (changeThreadCount) {\n                for (final StreamThread streamThread : threads) {\n                    if (streamThread.isAlive() && (!streamThread.getName().equals(Thread.currentThread().getName()) || threads.size() == 1)) {\n                        streamThread.shutdown();\n                        if (!streamThread.getName().equals(Thread.currentThread().getName())) {"
  },
  {
    "id" : "75c576a4-8e22-48f7-9fc6-a3984420c4a4",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-549586323",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc5cb0b6-8a7c-40ef-a654-d55139e5df4a",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We want to make `close()` idempotent and not throw an exception but we will log a warning, but only for close so that is why these logs are not in the `setState()` method.",
        "createdAt" : "2020-12-10T20:48:17Z",
        "updatedAt" : "2021-01-21T22:43:31Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +1198,1202 @@\n    private boolean close(final long timeoutMs) {\n        if (state == State.ERROR) {\n            log.info(\"Streams client is already in the terminal state ERROR, all resources are closed and the client has stopped.\");\n            return true;"
  },
  {
    "id" : "57952e05-f694-46fc-b83f-a3cf5f6a9676",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-566820304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23514653-c2ad-4723-a70b-6ee138965308",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I thought we always need to call close? If an error happens, we call the handler, and if the handler return shutdown, we transit to `PENDING_ERROR`. On `close()` we transit from `PENDING_ERROR -> ERROR`?\r\n\r\nOr do I have some misconception?",
        "createdAt" : "2021-01-07T00:02:19Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "603e3cdf-43b2-448f-bb05-48c1cd364ed6",
        "parentId" : "23514653-c2ad-4723-a70b-6ee138965308",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "the handler will call close, but the user will not need to. The `PENDING_ERROR` state is indicating the resources are closing before the transition to `ERROR` after which no more work will be done. We made it so the user can call close on `PENDING_ERROR` or `ERROR` but it will only log a warning",
        "createdAt" : "2021-01-07T21:52:36Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "ed87c757-318f-4b55-8ceb-62bf16036b31",
        "parentId" : "23514653-c2ad-4723-a70b-6ee138965308",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for clarifying!",
        "createdAt" : "2021-01-13T01:03:43Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +220,224 @@     * - Any state except NOT_RUNNING, PENDING_ERROR or ERROR can go to PENDING_SHUTDOWN (whenever close is called)\n     * - Of special importance: If the global stream thread dies, or all stream threads die (or both) then\n     *   the instance will be in the ERROR state. The user will not need to close it.\n     */\n    public enum State {"
  },
  {
    "id" : "cbc7c602-7fb5-407e-99c6-6ac483262c38",
    "prId" : 9863,
    "prUrl" : "https://github.com/apache/kafka/pull/9863#pullrequestreview-566702128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11bff7a6-e056-400e-ad0b-891d494cf37f",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I am not 100% sure this is the purpose of the interrupt flag but I think that this will do",
        "createdAt" : "2021-01-11T16:16:26Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "3d48a2a4-8c85-45b7-b983-e4d71f87103d",
        "parentId" : "11bff7a6-e056-400e-ad0b-891d494cf37f",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Could you elaborate on why you are not 100% sure? ",
        "createdAt" : "2021-01-11T20:20:19Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "e6281638-6731-40e4-b431-8b72dd8c9d41",
        "parentId" : "11bff7a6-e056-400e-ad0b-891d494cf37f",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I thought it was to break threads out loops, I don't know if the flag is actually checked. So will passing it up be useful if the don't retrun",
        "createdAt" : "2021-01-11T20:33:23Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "14ab8591-9880-4e60-975d-b3abb6b81a6c",
        "parentId" : "11bff7a6-e056-400e-ad0b-891d494cf37f",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "In the words of \"Java Concurrency in Practice\":\r\n\"Thread interruption is a cooperative mechanism for a thread to signal another thread that it should, at its convenience and if it feels like it, stop what it is doing and do something else.\" \r\nInterruption consists of the interruption status that can be set by the current thread itself or by another thread with `Thread#interrupt()`. The interruption status can be checked with `Thread#isInterrupted()` and it is checked by some blocking methods, most notably `Object#wait()` and `Thread#sleep()`, which -- if the current thread is interrupted -- clear the interruption status and throw an `InterruptedException`. \r\nThe \"something else\" means the application of an interruption policy. Since we do not always own the thread that calls `close()`, we do not know the interruption policy. So, the minimum that we can do is restoring the interrupted status if the current thread was interrupted so that further up the call stack of the current thread, the possibly existing interruption policy of the current thread can be applied.",
        "createdAt" : "2021-01-12T08:38:51Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "9eea3920-08a5-4d5e-a8d9-ded65d328843",
        "parentId" : "11bff7a6-e056-400e-ad0b-891d494cf37f",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "This makes sense. thanks for explaining. I see why previously it was ignored but its probably best to restore it.  ",
        "createdAt" : "2021-01-12T21:08:26Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae50d84983f51ca7d1340a36634a14607964579f",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +274,278 @@                // the current thread exits this method.\n                if (interrupted) {\n                    Thread.currentThread().interrupt();\n                }\n            }"
  },
  {
    "id" : "ac308dcd-b353-40fa-87f6-5ab51ab81d88",
    "prId" : 9863,
    "prUrl" : "https://github.com/apache/kafka/pull/9863#pullrequestreview-565714296",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c7a799a-139f-4a9f-920d-6a749f849325",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "do we want to interrupt before we return? if that is the case why wait until the condition is full-filled?",
        "createdAt" : "2021-01-11T16:17:53Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "768ccd33-f364-4767-9b06-eaf3988d2622",
        "parentId" : "2c7a799a-139f-4a9f-920d-6a749f849325",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "We do not really interrupt, we restore the interruption state if the current thread was interrupted. What would be the alternative to restoring before we return? \r\nIf we do not wait until the condition is fulfilled, the while loop with the wait degenerates to busy waiting because usually the interruption status is checked at the beginning of the `wait()` method and we will run into the `InterruptedException` in each iteration which would defeat the purpose of the wait(). When the `InterruptedException` is thrown, the interruption status is reset.",
        "createdAt" : "2021-01-11T20:32:12Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae50d84983f51ca7d1340a36634a14607964579f",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +269,273 @@                }\n            } finally {\n                // Make sure to restore the interruption status before returning.\n                // We do not always own the current thread that executes this method, i.e., we do not know the\n                // interruption policy of the thread. The least we can do is restore the interruption status before"
  },
  {
    "id" : "b895dae7-c943-43fb-9ec8-813b7097bff4",
    "prId" : 9863,
    "prUrl" : "https://github.com/apache/kafka/pull/9863#pullrequestreview-565718011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "102537e5-f030-4552-be3f-c0f4a9f27616",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "if we have this inside the try as well then we should return and set the interrupted status. That should be better for the user if they want to ignore the exception because they can be sure of the state change and avoid making this call again",
        "createdAt" : "2021-01-11T16:19:31Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "3d826d26-8f07-40d3-84cf-6d5307ff3e6c",
        "parentId" : "102537e5-f030-4552-be3f-c0f4a9f27616",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "As far as I see, moving the return into the try block would not change anything. ",
        "createdAt" : "2021-01-11T20:38:06Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae50d84983f51ca7d1340a36634a14607964579f",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +277,281 @@                }\n            }\n            return true;\n        }\n    }"
  },
  {
    "id" : "88267e3f-985e-403d-8fdb-9a496542f10b",
    "prId" : 9863,
    "prUrl" : "https://github.com/apache/kafka/pull/9863#pullrequestreview-574498132",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f89eae5-ecdd-4d3c-bced-e4988d7b7136",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Don't we want to `break` out of the loop here?",
        "createdAt" : "2021-01-12T19:49:38Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "696e2fe3-4af4-4c1e-b599-0e93a1902509",
        "parentId" : "8f89eae5-ecdd-4d3c-bced-e4988d7b7136",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I do not think we should break the loop, because we actually do not know what interruption means for the current thread since we do not own it in general. It might be cancellation -- for which breaking the loop might make sense -- but it could also be something else.",
        "createdAt" : "2021-01-12T20:41:03Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "8d2f9a93-c294-47df-b638-3e70e7f37152",
        "parentId" : "8f89eae5-ecdd-4d3c-bced-e4988d7b7136",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Maybe we should have a quick sync on this. My understanding is that an interrupt means that the thread wants to regain control somewhere along the callstack. So the only way I can see to interpret it is as \"(1) stop blocking/waiting on whatever you're doing, (2) get the system back into a consistent state, and then (3) reset the flag so the interrupt can be handled (or not) by the caller\". Before this PR we were doing (1) and (2), now we're doing (2) and (3), but why not all three?\r\n\r\nIf we don't break out of the loop then we've effectively ignored the interrupt, since we will go on waiting for it to reach NOT_RUNNING. But it's actually worse, since as you mentioned in another comment, it'll now be in a busy loop",
        "createdAt" : "2021-01-13T00:04:49Z",
        "updatedAt" : "2021-01-22T16:49:59Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "38d6b96b-6ae2-437c-bf76-5b8834c9984b",
        "parentId" : "8f89eae5-ecdd-4d3c-bced-e4988d7b7136",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "@ableegoldman Are there still open questions after our offline sync?",
        "createdAt" : "2021-01-22T17:06:31Z",
        "updatedAt" : "2021-01-22T17:06:31Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "4ce0d431-ca78-4fb6-9286-22d0cc76f2ed",
        "parentId" : "8f89eae5-ecdd-4d3c-bced-e4988d7b7136",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Nope, I just forget about this PR -- thanks for the reminder",
        "createdAt" : "2021-01-22T18:06:38Z",
        "updatedAt" : "2021-01-22T18:06:39Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae50d84983f51ca7d1340a36634a14607964579f",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +260,264 @@                            stateLock.wait(remainingMs);\n                        } catch (final InterruptedException e) {\n                            interrupted = true;\n                        }\n                    } else {"
  },
  {
    "id" : "de0fffdf-c02f-4f0d-83ce-5947d3a839d5",
    "prId" : 9887,
    "prUrl" : "https://github.com/apache/kafka/pull/9887#pullrequestreview-568344737",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71eb97e4-2cc4-4c4f-87bf-b74e4741e4fe",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "fix for case 2)",
        "createdAt" : "2021-01-14T15:27:33Z",
        "updatedAt" : "2021-01-19T06:33:09Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      }
    ],
    "commit" : "33cd0949f5a6baafa2f028df912e2de72564edfe",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +955,959 @@                // Creating thread should hold the lock in order to avoid duplicate thread index.\n                // If the duplicate index happen, the metadata of thread may be duplicate too.\n                streamThread = createAndAddStreamThread(cacheSizePerThread, threadIdx);\n            }\n"
  },
  {
    "id" : "3a6f7711-91eb-440f-b5d5-59dc343cd923",
    "prId" : 9978,
    "prUrl" : "https://github.com/apache/kafka/pull/9978#pullrequestreview-582915378",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f56c274b-e8a2-419f-99fb-0f1b7742b564",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "this is the only logical change in the KafkaStreams constructor: the rest of the diff is due to moving things around in order to get everything initialized in the proper order",
        "createdAt" : "2021-01-28T03:49:37Z",
        "updatedAt" : "2021-02-02T00:45:25Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "a02b3468-36f7-434e-9021-241f818cd7b3",
        "parentId" : "f56c274b-e8a2-419f-99fb-0f1b7742b564",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "cc @cadonna for the pre-creation of internal topics, we would also need to build the topology in order to populate the `RepartitionTopics` etc, let's just make sure we only build it once when we add that logic.",
        "createdAt" : "2021-02-04T00:02:06Z",
        "updatedAt" : "2021-02-04T00:13:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d1314eb206de4d916f5f020ee88645757ec2218",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +802,806 @@        try {\n            stateDirectory = new StateDirectory(config, time, hasPersistentStores);\n            processId = stateDirectory.initializeProcessId();\n        } catch (final ProcessorStateException fatal) {\n            throw new StreamsException(fatal);"
  },
  {
    "id" : "8bddf071-6921-4e04-a816-0b6aa1a8c5da",
    "prId" : 9978,
    "prUrl" : "https://github.com/apache/kafka/pull/9978#pullrequestreview-577966286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d9a33b6-787d-49e7-9a99-df6f5f584c9f",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Just tried to factor some of the self-contained logic into helper methods, since I found it incredibly difficult to get oriented within the super-long KafkaStreams constructor",
        "createdAt" : "2021-01-28T03:50:20Z",
        "updatedAt" : "2021-02-02T00:45:25Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d1314eb206de4d916f5f020ee88645757ec2218",
    "line" : 185,
    "diffHunk" : "@@ -1,1 +948,952 @@                                            \"must subscribe to at least one source topic or global table.\");\n        }\n        return numStreamThreads;\n    }\n"
  },
  {
    "id" : "b7fce3a4-85b3-4144-bcfc-7006619ca923",
    "prId" : 9978,
    "prUrl" : "https://github.com/apache/kafka/pull/9978#pullrequestreview-577980808",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84a3cb6f-251a-4e9e-92ff-f9ca29cfd9f3",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Something I noticed during testing, I feel it makes sense for the handling of ERROR and NOT_RUNNING to parallel (same for the PENDING_ flavors). This is a slight change in behavior; now if a user calls `close()` while the instance is already closing, it will wait for the ongoing shutdown to complete before returning (with timeout).",
        "createdAt" : "2021-01-28T03:52:33Z",
        "updatedAt" : "2021-02-02T00:45:25Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "9eb975e5-6317-48f1-9ef6-fc09bc88ea16",
        "parentId" : "84a3cb6f-251a-4e9e-92ff-f9ca29cfd9f3",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I think this change makes a lot of sense. I don't think it changes the final behavior besides avoiding extra state change rejections from the logs, but it looks like they are replaced.",
        "createdAt" : "2021-01-28T04:43:24Z",
        "updatedAt" : "2021-02-02T00:45:25Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d1314eb206de4d916f5f020ee88645757ec2218",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +1296,1300 @@\n    private boolean close(final long timeoutMs) {\n        if (state == State.ERROR || state == State.NOT_RUNNING) {\n            log.info(\"Streams client is already in the terminal {} state, all resources are closed and the client has stopped.\", state);\n            return true;"
  },
  {
    "id" : "cad08c74-4afd-4bf0-82fd-f85cd090f2a3",
    "prId" : 9978,
    "prUrl" : "https://github.com/apache/kafka/pull/9978#pullrequestreview-582972452",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a59ade39-6b3f-42c9-9c10-21b5794e621e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Thanks for the code cleanup and re-ordering! BTW if there's no logical changes at all maybe add a comment on the PR next time.",
        "createdAt" : "2021-02-04T00:03:37Z",
        "updatedAt" : "2021-02-04T00:13:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e0bda2d9-815e-40cc-a1ae-60f89ed6144b",
        "parentId" : "a59ade39-6b3f-42c9-9c10-21b5794e621e",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Ah sorry, I did but it got covered up when I pushed some changes: https://github.com/apache/kafka/pull/9978#discussion_r565746851",
        "createdAt" : "2021-02-04T01:57:36Z",
        "updatedAt" : "2021-02-04T01:57:36Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d1314eb206de4d916f5f020ee88645757ec2218",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +839,843 @@        ClientMetrics.addTopologyDescriptionMetric(streamsMetrics, internalTopologyBuilder.describe().toString());\n        ClientMetrics.addStateMetric(streamsMetrics, (metricsConfig, now) -> state);\n        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n            Math.toIntExact(countStreamThread(thread -> thread.state().isAlive())));\n"
  },
  {
    "id" : "12abe96c-b477-477b-9754-45778502db1b",
    "prId" : 9984,
    "prUrl" : "https://github.com/apache/kafka/pull/9984#pullrequestreview-577888622",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e85e4bb2-465b-442c-8f30-46658af3f2c6",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "have to make this a kafkaTimeout",
        "createdAt" : "2021-01-27T21:19:07Z",
        "updatedAt" : "2021-01-29T16:32:38Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "11cda63b-fe9c-486c-a112-45c41f214288",
        "parentId" : "e85e4bb2-465b-442c-8f30-46658af3f2c6",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Ugh I forgot that `KafkaFuture` still throws a regular java TimeoutException. Such a mess -- btw we should log an error here (or a warn?) before rethrowing",
        "createdAt" : "2021-01-27T23:57:55Z",
        "updatedAt" : "2021-01-29T16:32:38Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b1ee0714-ed50-426b-aeb4-c29faba2cbe7",
        "parentId" : "e85e4bb2-465b-442c-8f30-46658af3f2c6",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We should. And I think maybe we should log the original stack trace",
        "createdAt" : "2021-01-28T00:22:58Z",
        "updatedAt" : "2021-01-29T16:32:38Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "778e01fd0e97d9f087899f3259f69f5e24d802c2",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +1045,1049 @@                            try {\n                                removeMembersFromConsumerGroupResult.memberResult(memberToRemove).get(timeoutMs - begin, TimeUnit.MILLISECONDS);\n                            } catch (final java.util.concurrent.TimeoutException e) {\n                                log.error(\"Could not remove static member {} from consumer group {} due to a timeout: {}\",\n                                        groupInstanceID.get(), config.getString(StreamsConfig.APPLICATION_ID_CONFIG), e);"
  },
  {
    "id" : "d86c8d19-94b5-4077-9176-0f7231de3cd6",
    "prId" : 9984,
    "prUrl" : "https://github.com/apache/kafka/pull/9984#pullrequestreview-579390586",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1da22ef-31c9-4949-98f8-8acd94cc5273",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I thought we agreed to not allow non-positive timeouts, i.e., `timeout <= Duration.ZERO`, for now. Or did I miss something?",
        "createdAt" : "2021-01-29T12:59:18Z",
        "updatedAt" : "2021-01-29T16:32:38Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "47302766-e09f-4833-ac09-99812edcffab",
        "parentId" : "a1da22ef-31c9-4949-98f8-8acd94cc5273",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "We are not allowing them as they will timeout but we are not stoping someone from entering them",
        "createdAt" : "2021-01-29T15:58:50Z",
        "updatedAt" : "2021-01-29T16:32:38Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "778e01fd0e97d9f087899f3259f69f5e24d802c2",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1008,1012 @@     */\n    public Optional<String> removeStreamThread(final Duration timeout) {\n        final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeout, \"timeout\");\n        final long timeoutMs = validateMillisecondDuration(timeout, msgPrefix);\n        return removeStreamThread(timeoutMs);"
  },
  {
    "id" : "0b775671-feac-47c1-8e05-b027bc5d0385",
    "prId" : 10215,
    "prUrl" : "https://github.com/apache/kafka/pull/10215#pullrequestreview-601239504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "efa80e77-577a-4dfd-94c5-a5e268f697a2",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Do we really need an atomic integer here? `maxThreadId` is only used in the synchronized block.",
        "createdAt" : "2021-02-26T08:34:59Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "8918f504-4569-46b9-9aab-0527bf01bb2d",
        "parentId" : "efa80e77-577a-4dfd-94c5-a5e268f697a2",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "It's because of the whole \"variables used in a lambda must be final or effectively final\" thing",
        "createdAt" : "2021-03-01T22:51:05Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "2409f682a5a44fc2c0d5f8684d149229ab174cce",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +1116,1120 @@    private int getNextThreadIndex() {\n        final HashSet<String> allLiveThreadNames = new HashSet<>();\n        final AtomicInteger maxThreadId = new AtomicInteger(1);\n        synchronized (threads) {\n            processStreamThread(thread -> {"
  },
  {
    "id" : "9b465fab-6332-4e21-9244-b9dacb2826fc",
    "prId" : 10215,
    "prUrl" : "https://github.com/apache/kafka/pull/10215#pullrequestreview-601374574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a450561-6f7d-41a6-ba83-3d020030e9fa",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Where do we trim this list? I don't thing we do. In the begging of `addStreamThread()` can we purge the dead threads? That is the only place it should matter",
        "createdAt" : "2021-02-26T16:57:38Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "d0aabfe6-3cd7-4309-a8d3-4f3f3c03994c",
        "parentId" : "3a450561-6f7d-41a6-ba83-3d020030e9fa",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We're trimming it in `getNextThreadIndex`. But if we're going to rely on `threads.size()` elsewhere, which it seems we do, then yeah we should trim it more aggressively",
        "createdAt" : "2021-03-02T03:25:45Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "2409f682a5a44fc2c0d5f8684d149229ab174cce",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1049,1053 @@                                timeout = true;\n                                // Don't remove from threads until shutdown is complete. We will trim it from the\n                                // list once it reaches DEAD, and if for some reason it's hanging indefinitely in the\n                                // shutdown then we should just consider this thread.id to be burned\n                            } else {"
  },
  {
    "id" : "e63defcf-008a-4adf-affe-3daf71046d51",
    "prId" : 10215,
    "prUrl" : "https://github.com/apache/kafka/pull/10215#pullrequestreview-602009466",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78166412-42a3-4892-88f0-9e65e0359cda",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "If we purge the dead threads before we add new ones and if we remove the assumption that there are no dead threads in the thread list we can just not remove the threads in remove thread. This will make it there should be no concern about the cache size changing when a thread is removing itself. And make the risk we took about memory overflows unnecessary.",
        "createdAt" : "2021-02-26T17:08:50Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "45cb7017-c2f8-44a8-8872-1938c2649dc0",
        "parentId" : "78166412-42a3-4892-88f0-9e65e0359cda",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Yeah, I was mainly trying to keep things simple. There's definitely a tradeoff in when we resize the cache: either we resize it right away and risk an OOM or we resize it whenever we find newly DEAD threads but potentially have to wait to \"reclaim\" the memory of a thread. \r\nBoth scenarios run into trouble when a thread is hanging in shutdown, but if that occurs something has already gone wrong so I don't think we need to guarantee Streams will continue running perfectly. But the downside to resizing the cache only once a thread reaches DEAD is that a user could call `removeStreamThread()` with a timeout of 0 and then never call add/remove thread again, and they'll never get back the memory of the removed thread since we only trim the `threads` inside these methods (or the exception handler). ie, it seems ok to lazily remove DEAD threads if we only use the `threads` list to find a unique `threadId`, but not to lazily resize the cache. WDYT?",
        "createdAt" : "2021-03-02T03:20:59Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "df818b95-290e-4cf8-8c8d-2f496cbce3ac",
        "parentId" : "78166412-42a3-4892-88f0-9e65e0359cda",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I think we can leave it for now, if we should see problems this could be a fix, we don't run a single thread soak so we won't see this issue ourselves but there are many single thread applications that could start using this and we should see if they have problems",
        "createdAt" : "2021-03-02T16:22:06Z",
        "updatedAt" : "2021-03-02T21:37:16Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2409f682a5a44fc2c0d5f8684d149229ab174cce",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +1052,1056 @@                                // shutdown then we should just consider this thread.id to be burned\n                            } else {\n                                threads.remove(streamThread);\n                            }\n                        }"
  }
]