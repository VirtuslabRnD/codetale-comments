[
  {
    "id" : "973f242c-f1d8-45d1-b8d0-bee5ceff8623",
    "prId" : 4998,
    "prUrl" : "https://github.com/apache/kafka/pull/4998#pullrequestreview-119274280",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4f9d465-bc74-41c0-88f9-b7bdd574afb1",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Update the above TODO with only admin client left.",
        "createdAt" : "2018-05-10T22:55:59Z",
        "updatedAt" : "2018-05-15T16:31:43Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c857b9a7f14178e17b0a647af540b7af3bed2cf",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +388,392 @@        final Map<MetricName, Metric> result = new LinkedHashMap<>();\n        for (final StreamThread thread : threads) {\n            result.putAll(thread.producerMetrics());\n            result.putAll(thread.consumerMetrics());\n        }"
  },
  {
    "id" : "39f846d4-b8e9-447a-9f0b-40b15b894678",
    "prId" : 5682,
    "prUrl" : "https://github.com/apache/kafka/pull/5682#pullrequestreview-161804660",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang @bbejeck @vvcephei Should we change this to \"zero or negative\" ? Comparing the implementation, passing in a negative timestamp will \"expire\" the timeout even without checking the state transition at all and return immediately (with `false`) even if the state transition was successful.",
        "createdAt" : "2018-09-30T21:04:48Z",
        "updatedAt" : "2018-10-04T14:34:18Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "92810b3b-f3ad-4b4d-86fe-17c58b71a260",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I'm fine with those semantics, maybe we can make a Jira.\r\n\r\nThinking about it more, though, wouldn't it make more sense to:\r\n* reject negative numbers\r\n* make 0 just signal and return immediately (after checking the state once)\r\n* if I want to wait \"forever\", I can use `ofYears(1)` or `ofMillis(Long.MAX_VALUE)` or some other intuitively \"long enough to be forever\" value instead of a magic value.\r\n\r\nRegardless, I agree the current behavior is a little weird, and I'd be in favor of a Jira/KIP to revise it.",
        "createdAt" : "2018-10-01T14:34:28Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a3542d14-99af-441d-a421-f7ef9d5e353c",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Overall I'm ok with the semantics.\r\n \r\nBut my first instinct of a timeout of `0` implies shutdown immediately with no wait and blocking forever takes a value of `Long.MAX_VALUE`.\r\n\r\nIn short, I'm +1 as well on revising the behavior. ",
        "createdAt" : "2018-10-01T21:13:46Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "1e17e274-693c-44fd-a1ac-1a6c21dbc050",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Created: https://issues.apache.org/jira/browse/KAFKA-7477",
        "createdAt" : "2018-10-03T20:17:52Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0b290fa4-a871-4627-bea8-15eb72f3ac42",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think, we should fix this in 2.1 -- I am suggestion this, because we could use the new semantics for `close(Duration)` only and stay with old semantics for `close(long, TimeUnit)` -- if we don't so this, it would be an backward incompatible change and thus we could only do it in `3.0.0.`.",
        "createdAt" : "2018-10-03T22:21:12Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ec5da148-c2a0-44ff-ab14-f8ec70ebc79b",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@nizhikov Are you willing for address 7477 in this PR? If not, it's also fine and we do a follow up PR. However, it should be part of the KIP description. Could you update the KIP accordingly?",
        "createdAt" : "2018-10-03T22:56:34Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "50e8fcfa-d762-4039-a9ab-c8507d421a18",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "@mjsax I'll take care of KAFKA-7477 in follow up PR.\r\n\r\n[KIP-358](https://cwiki.apache.org/confluence/display/KAFKA/KIP-358%3A+Migrate+Streams+API+to+Duration+instead+of+long+ms+times) updated. Please, see, \"Proposed Changes\" section.",
        "createdAt" : "2018-10-04T09:59:13Z",
        "updatedAt" : "2018-10-04T14:34:19Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      },
      {
        "id" : "be0561a0-b6e6-4fc0-8f58-b0e62a025738",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Did you start working on KAFKA-7477 already @nizhikov ?",
        "createdAt" : "2018-10-04T16:43:20Z",
        "updatedAt" : "2018-10-04T16:43:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "94812d04-dd5a-46ff-a1ed-b5ed5ea3ac2b",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "As far as I can understand thus fix is trivial.\r\nI'm planning to provide PR in a 24 hour after this PR finish. Is it OK?",
        "createdAt" : "2018-10-04T18:49:40Z",
        "updatedAt" : "2018-10-04T18:49:40Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      },
      {
        "id" : "32d9f463-8a83-45c9-b0ca-50729bcc4d85",
        "parentId" : "f640e6d3-6d4e-4478-be45-f08c7375e88f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Wouldn't call it trivial, but sure, this sound good! Thanks a lot. Just want to make sure we get it on time to not miss code freeze deadline. Thanks a lot!",
        "createdAt" : "2018-10-04T20:50:39Z",
        "updatedAt" : "2018-10-04T20:50:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5210f9fff117c695cb1f3024c94eff7f49599a6a",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +903,907 @@     * Shutdown this {@code KafkaStreams} by signaling all the threads to stop, and then wait up to the timeout for the\n     * threads to join.\n     * A {@code timeout} of 0 means to wait forever.\n     *\n     * @param timeout  how long to wait for the threads to shutdown"
  },
  {
    "id" : "6925f1d7-d3cf-492c-b1ec-485f6af6670c",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-171455665",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add a new test to `KafkaStreamsTest` to check that no directory is created for this case",
        "createdAt" : "2018-11-04T03:11:28Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "727e1382-96ab-42a4-a6d2-e5cec7625d20",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "For the above case, `TopologyDiskAccessTest` class is added.  `KafkaStreamsTest` tests only the KafkaStreams logic (It doesn't create any topology which is required for the above case). ",
        "createdAt" : "2018-11-04T09:39:17Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      },
      {
        "id" : "a25b8e84-589f-45c9-b1c0-882be39d9cb8",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "> KafkaStreamsTest tests only the KafkaStreams logic\r\n\r\nWell, because `KafkaStreams` is responsible to create/or-not-crate the directory, this is part of `KafkaStreams` logic, isn't it? Thus, IMHO we should test this behavior in `KafkaStreamsTest`. Nothing prevents you create any topology in the test for this.\r\n\r\nAlso, `TopologyDisAccessTest` does not use `KafkaStreams` but `TopologyTestDriver` and thus, does not cover this code path.",
        "createdAt" : "2018-11-04T17:33:33Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "710a3047-0d47-43ea-a668-7b171c2b4292",
        "parentId" : "72d94a2e-acc9-48be-a82f-b4e745ea17ee",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "Agree, moved the test cases to `KafkaStreamsTest`.",
        "createdAt" : "2018-11-05T08:50:29Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +675,679 @@        final ProcessorTopology globalTaskTopology = internalTopologyBuilder.buildGlobalStateTopology();\n        final long cacheSizePerThread = totalCacheSize / (threads.length + (globalTaskTopology == null ? 0 : 1));\n        final boolean createStateDirectory = taskTopology.hasPersistentLocalStore() ||\n                (globalTaskTopology != null && globalTaskTopology.hasPersistentGlobalStore());\n"
  },
  {
    "id" : "ff999106-4702-482d-9d9e-865509cb6048",
    "prId" : 5747,
    "prUrl" : "https://github.com/apache/kafka/pull/5747#pullrequestreview-162648793",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We cannot change the semantics of exiting `close(long, TimeUnit)` -- this would be a backward incompatible change. We can only change the semantics for the new `close(Duration)` method.\r\n\r\nWe also should point out the different semantics in L830:\r\n```\r\n@deprecated Use {@link #close(Duration)} instead; note, that {@link #close(Duration)} has different semantics and does not block on zero, e.g., `Duration.ofMillis(0)`.",
        "createdAt" : "2018-10-05T17:43:46Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a25aa812-456a-4bf7-8df8-ae6cc0bb6f46",
        "parentId" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Seems this comment was not addressed yet.",
        "createdAt" : "2018-10-08T21:22:51Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "bc039738-a625-434d-bb03-24a3d2e12bd4",
        "parentId" : "9f9e30fd-9ea1-4fe8-9cc3-b71002c882f2",
        "authorId" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "body" : "Fixed.",
        "createdAt" : "2018-10-08T21:38:57Z",
        "updatedAt" : "2018-10-08T21:40:04Z",
        "lastEditedBy" : "fe0be475-2786-4ac9-8152-c07fa363b977",
        "tags" : [
        ]
      }
    ],
    "commit" : "d055d3e380704470a874bc477902c3a649298717",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +819,823 @@     * A {@code timeout} of 0 means to wait forever.\n     *\n     * @param timeout  how long to wait for the threads to shutdown. Can't be negative. If {@code timeout=0} just checking the state and return immediately.\n     * @param timeUnit unit of time used for timeout\n     * @return {@code true} if all threads were successfully stopped&mdash;{@code false} if the timeout was reached"
  },
  {
    "id" : "fd1beb28-1761-41fb-ae2f-7aef82650f87",
    "prId" : 5954,
    "prUrl" : "https://github.com/apache/kafka/pull/5954#pullrequestreview-179629376",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@ijuma Removed the `SuppressWarning` annotation and rewrote the code. Also have a PR for 2.1 branch: https://github.com/apache/kafka/pull/5963 for this fix.",
        "createdAt" : "2018-11-28T21:09:28Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "04044a72-350f-4a0a-a731-4aac7c11ba6f",
        "parentId" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We translate old default of zero to Long.MAX_VALUE within deprecated `close(final long timeout, final TimeUnit timeUnit)` -- we can call `private close()` directly instead.",
        "createdAt" : "2018-11-28T21:12:29Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8a5b63df-586a-4585-82e4-2b2afc40f6f6",
        "parentId" : "9632f937-e306-4a66-b06f-7827e78d724a",
        "authorId" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "body" : "Thanks, this looks better.",
        "createdAt" : "2018-11-29T05:01:39Z",
        "updatedAt" : "2018-12-11T09:51:36Z",
        "lastEditedBy" : "d8c7cf80-a55a-474c-a4f4-f60a9efda52c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9c692fa9804850c0cdd372d825db005bf3851f8",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +808,812 @@     */\n    public void close() {\n        close(Long.MAX_VALUE);\n    }\n"
  },
  {
    "id" : "978f0d8a-e9b5-4d0d-a782-1239d7a8c4d9",
    "prId" : 5963,
    "prUrl" : "https://github.com/apache/kafka/pull/5963#pullrequestreview-179518887",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5dce7be0-b76c-481b-9820-7f3ffd012c20",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We translate old default of zero to Long.MAX_VALUE within deprecated `close(final long timeout, final TimeUnit timeUnit)` -- we can call `private close()` directly instead.",
        "createdAt" : "2018-11-28T21:11:57Z",
        "updatedAt" : "2018-11-28T21:11:57Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "65462041543d7f9f12ffa5fab6c0bcc45403e83d",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +811,815 @@     */\n    public void close() {\n        close(Long.MAX_VALUE);\n    }\n"
  },
  {
    "id" : "3213f5d7-b9f5-42ec-86eb-ddf58739cef1",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-184656205",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f18710d-807b-4baa-8129-80ee7dc3843f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for 1).",
        "createdAt" : "2018-12-09T23:22:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "1f09a998-9753-4c8a-b92a-4d6fa3a1772d",
        "parentId" : "5f18710d-807b-4baa-8129-80ee7dc3843f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't get why we need this? `onChange()` is `synchronized`, so how can a race condition happen?",
        "createdAt" : "2018-12-13T14:08:22Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 175,
    "diffHunk" : "@@ -1,1 +395,399 @@        private GlobalStreamThread.State globalThreadState;\n        // this lock should always be held before the state lock\n        private final Object threadStatesLock;\n\n        StreamStateListener(final Map<Long, StreamThread.State> threadState,"
  },
  {
    "id" : "3882b8bc-8648-4081-a40c-e511db48f44e",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-185286174",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is for 1) as well: we allow REBALANCE -> REBALANCE and RUNNING -> RUNNING because of the deferred check.",
        "createdAt" : "2018-12-09T23:24:08Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4a91920c-3466-4260-9c29-2fbeca41a6f6",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just looking at this, it seems we need to assign `oldState = state` after we go the lock?",
        "createdAt" : "2018-12-13T13:55:37Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "296baa8c-a29c-47ab-8c02-51155629d3ff",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Also below, when calling `stateListener.onChange(state, oldState);` -- would we need to call `stateListener.onChange(newState, oldState);` instead? Otherwise, `state` could change before we do the callback because the lock is released already.\r\n\r\n",
        "createdAt" : "2018-12-13T13:56:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fcf7a0f8-d100-48d4-a2bb-7473616e50fe",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I cannot follow here. Why would this happen? Similar for RUNNING?",
        "createdAt" : "2018-12-13T14:05:41Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d0f9d087-e20d-4cd1-8c73-cb127f9ee51a",
        "parentId" : "ee712804-dd02-4022-baf5-fbd520aa6218",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Re first two comments: good call, lgtm.\r\n\r\nRe last comment: REBALANCING -> REBALANCING is quite normal, note that before this PR we check this before calling `setState(State.REBALANCING);` so this is prevented, but part of this fix is to move the logic that needs to access the state into a single place (here). Similarly RUNNING -> RUNNING is possible during starting up phase, where we first set the instance state to RUNNING directly to avoid it transit from CREATED -> REBALANCING, and then when threads are starting, it is possible that `maybeSetRunning` went through and hence calls `setState(RUNNING)` again.",
        "createdAt" : "2018-12-14T21:09:58Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +252,256 @@                // will be refused but we do not throw exception here, to allow idempotent close calls\n                return false;\n            } else if (state == State.REBALANCING && newState == State.REBALANCING) {\n                // when the state is already in REBALANCING, it should not transit to REBALANCING\n                return false;"
  },
  {
    "id" : "3af27371-8d50-4ae3-a3c3-287c33ec2540",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-183000687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81eed83d-de45-4312-9d03-20ec2d2e082f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This one-liner is for 2).",
        "createdAt" : "2018-12-09T23:24:36Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 210,
    "diffHunk" : "@@ -1,1 +426,430 @@            // state can be transferred to RUNNING if all threads are either RUNNING or DEAD\n            for (final StreamThread.State state : threadState.values()) {\n                if (state != StreamThread.State.RUNNING && state != StreamThread.State.DEAD) {\n                    return;\n                }"
  },
  {
    "id" : "7cb0566d-4b87-47e8-b5de-e66e67ad3c4d",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-185282740",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a590d369-4518-43b2-9cff-536e6386f5c6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Does it make sense to set the instance to RUNNING if all threads are DEAD ?",
        "createdAt" : "2018-12-13T13:21:11Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "38c58a07-ff20-4981-ba68-ed0a28195c79",
        "parentId" : "a590d369-4518-43b2-9cff-536e6386f5c6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note this is triggered only when a thread transited to RUNNING.\r\n\r\nWhen all threads are DEAD, by the time the last thread transited to DEAD the `maybeSetError` will proceed and the state will transit to ERROR.",
        "createdAt" : "2018-12-14T20:58:37Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 207,
    "diffHunk" : "@@ -1,1 +424,428 @@         */\n        private void maybeSetRunning() {\n            // state can be transferred to RUNNING if all threads are either RUNNING or DEAD\n            for (final StreamThread.State state : threadState.values()) {\n                if (state != StreamThread.State.RUNNING && state != StreamThread.State.DEAD) {"
  },
  {
    "id" : "46f0327d-6f21-4dc0-bd6e-0c8e17167446",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189542384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e75185e-ecad-4265-82ae-45d344ed785c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "With the state transitions changes for `StreamThread` is this still possible?",
        "createdAt" : "2018-12-19T09:40:03Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3f9d1d61-a0a6-4ba3-b9e3-94121d792fa0",
        "parentId" : "4e75185e-ecad-4265-82ae-45d344ed785c",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good point, I can remove it here.",
        "createdAt" : "2019-01-04T21:53:34Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +256,260 @@                return false;\n//            } else if (state == State.RUNNING && newState == State.RUNNING) {\n                // when the state is already in RUNNING, it should not transit to RUNNING\n                // this can happen during starting up\n//                return false;"
  },
  {
    "id" : "ebcbb2c3-5331-44b5-bc24-e2143bf92711",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189509479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81951a80-c33d-45bd-b259-c41be193ed3d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need `threadStateLock`? Can't we use `this`?",
        "createdAt" : "2018-12-19T09:43:40Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f9445e7e-ea74-42db-850e-926fadfde2e1",
        "parentId" : "81951a80-c33d-45bd-b259-c41be193ed3d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We can; but since we have a `stateLock` already I want to distinguish it with another dedicated object.",
        "createdAt" : "2019-01-04T20:03:25Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 242,
    "diffHunk" : "@@ -1,1 +445,449 @@                                          final ThreadStateTransitionValidator abstractNewState,\n                                          final ThreadStateTransitionValidator abstractOldState) {\n            synchronized (threadStatesLock) {\n                // StreamThreads first\n                if (thread instanceof StreamThread) {"
  },
  {
    "id" : "5f3155d9-4fd0-4db7-8d50-3bfc38a3a225",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189510538",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c68db677-5dd7-43bb-917e-efd9028596f0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If we want to encapsulate state handling at instance/thread level, maybe rewrite this to:\r\n```\r\nif (newState == GlobalStreamThread.State.DEAD) {\r\n    setState(State.ERROR);\r\n    log.error(\"Global thread has died. The instance will be in error state and should be closed.\");\r\n}\r\n```\r\n\r\nGlobalStreamThread would call this method only once anyway, and `setState()` should handle idempotent `setState(State.ERROR)` internally?",
        "createdAt" : "2018-12-19T09:51:04Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b4d7031f-57dd-4e7e-a60d-8193b96c96ea",
        "parentId" : "c68db677-5dd7-43bb-917e-efd9028596f0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I can do that, but I need to let `State.ERROR` transit to `State.ERROR` (currently it is not allowed, and hence will cause illegal state exception). Will do that.",
        "createdAt" : "2019-01-04T20:06:58Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 263,
    "diffHunk" : "@@ -1,1 +466,470 @@                    if (newState == GlobalStreamThread.State.DEAD) {\n                        setState(State.ERROR);\n                        log.error(\"Global thread has died. The instance will be in error state and should be closed.\");\n                    }\n                }"
  },
  {
    "id" : "1cd4e424-e639-4c62-ab64-25fd5c13710f",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189512662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9365ee7-fbe7-4def-9293-29b7c697a9be",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure if this holds. Don't we need to block state transitions while we cleanup is running?",
        "createdAt" : "2018-12-19T09:54:14Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2288ce29-5f71-434b-90af-7839cc75fd32",
        "parentId" : "e9365ee7-fbe7-4def-9293-29b7c697a9be",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`stateDirectory.cleanRemovedTasks(cleanupDelay);` itself have synchronization barriers as well, so we do not need to have the whole function in `synchronized(stateLock)`; and in that case, just locking `stateLock` for reading its value does not bring any additional guarantees.",
        "createdAt" : "2019-01-04T20:14:10Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 286,
    "diffHunk" : "@@ -1,1 +791,795 @@            final Long cleanupDelay = config.getLong(StreamsConfig.STATE_CLEANUP_DELAY_MS_CONFIG);\n            stateDirCleaner.scheduleAtFixedRate(() -> {\n                // we do not use lock here since we only read on the value and act on it\n                if (state == State.RUNNING) {\n                    stateDirectory.cleanRemovedTasks(cleanupDelay);"
  },
  {
    "id" : "8e6a0b59-271a-4b46-8bbf-03437c1e7d4e",
    "prId" : 6018,
    "prUrl" : "https://github.com/apache/kafka/pull/6018#pullrequestreview-189514003",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "688c09f2-dfbb-4dcc-9487-e03cc74ab8b8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we want to disallow calling `start()` twice? Could be idempotent no-op, too.",
        "createdAt" : "2018-12-19T09:55:45Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3826ab16-f13b-4a52-8db5-5e32154fb561",
        "parentId" : "688c09f2-dfbb-4dcc-9487-e03cc74ab8b8",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good question.. this was added at the very beginning when we try to fix a few state transition bugs, and one of them as calling start() twice which may re-create threads etc. Arguably we can still allow calling it twice while making second / future calls no-op.\r\n\r\nI'd suggest we leave it as a separate improvement.",
        "createdAt" : "2019-01-04T20:18:22Z",
        "updatedAt" : "2019-01-04T22:37:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a32c0e8aeca9e6a022faa4f72d679f75214b1868",
    "line" : 298,
    "diffHunk" : "@@ -1,1 +797,801 @@            }, cleanupDelay, cleanupDelay, TimeUnit.MILLISECONDS);\n        } else {\n            throw new IllegalStateException(\"The client is either already started or already stopped, cannot re-start\");\n        }\n    }"
  },
  {
    "id" : "fa3ee244-7af9-4c1a-b9c0-4ea6ff0e6f1d",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-198331265",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f9b44ac-99e3-489a-93d3-28ebf107af9d",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "why not go ahead and do this now?",
        "createdAt" : "2019-01-30T22:04:59Z",
        "updatedAt" : "2019-01-30T22:04:59Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +381,385 @@            // admin client is shared, so we can actually move it\n            // to result.putAll(adminClient.metrics()).\n            // we did it intentionally just for flexibility.\n            result.putAll(thread.adminClientMetrics());\n        }"
  },
  {
    "id" : "0830f5d5-da3f-4fe1-8170-fe221f75f7cc",
    "prId" : 6461,
    "prUrl" : "https://github.com/apache/kafka/pull/6461#pullrequestreview-215916722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05efc1ce-4b69-4048-97bb-f21cead50783",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: empty line after 657 here.",
        "createdAt" : "2019-03-19T00:40:51Z",
        "updatedAt" : "2019-04-20T01:33:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "355ddd92a45fc8c65cdb5893cee7dd161075d843",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +655,659 @@            }\n        }\n    }\n\n    private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,"
  },
  {
    "id" : "a4263d1c-80fb-4a1d-b626-835b9507125a",
    "prId" : 6468,
    "prUrl" : "https://github.com/apache/kafka/pull/6468#pullrequestreview-215893734",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c204ba4-54e1-4e57-b196-942088ecee5f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a minor cleanup piggy-backed in this PR: since in `setState` we already exclude `ERROR` to transit to itself so that the user's registered listener is triggered multiple times necessarily, we can actually exclude this transition all together in the diagram.",
        "createdAt" : "2019-03-18T23:01:52Z",
        "updatedAt" : "2019-03-19T04:30:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7449162b09d8bca28d3cef40e03421a7c33d43c6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +192,196 @@     */\n    public enum State {\n        CREATED(1, 3), REBALANCING(2, 3, 5), RUNNING(1, 3, 5), PENDING_SHUTDOWN(4), NOT_RUNNING, ERROR(3);\n\n        private final Set<Integer> validTransitions = new HashSet<>();"
  },
  {
    "id" : "e755c4d3-421f-43e6-b0fe-2c02e160f6de",
    "prId" : 6884,
    "prUrl" : "https://github.com/apache/kafka/pull/6884#pullrequestreview-270272845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d7dca36f-adba-490a-8b1d-399a5745ad2e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The FSM change on this and StreamThread is a quick fix due to onPartitionsRevoked not being triggered as always now. When we made the change on StreamsPartitionAssignor in a follow-up PR we should refactor this FSM further. cc @ableegoldman ",
        "createdAt" : "2019-08-02T16:19:14Z",
        "updatedAt" : "2019-08-08T21:28:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6041a792f58b0b9a38983a60e052e9018319a6e6",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +195,199 @@    //       state diagram more thoroughly after we refactor StreamsPartitionAssignor to support COOPERATIVE\n    public enum State {\n        CREATED(1, 2, 3), REBALANCING(2, 3, 5), RUNNING(1, 2, 3, 5), PENDING_SHUTDOWN(4), NOT_RUNNING, ERROR(3);\n\n        private final Set<Integer> validTransitions = new HashSet<>();"
  },
  {
    "id" : "b896f773-7a6f-46a7-84b9-7450ca6bfd1b",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-292070339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b139456-6836-4166-be2b-0947d0bfaa52",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "It's not necessary to add the transition CREATED -> RUNNING because we always go through REBALANCING first in `KafkaStreams#start`",
        "createdAt" : "2019-09-23T21:41:13Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +191,195 @@     */\n    public enum State {\n        CREATED(1, 3),          // 0\n        REBALANCING(2, 3, 5),   // 1\n        RUNNING(1, 2, 3, 5),    // 2"
  },
  {
    "id" : "437a5b7b-e9f7-4015-83f7-746a913167e0",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-294840947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b042124-5cdb-4b4b-955b-8dbce3b60178",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Here I add the instance-level metrics.",
        "createdAt" : "2019-09-30T09:09:25Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +686,690 @@        log.info(\"Kafka Streams version: {}\", ClientMetrics.version());\n        log.info(\"Kafka Streams commit ID: {}\", ClientMetrics.commitId());\n\n        // re-write the physical topology according to the config\n        internalTopologyBuilder.rewriteTopology(config);"
  },
  {
    "id" : "b4beae1c-aed8-4da3-8388-6daa4e607197",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-294840947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b97435a-bf9e-4b39-9564-61cc34f2e8cf",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "`StreamsMetricsImpl` is now created at client level and not on thread level anymore.",
        "createdAt" : "2019-09-30T09:10:11Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +677,681 @@        metrics = new Metrics(metricConfig, reporters, time);\n        streamsMetrics =\n            new StreamsMetricsImpl(metrics, clientId, config.getString(StreamsConfig.BUILT_IN_METRICS_VERSION_CONFIG));\n        streamsMetrics.setRocksDBMetricsRecordingTrigger(rocksDBMetricsRecordingTrigger);\n        ClientMetrics.addVersionMetric(streamsMetrics);"
  },
  {
    "id" : "323f4fec-9d03-4cdd-a5e2-5938cf78cb6c",
    "prId" : 7416,
    "prUrl" : "https://github.com/apache/kafka/pull/7416#pullrequestreview-296093410",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d540661d-a966-45be-b73d-f49e2a82f59f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just going out on a limb here... should we also log the topology description here?",
        "createdAt" : "2019-10-02T04:13:36Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "3b62d30b-ba10-4cb3-9d36-2ad4674894d7",
        "parentId" : "d540661d-a966-45be-b73d-f49e2a82f59f",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I thought, we already do, but I couldn't find any output in a log file that I have locally. I would be in favour of logging the topology because it helps us during on-call. On the other hand, it may pollute the logs. Anyways, could we postpone this discussion to after the release?",
        "createdAt" : "2019-10-02T08:48:14Z",
        "updatedAt" : "2019-10-04T08:23:54Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ab3c0436cf659dd6f76b2b6b5360d327bad385bb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +685,689 @@        ClientMetrics.addStateMetric(streamsMetrics, (metricsConfig, now) -> state);\n        log.info(\"Kafka Streams version: {}\", ClientMetrics.version());\n        log.info(\"Kafka Streams commit ID: {}\", ClientMetrics.commitId());\n\n        // re-write the physical topology according to the config"
  },
  {
    "id" : "de75a4de-e6e3-4806-9348-a11d95a20a3e",
    "prId" : 7417,
    "prUrl" : "https://github.com/apache/kafka/pull/7417#pullrequestreview-295745318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08dff732-6c58-4a89-9459-a6f8d14103f4",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "maybe instead to check that `rocksDBMetricsRecordingTriggerThread` is `null` instead? Here and elsewhere.",
        "createdAt" : "2019-10-01T15:15:16Z",
        "updatedAt" : "2019-10-01T17:20:44Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "cbb82b82-fb21-4e9c-b458-0c20e8a8f5af",
        "parentId" : "08dff732-6c58-4a89-9459-a6f8d14103f4",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Agreed!",
        "createdAt" : "2019-10-01T17:03:46Z",
        "updatedAt" : "2019-10-01T17:20:44Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a3fd4f3c9a945fe9e1a4ed8bdb99c567f0e199b",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +769,773 @@    private static ScheduledExecutorService maybeCreateRocksDBMetricsRecordingService(final String clientId,\n                                                                                      final StreamsConfig config) {\n        if (RecordingLevel.forName(config.getString(METRICS_RECORDING_LEVEL_CONFIG)) == RecordingLevel.DEBUG) {\n            return Executors.newSingleThreadScheduledExecutor(r -> {\n                final Thread thread = new Thread(r, clientId + \"-RocksDBMetricsRecordingTrigger\");"
  },
  {
    "id" : "d6debeb9-2b72-435d-9f1c-04af0110f6fb",
    "prId" : 7483,
    "prUrl" : "https://github.com/apache/kafka/pull/7483#pullrequestreview-301593928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5da74218-2321-42d4-9516-3afe4b351e0f",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I like the addition, we can reuse this when they inevitably do something else we'll need to warn our users about ðŸ˜œ ",
        "createdAt" : "2019-10-14T23:55:55Z",
        "updatedAt" : "2019-10-14T23:56:19Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "07769af5eeca7e9cc35580637706882528c77cc7",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +792,796 @@    }\n\n    private static void maybeWarnAboutCodeInRocksDBConfigSetter(final Logger log,\n                                                                final StreamsConfig config) {\n        if (config.getClass(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG) != null) {"
  },
  {
    "id" : "ac0cd778-e574-413e-8b71-539b44c556a1",
    "prId" : 7961,
    "prUrl" : "https://github.com/apache/kafka/pull/7961#pullrequestreview-344136818",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "@vvcephei @brary I actually have a concern with this overestimation.. Let's take a typical streams deployment with num_standby_replicas =1 ... During the time period, where the lag is fetched when a standby changelog partition is assigned but has not yet processed any events, we will report a really high value that may not lead to IQs being failed (since the store is deemed laggy).. Given a caller that periodically fetches the positions every few seconds would have a non-zero past value already, wonder if it makes sense to not report this partition instead.. i.e we only report lags on store partitions which have begun consumption..  At least for ksqlDB, I am thinking servers can track easily when lag was reported for a given store partition, given server and decide on using that value based on how recently it was updated..  But the values we receive won't be 'jumpy'. End of the day, I am also theorizing how this will behave.. So this is more about which way we want to bias. \r\n\r\n\r\nAcross the cluster, this time period will not in sync with each other and can happen differently. So not sure if this will in-fact provide correct relative order.. ",
        "createdAt" : "2020-01-15T01:40:18Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "9cdb0f54-4372-41c3-a6a8-31d03ef4ee6a",
        "parentId" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks for bringing this up. I'm not totally sure I follow, though...\r\n\r\nLet's say the partition in question has an end offset of 100 and a true \"earliest\" offset of 90 (due to compaction). If an instance has this partition assigned but has not yet recorded any position, we'd report its lag as 100. Another instance that has started processing but only processed one record would be reported with a lag of 9. This doesn't accurately represent the amount-of-work difference between the two instances (which is actually only one record, though the difference in lags is 91), but it _does_ correctly state that the second instance is ahead of the first in freshness.\r\n\r\nI also seems reasonable to not report a lag at all for not-yet-started stores, but then you have to handle the special case in client-side code. I.e., the metadata API would tell you that this instance owns a store, but then there's no lag reported, so maybe there was a rebalance and we lost the store, or maybe we do own the store, but haven't started processing yet... It still seems simpler to me to say \"woah, that lag is really big, like it's lagging by 100% of the topic, maybe I won't query this store\" if I don't want to query really stale data, versus handling the special case to reach the same conclusion.\r\n\r\nRealistically, even if we are still restoring, but the store is still behind by a year (for example), you _still_ wouldn't want to return the results, but rather would have _some_ heuristic of how stale is ok and how stale is too much, which would be able to handle this math just as easily either way.\r\n\r\nOne other thought is that offset values can still be jumpy, due to compaction. So there's nothing to say that there are any records at all between offset 5 and offset 9999. Maybe this is contributing to my feeling that it's ok to just gloss over this case.",
        "createdAt" : "2020-01-16T03:44:46Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2c783e81-5cdd-4ef6-8df6-494838a17d44",
        "parentId" : "a091ddfd-d786-41cd-8079-d71b32dd90f5",
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : ">but it does correctly state that the second instance is ahead of the first in freshness.\r\n\r\nFair. Your argument is if you have not begun work, then you would be behind another instance that has begun work.. \r\n\r\n>reasonable to not report a lag at all for not-yet-started stores, but then you have to handle the special case in client-side code.\r\n\r\nthe client code is going to have to use some mechanism to \"fence\" really bad lag.. i.e full restorations.. My concern was that if we hit this race condition, you would suddenly see a jump to \"oh this replica needs to fully restore\" and then back to the actual lag..\r\n\r\n>One other thought is that offset values can still be jumpy, due to compaction.\r\n\r\nI did think about this a bit.. I think what we have here would work fairly well in the common case, where the active and standby are apart by lag within the `uncompacted` portion of the changelog topic.. \r\n\r\n> So there's nothing to say that there are any records at all between offset 5 and offset 9999.\r\nOnce beyond that, since we just rely on the latest lag value, this is okay.. if there are no records, the restoration will be faster than expected.. but as a relative metric, it's still good.. \r\n\r\nIn all, I am okay sticking with this behavior for now.. We can revisit based on real world experience.. and really build a solid solid implementation in the next month or so.. ",
        "createdAt" : "2020-01-16T18:50:31Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      }
    ],
    "commit" : "026b9dd5f36a78839a5e628cd51d2e98f91313e9",
    "line" : 90,
    "diffHunk" : "@@ -1,1 +1272,1276 @@        log.debug(\"Current end offsets :{}\", allEndOffsets);\n        for (final Map.Entry<TopicPartition, ListOffsetsResultInfo> entry : allEndOffsets.entrySet()) {\n            // Avoiding an extra admin API lookup by computing lags for not-yet-started restorations\n            // from zero instead of the real \"earliest offset\" for the changelog.\n            // This will yield the correct relative order of lagginess for the tasks in the cluster,"
  },
  {
    "id" : "c9dcf1b1-8759-479e-a4bd-9aa1d56393ce",
    "prId" : 7961,
    "prUrl" : "https://github.com/apache/kafka/pull/7961#pullrequestreview-343995216",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "is there a notion of `experimental` APIs in streams? (like some other apache projects like Spark have) I think we can mark this experimental if so, setting the expectations with the user for the next release. ",
        "createdAt" : "2020-01-15T15:56:04Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "e7507d4b-64be-4820-a737-18466d0af29e",
        "parentId" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "There's not. There's \"interface: evolving\", but I think it's only for... interfaces. We already say in the javadoc that the returned values are estimates, so I think we've created enough wiggle room in the correctness of the returned lags. As to whether the method signature itself might change in the future, we'll just have to go the normal route of deprecating and replacing if we want to change it.",
        "createdAt" : "2020-01-15T22:26:18Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "fc91ffaa-7ea8-4b9e-82eb-cbc32679e479",
        "parentId" : "95802c90-abdf-4acb-b92b-80bed9f9ee9d",
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "Okay.. lets stick to what we have. ",
        "createdAt" : "2020-01-16T15:25:04Z",
        "updatedAt" : "2020-01-16T18:51:38Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      }
    ],
    "commit" : "026b9dd5f36a78839a5e628cd51d2e98f91313e9",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +1228,1232 @@     * @return map of store names to another map of partition to {@link LagInfo}s\n     */\n    public Map<String, Map<Integer, LagInfo>> allLocalStorePartitionLags() {\n        final long latestSentinel = -2L;\n        final Map<String, Map<Integer, LagInfo>> localStorePartitionLags = new TreeMap<>();"
  },
  {
    "id" : "370599a0-cfa9-43db-bac3-3bff06d9f7cf",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350590717",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d25acf1c-9ca1-4f9a-b4a8-8b294be83767",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add a `@deprecated` annotation to the JavaDocs:\r\n```\r\n@depreated since 2.5 release; use {@link #store(StoreQueryParams)} instead\r\n``` ",
        "createdAt" : "2020-01-29T22:59:57Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5b6e23e5-a3c0-464c-92df-4f7c0869e8e9",
        "parentId" : "d25acf1c-9ca1-4f9a-b4a8-8b294be83767",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-01-30T05:38:15Z",
        "updatedAt" : "2020-01-30T05:38:15Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1164,1168 @@    /**\n     * @deprecated since 2.5 release; use {@link #store(StoreQueryParams)}  instead\n     */\n    @Deprecated\n    public <T> T store(final String storeName, final QueryableStoreType<T> queryableStoreType) {"
  },
  {
    "id" : "90495dc3-fa5e-446d-bc56-386cd5a730f0",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350589051",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc99487d-cc71-4153-a917-758cbe093349",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should not explain how `StoreQueryParams` works -- this should to into `StoreQueryParams` JavaDocs -- we should just keep the first sentence of the paragraph.",
        "createdAt" : "2020-01-29T23:02:20Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c8432817-732f-45d1-a79c-f0cc082d7a64",
        "parentId" : "dc99487d-cc71-4153-a917-758cbe093349",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-01-30T05:30:58Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +1174,1178 @@     * StoreQueryParams need required parameters to be set, which are {@code storeName} and if\n     * type is accepted by the provided {@link QueryableStoreType#accepts(StateStore) queryableStoreType}.\n     * The returned object can be used to query the {@link StateStore} instances.\n     *\n     * @param storeQueryParams   to set the optional parameters to fetch type of stores user wants to fetch when a key is queried"
  },
  {
    "id" : "f93bfab2-e11a-4e6b-bc0f-afb74ef7c137",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-351884501",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Nit: I would remove this sentence. Should be part of the JavaDocs of `StoreQueryParams`.",
        "createdAt" : "2020-01-30T07:12:36Z",
        "updatedAt" : "2020-01-30T07:43:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "10e1c4af-1891-45cd-af2c-b9619355b4af",
        "parentId" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-02-01T09:55:41Z",
        "updatedAt" : "2020-02-01T09:55:42Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      },
      {
        "id" : "f6a770c3-b994-4e60-9c94-5b763ba16857",
        "parentId" : "32070e23-d035-43a1-963d-7f2d08b2136d",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-02-01T13:31:02Z",
        "updatedAt" : "2020-02-01T13:31:02Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +1173,1177 @@     * Get a facade wrapping the local {@link StateStore} instances with the provided {@link StoreQueryParams}.\n     * StoreQueryParams need required parameters to be set, which are {@code storeName} and if\n     * type is accepted by the provided {@link QueryableStoreType#accepts(StateStore) queryableStoreType}.\n     * The returned object can be used to query the {@link StateStore} instances.\n     *"
  },
  {
    "id" : "c7d6600f-5220-4348-b0ab-1f7e1646e40d",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350616789",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddfc3af3-d14b-4c0f-b653-29c296148d75",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: remove `optional` the object is used to set mandatory and optional parameters. Overall it reads a little bit complicated. Not sure atm how to improve it. Maybe @vinothchandar or @vvcephei have some ideas?",
        "createdAt" : "2020-01-30T07:16:52Z",
        "updatedAt" : "2020-01-30T07:43:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1176,1180 @@     * The returned object can be used to query the {@link StateStore} instances.\n     *\n     * @param storeQueryParams   to set the optional parameters to fetch type of stores user wants to fetch when a key is queried\n     * @return A facade wrapping the local {@link StateStore} instances\n     * @throws InvalidStateStoreException if Kafka Streams is (re-)initializing or a store with {@code storeName} and"
  }
]