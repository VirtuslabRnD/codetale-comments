[
  {
    "id" : "5fe5409b-9fac-448f-b1f6-3bf12e6163d3",
    "prId" : 6661,
    "prUrl" : "https://github.com/apache/kafka/pull/6661#pullrequestreview-234655668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ce266ce-14c4-4bb1-aa51-fcf7637a765b",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "same here",
        "createdAt" : "2019-05-02T17:06:28Z",
        "updatedAt" : "2019-05-02T21:35:44Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "e2c15ce0-981f-4477-9ca1-53bff3ed161f",
        "parentId" : "6ce266ce-14c4-4bb1-aa51-fcf7637a765b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`TimestampedKeyValueStore` vs `TimestampedWindowStore` -- or please elaborate.\r\n\r\nOr do you refer to missing tests? Those seems to be there actually:\r\n - `shouldFindTimestampedKeyValueStoresAsKeyValueStores()`\r\n - `shouldFindTimestampedWindowStoresAsWindowStore()`",
        "createdAt" : "2019-05-02T21:34:35Z",
        "updatedAt" : "2019-05-02T21:35:44Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9ba2a558-c86d-49a6-a6ea-8216855e07b8",
        "parentId" : "6ce266ce-14c4-4bb1-aa51-fcf7637a765b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "referring to my previous comments about the `if/else` but again I read to quickly",
        "createdAt" : "2019-05-07T17:31:10Z",
        "updatedAt" : "2019-05-07T17:45:49Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a69e7d7b38baf9a3478d7856c2b992f99101bc36",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +59,63 @@                            \" because the store is not open. The state store may have migrated to another instances.\");\n                }\n                if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) {\n                    stores.add((T) new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store));\n                } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) {"
  },
  {
    "id" : "bfbfea92-5149-49e9-ac14-a213a52e223b",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-348069849",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39da58bc-6586-4d6c-bbaa-9162f85d7bc9",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "can we do a null check way at the top when the `StoreQueryParams` is built and avoid this special casing here.. ",
        "createdAt" : "2020-01-24T06:53:36Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "cf6a2d2d-b118-4630-a01e-40b342af7a55",
        "parentId" : "39da58bc-6586-4d6c-bbaa-9162f85d7bc9",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Doing this check in stores() leads to an increase in cyclomatic complexity above 16. So, I have added it here.",
        "createdAt" : "2020-01-24T16:25:29Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +89,93 @@\n    private TaskId createKeyTaskId(final String storeName, final Integer partition) {\n        if (partition == null) {\n            return null;\n        }"
  },
  {
    "id" : "5f27add4-42bb-410e-b8a0-e05a781de3f6",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-348445940",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3177dfb9-ea8f-40ac-89c1-af2077cfadf2",
        "parentId" : null,
        "authorId" : "478a572c-b267-486a-b845-4847ccf71f62",
        "body" : "this looks right to me.. (I can't be sure unless I step through the code though :)) ",
        "createdAt" : "2020-01-24T06:56:23Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "478a572c-b267-486a-b845-4847ccf71f62",
        "tags" : [
        ]
      },
      {
        "id" : "ea7a61c0-6696-4ec4-b206-97c2ee6c85d2",
        "parentId" : "3177dfb9-ea8f-40ac-89c1-af2077cfadf2",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "I have added an integration test covering all 4 cases.\r\n\r\n- Fetch a key, by default gets stores for all partitions without stale store. Only active returns the value and standby returns null.\r\n\r\n- Fetch a key from a stale store from a specific partition. If the partition is available and active, it returns the key if not it throws InvalidStateStoreException.\r\n\r\n- Fetch a key with stale stores enabled, active and standby both should return the value.\r\n\r\n- Fetch a key with stale stores and enableda and from a specific partition, active and standby for that partition, both return the value. If you ask the key from a wrong partition, it returns null.",
        "createdAt" : "2020-01-27T05:32:05Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +95,99 @@        final Set<String> sourceTopicsSet = sourceTopics.stream().collect(Collectors.toSet());\n        final Map<Integer, InternalTopologyBuilder.TopicsInfo> topicGroups = internalTopologyBuilder.topicGroups();\n        for (final Map.Entry<Integer, InternalTopologyBuilder.TopicsInfo> topicGroup : topicGroups.entrySet()) {\n            if (topicGroup.getValue().sourceTopics.containsAll(sourceTopicsSet)) {\n                return new TaskId(topicGroup.getKey(), partition.intValue());"
  },
  {
    "id" : "4d29a5e2-c452-4ba4-829a-5db1ff79bd05",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-351921406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05e68652-1d8b-4648-8cc0-52fab43d99bd",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If we only need the source topics names and topic groups, we should not pass in the full `InternalTopologyBuilder` into this class, but only the two pieces we need.",
        "createdAt" : "2020-01-29T23:24:06Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "45ce796d-f317-4780-bfc5-9318da14bde5",
        "parentId" : "05e68652-1d8b-4648-8cc0-52fab43d99bd",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`internalTopologyBuilder.stateStoreNameToSourceTopics()` may return different values over time if the source nodes are regex pattern which means during rebalances we may update the stateStoreNameToSourceTopics mapping.",
        "createdAt" : "2020-01-30T00:18:34Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e997cadd-cde2-4751-bc93-881dc455b10d",
        "parentId" : "05e68652-1d8b-4648-8cc0-52fab43d99bd",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "However the below `topicGroups()` can evolve as well if we have regex source nodes, also for the `stateStoreNameToSourceTopics` it is only used in `StreamsMetadataState` to verify / build the metadata. I think we can actually have this logic inside `InternalTopologyBuilder` and just expose a\r\n\r\n```\r\nList<String> getSourceTopicsForStore(String storeName)\r\n```\r\n\r\n that both here and `StreamsMetadataState` can use. Then we do not need to overkill `stateStoreNameToSourceTopics` anymore.\r\n\r\nThis is just a code style suggestion.",
        "createdAt" : "2020-01-30T00:27:31Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e3a0e2a6-b789-46b9-bd60-96bdae9c499c",
        "parentId" : "05e68652-1d8b-4648-8cc0-52fab43d99bd",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks @guozhangwang -- as this is internal, we can still improve on it in a follow up.",
        "createdAt" : "2020-01-30T07:38:59Z",
        "updatedAt" : "2020-01-30T07:43:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "38df4e17-1fa7-4ce1-9f73-b139d6e25bda",
        "parentId" : "05e68652-1d8b-4648-8cc0-52fab43d99bd",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Thanks @guozhangwang and @mjsax on suggestions here. Now, since these can change during rebalancing, I am assuming just passing source topics names and topic groups will not suffice and we will have to pass complete internalTopologyBuilder. Is that right? I have added `List<String> getSourceTopicsForStore(String storeName)` in InternalTopologyBuilder class though.",
        "createdAt" : "2020-02-02T06:26:31Z",
        "updatedAt" : "2020-02-02T06:26:36Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +92,96 @@            return null;\n        }\n        final List<String> sourceTopics = internalTopologyBuilder.stateStoreNameToSourceTopics().get(storeName);\n        final Set<String> sourceTopicsSet = sourceTopics.stream().collect(Collectors.toSet());\n        final Map<Integer, InternalTopologyBuilder.TopicsInfo> topicGroups = internalTopologyBuilder.topicGroups();"
  },
  {
    "id" : "088da82a-f634-4f62-9f5e-9deda2042425",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350484961",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2696f88d-bbf1-4bbf-86b4-75beda9fa0aa",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "As we are only interested in the source topic ber topicGroup, we should just pass a `Map<Integer, Set<String>>` into this class.",
        "createdAt" : "2020-01-29T23:26:00Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +96,100 @@        final Map<Integer, InternalTopologyBuilder.TopicsInfo> topicGroups = internalTopologyBuilder.topicGroups();\n        for (final Map.Entry<Integer, InternalTopologyBuilder.TopicsInfo> topicGroup : topicGroups.entrySet()) {\n            if (topicGroup.getValue().sourceTopics.containsAll(sourceTopicsSet)) {\n                return new TaskId(topicGroup.getKey(), partition.intValue());\n            }"
  },
  {
    "id" : "5e0c8980-b76c-4a73-9b2d-91ce16901664",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-350595708",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "870eb73b-a84a-4517-99a2-92930b9cfe2f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: missing whitespace -> `isnot`",
        "createdAt" : "2020-01-29T23:27:17Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "002ba72e-6a68-4a56-8c72-1ba3c5a49b9e",
        "parentId" : "870eb73b-a84a-4517-99a2-92930b9cfe2f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "\\cc @vitojeng -- seems this is a new case we should cover in KIP-216?",
        "createdAt" : "2020-01-29T23:27:48Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1f08b1af-01b7-4de1-929c-1bfacfbd3f36",
        "parentId" : "870eb73b-a84a-4517-99a2-92930b9cfe2f",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "I think we should not need update KIP-216. \r\nIn IP-216, because we focus on **stream state** , not stream thread state, so I think this is the same thing like line 66-71, IMO. I would wrap these exception base on stream state at the upper calling level, e.g., CompositeReadOnlyXXXStore.\r\n\r\nDoes this make sense?",
        "createdAt" : "2020-01-30T02:57:11Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "8bcec27a-b7a8-4ecf-9a23-96bef732e7a8",
        "parentId" : "870eb73b-a84a-4517-99a2-92930b9cfe2f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For line 66-71 above, we will throw `StateStoreMigratedException`, right? So I guess, even if it's a slightly different case, I guess you a right that we can also throw a `StateStoreMigratedException` for this case, too.\r\n\r\nDiscussing this question, I am wondering if we should still cover the case when the user passes in a partition number that is not available? This would be a user error similar to passing in a wrong store name?",
        "createdAt" : "2020-01-30T04:31:00Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "84b510ec-ec9e-49cc-a9e3-9bf14ecae62a",
        "parentId" : "870eb73b-a84a-4517-99a2-92930b9cfe2f",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "oh...I just realized what you meant. Yes, we should cover this case in KIP-216, will update KIP.\r\nThanks @mjsax !",
        "createdAt" : "2020-01-30T05:58:40Z",
        "updatedAt" : "2020-01-30T05:58:40Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +101,105 @@        }\n        throw new InvalidStateStoreException(\"Cannot get state store \" + storeName + \" because the requested partition \" + partition + \"is\" +\n                                                \"not available on this instance\");\n    }\n}"
  },
  {
    "id" : "2c9c2618-e4b8-472f-b83f-0a1eca1c6203",
    "prId" : 7984,
    "prUrl" : "https://github.com/apache/kafka/pull/7984#pullrequestreview-354282329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bfe6e0a-136f-44fd-9f59-9f7009da0b71",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we have this check inside the loop? Should we not check this condition once, and only execute the loop if the condition is `false`?\r\n\r\nOr maybe pass a `Collections.singleton(keyTaskId)` into the loop if `keyTaskId != null` ? ",
        "createdAt" : "2020-01-29T23:30:18Z",
        "updatedAt" : "2020-01-30T05:36:55Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "0579289d-2784-479b-a4e6-3b4f715896dd",
        "parentId" : "1bfe6e0a-136f-44fd-9f59-9f7009da0b71",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Seems you missed this commnet? If you disagree with my comment, can you elaborate why (maybe I am missing something)?",
        "createdAt" : "2020-01-30T07:38:24Z",
        "updatedAt" : "2020-01-30T07:43:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "e77f152c-f236-46ee-abb0-17c8a133ee1e",
        "parentId" : "1bfe6e0a-136f-44fd-9f59-9f7009da0b71",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "If keyTaskId is null(user wants all servable stores) -> loop over all tasks and return the list of stores.\r\nIf keyTaskId is not null(user wants a specific servable store) -> find the store from the specific task, by looping over all tasks and matching when keyTaskId matches the current task in loop.\r\n\r\nSo, probably I can write it as:\r\n`if (keyTaskId != null) {`\r\n`for (final Task streamTask : tasks.values()) {`\r\n`if (keyTaskId.equals(streamTask.id()) { `\r\n`return streamTask.getStore(storeName); `\r\n`}`\r\n`} else {`\r\n`for (final Task streamTask : tasks.values()) {`\r\n`//return list of stores`\r\n`}`\r\n`}`\r\n\r\nBut I feel the current code is more readable than this one.",
        "createdAt" : "2020-02-02T06:06:17Z",
        "updatedAt" : "2020-02-02T06:07:24Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      },
      {
        "id" : "a43ec3e9-d4bd-415b-9dca-c9f375b58ac0",
        "parentId" : "1bfe6e0a-136f-44fd-9f59-9f7009da0b71",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do loop over all tasks? If a user want to query a single partition, we can just lookup the `keyTaskId` in the map `tasks`:\r\n```\r\nif (keyTaskId != null) {\r\n  return task.get(keyTaskId).getStore(storeName);\r\n} else {\r\n  for (final Task streamTask : tasks.values()) {\r\n    //return list of stores\r\n  }\r\n}\r\n```",
        "createdAt" : "2020-02-05T21:19:50Z",
        "updatedAt" : "2020-02-05T21:19:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fddc85ad-eae4-40c2-81ee-a1334ff52405",
        "parentId" : "1bfe6e0a-136f-44fd-9f59-9f7009da0b71",
        "authorId" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "body" : "Done.",
        "createdAt" : "2020-02-06T08:53:52Z",
        "updatedAt" : "2020-02-06T08:53:57Z",
        "lastEditedBy" : "3501d636-ea66-482b-a2ca-f215a3669632",
        "tags" : [
        ]
      }
    ],
    "commit" : "87c5b9c6789e6f77819eecee0400c64d4220356f",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +62,66 @@                if (keyTaskId != null && !keyTaskId.equals(streamTask.id())) {\n                    continue;\n                }\n                final StateStore store = streamTask.getStore(storeName);\n                if (store != null && queryableStoreType.accepts(store)) {"
  },
  {
    "id" : "62a17079-3b0d-492e-9ba0-8286f5b144fa",
    "prId" : 9020,
    "prUrl" : "https://github.com/apache/kafka/pull/9020#pullrequestreview-496110286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6e07a37-4c88-41c0-8733-ff8644b58458",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a great find, thanks!",
        "createdAt" : "2020-09-25T05:00:45Z",
        "updatedAt" : "2020-10-08T08:42:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "049ec22974580acd023f5d06e4cb34bfd4ad935e",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +96,100 @@    }\n\n    private Optional<Task> findStreamTask(final Collection<Task> tasks, final String storeName, final int partition) {\n        return tasks.stream().\n                filter(streamTask -> streamTask.id().partition == partition &&"
  }
]