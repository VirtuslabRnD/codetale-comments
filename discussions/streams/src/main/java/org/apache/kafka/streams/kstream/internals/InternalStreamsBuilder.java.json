[
  {
    "id" : "2ab64dac-e859-4f8f-9eb2-385a658037a3",
    "prId" : 4430,
    "prUrl" : "https://github.com/apache/kafka/pull/4430#pullrequestreview-89538965",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "270aa469-05e4-4827-bd6e-bb102ffc7ff3",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "we should not copy the code from the old `addGlobalStore()` but rather call the old `addGlobalStore()` passing the generated names.",
        "createdAt" : "2018-01-17T18:17:15Z",
        "updatedAt" : "2018-01-31T14:44:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f4728f60d68d61a376113cf4267d7c2c29774b5",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +200,204 @@                                            final ConsumedInternal consumed,\n                                            final ProcessorSupplier stateUpdateSupplier) {\n        // explicitly disable logging for global stores\n        storeBuilder.withLoggingDisabled();\n        final String sourceName = newProcessorName(KStreamImpl.SOURCE_NAME);"
  },
  {
    "id" : "69ff4015-87e3-4b32-ba2f-2e13f0e12177",
    "prId" : 5451,
    "prUrl" : "https://github.com/apache/kafka/pull/5451#pullrequestreview-143793752",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0fdbed28-86c1-42ad-9492-fe19829d1a99",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Traverse up the graph to only update the descendants of key-changing operation that actually require repartitioning. \r\n",
        "createdAt" : "2018-08-06T23:26:40Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "9faa4975e48126bc019e77e03e8ec8ce2f75826d",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +322,326 @@            for (final OptimizableRepartitionNode repartitionNodeToBeReplaced : entry.getValue()) {\n\n                final StreamsGraphNode keyChangingNodeChild = findParentNodeMatching(repartitionNodeToBeReplaced, gn -> gn.parentNodes().contains(keyChangingNode));\n\n                if (keyChangingNodeChild == null) {"
  },
  {
    "id" : "f3d54008-936f-45df-b778-2edc0a88b3ed",
    "prId" : 5451,
    "prUrl" : "https://github.com/apache/kafka/pull/5451#pullrequestreview-145886964",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Actually, Matthias's question is still nagging me... Do we know it's impossible to have two paths back to the keyChangingNode?",
        "createdAt" : "2018-08-10T22:33:51Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6b2573ce-fdbd-41e7-ad20-ef46a0b03151",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I think so, but I'll write a test to verify.",
        "createdAt" : "2018-08-10T22:53:53Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "277e4564-51af-44a1-8d40-f320195ab9c5",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : ">Actually, Matthias's question is still nagging me... Do we know it's impossible to have two paths back to the keyChangingNode\r\n\r\nWell if the key changing node has multiple children then yes, but code currently accounts for this and unless I misunderstand your concern, that's the main focus of this optimization,  taking multiple child nodes which require a repartition and reducing them down to one where possible.\r\n\r\nHaving said that, from thinking over the weekend I did come up with an edge condition concerning using `merge` which I'll address as general comment on this PR.",
        "createdAt" : "2018-08-13T13:53:47Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "ccbccf1f-29a7-48d3-b424-5f8e0a3505d6",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, I think that's what I was talking about. Not multiple child nodes, but multiple parents somewhere on the chain back from `repartitionNodeToBeReplaced` to `keyChangingNode`. \r\n\r\nThis line of code seems to assume that there is always one path back to `keyChangingNode`, but in general, you could have a diamond (since this is a DAG and not a tree). like :\r\n\r\n```\r\nkeyChangingNode\r\n  |        |\r\n  c1       c2\r\n   \\       /\r\n  (something)\r\n       |\r\nrepartitionNodeToBeReplaced\r\n```\r\n\r\nIf this can occur, then there would need to be multiple of `keyChangingNodeChild` which all need to be re-rooted.\r\n\r\nBut I'm not sure it can occur.",
        "createdAt" : "2018-08-13T14:11:40Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0f0153e3-f098-440d-9ca8-62e4d61f4fad",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "oh, actually I think it can. I think this will produce two paths back:\r\n```\r\nchangedKeyStream = stream.map(...)\r\nleft = changedKeyStream.filter(fnA)\r\nright = changedKeyStream.filter(fnB)\r\nmerged = left.merge(right)\r\nmerged.join(otherStream)\r\n```\r\nAnd I *think* this code would only re-root either `left` or `right`, but they should both be re-rooted, right?\r\n\r\nIf so, it might make a good test case.",
        "createdAt" : "2018-08-13T14:20:23Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "20b473c4-cdd3-4ea0-a6a5-2bc4ac951429",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "What you are talking about above is the \"edge condition\" (maybe not an edge condition, but rare?), I was referring to above.\r\n\r\nThis is the case I was thinking of :\r\n\r\n```\r\nupdatedA = originalStream.map(...);\r\nupdatedB = otherStream.map(...);\r\nmerged = updatedA.merge(updatedB)\r\nmerged.groupByKey().windowedBy(....)\r\nmerged.groupByKey().windowedBy(...)\r\n```\r\nAs the code stands right now, we only grab the first key-changing parent node, but in reality, we need to grab both key-changing parent nodes and insert a new repartition node as a child of both.\r\n\r\nI'm planning on updating the PR to handle this case.",
        "createdAt" : "2018-08-13T14:44:01Z",
        "updatedAt" : "2018-08-14T00:17:00Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "274ab377-d1f0-4513-87e4-5476ee41fbe0",
        "parentId" : "55e6f6ff-34d0-4d63-9b40-c8a200ffec1b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Now seeing the example (super helpful) I am wondering if we can/should be more fancy. I think, it's actually three cases:\r\n\r\n```\r\nrekeyed = stream1.map();\r\nmerged = rekeyed.merged(stream2);\r\nmerged.groupByKey()...\r\n```\r\nFor this case, without optimization, we would insert repartition _after_ merge _before_ groupBy -- this mean, we repartition stream2 for no good reason. Could we repartition _before_ merge? Checking first parent might catch this case?\r\n\r\n```\r\nrekeyed = stream1.map();\r\nmerged = stream2.merged(rekeyed); // similar to above put change order of childen\r\nmerged.groupByKey()...\r\n```\r\nThis case is similar, but we might not detect if, if we don't check all parent nodes. Thus, we might miss to insert an repartition topic at all in current code?\r\n\r\n```\r\nrekeyed1 = stream1.map();\r\nrekeyed2 = stream2.map();\r\nmerged = rekeyed1.merged(rekeyed2);\r\nmerged.groupByKey()...\r\n```\r\nFor this case, we should do the repartition _after_ merge -- otherwise, we would create two repartition topics what is not desired (for the case, that `rekeyed1` and `rekeyed2` are not used elsewhere, too). If `rekeyed1` or `rekeyed2` are use like this:\r\n```\r\nrekeyed1 = stream1.map();\r\nrekeyed1.groupByKey()\r\nrekeyed2 = stream2.map();\r\nmerged = rekeyed1.merged(rekeyed2);\r\nmerged.groupByKey()...\r\n```\r\nwe would still need two repartition topics, because we need content of `stream1` not be mixed with `stream2` in line 2. Also, as `rekeyed1` will be repartitions already before merge(), we don't need to repartition again but `stream2` should be repartition on it's own before merge(), too.\r\n\r\nDoes this make sense? (note, that merge requires that key and value type of both input streams are the same, and thus, we can use same Serdes independent where we insert the repartition topic(s))",
        "createdAt" : "2018-08-14T00:56:51Z",
        "updatedAt" : "2018-08-14T00:56:51Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9faa4975e48126bc019e77e03e8ec8ce2f75826d",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +322,326 @@            for (final OptimizableRepartitionNode repartitionNodeToBeReplaced : entry.getValue()) {\n\n                final StreamsGraphNode keyChangingNodeChild = findParentNodeMatching(repartitionNodeToBeReplaced, gn -> gn.parentNodes().contains(keyChangingNode));\n\n                if (keyChangingNodeChild == null) {"
  },
  {
    "id" : "4bf83aa9-a102-4041-95b7-fdb792a0eeb4",
    "prId" : 5451,
    "prUrl" : "https://github.com/apache/kafka/pull/5451#pullrequestreview-146184239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2ac7f8a-e084-4520-9daa-25724f3794c8",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "IMHO  it's more straightforward to build the key-changing to optimizing nodes map as is.  \r\n\r\nThen before optimizing the topology for repartition nodes, we iterate over the map and \"intercept\" any key-changing nodes that have a `merge` node as a child.\r\n\r\nSince the `merge` node sits between the key-changing node and the repartition node(s) we can use the `merge` node as a proxy for all parent key-changing nodes for the associated repartition node children.",
        "createdAt" : "2018-08-14T00:25:33Z",
        "updatedAt" : "2018-08-14T00:31:32Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "eac1d2d6-0916-41fc-8c69-5b2af9860df6",
        "parentId" : "c2ac7f8a-e084-4520-9daa-25724f3794c8",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@mjsax had a comment above that, for the following case:\r\n\r\n```\r\nrekeyed = stream1.map();\r\nmerged = rekeyed.merged(stream2);\r\nmerged.groupByKey()...\r\n```\r\n\r\nWe may want to do 1) repartition stream1, 2) then merge with stream2 on the mapped key, and 3) do aggregation without repartition any more. Whereas in the current approach we would 1) merge mapped stream1 with stream2 first, and 2) do repartition, and then 3) do aggregation.\r\n\r\nBut I think it is not only about optimization efficiency, but also about correctness: Note that merge signature is:\r\n\r\n```\r\nKStream<K, V> merge(final KStream<K, V> stream);\r\n```\r\n\r\nI.e. the merging KStream should have the same key/value type, so the merging operator itself should be also requiring co-partitioning. This makes me thinking that, we should probably think of `merge` also as a `join` from the optimization point of view, that it requires co-partitioning, and hence if there are key-changing operators, we should enforce a repartitioning before merging.\r\n\r\nI know this is not enforced today, which may just be a bug. WDYT?",
        "createdAt" : "2018-08-14T18:02:25Z",
        "updatedAt" : "2018-08-14T18:02:26Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9faa4975e48126bc019e77e03e8ec8ce2f75826d",
    "line" : 192,
    "diffHunk" : "@@ -1,1 +361,365 @@    }\n\n    private void maybeUpdateKeyChangingRepartitionNodeMap() {\n        final Map<StreamsGraphNode, Set<StreamsGraphNode>> mergeNodesToKeyChangers = new HashMap<>();\n        for (final StreamsGraphNode mergeNode : mergeNodes) {"
  },
  {
    "id" : "7f81d0e0-15a2-480b-b8c3-dd28cad0457c",
    "prId" : 5451,
    "prUrl" : "https://github.com/apache/kafka/pull/5451#pullrequestreview-146981875",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd0b932f-607b-4b19-b75e-92a995863dbf",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Since the criterion is StreamsGraphNode::isKeyChangingOperation, I don't see why the call on line 407 is needed: if there is no key changing operation, null would be returned anyway.",
        "createdAt" : "2018-08-15T22:41:11Z",
        "updatedAt" : "2018-08-15T22:41:11Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "bbff7301-f5c2-4d4d-b5d6-602f725487dd",
        "parentId" : "cd0b932f-607b-4b19-b75e-92a995863dbf",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Hmm.. that's a good question. @bbejeck could you take a look?",
        "createdAt" : "2018-08-15T22:48:30Z",
        "updatedAt" : "2018-08-15T22:48:30Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0033e97e-adbc-4107-a5b6-5535d0b0dc90",
        "parentId" : "cd0b932f-607b-4b19-b75e-92a995863dbf",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Yep, I'll take a look and push a minor PR if needed.",
        "createdAt" : "2018-08-16T15:44:30Z",
        "updatedAt" : "2018-08-16T15:44:30Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "764f54f2-88ae-4d9c-abd3-7c758cc8dd5a",
        "parentId" : "cd0b932f-607b-4b19-b75e-92a995863dbf",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "It is needed.  \r\n\r\nWhen we attempt to optimize a key-changing operation, if there are any KStream operations that change the value, between the key-changing operation and the repartition node,  we don't do the optimization.   \r\n\r\nThe call on 407 will retrieve either a value changing or key changing operation from the repartition node.  \r\n\r\nIf the two retrieved nodes aren't equal on line 410, then we won't perform the optimization for this individual repartition node, as the values could have changed types.\r\n\r\nUntil we have serde inheritance in place, we can't safely optimize the repartition due to serialization/deserialization issues with the new value type.\r\n\r\nBut I should add some comments to the method to describe what is going on.\r\n\r\nDoes this make sense?",
        "createdAt" : "2018-08-16T16:33:27Z",
        "updatedAt" : "2018-08-16T16:40:17Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "f7dd3cde-cf59-4b2a-a87a-8bbadfbb5ca4",
        "parentId" : "cd0b932f-607b-4b19-b75e-92a995863dbf",
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "I see what you intended.\r\n\r\nThanks for the response.",
        "createdAt" : "2018-08-16T19:02:52Z",
        "updatedAt" : "2018-08-16T19:02:52Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      }
    ],
    "commit" : "9faa4975e48126bc019e77e03e8ec8ce2f75826d",
    "line" : 239,
    "diffHunk" : "@@ -1,1 +408,412 @@\n        final StreamsGraphNode keyChangingNode = findParentNodeMatching(repartitionNode, StreamsGraphNode::isKeyChangingOperation);\n        if (shouldBeKeyChangingNode != null && shouldBeKeyChangingNode.equals(keyChangingNode)) {\n            return keyChangingNode;\n        }"
  },
  {
    "id" : "6212f5a0-0728-413a-80ae-801e3f7856d1",
    "prId" : 5521,
    "prUrl" : "https://github.com/apache/kafka/pull/5521#pullrequestreview-150181944",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e55519c-eee7-4cbb-8452-0ad58f063a3b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just to keep my bearings... We may be passing in `null` here, which would then get propagated to the children when we call other methods on the `KStream`. And the meaning of the `null` is that we'd look up the default serdes if we actually need them. Right?",
        "createdAt" : "2018-08-27T22:27:59Z",
        "updatedAt" : "2018-10-01T04:30:31Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "c592635e-a4fa-4af3-a36c-31408edf2b47",
        "parentId" : "9e55519c-eee7-4cbb-8452-0ad58f063a3b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "@vvcephei that is correct",
        "createdAt" : "2018-08-28T15:28:29Z",
        "updatedAt" : "2018-10-01T04:30:31Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "1278ae279c9fa20317e55ded8aeb364eab097127",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +101,105 @@\n        return new KStreamImpl<>(name,\n                                 consumed.keySerde(),\n                                 consumed.valueSerde(),\n                                 Collections.singleton(name),"
  },
  {
    "id" : "0f0e9ff8-4e2f-4850-ac2a-94f5044dce98",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-154017902",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang @bbejeck @vvcephei Discovered this by chance -- not sure if fixing this would result in compatibility issues? Thoughts?",
        "createdAt" : "2018-09-09T07:31:26Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9484ad8a-6cd6-40dd-9be3-40fb44555d16",
        "parentId" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good catch.\r\n\r\nIf we are considering topic / store names only, then no. I'd suggest we just fix it right away.",
        "createdAt" : "2018-09-10T16:35:36Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0bb50c22-0b7a-45ac-9fbc-c4602d23dc11",
        "parentId" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Hmm. I'm tracing through the code, but it's certainly safer just to mark it with a `//TODO` and leave it alone.",
        "createdAt" : "2018-09-10T16:50:19Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8aa8d6e2-511a-4ce7-b610-536e71e27134",
        "parentId" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Yeah, I think the only concern would be if the source node name were used for the store, and I don't think it is.",
        "createdAt" : "2018-09-10T17:00:49Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "cfa557a7-798e-45bf-b526-92d3fbade7dc",
        "parentId" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Okay, let's change it here then.",
        "createdAt" : "2018-09-10T17:11:47Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "eefc6042-37a2-4078-b6a8-9a3fae35da05",
        "parentId" : "6e5a2eb6-ae8c-4e95-8c8a-7b969ed35f10",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for verifying that this is a safe change/fix.",
        "createdAt" : "2018-09-11T00:58:02Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +150,154 @@        materialized.withLoggingDisabled();\n        final StoreBuilder storeBuilder = new KeyValueStoreMaterializer<>(materialized).materialize();\n        final String sourceName = newProcessorName(KTableImpl.SOURCE_NAME);\n        final String processorName = newProcessorName(KTableImpl.SOURCE_NAME);\n        final KTableSource<K, V> tableSource = new KTableSource<>(storeBuilder.name());"
  },
  {
    "id" : "755f844e-b659-4a85-839f-fb964f796584",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-159992139",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "194c48da-7aa1-4e77-bf4e-bac2910631e7",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Keep `OptimizableRepartitonNodes` in the same order as they are added.",
        "createdAt" : "2018-09-28T04:59:37Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "ba342020-5df0-42f9-9f7e-3899a30fd067",
        "parentId" : "194c48da-7aa1-4e77-bf4e-bac2910631e7",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Similar to my question about `mergeNodes`, should we go ahead and declare `keyChangingOperationsToOptimizableRepartitionNodes` as a `LinkedHashMap<StreamsGraphNode, LinkedHashSet<OptimizableRepartitionNode>>` to document that the insertion order is preserved at both levels?",
        "createdAt" : "2018-09-28T15:56:52Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "f581776b-232f-4a1e-894a-129abf3cad7c",
        "parentId" : "194c48da-7aa1-4e77-bf4e-bac2910631e7",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack, same as above",
        "createdAt" : "2018-09-28T19:21:19Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +253,257 @@\n        if (node.isKeyChangingOperation()) {\n            keyChangingOperationsToOptimizableRepartitionNodes.put(node, new LinkedHashSet<>());\n        } else if (node instanceof OptimizableRepartitionNode) {\n            final StreamsGraphNode parentNode = getKeyChangingParentNode(node);"
  },
  {
    "id" : "26dab4eb-92f3-4f2f-9016-3a683936b7d2",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-159992197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7eb511f0-e6f9-4bdb-b09b-3cd6ef1f24a9",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Keep the key-changing parent nodes for the merge node in order.",
        "createdAt" : "2018-09-28T05:05:25Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "2c12a497-0779-48b6-b2e9-9c36ffd3ec6b",
        "parentId" : "7eb511f0-e6f9-4bdb-b09b-3cd6ef1f24a9",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "ditto",
        "createdAt" : "2018-09-28T16:03:59Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a816003e-2da3-4e74-99fc-e58ca81e7641",
        "parentId" : "7eb511f0-e6f9-4bdb-b09b-3cd6ef1f24a9",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack, same as above",
        "createdAt" : "2018-09-28T19:21:33Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +370,374 @@        final Map<StreamsGraphNode, Set<StreamsGraphNode>> mergeNodesToKeyChangers = new HashMap<>();\n        for (final StreamsGraphNode mergeNode : mergeNodes) {\n            mergeNodesToKeyChangers.put(mergeNode, new LinkedHashSet<>());\n            final Collection<StreamsGraphNode> keys = keyChangingOperationsToOptimizableRepartitionNodes.keySet();\n            for (final StreamsGraphNode key : keys) {"
  },
  {
    "id" : "d886f1b6-8269-4fdb-a9a7-a71c760a7ff0",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-160084220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8d84e23-97e2-4c17-b294-c395792a1630",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Did we want to give priority to the explicitly named repartition topics?",
        "createdAt" : "2018-09-28T16:07:18Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0422d8a7-30fb-4ab8-8b8e-0deff3822d97",
        "parentId" : "d8d84e23-97e2-4c17-b294-c395792a1630",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I had the same thought, but so far we've only discussed grabbing the first repartition topic name. \r\n I'm inclined to leave as is because 1) users don't care about the name as much as it doesn't change and break the topology and 2) IMHO will add some complexity without a significant benefit",
        "createdAt" : "2018-09-28T21:15:18Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "f821fc03-95ab-49dc-9bf3-daf5617ce2b9",
        "parentId" : "d8d84e23-97e2-4c17-b294-c395792a1630",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ack.\r\n\r\nIt's probably also likely that the user who names some repartition topics names them all; another reason the extra complexity wouldn't buy anything.",
        "createdAt" : "2018-09-29T15:28:25Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +425,429 @@\n    private String getFirstRepartitionTopicName(final Collection<OptimizableRepartitionNode> repartitionNodes) {\n        return repartitionNodes.iterator().next().repartitionTopic();\n    }\n"
  },
  {
    "id" : "e86e348b-8565-49ca-ab06-47e9a4e027db",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-160133384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c3cc04b-7d96-49a5-885a-20065b14aaec",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: why does left hand side needs to specify classed instead of interface?",
        "createdAt" : "2018-09-29T23:54:38Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a5115026-9fab-4f4f-9f60-b902901da78c",
        "parentId" : "5c3cc04b-7d96-49a5-885a-20065b14aaec",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I suggested this.\r\n\r\nWhile it is normally better to use an interface on the LHS, it should only be done if the interface provides the correct semantics. I.e., you should be able to swap out any two implementations of the interface and maintain correct behavior.\r\n\r\nNormally, when we work with Maps or Sets, we do indeed need just the semantics they promise (i.e., a k/v mapping, or the set property), and we could in theory use any implementation without changing the correctness of the program.\r\n\r\nBut in this case, it seemed like the correct behavior of this class depends on maintaining these collections in insertion order. Unfortunately, Java does not have an interface for an ordered Map or Set. Therefore, the most general \"interface\" that provides the correct semantics is actually just the implicit interface of LinkedHashMap/Set itself.",
        "createdAt" : "2018-09-30T14:39:15Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "cf056416-c077-423f-a66a-b26aac7be457",
        "parentId" : "5c3cc04b-7d96-49a5-885a-20065b14aaec",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack. Thanks for clarification.",
        "createdAt" : "2018-09-30T22:39:26Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c47a2db0-0777-4d8e-8898-52529dbea3ac",
        "parentId" : "5c3cc04b-7d96-49a5-885a-20065b14aaec",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Additionally, I would in most circumstances agree with specifying the interface, but since these are private variables on an internal class, there is no \"leaking\" of an implementation.",
        "createdAt" : "2018-09-30T23:46:58Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +61,65 @@\n    private final AtomicInteger buildPriorityIndex = new AtomicInteger(0);\n    private final LinkedHashMap<StreamsGraphNode, LinkedHashSet<OptimizableRepartitionNode>> keyChangingOperationsToOptimizableRepartitionNodes = new LinkedHashMap<>();\n    private final LinkedHashSet<StreamsGraphNode> mergeNodes = new LinkedHashSet<>();\n"
  },
  {
    "id" : "2d8dc055-638c-4eea-b94a-8268abd260ca",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-160117130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61978735-abd7-418e-8af9-a41169105a72",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why is `Set` not sufficient? ",
        "createdAt" : "2018-09-29T23:55:17Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "df346a4b-10e0-428f-abf6-055bf8669bdc",
        "parentId" : "61978735-abd7-418e-8af9-a41169105a72",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is also my fault... see https://github.com/apache/kafka/pull/5709#discussion_r221461753",
        "createdAt" : "2018-09-30T14:39:48Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +307,311 @@        maybeUpdateKeyChangingRepartitionNodeMap();\n\n        for (final Map.Entry<StreamsGraphNode, LinkedHashSet<OptimizableRepartitionNode>> entry : keyChangingOperationsToOptimizableRepartitionNodes.entrySet()) {\n\n            final StreamsGraphNode keyChangingNode = entry.getKey();"
  },
  {
    "id" : "58c8e43c-ea46-4c9d-8593-4a27fddf23f4",
    "prId" : 5709,
    "prUrl" : "https://github.com/apache/kafka/pull/5709#pullrequestreview-160117141",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "298328fe-9f3a-48ec-b725-479dcf48b935",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why not `Set` left hand side?",
        "createdAt" : "2018-09-29T23:55:43Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "32c5f753-afda-4e66-81d5-29e1aba27bf2",
        "parentId" : "298328fe-9f3a-48ec-b725-479dcf48b935",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is also my fault... see https://github.com/apache/kafka/pull/5709#discussion_r221461753",
        "createdAt" : "2018-09-30T14:40:14Z",
        "updatedAt" : "2018-10-02T03:08:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "1865cefcf62b3da85b2bff112296d49717891c34",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +383,387 @@            final StreamsGraphNode mergeKey = entry.getKey();\n            final Collection<StreamsGraphNode> keyChangingParents = entry.getValue();\n            final LinkedHashSet<OptimizableRepartitionNode> repartitionNodes = new LinkedHashSet<>();\n            for (final StreamsGraphNode keyChangingParent : keyChangingParents) {\n                repartitionNodes.addAll(keyChangingOperationsToOptimizableRepartitionNodes.get(keyChangingParent));"
  },
  {
    "id" : "d4a8e74b-ef42-4aed-a615-464d25db14b8",
    "prId" : 5779,
    "prUrl" : "https://github.com/apache/kafka/pull/5779#pullrequestreview-163625802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bfbf2c4-d4f8-4752-b6f7-655c1dd95e4e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Removed `S` template since we will always need a key-value store for this API (the MaterializedInternal indicates that already).",
        "createdAt" : "2018-10-11T02:06:34Z",
        "updatedAt" : "2018-12-09T06:42:30Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d02ad5bab3f2cf4ae2c11457e8dfe099d3a4b12",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +109,113 @@    }\n\n    public <K, V> KTable<K, V> table(final String topic,\n                                     final ConsumedInternal<K, V> consumed,\n                                     final MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materialized) {"
  },
  {
    "id" : "70d25476-7d66-4545-aa84-0c3e39fd331a",
    "prId" : 5779,
    "prUrl" : "https://github.com/apache/kafka/pull/5779#pullrequestreview-163625802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b9f6f95-279b-4037-afdf-edfbf124465e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Minor fixes to remove unchecked warnings, ditto below.",
        "createdAt" : "2018-10-11T02:07:02Z",
        "updatedAt" : "2018-12-09T06:42:30Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d02ad5bab3f2cf4ae2c11457e8dfe099d3a4b12",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +151,155 @@        final KTableSource<K, V> tableSource = new KTableSource<>(storeName, storeName);\n\n        final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(tableSource, processorName);\n\n        final TableSourceNode<K, V> tableSourceNode = TableSourceNode.<K, V>tableSourceNodeBuilder()"
  },
  {
    "id" : "71aef3f2-920f-4ff2-bc4c-95f5cdf4c20d",
    "prId" : 5779,
    "prUrl" : "https://github.com/apache/kafka/pull/5779#pullrequestreview-163625802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa9bf256-bd45-4aeb-ab9f-47ca5f7ece82",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "As commented here, for GlobalKTables we should always materialize so we set the queryable name to store name at the first place to enforce that.",
        "createdAt" : "2018-10-11T02:07:44Z",
        "updatedAt" : "2018-12-09T06:42:30Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d02ad5bab3f2cf4ae2c11457e8dfe099d3a4b12",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +147,151 @@        final String sourceName = newProcessorName(KTableImpl.SOURCE_NAME);\n        final String processorName = newProcessorName(KTableImpl.SOURCE_NAME);\n        // enforce store name as queryable name to always materialize global table stores\n        final String storeName = materialized.storeName();\n        final KTableSource<K, V> tableSource = new KTableSource<>(storeName, storeName);"
  },
  {
    "id" : "bdeed735-df55-4fa4-ba8b-5db98b4298cb",
    "prId" : 6410,
    "prUrl" : "https://github.com/apache/kafka/pull/6410#pullrequestreview-216752499",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "663ed516-9d37-41f4-8a94-662d789f7857",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "appending `KTable` source operators with `-table-source` is not in the KIP, so we'll either need to remove this or update the KIP",
        "createdAt" : "2019-03-12T19:06:57Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "f98348c8-5bf0-4777-b2a4-1e096d5fa8e5",
        "parentId" : "663ed516-9d37-41f4-8a94-662d789f7857",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think we need to use some suffix because otherwise we would generate two names, ie, end up with a naming conflict -- problem is, that a `KTable` results in two processors and we need a name for each.",
        "createdAt" : "2019-03-20T00:10:29Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3ad7d395-236e-4e89-b4bd-af899fcda202",
        "parentId" : "663ed516-9d37-41f4-8a94-662d789f7857",
        "authorId" : "8090918c-29d3-43df-b67b-9b52e0bfe240",
        "body" : "@bbejeck actually, the `table()` method creates one SourceNode and one ProcessorNode. We need a way to differentiate those two nodes. I should update the KIP to mention this particularity.",
        "createdAt" : "2019-03-20T09:02:23Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "8090918c-29d3-43df-b67b-9b52e0bfe240",
        "tags" : [
        ]
      },
      {
        "id" : "f0b03d54-576d-4964-bddc-6405be2fb8e7",
        "parentId" : "663ed516-9d37-41f4-8a94-662d789f7857",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Ack, I get it now.  Thanks for clarifying.",
        "createdAt" : "2019-03-20T14:23:42Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "6836d5c194464a200fe5edbc4500ef046a60d794",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +116,120 @@                .orElseGenerateWithPrefix(this, KStreamImpl.SOURCE_NAME);\n        final String tableSourceName = new NamedInternal(consumed.name())\n                .suffixWithOrElseGet(\"-table-source\", () -> newProcessorName(KTableImpl.SOURCE_NAME));\n        final KTableSource<K, V> tableSource = new KTableSource<>(materialized.storeName(), materialized.queryableStoreName());\n        final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(tableSource, tableSourceName);"
  },
  {
    "id" : "e4d8fb9c-b72a-4f0c-b35e-acb001ad90d4",
    "prId" : 6410,
    "prUrl" : "https://github.com/apache/kafka/pull/6410#pullrequestreview-218583738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a7ec777-b66f-48a0-95d0-49999d4c767b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I am personally a little confused what `orElseGenerateWithPrefix` means? It's a personal preference, but I don't think it's easy to read. Similar for `suffixWithOrElseGet`. (Maybe it's just me, being not use to fancy Java8 constructs that are mimicked here...)\r\n\r\nCurious to hear what others think.",
        "createdAt" : "2019-03-20T18:08:53Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "39e5ec96-3aaa-4625-a11f-3e04928376f5",
        "parentId" : "5a7ec777-b66f-48a0-95d0-49999d4c767b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I'm ok with the names, but I don't have a strong opinion.  We still have time to address between now and the final PR though.",
        "createdAt" : "2019-03-25T21:03:06Z",
        "updatedAt" : "2019-04-18T08:31:45Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "6836d5c194464a200fe5edbc4500ef046a60d794",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +80,84 @@                                       final ConsumedInternal<K, V> consumed) {\n\n        final String name = new NamedInternal(consumed.name()).orElseGenerateWithPrefix(this, KStreamImpl.SOURCE_NAME);\n        final StreamSourceNode<K, V> streamSourceNode = new StreamSourceNode<>(name, topics, consumed);\n"
  },
  {
    "id" : "6f7bd0f5-b824-4d39-a1a0-c0f1cb517dbc",
    "prId" : 6413,
    "prUrl" : "https://github.com/apache/kafka/pull/6413#pullrequestreview-291344840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddd23e2f-908a-4542-989e-99b6d30a4435",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Would this result in a different name for the source than the prior code? (Not sure if it matters...)",
        "createdAt" : "2019-08-22T15:43:26Z",
        "updatedAt" : "2019-09-09T20:35:43Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "db237c91-5601-4c09-b0f5-80724a3c6411",
        "parentId" : "ddd23e2f-908a-4542-989e-99b6d30a4435",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Hey @fhussonnois or @bbejeck , what do you think about this?",
        "createdAt" : "2019-09-20T19:04:03Z",
        "updatedAt" : "2019-09-20T19:05:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "ccdf00c957c81272ad8c12040efb8adcd9302f0b",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +162,166 @@\n        final String sourceName = named\n                .suffixWithOrElseGet(TABLE_SOURCE_SUFFIX, this, KStreamImpl.SOURCE_NAME);\n\n        final String processorName = named"
  },
  {
    "id" : "170b1928-9e4b-4f23-861b-c140d2c0d9ab",
    "prId" : 7117,
    "prUrl" : "https://github.com/apache/kafka/pull/7117#pullrequestreview-269217765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b11beff-9be3-4394-9a2a-b28b80c935ba",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "The maps' names involved are very lengthy such as `keyChangingOperationsToOptimizableRepartitionNodes`, `mergeNodeKeyChangingParentsToRemove`, , shall we comment on their individual functionalities?",
        "createdAt" : "2019-07-29T20:04:13Z",
        "updatedAt" : "2019-07-29T20:06:30Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "e8b23558-faa6-4cb1-885b-89c786013f05",
        "parentId" : "2b11beff-9be3-4394-9a2a-b28b80c935ba",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2019-07-31T19:07:00Z",
        "updatedAt" : "2019-07-31T19:09:07Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d0e23f78780db4d337797326237807e760ba429",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +383,387 @@        for (final StreamsGraphNode mergeNode : mergeNodes) {\n            mergeNodesToKeyChangers.put(mergeNode, new LinkedHashSet<>());\n            final Collection<StreamsGraphNode> keys = keyChangingOperationsToOptimizableRepartitionNodes.keySet();\n            for (final StreamsGraphNode key : keys) {\n                final StreamsGraphNode maybeParentKey = findParentNodeMatching(mergeNode, node -> node.parentNodes().contains(key));"
  },
  {
    "id" : "3f29215d-edfa-4777-afcc-86dd3c75ddd4",
    "prId" : 7117,
    "prUrl" : "https://github.com/apache/kafka/pull/7117#pullrequestreview-269217765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a92531ff-c9b7-4149-a353-127e214ed61b",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Same here, add a comment on why we need to remove these nodes",
        "createdAt" : "2019-07-29T20:06:25Z",
        "updatedAt" : "2019-07-29T20:06:30Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "8f18b812-f8e1-42a8-9381-3b1be8d3305c",
        "parentId" : "a92531ff-c9b7-4149-a353-127e214ed61b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2019-07-31T19:06:46Z",
        "updatedAt" : "2019-07-31T19:09:07Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d0e23f78780db4d337797326237807e760ba429",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +403,407 @@        }\n\n        for (final StreamsGraphNode mergeNodeKeyChangingParent : mergeNodeKeyChangingParentsToRemove) {\n            keyChangingOperationsToOptimizableRepartitionNodes.remove(mergeNodeKeyChangingParent);\n        }"
  },
  {
    "id" : "62d234eb-5489-4229-9cc4-e2cb2d620f54",
    "prId" : 7117,
    "prUrl" : "https://github.com/apache/kafka/pull/7117#pullrequestreview-269217765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8631cd33-6e19-4436-a31d-b3e1ec3dbf50",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The stack trace on the ticket indicate that the NPE is thrown in this line, because `keyChangingOperationsToOptimizableRepartitionNodes.get(keyChangingParent)` returns `null` -- can you elaborate why it becomes `null`?\r\n\r\nFrom my current understanding, `keyChangingParents` should be a `Set` and hence we should get each item once and remove it once from `keyChangingOperationsToOptimizableRepartitionNodes` (in the old code). Why would we `get()` the same item twice? Seems I am missing something.",
        "createdAt" : "2019-07-30T20:49:58Z",
        "updatedAt" : "2019-07-30T20:49:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "409bfbb4-706e-4dc2-9f66-1fdee84f74b0",
        "parentId" : "8631cd33-6e19-4436-a31d-b3e1ec3dbf50",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "This is due to a single key changing node having multiple `merge` child nodes.  We build a map where the keys are merge nodes and point to a collection of key changing parents, hence we need to wait to remove from the map until we've dropped out of the loop.  cf https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java#L380-L389\r\n\r\nI'm not completely sure of this design now, I'm revisiting it at the moment, but IMHO it's beyond the scope of this PR.\r\n",
        "createdAt" : "2019-07-31T18:58:07Z",
        "updatedAt" : "2019-07-31T19:09:07Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d0e23f78780db4d337797326237807e760ba429",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +397,401 @@            final LinkedHashSet<OptimizableRepartitionNode> repartitionNodes = new LinkedHashSet<>();\n            for (final StreamsGraphNode keyChangingParent : keyChangingParents) {\n                repartitionNodes.addAll(keyChangingOperationsToOptimizableRepartitionNodes.get(keyChangingParent));\n                mergeNodeKeyChangingParentsToRemove.add(keyChangingParent);\n            }"
  }
]