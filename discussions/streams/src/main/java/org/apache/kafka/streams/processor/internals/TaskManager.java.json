[
  {
    "id" : "2e9b01c3-ad71-4ac3-b790-6b8b4663d0ee",
    "prId" : 4343,
    "prUrl" : "https://github.com/apache/kafka/pull/4343#pullrequestreview-86074571",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccc1c4a9-0aa4-4de8-86df-53f0dc933cca",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why this change? AFAIK, `unsubscribe()` will never throw.",
        "createdAt" : "2017-12-27T21:37:59Z",
        "updatedAt" : "2018-01-02T02:05:30Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fff882b8-f475-4bf0-be3d-436f9ad404c3",
        "parentId" : "ccc1c4a9-0aa4-4de8-86df-53f0dc933cca",
        "authorId" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "body" : "It throws in the test since the consumer was never opened.",
        "createdAt" : "2018-01-02T01:55:21Z",
        "updatedAt" : "2018-01-02T02:05:30Z",
        "lastEditedBy" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "tags" : [
        ]
      }
    ],
    "commit" : "5902a645c8eb9fc9f25f3c7076a0acc7d1e5def3",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +277,281 @@        try {\n            restoreConsumer.unsubscribe();\n        } catch (final RuntimeException fatalException) {\n            firstException.compareAndSet(null, fatalException);\n        }"
  },
  {
    "id" : "e5a27415-476f-4ef2-aa0d-f2014179cab1",
    "prId" : 4636,
    "prUrl" : "https://github.com/apache/kafka/pull/4636#pullrequestreview-113914060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4633a886-67b0-4ee6-be3e-f9b80cc3b951",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think this can still be package-private.",
        "createdAt" : "2018-04-19T21:56:03Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2db233ae-5d13-457f-bf5f-f81f77664c27",
        "parentId" : "4633a886-67b0-4ee6-be3e-f9b80cc3b951",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Unfortunately not. We need access in `FutureStreamsPartitionAssignor` that is in a different package.",
        "createdAt" : "2018-04-20T09:44:55Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a87bd5254155a9d60ba479371305ddaae99282d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +43,47 @@import static java.util.Collections.singleton;\n\npublic class TaskManager {\n    // initialize the task list\n    // activeTasks needs to be concurrent as it can be accessed"
  },
  {
    "id" : "46c2ea2a-f736-41ed-ba76-88b31a01e1b4",
    "prId" : 4909,
    "prUrl" : "https://github.com/apache/kafka/pull/4909#pullrequestreview-117689380",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7310105a-9031-4324-b6b3-140c53ead153",
        "parentId" : null,
        "authorId" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "body" : "ditto",
        "createdAt" : "2018-05-04T17:22:26Z",
        "updatedAt" : "2018-05-04T21:46:46Z",
        "lastEditedBy" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9abf1fea8a9e8c80b3f736aecb7a5445a9a4e5f",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +459,463 @@    public String toString(final String indent) {\n        final StringBuilder builder = new StringBuilder();\n        builder.append(\"TaskManager\\n\");\n        builder.append(indent).append(\"\\tMetadataState:\\n\");\n        builder.append(streamsMetadataState.toString(indent + \"\\t\\t\"));"
  },
  {
    "id" : "62af1781-8e8e-47c5-90b3-135b909b1ca1",
    "prId" : 6113,
    "prUrl" : "https://github.com/apache/kafka/pull/6113#pullrequestreview-206979987",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we close those tasks instead of just suspending them? Could we close them only if they are not re-assigned?",
        "createdAt" : "2019-01-14T17:41:42Z",
        "updatedAt" : "2019-02-22T01:03:34Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f0311874-95ec-4cb9-9e9d-6f7acd70e88d",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The life time of a task is:\r\n\r\ncreated -> [initializeStateStores] -> restoring (writes to the initialized state stores) -> [initializeTopology] -> running -> [closeTopology] -> suspended -> [closeStateManager] -> dead\r\n\r\nI.e. the restoring tasks do not have topology initialized at all, whereas `suspend` call is just trying to closeTopology.",
        "createdAt" : "2019-02-22T00:56:53Z",
        "updatedAt" : "2019-02-22T01:03:34Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b353f98c-2a22-4188-9de8-62d53ae28015",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ok, but why can't we keep restoring task open than, and hope they get reassigned so we can continue restoring them?",
        "createdAt" : "2019-02-22T01:40:43Z",
        "updatedAt" : "2019-02-22T01:40:43Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "df40113c-6ddf-4334-8abd-1d371c0d3eb6",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yes we can, the issue is that today we clear all the `store-restorers` hence there's an issue.\r\n\r\nWe can, of course do some optimizations like `do not close restoring tasks, and also do not clear their corresponding restorers as well`, but this is out of the scope of this PR and I want to address it separately.\r\n\r\ncc @vvcephei ",
        "createdAt" : "2019-02-22T18:46:40Z",
        "updatedAt" : "2019-02-22T18:47:53Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b26be70b-2b94-4472-9847-b54e6fa3e9f8",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack",
        "createdAt" : "2019-02-22T18:48:47Z",
        "updatedAt" : "2019-02-22T18:48:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "447a9bb3-1718-4b0a-b62a-24cd6ad26bb4",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang Can you create a Jira to track this cleanup?",
        "createdAt" : "2019-02-22T18:55:39Z",
        "updatedAt" : "2019-02-22T18:55:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9607b351-b286-4a62-9e68-227482116219",
        "parentId" : "709aa2b6-546e-4e1a-951f-9505086aef34",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yup: https://issues.apache.org/jira/browse/KAFKA-7985",
        "createdAt" : "2019-02-22T19:07:08Z",
        "updatedAt" : "2019-02-22T19:07:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "912a45642a92f4298d203d5c4eda6a1678208c05",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +244,248 @@        // for those restoring and still assigned tasks, they will be re-created\n        // in addStreamTasks.\n        firstException.compareAndSet(null, active.closeAllRestoringTasks());\n        changelogReader.reset();\n"
  },
  {
    "id" : "a41809f3-78d6-451c-b62b-ad84c1d42d4b",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-291486026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "294c4f97-377a-4c8f-afaf-e8d7c4baa1fb",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In our current code we check `if (assignment.containsAll(partitions)) {` and if the passed in partitions does not include all the partitions of the task, we treat it as `log.warn(\"Task {} owned partitions {} are not contained in the assignment {}\", taskId, partitions, assignment);` and create it as new (but I think the existing code did not close the old tasks from suspended, which is a bug..).\r\n\r\nPondering on it now, I'm not sure what would be the best solution to this, since such things would only happen if 1) users changed the partition-grouper, which is very rare and we are deprecating that API, and 2) users changed their code hence changed the topology, in which case `taskA_B` no longer mean the same thing at all. In either case, we are facing a much more severe issue than resuming suspended tasks.\r\n\r\nMaybe for now it's better to still log a WARN and not resume the task?",
        "createdAt" : "2019-09-20T17:31:33Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f3a8ff6c-fd84-48e5-b920-fcd06b3751c9",
        "parentId" : "294c4f97-377a-4c8f-afaf-e8d7c4baa1fb",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Yeah the implications of changing the task -> partition mapping seem pretty hairy (hence wanting to deprecate PartitionGrouper ASAP -- thanks @mjsax 😉)\r\nI was a bit worried about throwing an exception here, but if you follow the code path it really shouldn't be possible for a partition not to be found. The partition -> task and task -> partition maps are created at the same time from the assigned partitions list. There's no way for a task to be assigned partitions that aren't in the assignment.\r\nIf the mapping does change, we catch this in `maybeResumeSuspenedTask` and close/recreate the task",
        "createdAt" : "2019-09-22T01:47:32Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 405,
    "diffHunk" : "@@ -1,1 +574,578 @@    private Set<TaskId> partitionsToTaskSet(final Collection<TopicPartition> partitions) {\n        final Set<TaskId> taskIds = new HashSet<>();\n        for (final TopicPartition tp : partitions) {\n            final TaskId id = partitionsToTaskId.get(tp);\n            if (id != null) {"
  },
  {
    "id" : "ea867a60-2ac6-442a-814f-b46db53adda8",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-292743295",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Related to my other comments: if we assume that the same thread never have active and standby of the same task at the same time then we can simplify this a bit: first we can check inside `onAssignment` to make sure it is indeed the case, and if not treat it as a fatal error. Then we can be ensured that the partitions do not have any overlaps and we can just \"blindly\" remove partitions as we remove standbys since if they are not assigned yet, the removal would be safely a no-op. The only usage of this would be line 124 below.",
        "createdAt" : "2019-09-20T18:00:19Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "fc58d8f8-f8d2-42b1-b4a4-50160f010630",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Not sure I follow, why does it help us to check this in `onAssignment`? We should be confident there is no overlap (unless there is a bug, might be good to verify somewhere I suppose) -- `restoreConsumerAssignedStandbys` is meant as a flag whether it's assigned standby OR active, ie this would be false if it is assigned any active.",
        "createdAt" : "2019-09-22T01:51:15Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "ebc89809-dd22-4189-834b-5028cb0f3a8b",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Technically it should always be safe to remove any revoked standby or actives since its a no-op if not assigned them anyway. This is what the PR was doing originally, which was \"accidentally correct\" since I wasn't aware it was only assigned one or the other.",
        "createdAt" : "2019-09-22T01:52:30Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "780ea210-ba71-444b-b0e2-db6862261d59",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "My only motivation is to simplify the usage of the flag a bit :) I feel that some conditions on this flag is not necessary.",
        "createdAt" : "2019-09-23T17:13:20Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "42d3614f-2d3d-4440-a576-8305c64d6150",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I was thinking of it more as a slight optimization to avoid making a copy of the assignment and re-assigning, but maybe it's better to play it safe & decrease complexity by just always removing the partitions",
        "createdAt" : "2019-09-24T00:15:06Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "484a791c-a76f-4047-a335-61736d9e82a2",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Moved the removing changelogs from restore consumer into a separate method. I left in the check for whether its assigned/removing standbys or active but (I think) I simplified it a bit -- happy to take it out if you feel strongly though (note we can't get rid of it entirely as we need to check eg whether to unsubscribe all if its reading standbys and there are new restoring tasks",
        "createdAt" : "2019-09-24T00:23:54Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "3277192c-48a1-4884-a3bf-c0989f7815d4",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@ableegoldman this part of the code seems not changing to me?",
        "createdAt" : "2019-09-24T21:07:28Z",
        "updatedAt" : "2019-09-24T21:07:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e2eb74e8-c23d-4cbd-aeb2-c98747239221",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Sorry, what seems not changed?\r\n`restoreConsumerAssigneStandbys` is now used in only two places, first to determine whether it should unsubscribe all in case there are new restoring tasks, and second in `removeChangelogsFromRestoreConsumer` where we skip removing partitions if they weren't what it was assigned to (to avoid overhead of copying assignment)",
        "createdAt" : "2019-09-24T21:16:44Z",
        "updatedAt" : "2019-09-24T21:16:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "f531d2f3-b68c-49ed-8ab0-5db15558bd9e",
        "parentId" : "74c0ad2f-e194-49b2-a16f-8b073baa07a9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ah I think I was looking at an old commit :P LGTM now.",
        "createdAt" : "2019-09-24T22:30:54Z",
        "updatedAt" : "2019-09-24T22:30:54Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +63,67 @@\n    // the restore consumer is only ever assigned changelogs from restoring tasks or standbys (but not both)\n    private boolean restoreConsumerAssignedStandbys = false;\n\n    // following information is updated during rebalance phase by the partition assignor"
  },
  {
    "id" : "9f195015-b486-4665-8ec6-5ff4bc5fa650",
    "prId" : 7608,
    "prUrl" : "https://github.com/apache/kafka/pull/7608#pullrequestreview-308822028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f67735e4-52f8-49fe-9ec6-9af348f87d55",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Tried to tighten up the safety check here by verifying that all the things we expect to be fully cleared after `onPartitionsLost` are indeed empty of state/old objects",
        "createdAt" : "2019-10-29T02:32:46Z",
        "updatedAt" : "2019-10-29T23:41:43Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b76d8dda-40de-4c57-ad26-428615fa19ed",
        "parentId" : "f67735e4-52f8-49fe-9ec6-9af348f87d55",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Should we also check other maps in `TaskManager`, like `assignedStandbyTasks`or `revokedActiveTasks`. Again just my feeling about the current setup, I don't find it intuitive to deal with multiple mapping structs and they look so similar to me :) It's very easy to forget what they refer to really soon.",
        "createdAt" : "2019-10-29T19:12:02Z",
        "updatedAt" : "2019-10-29T23:41:43Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "2a657dfc-b9bc-42fe-9bcb-15edd169ee53",
        "parentId" : "f67735e4-52f8-49fe-9ec6-9af348f87d55",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Well, we actually don't clear the standbys on `onPartitionsLost` as they weren't part of the group subscription to begin with. `revokedActiveTasks` and `addedActiveTasks` just tell us how the assignment changed since the previous one, and don't matter at all to us here (they aren't required to be empty, since they're not updated except after a rebalance)",
        "createdAt" : "2019-10-29T21:12:52Z",
        "updatedAt" : "2019-10-29T23:41:43Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "01a2aedaf962ef937687f97786c637ed6821efd5",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +270,274 @@        if (exception != null) {\n            throw exception;\n        } else if (!(active.isEmpty() && assignedActiveTasks.isEmpty() && changelogReader.isEmpty())) {\n            throw new IllegalStateException(\"TaskManager found leftover active task state after closing all zombies\");\n        }"
  },
  {
    "id" : "2c95d166-dde1-48ec-b9f5-c431bc8993a4",
    "prId" : 7631,
    "prUrl" : "https://github.com/apache/kafka/pull/7631#pullrequestreview-310732592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1f259c4-c545-4251-b405-4737e2e37add",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Not sure why this was trace as the same message is debug in the parallel active method",
        "createdAt" : "2019-11-01T20:36:57Z",
        "updatedAt" : "2019-11-01T23:07:24Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "220ca4c7-22e4-4bf7-b3ce-7acb505b3993",
        "parentId" : "c1f259c4-c545-4251-b405-4737e2e37add",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Good catch!",
        "createdAt" : "2019-11-01T23:11:41Z",
        "updatedAt" : "2019-11-01T23:11:42Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "be1994fa4dd51c67bdb8e964d40699bedf770f30",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +164,168 @@\n    private void addNewStandbyTasks(final Map<TaskId, Set<TopicPartition>> newStandbyTasks) {\n        log.debug(\"New standby tasks to be created: {}\", newStandbyTasks);\n\n        for (final StandbyTask task : standbyTaskCreator.createTasks(consumer, newStandbyTasks)) {"
  },
  {
    "id" : "b17672ef-8843-43f7-9fa0-f37ebf53ad61",
    "prId" : 7681,
    "prUrl" : "https://github.com/apache/kafka/pull/7681#pullrequestreview-316029454",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5eb16849-f21b-459a-98c4-c6147b7788d7",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Adding a DEBUG log. This is also in support of the new system tests, but I think it's again nice to have this information available. I actually added this log while debugging the issue, before I wrote the test, to manually verify the bug.",
        "createdAt" : "2019-11-13T06:52:34Z",
        "updatedAt" : "2019-11-13T21:20:04Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "741306599487c10a3d5f753920f1f1c2e0e0ec73",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +441,445 @@        }\n\n        log.debug(\"Assigning and seeking restoreConsumer to {}\", checkpointedOffsets);\n        restoreConsumerAssignedStandbys = true;\n        restoreConsumer.assign(checkpointedOffsets.keySet());"
  },
  {
    "id" : "84ffd9d6-29d2-48dc-a7eb-dc69238310f2",
    "prId" : 8058,
    "prUrl" : "https://github.com/apache/kafka/pull/8058#pullrequestreview-354871741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e13e57e-3752-4230-952f-b244f1d8f46e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We have to call changelog.remove() before task.closeDirty since now we clear the `stores` map in closeDirty, and after that task.changelogPartitions() would return nothing.",
        "createdAt" : "2020-02-07T00:55:47Z",
        "updatedAt" : "2020-02-20T23:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03f4778cba8697bad6e5c5d7ce40df6e59214c02",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +128,132 @@\n            // this call is idempotent so even if the task is only CREATED we can still call it\n            changelogReader.remove(task.changelogPartitions());\n\n            // mark corrupted partitions to not be checkpointed, and then close the task as dirty"
  },
  {
    "id" : "e9bece07-4f47-48c9-a8bb-03821059137e",
    "prId" : 8058,
    "prUrl" : "https://github.com/apache/kafka/pull/8058#pullrequestreview-354871741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "77d47d73-fed6-4a2c-9ecf-c61dce36691c",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Consolidated a couple of the same pattern into this private function.",
        "createdAt" : "2020-02-07T00:56:39Z",
        "updatedAt" : "2020-02-20T23:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03f4778cba8697bad6e5c5d7ce40df6e59214c02",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +175,179 @@                standbyTasksToCreate.remove(task.id());\n            } else /* we previously owned this task, and we don't have it anymore, or it has changed active/standby state */ {\n                cleanupTask(task);\n\n                try {"
  },
  {
    "id" : "68f05ff0-c215-40bd-811d-27b2920042f1",
    "prId" : 8058,
    "prUrl" : "https://github.com/apache/kafka/pull/8058#pullrequestreview-354871741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d26b917-c9aa-4e08-9293-176ea8cf3fb4",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The order here cannot be changed so I left this comment.",
        "createdAt" : "2020-02-07T00:58:18Z",
        "updatedAt" : "2020-02-20T23:04:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03f4778cba8697bad6e5c5d7ce40df6e59214c02",
    "line" : 163,
    "diffHunk" : "@@ -1,1 +360,364 @@\n    private void cleanupTask(final Task task) {\n        // 1. remove the changelog partitions from changelog reader;\n        // 2. remove the input partitions from the materialized map;\n        // 3. remove the task metrics from the metrics registry"
  }
]