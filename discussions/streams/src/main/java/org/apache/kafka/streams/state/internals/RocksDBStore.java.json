[
  {
    "id" : "559702cf-e1d1-45ed-b810-6ac1a74cda0a",
    "prId" : 4518,
    "prUrl" : "https://github.com/apache/kafka/pull/4518#pullrequestreview-94546659",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "472598dc-8d9f-4b20-a254-603225d183e1",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This change is intentional. Same below removing raw key/value from the exception error message. Cf. https://issues.apache.org/jira/browse/KAFKA-6538 as follow up for this change.",
        "createdAt" : "2018-02-06T23:38:11Z",
        "updatedAt" : "2018-02-06T23:38:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "86c2892f6a2ac5462862eed2e1d49c13b545d04e",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +226,230 @@            return this.db.get(rawKey);\n        } catch (final RocksDBException e) {\n            throw new ProcessorStateException(\"Error while getting value for key from store \" + this.name, e);\n        }\n    }"
  },
  {
    "id" : "ed455118-79f0-431d-b95f-0cdf41d67d85",
    "prId" : 4801,
    "prUrl" : "https://github.com/apache/kafka/pull/4801#pullrequestreview-126084193",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3473a5f1-ed2e-41ad-9211-64fb87d0e05c",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Not sure if required but this method was `synchronized` in the first place so I've kept it that way.",
        "createdAt" : "2018-06-05T14:15:48Z",
        "updatedAt" : "2018-06-05T14:27:55Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "704ca040-aeed-4bea-b75f-47395945532d",
        "parentId" : "3473a5f1-ed2e-41ad-9211-64fb87d0e05c",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack.",
        "createdAt" : "2018-06-05T17:55:45Z",
        "updatedAt" : "2018-06-05T17:55:45Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "01be095ec6d013ca54bd0774f915922b0911dff2",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +467,471 @@        @Override\n        public synchronized KeyValue<Bytes, byte[]> next() {\n            return super.next();\n        }\n"
  },
  {
    "id" : "9f7fc9d1-2075-417a-b05f-1b0575c1bb83",
    "prId" : 4801,
    "prUrl" : "https://github.com/apache/kafka/pull/4801#pullrequestreview-126082591",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "091032f0-db38-4256-919e-8a02306dc7b8",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Having this check here has got me to thinking more about this issue.  \r\n\r\nWithout this guard condition, we have some failing unit tests. \r\n\r\nIn both the `RocksDBIterator` and the `AbstractIterator` all calls to `next()` make a call to `hasNext()` first before returning the next object.  I'm not sure about changing the semantics where we return from `next()` without calling `hasNext()` first (which if we end up keeping those semantics, leaves us in the same position as before extending `AbstractIterator`).   \r\n\r\nI guess the question is, do we want to continue to throw an exception when `hasNext()` is called (when the store is closed) or simply return `false`?\r\n\r\nI could be overthinking this, but I'm not entirely comfortable with returning a value from `next()` after closing the store.  I feel like that creates more corner cases for potential errors or unexpected behavior.\r\n\r\nWDYT?  \r\n\r\n",
        "createdAt" : "2018-06-05T14:25:36Z",
        "updatedAt" : "2018-06-05T14:35:26Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "f5c4306a-1f39-4154-9d65-1d1d3aa9378a",
        "parentId" : "091032f0-db38-4256-919e-8a02306dc7b8",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@bbejeck That is a good question!\r\n\r\nOriginally I thought it is okay to always calling `hasNext` inside `next()`, as long as we make sure `hasNext` implementation is idempotent, i.e. calling it multiple times before `next()` does not have side effect is sufficient. But by making it idempotent we could have the corner case you mentioned. For example:\r\n\r\n```\r\nt0: call `hasNext()` -> store is still open -> call `makeNext` -> `next` field is set.\r\nt1: store is closed.\r\nt2: call `next()` -> call `hasNext()` again\r\n```\r\n\r\nWithout this check, at `t3` we would still return the `next` field. \r\n",
        "createdAt" : "2018-06-05T17:51:37Z",
        "updatedAt" : "2018-06-05T17:51:37Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "01be095ec6d013ca54bd0774f915922b0911dff2",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +461,465 @@            if (!open) {\n                throw new InvalidStateStoreException(String.format(\"RocksDB store %s has closed\", storeName));\n            }\n            return super.hasNext();\n        }"
  },
  {
    "id" : "e1e0b2aa-c16e-4c2a-ae1c-b240d20b5bc3",
    "prId" : 4801,
    "prUrl" : "https://github.com/apache/kafka/pull/4801#pullrequestreview-126139332",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "A nit (and paranoid) comment: maybe we can reuse the same `KeyValue` object, but just set its key / value fields since they are public and not final. So we do not create those short-lived objects for young gen GC. Not sure how much it will really get us, but just want to be safer since it is part of a critical code path (i.e. one object per each iterated element).",
        "createdAt" : "2018-06-05T17:58:19Z",
        "updatedAt" : "2018-06-05T17:58:19Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a187e108-089e-49fd-ae13-79f9304989b4",
        "parentId" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2018-06-05T18:22:59Z",
        "updatedAt" : "2018-06-05T18:22:59Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "4209c3e5-1fbf-4218-9057-62631afeb24a",
        "parentId" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "With another look, `KeyValue` is immutable `key` and `value` fields are final.  We could extend `KeyValue` as an inner class of `RocksDBStore` to accomplish this.  WDYT?\r\n\r\nNM that won't work. ",
        "createdAt" : "2018-06-05T18:28:11Z",
        "updatedAt" : "2018-06-05T18:38:40Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "52ad38a5-a738-4242-a124-52463a749820",
        "parentId" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I see. Do not bother then :) At lease we are not introduce a regression to make perf worse :)",
        "createdAt" : "2018-06-05T18:43:18Z",
        "updatedAt" : "2018-06-05T18:43:18Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "27992e75-55d0-4d0b-9a88-a867d255f2a3",
        "parentId" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I am late thus just a meta comment: we hand the `KeyValue` object to the user and user might actually keep a reference. Thus, we cannot reuse an object anyway, because we might mess up user code if they access an earlier return `KeyValue` again, after they retrieved newer ones.",
        "createdAt" : "2018-06-05T20:00:49Z",
        "updatedAt" : "2018-06-05T20:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c09b10a5-fa72-4e24-bb4c-811a0d4420ae",
        "parentId" : "17ea091a-2353-4cdc-8964-9623ddc98ded",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "yeah, that's an excellent point.",
        "createdAt" : "2018-06-05T20:28:34Z",
        "updatedAt" : "2018-06-05T20:28:34Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "01be095ec6d013ca54bd0774f915922b0911dff2",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +482,486 @@\n        private KeyValue<Bytes, byte[]> getKeyValue() {\n            return new KeyValue<>(new Bytes(iter.key()), iter.value());\n        }\n"
  },
  {
    "id" : "2537d5f2-1cf5-4765-b86b-aca9b66a5b44",
    "prId" : 5975,
    "prUrl" : "https://github.com/apache/kafka/pull/5975#pullrequestreview-182045639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why do we want to log it as WARN?",
        "createdAt" : "2018-11-30T06:34:56Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "8ab0014f-e125-40c9-a771-ddac252ebdae",
        "parentId" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For our own code base, this should never happen. For IQ, it's a different story. I though it might be helpful to expose potential bugs in our code base? We can also log at debug level if you prefer.",
        "createdAt" : "2018-11-30T19:46:50Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2979ae4f-2a7d-4b31-bde0-54d1f34806b7",
        "parentId" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Maybe we could put this to `INFO` but change the message slightly to say \"This could be an issue for IQ\" or something along those lines.  Just a thought.",
        "createdAt" : "2018-12-05T14:49:41Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "b33548ce-ece5-454b-bf9f-cffa6ff9d2e9",
        "parentId" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think @guozhangwang would prefer less verbose log level like DEBUG? Not sure.\r\n\r\nLike the idea to mention IQ explicitly.",
        "createdAt" : "2018-12-05T19:47:10Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "42d40dc1-d61a-4e24-8da5-f8407605bd7c",
        "parentId" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I don't have a strong opinion on the log level `DEBUG` is fine with me.",
        "createdAt" : "2018-12-05T19:52:13Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "8a2771d4-10ef-47ed-b369-282436e6e4c6",
        "parentId" : "3ee1f867-3235-43c1-8fd8-04648e19fe8b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@mjsax I think I'm sold on your arguments, let's keep them as WARN then :)",
        "createdAt" : "2018-12-06T01:02:23Z",
        "updatedAt" : "2018-12-16T15:23:41Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1e7a870cab8c0d902f8dbe9acef4b8baebf0719",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +428,432 @@        }\n        if (iterators.size() != 0) {\n            log.warn(\"Closing {} open iterators for store {}\", iterators.size(), name);\n            for (final KeyValueIterator iterator : iterators) {\n                iterator.close();"
  },
  {
    "id" : "ff6dd8bb-ac64-489e-b9b7-70f61a44ad30",
    "prId" : 6012,
    "prUrl" : "https://github.com/apache/kafka/pull/6012#pullrequestreview-192800688",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da39eba7-2af6-4db8-a3ef-3816a78bf907",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Hi @bbejeck,\r\n\r\nShould we also consider `options.optimizeFiltersForHits()` to save memory on the bloom filter in exchange for one I/O for each get on a missing key?\r\n\r\n(see https://github.com/facebook/rocksdb/wiki/Memory-usage-in-RocksDB#indexes-and-filter-blocks)\r\n\r\nI just ran across this while reading about caching in Rocks.",
        "createdAt" : "2019-01-08T21:54:40Z",
        "updatedAt" : "2019-01-22T15:43:02Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "436e5c08-06ca-47f8-9516-6b26cf5f13b9",
        "parentId" : "da39eba7-2af6-4db8-a3ef-3816a78bf907",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "@vvcephei yeah that makes sense.\r\n\r\n\\cc @guozhangwang @mjsax  WDYT?",
        "createdAt" : "2019-01-09T21:16:26Z",
        "updatedAt" : "2019-01-22T15:43:02Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "612fb364-2bab-4bdd-9744-dab31309b972",
        "parentId" : "da39eba7-2af6-4db8-a3ef-3816a78bf907",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "FWIW, here's what I'm thinking...\r\nBloom filters can only tell you if the key is definitely not in the set. They can only answer \"no\" or \"maybe\". So if the filter says the key isn't in some sst we don't have to actually do the I/O to check, but if it says \"maybe\", we do still have to check.\r\n\r\nThis optimization would add a bloom filter to every level in the SST hierarchy except the last level. \r\n\r\nThe rationale is that if you're pretty sure the keys you get are in the db, the bloom filters at the higher levels would let you skip querying the SSTs that don't contain your key. If you get all the way to the bottom level, we're pretty sure the key is there (via our prior assumption), so checking the bloom filter isn't that valuable, since it would rarely answer \"no\".\r\nIf it answers \"maybe\", we have to check anyway. In other words, the filter only saves I/O in the rare case that it does say \"no\".\r\nOn the other hand, the last level has the most keys in it, so those are the most expensive filters. By dropping that last level of filters, we save a bunch of memory in exchange for rare extra I/Os.\r\n\r\nDo we have a prior assumption that the keys we query for are rarely missing? I think so...\r\nIn general, Streams only does a get while computing an aggregation value, etc. In this case, it does a get followed by a put. Therefore, the only get that might return missing is the very first one for each key.\r\n\r\nFactors that would cause more missed gets would be stuff like:\r\n* IQ\r\n* data sets that have a lot of thrash in the key space",
        "createdAt" : "2019-01-10T20:55:02Z",
        "updatedAt" : "2019-01-22T15:43:02Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a5976ea8-bc4a-46fe-9e3a-f4e1706f4cdc",
        "parentId" : "da39eba7-2af6-4db8-a3ef-3816a78bf907",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Thanks for the more in-depth explanation @vvcephei sounds good to me.",
        "createdAt" : "2019-01-10T21:53:51Z",
        "updatedAt" : "2019-01-22T15:43:02Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "cb654ed4-61e6-43f9-b12c-d245739b38f9",
        "parentId" : "da39eba7-2af6-4db8-a3ef-3816a78bf907",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Thanks @vvcephei for the explanation. I agree with you that for most cases we expect multiple gets on each key (only the first get will miss), besides the ones you already listed that may not be the case another case is that windowed stream-stream join will always have distinct keys, but given that this may be fixed in the future I'm in favor of adding it as well.",
        "createdAt" : "2019-01-15T18:47:00Z",
        "updatedAt" : "2019-01-22T15:43:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "846ea8d330379a183873d754eb643b00af10b3ac",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +121,125 @@        tableConfig.setBlockCacheSize(BLOCK_CACHE_SIZE);\n        tableConfig.setBlockSize(BLOCK_SIZE);\n        tableConfig.setFilter(new BloomFilter());\n\n        options.optimizeFiltersForHits();"
  },
  {
    "id" : "70ab7a8d-b43d-4ab0-9b5b-1d876d5276cd",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-196868153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d9d82966-e15b-4dc5-b6d3-03193174011d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`restoreAllInternal()` is only called here, so I think it's better to inline it.",
        "createdAt" : "2019-01-20T07:10:35Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "92642e28-c1b6-4fa1-adda-42b03a9e44be",
        "parentId" : "d9d82966-e15b-4dc5-b6d3-03193174011d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "+1",
        "createdAt" : "2019-01-23T20:13:58Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "97619e70-eb9b-419b-b7a0-2da06b7056f5",
        "parentId" : "d9d82966-e15b-4dc5-b6d3-03193174011d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Now I see why we need to make `name` package-private now; think it is okay.",
        "createdAt" : "2019-01-28T03:39:24Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 651,
    "diffHunk" : "@@ -1,1 +549,553 @@        @Override\n        public void restoreAll(final Collection<KeyValue<byte[], byte[]>> records) {\n            try (final WriteBatch batch = new WriteBatch()) {\n                rocksDBStore.dbAccessor.prepareBatchForRestore(records, batch);\n                rocksDBStore.write(batch);"
  },
  {
    "id" : "01d3076f-b447-4cf2-b48f-277a8163cf70",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-196868153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b49f306f-7948-4c18-b2c5-323c24c963da",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why `openIterators` needs to be package-private now?",
        "createdAt" : "2019-01-28T03:42:08Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +81,85 @@    final String name;\n    private final String parentDir;\n    final Set<KeyValueIterator<Bytes, byte[]>> openIterators = Collections.synchronizedSet(new HashSet<>());\n\n    File dbDir;"
  },
  {
    "id" : "60d0428d-dd6c-46a3-9094-6cddbfae6113",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-197343598",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92fa601b-f359-405c-ab32-c633286525ef",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For `put / putAll` etc the exception is captured inside the dbAccessor, while for `get` it is captured in the caller, is it intentional?",
        "createdAt" : "2019-01-28T03:49:09Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "451a21a8-79d8-42ae-a8d5-f7059bc81a0a",
        "parentId" : "92fa601b-f359-405c-ab32-c633286525ef",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "If not, we should move the exception capturing logic inside the dbAccessor as well.",
        "createdAt" : "2019-01-28T03:49:27Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b2123ab5-60da-46d3-b885-cfcc5b36d0ae",
        "parentId" : "92fa601b-f359-405c-ab32-c633286525ef",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fair question. If we move all try-catch into the dbAccessor, we need to duplicate more code. For example, `db.flush()` could throw and catching the exception in `RocksDB#flush()` is a single place -- if we move it into the dbAccessor, we need to to try-catch in both implementations.\r\n\r\nThoughts?",
        "createdAt" : "2019-01-29T01:33:17Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "dcb3d6c6-59a8-4d04-a956-f56b8f5a33f7",
        "parentId" : "92fa601b-f359-405c-ab32-c633286525ef",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`put` is different, because you requested to catch `put()` and `get()` within `DualAccessor` separately -- thus, I moved the code inside.\r\n\r\nFor `putAll()` does also throw (main pattern is that the caller catches).",
        "createdAt" : "2019-01-29T01:39:09Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 296,
    "diffHunk" : "@@ -1,1 +259,263 @@        validateStoreOpen();\n        try {\n            return dbAccessor.get(key.get());\n        } catch (final RocksDBException e) {\n            // String format is happening in wrapping stores. So formatted message is thrown from wrapping stores."
  },
  {
    "id" : "fb3b81b0-d302-4730-aea9-84c2a4c9fbe5",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-196868153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57035923-3b83-4dd8-88a6-f932955e88db",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ditto here.",
        "createdAt" : "2019-01-28T03:49:54Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 311,
    "diffHunk" : "@@ -1,1 +271,275 @@        final byte[] oldValue;\n        try {\n            oldValue = dbAccessor.getOnly(key.get());\n        } catch (final RocksDBException e) {\n            // String format is happening in wrapping stores. So formatted message is thrown from wrapping stores."
  },
  {
    "id" : "4cf062ed-428e-459f-b7f8-6c76cf29bc16",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-196868153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "949fb89c-d4d4-430f-95e1-86f14394491b",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ditto here.",
        "createdAt" : "2019-01-28T03:50:23Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 352,
    "diffHunk" : "@@ -1,1 +317,321 @@        final long numEntries;\n        try {\n            numEntries = dbAccessor.approximateNumEntries();\n        } catch (final RocksDBException e) {\n            throw new ProcessorStateException(\"Error fetching property from store \" + name, e);"
  },
  {
    "id" : "b027a738-196f-4864-adef-1a0163bd487c",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-197346766",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3cabe0a-7e7f-4cca-8df5-e470323878cc",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For line 376 above, which is out of scope of this PR: thinking about it again now I'm not sure if Streams should be responsible for closing the open iterators when closing the database; this logic is a bit awkward and also subject to errors with concurrent access from IQ. We may instead just educate users to always close the iterators themselves (for both IQ and processor). WDYT?",
        "createdAt" : "2019-01-28T03:55:11Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "545abbe6-3763-43dd-b058-26b9bfa28aa6",
        "parentId" : "c3cabe0a-7e7f-4cca-8df5-e470323878cc",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well. It seems to be a nice \"safe guard\" -- as you mention out-of scope: maybe create jira and we can discuss there? not sure atm.",
        "createdAt" : "2019-01-29T01:54:29Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 411,
    "diffHunk" : "@@ -1,1 +372,376 @@        open = false;\n        closeOpenIterators();\n        dbAccessor.close();\n        userSpecifiedOptions.close();\n        wOptions.close();"
  },
  {
    "id" : "b1bd992f-01de-4367-9e92-3e8c9adbec1e",
    "prId" : 6186,
    "prUrl" : "https://github.com/apache/kafka/pull/6186#pullrequestreview-216546572",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb93334e-21e4-4eea-8423-5a964bfbc4bd",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We add this new method to `RocksDBAccessor` for the fix",
        "createdAt" : "2019-03-20T06:38:05Z",
        "updatedAt" : "2019-03-20T06:38:05Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "39578f44d576e1839048f1b2432411729cb50172",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +439,443 @@        void addToBatch(final byte[] key,\n                        final byte[] value,\n                        final WriteBatch batch) throws RocksDBException;\n\n        void close();"
  },
  {
    "id" : "e39826d9-ec84-49eb-b592-eddbdb6f6854",
    "prId" : 6186,
    "prUrl" : "https://github.com/apache/kafka/pull/6186#pullrequestreview-216546714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "caee4b71-bb0a-4f44-be09-49dd068e9786",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "some refactoring to share more code exploiting the newly added method (similar below)",
        "createdAt" : "2019-03-20T06:38:48Z",
        "updatedAt" : "2019-03-20T06:38:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "39578f44d576e1839048f1b2432411729cb50172",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +478,482 @@            for (final KeyValue<Bytes, byte[]> entry : entries) {\n                Objects.requireNonNull(entry.key, \"key cannot be null\");\n                addToBatch(entry.key.get(), entry.value, batch);\n            }\n        }"
  }
]