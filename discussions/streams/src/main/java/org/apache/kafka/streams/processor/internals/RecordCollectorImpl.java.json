[
  {
    "id" : "468bc459-f1a9-4e3d-83fa-ce52a8509376",
    "prId" : 5279,
    "prUrl" : "https://github.com/apache/kafka/pull/5279#pullrequestreview-131379868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0c51f5f-bb31-480c-8ace-84bf1ace37e0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Isn't `toString()` called implicitly?",
        "createdAt" : "2018-06-22T19:32:22Z",
        "updatedAt" : "2018-06-22T19:32:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fd3fab72-470a-468f-9f22-6f48be3a30b3",
        "parentId" : "a0c51f5f-bb31-480c-8ace-84bf1ace37e0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We've observed from the actual logs that it's not actually.. and the reason is this: \r\n\r\nhttps://stackoverflow.com/questions/6371638/slf4j-how-to-log-formatted-message-object-array-exception",
        "createdAt" : "2018-06-23T00:24:42Z",
        "updatedAt" : "2018-06-23T00:24:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0f211f1d-3177-4c82-8da1-139d4efa4b2f",
        "parentId" : "a0c51f5f-bb31-480c-8ace-84bf1ace37e0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note this is indeed fixed in trunk but not in older versions.",
        "createdAt" : "2018-06-23T00:25:07Z",
        "updatedAt" : "2018-06-23T00:25:07Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4c4d3e3f-75b6-425a-af34-7875279c07b3",
        "parentId" : "a0c51f5f-bb31-480c-8ace-84bf1ace37e0",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for clarification, @guozhangwang !",
        "createdAt" : "2018-06-23T01:14:58Z",
        "updatedAt" : "2018-06-23T01:14:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "867f3c36-d4ad-4e23-965c-1b99385a67b2",
        "parentId" : "a0c51f5f-bb31-480c-8ace-84bf1ace37e0",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Is only `1.0` affected? What about `1.1` or `0.11.0` and older?",
        "createdAt" : "2018-06-23T01:15:59Z",
        "updatedAt" : "2018-06-23T01:16:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e27ce2a851508e7093ab0f7ebf2b107c3f7b1306",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +111,115 @@                                log.error(\"Error sending record (key {} value {} timestamp {}) to topic {} due to {}; \" +\n                                                \"No more records will be sent and no more offsets will be recorded for this task.\",\n                                        key, value, timestamp, topic, exception.toString());\n                                if (exception instanceof ProducerFencedException) {\n                                    sendException = new ProducerFencedException(String.format(\"%sAbort sending since producer got fenced with a previous record (key %s value %s timestamp %d) to topic %s, error message: %s\","
  },
  {
    "id" : "734d6d33-50b8-46bf-86f7-5a0b6a1170e0",
    "prId" : 5613,
    "prUrl" : "https://github.com/apache/kafka/pull/5613#pullrequestreview-152962987",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3059fbc-a045-482b-8d03-472184863ea7",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "this import was missing.",
        "createdAt" : "2018-09-05T13:47:58Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "43548a53-6f14-443d-90eb-34c4071ebaac",
        "parentId" : "c3059fbc-a045-482b-8d03-472184863ea7",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why it did not fail before?",
        "createdAt" : "2018-09-05T17:44:36Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "5557845b-f6bc-465f-8904-0ba570fcc535",
        "parentId" : "c3059fbc-a045-482b-8d03-472184863ea7",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "don't know, maybe something was missed in porting back? compared against upstream/0.11.0 and the import is not there. The lines (128-137) requiring the import were introduced in #5520 so maybe in cherry-picking, it was missed",
        "createdAt" : "2018-09-06T14:37:46Z",
        "updatedAt" : "2018-09-06T14:50:30Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "34402b501d00d4f2af8b421a63004c2af3c3bd34",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +24,28 @@import org.apache.kafka.clients.producer.ProducerRecord;\nimport org.apache.kafka.clients.producer.RecordMetadata;\nimport org.apache.kafka.common.KafkaException;\nimport org.apache.kafka.common.PartitionInfo;\nimport org.apache.kafka.common.TopicPartition;"
  },
  {
    "id" : "1789054d-313d-451d-926b-0c65666656c2",
    "prId" : 6280,
    "prUrl" : "https://github.com/apache/kafka/pull/6280#pullrequestreview-257109026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9740ab8e-1a89-4e93-84c3-ab00030be6de",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: missing whitespace before `retries` (or after `and/or` the line above)",
        "createdAt" : "2019-07-02T19:40:52Z",
        "updatedAt" : "2019-07-02T20:29:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d8e33a52559274540b2dbebe61f35bcf1baeb3",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +61,65 @@    private final static String EXCEPTION_MESSAGE = \"%sAbort sending since %s with a previous record (timestamp %d) to topic %s due to %s\";\n    private final static String PARAMETER_HINT = \"\\nYou can increase the producer configs `delivery.timeout.ms` and/or \" +\n        \"`retries` to avoid this error. Note that `retries` is set to infinite by default.\";\n\n    private volatile KafkaException sendException;"
  },
  {
    "id" : "f346cc3e-55fc-4415-8bc0-adcc6e293915",
    "prId" : 6372,
    "prUrl" : "https://github.com/apache/kafka/pull/6372#pullrequestreview-210467895",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c050e54-b8cb-42af-9d3f-3b9306727450",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I added the `TimeoutException` to the error message and as the cause of the `StreamsException`. This made the lines too long, so I reformatted them.\r\n\r\nI also added some more failure modes to the log message; I felt the existing message could be misleading if the problem was actually just a network interruption.",
        "createdAt" : "2019-03-05T02:35:27Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9136d41ec244506da0739e2c2213fdaab4629c7",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +232,236 @@                String.format(\"%sFailed to send record to topic %s due to timeout.\", logPrefix, topic),\n                e\n            );\n        } catch (final Exception uncaughtException) {\n            if (uncaughtException instanceof KafkaException &&"
  },
  {
    "id" : "db355c6f-4598-4400-926e-28a2b9ebecf1",
    "prId" : 6372,
    "prUrl" : "https://github.com/apache/kafka/pull/6372#pullrequestreview-212067786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: why one more indent ?",
        "createdAt" : "2019-03-07T02:08:04Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "7551ed35-1f63-49a1-9ebe-7fe1b1042a36",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "It's just how Idea seems to format multiline expressions... e.g.,\r\n```\r\n1 +\r\n    2\r\n```\r\n\r\ninstead of \r\n```\r\n1 + \r\n2\r\n```\r\n\r\nIs it undesirable?",
        "createdAt" : "2019-03-07T18:08:32Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "218a276e-d3c8-4d12-84e7-4153a270403e",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not important -- just look funky to me. We concatenate multiple strings and thus all should have the same indent -- why would we indent the first differently? I would format as follows (even if I know that you don't like that the plus goes into the next line):\r\n```\r\n\"string1\"\r\n+ \"string2\"\r\n+ \"string3\"\r\n```\r\n\r\nThis avoid the \"ambiguity\", of multiple string parameters, vs one concatenated parameter:\r\n```\r\nmethod(\r\n    \"param1\",\r\n    \"param2\",\r\n    \"param3\",\r\n    \"param4\");\r\n\r\n// vs\r\n\r\nmethod(\r\n    \"param-part-1\" +\r\n    \"param-part-2\" +\r\n    \"param-part-3\",\r\n    \"new-param\");\r\n\r\n// vs\r\n\r\nmethod(\r\n    \"param-part-1\"\r\n    + \"param-part-2\"\r\n    + \"param-part-3\",\r\n    \"new-param\");\r\n```\r\n\r\nThirst and second hard hard to distinguish (where do parameters start/stop), but third makes it clear, that it's two parameters but not one or four, what is hard to tell in the middle case. Of course, double indent also fixes this but it's weird to me:\r\n```\r\nmethod(\r\n    \"param-part-1\" +\r\n        \"param-part-2\" +\r\n        \"param-part-3\",\r\n    \"new-param\");\r\n```",
        "createdAt" : "2019-03-07T18:41:35Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "66e0db31-ddfa-404e-9e44-f404a5de9c91",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I remember a while back someone on the internet trying to get everyone to always put operators (and commas) at the beginning of the line for this reason. I think it makes sense. I don't think it caught on in general because it creates syntactic ambiguity in Javascript, but since Java requires semicolons to end a line, it should be fine.\r\n\r\nDo you have your IDE set up to create this formatting? Maybe it sounds lazy, but the reason I've formatted it this way is that that's what IDEA does by default. I don't want to spend time curating the number of indent spaces by hand on every code change. I couldn't figure out how to get rid of the extra indent in the multi-line string concatenation. Eg, it even does this:\r\n```java\r\n        final String s =\r\n            \"asdf\"\r\n                + \"qwer\"\r\n                + \"qwer\";\r\n```\r\nwhich is like the worst outcome.\r\n\r\n",
        "createdAt" : "2019-03-07T22:07:27Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "d7d8caf3-5115-4589-b424-94ca2fdf72f6",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't know the IDE setting -- this case is rare enough that I \"fix\" fit manually if it happens.",
        "createdAt" : "2019-03-07T22:23:14Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "7dbc23d6-7014-4a19-9e7d-8b93e75566d1",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Let me know if you plan to address or ignore this -- I am fine either way.",
        "createdAt" : "2019-03-07T22:30:27Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fd09300b-2275-4135-8417-1c6367d39e06",
        "parentId" : "3d2be8c6-f1d5-4ac1-957c-6c3e0355e22c",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, I agree with you in principle, but I think I'll just leave it as-is, until I can figure out a way to get the IDE to do it for me.",
        "createdAt" : "2019-03-07T23:01:41Z",
        "updatedAt" : "2019-03-07T23:01:41Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9136d41ec244506da0739e2c2213fdaab4629c7",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +221,225 @@            log.error(\n                \"Timeout exception caught when sending record to topic {}. \" +\n                    \"This might happen if the producer cannot send data to the Kafka cluster and thus, \" +\n                    \"its internal buffer fills up. \" +\n                    \"This can also happen if the broker is slow to respond, if the network connection to \" +"
  },
  {
    "id" : "e895fd0f-7b0f-4e14-87ad-352480e442a7",
    "prId" : 7223,
    "prUrl" : "https://github.com/apache/kafka/pull/7223#pullrequestreview-278123699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "218b8eae-1025-47ee-b2ab-32356243571b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Would it be simpler to hand out a deep copy of the map directly?",
        "createdAt" : "2019-08-20T01:15:15Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "68c8986f-4b92-43c0-8dff-6fa94e686de2",
        "parentId" : "218b8eae-1025-47ee-b2ab-32356243571b",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "That would be totally fine for the current usage pattern, where we have a single query that ends up copying the map anyway. However, if we ever ended up with other queries then those queries would pay the cost of the copy whether they need it or not. It would be a bit surprising that a copy is happening without looking at the implementation. My bias would be towards defensive coding without surprise performance impact.",
        "createdAt" : "2019-08-20T02:20:18Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "4269fd24-5f24-4e17-b859-74434c07ecc7",
        "parentId" : "218b8eae-1025-47ee-b2ab-32356243571b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fair enough.",
        "createdAt" : "2019-08-21T23:25:02Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e0fd82b3fcf3eb7d338aabc674aead40c28e0f6",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +281,285 @@    @Override\n    public Map<TopicPartition, Long> offsets() {\n        return Collections.unmodifiableMap(offsets);\n    }\n"
  },
  {
    "id" : "fb553f1e-cb19-443f-b8ab-1b50ff7fa857",
    "prId" : 7635,
    "prUrl" : "https://github.com/apache/kafka/pull/7635#pullrequestreview-314488714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a605e1e8-72ee-4460-9b1d-fc8e7e2e87e6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Can you move the comments from L136-7 below the new block, so that it can maintain its association with the `RetriableException`? Maybe you can put it inside the right block to keep it from getting dissociated again.",
        "createdAt" : "2019-11-08T15:51:19Z",
        "updatedAt" : "2019-12-04T18:30:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8d193fbc-836e-4570-b7f8-c4a5a6c744d7",
        "parentId" : "a605e1e8-72ee-4460-9b1d-fc8e7e2e87e6",
        "authorId" : "496af868-b188-44f1-b935-49de5eaeede1",
        "body" : "I moved the comment below as you asked. However, on a personal note I think the both blocks are the right ones  as TimeoutException is a subclass of Retriable Exception.",
        "createdAt" : "2019-11-08T17:47:42Z",
        "updatedAt" : "2019-12-04T18:30:49Z",
        "lastEditedBy" : "496af868-b188-44f1-b935-49de5eaeede1",
        "tags" : [
        ]
      },
      {
        "id" : "1dd951c8-d787-41ef-a8d2-bb5b453a06ae",
        "parentId" : "a605e1e8-72ee-4460-9b1d-fc8e7e2e87e6",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I see your point, but it seems like the comment is more acknowledging that using `RetriableException` as a catch-all for all \"retriable exceptions\" isn't guaranteed to work, although it's the best we can do right now. If I understood the consumer API, though, `TimeoutException` _is_ recommended as the way to catch \"timeout exceptions\".\r\n\r\nBut this might also be me justifying the position after the fact... Anyway, thanks for making the change.",
        "createdAt" : "2019-11-08T22:14:27Z",
        "updatedAt" : "2019-12-04T18:30:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "732f46ba8adfd429c31c11e2f82736b23f60ff3a",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +140,144 @@            errorLogMessage += topicTimeoutHint;\n            errorMessage += topicTimeoutHint;\n        } else if (exception instanceof RetriableException) {\n            // There is no documented API for detecting retriable errors, so we rely on `RetriableException`\n            // even though it's an implementation detail (i.e. we do the best we can given what's available)"
  },
  {
    "id" : "fc48ce21-4776-4614-9e04-4d9940cae8f9",
    "prId" : 7748,
    "prUrl" : "https://github.com/apache/kafka/pull/7748#pullrequestreview-326538399",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cebd8da7-33bd-45f5-a319-db50d93b484f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For `UnknownProducerIdException` we actually can still reuse the client and just need to send the next produce request (unlike `ProducerFencedException` we cannot reuse the client and hence have to create a new client). However when we translate them into `TaskMigrationException` on higher level it would be treated equally as re-triggering a rebalance.\r\n\r\nIt's just that in current EOS implementation (before KIP-447) have one producer per task, hence when the task is closed the corresponding producer is closed and discarded as well. In KIP-447 however we may still need to treat them differently: for `UnknownProducerIdException` we can just log and proceed, for `ProducerFencedException` we need to close the producer and re-create a new one.",
        "createdAt" : "2019-12-03T22:01:28Z",
        "updatedAt" : "2019-12-03T23:29:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e5144da5-0795-4131-a53e-e7e80995f84f",
        "parentId" : "cebd8da7-33bd-45f5-a319-db50d93b484f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks. One thing I'm not sure about, but felt at the time of putting this together was that, if we get an UnknownProducerIdException on one call, we'd probably just keep getting it on all subsequent calls. It seemed to me that the exception was originating from a condition where the broker \"forgot\" about our id, and if it has \"forgotten\" about us, I'm not sure why it would \"remember\" us later on.\r\n\r\nIf that's not true, then this approach certainly may result in more close+reopen operations than is necessary.",
        "createdAt" : "2019-12-04T00:32:13Z",
        "updatedAt" : "2019-12-04T00:32:13Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "96a2d969df7fe000bbda04c9aab3b0d50eaa655c",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +269,273 @@        try {\n            producer.flush();\n        } catch (final ProducerFencedException | UnknownProducerIdException e) {\n            throw new RecoverableClientException(\"Caught a recoverable exception while flushing\", e);\n        }"
  },
  {
    "id" : "9f8b0a75-81ed-488f-ab78-5eee8fe16f4a",
    "prId" : 7748,
    "prUrl" : "https://github.com/apache/kafka/pull/7748#pullrequestreview-326558462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21509735-626f-4908-b690-daaf2ccb479c",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Minor for log4j succinctness: from looking at the production log files, I think keeping the whole stack trace of the original `exception` is not necessary since we know exactly it would be thrown from\r\n\r\n```\r\n\tat org.apache.kafka.streams.processor.internals.RecordCollectorImpl$1.onCompletion(RecordCollectorImpl.java:202)\r\n\tat org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1318)\r\n\tat org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:230)\r\n\tat org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:196)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:730)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:716)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:674)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:596)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.access$100(Sender.java:74)\r\n\tat org.apache.kafka.clients.producer.internals.Sender$1.onComplete(Sender.java:798)\r\n\tat org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)\r\n\tat org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:561)\r\n\tat org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:553)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:335)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:244)\r\n```\r\n\r\nSo may be we can just log the original exception name; similarly in `recordSendError` we can just keep the original exception's name but not the stack trace since we know exactly it is from the same `Sender.failBatch` trace.",
        "createdAt" : "2019-12-03T23:39:24Z",
        "updatedAt" : "2019-12-03T23:39:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "36e9c723-e580-4dd5-a1d5-c79aaa9c472c",
        "parentId" : "21509735-626f-4908-b690-daaf2ccb479c",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "In practice, the exceptions we're recording here are ApiExceptions, so they don't contain stack traces anyway.\r\n\r\nI actually added the exception to the \"cause\" on purpose, because it was a pain trying to understand the stack traces we were previously logging while I was digging in to this issue. Even if the log messages are more verbose, they're easy to follow. I.e., it's a nice chain of \"E1 caused by E2 caused by E3\", instead of \"E1-with-E3-in-the-message caused by E2\".\r\n\r\nI actually wanted to take it farther by removing the `exception.toString` from the message, but I didn't want to be _too_ bold in this patch, and cause even more controversy. ",
        "createdAt" : "2019-12-04T00:39:34Z",
        "updatedAt" : "2019-12-04T00:39:34Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "031f8e9f-e949-4ac3-8b74-cfff519ae8c8",
        "parentId" : "21509735-626f-4908-b690-daaf2ccb479c",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "SG!",
        "createdAt" : "2019-12-04T01:44:13Z",
        "updatedAt" : "2019-12-04T01:44:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "96a2d969df7fe000bbda04c9aab3b0d50eaa655c",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +196,200 @@                                        exception.toString()\n                                    ),\n                                    exception\n                                );\n                            } else {"
  },
  {
    "id" : "1cc7d493-ac01-4534-8ded-82530e176ff7",
    "prId" : 8060,
    "prUrl" : "https://github.com/apache/kafka/pull/8060#pullrequestreview-357138189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f99045b-d3e0-4109-84cd-30cc93491957",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well -- we could also \"buffer\" the record and try to send it later? In the mean time we would need to pause the corresponding task though to not process more input records (or course, we would need to let the task finish processing the current input record what might lead to more output records that we would need to buffer, too). -- This is just a wild thought and we could also handle this case later if required.",
        "createdAt" : "2020-02-10T01:47:14Z",
        "updatedAt" : "2020-02-14T22:46:42Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "7c65efa0-15e6-4ec9-b3f4-67f2a7fc1902",
        "parentId" : "1f99045b-d3e0-4109-84cd-30cc93491957",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I thought about the buffering mechanism here, but decided it may not worth since we've not seen timeout from `partitionsFor` -- it should be quite rare because in most cases the producer already got the partition metadata cached locally. If we found this call timing out become an issue we can revisit the buffering, wdyt?",
        "createdAt" : "2020-02-12T01:38:09Z",
        "updatedAt" : "2020-02-14T22:46:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "19332579cacd46146a8309938215845c16448a8d",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +259,263 @@            } catch (final KafkaException e) {\n                // here we cannot drop the message on the floor even if it is a transient timeout exception,\n                // so we treat everything the same as a fatal exception\n                throw new StreamsException(\"Could not determine the number of partitions for topic '\" + topic +\n                    \"' for task \" + taskId + \" due to \" + e.toString());"
  }
]