[
  {
    "id" : "3d875c8a-9a2f-4a7c-b855-655e2e1043c5",
    "prId" : 7538,
    "prUrl" : "https://github.com/apache/kafka/pull/7538#pullrequestreview-322649213",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9728dc0-333d-4330-bab5-114ad5e108f9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: `<p>` not needed because there is no following paragraph",
        "createdAt" : "2019-11-25T23:57:43Z",
        "updatedAt" : "2019-12-01T00:43:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3553929c506967ca45dff88e7139f3a4cdae0b4d",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +542,546 @@     * It is an intermediate representation after a grouping of {@link KStream}s, before the\n     * aggregations are applied to the new partitions resulting in a {@link KTable}.\n     * <p>\n     * The specified {@link Aggregator} is applied in the actual {@link CogroupedKStream#aggregate(Initializer)\n     * aggregation} step for each input record and computes a new aggregate using the current aggregate (or for the very"
  },
  {
    "id" : "10f01ac2-41bd-4884-af0c-23579b4ab49c",
    "prId" : 7538,
    "prUrl" : "https://github.com/apache/kafka/pull/7538#pullrequestreview-323394971",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b6c60c0-77d1-4d6c-9179-4dc85f7fd750",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2019-11-27T02:43:09Z",
        "updatedAt" : "2019-12-01T00:43:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3553929c506967ca45dff88e7139f3a4cdae0b4d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +540,544 @@     * {@code KGroupedStream} to it.\n     * {@link CogroupedKStream} is an abstraction of multiple <i>grouped</i> record streams of {@link KeyValue} pairs.\n     * It is an intermediate representation after a grouping of {@link KStream}s, before the\n     * aggregations are applied to the new partitions resulting in a {@link KTable}.\n     * <p>"
  },
  {
    "id" : "5ade7d8d-a096-46c9-ade1-f7da81c8cdde",
    "prId" : 7538,
    "prUrl" : "https://github.com/apache/kafka/pull/7538#pullrequestreview-324915018",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f9bbb4b-0a05-4550-a0ef-108865c10a8a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "New paragraph",
        "createdAt" : "2019-12-01T00:51:23Z",
        "updatedAt" : "2019-12-01T00:51:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3553929c506967ca45dff88e7139f3a4cdae0b4d",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +546,550 @@     * aggregation} step for each input record and computes a new aggregate using the current aggregate (or for the very\n     * first record per key using the initial intermediate aggregation result provided via the {@link Initializer} that\n     * is passed into {@link CogroupedKStream#aggregate(Initializer)}) and the record's value.\n     *\n     * @param aggregator an {@link Aggregator} that computes a new aggregate result"
  },
  {
    "id" : "c7bf8fd4-fd20-4d32-b08d-b129174ec544",
    "prId" : 9606,
    "prUrl" : "https://github.com/apache/kafka/pull/9606#pullrequestreview-545236680",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76652add-df96-4796-9f7e-c3b6a3c63d09",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Should apply the same improvement to `reduce()` and `count()` overloads? Also for `CogroupedKStream#aggregate()`?\r\n\r\nWhat about `TimeWindowedKStream` and `TimeWindowedCogroupedKStream` ?\r\n\r\nAlso `StreamsBuilder#table()` (and `#globalTable()`) might need an update?",
        "createdAt" : "2020-11-17T22:55:52Z",
        "updatedAt" : "2020-12-23T22:04:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "04cbd67e-12c7-4bc9-8640-bfad9cf10322",
        "parentId" : "76652add-df96-4796-9f7e-c3b6a3c63d09",
        "authorId" : "355e14de-1b26-40ff-b34b-fd3a7820713a",
        "body" : "Yes, this should be probably done. But since I don't know how they work and what to write there, I'd prefer to do it in another PR (or someone else should do it).",
        "createdAt" : "2020-11-18T07:48:44Z",
        "updatedAt" : "2020-12-23T22:04:36Z",
        "lastEditedBy" : "355e14de-1b26-40ff-b34b-fd3a7820713a",
        "tags" : [
        ]
      },
      {
        "id" : "c6f24008-0f3c-4034-a8e7-a89503d666e6",
        "parentId" : "76652add-df96-4796-9f7e-c3b6a3c63d09",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`reduce()` and `count()` are similar to `aggregate()`: reduce only does not allow you to change the value type (ie, output type == input type) and count, well implements an aggregate() that counts :)\r\n\r\nAnd they all work the same for `KGroupedStream`, `CogroupedKStream`, `TimeWindowedKStream` and `TimeWindowedCoGroupedKStream`.\r\n\r\n`table()` and `globalTable()` just read a topic and upsert the data into a state store / table.\r\n\r\nSo it would be great to do them all in one PR?",
        "createdAt" : "2020-12-01T00:40:01Z",
        "updatedAt" : "2020-12-23T22:04:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c5459f19-76f1-4dad-86f0-6601adac5611",
        "parentId" : "76652add-df96-4796-9f7e-c3b6a3c63d09",
        "authorId" : "355e14de-1b26-40ff-b34b-fd3a7820713a",
        "body" : "I'd prefer to commit this chages and create an issue referring to this PR. What do you think?",
        "createdAt" : "2020-12-02T20:58:18Z",
        "updatedAt" : "2020-12-23T22:04:36Z",
        "lastEditedBy" : "355e14de-1b26-40ff-b34b-fd3a7820713a",
        "tags" : [
        ]
      },
      {
        "id" : "a9a56708-e2f6-410b-a2d1-bb51877cdeeb",
        "parentId" : "76652add-df96-4796-9f7e-c3b6a3c63d09",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We can still do multiple PRs -- feel free to open them in parallel reusing the existing JIRA ticket.\r\n\r\nWill hold off to merge this because if we can detect other things we need to change in the other PRs, we can keep the applied changes in-sync more easily.",
        "createdAt" : "2020-12-04T19:24:58Z",
        "updatedAt" : "2020-12-23T22:04:36Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e88a1bad1bddcfdf5ee2f76f49c3dbffebd32ecb",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +390,394 @@     * <p>\n     * For failure and recovery the store (which always will be of type {@link TimestampedKeyValueStore}) will be backed by\n     * an internal changelog topic that will be created in Kafka.\n     * The changelog topic will be named \"${applicationId}-${internalStoreName}-changelog\", where \"applicationId\" is\n     * user-specified in {@link StreamsConfig} via parameter"
  }
]