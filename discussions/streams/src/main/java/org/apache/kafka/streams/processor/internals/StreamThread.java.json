[
  {
    "id" : "b8c94f55-9978-4c55-9429-3a7232abd0f2",
    "prId" : 4343,
    "prUrl" : "https://github.com/apache/kafka/pull/4343#pullrequestreview-86195518",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bca94a6-8674-4fec-999b-b1e8a69ba6ca",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why don't we call `completeShutdown(true)` directly instead via the redirect to `run()` ?",
        "createdAt" : "2017-12-27T21:53:24Z",
        "updatedAt" : "2018-01-02T02:05:30Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9862e3b2-6729-4670-a40f-e21b5a6b3520",
        "parentId" : "0bca94a6-8674-4fec-999b-b1e8a69ba6ca",
        "authorId" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "body" : "It seemed simpler to have all the shutdown stuff handled in the streams thread. I don't have a strong preference either way though.",
        "createdAt" : "2018-01-02T01:56:26Z",
        "updatedAt" : "2018-01-02T02:05:30Z",
        "lastEditedBy" : "5b2b5fa0-0fb4-4e52-a4f9-9d4318b5ae5d",
        "tags" : [
        ]
      },
      {
        "id" : "5f1f12fe-c946-463f-a3ee-e4c81a1c5447",
        "parentId" : "0bca94a6-8674-4fec-999b-b1e8a69ba6ca",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This lgtm.",
        "createdAt" : "2018-01-02T17:29:57Z",
        "updatedAt" : "2018-01-02T17:29:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5902a645c8eb9fc9f25f3c7076a0acc7d1e5def3",
    "line" : 80,
    "diffHunk" : "@@ -1,1 +1099,1103 @@        if (oldState == State.CREATED) {\n            // Start so that we shutdown on the thread\n            this.start();\n        }\n    }"
  },
  {
    "id" : "5be4b37b-86f5-460e-baa5-af0a95a3a5e9",
    "prId" : 4636,
    "prUrl" : "https://github.com/apache/kafka/pull/4636#pullrequestreview-123532297",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93331a55-a64a-4ef0-90af-9e7153b31699",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I'm probably missing something and brought this up before, but above in `onPartitionsAssigned` we create tasks with the `assignment` when _not_ version probing.  But in `onPartitionsRevoked` if we are version probing we flip the version probing flag, hence on assignment we create tasks.  Why don't we flip the version probing flag in `onPartitionedAssigned` as an else statement on line 270 so we are only every suspending and creating tasks during non-version probing rebalances?",
        "createdAt" : "2018-05-25T19:38:11Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "5f52f736-e2fe-44cb-9d03-1938e4a86824",
        "parentId" : "93331a55-a64a-4ef0-90af-9e7153b31699",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`onPartitionsAssigned`: if version probing flag is set, it means assignment is empty and we want to trigger a new rebalance. If we call `taskManager.createTasks(assignment);`, we would close suspended task and that is what we do not want to do at this point, because we hope to get those task assigned after the second rebalance.\r\n\r\n`onPartitionsRevoked`: if version probing flag is set, we don't want to suspend tasks either. Tasks are already suspended but if we call `taskManager.suspendTasksAndState();` again, we loose the information about currently suspended tasks (but we need to keep this information; ie, we avoid an incorrect internal metadata update here).\r\n\r\nThe flow is the following:\r\n - trigger first rebalance\r\n - onPartitionsRevoke -> version probing flag not set: suspend tasks regularly\r\n - onPartitionAssigned -> version probing flag set by StreamsPartitionsAssignor: we skip task creation as we will rebalance again (we cannot reset the flag here, because we need it in the next step)\r\n - trigger second rebalance\r\n - onPartitionsRevoke -> version probing flag is still set; we can reset the flag and skip suspending tasks to preserve metadata\r\n - onPartitionAssigned -> version probing flag not set: we do regular assignment and start processing\r\n\r\nDoes this make sense?",
        "createdAt" : "2018-05-25T22:29:51Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "62dd3643-53d4-4354-980a-e91080891a1e",
        "parentId" : "93331a55-a64a-4ef0-90af-9e7153b31699",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "yep - thanks for the clarification",
        "createdAt" : "2018-05-25T22:57:15Z",
        "updatedAt" : "2018-05-31T03:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a87bd5254155a9d60ba479371305ddaae99282d",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +305,309 @@                        streamThread.versionProbingFlag.set(false);\n                    } else {\n                        taskManager.suspendTasksAndState();\n                    }\n                } catch (final Throwable t) {"
  },
  {
    "id" : "f7d80ca4-d114-4e25-af7b-6653097ec8ec",
    "prId" : 4998,
    "prUrl" : "https://github.com/apache/kafka/pull/4998#pullrequestreview-119296797",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "940b510c-38e9-4113-a546-d8c031031e9e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Hmm... note that when EOS is turned on, each task will has its own producer client and the producer object passed in here will be null.\r\n\r\nSo I'd suggest update the following code in line 1224: when `producer == null`, try to iterate the owned tasks from the `taskManager.activeTasks().values()` and get its producer (it is private, so we may need to add a package private getter).\r\n\r\nIn this way for both EOS and non-EOS we will get the producer metrics.",
        "createdAt" : "2018-05-10T23:17:44Z",
        "updatedAt" : "2018-05-15T16:31:43Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "44fbb0b3-49f8-4502-b7db-a6966f7c59bf",
        "parentId" : "940b510c-38e9-4113-a546-d8c031031e9e",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Make sense to me!",
        "createdAt" : "2018-05-11T01:33:20Z",
        "updatedAt" : "2018-05-15T16:31:43Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c857b9a7f14178e17b0a647af540b7af3bed2cf",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +694,698 @@        this.rebalanceListener = new RebalanceListener(time, taskManager, this, this.log);\n        this.taskManager = taskManager;\n        this.producer = producer;\n        this.restoreConsumer = restoreConsumer;\n        this.consumer = consumer;"
  },
  {
    "id" : "f7e60af9-0ad5-45f3-8116-675049bab694",
    "prId" : 5107,
    "prUrl" : "https://github.com/apache/kafka/pull/5107#pullrequestreview-126131413",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b3c1795-90d7-4cfb-8037-2c2b0788d8f1",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thank you, Java8! :)",
        "createdAt" : "2018-06-05T20:09:33Z",
        "updatedAt" : "2018-06-08T15:17:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b829d558490d21cf4350eb54a4f18880243744ba",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +214,218 @@                updateThreadMetadata(taskManager.activeTasks(), taskManager.standbyTasks());\n            } else {\n                updateThreadMetadata(Collections.emptyMap(), Collections.emptyMap());\n            }\n        }"
  },
  {
    "id" : "e3093a65-eef0-4cfe-94fc-2c43e44e06d9",
    "prId" : 5107,
    "prUrl" : "https://github.com/apache/kafka/pull/5107#pullrequestreview-126403871",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "939bb584-7f2d-4cb1-8e5d-80dfbb58ed73",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "As above: should we check for `\"restore.consumer.poll.ms\"` ?",
        "createdAt" : "2018-06-05T20:10:16Z",
        "updatedAt" : "2018-06-08T15:17:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "afbd1db6-b28c-41f1-94b3-49a4877224fe",
        "parentId" : "939bb584-7f2d-4cb1-8e5d-80dfbb58ed73",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I guess not, following Guozhang's comment.",
        "createdAt" : "2018-06-06T14:34:36Z",
        "updatedAt" : "2018-06-08T15:17:39Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "b829d558490d21cf4350eb54a4f18880243744ba",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +604,608 @@        final Map<String, Object> restoreConsumerConfigs = config.getRestoreConsumerConfigs(threadClientId);\n        final Consumer<byte[], byte[]> restoreConsumer = clientSupplier.getRestoreConsumer(restoreConsumerConfigs);\n        final Duration pollTime = Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreConsumer, pollTime, userStateRestoreListener, logContext);\n"
  },
  {
    "id" : "bdc74563-3614-4ba7-aca5-9d317ee67438",
    "prId" : 5107,
    "prUrl" : "https://github.com/apache/kafka/pull/5107#pullrequestreview-126403898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f17de47-3996-454d-8987-91eba04650a3",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above: `\"main.consumer.poll.ms\"` ?",
        "createdAt" : "2018-06-05T20:13:48Z",
        "updatedAt" : "2018-06-08T15:17:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "11e574af-5f73-43c7-9b85-5f2ef4da3f38",
        "parentId" : "5f17de47-3996-454d-8987-91eba04650a3",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I guess not, following Guozhang's comment.",
        "createdAt" : "2018-06-06T14:34:40Z",
        "updatedAt" : "2018-06-08T15:17:39Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "b829d558490d21cf4350eb54a4f18880243744ba",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +713,717 @@        this.versionProbingFlag = versionProbingFlag;\n\n        this.pollTime = Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG));\n        this.commitTimeMs = config.getLong(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG);\n"
  },
  {
    "id" : "40fca684-ecc5-4f5b-9ee4-7351a46ee4d8",
    "prId" : 5306,
    "prUrl" : "https://github.com/apache/kafka/pull/5306#pullrequestreview-132939982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c43c1ccb-dc68-4c75-823a-0cb10167f64e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: should we unify `PARTITONS_REVOKED` and ` RUNNING`?",
        "createdAt" : "2018-06-28T03:49:25Z",
        "updatedAt" : "2018-06-28T03:51:40Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2777d5a6-1313-431f-b728-fdc6a95524ea",
        "parentId" : "c43c1ccb-dc68-4c75-823a-0cb10167f64e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I've thought about that, and I think moving forward we may want still use different poll time for RUNNING and PARTITION_REVOKED as well, since for former we should use normal long polling, while for latter there may be some optimization we can do regarding the consumer internals. But those ideas need to be validated via some profiling. I'm intentionally leaving them separated for now.",
        "createdAt" : "2018-06-28T17:18:13Z",
        "updatedAt" : "2018-06-28T17:18:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "731877a66ffe2ffbca721e27adada3ce65420c4b",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +812,816 @@            // try to fetch some records with normal poll time\n            // in order to get long polling\n            records = pollRequests(pollTime);\n        } else {\n            // any other state should not happen"
  },
  {
    "id" : "d0df1d4a-5e90-4f4b-ace9-1b92b5cebaef",
    "prId" : 5398,
    "prUrl" : "https://github.com/apache/kafka/pull/5398#pullrequestreview-138881703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c63ef0b0-f695-41c2-ae39-1c68f62a9558",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "why this change?",
        "createdAt" : "2018-07-19T22:29:55Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "16dc2297-b29f-4ff3-b8f4-08c76c202eaf",
        "parentId" : "c63ef0b0-f695-41c2-ae39-1c68f62a9558",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "As in description :)\r\n\r\n```\r\nBreak the main loop on put-raw-data and process-them. Since now not all data put into the queue would be processed completely within a single iteration.\r\n```",
        "createdAt" : "2018-07-19T23:00:56Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c57cec79fa53032b55dd7a5f374c9ee62c25098",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +837,841 @@        }\n\n        if (taskManager.hasActiveRunningTasks()) {\n            final long totalProcessed = processAndMaybeCommit(recordsProcessedBeforeCommit);\n            if (totalProcessed > 0) {"
  },
  {
    "id" : "cc613a3d-a1f9-42bc-9769-67afbf8c618b",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-144980385",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ab64dfc-3195-40b6-b07d-d00e65254583",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Could we actually remove this guard? We don't call `time. milliseconds()` as below.",
        "createdAt" : "2018-08-08T22:55:11Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "0fe9115b-1f17-4987-871b-058233659276",
        "parentId" : "5ab64dfc-3195-40b6-b07d-d00e65254583",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The intention is to save calling `taskManager.activeTaskIds(), taskManager.standbyTaskIds()` etc and pass them as parameters. It may not really introduce significant differences, but no harm to still keep them?",
        "createdAt" : "2018-08-09T00:06:00Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e70120d2-9f20-4d3e-946d-c58af8566874",
        "parentId" : "5ab64dfc-3195-40b6-b07d-d00e65254583",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fine with me to keep the guard. Was just double checking.",
        "createdAt" : "2018-08-09T18:56:36Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 320,
    "diffHunk" : "@@ -1,1 +1028,1032 @@                taskManager.maybePurgeCommitedRecords();\n\n                if (log.isDebugEnabled()) {\n                    log.debug(\"Committed all active tasks {} and standby tasks {} in {}ms\",\n                        taskManager.activeTaskIds(), taskManager.standbyTaskIds(), intervalCommitLatency);"
  },
  {
    "id" : "e00cb96a-3b9b-4595-a50f-c246899fab30",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-145833804",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad033956-8eed-4c8f-a155-6455ab5bd55e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I didn't follow why we need this now. Can you explain?",
        "createdAt" : "2018-08-10T15:13:11Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8851e650-64d0-48f9-ba02-0fe5e80c01c1",
        "parentId" : "ad033956-8eed-4c8f-a155-6455ab5bd55e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is following the same PR that @mjsax had: https://github.com/apache/kafka/pull/5389\r\n\r\nThe point is that when a XXXConfig is created, by default it will print `logAll` and hence swamped the logs (we can see the same lists to be printed multiple times whenever it is created). This function is to disable `log` for such cases.",
        "createdAt" : "2018-08-10T23:23:23Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "35f89b4e-3c20-4cf7-9e6a-ff740560db27",
        "parentId" : "ad033956-8eed-4c8f-a155-6455ab5bd55e",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ah! I misread this as turning `logAll` *on* instead of *off*. Now I get it :)",
        "createdAt" : "2018-08-13T21:00:25Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +729,733 @@        }\n    }\n\n    /**\n     * Execute the stream processors"
  },
  {
    "id" : "878d8c45-8593-4636-92cd-47c5b59b7d92",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149928399",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f175717-5142-44ca-966c-722f9737c1b0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "It seem we rely on `computeLatency()` above to advance `now` -- it seems \"dangerous\" to rely on a \"side effect\" for this. Should we advance time explicitly here? Or at least put a check if `now < lastPollMs || now > timeSinceLastPoll` ?",
        "createdAt" : "2018-08-25T00:22:19Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "433b6eb6-dc52-46ac-a6b1-7cc7451391a6",
        "parentId" : "3f175717-5142-44ca-966c-722f9737c1b0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The motivation of advancing `now` in `computeLatency` is to save on `milliseconds()` call. I admit it is not ideal, if we want to change it to a different way, say: passing `now` along the calls than using a variable at all, then I'd suggest we do it in a separate PR as this PR has been dragging too long.\r\n\r\nRegarding the check: that is a good idea, but I guess you mean `now - lastPollMs > timeSinceLastPoll` right? I will add that check.",
        "createdAt" : "2018-08-28T00:24:58Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 163,
    "diffHunk" : "@@ -1,1 +879,883 @@                }\n\n                timeSinceLastPoll = Math.max(now - lastPollMs, 0);\n\n                if (maybePunctuate() || maybeCommit()) {"
  },
  {
    "id" : "317c7c63-1664-4d1f-b369-867c7de07335",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149929974",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c35edcca-d516-48e9-be09-9afa3b4a29bd",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: should we rename to `taskManger.maybePunctuate()` as well as `AssignedStreamTasks#maybePunctuate()` to align naming?",
        "createdAt" : "2018-08-25T00:24:17Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ef470d7d-0fb5-4084-982b-9d85a3ef1569",
        "parentId" : "c35edcca-d516-48e9-be09-9afa3b4a29bd",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think `commit()` and `punctuate()` in TaskManager is okay, as they return the number of actual number of punctuation / commits triggered, while the `maybeXX` returns true or false.",
        "createdAt" : "2018-08-28T00:28:20Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 245,
    "diffHunk" : "@@ -1,1 +994,998 @@     */\n    private boolean maybePunctuate() {\n        final int punctuated = taskManager.punctuate();\n        if (punctuated > 0) {\n            final long punctuateLatency = advanceNowAndComputeLatency();"
  },
  {
    "id" : "549de892-856c-43c9-b454-0e2768f87025",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-191960169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c22a368-d6ee-47f4-8b52-526999732d17",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we have a comment on explaining what `shared` means in this context?",
        "createdAt" : "2019-01-13T04:37:00Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +753,757 @@\n    // currently admin client is shared among all threads\n    public static String getSharedAdminClientId(final String clientId) {\n        return clientId + \"-admin\";\n    }"
  },
  {
    "id" : "1dbcc0dc-ba91-4f86-8eb8-5f4037c232c0",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-194213849",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "032fe55f-7b04-474c-a15b-688fe021e090",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we keep the format of `updateThreadMetadata` to avoid unnecessary changes on L1221?",
        "createdAt" : "2019-01-13T04:43:51Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "a128cdde-b232-429e-a21d-c0399721d5ad",
        "parentId" : "032fe55f-7b04-474c-a15b-688fe021e090",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I cannot completely follow since L1221 did not change, could you elaborate?",
        "createdAt" : "2019-01-15T22:22:51Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "67993f3b-1e4b-4ae4-a44a-9ca737632e14",
        "parentId" : "032fe55f-7b04-474c-a15b-688fe021e090",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I mean, if we keep parameters in one line:\r\n` private void updateThreadMetadata(final Map<TaskId, StreamTask> activeTasks, final Map<TaskId, StandbyTask> standbyTasks)` then the changes shall be reduced.",
        "createdAt" : "2019-01-16T00:12:56Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "194b44d6-816c-44db-8546-3edd1eb50465",
        "parentId" : "032fe55f-7b04-474c-a15b-688fe021e090",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The line is quite long, thus we should reformat it to make the code more readable. I am +1 on this change -- also, I don't think we should optimize for fewer line changes :)",
        "createdAt" : "2019-01-18T18:02:31Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +1256,1260 @@    }\n\n    private void updateThreadMetadata(final Map<TaskId, StreamTask> activeTasks,\n                                      final Map<TaskId, StandbyTask> standbyTasks) {\n        final Set<String> producerClientIds = new HashSet<>();"
  },
  {
    "id" : "00a21281-57a2-4266-9a79-5a380d16f001",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-191960169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1dfb3fd1-2a43-4334-8d88-f5e2913cf354",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Since this constructor is only called once, could we just reuse the constructor augmented:\r\n```\r\npublic ThreadMetadata(final String threadName,\r\n                          final String threadState,\r\n                          final String mainConsumerClientId,\r\n                          final String restoreConsumerClientId,\r\n                          final Set<String> producerClientIds,\r\n                          final String adminClientId,\r\n                          final Set<TaskMetadata> activeTasks,\r\n                          final Set<TaskMetadata> standbyTasks)\r\n```\r\nand set active & standby tasks with empty set? I figure this could reduce code redundancy.",
        "createdAt" : "2019-01-13T04:47:11Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 91,
    "diffHunk" : "@@ -1,1 +1243,1247 @@    StreamThread updateThreadMetadata(final String adminClientId) {\n\n        threadMetadata = new ThreadMetadata(\n            this.getName(),\n            this.state().name(),"
  },
  {
    "id" : "c54db788-4b0e-4327-8a43-6a7792edbc9d",
    "prId" : 6107,
    "prUrl" : "https://github.com/apache/kafka/pull/6107#pullrequestreview-194338978",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bde155af-30ca-439f-8623-c4a10495adf9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we not pass the admin client-id into the constructor?",
        "createdAt" : "2019-01-18T18:01:03Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6463f541-b8f1-4946-a2cb-bbfe0b0b3f98",
        "parentId" : "bde155af-30ca-439f-8623-c4a10495adf9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I've thought about passing in the client-id, it is a bit overkill in addition to the thread-client-id just to set the shared admin client inside the constructor. I felt the current way is less intrusive but if you feel strong the other way we can discuss.",
        "createdAt" : "2019-01-18T19:54:19Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b4481aaf-458e-4a50-af76-6b6abcd43d60",
        "parentId" : "bde155af-30ca-439f-8623-c4a10495adf9",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Because the shared admit client id does never change, it seems weird to have a setter that allow to update is at any time. It seems cleaner to pass it in the constructor and make it immutable this way.",
        "createdAt" : "2019-01-19T02:13:31Z",
        "updatedAt" : "2019-01-23T23:34:09Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e8c144ba2d48adfd7b35fdfc7224106c295254",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +689,693 @@            logContext,\n            assignmentErrorCode)\n            .updateThreadMetadata(getSharedAdminClientId(clientId));\n    }\n"
  },
  {
    "id" : "c159aabb-12d3-468d-bdfc-94df7b8b3c6e",
    "prId" : 7008,
    "prUrl" : "https://github.com/apache/kafka/pull/7008#pullrequestreview-261449849",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "555df2e0-8564-409e-aec6-db275cefacd2",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Does this still work for optimized source tables, which read from the input topic instead?",
        "createdAt" : "2019-07-05T19:26:45Z",
        "updatedAt" : "2019-07-09T13:01:47Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "e6bb384d-541d-4952-a59a-b58d4bab6f46",
        "parentId" : "555df2e0-8564-409e-aec6-db275cefacd2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Good point. Thinking about this, StandBys for source-KTables might have been broker for a long time already... (maybe since 0.10.0.0???)\r\n\r\nMaybe @cadonna can verify? If that is the case, we should split out a separate ticket and PR to fix StandBys for source-KTables independently.",
        "createdAt" : "2019-07-09T01:57:52Z",
        "updatedAt" : "2019-07-09T13:01:47Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "32b89725-86c4-4822-894a-13d4f041c31e",
        "parentId" : "555df2e0-8564-409e-aec6-db275cefacd2",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Yeah, good point! Added an integration test to verify materialized and optimized source tables.",
        "createdAt" : "2019-07-09T13:03:17Z",
        "updatedAt" : "2019-07-09T13:03:17Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "4bf0d92c-c02b-4f77-aa59-b8e0ea86f592",
        "parentId" : "555df2e0-8564-409e-aec6-db275cefacd2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Cannot follow. You test seem to use the PAPI, and the PAPI does not provide the KTable optimization. You would need to use `StreamBuilder#table()` to test the changelog optimization.",
        "createdAt" : "2019-07-10T20:54:39Z",
        "updatedAt" : "2019-07-10T20:54:40Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6e5e4926-58bf-4281-961c-aacf3831ffd5",
        "parentId" : "555df2e0-8564-409e-aec6-db275cefacd2",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "See `StandbyTaskCreationIntegrationTest` line 128.",
        "createdAt" : "2019-07-12T19:59:51Z",
        "updatedAt" : "2019-07-12T19:59:51Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae3290c70e892fdadcd6585d2e05696628689718",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +496,500 @@            final ProcessorTopology topology = builder.build(taskId.topicGroupId);\n\n            if (!topology.stateStores().isEmpty() && !topology.storeToChangelogTopic().isEmpty()) {\n                return new StandbyTask(\n                    taskId,"
  },
  {
    "id" : "2b029000-687e-4961-a11a-6458190accba",
    "prId" : 7021,
    "prUrl" : "https://github.com/apache/kafka/pull/7021#pullrequestreview-259661520",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47cb6d36-31fe-4f69-88e8-6a5878b598fb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This might be miss leading for users who don't know the details. What about:\r\n```\r\nlog.debug(\"Ignoring request to transit from PENDING_SHUTDOWN to {}\", newState);\r\n```",
        "createdAt" : "2019-07-09T00:53:26Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3706ba2e-4a23-4c73-8c19-52590752f8d9",
        "parentId" : "47cb6d36-31fe-4f69-88e8-6a5878b598fb",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Would be better to add an explanation for ignorance?",
        "createdAt" : "2019-07-09T02:26:13Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "3b4424e2-170c-4710-87b2-22e13e51682e",
        "parentId" : "47cb6d36-31fe-4f69-88e8-6a5878b598fb",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Sure. Why not. I just would avoid the term \"invalid\" because it might confuse users (they may thing something bad happens, but it's expected and not bad).",
        "createdAt" : "2019-07-09T03:35:16Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "375bc4bd-465a-4375-afde-cfbc3459b84a",
        "parentId" : "47cb6d36-31fe-4f69-88e8-6a5878b598fb",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Sounds good",
        "createdAt" : "2019-07-09T17:48:03Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6ec626b0d4a4252209fffa8f705fcda739a2e7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +192,196 @@            if (state == State.PENDING_SHUTDOWN && newState != State.DEAD) {\n                log.debug(\"Ignoring request to transit from PENDING_SHUTDOWN to {}: \" +\n                              \"only DEAD state is a valid next state\", newState);\n                // when the state is already in PENDING_SHUTDOWN, all other transitions will be\n                // refused but we do not throw exception here"
  },
  {
    "id" : "78d4b7a2-ddd0-41b4-bf0f-0229f0a3700f",
    "prId" : 7021,
    "prUrl" : "https://github.com/apache/kafka/pull/7021#pullrequestreview-259223839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "817c3a8d-384e-4dc1-8981-84e901384681",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Similar to above.",
        "createdAt" : "2019-07-09T00:53:36Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6ec626b0d4a4252209fffa8f705fcda739a2e7",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +198,202 @@            } else if (state == State.DEAD) {\n                log.debug(\"Ignoring request to transit from DEAD to {}: \" +\n                              \"no valid next state after DEAD\", newState);\n                // when the state is already in NOT_RUNNING, all its transitions\n                // will be refused but we do not throw exception here"
  },
  {
    "id" : "f95fc721-ad56-4b8c-b913-0b72096d3a23",
    "prId" : 7021,
    "prUrl" : "https://github.com/apache/kafka/pull/7021#pullrequestreview-262101642",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a648713-3081-49a9-9c04-5288224851ea",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thinking about this, I am wondering if we should just change the FSM to allow this transition and simplify the code here? \\cc @guozhangwang ",
        "createdAt" : "2019-07-09T00:57:20Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fca57b9d-a76c-4551-b5e5-20f20462e563",
        "parentId" : "9a648713-3081-49a9-9c04-5288224851ea",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I thought about this when tightening the FSM before but the unit tests reminds me of one thing: our current contract is that we only transit to PARTITIONS_REVOKED when calling onPartitionsRevoked, which is called only once at the beginning of the rebalance today, so keeping it strict is better just in case we have incorrect partial rebalance procedure.\r\n\r\nWith KIP-429 this may be violated so we need to revisit our FSM once Streams adopt cooperative protocols. cc @ableegoldman who's working on this.",
        "createdAt" : "2019-07-15T22:10:30Z",
        "updatedAt" : "2019-07-15T22:45:32Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6ec626b0d4a4252209fffa8f705fcda739a2e7",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +204,208 @@            } else if (state == State.PARTITIONS_REVOKED && newState == State.PARTITIONS_REVOKED) {\n                log.debug(\"Ignoring request to transit from PARTITIONS_REVOKED to PARTITIONS_REVOKED: \" +\n                              \"self transition is not allowed\");\n                // when the state is already in PARTITIONS_REVOKED, its transition to itself will be\n                // refused but we do not throw exception here"
  },
  {
    "id" : "90957c73-eeb9-4904-954f-ab81fda5a10d",
    "prId" : 7021,
    "prUrl" : "https://github.com/apache/kafka/pull/7021#pullrequestreview-259768529",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e500e085-5c36-4d24-abe7-dabc6c466a17",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Isn't this a rather brittle fix? How does this code guarantee that after `streamThread.assignmentErrorCode.get() != StreamsPartitionAssignor.Error.NONE.code()` is `false`, the result of `streamThread.assignmentErrorCode.get()` does not change again before the tasks are created? ",
        "createdAt" : "2019-07-09T09:11:49Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "d34d49ca-7090-47c9-b90b-88f1029e2bb1",
        "parentId" : "e500e085-5c36-4d24-abe7-dabc6c466a17",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "in `PartitionsAssigned` we should have already passed the assignment error placement, so I won't expect another flip for its value during this round rebalance.",
        "createdAt" : "2019-07-09T20:05:22Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "d3b7836c-068d-4517-95f9-b0b5b80a91d3",
        "parentId" : "e500e085-5c36-4d24-abe7-dabc6c466a17",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Makes sense",
        "createdAt" : "2019-07-09T21:25:21Z",
        "updatedAt" : "2019-07-10T15:28:46Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6ec626b0d4a4252209fffa8f705fcda739a2e7",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +279,283 @@                        streamThread.state()\n                    );\n                } else if (streamThread.assignmentErrorCode.get() != StreamsPartitionAssignor.Error.NONE.code()) {\n                    log.debug(\n                        \"Encountered assignment error during partition assignment: {}. Skipping task initialization\","
  },
  {
    "id" : "65144890-b13a-4dda-b21b-5abdc8f98bc9",
    "prId" : 7021,
    "prUrl" : "https://github.com/apache/kafka/pull/7021#pullrequestreview-262101642",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9f130aa1-de09-4d7d-925c-7ee05232ebc9",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice catch.",
        "createdAt" : "2019-07-15T22:12:03Z",
        "updatedAt" : "2019-07-15T22:45:32Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6ec626b0d4a4252209fffa8f705fcda739a2e7",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +291,295 @@                log.error(\n                    \"Error caught during partition assignment, \" +\n                        \"will abort the current process and re-throw at the end of rebalance\", t);\n                streamThread.setRebalanceException(t);\n            } finally {"
  },
  {
    "id" : "16c19dd9-c9bb-468c-afc3-27d007f74c7f",
    "prId" : 7143,
    "prUrl" : "https://github.com/apache/kafka/pull/7143#pullrequestreview-269804841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80ec6b1b-ba00-421b-bda3-9df84e8227e6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The problem was here: `committed` could be zero without this fix.",
        "createdAt" : "2019-08-01T01:19:47Z",
        "updatedAt" : "2019-08-01T01:19:47Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ad90e171-bcab-4d7f-a19c-b4b8278067bd",
        "parentId" : "80ec6b1b-ba00-421b-bda3-9df84e8227e6",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Seems like this should have noticeably screwed up these metrics, do we think this branch is just rarely seen or no one has noticed somehow?",
        "createdAt" : "2019-08-01T17:58:48Z",
        "updatedAt" : "2019-08-01T17:58:48Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "f9ed7e88-ae2c-42d1-8b3b-f7e132e81799",
        "parentId" : "80ec6b1b-ba00-421b-bda3-9df84e8227e6",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think it's rarely executed. Only if a PAPI user request committing via `context.commit()`, what is expected to be rarely used feature.",
        "createdAt" : "2019-08-01T18:35:21Z",
        "updatedAt" : "2019-08-01T18:35:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb9409410771116061cc2e3ae35fce6bc8cc67a9",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +1071,1075 @@            if (committed > 0) {\n                final long requestCommitLatency = advanceNowAndComputeLatency();\n                commitSensor.record(requestCommitLatency / (double) committed, now);\n            }\n        }"
  },
  {
    "id" : "fd954207-dc3c-4639-8332-30618ebba169",
    "prId" : 7321,
    "prUrl" : "https://github.com/apache/kafka/pull/7321#pullrequestreview-292074297",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b477b1bc-c11c-41e3-8b63-8ed9f29dd0e6",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Nothing changed here, just trying to make it more readable. Did modify the fsm diagram above, but only to make it consistent with the transitions listed here -- basically, we can now transition directly to PARTITIONS_ASSIGNED",
        "createdAt" : "2019-09-23T21:50:27Z",
        "updatedAt" : "2019-09-24T05:45:47Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3935aa6be7cc55911bb4e24332557df24d01f18",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +134,138 @@    public enum State implements ThreadStateTransitionValidator {\n\n        CREATED(1, 5),                   // 0\n        STARTING(2, 3, 5),               // 1\n        PARTITIONS_REVOKED(3, 5),        // 2"
  },
  {
    "id" : "ae985cf6-113e-4c17-833f-71e8df5b5837",
    "prId" : 7386,
    "prUrl" : "https://github.com/apache/kafka/pull/7386#pullrequestreview-293937243",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7955c35a-4217-4319-8888-1d49c745a6e2",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Allow PARTITIONS_REVOKED to transition to itself (but callback is a no-op if no new partitions have been revoked)",
        "createdAt" : "2019-09-26T18:58:40Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "f047cd9bea88a4ffc88ce2b4f82946d52202c539",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +137,141 @@        CREATED(1, 5),                    // 0\n        STARTING(2, 3, 5),                // 1\n        PARTITIONS_REVOKED(2, 3, 5),      // 2\n        PARTITIONS_ASSIGNED(2, 3, 4, 5),  // 3\n        RUNNING(2, 3, 5),                 // 4"
  },
  {
    "id" : "92aa39cc-4f1e-4941-8b8b-a85b1d622f83",
    "prId" : 7386,
    "prUrl" : "https://github.com/apache/kafka/pull/7386#pullrequestreview-296451491",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fef9324a-e1ab-4043-a46b-8deb9bac863f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a meta comment: maybe another (equally hacky?) way to do this, is to expose the `MemberState` from `ConsumerMetadata` (we are exposing this in KIP-447). And then in Streams, we can check that state after each `poll` call -- remember that state can only change within the poll call, and depending on that we can decide whether or not commit.\r\n\r\nAs for now I think this way is fine, cannot really think of a better way that does not change public APIs.",
        "createdAt" : "2019-10-01T16:13:53Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0d013f4a-734b-4e8d-a666-8efb7e8bb00c",
        "parentId" : "fef9324a-e1ab-4043-a46b-8deb9bac863f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "cc @abbccdda ",
        "createdAt" : "2019-10-02T18:50:19Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f047cd9bea88a4ffc88ce2b4f82946d52202c539",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +981,985 @@            }\n\n            if (committed == -1) {\n                log.trace(\"Unable to commit as we are in the middle of a rebalance, will try again when it completes.\");\n            } else {"
  },
  {
    "id" : "5d7f8f35-cffd-4c8a-9fa2-ca27aeec2c46",
    "prId" : 7386,
    "prUrl" : "https://github.com/apache/kafka/pull/7386#pullrequestreview-297864337",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5a9ac92-9a1e-4cb7-b516-9a25b199e28f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "What's this trace for?",
        "createdAt" : "2019-10-02T18:24:08Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "368d135d-28b0-4941-b9d5-3da44204cbf9",
        "parentId" : "c5a9ac92-9a1e-4cb7-b516-9a25b199e28f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I thought it might be helpful to see that we are not committing some of what we've processed, because it is we can't commit during a rebalance. But I don't think it's absolutely necessary and can take it out if you don't think it adds much?",
        "createdAt" : "2019-10-02T19:38:55Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "5d566371-9ea5-4e50-96ee-1204108897ff",
        "parentId" : "c5a9ac92-9a1e-4cb7-b516-9a25b199e28f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think it's okay to leave it as TRACE, as practically we do not turn on TRACE that frequently.",
        "createdAt" : "2019-10-06T22:24:25Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f047cd9bea88a4ffc88ce2b4f82946d52202c539",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +981,985 @@            }\n\n            if (committed == -1) {\n                log.trace(\"Unable to commit as we are in the middle of a rebalance, will try again when it completes.\");\n            } else {"
  },
  {
    "id" : "6194eec0-4003-455d-aea7-4b319c58c62d",
    "prId" : 7386,
    "prUrl" : "https://github.com/apache/kafka/pull/7386#pullrequestreview-296944383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42f4d08b-57c2-4429-944d-7a9103accbe7",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We can potentially be in PARTITIONS_REVOKED with cooperative rebalancing so we don't want to just block doing nothing during the rebalance -- not sure if it's worth polling for zero since this is rare with cooperative, or some other time < `pollTime`? cc/ @guozhangwang ",
        "createdAt" : "2019-10-03T02:42:01Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "8ce7349a-c95f-4c4b-b211-cc801383d609",
        "parentId" : "42f4d08b-57c2-4429-944d-7a9103accbe7",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In EAGER, during the PARTITIONS_REVOKED state we would not return any data from consumer anyways; In future COOPERATIVE, even if we can return some data during the rebalance, the transition of PARTITIONS_REVOKED -> PARTITIONS_ASSIGNED would happen in a single `consumer.poll` call, and only very rarely we would stay in PARTITION_REVOKED after consumer.poll if the subscription changed. So I think poll with zero sounds good to me.\r\n\r\nAlso note that in my PR for returning data in the middle of a rebalance, we still pass in non-zero timeout for finding the coordinator so that we are ensured to have one round-trip at least within that call.",
        "createdAt" : "2019-10-03T15:09:40Z",
        "updatedAt" : "2019-10-06T23:53:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f047cd9bea88a4ffc88ce2b4f82946d52202c539",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +745,749 @@            records = pollRequests(Duration.ZERO);\n        } else if (state == State.PARTITIONS_REVOKED) {\n            // try to fetch som records with zero poll millis to unblock\n            // other useful work while waiting for the join response\n            records = pollRequests(Duration.ZERO);"
  },
  {
    "id" : "431c205e-3828-45d6-b9b9-c14c35c49f9f",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-301564318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d45ad4d9-32ce-4bfb-826a-85bc2c394bde",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Side cleanup",
        "createdAt" : "2019-10-08T06:29:57Z",
        "updatedAt" : "2019-10-10T01:02:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "cdf1b016-8020-4b47-9306-905361ec07f3",
        "parentId" : "d45ad4d9-32ce-4bfb-826a-85bc2c394bde",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Why do we need a LinkedHashMap here? Particularly because the interface doesn't suggest it needs anything more than a Map implementation? Actually I'm also wondering why we need to copy at all since we get back a read only view of the map from Admin and it appears the only consumer of adminClientMetrics immediately copies the results anyway.",
        "createdAt" : "2019-10-14T15:52:51Z",
        "updatedAt" : "2019-10-14T15:52:51Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "f04c78e6-2819-4d92-a825-d5c94fc3c27f",
        "parentId" : "d45ad4d9-32ce-4bfb-826a-85bc2c394bde",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure about the `LinkedHashMap` -- maybe @guozhangwang knows more?\r\n\r\nFor why to copy: it's not a public contract that we get a read-only map and hence we need to guard the map from writes via a copy. Not sure if we could rely on an AdminClient implementation detail... \\cc @cmccabe ?",
        "createdAt" : "2019-10-14T21:59:17Z",
        "updatedAt" : "2019-10-14T21:59:17Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "e67856b5-c58b-4be3-8f7e-d4d516f499e9",
        "parentId" : "d45ad4d9-32ce-4bfb-826a-85bc2c394bde",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Yes, the only use case I found above this code is to immediately copy it into yet another map (which is why the LinkedHashMap also doesn't make sense), so it should not matter, unless we're expecting to do something else with it down the road. Anyway, per our discussion I'm OK with this going in without fixing it, but it is low hanging fruit to reduce unnecessary work.",
        "createdAt" : "2019-10-14T22:08:27Z",
        "updatedAt" : "2019-10-14T22:08:27Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1244,1248 @@    public Map<MetricName, Metric> adminClientMetrics() {\n        final Map<MetricName, ? extends Metric> adminClientMetrics = taskManager.adminClient().metrics();\n        return new LinkedHashMap<>(adminClientMetrics);\n    }\n"
  },
  {
    "id" : "ea244b61-c267-41c9-ab46-034b54db7f38",
    "prId" : 7969,
    "prUrl" : "https://github.com/apache/kafka/pull/7969#pullrequestreview-343660966",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d66be287-f4df-476c-95b5-af78f85e394b",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This is the actual fix; if the user has not themselves added pattern source topics we will go back to using regular subscription (having safely disabled auto topic creation)",
        "createdAt" : "2020-01-16T03:54:44Z",
        "updatedAt" : "2020-01-23T22:13:21Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ba3ee4e5849cae6c81d5b229846e0507630647f",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +718,722 @@\n    private void subscribeConsumer() {\n        if (builder.usesPatternSubscription()) {\n            consumer.subscribe(builder.sourceTopicPattern(), rebalanceListener);\n        } else {"
  },
  {
    "id" : "fa5316f7-f935-4f7b-ad92-c0a8d0cddff3",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-356393540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8cc7f71c-534a-4431-960f-60fc19b3d72b",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "maybe we can also log this as INFO for debugging purposes?",
        "createdAt" : "2020-02-11T02:41:54Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +923,927 @@                    // hence, we just skip adding the corresponding records\n                    log.info(\"State already transits to {}, skipping the add records to non-existing task for partition {}\", state, partition);\n                    continue;\n                }\n"
  },
  {
    "id" : "66e94936-85e2-45f5-8295-b846ceaf0887",
    "prId" : 8112,
    "prUrl" : "https://github.com/apache/kafka/pull/8112#pullrequestreview-359119292",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "396d5695-652e-409f-a6aa-8ad0d129953b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I moved this into the block here because it makes no difference to the result, and it's a little more efficient.",
        "createdAt" : "2020-02-14T18:08:00Z",
        "updatedAt" : "2020-02-14T18:08:21Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65733c1d76583d727dc6d5a7b6b2dd3d773993bf",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +860,864 @@                        // It makes no difference to the outcome of these metrics when we record \"0\",\n                        // so we can just avoid the method call when we didn't process anything.\n                        processRateSensor.record(processed, now);\n\n                        // This metric is scaled to represent the _average_ processing time of _each_"
  },
  {
    "id" : "86ff6a94-97eb-40bd-91b6-00ea0de54b00",
    "prId" : 8112,
    "prUrl" : "https://github.com/apache/kafka/pull/8112#pullrequestreview-359208182",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8f0201a-2b40-4165-bfd8-d6e95a086cad",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "not a suggestion: We have a new metrics proposed in KIP-444 to report the ratio of processing each task within a thread (CPU wise), hopefully that helps with the debugging purposes.",
        "createdAt" : "2020-02-14T18:24:38Z",
        "updatedAt" : "2020-02-14T18:27:45Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0d515261-e4e5-4620-be6b-4b4b67373593",
        "parentId" : "f8f0201a-2b40-4165-bfd8-d6e95a086cad",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Yeah, I think the task-level latency metric would be the most useful. At the thread-level, it seems better to just report the total latency of all processing, so you could help debug the sources of poll latency or whatever, but it didn't seem like a good idea to just change it with no KIP.",
        "createdAt" : "2020-02-14T20:43:49Z",
        "updatedAt" : "2020-02-14T20:43:49Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65733c1d76583d727dc6d5a7b6b2dd3d773993bf",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +864,868 @@                        // This metric is scaled to represent the _average_ processing time of _each_\n                        // task. Note, it's hard to interpret this as defined, but we would need a KIP\n                        // to change it to simply report the overall time spent processing all tasks.\n                        final long processLatency = advanceNowAndComputeLatency();\n                        processLatencySensor.record(processLatency / (double) processed, now);"
  },
  {
    "id" : "9d4977dd-6897-43db-84a9-23596dcafd70",
    "prId" : 8116,
    "prUrl" : "https://github.com/apache/kafka/pull/8116#pullrequestreview-358620922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4790a2f2-ed3a-42a6-92d3-d98546da722b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I added the exception to the log message, so we can see where the TaskMigratedException is actually caused.",
        "createdAt" : "2020-02-13T23:19:09Z",
        "updatedAt" : "2020-02-20T20:36:25Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ba79bf6de34142dff929bae3d5c9e50b96800c1",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +708,712 @@                             ignoreAndRejoinGroup.migratedTask().toString(\">\"),\n                         ignoreAndRejoinGroup\n                         );\n\n                enforceRebalance();"
  },
  {
    "id" : "5119b46b-324d-4633-879b-8c868966af1c",
    "prId" : 8140,
    "prUrl" : "https://github.com/apache/kafka/pull/8140#pullrequestreview-362141507",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b75c4641-a1a5-4205-b3c4-4657ce37a108",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This isn't a necessary part of the fix, but I feel it makes more sense to move this here: the restore consumer's can only make progress on tasks that have been initialized, which only happens in `taskManager.tryToCompleteRestoration`",
        "createdAt" : "2020-02-20T03:00:17Z",
        "updatedAt" : "2020-02-20T20:31:48Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "99370c88-dc07-4e3a-835b-616eda375a28",
        "parentId" : "b75c4641-a1a5-4205-b3c4-4657ce37a108",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I agree. Originally I put it in front intentionally since `initializeIfNeeded` is called at task creation not here, and we would only try to initialize the changelogs in `restore` and hence only check if the restoration can be completed.\r\n\r\nNow that we've delayed the `initializeIfNeeded` in `tryToComplete` we should reorder the restore call as well.",
        "createdAt" : "2020-02-20T18:47:10Z",
        "updatedAt" : "2020-02-20T20:31:48Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3164fce49de499e640dad11ed3d56ba47ad14bb7",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +836,840 @@        // we can always let changelog reader try restoring in order to initialize the changelogs;\n        // if there's no active restoring or standby updating it would not try to fetch any data\n        changelogReader.restore();\n\n        advanceNowAndComputeLatency();"
  },
  {
    "id" : "4d1c4682-b9e5-4b67-84ef-4725043aac1b",
    "prId" : 8190,
    "prUrl" : "https://github.com/apache/kafka/pull/8190#pullrequestreview-366171090",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c16cec8e-ea04-44ba-bcad-292ec0c32263",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is the actual fix.",
        "createdAt" : "2020-02-28T01:32:51Z",
        "updatedAt" : "2020-02-28T01:34:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "be99476e-0a59-4b75-9c19-5b0d19fff469",
        "parentId" : "c16cec8e-ea04-44ba-bcad-292ec0c32263",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We need to avoid adding these new records to the `PartitionGroup` down on line 825 or else they'll be included in the offsets committed",
        "createdAt" : "2020-02-28T05:41:27Z",
        "updatedAt" : "2020-02-28T05:41:28Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b0dccddb-b2d2-45ba-9f18-070a1ba4f14b",
        "parentId" : "c16cec8e-ea04-44ba-bcad-292ec0c32263",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "If we need to poll more than once to complete the rebalance for example",
        "createdAt" : "2020-02-28T05:43:36Z",
        "updatedAt" : "2020-02-28T05:43:36Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "84791c9a2da624b9d0c9dcffef2d0a4eb5e6d560",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +747,751 @@        // if the thread is still in the middle of a rebalance, we should keep polling\n        // until the rebalance is completed before we close and commit the tasks\n        while (isRunning() || taskManager.isRebalanceInProgress()) {\n            try {\n                runOnce();"
  },
  {
    "id" : "efb0639e-2de1-4569-b80b-412e140fd09d",
    "prId" : 8213,
    "prUrl" : "https://github.com/apache/kafka/pull/8213#pullrequestreview-368367495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47f0318b-eae4-4468-8b35-3694d7df6262",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "We don't manage the producers anymore, so we can defer to the taskManager (who will defer to the active task creator, but that's none of the thread's business)",
        "createdAt" : "2020-03-03T22:27:22Z",
        "updatedAt" : "2020-03-05T18:59:47Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "2eb596b0721bcf1908d19f811d96e5121ca4e41d",
    "line" : 413,
    "diffHunk" : "@@ -1,1 +934,938 @@\n    public Map<MetricName, Metric> producerMetrics() {\n        return taskManager.producerMetrics();\n    }\n"
  },
  {
    "id" : "9d0dc943-f8db-41b6-9a15-3e91f3fa42c4",
    "prId" : 8299,
    "prUrl" : "https://github.com/apache/kafka/pull/8299#pullrequestreview-375693073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5fb57414-dff0-48a4-a5aa-fcd22acf9b6d",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Are we deprecating the VERSION_PROBING?",
        "createdAt" : "2020-03-17T00:54:27Z",
        "updatedAt" : "2020-03-18T05:44:55Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "1dbcdb2e-f95e-4225-a95c-a3cbfc77025a",
        "parentId" : "5fb57414-dff0-48a4-a5aa-fcd22acf9b6d",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This isn't a client or externally-facing config, just something each thread sets internally if it detects version probing during `onAssignment`\r\nIf you're asking about the old log message, I moved it to where we set the error code.",
        "createdAt" : "2020-03-17T02:06:27Z",
        "updatedAt" : "2020-03-18T05:44:55Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "80c457cbd193c011347903439463da5e0a46b19f",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +497,501 @@            try {\n                runOnce();\n                if (assignmentErrorCode.get() == AssignorError.REBALANCE_NEEDED.code()) {\n                    assignmentErrorCode.set(AssignorError.NONE.code());\n                    mainConsumer.enforceRebalance();"
  },
  {
    "id" : "694870ed-4f02-47ff-ab11-8b5417642670",
    "prId" : 8318,
    "prUrl" : "https://github.com/apache/kafka/pull/8318#pullrequestreview-378183147",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "637e07e2-d174-4e64-b302-f0557f72e439",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`Not for this PR`: I think a better place for these static methods is StreamsConfig.",
        "createdAt" : "2020-03-19T22:49:08Z",
        "updatedAt" : "2020-03-21T18:49:58Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e4c3722c-c841-428a-8e65-a7fb6d5e8f17",
        "parentId" : "637e07e2-d174-4e64-b302-f0557f72e439",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`StreamsConfig` is public API and IMHO we should not add those helpers method they as they are internal. Thoughts?",
        "createdAt" : "2020-03-19T23:17:14Z",
        "updatedAt" : "2020-03-21T18:49:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "0493a6a2-08f1-404e-9c5c-1663e7ffd9fe",
        "parentId" : "637e07e2-d174-4e64-b302-f0557f72e439",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Can we make it package-private?",
        "createdAt" : "2020-03-20T00:31:04Z",
        "updatedAt" : "2020-03-21T18:49:58Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "5eec3405-0c6e-4c95-ad43-e86f69485d36",
        "parentId" : "637e07e2-d174-4e64-b302-f0557f72e439",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Unfortunately not, because `StreamsConfig` is in package `o.a.k.streams` but we use it in `o.a.k.streams.processor`",
        "createdAt" : "2020-03-20T00:35:43Z",
        "updatedAt" : "2020-03-21T18:49:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a8bc58ca-bf6d-46b8-a204-29c3e4521f7d",
        "parentId" : "637e07e2-d174-4e64-b302-f0557f72e439",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Fair enough, let's keep it inside StreamThread for now.\r\n\r\nIn a longer term refactoring, maybe we could have an StreamsUtil class where such static functions / fields can be stuffed in.",
        "createdAt" : "2020-03-20T00:45:02Z",
        "updatedAt" : "2020-03-21T18:49:58Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "59154ab4ee7c4f24706911fb37b8118510d1a3a1",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +408,412 @@    }\n\n    static boolean eosAlphaEnabled(final StreamsConfig config) {\n        return EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG));\n    }"
  },
  {
    "id" : "23f1d6a5-ec36-4202-91a8-82818bf751f8",
    "prId" : 8319,
    "prUrl" : "https://github.com/apache/kafka/pull/8319#pullrequestreview-378123686",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74b96225-6913-420a-8961-2741b5c41e28",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Rearranged this so we can include the exception itself. The stacktrace is useful for tracking down the reason for the exception.",
        "createdAt" : "2020-03-19T22:01:54Z",
        "updatedAt" : "2020-03-20T03:06:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e6b6aed01435aef1bcac534e9992b9e9579f18",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +503,507 @@            } catch (final TaskCorruptedException e) {\n                log.warn(\"Detected the states of tasks \" + e.corruptedTaskWithChangelogs() + \" are corrupted. \" +\n                             \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n\n                taskManager.handleCorruption(e.corruptedTaskWithChangelogs());"
  },
  {
    "id" : "734e2d60-1e6f-4304-9408-b7431ccb4e5a",
    "prId" : 8319,
    "prUrl" : "https://github.com/apache/kafka/pull/8319#pullrequestreview-378123686",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba9057b0-8b10-445f-88ee-1cbbaff8df38",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Also, here.",
        "createdAt" : "2020-03-19T22:02:01Z",
        "updatedAt" : "2020-03-20T03:06:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e6b6aed01435aef1bcac534e9992b9e9579f18",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +509,513 @@                log.warn(\"Detected that the thread is being fenced. \" +\n                             \"This implies that this thread missed a rebalance and dropped out of the consumer group. \" +\n                             \"Will close out all assigned tasks and rejoin the consumer group.\", e);\n\n                taskManager.handleLostAll();"
  },
  {
    "id" : "01dfac4c-b056-40f5-97c9-62faed962930",
    "prId" : 8319,
    "prUrl" : "https://github.com/apache/kafka/pull/8319#pullrequestreview-378123686",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c16d2ef-95c7-40a6-aa47-d03f1d659fa4",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is the primary fix. Instead of relying (hoping) on TaskManager to put the changelog reader into restoring_active, we just idempotently make sure it's in that state any time we're in partitions_assigned.",
        "createdAt" : "2020-03-19T22:07:55Z",
        "updatedAt" : "2020-03-20T03:06:40Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "65e6b6aed01435aef1bcac534e9992b9e9579f18",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +580,584 @@        if (state == State.PARTITIONS_ASSIGNED) {\n            // transit to restore active is idempotent so we can call it multiple times\n            changelogReader.enforceRestoreActive();\n\n            if (taskManager.tryToCompleteRestoration()) {"
  },
  {
    "id" : "f01713b8-a328-4b51-ac08-20f98be239a3",
    "prId" : 8358,
    "prUrl" : "https://github.com/apache/kafka/pull/8358#pullrequestreview-381638704",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b72caca5-ea61-467d-b3e9-902bca707db3",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is the meat of the PR: measure the total process / punctuate / commit latency, in order to measure the corresponding ratio.",
        "createdAt" : "2020-03-26T01:02:31Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "990ec8a34eb22dd13b0120c288f4161007f6ae46",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +660,664 @@             */\n            do {\n                final int processed = taskManager.process(numIterations, now);\n                final long processLatency = advanceNowAndComputeLatency();\n                totalProcessLatency += processLatency;"
  },
  {
    "id" : "81fda837-047f-425f-85c8-daaffc10c8ef",
    "prId" : 8358,
    "prUrl" : "https://github.com/apache/kafka/pull/8358#pullrequestreview-381638704",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5936d1c8-ca82-4554-a1a1-e13c65db2d6f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "There are also a minor fix here: we used to calculate the `timeSinceLastPoll` before we call maybePunctuate / maybeCommit, which may actually take a lot of time; this would cause us to be mistakenly more aggressive in `timeSinceLastPoll > maxPollTimeMs / 2` since `timeSinceLastPoll` is actually larger than the recorded value, and hence more likely to be kicked out of the group.",
        "createdAt" : "2020-03-26T01:06:40Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "990ec8a34eb22dd13b0120c288f4161007f6ae46",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +696,700 @@                    // if there is no records to be processed, exit after punctuate / commit\n                    break;\n                } else if (Math.max(now - lastPollMs, 0) > maxPollTimeMs / 2) {\n                    numIterations = numIterations > 1 ? numIterations / 2 : numIterations;\n                    break;"
  },
  {
    "id" : "2c3101f9-c99d-4958-90ca-5339b86a85b5",
    "prId" : 8358,
    "prUrl" : "https://github.com/apache/kafka/pull/8358#pullrequestreview-382565749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4bd7441f-a4d1-4000-9a19-baa43e1d7283",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note I did not record sensor  for restoration; it is intentional since we will be moving that out of the thread here. Atm the restoration ratio can be inferred by 100% - other four.",
        "createdAt" : "2020-03-26T16:23:57Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "69c4d76a-741f-403a-8543-62a223c71f0c",
        "parentId" : "4bd7441f-a4d1-4000-9a19-baa43e1d7283",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Not sure about this. I think the motivation is reasonable, if we're going to change the metric, then it creates unnecessary thrashing to introduce it here.\r\n\r\nOTOH, even if we move restoration to another thread, that thread will still have a name, so the metric name itself wouldn't actually change, just the value of the thread name, which changes between every instance run anyway.",
        "createdAt" : "2020-03-26T20:25:27Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "81d5d6c0-cbe6-47f3-8035-eb7f0c1bedd2",
        "parentId" : "4bd7441f-a4d1-4000-9a19-baa43e1d7283",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Here's a few considerations: 1) when we move that to another thread(s), then the restoration-ratio would basically be 100% of that thread(s), unless we separate the the restoreConsumer.poll call out of applying updates here, but in that case we'd probably introduce with different tags, 2) if we are moving it to a thread pool instead of a single thread, then there would be no `thread-id` in the tags, but some other ids.\r\n\r\nSo I decided to defer adding this metric until we've figured out exactly how we are going to restore in the other threads --- I'm not suggesting that we never add this metric, just defer it :)",
        "createdAt" : "2020-03-26T23:25:38Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "958bff24-5f90-456e-aa9e-78164e2f46ed",
        "parentId" : "4bd7441f-a4d1-4000-9a19-baa43e1d7283",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, sounds good.",
        "createdAt" : "2020-03-27T03:55:57Z",
        "updatedAt" : "2020-03-27T05:53:18Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "990ec8a34eb22dd13b0120c288f4161007f6ae46",
    "line" : 174,
    "diffHunk" : "@@ -1,1 +709,713 @@        now = time.milliseconds();\n        final long runOnceLatency = now - startMs;\n        processRatioSensor.record((double) totalProcessLatency / runOnceLatency);\n        punctuateRatioSensor.record((double) totalPunctuateLatency / runOnceLatency);\n        pollRatioSensor.record((double) pollLatency / runOnceLatency);"
  },
  {
    "id" : "141596dd-1af2-418f-9257-e81a0c65f4cb",
    "prId" : 8367,
    "prUrl" : "https://github.com/apache/kafka/pull/8367#pullrequestreview-383144320",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b0b2252d-5726-4218-b6ed-2f900abfe25f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang New special log message for old brokers.",
        "createdAt" : "2020-03-27T19:28:48Z",
        "updatedAt" : "2020-03-27T19:28:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef41d1a1c748b3930b4bf6175a015896eaefe962",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +514,518 @@            // should be due to user application errors\n\n            if (e instanceof UnsupportedVersionException) {\n                final String errorMessage = e.getMessage();\n                if (errorMessage != null &&"
  },
  {
    "id" : "12e20500-83f8-4cf7-add9-bcf81670acdd",
    "prId" : 8370,
    "prUrl" : "https://github.com/apache/kafka/pull/8370#pullrequestreview-385156513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67309d24-fd62-437f-8b56-171a9668d79b",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note we should only call this inside the `if (state == State.RUNNING)` condition otherwise we may get ConcurrentModification exception.",
        "createdAt" : "2020-03-27T21:48:48Z",
        "updatedAt" : "2020-03-31T23:37:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "858ec7b1-efc1-449c-b9be-c5aadb823922",
        "parentId" : "67309d24-fd62-437f-8b56-171a9668d79b",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Q: Could you elaborate on this?",
        "createdAt" : "2020-03-31T18:24:13Z",
        "updatedAt" : "2020-03-31T23:37:08Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "1091f05e-8073-4d9e-af44-0f7a411edc62",
        "parentId" : "67309d24-fd62-437f-8b56-171a9668d79b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I do not know exactly what's happening here, my guess is that in PARTITION_REVOKED state the tasks might be modified.",
        "createdAt" : "2020-03-31T22:45:49Z",
        "updatedAt" : "2020-03-31T23:37:08Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "32ef38c40728841a720aa75e7c21b193215eea1e",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +727,731 @@            // we record the ratio out of the while loop so that the accumulated latency spans over\n            // multiple iterations with reasonably large max.num.records and hence is less vulnerable to outliers\n            taskManager.recordTaskProcessRatio(totalProcessLatency);\n        }\n"
  },
  {
    "id" : "82762f3f-ff6f-4702-8c61-da6fb51195ad",
    "prId" : 8371,
    "prUrl" : "https://github.com/apache/kafka/pull/8371#pullrequestreview-387631789",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "809d7b8a-a6c0-439a-a17f-116c2b6db548",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: Could you please add verifications of the creation of those metrics in `StreamThreadTest#shouldCreateMetricsAtStartup()`? ",
        "createdAt" : "2020-04-03T09:56:27Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "3cfcac36-9e8e-41b7-9b52-4fdab5b332bf",
        "parentId" : "809d7b8a-a6c0-439a-a17f-116c2b6db548",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack.",
        "createdAt" : "2020-04-03T23:24:41Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "325f0a4e5b38f0cdd495629577cba64c9857b98c",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +442,446 @@        this.commitSensor = ThreadMetrics.commitSensor(threadId, streamsMetrics);\n        this.pollSensor = ThreadMetrics.pollSensor(threadId, streamsMetrics);\n        this.pollRecordsSensor = ThreadMetrics.pollRecordsSensor(threadId, streamsMetrics);\n        this.pollRatioSensor = ThreadMetrics.pollRatioSensor(threadId, streamsMetrics);\n        this.processLatencySensor = ThreadMetrics.processLatencySensor(threadId, streamsMetrics);"
  },
  {
    "id" : "b92bdfa4-696d-4dd7-a5df-ee256e0e6bd2",
    "prId" : 8371,
    "prUrl" : "https://github.com/apache/kafka/pull/8371#pullrequestreview-387631839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1176c28d-8016-4f7e-a244-cdc4131819f5",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: Could you please add verifications of the creation of those metrics in `StreamThreadTest#shouldCreateMetricsAtStartup()`? ",
        "createdAt" : "2020-04-03T09:56:37Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "2507380e-f177-44d0-8935-a7d92b33464b",
        "parentId" : "1176c28d-8016-4f7e-a244-cdc4131819f5",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack.",
        "createdAt" : "2020-04-03T23:24:54Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "325f0a4e5b38f0cdd495629577cba64c9857b98c",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +445,449 @@        this.pollRatioSensor = ThreadMetrics.pollRatioSensor(threadId, streamsMetrics);\n        this.processLatencySensor = ThreadMetrics.processLatencySensor(threadId, streamsMetrics);\n        this.processRecordsSensor = ThreadMetrics.processRecordsSensor(threadId, streamsMetrics);\n        this.processRateSensor = ThreadMetrics.processRateSensor(threadId, streamsMetrics);\n        this.processRatioSensor = ThreadMetrics.processRatioSensor(threadId, streamsMetrics);"
  },
  {
    "id" : "2af35554-1abc-4ab5-b1ec-e808dde8a7f1",
    "prId" : 8409,
    "prUrl" : "https://github.com/apache/kafka/pull/8409#pullrequestreview-389748015",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ec90c170-57aa-48a6-8e0e-cb19584966c7",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: Please add a test that calls `StreamThread#create()` with a custom `KafkaClientSupplier` that provides a mock consumer and verify that the internal config is set. ",
        "createdAt" : "2020-04-07T12:47:06Z",
        "updatedAt" : "2020-04-08T01:54:58Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "87fe93b7-3ec4-4a8b-8929-208bd3860954",
        "parentId" : "ec90c170-57aa-48a6-8e0e-cb19584966c7",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This feels a bit out of scope, since we don't currently have _any_ tests that verify `StreamThread#create()`. Also, failing to set this attribute would instantly break all of our integration tests, since the consumer wouldn't be able to instantiate the assignor.\r\n\r\nNot saying it wouldn't be valuable to have a unit test for it, but maybe we can call this one a follow-on task.",
        "createdAt" : "2020-04-07T21:28:00Z",
        "updatedAt" : "2020-04-08T01:54:58Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2dabe0a6-8c40-4b8e-86bc-43555c25fc15",
        "parentId" : "ec90c170-57aa-48a6-8e0e-cb19584966c7",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Agreed",
        "createdAt" : "2020-04-08T08:15:13Z",
        "updatedAt" : "2020-04-08T08:15:13Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "51cf963d8b8817cf7f617356b55fdfe1459a0760",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +367,371 @@        consumerConfigs.put(StreamsConfig.InternalConfig.ASSIGNMENT_ERROR_CODE, assignmentErrorCode);\n        final AtomicLong nextProbingRebalanceMs = new AtomicLong(Long.MAX_VALUE);\n        consumerConfigs.put(StreamsConfig.InternalConfig.NEXT_PROBING_REBALANCE_MS, nextProbingRebalanceMs);\n        String originalReset = null;\n        if (!builder.latestResetTopicsPattern().pattern().equals(\"\") || !builder.earliestResetTopicsPattern().pattern().equals(\"\")) {"
  },
  {
    "id" : "12ad5b17-fc05-4efa-8ddc-d5e0b2e14c94",
    "prId" : 8409,
    "prUrl" : "https://github.com/apache/kafka/pull/8409#pullrequestreview-389549099",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25dfb0f0-ea8d-42c7-b192-db213ff35d62",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: I guess you could also verify this with a mock consumer.",
        "createdAt" : "2020-04-07T13:00:49Z",
        "updatedAt" : "2020-04-08T01:54:58Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "ca9ada77-dbf0-4123-9a72-0b0c519d33e9",
        "parentId" : "25dfb0f0-ea8d-42c7-b192-db213ff35d62",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "added `shouldEnforceRebalanceAfterNextScheduledProbingRebalanceTime`",
        "createdAt" : "2020-04-07T23:03:07Z",
        "updatedAt" : "2020-04-08T01:54:58Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "51cf963d8b8817cf7f617356b55fdfe1459a0760",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +564,568 @@                    log.info(\"The probing rebalance interval has elapsed since the last rebalance, triggering a \" +\n                                \"rebalance to probe for newly caught-up clients\");\n                    mainConsumer.enforceRebalance();\n                }\n            } catch (final TaskCorruptedException e) {"
  },
  {
    "id" : "eba29432-3554-4805-871a-49428fa7adf9",
    "prId" : 8440,
    "prUrl" : "https://github.com/apache/kafka/pull/8440#pullrequestreview-392440532",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "342909f6-5049-4fab-8411-c0d56a6dbadb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If we hit a `TaskCorruptedException`, we know that only a task in restore mode could be affected and those don't have anything to be committed (their `commitNeeded` flag should be set to `false`). Hence, we just commit all non-corrupted tasks. Afterwards we can safely call `handleCorruption()` (if we don't commit, we might abort a pending transaction for eos-beta incorrectly within `handleCorruption()`)\r\n\r\n\\cc @abbccdda @guozhangwang ",
        "createdAt" : "2020-04-13T21:07:47Z",
        "updatedAt" : "2020-04-14T23:37:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "15e0b98ef384c15022ee76e6ca88b325567e31cb",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +577,581 @@                        .filter(t -> !e.corruptedTaskWithChangelogs().containsKey(t.id()))\n                        .collect(Collectors.toSet())\n                );\n                taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n            } catch (final TaskMigratedException e) {"
  },
  {
    "id" : "f2304af6-b9bc-4776-b73c-2ef14649ab0e",
    "prId" : 8596,
    "prUrl" : "https://github.com/apache/kafka/pull/8596#pullrequestreview-404482307",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49d11d43-2c99-46f4-aca5-0b8bf43d4d7c",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We lose information here, but now log the reason for the scheduled rebalance in a (hopefully) more clear way during `onAssignment`",
        "createdAt" : "2020-05-02T00:32:42Z",
        "updatedAt" : "2020-05-12T01:28:53Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "0966ea5d6cc1868e64ffdffaa157769f4873d34a",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +550,554 @@                runOnce();\n                if (nextProbingRebalanceMs.get() < time.milliseconds()) {\n                    log.info(\"Triggering the followup rebalance scheduled for {} ms.\", nextProbingRebalanceMs.get());\n                    mainConsumer.enforceRebalance();\n                }"
  },
  {
    "id" : "2dd50375-9961-4144-9455-eb8173c79feb",
    "prId" : 8667,
    "prUrl" : "https://github.com/apache/kafka/pull/8667#pullrequestreview-412128164",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9ff05cd0-c460-4a67-8a94-b070937875ad",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Should we also handle the corrupted tasks here (before this line), so that they can be already cleaned up before the next round? Or, alternatively, should we move `taskManager.handleCorruption(e.corruptedTaskWithChangelogs());` to before the attempted commit (it looks like it could be outside the try block as well).",
        "createdAt" : "2020-05-14T18:31:30Z",
        "updatedAt" : "2020-05-14T18:34:44Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "0a9c5f43-d0a5-40a6-b589-1113c9270441",
        "parentId" : "9ff05cd0-c460-4a67-8a94-b070937875ad",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Good point, I was also thinking whether we should do the corruption logic no matter what. But if we hit a TaskMigrated, the `taskManager.handleLostAll` will wipe out all the task states dirty, which seems like a super-set of jobs for handleCorruption. If we failed the commit, maybe we should just skip the corruption logic?",
        "createdAt" : "2020-05-14T19:03:05Z",
        "updatedAt" : "2020-05-14T19:03:05Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "1fe41a0b-30ef-4763-8e7d-018a8dc2647d",
        "parentId" : "9ff05cd0-c460-4a67-8a94-b070937875ad",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Sounds legit. Thanks.",
        "createdAt" : "2020-05-14T19:42:00Z",
        "updatedAt" : "2020-05-14T19:42:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2f26677f150951d9a6ae3d09ed6a058b936c050",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +567,571 @@                    taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n                } catch (final TaskMigratedException taskMigrated) {\n                    handleTaskMigrated(taskMigrated);\n                }\n            } catch (final TaskMigratedException e) {"
  },
  {
    "id" : "bea2854c-b2f6-4b18-a3da-df660d611d2e",
    "prId" : 8738,
    "prUrl" : "https://github.com/apache/kafka/pull/8738#pullrequestreview-420348511",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0bb615f-f6ad-4449-99e8-dfb9acd98eeb",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This is neither relevant to this PR nor required for correctness, but I noticed the log message above tends to spam the logs in some tests. Since this gets set/reset at the end of every rebalance, we may as well reset it here to avoid an avalanche of `Triggering the followup rebalance...`",
        "createdAt" : "2020-05-28T04:16:08Z",
        "updatedAt" : "2020-05-28T22:27:43Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "8322ecff-993a-4edb-9f21-f70bae35fcea",
        "parentId" : "e0bb615f-f6ad-4449-99e8-dfb9acd98eeb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "enforceRebalance is guaranteed not to actually run the assignment logic, right? That will only run during a call to poll, I'm hoping. Otherwise, this line should go before the call.",
        "createdAt" : "2020-05-28T17:37:37Z",
        "updatedAt" : "2020-05-28T22:27:43Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "39d56262-835e-421c-8dd9-8b6ed6175587",
        "parentId" : "e0bb615f-f6ad-4449-99e8-dfb9acd98eeb",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Yep. It just provides a notice to the consumer to enforce that a rebalance will occur on the next poll ",
        "createdAt" : "2020-05-28T17:44:47Z",
        "updatedAt" : "2020-05-28T22:27:43Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "f7aad3ae9d2dbce77fe3e2ec2957298d466fb003",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +552,556 @@                    log.info(\"Triggering the followup rebalance scheduled for {} ms.\", nextProbingRebalanceMs.get());\n                    mainConsumer.enforceRebalance();\n                    nextProbingRebalanceMs.set(Long.MAX_VALUE);\n                }\n            } catch (final TaskCorruptedException e) {"
  },
  {
    "id" : "90913c76-5dbb-406f-8daa-0d463ca8fff9",
    "prId" : 8994,
    "prUrl" : "https://github.com/apache/kafka/pull/8994#pullrequestreview-446716036",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "What's up with this?",
        "createdAt" : "2020-07-08T23:43:58Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "84b49f03-b5bc-490d-a4bd-038067957abf",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I meant to call this out, too. In order to get the task re-initialized after a corruption recovery, we could set the state back to PartitionsAssigned, but I felt that would be confusing in the logs. Instead, I added an extra condition that we'll initialize tasks if there are any that need initialization, even though the thread may already be in running, which means we can have a self-transition from running to running.",
        "createdAt" : "2020-07-09T03:10:36Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "bb24d23a-a4c2-4c6a-bec2-f2fbd92615ef",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Where does this self-transition happen exactly? And could/should we detect this case and not call `setState()` for this case instead of allowing the transition?",
        "createdAt" : "2020-07-09T18:29:26Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1a5a392b-9fb6-4bf5-a88e-f7f0f6187a62",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "\\cc @vvcephei ",
        "createdAt" : "2020-07-10T04:50:02Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8a6e4dcf-3327-4755-9945-6279914a3258",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ah, sorry, I didn't see this follow-up question.\r\n\r\nIt's here: https://github.com/apache/kafka/blob/568dceb5f61c71428432d23d947c5f9b29fb7bfb/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L657\r\n\r\nI thought about it, but it seemed to be in violation of the whole idea of having a specified state machine. I.e., saying \"`if not running, setState(running)`\" is literally the same thing as saying that self-transitions are allowed. So why not just say that self-transitions are allowed (explicitly instead of implicitly)?\r\n\r\nAnyway, that's what I was thinking; no guarantee that it makes sense ;)",
        "createdAt" : "2020-07-10T19:19:05Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "797007dd-13cf-474d-ac65-9dfbd4fd35ea",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I agree with the sentiment. However, our overall patterns is to disallowed self-transitions, ie, this pattern is applied throughout all other code. IMHO, I might be better to stick with one pattern. Thus, if we think we should allow self-transitions, we might want to do it for all states and update the code throughout accordingly. Begin in a \"mixed mode\" seems suboptimal.\r\n\r\nOf course this would be follow up work. And frankly I am not sure if it would buy us much at this point?",
        "createdAt" : "2020-07-10T20:48:36Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "62bcd995-1cd4-485e-8596-46afdc8e7b50",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "FWIW, we actually do follow this pattern already, at least with respect to StreamThread state transitions. I'd rather be consistent with the other StreamThread state changes and inconsistent with other places in the code (eg the Task state changes), especially if we all agree this seems like the sensible approach to the fsm",
        "createdAt" : "2020-07-10T20:56:29Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b12510f5-424a-4ab0-b45f-4c7b68158e1c",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for chiming in. Seems I did not separate thread state and task state transition. Sorry for the confusion.",
        "createdAt" : "2020-07-10T21:20:05Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "422b97ef-eaa8-41d6-bfa5-0fa7355ae580",
        "parentId" : "1e5e9ba3-ee3a-46d9-9e33-d02c2f335b72",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "No worries, thanks for the review @mjsax . Now that I'm thinking about it, it does seem like Task is _allowing_ self-transitions, rather than _disallowing_ them, so we should probably add the self-transitions to the Task state machine. But maybe in a follow-up.",
        "createdAt" : "2020-07-10T21:41:44Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a8fbcc37a3f9881be49852b8a300b046a90a920",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +96,100 @@     *          |      +-----+-------+      |\n     *          |            |              |\n     *          |            |--------------+\n     *          |            v              |\n     *          |      +-----+-------+      |"
  },
  {
    "id" : "6be3be27-c033-4cca-9624-dabddcf10c78",
    "prId" : 8994,
    "prUrl" : "https://github.com/apache/kafka/pull/8994#pullrequestreview-445261425",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b9e1380-2f41-4fa3-940c-0df113e4303c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need this?",
        "createdAt" : "2020-07-08T23:59:38Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8ebb21d5-28cf-4ccc-af2a-a37b516ce0b3",
        "parentId" : "9b9e1380-2f41-4fa3-940c-0df113e4303c",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Sorry, I meant to explain it, but forgot. I've explained it here: https://github.com/apache/kafka/pull/8994#discussion_r451938891",
        "createdAt" : "2020-07-09T03:11:24Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a8fbcc37a3f9881be49852b8a300b046a90a920",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +138,142 @@        PARTITIONS_REVOKED(2, 3, 5),      // 2\n        PARTITIONS_ASSIGNED(2, 3, 4, 5),  // 3\n        RUNNING(2, 3, 4, 5),              // 4\n        PENDING_SHUTDOWN(6),              // 5\n        DEAD;                             // 6"
  },
  {
    "id" : "f40c9a7c-bbb9-4af6-bc89-7399b1efb1c8",
    "prId" : 8994,
    "prUrl" : "https://github.com/apache/kafka/pull/8994#pullrequestreview-446760274",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab5e33fc-6da6-4827-b2b7-a55cb880e9bb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We we need this `isEmpty` check? What happens is we blindly pass an empty set into `seekToBeginning`? -- Similar for `seekToEnd()` below?",
        "createdAt" : "2020-07-10T22:31:31Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3b1bfda0-c0a4-4adf-bd81-4afb136e361b",
        "parentId" : "ab5e33fc-6da6-4827-b2b7-a55cb880e9bb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Huh, I didn't wonder that before, but ... dear god. From the javadoc on KafkaConsumer:\r\n> If no partitions are provided, seek to the first offset for all of the currently assigned partitions.\r\n\r\nWhat a dangerous API!",
        "createdAt" : "2020-07-10T22:39:05Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "5869a5bf-eb58-46a1-9268-7a25f91a791a",
        "parentId" : "ab5e33fc-6da6-4827-b2b7-a55cb880e9bb",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just verified that we never call it unguarded by a non-empty check.",
        "createdAt" : "2020-07-10T23:35:46Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "ffc40f53-351b-48c2-b9d2-0c7184e41474",
        "parentId" : "ab5e33fc-6da6-4827-b2b7-a55cb880e9bb",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Awesome! Thanks for double checking!",
        "createdAt" : "2020-07-11T00:33:59Z",
        "updatedAt" : "2020-07-11T04:40:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a8fbcc37a3f9881be49852b8a300b046a90a920",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +795,799 @@\n        if (notReset.isEmpty()) {\n            if (!seekToBeginning.isEmpty()) {\n                mainConsumer.seekToBeginning(seekToBeginning);\n            }"
  },
  {
    "id" : "2338d3b6-a8e0-4a18-93c9-880e9a3af219",
    "prId" : 8994,
    "prUrl" : "https://github.com/apache/kafka/pull/8994#pullrequestreview-446821078",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ba787e4-394e-416c-aab1-7824187b8573",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The flaky test was related to us going into this block from other states. I finally got a clue when one of the tests failed on \"invalid transition from PARTITIONS_REVOKED to RUNNING\". I'm not sure how, exactly, but I think the shutdown test that failed on ConcurrentModificationException was also related, probably due to the test invoking the handleAssignment/Revocation/Lost methods from a different thread (which can normally never happen).\r\n\r\nAnyway, my prior code only intended to add the _self_ transition, but failed to make sure we were actually in a self-transition. It's fixed now.",
        "createdAt" : "2020-07-11T04:58:02Z",
        "updatedAt" : "2020-07-11T05:00:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "ac8b249a-fdb1-4bac-b71a-9808a748415d",
        "parentId" : "0ba787e4-394e-416c-aab1-7824187b8573",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks. The fix makes sense to me.",
        "createdAt" : "2020-07-11T18:38:57Z",
        "updatedAt" : "2020-07-11T18:38:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a8fbcc37a3f9881be49852b8a300b046a90a920",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +653,657 @@        // if the state is still in PARTITION_ASSIGNED after the poll call\n        if (state == State.PARTITIONS_ASSIGNED\n            || state == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n\n            // transit to restore active is idempotent so we can call it multiple times"
  },
  {
    "id" : "78a11b8c-2498-4a34-b305-25497f4c49f3",
    "prId" : 9267,
    "prUrl" : "https://github.com/apache/kafka/pull/9267#pullrequestreview-484324140",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "705927a5-d5cc-45d6-8940-d3f8aa3942b6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "`runOnce` was too long, according to checkStyle, so I factored out some of the execution phases.",
        "createdAt" : "2020-09-08T16:50:45Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "beb93768cb761367344fb31e40945bdebbba7cb5",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +613,617 @@        now = startMs;\n\n        final long pollLatency = pollPhase();\n\n        // Shutdown hook could potentially be triggered and transit the thread state to PENDING_SHUTDOWN during #pollRequests()."
  },
  {
    "id" : "8b620cdd-2934-4c24-8327-fa69376503fd",
    "prId" : 9267,
    "prUrl" : "https://github.com/apache/kafka/pull/9267#pullrequestreview-484324140",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a74df75-312a-4c84-a140-c8fa197ee898",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just a slight rewording I thought could be clearer.",
        "createdAt" : "2020-09-08T16:51:10Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "beb93768cb761367344fb31e40945bdebbba7cb5",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +620,624 @@        // could affect the task manager state beyond this point within #runOnce().\n        if (!isRunning()) {\n            log.debug(\"Thread state is already {}, skipping the run once call after poll request\", state);\n            return;\n        }"
  },
  {
    "id" : "05b132c5-e610-434b-bbd1-63f98dd93b97",
    "prId" : 9267,
    "prUrl" : "https://github.com/apache/kafka/pull/9267#pullrequestreview-484413135",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be3a7173-80bd-4005-ad25-8768b2931912",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note, this was previously `records != null && !records.isEmpty()`:\r\nhttps://github.com/apache/kafka/pull/9267/files#diff-045aeaddb4232a85a8560186b4901e69L640\r\n\r\nHowever, `records` can never be null, except if `Consumer#poll` returns `null`, which it does not. It turned out the reason for checking this condition was that there was exactly one test that relied on a nice mock returning `null`. I fixed the test below.\r\n\r\nNote, the only reason I messed with this was to simplify the debug log message on L775. Otherwise, I'd have needed to think of what to say if `records` were `null`.",
        "createdAt" : "2020-09-08T16:59:07Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "13e1a498-dc96-4b9b-9dc8-79c9c19f443c",
        "parentId" : "be3a7173-80bd-4005-ad25-8768b2931912",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "SG.",
        "createdAt" : "2020-09-08T19:18:12Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "beb93768cb761367344fb31e40945bdebbba7cb5",
    "line" : 164,
    "diffHunk" : "@@ -1,1 +780,784 @@        pollSensor.record(pollLatency, now);\n\n        if (!records.isEmpty()) {\n            pollRecordsSensor.record(records.count(), now);\n            taskManager.addRecordsToTasks(records);"
  },
  {
    "id" : "3b9c8ebb-4718-4049-9b3d-c732d75378c5",
    "prId" : 9267,
    "prUrl" : "https://github.com/apache/kafka/pull/9267#pullrequestreview-484324140",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6eef20e4-3e8a-4c75-8f29-f6fe7c8ad553",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Not necessary, but also not harmful, since it's a static final instance anyway. I thought it was nicer for self-documentation this way.",
        "createdAt" : "2020-09-08T16:59:46Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "beb93768cb761367344fb31e40945bdebbba7cb5",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +795,799 @@     */\n    private ConsumerRecords<byte[], byte[]> pollRequests(final Duration pollTime) {\n        ConsumerRecords<byte[], byte[]> records = ConsumerRecords.empty();\n\n        lastPollMs = now;"
  },
  {
    "id" : "be494efb-9ba5-4c80-a6db-e283edd93173",
    "prId" : 9267,
    "prUrl" : "https://github.com/apache/kafka/pull/9267#pullrequestreview-484324140",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08fbd36d-62b1-4d1b-b2b7-443d2db1ceff",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Switched these to debug now, since they seem to fit with the newly added logs.",
        "createdAt" : "2020-09-08T17:03:49Z",
        "updatedAt" : "2020-09-09T17:14:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "beb93768cb761367344fb31e40945bdebbba7cb5",
    "line" : 190,
    "diffHunk" : "@@ -1,1 +881,885 @@        if (now - lastCommitMs > commitTimeMs) {\n            if (log.isDebugEnabled()) {\n                log.debug(\"Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)\",\n                          taskManager.activeTaskIds(), taskManager.standbyTaskIds(), now - lastCommitMs, commitTimeMs);\n            }"
  },
  {
    "id" : "e1739028-c594-462a-884e-764bb44ce6f3",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-520037303",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bc2ca3ac-db6c-4a32-9a22-185a5b2f1f86",
        "parentId" : null,
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "extra line",
        "createdAt" : "2020-10-29T20:09:41Z",
        "updatedAt" : "2020-11-18T03:39:13Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +586,590 @@        this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n    }\n\n    public void shutdownToError() {\n        shutdownErrorHook.run();"
  },
  {
    "id" : "7c04e911-7f28-4866-8350-1f2d8418b5f6",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-520037303",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e827ae9-2c0a-4a26-bff6-6dc7b6fdc5a0",
        "parentId" : null,
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "extra line (: ",
        "createdAt" : "2020-10-29T20:09:56Z",
        "updatedAt" : "2020-11-18T03:39:13Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +597,601 @@        mainConsumer.enforceRebalance();\n    }\n\n    private void handleTaskMigrated(final TaskMigratedException e) {\n        log.warn(\"Detected that the thread is being fenced. \" +"
  },
  {
    "id" : "930a610c-2691-4720-8975-cfda44275143",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-531953733",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Hmm...this one seems like it should be a fatal error, so is it safe to just pass it along to the user and let them potentially just keep replacing the thread? (I know that option doesn't exist yet, but it will). There are some instances where we interpret errors as permanently fatal and choose to shut down the entire application, eg some errors during assignment. Should we do the same here? cc @abbccdda or @mjsax for more context on this error",
        "createdAt" : "2020-11-13T04:30:37Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "7edd8716-3c39-47c0-b91b-3b60d4ad7709",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I think this is fine for now. When we add replace thread as an option we can include overrides when handling the response that prevent the thread from being restarted in certain error cases.",
        "createdAt" : "2020-11-13T17:10:31Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "b4db9b53-f6c5-457f-8e01-7a76c3988b2e",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Personally, as long as users have the information available to understand the nature of the error, it's fine to let them make their own decision about how to handle it. Maybe another team is in the middle of a broker upgrade, for example, and the owner of this app would like to just keep trying until the broker team gets it together.",
        "createdAt" : "2020-11-16T18:14:59Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "605c3642-3a44-4b1d-8208-f0e494b769ca",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "That is probably fine. We can really get into it when we add the replace option, as now all calls to the handler are fatal.",
        "createdAt" : "2020-11-16T18:35:22Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "4c256240-c5a5-440d-acb5-50b512b5b80a",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "That's a fair point about broker upgrades, but don't we require the brokers to be upgraded to a version that supports EOS _before_ turning on eos-beta?\r\nAnyways I was wondering if there was something special about this exception such that ignoring it could violate eos or corrupt the state of the program. I'll ping the eos experts to assuage my concerns",
        "createdAt" : "2020-11-17T00:56:33Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "2dceb936-1d56-4901-86fc-9fb454b1bc61",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Just to clarify I think it's ok to leave this as-is for now, since as Walker said all handler options are fatal at this point ",
        "createdAt" : "2020-11-17T01:08:55Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "0358f156-8b03-4631-a9ff-f83a775b2783",
        "parentId" : "c0b2cd24-2051-4770-9c85-b018fbfda38f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Mm ok actually I think this should be fine. I was thinking of the handler as just \"swallowing\" the exception, but in reality the user would still let the current thread die and just spin up a new one in its place. And then the new one would hit this UnsupportedVersionException and so on, until the brokers are upgraded. So there shouldn't be any way to get into a bad state",
        "createdAt" : "2020-11-17T01:25:57Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +561,565 @@            } catch (final TaskMigratedException e) {\n                handleTaskMigrated(e);\n            } catch (final UnsupportedVersionException e) {\n                final String errorMessage = e.getMessage();\n                if (errorMessage != null &&"
  },
  {
    "id" : "6b6cf7a4-972c-4608-b7b6-1da803807b62",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-533007140",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eda9122c-2d9d-4a0c-9563-7ff3da6afd4b",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We should remember to update the wording here when we add the REPLACE_THREAD functionality",
        "createdAt" : "2020-11-18T02:28:30Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +566,570 @@                        errorMessage.startsWith(\"Broker unexpectedly doesn't support requireStable flag on version \")) {\n\n                    log.error(\"Shutting down because the Kafka cluster seems to be on a too old version. \" +\n                                    \"Setting {}=\\\"{}\\\" requires broker version 2.5 or higher.\",\n                            StreamsConfig.PROCESSING_GUARANTEE_CONFIG,"
  },
  {
    "id" : "3ca92520-f086-4337-8f4a-97c318359426",
    "prId" : 9572,
    "prUrl" : "https://github.com/apache/kafka/pull/9572#pullrequestreview-532761868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e04fa45d-cb93-43de-9e65-52e99da20184",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need the `cacheResizer`? Can't we just call `cache.resize(size)` here?",
        "createdAt" : "2020-11-17T18:51:45Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b1c20e42-1272-4ed6-afd6-3e82b4ef7a91",
        "parentId" : "e04fa45d-cb93-43de-9e65-52e99da20184",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "The cache is not exposed in stream thread. Since I was only using one method I thought it best to only expose that.",
        "createdAt" : "2020-11-17T19:25:13Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "dbf2392a-680d-43c7-8bad-97552b7cefaf",
        "parentId" : "e04fa45d-cb93-43de-9e65-52e99da20184",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ah. I see. -- Should we pass `java.util.function.Consumer<Long> cacheResizer` into `StreamThread` constructor for this case instead?",
        "createdAt" : "2020-11-17T19:37:34Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "4379867c-c097-4deb-a7d6-0cc402ad74dc",
        "parentId" : "e04fa45d-cb93-43de-9e65-52e99da20184",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I think we can, thats probably a good idea.",
        "createdAt" : "2020-11-17T19:58:22Z",
        "updatedAt" : "2020-11-18T17:38:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b69b6b256f77448097a144f5f9ef0e14fed1445f",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +622,626 @@\n    public void resizeCache(final long size) {\n        cacheResizer.accept(size);\n    }\n"
  },
  {
    "id" : "e8f509d0-7d22-4840-a5d4-56cd2a57954c",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-549586323",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f4bedd9-ca65-44a9-aa77-aa881f487825",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "This will let Streams shutdown uncleanly when in EOS mode",
        "createdAt" : "2020-12-10T20:48:50Z",
        "updatedAt" : "2021-01-21T22:43:31Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +553,557 @@     * @throws StreamsException      if the store's change log does not contain the partition\n     */\n    boolean runLoop() {\n        subscribeConsumer();\n"
  },
  {
    "id" : "2dac332e-d988-467b-b900-33f57885df0e",
    "prId" : 9863,
    "prUrl" : "https://github.com/apache/kafka/pull/9863#pullrequestreview-575726914",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9d5b15f-8754-43ac-90d4-a3a049690b7d",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I am still a bit concerned about `#removeStreamThread` potentially hanging indefinitely...maybe we should add a timeout to this API? If we want to do so, it would need to be soon since the 2.8 release is coming up. WDYT @cadonna @wcarlson5 ?",
        "createdAt" : "2021-01-22T18:08:06Z",
        "updatedAt" : "2021-01-22T18:08:07Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "350e511c-6059-4cd2-a1b5-6227316d2936",
        "parentId" : "b9d5b15f-8754-43ac-90d4-a3a049690b7d",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "This particular bit would only hang if the thread is not shutting down. If that is happening maybe we are already in an unrecoverable state? \r\n\r\nOverall I wouldn't mind having some sort of timeout but I am not very worried about it. @cadonna maybe you have any insights from writing the KIP?",
        "createdAt" : "2021-01-22T18:15:21Z",
        "updatedAt" : "2021-01-22T18:15:21Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "48f069c2-7415-4f75-adcc-346a37df4192",
        "parentId" : "b9d5b15f-8754-43ac-90d4-a3a049690b7d",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Maybe I'm just paranoid from going through some incidents where the thread really did never shut down. I would agree we're probably in a bad & unrecoverable state at that point, but hanging indefinitely is not the right answer. What happens when a program freezes on your laptop? I usually just try to force quit it -- the user might want to do the same. But if we never return control of their thread then it's hard for them to know to shut it down",
        "createdAt" : "2021-01-22T20:13:00Z",
        "updatedAt" : "2021-01-22T20:13:00Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "ee097528-cf09-4f33-a83d-fb10e71718f8",
        "parentId" : "b9d5b15f-8754-43ac-90d4-a3a049690b7d",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "That is a fair concern. Based on the interrupt documentation I would hope that force quit doesn't use the interrupt path. As Bruno said \r\n\r\n> In the words of \"Java Concurrency in Practice\":\r\n\"Thread interruption is a cooperative mechanism for a thread to signal another thread that it should, at its convenience and if it feels like it, stop what it is doing and do something else.\"\r\n \r\nThe \"at its convenience\" is what makes me less concerned ",
        "createdAt" : "2021-01-22T21:40:58Z",
        "updatedAt" : "2021-01-22T21:46:26Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "2fc0154e-53a8-4967-8aa6-21d2894d7406",
        "parentId" : "b9d5b15f-8754-43ac-90d4-a3a049690b7d",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "That's right, I don't think force quit uses the interrupt path. But anyways I don't think it's possible to force quit a Kafka Streams application until we get around to making it a desktop application. I was just trying to draw a parallel -- my concern here is just that there is absolutely no way to recover should a StreamThread hang during shutdown, meaning you will just need to kill the process and do an unclean shutdown. With ALOS it's maybe not so bad, but with EOS an unclean shutdown requires wiping out all state stores and completely restoring them from scratch. So there is absolutely something to lose besides just the annoyance of having to manually kill the Streams process.\r\n\r\nI just got a notification from a report of Streams being stuck during shutdown in an EOS application, so I promise I'm not making this up 🙂 . I can point you to it if you'd like -- unfortunately we never even managed to determine the root cause, so there may be more bugs out there which cause this besides just the ones we currently know",
        "createdAt" : "2021-01-25T19:15:05Z",
        "updatedAt" : "2021-01-25T19:15:05Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae50d84983f51ca7d1340a36634a14607964579f",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +617,621 @@                while (state != targetState) {\n                    try {\n                        stateLock.wait();\n                    } catch (final InterruptedException e) {\n                        interrupted = true;"
  },
  {
    "id" : "c2d3e951-9b3c-4a67-8d89-aaff208ff4ba",
    "prId" : 9875,
    "prUrl" : "https://github.com/apache/kafka/pull/9875#pullrequestreview-567710419",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d09d13a-e249-4ed1-93f8-582956dd983b",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Maybe we do this else where but can we log at DEBUG if there is nothing done and there is tasks assigned to the thread? It might be good to be able to confirm that its not getting stuck here or its actually not polling anything.",
        "createdAt" : "2021-01-12T21:04:28Z",
        "updatedAt" : "2021-01-12T21:06:07Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "395e5356-d06a-4a5d-aac1-35d9a76ea6a8",
        "parentId" : "3d09d13a-e249-4ed1-93f8-582956dd983b",
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "I have a similar question here, other than that LGTM",
        "createdAt" : "2021-01-12T22:44:32Z",
        "updatedAt" : "2021-01-12T22:44:32Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      },
      {
        "id" : "717ade2a-6657-43a9-903d-2d6d9f57ca70",
        "parentId" : "3d09d13a-e249-4ed1-93f8-582956dd983b",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Good thought, but don't worry, we already do. John added some pretty thorough logging at the DEBUG level after an escalation a while back",
        "createdAt" : "2021-01-13T22:28:12Z",
        "updatedAt" : "2021-01-13T22:28:12Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "f648cb27b1604cc20ac63fabcd03ef640929737d",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +752,756 @@            // Don't log summary if no new records were processed to avoid spamming logs for low-traffic topics\n            if (totalProcessed > 0 || totalPunctuated > 0 || totalCommitted > 0) {\n                log.info(\"Processed {} total records, ran {} punctuators, and committed {} total tasks\",\n                         totalProcessed, totalPunctuated, totalCommitted);\n            }"
  },
  {
    "id" : "e5b2d1dc-8feb-446b-aaaa-3a42f18fd0b9",
    "prId" : 9875,
    "prUrl" : "https://github.com/apache/kafka/pull/9875#pullrequestreview-566699420",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "553595d0-1b1f-442c-9045-015ef4853603",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "The above probably doesn't need to be applied here as well, i don't think",
        "createdAt" : "2021-01-12T21:05:36Z",
        "updatedAt" : "2021-01-12T21:06:07Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f648cb27b1604cc20ac63fabcd03ef640929737d",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +827,831 @@\n        final int numRecords = records.count();\n        if (numRecords > 0) {\n            log.info(\"Main Consumer poll completed in {} ms and fetched {} records\", pollLatency, numRecords);\n        }"
  },
  {
    "id" : "6270d991-b37e-427f-8c58-267603cff3ad",
    "prId" : 10387,
    "prUrl" : "https://github.com/apache/kafka/pull/10387#pullrequestreview-620013480",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5023e60f-f66e-49ed-8656-2717aafaea0a",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Since this thread is going to immediately shut down anyways, I think we can skip the `mainConsumer.enforceRebalance()`",
        "createdAt" : "2021-03-24T00:01:05Z",
        "updatedAt" : "2021-03-27T00:01:56Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "fdfadcaa-56ee-491e-b4c5-db4a6800db2e",
        "parentId" : "5023e60f-f66e-49ed-8656-2717aafaea0a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "This is also how we trigger the rebalance for the other threads so we can't just remove it",
        "createdAt" : "2021-03-24T00:15:12Z",
        "updatedAt" : "2021-03-27T00:01:56Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "2b9c8cab-f3c1-4f40-a98f-bcbadc2e2f1f",
        "parentId" : "5023e60f-f66e-49ed-8656-2717aafaea0a",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "But do we even need to invoke `maybeSendShutdown` at all from the two catch blocks? The thread that we start up should handle this",
        "createdAt" : "2021-03-24T00:28:00Z",
        "updatedAt" : "2021-03-27T00:01:56Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "d784c41c-a4c5-4af5-9987-9bdf22c83e9b",
        "parentId" : "5023e60f-f66e-49ed-8656-2717aafaea0a",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "No we don't we can take those out",
        "createdAt" : "2021-03-24T17:19:49Z",
        "updatedAt" : "2021-03-27T00:01:56Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a0488a898ee9faec5f15fbf1fe45c3d3c380bae",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +627,631 @@            log.warn(\"Detected that shutdown was requested. \" +\n                    \"All clients in this app will now begin to shutdown\");\n            mainConsumer.enforceRebalance();\n        }\n    }"
  }
]