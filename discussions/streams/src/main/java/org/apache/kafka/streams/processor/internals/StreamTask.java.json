[
  {
    "id" : "929c634f-bcc8-4f18-923a-fc30eade8968",
    "prId" : 4826,
    "prUrl" : "https://github.com/apache/kafka/pull/4826#pullrequestreview-109814681",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4c581c0-1e9a-4f7d-b8e4-fd1bf6471d77",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This comment is not for this line but for line 361 above (it is not introduced in this PR but we can tighten the screws a bit more along side):\r\n\r\nwe should switch the line `transactionInFlight = true;` to go after `producer.beginTransaction();`\r\n",
        "createdAt" : "2018-04-05T17:56:28Z",
        "updatedAt" : "2018-04-05T22:09:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fcd3e0ec75d3e5133c97a33246e248268acebdb6",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +483,487 @@                if (!clean) {\n                    try {\n                        if (!isZombie && transactionInFlight) {\n                            producer.abortTransaction();\n                        }"
  },
  {
    "id" : "213d344a-0b57-463b-bbac-dedbd26bb49d",
    "prId" : 5398,
    "prUrl" : "https://github.com/apache/kafka/pull/5398#pullrequestreview-145330266",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Can you open PRs for older branches to back-port this fix?",
        "createdAt" : "2018-07-20T17:34:44Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "e2bacee0-cf66-4473-8b62-85ac2501d8a2",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "yup.",
        "createdAt" : "2018-07-20T18:24:20Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "91920164-d9f4-469e-a6c1-58f6502e8f77",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "ah geez; good catch.",
        "createdAt" : "2018-07-31T21:50:26Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "348b918c-3cb8-47f2-855a-41fb7df75117",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "FWIW, it wouldn't break anything. This is only the name of the sensor, which just needs to be unique, and it's just as unique in this order, unless some other task is named \"commit\" (which wouldn't happen).",
        "createdAt" : "2018-08-02T18:18:29Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6a7b6ba5-3442-4705-a36a-cfa625e8d634",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "To be clear, we should fix it, just not sure if we need to bother backporting.",
        "createdAt" : "2018-08-02T18:19:16Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "06b118a7-ad80-4c5f-9f3e-143fe0547e94",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Cannot follow the argument? It seems to be an easy fix and we should back port all fixes by default and only not back port if there is a good reason for not doing it.\r\n\r\n@guozhangwang Is there already a PR or ticket so this is not dropped on the floor?",
        "createdAt" : "2018-08-02T21:26:33Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "4b7e79ea-b67d-4881-82b4-9095a2c5a49a",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@vvcephei I think it did break sth.. the sensorName is used as part of `fullSensorName = key + \".\" + sensorName;`. With `sensorName == taskName`, we will not add them since `Sensor s = getSensor(name);` already exists, i.e. we will lose some metrics, right?",
        "createdAt" : "2018-08-02T21:28:10Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "fd2361c9-8286-4f6f-b776-f5728e85d7eb",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "@mjsax fair enough!\r\n\r\n@guozhangwang I think you're right. The full sensor name is still unique, but it would mess up the ability to unload sensors (we basically wouldn't be able to unload any task level sensors). My bad.",
        "createdAt" : "2018-08-03T22:31:31Z",
        "updatedAt" : "2018-08-03T22:31:31Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "625a59ba-9308-4ff2-95f7-7679114c92eb",
        "parentId" : "0a0a615c-9fea-40f4-9fb1-b5f41f647ea5",
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Maybe create (internal) SensorName type (alias for String) so that there is no chance of mixup in the future.",
        "createdAt" : "2018-08-10T17:25:08Z",
        "updatedAt" : "2018-08-10T17:25:09Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c57cec79fa53032b55dd7a5f374c9ee62c25098",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +113,117 @@            // add the operation metrics with additional tags\n            final Map<String, String> tagMap = metrics.tagMap(\"task-id\", taskName);\n            taskCommitTimeSensor = metrics.taskLevelSensor(taskName, \"commit\", Sensor.RecordingLevel.DEBUG, parent);\n            taskCommitTimeSensor.add(\n                new MetricName(\"commit-latency-avg\", group, \"The average latency of commit operation.\", tagMap),"
  },
  {
    "id" : "f7fee4d1-0d0d-4a9a-bc3b-e714f6ccede1",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-148681869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1a991cc-5f3a-4cbc-913c-be5b9b5e5e13",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "In trunk, the ordering of calls for the `producer` during a commit was broken up, but now they are all grouped together.  It seems ok to do this and is cleaner to follow, I just wanted to double check the change of ordering doesn't matter. \r\n\r\nMaybe we should run system tests to confirm?",
        "createdAt" : "2018-08-07T18:54:08Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "58bc5045-4e53-4bfb-96ed-4d30088603aa",
        "parentId" : "b1a991cc-5f3a-4cbc-913c-be5b9b5e5e13",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good point, I will run the system test accordingly.",
        "createdAt" : "2018-08-08T20:37:54Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0c8bf06a-41c9-4ee5-97bb-0c9c13c485f0",
        "parentId" : "b1a991cc-5f3a-4cbc-913c-be5b9b5e5e13",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "It was broken apart because we checked if there is anything to commit in the first place (ie, do the check on one place)-- if we did not process any data, we don't need to commit.\r\n\r\nThis check now happens outside of `StreamTask` as pointed out by Guozhang https://github.com/apache/kafka/pull/5428/files#r212395430 Thus, regrouping makes sense. Code is cleaner this way.",
        "createdAt" : "2018-08-22T22:13:22Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +455,459 @@\n        try {\n            if (eosEnabled) {\n                producer.sendOffsetsToTransaction(consumedOffsetsAndMetadata, applicationId);\n                producer.commitTransaction();"
  },
  {
    "id" : "3a78173f-9786-438b-853e-0bf000e71d92",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149953014",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "is this just because punctuations might result in context.forwards?",
        "createdAt" : "2018-08-10T16:09:53Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "f10a947a-6cef-48e9-a5ee-4df87f5def99",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Actually it is because users can call `context.commit()` in either ` punctuate()` or `process()` calls.",
        "createdAt" : "2018-08-10T23:24:16Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "adebb24d-126e-4227-911a-8b920ba318af",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Hmmm... if there is nothing to commit, it might also be fine to ignore the user commit request? It's a tricky question what to do for this case. Just follow what the user demands, or be smart? From a correctness point of view, it should not make a difference, would it?\r\n\r\nAlso, we set flag `commitRequested` for this case -- thus, it might be better to put this logic somewhere else? Eg: `AbstractTask` or overwrite in `StreamTask`:\r\n```\r\npublic boolean commitNeeded() {\r\n    return commitNeeded || commitRequested;\r\n}\r\n```\r\n\r\n (An alternative, that I like less would be to add a check if `commitRequested==true`)?",
        "createdAt" : "2018-08-22T22:21:57Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "68279723-cbca-49e6-a0d6-eaf9650bd113",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Not sure I follow your comment here.. let me elaborate a bit on my logic:\r\n\r\nWe have two commits in places: commitAll (periodic) and maybeCommit (for user requested):\r\n\r\nThe latter checks\r\n\r\n```\r\nif (task.commitRequested() && task.commitNeeded()) \r\n                    task.commit();\r\n```\r\n\r\nWhile the former only checks:\r\n\r\n```\r\nif (task.commitNeeded()) \r\n                    task.commit();\r\n```\r\n\r\nI.e. the logic for the latter is that \"only if user have requested, and it is indeed needed to commit\": for example, if we have actually committed from the commit interval, and then user requested it as well, the second will be omitted.\r\n\r\nI intentionally separated \"commitRequest\" (this is only set by user) and \"commitNeeded\" (this is determined by the library) because this way looks cleaner to me.",
        "createdAt" : "2018-08-23T17:47:42Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "7bac8d5e-b9fc-400f-9680-518fe4a244ec",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "So setting `commitNeeded` is a conservative approach, because we don't know what the user did within punctuation call? Might be better to set `commitNeeded` if user calls `context.forward` or `state.put()` -- not sure how hard this would be -- would also be out-of-scope for this PR. If we think it might be worth it, we should create a JIRA for this optimization.",
        "createdAt" : "2018-08-23T18:03:45Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "7ad87686-7aed-4d3f-bc87-570cd0e3b0b3",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thought on my last comment?",
        "createdAt" : "2018-08-25T00:14:15Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "026e5009-286a-4e49-94a4-3116e7a813b1",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We still need to commit even if no records are processed: consider a topology which only contains a single source node, then no data processed at all, but we still want to commit so that we would not re-process them right?",
        "createdAt" : "2018-08-27T22:59:59Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "12d3cecb-4c2c-49a3-989f-d5f29b765aa7",
        "parentId" : "6085021a-6973-4ed8-99f0-f8743e5c4b03",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fair enough. Thanks for pointing it out.",
        "createdAt" : "2018-08-28T03:11:36Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 239,
    "diffHunk" : "@@ -1,1 +794,798 @@\n            if (punctuated) {\n                commitNeeded = true;\n            }\n"
  },
  {
    "id" : "f197a9dd-1706-4641-bede-d92e8d377cb2",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149019658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "603e1f0c-423b-4c03-9709-a2ff6b308346",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we not check `if(commitNeeded)` any longer?",
        "createdAt" : "2018-08-22T22:09:07Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "73f6657b-a2b8-4158-a3e5-43cbf0addbb5",
        "parentId" : "603e1f0c-423b-4c03-9709-a2ff6b308346",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We check this in the AssignedTasks now: if no commit is needed, we skip the whole committing function, including commit offsets, flushing stores, etc.",
        "createdAt" : "2018-08-23T17:37:20Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +446,450 @@        }\n\n        final Map<TopicPartition, OffsetAndMetadata> consumedOffsetsAndMetadata = new HashMap<>(consumedOffsets.size());\n        for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n            final TopicPartition partition = entry.getKey();"
  },
  {
    "id" : "795f0b14-a972-492a-836c-cd31921723a4",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-153876402",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: should it be `>` instead of `>=` ?",
        "createdAt" : "2018-09-06T18:38:24Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "44d1fd3f-d6c8-404a-a560-a6f32c9fb36c",
        "parentId" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "There was an early comment on the test code that suggests `>=`. Personally I think it does not make a big difference at all.",
        "createdAt" : "2018-09-07T17:32:21Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "721169e2-bf17-443c-86cb-1eaaa9890cd6",
        "parentId" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I am to blame for this suggestion. I agree it doesn't make a big difference.\r\nThe reasoning was that if it's the \"maximum idle time\", then you shouldn't idle longer than it, otherwise, it's not really a maximum.",
        "createdAt" : "2018-09-07T19:38:19Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "c5c3bdaf-3f6a-4983-94d0-9a65a92a21d7",
        "parentId" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I agree that it does not matter too much :) (that why it's a nit)\r\n\r\nHowever, I think that the maximum is inclusive, and only if we exceed it, we should force processing. From my understanding, \"maximum idle time\" is actually a lower bound (-> don't force processing until this time passed) because we cannot guarantee anyway to not exceed this threshold. I see your point why the name might be counter intuitive (even if I think the name is correct). If you interpret the name strictly, we would be allowed (or actually we would be required) to force processing before the time passed. This interpretation would make the parameter useless (ie, user tells us to idle max 5 minutes and we obey by forcing processing after 1 minute).\r\n\r\nTo me, the right interpretation is, \"wait until this time passed and force processing asap if the time is exceeded\". Chaning the name to `min.idle.time.ms` would be more precise, but I think it would be more confusing to users. ",
        "createdAt" : "2018-09-08T21:50:01Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6004d97c-77aa-419e-afe1-9076c0787dfd",
        "parentId" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Okay guys, I'm going to make a final call here to end the discussion: I'm staying with `max.idle..` since I feel it is easier to understand for users, and be aware that this is not strictly respected in practice unless it is set to `0`. Also I'm staying with `>=` since again, it is easier to understand though not strictly sound mathematically.",
        "createdAt" : "2018-09-10T17:09:01Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "59407b08-636d-476d-a615-3e54b7a3064a",
        "parentId" : "5c3fb631-27f5-4af1-bd37-117ca6c0a451",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : ":) Fair enough.",
        "createdAt" : "2018-09-10T17:17:35Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +313,317 @@            }\n\n            if (now - idleStartTime >= maxTaskIdleMs) {\n                taskMetrics.taskEnforcedProcessSensor.record();\n                return true;"
  },
  {
    "id" : "e8d7ebaa-9c5f-4605-9012-57321f53dca2",
    "prId" : 6115,
    "prUrl" : "https://github.com/apache/kafka/pull/6115#pullrequestreview-194301968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I seems, we should remove writing the checkpoint file in `closeStateManager`, too? Note, that `suspend()` will be called anyway (during rebalance, and during shutdown)\r\n\r\nAlso, why do we write the checkpoint if EOS is enabled only? To me, it seems we can write the checkpoint file if EOS is disabled, too?\r\n\r\n\\cc @guozhangwang ",
        "createdAt" : "2019-01-14T17:50:16Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "bedc648a-5e0a-4ec3-ad4e-ab90ea5fba00",
        "parentId" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "@mjsax  Because in the #commit() function we shall write checkpoint file if EOS is not turned on. So we are avoiding writing checkpoint file twice in consecutive.",
        "createdAt" : "2019-01-14T18:57:21Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "ec262be5-55ca-4cff-878b-f7ea6f03fe12",
        "parentId" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack. Might be worth to add this to the comment.",
        "createdAt" : "2019-01-16T17:56:12Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "eac86d98-83a4-44c3-bc79-ef1afe0b24e5",
        "parentId" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Sure, will do!",
        "createdAt" : "2019-01-18T01:57:56Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "692b0906-5f4b-4f73-a23a-62eb31f5135b",
        "parentId" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "What about:\r\n\r\n> I seems, we should remove writing the checkpoint file in closeStateManager, too? Note, that suspend() will be called anyway (during rebalance, and during shutdown)",
        "createdAt" : "2019-01-18T18:55:31Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "442b3e70-1fd7-492e-bf65-822ff6aac5f7",
        "parentId" : "e8f4260f-0f04-4e95-a167-a37cddb688b6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I see, will address this!",
        "createdAt" : "2019-01-18T22:08:10Z",
        "updatedAt" : "2019-02-23T05:48:22Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "aefb0007849d918b9d0eec09c5f4ffcf92ad3aeb",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +580,584 @@                if (eosEnabled) {\n\n                    stateMgr.checkpoint(activeTaskCheckpointableOffsets());\n\n                    try {"
  },
  {
    "id" : "5fde03e7-0fe0-4968-b841-e4f1a839d523",
    "prId" : 6310,
    "prUrl" : "https://github.com/apache/kafka/pull/6310#pullrequestreview-206983232",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dbcf824c-060b-4b21-b623-6c85ad3dd2b8",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Maybe we could inline this, but my personal preference is to have a separate method call for readability.",
        "createdAt" : "2019-02-22T19:14:42Z",
        "updatedAt" : "2019-02-23T16:30:03Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "48ef2b74706f9ceea98186b22ed2a7d8da3918f7",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +394,398 @@    }\n\n    private String getStacktraceString(final KafkaException e) {\n        String stacktrace = null;\n        try (final StringWriter stringWriter = new StringWriter();"
  },
  {
    "id" : "73a26cac-9497-4fa0-9574-81425bb05486",
    "prId" : 6372,
    "prUrl" : "https://github.com/apache/kafka/pull/6372#pullrequestreview-211569989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "501f87ae-9ac0-49fe-b337-4b112bd63b8d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: as above",
        "createdAt" : "2019-03-07T02:08:35Z",
        "updatedAt" : "2019-03-07T23:00:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9136d41ec244506da0739e2c2213fdaab4629c7",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +881,885 @@            log.error(\n                \"Timeout exception caught when initializing transactions for task {}. \" +\n                    \"This might happen if the broker is slow to respond, if the network connection to \" +\n                    \"the broker was interrupted, or if similar circumstances arise. \" +\n                    \"You can increase producer parameter `max.block.ms` to increase this timeout.\","
  },
  {
    "id" : "d5e96513-e635-4c6f-995a-8e76e06d8f2c",
    "prId" : 6636,
    "prUrl" : "https://github.com/apache/kafka/pull/6636#pullrequestreview-239206933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6eed79a-e7bc-40ff-8630-25edf8d3cfa7",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We actually did not call `close()` for this case on purpose. IIRC, the producer contract is to not call _any_ method (not even `close()`) after a `ProducerFencedException` was thrown by the producer, as indicated by the `isZombie` flag.\r\n\r\n\\cc @hachikuji to confirm.",
        "createdAt" : "2019-04-25T18:22:29Z",
        "updatedAt" : "2019-04-25T18:30:44Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ea871e01-9428-4d87-b8c0-39f120925f9e",
        "parentId" : "a6eed79a-e7bc-40ff-8630-25edf8d3cfa7",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : ">it seems that the old code ignores the `isZombie` flag and calls close() if eosEnable=true\r\n\r\nDo you mean the new code? The previous code only closed the `recordCollector` (which in turn closes the `producer`) when `isZombie=false`.  This was leading to streams leaking producers that never got closed after a rebalance from a fenced producer.",
        "createdAt" : "2019-04-25T18:36:28Z",
        "updatedAt" : "2019-04-25T18:36:29Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "db503ca4-6573-42b2-a4da-36c8b639848d",
        "parentId" : "a6eed79a-e7bc-40ff-8630-25edf8d3cfa7",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I was confused initially -- sorry for the confusion -- deleted my other comment already...",
        "createdAt" : "2019-04-25T18:40:02Z",
        "updatedAt" : "2019-04-25T18:40:03Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fb96183e-ab39-43bf-99af-7c1cef4578a2",
        "parentId" : "a6eed79a-e7bc-40ff-8630-25edf8d3cfa7",
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "@mjsax @bbejeck Just to clarify, I think we should always close the producer even if it was fenced. Resources like network connections only get cleaned up in `KafkaProducer.close()`.",
        "createdAt" : "2019-05-18T17:16:25Z",
        "updatedAt" : "2019-05-18T17:16:25Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "711e6c4e-ecc1-4bf8-9c49-e51b5bc0ba2e",
        "parentId" : "a6eed79a-e7bc-40ff-8630-25edf8d3cfa7",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for confirming @hachikuji!",
        "createdAt" : "2019-05-18T17:46:43Z",
        "updatedAt" : "2019-05-18T17:46:44Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e0e7bc13104cf0308cec2351ec766a1d6a44826",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +638,642 @@        }\n\n        if (eosEnabled) {\n            try {\n                recordCollector.close();"
  },
  {
    "id" : "debe6e2d-ec7d-4fbf-a9a0-efcd706e06ca",
    "prId" : 6694,
    "prUrl" : "https://github.com/apache/kafka/pull/6694#pullrequestreview-272919477",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "629b26ec-0899-40a2-bd66-9fca3cb654c2",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Might be good to add an `else` and also add a DEBUG log stating that no committed offset was found",
        "createdAt" : "2019-08-08T18:00:42Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d5a65407-fa10-4df4-aef1-93afce1350e3",
        "parentId" : "629b26ec-0899-40a2-bd66-9fca3cb654c2",
        "authorId" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "body" : "Done that.",
        "createdAt" : "2019-08-09T02:23:56Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42a883a14bc3a48a28624e3964be81e4f75d8f5",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +747,751 @@        } else {\n            log.debug(\"No committed timestamp was found in metadata for partition {}\", partition);\n        }\n    }\n"
  },
  {
    "id" : "4ea2f63c-483e-4d0d-bc54-732127c68b8d",
    "prId" : 6694,
    "prUrl" : "https://github.com/apache/kafka/pull/6694#pullrequestreview-272737998",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d658414c-5915-4015-a1dc-efb935cdd548",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: add comment `// visible for testing` (same for decodeTimestamp() below)\r\n\r\nAlso add test methods to `StreamTaskTest` to test both methods.",
        "createdAt" : "2019-08-08T18:04:15Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42a883a14bc3a48a28624e3964be81e4f75d8f5",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +932,936 @@\n    // visible for testing\n    String encodeTimestamp(final long partitionTime) {\n        final ByteBuffer buffer = ByteBuffer.allocate(9);\n        buffer.put(LATEST_MAGIC_BYTE);"
  },
  {
    "id" : "e7b080f9-acf3-4e70-8bdd-30fd79db6283",
    "prId" : 6694,
    "prUrl" : "https://github.com/apache/kafka/pull/6694#pullrequestreview-275542672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57a3dfad-f25c-46ff-b6cc-c730215c91f7",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I would put methods to write and read record metadata in their own classes. Those classes would be kind of SerDes for metadata. Such SerDes would make the code better testable and separates the concerns of a task and reading and writing metadata which are completely independent. It does not need to be done in this PR. I just wanted to mention it. ",
        "createdAt" : "2019-08-15T09:09:53Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "a333e4f8-33b2-486c-a7a9-0331b6789712",
        "parentId" : "57a3dfad-f25c-46ff-b6cc-c730215c91f7",
        "authorId" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "body" : "Yeah, that would probably be a good idea in the future.",
        "createdAt" : "2019-08-15T16:46:54Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42a883a14bc3a48a28624e3964be81e4f75d8f5",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +932,936 @@\n    // visible for testing\n    String encodeTimestamp(final long partitionTime) {\n        final ByteBuffer buffer = ByteBuffer.allocate(9);\n        buffer.put(LATEST_MAGIC_BYTE);"
  },
  {
    "id" : "31adfa11-b21a-40e4-b99c-2be48b2caf16",
    "prId" : 7030,
    "prUrl" : "https://github.com/apache/kafka/pull/7030#pullrequestreview-257624022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ce75710-f9cf-48a1-8881-0e9e6905f5be",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "checking for null is now encapsulated.",
        "createdAt" : "2019-07-03T17:20:06Z",
        "updatedAt" : "2019-07-09T23:16:30Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b33b85c4fa71ed08802599697404720a66d88ef",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +288,292 @@\n            try {\n                stateMgr.clearCheckpoints();\n            } catch (final IOException e) {\n                throw new ProcessorStateException(format(\"%sError while deleting the checkpoint file\", logPrefix), e);"
  },
  {
    "id" : "0b4aae60-85bc-4b8f-b522-c19d141d9bbb",
    "prId" : 7238,
    "prUrl" : "https://github.com/apache/kafka/pull/7238#pullrequestreview-285031723",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "50837f83-e6cf-47a0-a66a-70b2e648e474",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "With EOS, Consumer.committed maybe taking long time as the previous txn is being completed, we need to make sure that it would not throw any unexpected exceptions and if so we should not fail the streams instance. cc @abbccdda @mjsax .",
        "createdAt" : "2019-09-05T23:27:43Z",
        "updatedAt" : "2019-09-11T16:35:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d6aa407c-8846-4a80-bade-c3c0c3c3391c",
        "parentId" : "50837f83-e6cf-47a0-a66a-70b2e648e474",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "This code should be functionally equivalent to the previous code. Previously we initialized the offset limits in `registerStateStores`, which is called by `initializeStateStores` here. The biggest difference is that we no longer do this immediately for standby tasks - we defer to the first time we need a new offset limit to apply a record.",
        "createdAt" : "2019-09-06T15:24:36Z",
        "updatedAt" : "2019-09-11T16:35:57Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "0c9875cc-93d5-420c-b523-b3eb83d9fd22",
        "parentId" : "50837f83-e6cf-47a0-a66a-70b2e648e474",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The only exception that is non-fatal should be `TimeoutException`? ",
        "createdAt" : "2019-09-06T18:04:56Z",
        "updatedAt" : "2019-09-11T16:35:57Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "9748a733-a37a-416d-a4a3-e7d457469f32",
        "parentId" : "50837f83-e6cf-47a0-a66a-70b2e648e474",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yeah this is not a comment for this PR but more or less an FYI for folks who are working on KIP-447 :) I also left some thoughts on the voting thread regarding this purpose.",
        "createdAt" : "2019-09-06T18:32:57Z",
        "updatedAt" : "2019-09-11T16:35:57Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b14fbdce1f31b17070923325715f68c0238d43d",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +245,249 @@        // partitions of topics that are both sources and changelogs and set the consumer committed\n        // offset via stateMgr as there is not a more direct route.\n        final Set<String> changelogTopicNames = new HashSet<>(topology.storeToChangelogTopic().values());\n        partitions.stream()\n            .filter(tp -> changelogTopicNames.contains(tp.topic()))"
  },
  {
    "id" : "69a8a1ec-7fe9-4268-88cf-79da7d067eb4",
    "prId" : 7304,
    "prUrl" : "https://github.com/apache/kafka/pull/7304#pullrequestreview-337924758",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7f7f270-cf53-41cd-b8a7-9de4d6e17f13",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "If there is no `metadata` would we want to use the latest timestamp seen so far for the `StreamTask` and use that to set `PartitionGroup#setPartitionTime`?",
        "createdAt" : "2019-09-20T20:30:04Z",
        "updatedAt" : "2019-09-20T20:32:32Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "985dd874-4379-4779-a071-998695d45ed4",
        "parentId" : "e7f7f270-cf53-41cd-b8a7-9de4d6e17f13",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I followed the logic from the other PR that @RichardYuSTUG did, would leave to Richard to explain why we did this :)",
        "createdAt" : "2019-09-20T20:35:16Z",
        "updatedAt" : "2019-09-20T20:35:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c93a3c67-a7d2-4038-a92e-c68186a4b798",
        "parentId" : "e7f7f270-cf53-41cd-b8a7-9de4d6e17f13",
        "authorId" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "body" : "@bbejeck @guozhangwang  Oops, looks like I missed this. Bill has a point here. I will probably log a JIRA to get this done.",
        "createdAt" : "2020-01-03T01:20:06Z",
        "updatedAt" : "2020-01-03T01:20:07Z",
        "lastEditedBy" : "32d43f1c-0232-4c2f-9548-9c3dfd6f181a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bc8bf0f0703bf557bff6c8ae5c9a347599c8d4f",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +751,755 @@                    + \" to {} in stream task {}\", partition, committedTimestamp, this);\n            } else {\n                log.debug(\"No committed timestamp was found in metadata for partition {}\", partition);\n            }\n        }"
  },
  {
    "id" : "78677307-e8c8-4209-afc8-cde25b0f0527",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-298553524",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3162310-dc9d-4634-b382-cb3087a80cbb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is a mix of \"old\" `initializeStateStores` (the part to filter for source topic partitions that are use as changelogs) and \"old\" `AbstractTaks#committedOffsetForPartitions`)",
        "createdAt" : "2019-10-08T06:28:04Z",
        "updatedAt" : "2019-10-10T01:02:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +270,274 @@    }\n\n    private void initializeCommittedOffsets(final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata) {\n        // Currently there is no easy way to tell the ProcessorStateManager to only restore up to\n        // a specific offset. In most cases this is fine. However, in optimized topologies we can"
  },
  {
    "id" : "62522ca8-b327-438f-832e-17edb212ed70",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-298553743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7356799b-ac5e-4a93-ae4b-04d6b92d724f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is not private. Same implementation as before, however, we get `offsetsAndMetadata` passed in, and don't use the consumer to get them from the brokers.",
        "createdAt" : "2019-10-08T06:28:48Z",
        "updatedAt" : "2019-10-10T01:02:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +292,296 @@    }\n\n    private void initializeTaskTime(final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata) {\n        for (final Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsetsAndMetadata.entrySet()) {\n            final TopicPartition partition = entry.getKey();"
  },
  {
    "id" : "e41ea101-ef90-4c41-a3e9-a26dd40b930f",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-298553997",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b47c94b-ef25-425a-9ad3-bdf83c1829bb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just simplified -- moved the offset initialization into the constructor.",
        "createdAt" : "2019-10-08T06:29:34Z",
        "updatedAt" : "2019-10-10T01:02:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +316,320 @@\n    @Override\n    public boolean initializeStateStores() {\n        log.debug(\"Initializing state stores\");\n        registerStateStores();"
  },
  {
    "id" : "aa80b403-ca1e-4d6b-96c0-266e341b9374",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-298684931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12bcd06c-f0c8-41fe-9e42-1dc9e6852d4f",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Apparently it is not completely save to call instance methods from the constructor since the object and its member variables are  not completely initialised yet. Static methods would be fine, though.\r\n\r\nI do not think that `initializeCommittedOffsets()` is currently problematic since it only accesses member variables from `AbstractTask` which should be already initialised. However, `initializeTaskTime()` accesses `partitionGroup` which is created in the constructor. Since we cannot know what reorderings a compiler does, it would be better to specify `initializeTaskTime()` as static and pass in `partitionGroup`. To make `initializeCommittedOffsets()` future-proof, it would also be good to also transform it to a static method.",
        "createdAt" : "2019-10-08T12:23:37Z",
        "updatedAt" : "2019-10-10T01:02:23Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +260,264 @@            final Map<TopicPartition, OffsetAndMetadata> offsetsAndMetadata = consumer.committed(partitions);\n            initializeCommittedOffsets(offsetsAndMetadata);\n            initializeTaskTime(offsetsAndMetadata);\n        } catch (final AuthorizationException e) {\n            throw new ProcessorStateException(String.format(\"task [%s] AuthorizationException when initializing offsets for %s\", id, partitions), e);"
  },
  {
    "id" : "8047a7cb-80c3-42f3-9e5a-f412fc6d762a",
    "prId" : 7463,
    "prUrl" : "https://github.com/apache/kafka/pull/7463#pullrequestreview-300479851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74d58e42-6940-4592-b0e0-618133c794f5",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is also new -- we implicitly re-initialize the task on `resume()` -- was done \"outside\" before",
        "createdAt" : "2019-10-10T01:06:45Z",
        "updatedAt" : "2019-10-10T01:06:45Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "eb7a87fc-0888-4d03-86d4-cecbbcf36b9c",
        "parentId" : "74d58e42-6940-4592-b0e0-618133c794f5",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Do we really need to re-initialize committed offsets and task time during Resume?",
        "createdAt" : "2019-10-10T22:03:15Z",
        "updatedAt" : "2019-10-10T22:03:16Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "0f020881-d857-4f99-aa3c-3f01832cf8db",
        "parentId" : "74d58e42-6940-4592-b0e0-618133c794f5",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes, because in `StreamTask#suspend()` we call `closeTopology()` that calls `partitionGroup.clear()` that resets all times to `UNKNOWN`.",
        "createdAt" : "2019-10-11T06:00:02Z",
        "updatedAt" : "2019-10-11T06:00:03Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c47dfc79b0b4a8238e7bdc8707ee9ca32ff324ea",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +373,377 @@            }\n        }\n        initializeMetadata();\n    }\n"
  },
  {
    "id" : "ccba96cc-dbe6-4f8b-a587-61588fd0b393",
    "prId" : 7566,
    "prUrl" : "https://github.com/apache/kafka/pull/7566#pullrequestreview-306864390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c9f3fcf-6a62-4765-b97a-17afb248f040",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Nice cleanup, it makes looking at `StreamTask` bit easier having `TaskMetrics` in a separate class.",
        "createdAt" : "2019-10-24T21:06:11Z",
        "updatedAt" : "2019-10-25T09:01:15Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "415bca6f0f8d8acd47bfb9bdbc19e08fa50eb673",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +141,145 @@        punctuateLatencySensor = TaskMetrics.punctuateSensor(threadId, taskId, streamsMetrics);\n        recordLatenessSensor = TaskMetrics.recordLatenessSensor(threadId, taskId, streamsMetrics);\n        TaskMetrics.droppedRecordsSensor(threadId, taskId, streamsMetrics);\n\n        final ProductionExceptionHandler productionExceptionHandler = config.defaultProductionExceptionHandler();"
  },
  {
    "id" : "8cba26fd-6675-43b2-8c0e-f6095c7d649a",
    "prId" : 7566,
    "prUrl" : "https://github.com/apache/kafka/pull/7566#pullrequestreview-307314605",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f42bc93b-4210-4d19-87d0-b27a3b29c0b1",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Are we ever going to need to use the return value here? Instead of using a `Supplier` maybe we could use a `Runnable` in the signature and we could get rid of the `return null` statements.",
        "createdAt" : "2019-10-24T21:11:01Z",
        "updatedAt" : "2019-10-25T09:01:15Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "97271194-a9c2-4e87-a132-7d1c446c010d",
        "parentId" : "f42bc93b-4210-4d19-87d0-b27a3b29c0b1",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "+1. I think the appropriate functional interface is ‘Java.util.function.Consumer’",
        "createdAt" : "2019-10-25T16:22:56Z",
        "updatedAt" : "2019-10-25T16:22:56Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "415bca6f0f8d8acd47bfb9bdbc19e08fa50eb673",
    "line" : 212,
    "diffHunk" : "@@ -1,1 +439,443 @@        try {\n            StreamsMetricsImpl.maybeMeasureLatency(\n                () -> {\n                    node.punctuate(timestamp, punctuator);\n                },"
  },
  {
    "id" : "fcca0254-a8a5-4c0c-96f7-273498d83005",
    "prId" : 7589,
    "prUrl" : "https://github.com/apache/kafka/pull/7589#pullrequestreview-306262564",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4056b20a-57a8-4df7-a38d-5612cf5d4ddf",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "just a small cleanup on the side",
        "createdAt" : "2019-10-24T00:27:01Z",
        "updatedAt" : "2019-10-25T00:11:45Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e32bf0cafcfb8d5e7765f081fe54450112465e1",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +682,686 @@            super.flushState();\n\n            if (eosEnabled) {\n                maybeAbortTransactionAndCloseRecordCollector(isZombie);\n            }"
  },
  {
    "id" : "685ffb7b-8eb9-4c15-adae-fee289ca6b10",
    "prId" : 7748,
    "prUrl" : "https://github.com/apache/kafka/pull/7748#pullrequestreview-326537264",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't think that an `UnknownProducerIdException` implies that a task was migrated.",
        "createdAt" : "2019-11-30T02:52:58Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8d7f7e04-bc32-45a9-9591-732cea73a7ed",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Agreed, but `TaskMigratedException` is the mechanism to initiate a rebalance, which is currently the only way that we can re-initialize the producers.\r\n\r\nI think we can stand to re-evaluate how we're handling all these different producer and consumer exceptions (with and without eos). Right now, there are a _lot_ of catch blocks for specific exceptions sprinkled throughout the codebase, and we universally either crash the thread or initiate a rebalance to attempt recovery. It would certainly benefit from developing a holistic approach, but right now, I'm just trying to get Streams threads to quit dying within a few hours of running in EOS mode, and I'm trying to restrain myself from broad refactoring so we can hope to merge this in for 2.4.0.\r\n\r\n(About that last statement, I've been on holiday this week, so I haven't had time to document the comprehensive analysis in the ticket, but I do plan to make a case that it is a regression. When I ran 2.3 under similar conditions, we still had threads dying, but they were only dying from KIP-360-related-causes. In 2.4, Streams threads are dying from multiple new causes, related to the changes that we made in 2.4... Anyway, more details coming early next week, then we can discuss it)",
        "createdAt" : "2019-11-30T03:15:56Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "84e7ee4d-960f-4f3a-a054-43668b229308",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Give the fix for the root cause of `UnknownProducerIdException` (via KIP-360), I am wondering if we should actually treat it as fatal? I also don't see why it would be regression if KS dies if this exception is thrown though? (I understand that we did introduce some regression bugs, but those seem unrelated to `UnknownProducerIdException`?)\r\n\r\nTo be fair, 2.4.0 does not contain a full implementation of KIP-360 and thus, this fix might be a workaround... But frankly, I am not very happy about it, even if I understand the desire to just stabilize it somehow without a refactoring that won't make it into 2.4.0 anyway.",
        "createdAt" : "2019-11-30T05:18:08Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f0048ce6-6579-45bc-bef3-7004689f2708",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, then it seems worth hashing it out. Can you elaborate what is there to be unhappy about? I figured it would be reasonable to treat it as \"recoverable by creating a new Producer\" instead of \"fatal and you should immediately terminate the thread\".\r\n\r\nWhat I was thinking was that is seems like the broker is telling us it doesn't know who we are (anymore). Because of the context, we know that it _used_ to know who we were, so it must have forgotten somehow, and it doesn't really matter how because we can always shrug it off and re-create our producer to try again.\r\n\r\nIIUC, KIP-360 would reduce the occurrence of the exception by keeping your producer id cached even after its ttl has expired, but it by no means guarantees that it'll remember you regardless of how long you're silent.\r\n\r\nFrom that perspective it seems reasonable to catch this exception and conclude, \"Oops, it looks like we were silent too long and our Producer has effectively expired. We should make a new one and try again.\" This isn't the same thing as getting fenced, but the resolution is the same (make a new Producer and try again).\r\n\r\nThen again, this perspective may be based on a faulty understanding of the system. Is this approach unsafe, and we should actually terminate the application instead?",
        "createdAt" : "2019-11-30T05:39:02Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "f742f5ba-424f-44db-9a1f-9ae174904bbe",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For this type or error, before KIP-360, the producer should self-recover and never throw an exception. (Cf \"motivation\" section of the KIP). If this error occurs, something really bad happened for the transaction and we are in an unknown state -- not sure if rebalancing and retrying is the right approach for this case \\cc @guozhangwang @hachikuji @bob-barrett -- also, maybe it's just sufficient to close the task locally and recreate it -- I don't see a need to trigger a rebalance (in case it is ok to recorve from within KS).\r\n\r\n>  This isn't the same thing as getting fenced, but the resolution is the same (make a new Producer and try again).\r\n\r\nI disagree. If we got fenced, a new producer with the same transactional.id was created and we know that we don't own the task any longer. For a `UnknownProducerIdException` we still own the task.\r\n\r\n> Is this approach unsafe, and we should actually terminate the application instead?\r\n\r\nI don't thinks it's unsafe, but it's not the \"right\" fix IMHO, and this bug is also not a regression.",
        "createdAt" : "2019-11-30T20:57:37Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c78b9c6a-1984-40d1-b00b-46c1aea66793",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks for the clarification, @mjsax .\r\n\r\nI agree that it would be better to just close the task and re-open it, but I don't feel comfortable introducing a whole new task lifecycle at this point for the 2.4.0 release. My rationale was that triggering a rebalance would put Kafka Streams through a well-known and well-tested code path that will result in the task getting closed and then opened again.\r\n\r\nI do think it makes sense to go ahead and handle this case along with the two regressions. In my testing, this exception was just as fatal for Streams as the other two. Specifically, unless I include all three fixes, my soak test saw StreamThreads start dying within a few hours.\r\n\r\nIt seems like maybe a good approach right now would be to take the simple and sub-optimal path of just rebalancing when we encounter this exception for the 2.4.0 release, and file a Jira to optimize it in the way you suggest.\r\n\r\nIt would be good, by the way, to find out the answer to your question of whether it's safe to continue or not. Note that the current behavior, both in 2.4 and 2.3, without this patch is that a thread will get this exception and then shut itself down. This leads to a rebalance (since a member has left the group), after which the task is assigned to another thread, which continues processing it. Thus, we are already responding to this condition by rebalancing. It's just that we permanently lose a thread in the process. With this patch, we still rebalance, but we get to keep the thread running. If it's really unsafe to continue processing, though, we should stop the entire Streams application and force the operator to diagnose the problem with the brokers and start the app back up in a safe state.",
        "createdAt" : "2019-12-02T05:18:15Z",
        "updatedAt" : "2019-12-03T04:02:12Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6bfeffc1-32e9-4f6e-9719-12601474ed70",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I shared some thoughts on the comment above: before KIP-447, when we re-trigger the rebalance if the task is indeed migrated out the corresponding producer would be closed, otherwise that producer will be retained. But I think after KIP-447 we need to revisit this again.\r\n\r\nAt the moment I feel okay to treat `UnknownProducerId` equally as `ProducerFenced`.",
        "createdAt" : "2019-12-03T22:10:12Z",
        "updatedAt" : "2019-12-03T23:29:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "17f7e1b5-4135-48a2-80fd-eb9ecac6688f",
        "parentId" : "79f72754-1c4e-4ae2-a906-a2da97d618af",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks. That will be a good opportunity to clean up what is honestly a pretty ham-handed approach here to gracefully deal with this condition without changing too much code.",
        "createdAt" : "2019-12-04T00:28:38Z",
        "updatedAt" : "2019-12-04T00:28:38Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "96a2d969df7fe000bbda04c9aab3b0d50eaa655c",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +340,344 @@                this.producer.beginTransaction();\n            } catch (final ProducerFencedException | UnknownProducerIdException e) {\n                throw new TaskMigratedException(this, e);\n            }\n            transactionInFlight = true;"
  },
  {
    "id" : "9ae63bef-8e89-40f0-b99d-f8a5a72a42bb",
    "prId" : 7748,
    "prUrl" : "https://github.com/apache/kafka/pull/7748#pullrequestreview-326539096",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32dc6cc3-f0f0-4ba1-8f12-4f6059da6a68",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For here and `producer.beginTransaction` above: I think `beginTxn / sendOffsetsToTxn / commitTxn` would not throw UnknownProducerIdException but it does not harm to be more careful for 2.4 release -- so if you want to keep it as is I'm fine with it too.",
        "createdAt" : "2019-12-03T22:47:17Z",
        "updatedAt" : "2019-12-03T23:29:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "4b48f025-3cb2-4df0-a695-2586640c67ce",
        "parentId" : "32dc6cc3-f0f0-4ba1-8f12-4f6059da6a68",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, I wasn't sure, so I just put it everywhere that we already check for `ProducerFencedException`, on the rationale that, if we can get fenced, then we must have a transactional id, and if we have an id, then it could be \"unknown\". Clearly, this is more intuitive than analytical, so I find your feedback plausible.",
        "createdAt" : "2019-12-04T00:34:29Z",
        "updatedAt" : "2019-12-04T00:34:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "96a2d969df7fe000bbda04c9aab3b0d50eaa655c",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +560,564 @@                consumer.commitSync(consumedOffsetsAndMetadata);\n            }\n        } catch (final CommitFailedException | ProducerFencedException | UnknownProducerIdException error) {\n            throw new TaskMigratedException(this, error);\n        }"
  },
  {
    "id" : "b905a606-0515-4330-b13a-2c8aee97e19f",
    "prId" : 7833,
    "prUrl" : "https://github.com/apache/kafka/pull/7833#pullrequestreview-332279479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a933758b-883b-4394-9721-622244cd8b32",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Minor cleanup.",
        "createdAt" : "2019-12-15T18:22:54Z",
        "updatedAt" : "2019-12-16T22:43:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d9c7dac7c2dd1088bd1dcf75c130708cb72e80f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +178,182 @@\n        // initialize the topology with its own context\n        processorContext = new ProcessorContextImpl(id, this, config, this.recordCollector, stateMgr, streamsMetrics, cache);\n\n        final TimestampExtractor defaultTimestampExtractor = config.defaultTimestampExtractor();"
  },
  {
    "id" : "60f73d3b-2aa7-4d74-b124-767af85a0512",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-355526952",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f8c1b2c-4b8d-412f-9fda-757789973d5c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Previously, we clear the `partitionGroup` within `closeTopology()` that we call above -- however, because of the consumer position tracking, we need to delay it after the commit.",
        "createdAt" : "2020-02-08T03:30:01Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +637,641 @@                commit(false, partitionTimes);\n            } finally {\n                partitionGroup.clear();\n\n                if (eosEnabled) {"
  },
  {
    "id" : "a2a3efde-e32c-4125-9438-c7bf0ae063e2",
    "prId" : 8058,
    "prUrl" : "https://github.com/apache/kafka/pull/8058#pullrequestreview-362291724",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b05483b-fcfd-4cd0-92ce-ee4bbed1c45f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Here is the attempted fix of https://issues.apache.org/jira/browse/KAFKA-9572: if we are closing / suspending a restoring task, we should only update the checkpoint file but should NOT commit offsets, since the committed offsets indicate the  \"restore end\" and should not be updated, cc @cadonna who filed the JIRA.",
        "createdAt" : "2020-02-20T22:50:45Z",
        "updatedAt" : "2020-02-20T23:13:53Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03f4778cba8697bad6e5c5d7ce40df6e59214c02",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +237,241 @@            // do nothing\n            log.trace(\"Skip suspending since state is {}\", state());\n        } else if (state() == State.RUNNING) {\n            closeTopology(true);\n"
  },
  {
    "id" : "28f31bce-02fd-4214-82c7-2593ad7ea449",
    "prId" : 8058,
    "prUrl" : "https://github.com/apache/kafka/pull/8058#pullrequestreview-362291724",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4deffb7-124f-48cb-9577-9dca360c20af",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is part of the fix as well: only flushing / checkpointing, but not committing.",
        "createdAt" : "2020-02-20T22:51:30Z",
        "updatedAt" : "2020-02-20T23:13:53Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03f4778cba8697bad6e5c5d7ce40df6e59214c02",
    "line" : 127,
    "diffHunk" : "@@ -1,1 +429,433 @@\n                transitionTo(State.CLOSING);\n            } else if (state() == State.RESTORING) {\n                executeAndMaybeSwallow(clean, () -> {\n                    stateMgr.flush();"
  },
  {
    "id" : "35181657-46cf-46d7-9535-fecf40e3b5ec",
    "prId" : 8060,
    "prUrl" : "https://github.com/apache/kafka/pull/8060#pullrequestreview-357139833",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00ede6cc-b562-4d1a-9f6e-9f961ac9fbda",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we throw `TimeoutException` directly but not wrap it?",
        "createdAt" : "2020-02-10T01:56:41Z",
        "updatedAt" : "2020-02-14T22:46:42Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "83bc4163-b257-480c-83ac-ada779399842",
        "parentId" : "00ede6cc-b562-4d1a-9f6e-9f961ac9fbda",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Because on the caller `TaskManager` we would swallow TimeoutException anyways.",
        "createdAt" : "2020-02-12T01:43:31Z",
        "updatedAt" : "2020-02-14T22:46:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "19332579cacd46146a8309938215845c16448a8d",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +625,629 @@                ConsumerConfig.DEFAULT_API_TIMEOUT_MS_CONFIG);\n\n            throw e;\n        } catch (final KafkaException e) {\n            throw new StreamsException(format(\"task [%s] Failed to initialize offsets for %s\", id, partitions), e);"
  },
  {
    "id" : "45f73f54-7057-4004-b415-89293c55a7fd",
    "prId" : 8065,
    "prUrl" : "https://github.com/apache/kafka/pull/8065#pullrequestreview-356417505",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "65268339-8208-4f50-9677-5df83c08dd17",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Exposed this again for use in TopologyTestDriver",
        "createdAt" : "2020-02-11T04:55:54Z",
        "updatedAt" : "2020-02-11T22:50:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fc4da0e7f0a29845782c4f3a860289bbdfb356a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +445,449 @@     * source topic partitions, or if it is enforced to be processable\n     */\n    public boolean isProcessable(final long wallClockTime) {\n        if (partitionGroup.allPartitionsBuffered()) {\n            idleStartTime = RecordQueue.UNKNOWN;"
  },
  {
    "id" : "8133cef1-87de-4f00-abf0-b584c4479097",
    "prId" : 8116,
    "prUrl" : "https://github.com/apache/kafka/pull/8116#pullrequestreview-359211897",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "736a3cb8-b53e-4f2c-959c-261e0950cf89",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Judging from the stacktrace generated in the prior logging change, this is where we're throwing a TaskMigratedException, even though this block is an \"unclean close\". Just trying out ignoring the exception to see what happens.",
        "createdAt" : "2020-02-13T23:20:32Z",
        "updatedAt" : "2020-02-20T20:36:25Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6035425a-f6b5-4ca3-890e-15dcfd407678",
        "parentId" : "736a3cb8-b53e-4f2c-959c-261e0950cf89",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Just to clarify we should only swallow under `dirty` suspension (in trunk it is wrapped in `close`) right? For clean close / suspend if it throws we would capture it and wrap as TaskMigrated still and then handle them by closing the task as dirty (in that second try we would swallow).",
        "createdAt" : "2020-02-14T16:29:33Z",
        "updatedAt" : "2020-02-20T20:36:25Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f9013948-8d41-4afc-80a0-868f450f0ac0",
        "parentId" : "736a3cb8-b53e-4f2c-959c-261e0950cf89",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "That's right",
        "createdAt" : "2020-02-14T20:51:36Z",
        "updatedAt" : "2020-02-20T20:36:25Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ba79bf6de34142dff929bae3d5c9e50b96800c1",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +660,664 @@            } catch (final ProcessorStateException e) {\n                // ignore any exceptions while flushing (all stores would have had a chance to flush anyway)\n            }\n\n            if (eosEnabled) {"
  },
  {
    "id" : "b70ad110-b0c8-4ad6-b430-cc9a492d0984",
    "prId" : 8140,
    "prUrl" : "https://github.com/apache/kafka/pull/8140#pullrequestreview-361604555",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ef59624-38c5-42c9-b112-4a644a516252",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Technically it may be running or restoring here",
        "createdAt" : "2020-02-20T02:58:03Z",
        "updatedAt" : "2020-02-20T20:31:48Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "3164fce49de499e640dad11ed3d56ba47ad14bb7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +255,259 @@\n                transitionTo(State.SUSPENDED);\n                log.info(\"Suspended active\");\n            } else {\n                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);"
  },
  {
    "id" : "e7ebfb0d-bc62-40db-88de-fea5b6c4414c",
    "prId" : 8173,
    "prUrl" : "https://github.com/apache/kafka/pull/8173#pullrequestreview-365270536",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e15310e5-3ce4-4799-8df4-a61b100aaba9",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Seems like maybe we could just get rid of the `suspended` state entirely, but I guess we plan to do that anyway if/when we remove support for EAGER",
        "createdAt" : "2020-02-26T21:30:59Z",
        "updatedAt" : "2020-02-26T21:31:00Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "b7497b2c-88ce-4146-a903-8e4af5e369c1",
        "parentId" : "e15310e5-3ce4-4799-8df4-a61b100aaba9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yes -- from restoring to suspended it is only to update the local `checkpoint` file, from suspended to restoring there's actually nothing needed. In that sense restoring and suspended states are very similar already, BUT still not exactly the same.\r\n\r\nI do hope we get rid of it some time after we remove the EAGER protocol.",
        "createdAt" : "2020-02-26T21:52:42Z",
        "updatedAt" : "2020-02-26T21:52:43Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef60891ca88d46a9f2bf6d26dfa16626420b4df9",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +284,288 @@            case SUSPENDED:\n                // just transit the state without any logical changes: suspended and restoring states\n                // are not actually any different for inner modules\n                transitionTo(State.RESTORING);\n                log.info(\"Resumed to restoring state\");"
  },
  {
    "id" : "d87c70b2-76bd-44fe-bfb8-bb7152bcc9c2",
    "prId" : 8180,
    "prUrl" : "https://github.com/apache/kafka/pull/8180#pullrequestreview-370505629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9329ff1-1c90-4815-a5a2-27a553e38269",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is an improvement I want to add along with the PR: since we delete the checkpoint file after completed loading, and before we initialize to RESTORING if there's an exception we could lose that checkpoint. So here in Restoring / Created state upon closing I also added the checkpoint logic here.",
        "createdAt" : "2020-03-06T17:39:23Z",
        "updatedAt" : "2020-03-06T23:37:23Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d1bea170bbbf209ad20e5493ae832fd247ebfc3d",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +415,419 @@        if (state() == State.CREATED) {\n            // the task is created and not initialized, just re-write the checkpoint file\n            executeAndMaybeSwallow(clean, () -> {\n                stateMgr.checkpoint(Collections.emptyMap());\n            }, \"state manager checkpoint\");"
  },
  {
    "id" : "ca866840-07a0-443b-9523-70fdbfe3d739",
    "prId" : 8180,
    "prUrl" : "https://github.com/apache/kafka/pull/8180#pullrequestreview-370505629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57ea11a0-8baa-4b04-887c-89e08aaf4bc9",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We could have added the stores, but then before transiting to RESTORING an exception happens; hence here I always call closeStateManager which would just be an no-op if the lock is not grabbed / stores not added.",
        "createdAt" : "2020-03-06T17:40:50Z",
        "updatedAt" : "2020-03-06T23:37:23Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d1bea170bbbf209ad20e5493ae832fd247ebfc3d",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +445,449 @@        }\n\n        if (state() == State.CLOSING) {\n            // if EOS is enabled, we wipe out the whole state store for unclean close\n            // since they are invalid to use anymore"
  },
  {
    "id" : "1fd08a18-8e3b-4ea9-8c76-560b7f8a5566",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-370512287",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07cdd6b2-9915-4e1b-a15a-8bac43966776",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Why do we start to suppress warnings?",
        "createdAt" : "2020-03-05T00:33:39Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "c9c9ef5c-a259-4710-bee7-1b1aa7af708a",
        "parentId" : "07cdd6b2-9915-4e1b-a15a-8bac43966776",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should have done this from the beginning on... (it's just a \"side fix\")",
        "createdAt" : "2020-03-06T17:50:27Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 375,
    "diffHunk" : "@@ -1,1 +562,566 @@     * @throws TaskMigratedException if the task producer got fenced (EOS only)\n     */\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    public boolean process(final long wallClockTime) {\n        if (!isProcessable(wallClockTime)) {"
  },
  {
    "id" : "81f2983a-3ec4-4cb2-be41-68a33b0d465b",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375614304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b39992d-fb9e-4358-843f-18d2f6f16184",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we add a `@return` for this method? Also we should comment about the different indications when we return an empty map vs null.",
        "createdAt" : "2020-03-11T21:01:37Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "ae4e6568-ea3c-4382-b1e8-6df785123d38",
        "parentId" : "8b39992d-fb9e-4358-843f-18d2f6f16184",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need to document this in the method JavaDoc? It's an internal method? Internal comment outdate quickly if code is changed and comments are not updated accordingly (what happens 99% of the time). Hence, I would prefer to limit comments if possible. In doubt, we should document at `Task` level anyway.",
        "createdAt" : "2020-03-12T00:13:04Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fff75631-b190-4e07-ae69-64835ab2892b",
        "parentId" : "8b39992d-fb9e-4358-843f-18d2f6f16184",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "@guozhangwang I am actually wondering about point (5) -- why do we need to checkpoint the state manager if we wipe out the store later anyway for the unclean EOS case?",
        "createdAt" : "2020-03-12T00:17:53Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "0f9e00fb-e27b-4373-b76b-ef4d63947dca",
        "parentId" : "8b39992d-fb9e-4358-843f-18d2f6f16184",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yes we are unnecessarily checkpointing here --- the reason is that EOS flag was original striped out of task and only processor-state-manager knows about it; now since we get this EOS flag back to task (sigh.. :) we can add this additional check.",
        "createdAt" : "2020-03-16T23:52:01Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 250,
    "diffHunk" : "@@ -1,1 +437,441 @@     * @throws TaskMigratedException if the task producer got fenced (EOS)\n     */\n    private Map<TopicPartition, Long> prepareClose(final boolean clean) {\n        final Map<TopicPartition, Long> checkpoint;\n"
  },
  {
    "id" : "94b178af-b8e2-44bc-9b48-15cf894325c0",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-372454953",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a776c78b-fd64-4508-8e9e-f243a07e8e96",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Remove `if`",
        "createdAt" : "2020-03-11T21:04:39Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 290,
    "diffHunk" : "@@ -1,1 +458,462 @@            checkpoint = Collections.emptyMap();\n        } else if (state() == State.SUSPENDED) {\n            // if `SUSPENDED` do not need to checkpoint, since when suspending we've already committed the state\n            checkpoint = null; // `null` indicates to not write a checkpoint\n        } else {"
  },
  {
    "id" : "242d280a-7e07-4e68-99ce-dc05cc740522",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375614304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d52ce389-a257-4b8d-93f4-3e0db0113d71",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Also the above step #4 is no longer correct, the commit is done on TaskManager now.",
        "createdAt" : "2020-03-11T21:57:16Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "05aa84db-dd89-4b00-8864-006b6f0a13c9",
        "parentId" : "d52ce389-a257-4b8d-93f4-3e0db0113d71",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "You see -- that is may point from above... The code should be written in a way that explains itself... Updating comments always slips...",
        "createdAt" : "2020-03-12T00:13:57Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1049e289-f7a1-4c5e-89c2-6e6126d8882e",
        "parentId" : "d52ce389-a257-4b8d-93f4-3e0db0113d71",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I couldn't fully follow this idea, just playing devil advocates here, if we think meta code comments actually hinder the readability of internal class, why not just remove all the internal function meta comments, as they would get outdated anyway? For me the return type comment is still valuable for understandability. If the comment gets outdated, we should just update it. cc @guozhangwang if the idea here makes sense, or we could get a consensus on what needs to be done in internal class comments, and what's not.",
        "createdAt" : "2020-03-16T17:06:41Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "f93693f3-99d5-4411-a1ee-933278b8c837",
        "parentId" : "d52ce389-a257-4b8d-93f4-3e0db0113d71",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I would suggest not restricting ourselves to some specific rules about comments :) Personally I tried to avoid the `one line comment explaining one line code` type of comments inside a function since it should be obvious, rather I'd add some comments for a block or several blocks if I fear it maybe hard to read by itself. I think you guys should just make your best judgement here.\r\n\r\nAnd for internal functions, I agree that we do not necessarily need to write java-docs, and this one, for example, I wrote the java-doc as part of the tech debt cleanup just to remind what operations MUST be considered here inside closing / suspending etc so that later on when we change the function itself by other contributors, they would use it as a reference to check if they mistakenly missed some steps or re-ordered some steps. However if we are going to split this function into multiple, instead of just re-structuring the function as a whole, then although I have my preference I'd leave to you guys if you want to add the javadoc for both pre/post of you feel now it is too obvious to bother :) ",
        "createdAt" : "2020-03-16T23:57:18Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 250,
    "diffHunk" : "@@ -1,1 +437,441 @@     * @throws TaskMigratedException if the task producer got fenced (EOS)\n     */\n    private Map<TopicPartition, Long> prepareClose(final boolean clean) {\n        final Map<TopicPartition, Long> checkpoint;\n"
  },
  {
    "id" : "97c8e889-43e4-490f-ad35-0550b0aa55fc",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-374913535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90c6b577-a344-4c44-8e1a-7c4fb46317eb",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Looks like we lack test coverage for TimeoutException and KafkaException cases",
        "createdAt" : "2020-03-11T22:13:39Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "4c935653-557b-466c-9bf1-baa0faf7173f",
        "parentId" : "90c6b577-a344-4c44-8e1a-7c4fb46317eb",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yeah, this PR does not yet add all required test...",
        "createdAt" : "2020-03-12T00:10:57Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2c434d70-9979-42f7-88d5-8ff8ab837701",
        "parentId" : "90c6b577-a344-4c44-8e1a-7c4fb46317eb",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Covered via `shouldCommitNextOffsetFromQueueIfAvailable` and `shouldCommitConsumerPositionIfRecordQueueIsEmpty`",
        "createdAt" : "2020-03-16T05:02:44Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 193,
    "diffHunk" : "@@ -1,1 +384,388 @@        }\n\n        return consumedOffsetsAndMetadata;\n    }\n"
  },
  {
    "id" : "ab5e0859-cae0-4a10-89e6-d476111bf1e1",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375631922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48b86590-d8a2-4c39-92ae-8e6e44718b1c",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is not introduced in this PR, but: while thinking about it, I realized for RESTORING state we do not need to rely on eosDisabled to checkpoint, in fact we can always checkpoint during RESTORING here.",
        "createdAt" : "2020-03-13T03:50:05Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "16f2671f-65ea-4641-b560-4d89af3a5a34",
        "parentId" : "48b86590-d8a2-4c39-92ae-8e6e44718b1c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack",
        "createdAt" : "2020-03-16T05:00:28Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "69e476b1-ffff-46dc-9312-a7398086022e",
        "parentId" : "48b86590-d8a2-4c39-92ae-8e6e44718b1c",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Do we have unit test to check the checkpoint status after `postCommit()`?",
        "createdAt" : "2020-03-16T16:10:32Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "a96fbd77-5ec4-4fd0-87ff-1f2ae72d6350",
        "parentId" : "48b86590-d8a2-4c39-92ae-8e6e44718b1c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes, `shouldRespectCommitNeeded()` check this already.",
        "createdAt" : "2020-03-16T22:44:47Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +325,329 @@            case RUNNING:\n                commitNeeded = false;\n                commitRequested = false;\n\n                if (eosDisabled) {"
  },
  {
    "id" : "6318076a-990a-4f5f-8d1a-d9af1ed5aa9d",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375631536",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "282b3b85-5206-4b29-91d0-dd1f68710aad",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "we could just do one log in front: `log.info(\"Prepare suspending {}\", state());`",
        "createdAt" : "2020-03-16T16:06:09Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "3c065f67-338b-4825-9bfc-c47071be08b7",
        "parentId" : "282b3b85-5206-4b29-91d0-dd1f68710aad",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well, we log \"skip\" for state CREATED and we throw for invalid states. Note sure how to do this?",
        "createdAt" : "2020-03-16T22:43:50Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +239,243 @@            recordCollector.flush();\n\n            log.info(\"Prepare suspending running\");\n        } else if (state() == State.RESTORING) {\n            stateMgr.flush();"
  },
  {
    "id" : "2bf013a7-a541-4d8a-b8ee-3417ef9b31d1",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375614304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "857b56e2-4fdd-4e36-9544-f5fff073b8a4",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In either eos-alpha or eos-beta or non-eos, we can just loop over all the \"committable partitions\" and call `mainConsumer#position` once, so this function can be extracted out of the task as a per-task call.\r\n\r\nMore specifically, in the prepareXX calls, we know based on the state of the task and clean flag whether or not we should commit the source topic offsets for this task, so we can let the prepareXX function to return `Map<TopicPartition, Long> partitionTimes` encoding the extracted timestamps for each partition instead of void --- when we decided not to commit we return an empty map. And then inside TaskManager we just use the `mainConsumer` to call position once and then pass that to the `commitOffsetsOrTransaction` call.",
        "createdAt" : "2020-03-16T22:23:14Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 169,
    "diffHunk" : "@@ -1,1 +351,355 @@\n    @Override\n    public Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n        if (state() == State.CLOSED) {\n            throw new IllegalStateException(\"Task \" + id + \" is closed.\");"
  },
  {
    "id" : "c8e06442-87cd-4d34-9513-8b23c6fbb82c",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-375614304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8b6a231-4231-4d95-bf7b-37f6e92949ac",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`For the next PR`: as I mentioned in the last commit I feel `prepareSuspend` and `prepareClose` can be consolidated with `prepareCommit` but in the next PR these logic would be changed again for eos-beta so maybe we cannot do that any more, so I'm fine with keeping as-is and we can revisit to see if we can really do this refactoring or not in the next PR when we did the eos-beta.",
        "createdAt" : "2020-03-16T23:47:56Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +229,233 @@     */\n    @Override\n    public void prepareSuspend() {\n        if (state() == State.CREATED || state() == State.SUSPENDED) {\n            // do nothing"
  },
  {
    "id" : "d8785680-6813-4e7e-abc9-35191e645311",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-376297222",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "337006b3-6f87-4386-9db3-fa886d73b87d",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "`For the next PR`: I see the reason I return the checkpoint is that we are now extracting the committing out of the task and I need to remember if we need to checkpoint and if yes which offsets after we've flushed and before we checkpoint, but since the state of the task would not change before / after the commit during close. \r\n\r\nMore specifically we only have three cases: 1) to not write checkpoint, 2) write checkpoints for written offsets (changelogs) only, 3) write checkpoint for written and consumed offsets. And no matter which case it is during the `preClose`, it would always be the same in the `post`, so why do we need to return it to task-manager, book-keep there, and then after commit to pass it back to tasks?",
        "createdAt" : "2020-03-17T00:07:51Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "cd7ed42a-6241-4811-9a79-30d5b67120c6",
        "parentId" : "337006b3-6f87-4386-9db3-fa886d73b87d",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "By `next PR`, you mean the one after we finish the EOS-beta commit feature right?",
        "createdAt" : "2020-03-17T16:05:29Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "e03c1b40-7ab7-4d5f-a66b-88582ff4e7b4",
        "parentId" : "337006b3-6f87-4386-9db3-fa886d73b87d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I mean the next PR when we add the EOS-beta feature --- please see the first comment I have with this tag.",
        "createdAt" : "2020-03-17T18:25:59Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 250,
    "diffHunk" : "@@ -1,1 +437,441 @@     * @throws TaskMigratedException if the task producer got fenced (EOS)\n     */\n    private Map<TopicPartition, Long> prepareClose(final boolean clean) {\n        final Map<TopicPartition, Long> checkpoint;\n"
  },
  {
    "id" : "d32d417d-e015-4896-b900-7c6dff8f5ab1",
    "prId" : 8221,
    "prUrl" : "https://github.com/apache/kafka/pull/8221#pullrequestreview-374782223",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aafd7c60-4d69-4540-9f4e-92a40fd9b10f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "This is nice!",
        "createdAt" : "2020-03-13T21:34:10Z",
        "updatedAt" : "2020-05-26T16:32:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "4b9cdd59-f770-44a7-9c8d-5c65c0a372aa",
        "parentId" : "aafd7c60-4d69-4540-9f4e-92a40fd9b10f",
        "authorId" : "889d8126-0663-4a3e-8712-81869bada9e0",
        "body" : "Thank you",
        "createdAt" : "2020-03-15T09:06:42Z",
        "updatedAt" : "2020-05-26T16:32:00Z",
        "lastEditedBy" : "889d8126-0663-4a3e-8712-81869bada9e0",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc85a4694d663ad13d75681d28398d4b61a4f482",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +1023,1027 @@    }\n\n    private class RecordQueueCreator {\n        private final LogContext logContext;\n        private final TimestampExtractor defaultTimestampExtractor;"
  },
  {
    "id" : "ae41bbad-8d4b-47ae-818b-936dfb983600",
    "prId" : 8221,
    "prUrl" : "https://github.com/apache/kafka/pull/8221#pullrequestreview-409930931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d086138-f11f-4a8a-98b7-7a3663c4b17c",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "If the state was RUNNING then we would effectively call `initializeTopology` twice. Is that intentional?",
        "createdAt" : "2020-05-10T04:33:26Z",
        "updatedAt" : "2020-05-26T16:32:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "8d6d1d97-9fcb-420c-9449-ede7d5bce0e8",
        "parentId" : "9d086138-f11f-4a8a-98b7-7a3663c4b17c",
        "authorId" : "889d8126-0663-4a3e-8712-81869bada9e0",
        "body" : "if I correctly remember if state==`RUNNING` `initializeTopology` is called only once in `update` method. Only if state == RESTORING it will be called later. It's no problem to call this method twice but it's aka optimization.",
        "createdAt" : "2020-05-12T11:03:17Z",
        "updatedAt" : "2020-05-26T16:32:00Z",
        "lastEditedBy" : "889d8126-0663-4a3e-8712-81869bada9e0",
        "tags" : [
        ]
      }
    ],
    "commit" : "dc85a4694d663ad13d75681d28398d4b61a4f482",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +428,432 @@        super.update(topicPartitions, processorTopology);\n        partitionGroup.updatePartitions(topicPartitions, recordQueueCreator::createQueue);\n        if (state() != State.RESTORING) { // if task is RESTORING then topology will be initialized in completeRestoration\n            initializeTopology();\n        }"
  },
  {
    "id" : "2131e18c-0ebe-4966-b720-58ee2ed82cac",
    "prId" : 8246,
    "prUrl" : "https://github.com/apache/kafka/pull/8246#pullrequestreview-372252785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ec986846-708c-4790-a2b4-8a2597be5e8b",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Not taking a hard stance on this spelling, just aiming for consistency across the code base",
        "createdAt" : "2020-03-10T19:21:08Z",
        "updatedAt" : "2020-03-13T22:09:33Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "a757918bbbf7c4b27aa29720e540a5603f890b1e",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +672,676 @@\n    @Override\n    public Map<TopicPartition, Long> purgeableOffsets() {\n        final Map<TopicPartition, Long> purgeableConsumedOffsets = new HashMap<>();\n        for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {"
  },
  {
    "id" : "713d6f2e-815c-4603-a8af-b41a6f348dee",
    "prId" : 8307,
    "prUrl" : "https://github.com/apache/kafka/pull/8307#pullrequestreview-378782369",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "718ab1ad-ca99-4445-a78d-c518aa2ee8e6",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This part will have some conflicts with @mjsax 's PR, just a note.",
        "createdAt" : "2020-03-20T18:57:54Z",
        "updatedAt" : "2020-03-20T19:02:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a6995ea1-5e32-4f33-ad29-687e02b88b2e",
        "parentId" : "718ab1ad-ca99-4445-a78d-c518aa2ee8e6",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Yea, one of us probably needs to rebase",
        "createdAt" : "2020-03-20T20:10:45Z",
        "updatedAt" : "2020-03-20T20:10:45Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f4cfd7503c0959ed2453e88ee9f1c98d280ca71",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +121,125 @@        this.time = time;\n        this.recordCollector = recordCollector;\n        eosEnabled = StreamsConfig.EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG));\n\n        final String threadId = Thread.currentThread().getName();"
  },
  {
    "id" : "f4e15dec-d784-4a87-a22d-b20ec1615d6c",
    "prId" : 8371,
    "prUrl" : "https://github.com/apache/kafka/pull/8371#pullrequestreview-387632893",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81d69d30-5d84-47da-9fdb-879d925193eb",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "req: Please verify the creation of those metrics in `StreamTaskTest#shouldConstructMetricsWithBuiltInMetricsVersionLatest()`.",
        "createdAt" : "2020-04-03T10:04:26Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "614b547c-923c-4094-9516-90007b317cf1",
        "parentId" : "81d69d30-5d84-47da-9fdb-879d925193eb",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack.",
        "createdAt" : "2020-04-03T23:29:12Z",
        "updatedAt" : "2020-04-06T18:04:42Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "325f0a4e5b38f0cdd495629577cba64c9857b98c",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +139,143 @@        processLatencySensor = TaskMetrics.processLatencySensor(threadId, taskId, streamsMetrics);\n        punctuateLatencySensor = TaskMetrics.punctuateSensor(threadId, taskId, streamsMetrics);\n        bufferedRecordsSensor = TaskMetrics.activeBufferedRecordsSensor(threadId, taskId, streamsMetrics);\n\n        streamTimePunctuationQueue = new PunctuationQueue();"
  }
]