[
  {
    "id" : "80ad6a43-8eb9-453e-a984-41542aff739c",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-196868153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "891cab3a-2dca-4ac3-9ff0-5d6a960109e3",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think we can still use `write(batch);` here for efficiency?",
        "createdAt" : "2019-01-23T22:56:57Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "7df54054-0487-41d7-93e5-bdf2d998711d",
        "parentId" : "891cab3a-2dca-4ac3-9ff0-5d6a960109e3",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`write(batch)` should be done by the caller -- that we call it in the other accessor is a bug -- will rename the method to `prepareBatch()`.",
        "createdAt" : "2019-01-24T19:04:07Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "418192eb-9825-43a1-9092-bc28988e67cc",
        "parentId" : "891cab3a-2dca-4ac3-9ff0-5d6a960109e3",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Not sure I can follow this: could you elaborate a bit more? I was thinking to use the RocksDB's\r\n\r\n```\r\nvoid write(final WriteOptions writeOpts, final WriteBatch updates)\r\n```\r\n\r\nAPI for the putAll call, is it possible?",
        "createdAt" : "2019-01-25T00:18:32Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "910a1d31-3912-4d29-90a6-316a61dc0a72",
        "parentId" : "891cab3a-2dca-4ac3-9ff0-5d6a960109e3",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "That is exactly what is use. Compare `RocksDB#putAll()`:\r\n```\r\n    @Override\r\n    public void putAll(final List<KeyValue<Bytes, byte[]>> entries) {\r\n        try (final WriteBatch batch = new WriteBatch()) {\r\n            dbAccessor.prepareBatch(entries, batch);\r\n            write(batch);\r\n        } catch (final RocksDBException e) {\r\n            throw new ProcessorStateException(\"Error while batch writing to store \" + name, e);\r\n        }\r\n    }\r\n```\r\n\r\nIt calls `dbAccessor.prepareBatch(entries, batch);` (already renamed from `putAll -> prepareBatch`) that is this method. We do the call \"outside\" because only who the batch is prepared differs.\r\n\r\nDoes this make sense",
        "createdAt" : "2019-01-25T04:57:34Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "32f6ff21-984a-425d-b2ec-dd2ba46ca627",
        "parentId" : "891cab3a-2dca-4ac3-9ff0-5d6a960109e3",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yup.",
        "createdAt" : "2019-01-28T04:03:04Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 143,
    "diffHunk" : "@@ -1,1 +141,145 @@        public void prepareBatch(final List<KeyValue<Bytes, byte[]>> entries,\n                                 final WriteBatch batch) throws RocksDBException {\n            for (final KeyValue<Bytes, byte[]> entry : entries) {\n                Objects.requireNonNull(entry.key, \"key cannot be null\");\n                if (entry.value == null) {"
  },
  {
    "id" : "6d4f248e-618e-44de-916c-d85b0509699e",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-197346836",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97052329-b460-4a04-8839-36ffce0a396b",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a meta question for my own understanding: my take is that after https://github.com/apache/kafka/pull/6204 we will let this store to extend `TimestampedBytesStore` as well, right?",
        "createdAt" : "2019-01-28T03:56:34Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "610c400b-2f41-4405-b959-54bfeee35bde",
        "parentId" : "97052329-b460-4a04-8839-36ffce0a396b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Correct.",
        "createdAt" : "2019-01-29T01:54:51Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +15,19 @@ * limitations under the License.\n */\npackage org.apache.kafka.streams.state.internals;\n\nimport org.apache.kafka.common.utils.AbstractIterator;"
  },
  {
    "id" : "44a8a5bd-f098-4587-a6a7-adb588b65561",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-197663800",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15cfe63e-6fc8-46e7-9ec5-f1a271cb1c48",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Are these two constructor necessary?",
        "createdAt" : "2019-01-28T03:57:07Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b6ae8550-e2cb-4781-b6c8-a86a923e41d3",
        "parentId" : "15cfe63e-6fc8-46e7-9ec5-f1a271cb1c48",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not really -- it's c&p from `RocksDBStore` that also has both. For both stores, actually only one constructor is used, so we could remove one constructor on both.",
        "createdAt" : "2019-01-29T01:56:32Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f81465bd-db64-4a5f-970f-514cb24b29c3",
        "parentId" : "15cfe63e-6fc8-46e7-9ec5-f1a271cb1c48",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : ":+1: It looks like the two-arg constructor is unused.",
        "createdAt" : "2019-01-29T16:49:52Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +51,55 @@    private static final Logger log = LoggerFactory.getLogger(RocksDBTimestampedStore.class);\n\n    RocksDBTimestampedStore(final String name) {\n        super(name);\n    }"
  },
  {
    "id" : "d887c9e4-5e55-4959-aa72-19fb0397ad1f",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-198218914",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: maybe we can make it just a general accessor that takes two parameters: `oldCF` and `newCF`? Or we can do this generalizing in the future if you'd like to hard-code for now.",
        "createdAt" : "2019-01-28T04:04:17Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e9cd5649-de33-4a85-9553-9487f54eaa25",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If we make one, how does it now that it need to upgrade stuff or not? Seems to imply a `null` check for each operation if both or only one CF should be accessed? That would imply runtime overhead. Also, I _think_ the code would be a little bit harder to read. Thoughts?",
        "createdAt" : "2019-01-29T02:01:45Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ab0774a3-83bd-4ba6-9f4b-8bb24bd84f7a",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We will create the `DualColumnFamilyAccessor` only when at the construction time if we found there are two CFs and the old CF is not empty right?",
        "createdAt" : "2019-01-29T07:25:34Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "107389c2-bf40-42e9-ae96-fda31127b643",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes.",
        "createdAt" : "2019-01-29T17:54:34Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "42cc7243-3f84-4fd5-9a18-5b91131f9cfe",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "So that means we do not need to do extra check inside this accessor impl right?",
        "createdAt" : "2019-01-29T19:17:28Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e78eca61-88aa-44de-b0de-86204b0950bf",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Personally, I like the existing design. The `DualColumnFamilyAccessor` has to do a lot of extra checking that isn't necessary if there's just one cf to deal with. If we collapse them into one class with a flag, we pay for it with a lot of branching.\r\n\r\nOne thing I did find confusing was reasoning about the fact that the Dual accessor is embedded in this (Timestamped) class, and the Single accessor is embedded in the parent (non-timestamped) class. But, we're using it as an accessor for this (the child) class. This seems unnecessarily convoluted, and it's a little hard to see if it's actually ok, or just coincidentally ok, since the parent and child APIs are only semantically, rather than actually, different.\r\n\r\nIt seems simpler to understand if we pull both accessors out into separate classes that take `db`, `name`, `options`, etc as constructor arguments, rather than closing over protected state.",
        "createdAt" : "2019-01-29T23:16:46Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "223c9b63-762f-425a-9620-e9509832c38d",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "+1 from me as well for putting both accessors into separate classes",
        "createdAt" : "2019-01-29T23:47:34Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "a8f0f7cf-704a-4ebd-a691-0557580fc082",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I looked at it closer. I still think it's better to split them out, but I also don't think it's a correctness issue right now, so I'd be fine with merging what you have.",
        "createdAt" : "2019-01-30T06:35:24Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "a44c68aa-ae7e-4c64-8921-c8c1d2c12b33",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Let's to some refactoring as follow ups. It's internal anyway. Would like to keep the PRs focused to get stuff in and merged :)",
        "createdAt" : "2019-01-30T09:22:56Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "315d11d0-a869-4e00-af5d-6eec22fead2a",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Actually I was only suggesting to make the current Dual accessor to be more general\r\ncurrently it assumes the `old` to be `default`, and `new` to be `withTimestamp`.\r\nwhat I was suggesting is only to make these two parameterized; so that in the future we only have two accessor impls:\r\n\r\n1) XX-CF only; which we already do in this PR.\r\n2) XX-to-YY upgrade: old XX CF to YY CF upgrade accessor.\r\n\r\nAll that being said, I'm okay with such refactoring as follow-ups.",
        "createdAt" : "2019-01-30T17:32:22Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e3626811-bf68-48ff-ab2f-a2d24624f442",
        "parentId" : "ebe780c4-475c-4a99-9b78-2f30bc6aa9fa",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This refactoring is already done: `DualAccessor` has a constructor with two CF parameters.\r\n\r\nThere is one missing piece: the conversion function is hard coded. After `TimestampedByteStore` PR is merged, I will refactor this to pass in a `RecordConverter` that and will pass in `TimestampedByteStore#convertValueToNewFormat()`",
        "createdAt" : "2019-01-30T17:52:25Z",
        "updatedAt" : "2019-01-30T17:52:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +96,100 @@\n\n    private class DualColumnFamilyAccessor implements RocksDBAccessor {\n        private final ColumnFamilyHandle oldColumnFamily;\n        private final ColumnFamilyHandle newColumnFamily;"
  },
  {
    "id" : "9aa7f344-3324-4054-af82-7db0976aaa90",
    "prId" : 6149,
    "prUrl" : "https://github.com/apache/kafka/pull/6149#pullrequestreview-198207270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "029724f0-cfdd-4aea-85e8-a3a0cf2783f6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Did @guozhangwang suggest to rename this DF to `2.2`? I actually think the descriptive name might be better. It seems like it'll be less work in the long run to remember what exactly is different about the different CFs.",
        "createdAt" : "2019-01-29T16:52:49Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "fc794508-706b-426d-bce3-46f98e3885a2",
        "parentId" : "029724f0-cfdd-4aea-85e8-a3a0cf2783f6",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "He did suggest but there was no final agreement. I personally don't care too much.",
        "createdAt" : "2019-01-29T23:41:13Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "67572563-6c56-479b-9010-7d8174b4c122",
        "parentId" : "029724f0-cfdd-4aea-85e8-a3a0cf2783f6",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "what about naming `keyValueWithTimestamp_2.2`?",
        "createdAt" : "2019-01-29T23:44:20Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "1ce86f7f-8374-4ba6-8e34-13a8e4132d0d",
        "parentId" : "029724f0-cfdd-4aea-85e8-a3a0cf2783f6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I don't feel strong about my suggestion either :) Will leave it to anyone who has a strong feeling here.",
        "createdAt" : "2019-01-30T17:27:24Z",
        "updatedAt" : "2019-01-30T17:46:21Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "88e573ccb6b6121f755461444c6ad90cf17d9d1d",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +60,64 @@        final List<ColumnFamilyDescriptor> columnFamilyDescriptors = asList(\n            new ColumnFamilyDescriptor(RocksDB.DEFAULT_COLUMN_FAMILY, columnFamilyOptions),\n            new ColumnFamilyDescriptor(\"keyValueWithTimestamp\".getBytes(StandardCharsets.UTF_8), columnFamilyOptions));\n        final List<ColumnFamilyHandle> columnFamilies = new ArrayList<>(columnFamilyDescriptors.size());\n"
  }
]