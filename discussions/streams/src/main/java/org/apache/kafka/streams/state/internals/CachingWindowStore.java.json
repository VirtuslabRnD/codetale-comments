[
  {
    "id" : "430cef6f-e930-4564-b199-7261bad7d1fb",
    "prId" : 4978,
    "prUrl" : "https://github.com/apache/kafka/pull/4978#pullrequestreview-118583867",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f220a584-fb6c-406e-b444-f385e83acbd7",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In `CachingSessionStore#findSessions`, we could also check if `cache` is null.",
        "createdAt" : "2018-05-09T00:50:40Z",
        "updatedAt" : "2018-05-09T02:30:06Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "2500d67b-9fd5-4b6d-803f-8ab78e6a80d9",
        "parentId" : "f220a584-fb6c-406e-b444-f385e83acbd7",
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Looking at CachingSessionStore#findSessions, an Iterator is returned.\r\n```\r\n        final ThreadCache.MemoryLRUCacheBytesIterator cacheIterator = cache.range(cacheName, cacheKeyFrom, cacheKeyTo);\r\n```\r\nWhen cache is null, should a special MemoryLRUCacheBytesIterator be returned ?",
        "createdAt" : "2018-05-09T01:26:54Z",
        "updatedAt" : "2018-05-09T02:30:06Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0cbc1844df5116da09115635312140053b6af15",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +161,165 @@        final Bytes bytesKey = WindowKeySchema.toStoreKeyBinary(key, timestamp, 0);\n        final Bytes cacheKey = cacheFunction.cacheKey(bytesKey);\n        if (cache == null) {\n            return underlying.fetch(key, timestamp);\n        }"
  },
  {
    "id" : "699ca746-ba50-47ef-80cf-55e8b7467867",
    "prId" : 6147,
    "prUrl" : "https://github.com/apache/kafka/pull/6147#pullrequestreview-192831329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0d108ca-6e60-4c83-b703-23e10438085a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "part of the fix: we now also forward the timestamp on eviction",
        "createdAt" : "2019-01-15T19:48:01Z",
        "updatedAt" : "2019-01-18T03:06:14Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "30b8447f5ca42f0be25ab3144de9a68b532e9924",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +115,119 @@                    serdes.valueFrom(entry.newValue()),\n                    oldValue,\n                    entry.entry().context().timestamp());\n            } finally {\n                context.setRecordContext(current);"
  },
  {
    "id" : "8b809c98-a0c1-4032-8272-2879c7b697ff",
    "prId" : 6191,
    "prUrl" : "https://github.com/apache/kafka/pull/6191#pullrequestreview-202426327",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ceba71aa-bb6a-4d5e-bf19-4e680e9b39df",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2019-02-12T01:06:03Z",
        "updatedAt" : "2019-02-13T06:01:27Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fef77ba1a948117f4218a8ae8b96a8cd924e8e7",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +105,109 @@                final Windowed<K> windowedKey = WindowKeySchema.fromStoreKey(windowedKeyBytes, serdes.keyDeserializer(), serdes.topic());\n                final V newValue = newValueBytes != null ? serdes.valueFrom(newValueBytes) : null;\n                final V oldValue = sendOldValues && oldValueBytes != null ? serdes.valueFrom(oldValueBytes) : null;\n                // we need to get the old values if needed, and then put to store, and then flush\n                underlying.put(key, entry.newValue(), windowStartTimestamp);"
  },
  {
    "id" : "015ef783-6ec8-4f25-932a-e7888153b7a6",
    "prId" : 6191,
    "prUrl" : "https://github.com/apache/kafka/pull/6191#pullrequestreview-202855030",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5df9b61-5ff8-4cca-be90-047baa6e0b2b",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "It seems that after setting `final Windowed<K> key` in the `putAndMaybeForward` method the code is more or less the same for all caching stores in question.\r\n\r\nJust a thought, but would it be worth extracting the logic from the two similar methods and placing them in a method of `WrappedStateStore.AbstractStateStore`",
        "createdAt" : "2019-02-12T17:04:18Z",
        "updatedAt" : "2019-02-13T06:01:27Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "ec6816fd-f6d8-4ffc-aef4-797b68754412",
        "parentId" : "c5df9b61-5ff8-4cca-be90-047baa6e0b2b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think AbstractStateStore is not a good place to share this logic, since it is not only for wrapping caching layers, but also for other layers as well.\r\n\r\nI feel good about keeping these three functions separated so far, mainly because their callees (fetches) are still different.",
        "createdAt" : "2019-02-12T19:12:00Z",
        "updatedAt" : "2019-02-13T06:01:27Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fef77ba1a948117f4218a8ae8b96a8cd924e8e7",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +104,108 @@            if (newValueBytes != null || oldValueBytes != null) {\n                final Windowed<K> windowedKey = WindowKeySchema.fromStoreKey(windowedKeyBytes, serdes.keyDeserializer(), serdes.topic());\n                final V newValue = newValueBytes != null ? serdes.valueFrom(newValueBytes) : null;\n                final V oldValue = sendOldValues && oldValueBytes != null ? serdes.valueFrom(oldValueBytes) : null;\n                // we need to get the old values if needed, and then put to store, and then flush"
  },
  {
    "id" : "cbd12b76-db88-4569-b923-cc1b538dbca0",
    "prId" : 6448,
    "prUrl" : "https://github.com/apache/kafka/pull/6448#pullrequestreview-224137266",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "059970e6-94ca-40ca-8d0a-463091736b75",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Are these two iterator wrapper's sharing the same logic?",
        "createdAt" : "2019-03-19T00:28:03Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "88352472-b4c2-4f32-adfc-9345473f3508",
        "parentId" : "059970e6-94ca-40ca-8d0a-463091736b75",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I believe they share enough logic that they *could* be consolidated, however I decided to leave them separate for now for a few reasons:\r\n1) Cleaner as inner classes since they need access to a number of the outer class's members\r\n2) Easier to reason about the logic for each in the context of the specific store, with variable names that reflect the appropriate situation\r\n3) There may be additional optimizations we want to consider, which may have differing logic\r\n\r\nNone of these are necessarily reasons to *never* consolidate them, just to defer that for now",
        "createdAt" : "2019-03-20T01:18:57Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "81cb3d35-1f80-4da9-b697-729246f808d6",
        "parentId" : "059970e6-94ca-40ca-8d0a-463091736b75",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Thanks, makes sense to me.",
        "createdAt" : "2019-04-08T23:45:25Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "dcdc8866e0ff0293f2b974bc65cdfb3fc6618138",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +288,292 @@    }\n\n    private class CacheIteratorWrapper implements PeekingKeyValueIterator<Bytes, LRUCacheEntry> {\n\n        private final long segmentInterval;"
  },
  {
    "id" : "6ca3b124-c701-4131-abea-ec750be7e67e",
    "prId" : 6448,
    "prUrl" : "https://github.com/apache/kafka/pull/6448#pullrequestreview-224687555",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a086a24c-cbc0-45d2-bc37-fb626c3bd9d8",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Similarly, can we set the begin time to `Math.max(timeFrom, currentSegmentId * segmentInterval)` directly?",
        "createdAt" : "2019-03-19T00:38:07Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "69db7377-5f09-4675-89cf-406c9b517f89",
        "parentId" : "a086a24c-cbc0-45d2-bc37-fb626c3bd9d8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "currentSegmentBeginTime() will always be greater than timeFrom when called (the call to setCacheKeyRange in the constructor uses timeFrom explicitly instead of currentSegmentBeginTime(), after that it will always be larger)",
        "createdAt" : "2019-03-20T01:49:23Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "c03fdb84-844e-478b-9f06-0102d1a648ab",
        "parentId" : "a086a24c-cbc0-45d2-bc37-fb626c3bd9d8",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack, makes sense.",
        "createdAt" : "2019-04-09T22:34:45Z",
        "updatedAt" : "2019-04-10T20:22:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "dcdc8866e0ff0293f2b974bc65cdfb3fc6618138",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +375,379 @@\n        private long currentSegmentBeginTime() {\n            return currentSegmentId * segmentInterval;\n        }\n"
  },
  {
    "id" : "c0809c38-0344-4376-a5ef-b7697da2058f",
    "prId" : 6521,
    "prUrl" : "https://github.com/apache/kafka/pull/6521#pullrequestreview-223002130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9958c641-871c-4ead-8c56-1756c6d26ec0",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ditto here and below",
        "createdAt" : "2019-04-04T21:05:51Z",
        "updatedAt" : "2019-04-08T23:54:35Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "892b1e9a0dae3447bc55330e943717847504377c",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +205,209 @@                + \"This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. \" +\n                \"Note that the built-in numerical serdes do not follow this for negative numbers\");\n            return KeyValueIterators.emptyIterator();\n        }\n"
  },
  {
    "id" : "30f148f9-26a5-4354-a478-67d4bf7d85f2",
    "prId" : 9138,
    "prUrl" : "https://github.com/apache/kafka/pull/9138#pullrequestreview-472838491",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c005a0b0-4008-434a-bacb-3003a4d00e61",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Just noticed that we use `==` instead of `.equals` down on line 437, can you fix that on the side?",
        "createdAt" : "2020-08-21T22:04:58Z",
        "updatedAt" : "2020-09-02T15:24:52Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "273f612bfe98c58c40e77ec8a2d77e5eabdd2f18",
    "line" : 357,
    "diffHunk" : "@@ -1,1 +574,578 @@        }\n\n        private void setCacheKeyRange(final long lowerRangeEndTime, final long upperRangeEndTime) {\n            if (cacheFunction.segmentId(lowerRangeEndTime) != cacheFunction.segmentId(upperRangeEndTime)) {\n                throw new IllegalStateException(\"Error iterating over segments: segment interval has changed\");"
  },
  {
    "id" : "4d2317e2-5b92-4f04-a503-6c79a34db26c",
    "prId" : 9138,
    "prUrl" : "https://github.com/apache/kafka/pull/9138#pullrequestreview-479093838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5e0e3a1-8ff0-470d-b3ac-6d8c0f2627d2",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "See my other comments: I think we do not need to add overloads for primitive types for the newly added APIs?",
        "createdAt" : "2020-08-31T23:27:40Z",
        "updatedAt" : "2020-09-02T15:24:52Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "906247e8-bf81-4594-a613-e991b8d2c788",
        "parentId" : "e5e0e3a1-8ff0-470d-b3ac-6d8c0f2627d2",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "We would still need to keep this method: we're not removing all long-based APIs, just the public/IQ methods in ReadOnlyWindowStore. But we still want to keep the long-based methods on WindowStore and all the internal store interfaces for performance reasons.\r\nMaybe once we move everything to use `Instant` all the way down to the serialization then we can remove these long-based methods. I guess we should consider that when discussing KIP-667, but for the time being at least, we should keep them for internal use",
        "createdAt" : "2020-08-31T23:55:57Z",
        "updatedAt" : "2020-09-02T15:24:52Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "273f612bfe98c58c40e77ec8a2d77e5eabdd2f18",
    "line" : 186,
    "diffHunk" : "@@ -1,1 +356,360 @@\n    @Override\n    public KeyValueIterator<Windowed<Bytes>, byte[]> backwardFetchAll(final long timeFrom,\n                                                                      final long timeTo) {\n        validateStoreOpen();"
  },
  {
    "id" : "ff3991b7-c2ef-48d8-a275-65894eba7d4c",
    "prId" : 9138,
    "prUrl" : "https://github.com/apache/kafka/pull/9138#pullrequestreview-481344393",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bbad442-57aa-4eed-8a70-7ca8ae453f64",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why this call is different based on the `forward` boolean? It's not clear to me. cc @ableegoldman @lct45 could you double check?",
        "createdAt" : "2020-08-31T23:31:42Z",
        "updatedAt" : "2020-09-02T15:24:52Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "dc9fc77b-5766-48a2-994a-aacd7f38baf3",
        "parentId" : "5bbad442-57aa-4eed-8a70-7ca8ae453f64",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This looks right to me -- in the iterator constructor, we would normally start from `timeFrom` (the minimum time) and advance to the end of the current segment (that's what the \"cache key range\" defines, the range of the current segment) When iterating backwards, the current segment is actually the largest segment, so the cache key lower range is the current (largest) segment's beginning timestamp, and the upper range is the maximum timestamp of the backwards fetch. Does that make sense?",
        "createdAt" : "2020-09-01T00:00:27Z",
        "updatedAt" : "2020-09-02T15:24:52Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "710c4cc7-0dcc-4733-b8a1-e4c9e4c9f085",
        "parentId" : "5bbad442-57aa-4eed-8a70-7ca8ae453f64",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "SG",
        "createdAt" : "2020-09-02T22:16:06Z",
        "updatedAt" : "2020-09-02T22:16:07Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "273f612bfe98c58c40e77ec8a2d77e5eabdd2f18",
    "line" : 306,
    "diffHunk" : "@@ -1,1 +480,484 @@                this.lastSegmentId = cacheFunction.segmentId(timeFrom);\n\n                setCacheKeyRange(currentSegmentBeginTime(), Math.min(timeTo, maxObservedTimestamp.get()));\n                this.current = context.cache().reverseRange(cacheName, cacheKeyFrom, cacheKeyTo);\n            }"
  }
]