[
  {
    "id" : "f347b6d7-9c38-411d-a955-9be69350e3a9",
    "prId" : 10331,
    "prUrl" : "https://github.com/apache/kafka/pull/10331#pullrequestreview-629447958",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "df35ed86-bf24-41e3-9c70-478900b26c9e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We know these functions are triggered by `fetch(final Bytes key, final long timeFrom, final long timeTo)` and following the default implementation it is sub-optimal since we will range over a large scan and then drop a lot of the records. Let's add a oneliner comment on top of them referring readers to the head javadoc of this schema class that they should try avoid ever calling these functions.",
        "createdAt" : "2021-04-06T22:24:43Z",
        "updatedAt" : "2021-04-07T18:50:34Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "708f08083e0ca568d9395e50b49d5883fc6e8fa2",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +73,77 @@     */\n    @Override\n    public Bytes upperRangeFixedSize(final Bytes key, final long to) {\n        return toStoreKeyBinary(key, to, Integer.MAX_VALUE);\n    }"
  },
  {
    "id" : "62b361b2-9f48-4b52-a7a4-520a1673a797",
    "prId" : 10331,
    "prUrl" : "https://github.com/apache/kafka/pull/10331#pullrequestreview-629447958",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7501a3d9-d2cc-4b8f-9c7e-0f7ba968d341",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true.\r\n\r\nI think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this:\r\n\r\n```\r\nreturn keySchema instanceOf TimeOrderedKeySchema ?\r\n            return new SegmentIterator<>(\r\n            searchSpace.iterator(),\r\n            (....) -> true,\r\n            TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0),\r\n            TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE),\r\n            true) : // else return the normal implementation\r\n```",
        "createdAt" : "2021-04-06T22:29:11Z",
        "updatedAt" : "2021-04-07T18:50:34Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "708f08083e0ca568d9395e50b49d5883fc6e8fa2",
    "line" : 103,
    "diffHunk" : "@@ -1,1 +101,105 @@     */\n    @Override\n    public HasNextCondition hasNextCondition(final Bytes binaryKeyFrom, final Bytes binaryKeyTo, final long from, final long to) {\n        return iterator -> {\n            while (iterator.hasNext()) {"
  }
]