[
  {
    "id" : "2f20e053-0731-4d39-94f3-9037b4d7b90d",
    "prId" : 6080,
    "prUrl" : "https://github.com/apache/kafka/pull/6080#pullrequestreview-194373514",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4012a8ae-20af-47a2-8949-8b2f6d927062",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I was originally thinking about getting the list of all metrics from kafkaStreams.metrics() which contains producer, consumer, admin and streams' own metrics (thread, task, processor node, store, cache), and check that they all exist with the exact number of metrics (with the PR for KIP-414 is in it should be easy to get the corresponding client id for different modules).\r\n\r\nBut after reading @vvcephei 's comment I think I'm convinced that we can save on getting non-streams embedded client's metrics later, and also the actual metrics name validation may better not in Streams metrics test, so we'd probably only check that the corresponding groups with clientIds existed rather than checking each metric exists. So I'm fine with the current scope of this PR.",
        "createdAt" : "2019-03-06T16:56:01Z",
        "updatedAt" : "2019-03-21T09:38:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "bde6ef0dca284b4118d278113cfb39efbebc60ed",
    "line" : 248,
    "diffHunk" : "@@ -1,1 +246,250 @@\n    @Test\n    public void testStreamMetricOfWindowStore() throws Exception {\n        final StringBuilder errorMessage = new StringBuilder();\n        stream2 = builder.stream(STREAM_INPUT, Consumed.with(Serdes.Integer(), Serdes.String()));"
  },
  {
    "id" : "58131ffc-1669-44c4-a2df-277f90155d2c",
    "prId" : 6080,
    "prUrl" : "https://github.com/apache/kafka/pull/6080#pullrequestreview-217130510",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5664cd1f-9caf-428a-bc30-5223a1cb4c5e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Do I read this correctly: it's verifying that we have 0 metrics registered for `PUT_IF_ABSENT_LATENCY_AVG`?",
        "createdAt" : "2019-03-19T20:23:32Z",
        "updatedAt" : "2019-03-21T09:38:15Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "37c16574-3c0c-4f3a-a6e5-26bbc94a7cdc",
        "parentId" : "5664cd1f-9caf-428a-bc30-5223a1cb4c5e",
        "authorId" : "657484ed-fccd-4b06-86ba-5b7842d474d1",
        "body" : "That's what i found after starting the app. I don't know the required \"given\" to got this type of metrics :)",
        "createdAt" : "2019-03-20T14:08:48Z",
        "updatedAt" : "2019-03-21T09:38:15Z",
        "lastEditedBy" : "657484ed-fccd-4b06-86ba-5b7842d474d1",
        "tags" : [
        ]
      },
      {
        "id" : "39e9e55a-87eb-42e9-b48c-55f3277635af",
        "parentId" : "5664cd1f-9caf-428a-bc30-5223a1cb4c5e",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "For window / session stores, there's no putIfAbsent function and hence no metrics would be registered.",
        "createdAt" : "2019-03-20T22:15:27Z",
        "updatedAt" : "2019-03-21T09:38:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a3721415-cc22-4ec3-ba6d-64148eae888d",
        "parentId" : "5664cd1f-9caf-428a-bc30-5223a1cb4c5e",
        "authorId" : "657484ed-fccd-4b06-86ba-5b7842d474d1",
        "body" : "i remove it or let the test on 0 ?",
        "createdAt" : "2019-03-21T09:14:11Z",
        "updatedAt" : "2019-03-21T09:38:15Z",
        "lastEditedBy" : "657484ed-fccd-4b06-86ba-5b7842d474d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "bde6ef0dca284b4118d278113cfb39efbebc60ed",
    "line" : 375,
    "diffHunk" : "@@ -1,1 +373,377 @@            testMetricByName(listMetricStore, PUT_LATENCY_AVG, 2);\n            testMetricByName(listMetricStore, PUT_LATENCY_MAX, 2);\n            testMetricByName(listMetricStore, PUT_IF_ABSENT_LATENCY_AVG, 0);\n            testMetricByName(listMetricStore, PUT_IF_ABSENT_LATENCY_MAX, 0);\n            testMetricByName(listMetricStore, GET_LATENCY_AVG, 0);"
  }
]