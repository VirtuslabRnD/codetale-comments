[
  {
    "id" : "f3ba201a-3411-406d-b5b0-750957720857",
    "prId" : 5398,
    "prUrl" : "https://github.com/apache/kafka/pull/5398#pullrequestreview-142989920",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4883038e-df56-44be-9d62-8a328686be37",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We do reset the `wait-counter` to 5 when we add records on purpose?",
        "createdAt" : "2018-08-02T21:38:45Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8bf38f69-57be-4f47-a622-1af4faa3d061",
        "parentId" : "4883038e-df56-44be-9d62-8a328686be37",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Yes, we want to only force process once every these times.",
        "createdAt" : "2018-08-02T21:48:21Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c57cec79fa53032b55dd7a5f374c9ee62c25098",
    "line" : 259,
    "diffHunk" : "@@ -1,1 +481,485 @@        final byte[] bytes = ByteBuffer.allocate(4).putInt(1).array();\n\n        task.addRecords(partition1, Collections.singleton(new ConsumerRecord<>(topic1, 1, 0, bytes, bytes)));\n\n        assertFalse(task.isProcessable());"
  },
  {
    "id" : "1e2fff95-04e0-4a16-94d6-9ea860a8578c",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149490195",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b61bc69-eb2f-4b63-8d12-3cfd5e06b9ea",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "What do you mean by \"respect\" -- don't understand the test name",
        "createdAt" : "2018-08-25T00:48:36Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +453,457 @@\n    @Test\n    public void shouldRespectCommitNeeded() {\n        task = createStatelessTask(createConfig(false));\n        task.initializeStateStores();"
  },
  {
    "id" : "bfc7c0f3-2a03-4d8a-a2db-f537467aee01",
    "prId" : 5428,
    "prUrl" : "https://github.com/apache/kafka/pull/5428#pullrequestreview-149933075",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c55b63e-c721-4282-b88f-bf6858757754",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If commit interval is 100ms, we might want to test the edge case 100 and 101 -- the test does not cover that we would force processing at 70L already.",
        "createdAt" : "2018-08-25T00:54:07Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5068c70d-ace4-44c9-9585-2e62360fc7db",
        "parentId" : "3c55b63e-c721-4282-b88f-bf6858757754",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Note we are testing for max idle time as `now - lastEnforcedProcessingTime > maxTaskIdleMs` so 101 is necessary, ditto for below `202`.",
        "createdAt" : "2018-08-28T00:49:15Z",
        "updatedAt" : "2018-09-11T21:32:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "71b2b16d0b0f37a05af3df60ae9b5ff88649a7a4",
    "line" : 159,
    "diffHunk" : "@@ -1,1 +527,531 @@        assertFalse(task.isProcessable(time.milliseconds()));\n\n        assertFalse(task.isProcessable(time.milliseconds() + 50L));\n\n        assertTrue(task.isProcessable(time.milliseconds() + 100L));"
  },
  {
    "id" : "6f2122dd-ecfa-499a-a012-350e241bad7d",
    "prId" : 5714,
    "prUrl" : "https://github.com/apache/kafka/pull/5714#pullrequestreview-160056645",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d25f6c1-57ec-40cf-b68d-cabb6b015b71",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is a tiny piggy-back: I realized that we are always using 0 as the timestamp which does not make sense in the buffer queue related questions, while the offset is being modified. So I changed the timestamp to be the same as the offset as well here.",
        "createdAt" : "2018-09-29T00:21:00Z",
        "updatedAt" : "2018-09-29T00:21:01Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "238139781ae1c15bf6245a87f488b5d406155029",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1393,1397 @@            topicPartition.partition(),\n            offset,\n            offset, // use the offset as the timestamp\n            TimestampType.CREATE_TIME,\n            0L,"
  },
  {
    "id" : "7e80dfdb-0d76-4fc3-a7be-566b745c79fc",
    "prId" : 6636,
    "prUrl" : "https://github.com/apache/kafka/pull/6636#pullrequestreview-230810105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98c9225f-63aa-4e32-955d-eb713bc4d0b3",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "This is a minor cleanup that I piggybacked on this PR.",
        "createdAt" : "2019-04-25T18:21:04Z",
        "updatedAt" : "2019-04-25T18:25:03Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e0e7bc13104cf0308cec2351ec766a1d6a44826",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1160,1164 @@        task = createStatelessTask(createConfig(true));\n\n        assertFalse(producer.transactionInFlight());\n        task.close(false, false);\n    }"
  },
  {
    "id" : "e79d75c3-0b6f-4736-b4ae-58bb34acc7f8",
    "prId" : 6636,
    "prUrl" : "https://github.com/apache/kafka/pull/6636#pullrequestreview-230810105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e048a350-1a31-4f2f-98b2-0c4f5fa9defd",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "closing a task `clean=false` and `isZombie=true`",
        "createdAt" : "2019-04-25T18:23:02Z",
        "updatedAt" : "2019-04-25T18:25:03Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e0e7bc13104cf0308cec2351ec766a1d6a44826",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1098,1102 @@        producer.fenceProducer();\n\n        task.close(false, true);\n        task = null;\n"
  },
  {
    "id" : "bfbbf18f-3964-444a-b76f-3b327eaa4248",
    "prId" : 6636,
    "prUrl" : "https://github.com/apache/kafka/pull/6636#pullrequestreview-230810105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad4f8b58-a4c4-4f8f-9752-14e98c901cc2",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "closing a task `clean=false` `isZombie=true`",
        "createdAt" : "2019-04-25T18:24:13Z",
        "updatedAt" : "2019-04-25T18:25:03Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e0e7bc13104cf0308cec2351ec766a1d6a44826",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +1331,1335 @@        task = createStatelessTask(createConfig(true));\n        task.initializeTopology();\n        task.close(false, true);\n        task = null;\n"
  },
  {
    "id" : "b60c31d1-bd94-4045-a060-7e2dbd3cb3f1",
    "prId" : 6694,
    "prUrl" : "https://github.com/apache/kafka/pull/6694#pullrequestreview-274849969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c99c4884-d2f7-4ebd-8984-6520cbbb0633",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add more test method for the different error cases, too.",
        "createdAt" : "2019-08-09T18:08:18Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "681faba1-35b5-42be-9050-4f696d019839",
        "parentId" : "c99c4884-d2f7-4ebd-8984-6520cbbb0633",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "I see that you tested the different error cases as @mjsax suggested. However, I would put each test in its own test method.  ",
        "createdAt" : "2019-08-15T08:55:49Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42a883a14bc3a48a28624e3964be81e4f75d8f5",
    "line" : 103,
    "diffHunk" : "@@ -1,1 +724,728 @@\n        assertEquals(RecordQueue.UNKNOWN, task.decodeTimestamp(\"\"));\n    }\n\n    @Test"
  },
  {
    "id" : "2e394d16-a211-4ef3-9b49-b953195b0e6b",
    "prId" : 7030,
    "prUrl" : "https://github.com/apache/kafka/pull/7030#pullrequestreview-257624022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2d483ee-cb2f-481a-bd53-83720305018e",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "We're no longer overlooking the fact that this store wasn't \"logged\" when we write the checkpoints.",
        "createdAt" : "2019-07-03T17:23:29Z",
        "updatedAt" : "2019-07-09T23:16:30Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b33b85c4fa71ed08802599697404720a66d88ef",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1478,1482 @@\n    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged) {\n        final StateStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with("
  }
]