[
  {
    "id" : "7a13d577-3ee0-4b1b-a02b-333cceb9cbd4",
    "prId" : 4491,
    "prUrl" : "https://github.com/apache/kafka/pull/4491#pullrequestreview-96354621",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2fe526a-397b-4215-88d8-581a4ab07557",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This change is intentional: `getProperty` will always return null for non-string typed value, changed to `get` would return the correct int value for printing.",
        "createdAt" : "2018-02-14T00:46:04Z",
        "updatedAt" : "2018-02-14T00:46:04Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a66a86136a04896102819d5c5e6da66a44ba46a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +105,109 @@        for (int i = 0; i < brokers.length; i++) {\n            brokerConfig.put(KafkaConfig$.MODULE$.BrokerIdProp(), i);\n            log.debug(\"Starting a Kafka instance on port {} ...\", brokerConfig.get(KafkaConfig$.MODULE$.PortProp()));\n            brokers[i] = new KafkaEmbedded(brokerConfig, time);\n"
  },
  {
    "id" : "c6e5debe-2d2b-4ca9-aa31-dc852ff412f8",
    "prId" : 5418,
    "prUrl" : "https://github.com/apache/kafka/pull/5418#pullrequestreview-139705683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d2f89cf-9ed5-4a52-8107-6ee3822df519",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Should the exception be logged ?",
        "createdAt" : "2018-07-24T01:12:53Z",
        "updatedAt" : "2018-07-24T01:14:13Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1db38f66f02a63fc756050ffa2a8c8ac2212d94",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +285,289 @@            try {\n                brokers[0].deleteTopic(topic);\n            } catch (final UnknownTopicOrPartitionException e) { }\n        }\n"
  },
  {
    "id" : "c2b69233-6ce2-47e4-904a-c823e6b3b18a",
    "prId" : 5418,
    "prUrl" : "https://github.com/apache/kafka/pull/5418#pullrequestreview-139705683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46d887a8-939e-440d-9170-a9d09b331907",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "Should timeout be re-calculated considering the for loop above ?",
        "createdAt" : "2018-07-24T01:13:47Z",
        "updatedAt" : "2018-07-24T01:14:13Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      }
    ],
    "commit" : "b1db38f66f02a63fc756050ffa2a8c8ac2212d94",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +288,292 @@        }\n\n        if (timeoutMs > 0) {\n            TestUtils.waitForCondition(new TopicsDeletedCondition(topics), timeoutMs, \"Topics not deleted after \" + timeoutMs + \" milli seconds.\");\n        }"
  },
  {
    "id" : "71d02171-784c-429e-9245-e8fe6a552a86",
    "prId" : 8366,
    "prUrl" : "https://github.com/apache/kafka/pull/8366#pullrequestreview-382478598",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "994fc0e2-36ff-48f5-8737-404c60f26b41",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I thought this could throw, too?",
        "createdAt" : "2020-03-26T22:35:39Z",
        "updatedAt" : "2020-03-26T22:35:39Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b77b3d8b-1aa2-4c80-a4cb-5efa6505655b",
        "parentId" : "994fc0e2-36ff-48f5-8737-404c60f26b41",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I guess it could, but it's just directly reading the topics from zookeeper (of which there's only one node in the cluster). If that fails, it seems like everything else would also fail, so it's probably pointless to even bother closing the brokers. Similarly, calling `shutdown` on the first broker could also throw, but we don't bother catching there to continue closing the rest of the cluster.",
        "createdAt" : "2020-03-26T22:54:56Z",
        "updatedAt" : "2020-03-26T22:55:25Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "82d4e127-2fc2-4d99-b372-70aa8227cc2d",
        "parentId" : "994fc0e2-36ff-48f5-8737-404c60f26b41",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ok. Works for me.",
        "createdAt" : "2020-03-26T23:01:17Z",
        "updatedAt" : "2020-03-26T23:01:17Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "002e80db429cda99e23be5116391395adfe7e649",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +123,127 @@        if (brokers.length > 1) {\n            // delete the topics first to avoid cascading leader elections while shutting down the brokers\n            final Set<String> topics = getAllTopicsInCluster();\n            if (!topics.isEmpty()) {\n                try (final Admin adminClient = brokers[0].createAdminClient()) {"
  }
]