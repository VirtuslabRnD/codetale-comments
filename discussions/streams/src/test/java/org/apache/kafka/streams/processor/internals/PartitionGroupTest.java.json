[
  {
    "id" : "5f41c760-914a-4b1a-b988-e5970325e288",
    "prId" : 5382,
    "prUrl" : "https://github.com/apache/kafka/pull/5382#pullrequestreview-138480368",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3304e72-8c05-4969-aa75-1e9bb56dc65c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Should we add a comment about `stream time`  to align with the test code from above?",
        "createdAt" : "2018-07-18T21:36:14Z",
        "updatedAt" : "2018-07-18T23:58:09Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ff1d83b9-33ec-4820-b04b-3fc00b7dedfa",
        "parentId" : "b3304e72-8c05-4969-aa75-1e9bb56dc65c",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "ack.",
        "createdAt" : "2018-07-18T23:43:00Z",
        "updatedAt" : "2018-07-18T23:58:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b470e6ef4d2f0971548ddf865a635cb5e6a551f",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +152,156 @@        record = group.nextRecord(info);\n        // 1:[5, 2, 4]\n        // 2:[6]\n        // st: 5 as partition st is now {5, 6}\n        assertEquals(partition2, info.partition());"
  },
  {
    "id" : "dc3b6e7b-cf80-4b86-9500-f2557d00724f",
    "prId" : 5382,
    "prUrl" : "https://github.com/apache/kafka/pull/5382#pullrequestreview-138480554",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8ecd3e0-9ef8-4c48-9473-6ec003aad357",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just a question: Why is this not `6L` ? (it should be `5L` after you applied the fix you want to do in a follow up PR).",
        "createdAt" : "2018-07-18T21:38:23Z",
        "updatedAt" : "2018-07-18T23:58:09Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2c3dfeb8-b505-41da-be39-8e9e4b5b2a5c",
        "parentId" : "e8ecd3e0-9ef8-4c48-9473-6ec003aad357",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "When we pop out 5, the stream time of partition1 is still 5 since the next record's ts is 2, and hence st stays as min(5, 6) = 5.",
        "createdAt" : "2018-07-18T23:44:11Z",
        "updatedAt" : "2018-07-18T23:58:09Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b470e6ef4d2f0971548ddf865a635cb5e6a551f",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +171,175 @@        assertEquals(2, group.numBuffered(partition1));\n        assertEquals(1, group.numBuffered(partition2));\n        assertEquals(5L, group.timestamp());\n\n        // get one more record, time should not be advanced"
  },
  {
    "id" : "d792c312-9078-44c8-8489-33c9110cf6b3",
    "prId" : 5398,
    "prUrl" : "https://github.com/apache/kafka/pull/5398#pullrequestreview-142831633",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Interesting. So the stream time is `max(oldStreamTime, currentRecordTime)`, while we pick the current record as the `record with min timestamp among queue heads`.\r\n\r\nThis is actually different than the prior stream time definition, which would be computed from the queues regardless of the current record's timestamp.\r\n\r\nI like the new definition better, as the observer can determine after the fact what the stream time was at any point knowing only the records that got processed (not needing to know what was queued). It also means you know stream time can only advance when you get the next record, not when you add new records.\r\n\r\n\r\n---\r\n\r\nActually upon re-reading, enqueuing can change the stream time only when the group transitions from missing data from a partition to having data for all partitions. Is it actually necessary for stream time to update in such a scenario? Can we simplify both the definition and implementation by sticking with the definition I wrote down?\r\n\r\nIf not, maybe we should update this scenario to demonstrate that transition.",
        "createdAt" : "2018-07-31T22:09:08Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "cf53f523-1a88-4a46-b841-45738665df6c",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Can you also update or remove the explanatory comments? (Update if the behavior might be confusing still, remove if it's obvious under these much simpler semantics)",
        "createdAt" : "2018-07-31T22:10:16Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "29ac031a-ad72-431b-9326-f95c10bce3ac",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Sure, I will update the comments in PartitionGroup.\r\n\r\nAbout whether we should still update stream time when filling in records to an empty partition, my gut feeling is yes. Consider the following example of two partitions in a task:\r\n\r\nP1 (0): [0,1,2,3,4]\r\nP2 (100): [100,101,102,103,104]\r\n\r\nAgain the digits above are record timestamps. When processing this task we will pop out records from P1 until it is empty. When a partition becomes empty, its stream time stays as the timestmap of the last popped record, hence P1's st (stream time) stays as 4, and hence the task st stays as 4.\r\n\r\nP1 (4): []\r\nP2 (100): [100,101,102,103,104]\r\n\r\nNow consider we polled more records into P:\r\n\r\nP1 (5): [5,6,7,8]\r\nP2 (100): [100,101,102,103,104]\r\n\r\nP1's st will be updated immediately as 5. If we do not update immediately, the task st is still 4, and only when record with timestamp 5 has been popped and processed, the task st will be \"jumpping\" from 4 to 6.\r\n\r\nOf course, one can argue to favor \"let the st jump in this case\" over \"let the st increase after adding new data, and hence users may observe st being increased without processing even a record yet\". Personally I'm in favor of the latter, but I'm open to be convinced :)",
        "createdAt" : "2018-08-01T18:51:17Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c6bdc39c-530f-4d53-9fb2-b949a55da26f",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Another note: the above example is that we do not yet enforce processing before new records are enqueued to P1, otherwise it will look like\r\n\r\nP1 (4): []\r\nP2 (104): []\r\n\r\nI.e. users processing records with ts 100+ while the stream time stays at 4. This is intentional in my design (users would be aware that some enforced processing is happening as st did not increment) but I'm also open for questions / arguments against it.",
        "createdAt" : "2018-08-01T18:54:55Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "aa952bc0-4115-490c-bf97-8b29512f770a",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "It seems like it would be sensible either way.\r\n\r\nI think the distinction really comes down to situations in which you observe the stream time *without* processing a record. I think that we only look at the stream time while we are processing a record, so there's actually no need to update the stream time during enqueue.\r\n\r\nActually, I didn't completely follow the \"jumping\" behavior in your example.\r\n\r\nStarting from \r\nP1 (4): []\r\nP2 (100): [100,101,102,103,104]\r\nST:4\r\n\r\nwe poll more records into P1:\r\nP1 (5): [5,6,7,8]\r\nP2 (100): [100,101,102,103,104]\r\nST:4\r\n\r\nThen when we grab a record (5) to process, ST would advance to 5, no?\r\n\r\nP1 (6): [6,7,8]\r\nP2 (100): [100,101,102,103,104]\r\nST:5\r\n\r\nIn other words, a processor would observe:\r\nrecord time = 0; stream time = 0\r\nrecord time = 1; stream time = 1\r\nrecord time = 2; stream time = 2\r\nrecord time = 3; stream time = 3\r\nrecord time = 4; stream time = 4\r\n(processing pauses for a while while we wait for more records on P1)\r\nrecord time = 5; stream time = 5\r\n... 6, 7, ...\r\nrecord time = 8; stream time = 8\r\n(processing pauses for a while, until we give up on P1)\r\nrecord time = 100; stream time = 8\r\nrecord time = 101; stream time = 8\r\n... etc (stream time doesn't advance any more until we see another record on P1)\r\n\r\nI believe this sequence of observations is the same whether you advance stream time during enqueue or not.",
        "createdAt" : "2018-08-01T22:42:09Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "d1a1f15b-7115-46b9-b7b0-d975d373c665",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "You are right, I was confused before with the case\r\n\r\nP1 (6): [6,7,8]\r\nP2 (100): [100,101,102,103,104]\r\nProcessing 5, ST:5\r\n\r\nAnd thought it was\r\n\r\nP1 (6): [6,7,8]\r\nP2 (100): [100,101,102,103,104]\r\nProcessing 5, ST:6\r\n\r\nSince the P1's ts is already 6. But we are not setting task st as the min of all partition's ts anymore, but only the the popped record's ts if it is larger. \r\n\r\nGoing back to your original comment, today we may still look at the task st before even processing a record after enqueuing records, think: ST based punctuation. But since we only consider updating ST if `allBuffered = true;` anyways, it means we will definitely tries to process some data right away within in iteration, so it is indeed not necessary to update the ST here.",
        "createdAt" : "2018-08-02T00:13:03Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "45ece710-149a-4ae4-bb2f-e697facd7a48",
        "parentId" : "1583e579-3a57-4e9f-9be4-13aa5633d6e6",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Got it. Thanks for the clarification!",
        "createdAt" : "2018-08-02T14:51:35Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c57cec79fa53032b55dd7a5f374c9ee62c25098",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +109,113 @@        assertEquals(2, group.numBuffered(partition1));\n        assertEquals(3, group.numBuffered(partition2));\n        assertEquals(1L, group.timestamp());\n\n        // get one record, now the time should be advanced"
  },
  {
    "id" : "dd7c7916-45e1-4772-a548-b49ed5433a3f",
    "prId" : 5398,
    "prUrl" : "https://github.com/apache/kafka/pull/5398#pullrequestreview-142515432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aec4fde5-c749-4bf3-8f8a-8c58465f8b97",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I'm not opposed to leaving the whole scenario in place, but fwiw it could be simpler now, since enqueuing no longer updates the stream time.",
        "createdAt" : "2018-07-31T22:12:19Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "040b1e9d-7267-4670-ab78-a7714e86f86f",
        "parentId" : "aec4fde5-c749-4bf3-8f8a-8c58465f8b97",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Enqueuing may still update the st right now (see my comment above).",
        "createdAt" : "2018-08-01T18:51:48Z",
        "updatedAt" : "2018-08-02T22:06:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8c57cec79fa53032b55dd7a5f374c9ee62c25098",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +207,211 @@        assertEquals(0, group.numBuffered(partition1));\n        assertEquals(0, group.numBuffered(partition2));\n        assertEquals(6L, group.timestamp());\n\n    }"
  },
  {
    "id" : "aab0fa74-09f4-4f97-9d6e-672c79b39af5",
    "prId" : 6694,
    "prUrl" : "https://github.com/apache/kafka/pull/6694#pullrequestreview-274849969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5dc4cd80-f43b-4efa-8674-3bec0ab1d983",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "This tests misses to verify whether `streamTime` is set or not.\r\n\r\nFurthermore, I would write two (or three) distinct tests:\r\n- `partitionTimestamp` is set (could be further split for `streamTime` is set or not)\r\n- `NullPointerException` is thrown ",
        "createdAt" : "2019-08-15T09:33:50Z",
        "updatedAt" : "2019-09-16T23:28:41Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42a883a14bc3a48a28624e3964be81e4f75d8f5",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +310,314 @@            group.setPartitionTime(randomPartition, 0L);\n        });\n    }\n\n    @Test"
  }
]