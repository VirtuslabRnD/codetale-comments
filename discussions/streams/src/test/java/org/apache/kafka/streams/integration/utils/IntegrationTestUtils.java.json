[
  {
    "id" : "3561611b-ff97-4a33-ada9-1459b6a9038f",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c128f860-f7e7-47d2-8666-60e6d7c189b7",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:41:39Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +311,315 @@        final List<KeyValue<K, V>> accumData = new ArrayList<>();\n        try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n            final TestCondition valuesRead = () -> {\n                final List<KeyValue<K, V>> readData =\n                    readKeyValues(topic, consumer, waitTime, expectedNumRecords);"
  },
  {
    "id" : "15b856f9-7a48-493b-90f4-ba38458f8bb3",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f6f4ca7-0a57-4680-8385-dc11f943324d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:41:52Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +392,396 @@        final List<V> accumData = new ArrayList<>();\n        try (final Consumer<Object, V> consumer = createConsumer(consumerConfig)) {\n            final TestCondition valuesRead = () -> {\n                final List<V> readData =\n                    readValues(topic, consumer, waitTime, expectedNumRecords);"
  },
  {
    "id" : "7376d343-22a2-440d-907f-01559624fec9",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20526b5a-5046-4aea-8bc1-89d77c4b8d47",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:41:55Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +421,425 @@                                                     final int partition,\n                                                     final long timeout) throws InterruptedException {\n        TestUtils.waitForCondition(() -> {\n            for (final KafkaServer server : servers) {\n                final MetadataCache metadataCache = server.apis().metadataCache();"
  },
  {
    "id" : "74d4960b-61d3-4962-af24-c4af4666f8e3",
    "prId" : 5724,
    "prUrl" : "https://github.com/apache/kafka/pull/5724#pullrequestreview-160966118",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8eaf5b47-6d5b-4ebb-b2c3-f09a52c4553d",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "this verification block duplicates code in `OutputVerifier`, refactoring to some common verification method is out of scope for this PR, but I wanted to get my thoughts out on this as it seems some of our testing code can be consolidated some.\r\n\r\n\\cc @guozhangwang @mjsax ",
        "createdAt" : "2018-10-02T19:08:56Z",
        "updatedAt" : "2018-10-03T00:05:51Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "a20c8b6e-183c-4307-b3ba-66732292dd72",
        "parentId" : "8eaf5b47-6d5b-4ebb-b2c3-f09a52c4553d",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I hear you, but in this case, I would resist consolidation.\r\n\r\nOutputVerifier is a public test utility for use with the TopologyTestDriver. Its behavior needs to be stable over time.\r\n\r\nIntegrationTestUtils is a private utility for use in our integration tests (i.e., not TopologyTestDriver). We should maintain the flexibility to change these utilities completely at will.\r\n\r\nSo it seems they have little in common except that they need to print a message when an assertion is false during testing. The message is for human consumption, so its format doesn't need to be any particular way, just as long as it's clear and informative.\r\n\r\nIMHO, these two components are far apart in usage and modular structure, and there doesn't seem to be a compelling benefit from coupling them.",
        "createdAt" : "2018-10-02T20:06:50Z",
        "updatedAt" : "2018-10-03T00:05:51Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "c3f368e2-ef5f-4f98-ac3f-8ff637d617ee",
        "parentId" : "8eaf5b47-6d5b-4ebb-b2c3-f09a52c4553d",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't care too much personally. However, I don't think it's a issue to use `OutputVerifier` in unit test (if we can pull it in, with dependency issues?) as long as it does what we need. Of course, we would not change `OutputVerifier` is it does not meet the unit test requirements but would move off it for this case.",
        "createdAt" : "2018-10-02T21:12:24Z",
        "updatedAt" : "2018-10-03T00:05:51Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3be8a660-cc1a-415e-b645-7c8e3ffcf950",
        "parentId" : "8eaf5b47-6d5b-4ebb-b2c3-f09a52c4553d",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Also, note that this is a `ConsumerRecord`, and `OutputVerifier` is for a `ProducerRecord`.",
        "createdAt" : "2018-10-02T23:53:30Z",
        "updatedAt" : "2018-10-03T00:05:51Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d405ac999adf4136de26b1e533c627ca00ed3238",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +569,573 @@        final long recordTimestamp = record.timestamp();\n        final AssertionError error = new AssertionError(\"Expected <\" + expectedKey + \", \" + expectedValue + \"> with timestamp=\" + expectedTimestamp +\n                                                            \" but was <\" + recordKey + \", \" + recordValue + \"> with timestamp=\" + recordTimestamp);\n        if (recordKey != null) {\n            if (!recordKey.equals(expectedKey)) {"
  },
  {
    "id" : "81813b9d-9297-4766-b5b0-a88e6e40be07",
    "prId" : 5724,
    "prUrl" : "https://github.com/apache/kafka/pull/5724#pullrequestreview-160935526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38208a8d-065e-4c8f-ab61-bfa45baee81a",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Good job moving common utils to this class!",
        "createdAt" : "2018-10-02T22:53:20Z",
        "updatedAt" : "2018-10-03T00:05:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d405ac999adf4136de26b1e533c627ca00ed3238",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +118,122 @@    }\n\n    public static void cleanStateBeforeTest(final EmbeddedKafkaCluster cluster, final String... topics) {\n        try {\n            cluster.deleteAllTopicsAndWait(DEFAULT_TIMEOUT);"
  },
  {
    "id" : "f07daf81-5b8b-494f-8c06-a57927b82766",
    "prId" : 6751,
    "prUrl" : "https://github.com/apache/kafka/pull/6751#pullrequestreview-242857930",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d31e18a4-be6f-4715-826a-e6575716a841",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Curious: why should we need this in the integration test utils? There's no need to make something public for later use, since we can just make it public if/when we need it to be.",
        "createdAt" : "2019-05-28T14:52:52Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "8d594e6f-282c-46a1-948c-7ade31119531",
        "parentId" : "d31e18a4-be6f-4715-826a-e6575716a841",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "It's for discoverability -- I often use Intellij auto-complete to see what methods are available -- if not public, it's not listed...",
        "createdAt" : "2019-05-28T18:50:11Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f06e10cec644ff9e471ead47982151bbe1e63d0",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +242,246 @@     * @param <V>                 Value type of the data records\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    public static <K, V> void produceKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                         final Collection<KeyValue<K, V>> records,"
  },
  {
    "id" : "73b3531d-8551-419f-9bd5-bf4f2d4cd5a4",
    "prId" : 6884,
    "prUrl" : "https://github.com/apache/kafka/pull/6884#pullrequestreview-270434333",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46f0301d-7282-4a98-a703-5cbd02cb1c1a",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is related to the FSM change as well. Ditto above.",
        "createdAt" : "2019-08-03T00:02:47Z",
        "updatedAt" : "2019-08-08T21:28:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6041a792f58b0b9a38983a60e052e9018319a6e6",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +85,89 @@                             final ThreadStateTransitionValidator newState,\n                             final ThreadStateTransitionValidator oldState) {\n            if (newState == StreamThread.State.PENDING_SHUTDOWN) {\n                toPendingShutdownSeen = true;\n            }"
  },
  {
    "id" : "4fd75bc7-5df2-4f0c-a3de-bd74755ecd2b",
    "prId" : 7500,
    "prUrl" : "https://github.com/apache/kafka/pull/7500#pullrequestreview-301571593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93dc944e-0aa9-458b-9209-754a93f84f61",
        "parentId" : null,
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "Note that the streams toString is just the object and hash (e.g. `org.apache.kafka.streams.KafkaStreams@77258e59`). It would be nice if there were a better way to identify the instance, but I couldn't find anything in the public API.",
        "createdAt" : "2019-10-11T19:32:06Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "72682b1c-6501-494b-9378-f47e11d5b3eb",
        "parentId" : "93dc944e-0aa9-458b-9209-754a93f84f61",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Maybe we could use `client.id` (if set?) from `StreamsConfig`? ",
        "createdAt" : "2019-10-11T22:28:02Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "561d55e2-a9c0-42d4-a7dd-c8dfe3f9e257",
        "parentId" : "93dc944e-0aa9-458b-9209-754a93f84f61",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "That would be great - client.id is what I was going for - but I don't see a good way to get the config out of the KafkaStreams either (besides reflection :)). Did I miss anything?",
        "createdAt" : "2019-10-14T15:05:08Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "d768bd06-2b56-4b88-9acb-6b88f8c4fa6a",
        "parentId" : "93dc944e-0aa9-458b-9209-754a93f84f61",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well, maybe we can update `KafkaStreams#toString()` to access the `client.id` ?",
        "createdAt" : "2019-10-14T22:31:36Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c09dfb7b7fd9426578e779fb7c53a0febb1fa9a",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +799,803 @@                final long millisRemaining = expectedEnd - System.currentTimeMillis();\n                if (millisRemaining <= 0) {\n                    fail(\"Application did not reach a RUNNING state for all streams instances. Non-running instances: \" +\n                        nonRunningStreams);\n                }"
  },
  {
    "id" : "8f64771d-ca26-4f3e-a0b8-19abe85e4494",
    "prId" : 7500,
    "prUrl" : "https://github.com/apache/kafka/pull/7500#pullrequestreview-301578077",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eb112e2-721e-43cd-814a-7d56f1dd963f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just to clarify: when we call await() here, we release `stateLock`, right?",
        "createdAt" : "2019-10-11T22:26:47Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "47ed46f4-e871-4dd8-b185-79d759437d1d",
        "parentId" : "4eb112e2-721e-43cd-814a-7d56f1dd963f",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "That's exactly how it works. Some more details here, if you're curious: https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/locks/Condition.html#awaitNanos(long).",
        "createdAt" : "2019-10-14T14:53:25Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      },
      {
        "id" : "ef749aee-a530-4875-a1e9-4dd616de9c96",
        "parentId" : "4eb112e2-721e-43cd-814a-7d56f1dd963f",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "@mjsax haven't you had to do the `Job Scheduler` interview question? :P ",
        "createdAt" : "2019-10-14T22:53:40Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c09dfb7b7fd9426578e779fb7c53a0febb1fa9a",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +803,807 @@                }\n\n                stateUpdate.await(millisRemaining, TimeUnit.MILLISECONDS);\n            }\n        } finally {"
  },
  {
    "id" : "e3fe6485-0570-476c-8965-71e1b4460d98",
    "prId" : 7500,
    "prUrl" : "https://github.com/apache/kafka/pull/7500#pullrequestreview-302113194",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d500367f-c30c-41f6-9369-99780a2ce57b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We recently merge a fix for EosIntegrationTest that also starts two instances -- can we update this test to use this new method in this PR? https://github.com/apache/kafka/blob/trunk/streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java#L467-L468\r\n\r\nAlso, the other PR introduced `StreamsTestUtils#startKafkaStreamsAndWaitForRunningState(...)` that takes a long as timeout -- to align with this PR, we could change it to `Duration` as well.\r\n\r\nWe can also do a follow up PR if you don't want to block this PR by both.",
        "createdAt" : "2019-10-14T22:28:52Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6aeea548-4a78-43cb-99f6-2e67be67364a",
        "parentId" : "d500367f-c30c-41f6-9369-99780a2ce57b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Do we need both startKafkaStreamsAndWaitForRunningState and this? Can we just consolidate them into a single function?",
        "createdAt" : "2019-10-15T18:33:17Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c09dfb7b7fd9426578e779fb7c53a0febb1fa9a",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +749,753 @@     * @param timeout the time to wait for the streams to all be in @{link State#RUNNING} state.\n     */\n    public static void startApplicationAndWaitUntilRunning(final List<KafkaStreams> streamsList,\n                                                           final Duration timeout) throws InterruptedException {\n        final Lock stateLock = new ReentrantLock();"
  },
  {
    "id" : "35c34966-b2da-470f-a730-b2e34e15c6e9",
    "prId" : 7500,
    "prUrl" : "https://github.com/apache/kafka/pull/7500#pullrequestreview-301725340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc56ce0d-952b-4553-b038-b9592d40d4d2",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I just have to say, personally I think reflection seems like overkill here, but I take it we're just trying to avoid the need to go through a KIP?\r\nIt seems like a potentially useful API, although admittedly I've never seen it requested specifically. Just wondering what the thoughts/status is here: are we considering adding it as an official API at some later point?",
        "createdAt" : "2019-10-14T23:13:29Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "182c35ec-80cb-4cc1-860b-8e3658813a1f",
        "parentId" : "dc56ce0d-952b-4553-b038-b9592d40d4d2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I would be open to add this to the public API -- but short term, reflections are the only \"hack\" we can use.",
        "createdAt" : "2019-10-15T08:16:10Z",
        "updatedAt" : "2019-10-16T16:30:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c09dfb7b7fd9426578e779fb7c53a0febb1fa9a",
    "line" : 105,
    "diffHunk" : "@@ -1,1 +812,816 @@    private static StateListener getStateListener(final KafkaStreams streams) {\n        try {\n            final Field field = streams.getClass().getDeclaredField(\"stateListener\");\n            field.setAccessible(true);\n            return (StateListener) field.get(streams);"
  },
  {
    "id" : "3b103511-a4b0-4d0e-a5db-84a743b0d96a",
    "prId" : 8248,
    "prUrl" : "https://github.com/apache/kafka/pull/8248#pullrequestreview-420531757",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb5f7e1b-da9a-4dd2-9905-8c5a3a2889c0",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This isn't threadsafe, but it looks like we're using it from multiple threads during the tests.",
        "createdAt" : "2020-05-28T20:37:45Z",
        "updatedAt" : "2020-05-28T23:49:30Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "2c3d5a2c-519e-4b75-bd59-575ea1138edb",
        "parentId" : "eb5f7e1b-da9a-4dd2-9905-8c5a3a2889c0",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Whoops",
        "createdAt" : "2020-05-28T22:18:06Z",
        "updatedAt" : "2020-05-28T23:49:30Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "30ac7b3ccd47063497c17ac148d90f9b29683e82",
    "line" : 251,
    "diffHunk" : "@@ -1,1 +1285,1289 @@     * if it's important to track across multiple stores in a topology\n     */\n    public static class TrackingStateRestoreListener implements StateRestoreListener {\n        public final Map<TopicPartition, AtomicLong> changelogToStartOffset = new ConcurrentHashMap<>();\n        public final Map<TopicPartition, AtomicLong> changelogToEndOffset = new ConcurrentHashMap<>();"
  },
  {
    "id" : "1d9a0074-9ff4-402d-a414-983810db0c00",
    "prId" : 8568,
    "prUrl" : "https://github.com/apache/kafka/pull/8568#pullrequestreview-401497994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79200737-8b55-4154-92d4-15c5fc09ef04",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is fix 2).",
        "createdAt" : "2020-04-28T04:59:22Z",
        "updatedAt" : "2020-04-28T22:02:54Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +213,217 @@                                                            final boolean enableTransactions) {\n\n        try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n            if (enableTransactions) {\n                producer.initTransactions();"
  },
  {
    "id" : "91d624e0-d466-4f1c-bef0-c447acf980fe",
    "prId" : 8568,
    "prUrl" : "https://github.com/apache/kafka/pull/8568#pullrequestreview-402240933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e33d023-26d9-472e-91d0-35207167397f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I guess the flush at the end makes it synchronous anyway?",
        "createdAt" : "2020-04-28T21:14:22Z",
        "updatedAt" : "2020-04-28T22:02:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "3357816a-63d9-41e5-81d7-fe58e6157b5a",
        "parentId" : "8e33d023-26d9-472e-91d0-35207167397f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Previously we wait after sending each record, here we only wait once after sending all records, so it is more efficient.",
        "createdAt" : "2020-04-28T21:48:05Z",
        "updatedAt" : "2020-04-28T22:02:54Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c044c033-42be-4573-bc4f-1b371cda1c03",
        "parentId" : "8e33d023-26d9-472e-91d0-35207167397f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks. That's what I was asking for confirmation on. I realize now the structure of my sentence was ambiguous.\r\n\r\nI agree that the method contract is that the batch should be synchronously produced, not that each record should be synchronously produced, so this change looks good to me.",
        "createdAt" : "2020-04-28T21:55:48Z",
        "updatedAt" : "2020-04-28T22:02:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +285,289 @@            }\n            for (final KeyValue<K, V> record : records) {\n                producer.send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));\n            }\n            if (enableTransactions) {"
  },
  {
    "id" : "58143b14-ed05-473a-af7e-b478c629f7f0",
    "prId" : 8578,
    "prUrl" : "https://github.com/apache/kafka/pull/8578#pullrequestreview-402972776",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c1be683-57dc-44ff-88d3-278aebb88ed0",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is really the fix for KAFKA-9875. The other change just hopefully reduces the probability that ignoring the exceptions could cause subsequent failures (e.g., if the topics don't get deleted before the next test, at least the next one will have different topic names).\r\n\r\nI've verified that all usages of this method are ok to ignore potential exceptions. Namely, as long as the test logic itself doesn't want to ensure that any topics got deleted, and as long as this method is the last line in the method, then it should be fine just to ignore failures here.\r\n\r\nI also considered just deleting the method, but if it does succeed, then it leaves less garbage around for subsequent tests, so it feels better to at least attempt a cleanup.",
        "createdAt" : "2020-04-28T22:56:13Z",
        "updatedAt" : "2020-04-29T19:48:31Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "6a9cfefb-5362-4b31-ad3b-5ee27e58dabf",
        "parentId" : "3c1be683-57dc-44ff-88d3-278aebb88ed0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "req: Actually deleting topics after test is critical for some tests: I've encountered some cases where the same topics are reused mistakenly across different test cases within the single class. But I feel that it is better to put the topic deletion in the `@after` function while leaving `cleanUp()` as part of the test function itself.",
        "createdAt" : "2020-04-29T01:05:00Z",
        "updatedAt" : "2020-04-29T19:48:31Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "9b964c73-4091-4ebe-b3ca-cb308cc9db67",
        "parentId" : "3c1be683-57dc-44ff-88d3-278aebb88ed0",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I share your concern, but I'm not sure about the conclusion.\r\n\r\nYes, if there is state (such as a topic) that leaks from one test to the next, it can certainly cause difficult-to-debug failures. However, there are multiple things we can do to prevent/mitigate it:\r\n* delete state after tests (not to leave any garbage behind)\r\n* delete state before the tests (to ensure a clean slate for the test)\r\n* choose unique names for all resources of each test (this is where the other part of this PR comes in)\r\n\r\nAny one of these should be sufficient to prevent state from leaking in between tests, and most of these tests do all three. In other words, we have 3x redundancy guarding against such test pollution. If you look at all three of these measures, the clean up _after_ tests is actually the most optional, since tests can't tolerate failures in the clean up _before_ (because it also creates necessary topics), and choosing unique topic names per test is bulletproof and easy to fix (once we know what the problem is).\r\n\r\nWhether the cleanup is part of the test or in the `@After` method, the outcome is the same, if the method throws an exception, the test will fail. The downside of After is that it requires you to store the topic names in mutable class-level fields, which actually makes it more awkward to choose unique names per test.",
        "createdAt" : "2020-04-29T03:16:15Z",
        "updatedAt" : "2020-04-29T19:48:31Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "d232f263-116d-491b-8cd1-24491faacd20",
        "parentId" : "3c1be683-57dc-44ff-88d3-278aebb88ed0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Sounds good. I think this is convincing :)",
        "createdAt" : "2020-04-29T19:28:10Z",
        "updatedAt" : "2020-04-29T19:48:31Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b3bd1505-fe7a-41eb-b001-9b696180e0b3",
        "parentId" : "3c1be683-57dc-44ff-88d3-278aebb88ed0",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Whew! :)",
        "createdAt" : "2020-04-29T19:28:59Z",
        "updatedAt" : "2020-04-29T19:48:31Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "1884686387a8af57d0123deead442c98529239d5",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +169,173 @@        } catch (final RuntimeException | InterruptedException e) {\n            LOG.warn(\"Ignoring failure to clean test state\", e);\n        }\n    }\n"
  },
  {
    "id" : "95fd28af-fe05-4c48-96af-3db8842fc145",
    "prId" : 8953,
    "prUrl" : "https://github.com/apache/kafka/pull/8953#pullrequestreview-439475760",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80ce1534-ca9a-4bd2-ac50-d976c02b10f7",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "nit: should we also log expected records then?",
        "createdAt" : "2020-06-29T20:28:27Z",
        "updatedAt" : "2020-06-29T20:28:31Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      }
    ],
    "commit" : "26ad369ce932bf4c521615134aadf61c34b82534",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +595,599 @@                    readKeyValues(topic, consumer, waitTime, expectedNumRecords);\n                accumData.addAll(readData);\n                assertThat(reason + \",  currently accumulated data is \" + accumData, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n            });\n        }"
  },
  {
    "id" : "704d2cad-f63b-48c6-b055-2f6f997b4372",
    "prId" : 8963,
    "prUrl" : "https://github.com/apache/kafka/pull/8963#pullrequestreview-442626820",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "abfcb338-0070-44f1-a6cb-94b93a03435e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Makes sense to me.",
        "createdAt" : "2020-07-04T19:15:40Z",
        "updatedAt" : "2020-07-04T19:16:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b4b8c635c2887902f405bcfbb6e252678700290",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1274,1278 @@        public void waitForNextStableAssignment(final long maxWaitMs) throws InterruptedException {\n            waitForCondition(\n                () -> numStableAssignments() >= nextExpectedNumStableAssignments,\n                maxWaitMs,\n                () -> \"Client did not reach \" + nextExpectedNumStableAssignments + \" stable assignments on time, \" +"
  },
  {
    "id" : "e947c24f-a84c-4309-a46d-705f5bc4c334",
    "prId" : 9629,
    "prUrl" : "https://github.com/apache/kafka/pull/9629#pullrequestreview-535464234",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bbb34ac-7ccb-418a-9009-d1b16400c879",
        "parentId" : null,
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "We should throw a specific kind of exception, not an `Exception`.",
        "createdAt" : "2020-11-20T14:17:03Z",
        "updatedAt" : "2020-11-24T04:29:44Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b6d0a2d285b5b7fc0a9a8474712870f6f7a767e",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +916,920 @@    public static void waitForApplicationState(final List<KafkaStreams> streamsList,\n                                               final State state,\n                                               final Duration timeout) throws InterruptedException {\n        retryOnExceptionWithTimeout(timeout.toMillis(), () -> {\n            final Map<KafkaStreams, State> streamsToStates = streamsList"
  },
  {
    "id" : "43ee4857-a3cf-4085-847d-a8553ee1b4a7",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544784709",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43abbc80-3853-43b0-8eac-f4ed5b4df01f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We have cases when we pass in `0` and for this case, the old code did loop forever until the timeout hits and the test fails. Seems this logic was wrong from the beginning on an we should stop fetching if `maxMessages <= 0` instead of looping forever.",
        "createdAt" : "2020-12-04T09:23:22Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1162,1166 @@\n    private static boolean continueConsuming(final int messagesConsumed, final int maxMessages) {\n        return maxMessages > 0 && messagesConsumed < maxMessages;\n    }\n"
  }
]