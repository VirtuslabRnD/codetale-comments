[
  {
    "id" : "2fda4b01-1e3d-4d8f-bd05-3c10debaeb36",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-395028242",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ac24df3-13ca-4fef-a870-e16b4d71b306",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Could we just use a boolean flag as parameter to determine whether to only read committed data?",
        "createdAt" : "2020-04-16T16:40:22Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "287515ed-38e6-4a58-842f-39cf57d737c4",
        "parentId" : "7ac24df3-13ca-4fef-a870-e16b4d71b306",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "+1 It seems we do not need the actual groupId here, just a boolean flag.",
        "createdAt" : "2020-04-16T22:24:32Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 972,
    "diffHunk" : "@@ -1,1 +970,974 @@    }\n\n    private List<KeyValue<Long, Long>> readResult(final int numberOfRecords,\n                                                  final boolean readCommitted) throws Exception {\n        if (readCommitted) {"
  },
  {
    "id" : "a3f4d219-87c4-468b-8ad2-3ba612e4b520",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-395119860",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff3bc3fe-3c66-4a8f-9a51-bb3283893e7f",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In the current settings, with either alpha or beta, we will have one producer per thread since each thread would host one task only, right? Should we have 4 partitions so that under alpha we will have two producers and two txns per thread?",
        "createdAt" : "2020-04-16T22:14:06Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "a5c20438-aa74-42aa-9932-2123b80fdc9b",
        "parentId" : "ff3bc3fe-3c66-4a8f-9a51-bb3283893e7f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "That is correct. I did consider using 4 partitions for the same reason, but was not sure if it would add value to the test? In the end, the \"gap\" between eos-alpha and eos-beta is not the number to open transaction, but the usage of different `transactional.id`s between a task-producer and a thread-producer and this gap is closed via \"fetch offset fencing\". Hence, if the \"fetch offset fencing\" works for one task-producer vs one thread-producer (both using different txId), it also works for two task-producers vs one thread-producer?\r\n\r\nThoughts?",
        "createdAt" : "2020-04-16T23:01:41Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "add4e316-ebf8-4892-a3a3-5e4eea9a46a0",
        "parentId" : "ff3bc3fe-3c66-4a8f-9a51-bb3283893e7f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "What I'm thinking is when there are two running clients, one with eos-alpha and another with eos-beta (upgraded from eos-alpha) the number of transaction.ids is actually reduced, and hence the number of max in-flight txns, and logically I agree they should not have much impact, but hey without the testing we don't know about what we don't know right? If you think such \"changes of number of txn.ids and hence number of txns\" has been covered in other system tests then probably it's fine. But if using 4 partitions isn't going to make the test more complex / takes much longer, could we be a bit over-cautious here?",
        "createdAt" : "2020-04-17T01:16:44Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "90fe6775-1a3d-4d91-a094-4ff57ad7a4b0",
        "parentId" : "ff3bc3fe-3c66-4a8f-9a51-bb3283893e7f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Sure. Works for me.",
        "createdAt" : "2020-04-17T02:24:45Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 200,
    "diffHunk" : "@@ -1,1 +198,202 @@        // picked up, i.e., GroupCoordinator fencing works correctly.\n        //\n        // The commit interval is set to MAX_VALUE and the used `Processor` request commits manually so we have full\n        // control when a commit actually happens. We use an input topic with 4 partitions and each task will request\n        // a commit after processing 10 records."
  },
  {
    "id" : "682d5939-6037-4940-a95b-3427d46b84f7",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87a3be85-626f-4bac-a599-283abc200492",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The test fails here... (cf. over TODO)",
        "createdAt" : "2020-04-30T03:50:11Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 389,
    "diffHunk" : "@@ -1,1 +387,391 @@                final List<KeyValue<Long, Long>> expectedCommittedResult =\n                    computeExpectedResult(committedInputDataDuringFirstUpgrade, committedState);\n                verifyCommitted(expectedCommittedResult);\n            } else {\n                // retrying TX"
  },
  {
    "id" : "5de65042-fbd4-411a-972e-de187d4a6530",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403183398",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e48d38d-cb14-42ba-812b-4180b3a33242",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the workaround that make the test (clean run) pass. For the error injection run, the test passed w/ and w/o this partitioner.",
        "createdAt" : "2020-04-30T03:50:51Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 882,
    "diffHunk" : "@@ -1,1 +880,884 @@        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n        properties.put(StreamsConfig.producerPrefix(ProducerConfig.PARTITIONER_CLASS_CONFIG), KeyPartitioner.class);\n        properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n        properties.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath() + File.separator + appDir);"
  },
  {
    "id" : "fedaee8f-0de0-4062-a4f2-b49bf71e4770",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403782661",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbfb88e4-5eb2-4197-9ea0-92ae0ba03a64",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is just needed to make the partitioner work for writing into input topics and to use within KS to write into output topic.",
        "createdAt" : "2020-04-30T03:51:38Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8684ef3b-bea5-4728-9331-58f3d848409d",
        "parentId" : "bbfb88e4-5eb2-4197-9ea0-92ae0ba03a64",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Hmm, this sounds to me that the StreamProducer's own `partitionsFor` did not return the num.partitions so we ended up calling `send` with `partition == null`, since otherwise we will get the `partition` as\r\n\r\n```\r\npartition = partitioner.partition(topic, key, value, partitions.size());\r\n```\r\n\r\nwhere `partitioner` is the `StreamsPartitioner` and the producer's own partitioner should not be used. ",
        "createdAt" : "2020-04-30T18:25:15Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e8ba4bda-9aff-4f42-b8d5-afe95c7501a3",
        "parentId" : "bbfb88e4-5eb2-4197-9ea0-92ae0ba03a64",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't think so. The original impl (just for the upstream producer to write into the input topics) was:\r\n```\r\nreturn ((Long) key).intValue() % NUM_TOPIC_PARTITIONS;\r\n```\r\n\r\nHowever, this assumes that `key` is of type `Long` what is not true when used within streams, because Streams does serialize all data upfront and `key` and `value` type is `byte[]` -- thus, we need to deserialize  to get the original key object.",
        "createdAt" : "2020-04-30T18:32:32Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "75d4e670-f0e0-47ea-ab1a-4ba7613a2c88",
        "parentId" : "bbfb88e4-5eb2-4197-9ea0-92ae0ba03a64",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "What I was asking is for the necessity of \r\n\r\n```\r\nproperties.put(StreamsConfig.producerPrefix(ProducerConfig.PARTITIONER_CLASS_CONFIG), KeyPartitioner.class);\r\n```\r\n\r\nAs I mentioned, Streams has its own StreamsPartitioner, and if it can get the actual not-null `partition` value passing to the `send` call, then the embedded producer's partitioner would not be used. Maybe I missed something critical here --- did you mean this config is only used for sending data to the source topics? If yes why put it into a streams props?",
        "createdAt" : "2020-04-30T18:41:46Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 1065,
    "diffHunk" : "@@ -1,1 +1063,1067 @@                             final byte[] valueBytes,\n                             final Cluster cluster) {\n            return LONG_DESERIALIZER.deserialize(topic, keyBytes).intValue() % NUM_TOPIC_PARTITIONS;\n        }\n"
  },
  {
    "id" : "8ddffa58-7569-4aeb-8a97-540c611e13ff",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184063",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99218398-6998-492f-89c8-7df1eaad802e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We use 6 clients now, to do some error injection in \"mixed mode\". To avoid JXM warnings, we cannot create all clients at the same time and thus cannot use try-with-resources...",
        "createdAt" : "2020-04-30T03:53:51Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 256,
    "diffHunk" : "@@ -1,1 +254,258 @@        KafkaStreams streams2Beta = null;\n\n        try {\n            // phase 1: start both clients\n            streams1Alpha = getKafkaStreams(\"appDir1\", StreamsConfig.EXACTLY_ONCE);"
  },
  {
    "id" : "238d5195-8fec-46d9-bda5-bebb0787703d",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184310",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da6ec8d3-ecf9-48ed-904a-2106f70fcea0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is new: for the crash case, in inject more errors in mixed mode, after we called `sendOffsetsToTransaction()` but before actually committing.",
        "createdAt" : "2020-04-30T03:55:03Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 442,
    "diffHunk" : "@@ -1,1 +440,444 @@            verifyCommitted(expectedCommittedResultAfterRestartFirstClient);\n\n            // phase 6: (complete second batch of data; crash: let second client fail on commit)\n            // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n            //"
  },
  {
    "id" : "9a11a5d9-72b5-4c35-8e55-970d3724915f",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403184711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "879a4592-cc9e-45f7-a760-1042e6ceaa64",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the second part of the \"mixed mode\" test: client1 is on eos-beta and client2 is on eoa-alpha. In the first part above, we crashed the second client and restarted it in eos-alpha mode. In this second part, we crash client1 and restart it in eos-beta mode.\r\n\r\nThe actual upgrade continues in the next phase.",
        "createdAt" : "2020-04-30T03:56:49Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 523,
    "diffHunk" : "@@ -1,1 +521,525 @@            }\n\n            // 7. only for crash case:\n            //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n            //     7b. write third batch of input data"
  },
  {
    "id" : "739243c0-1c57-463e-b6bc-88561f949637",
    "prId" : 8496,
    "prUrl" : "https://github.com/apache/kafka/pull/8496#pullrequestreview-403185649",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3fc798a-565c-46b9-80ed-4f5ac5afa25d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "With 4 partitions, we need a custom partitioner to make sure we write the 4 different keys into 4 different partitions -- the default partitioner would only write data to 2 partitions (this behavior, ie, empty partitions vs. non-empty partitions, seems to be related to the bug when the test fails -- ensuring that data is written into all partitions avoids the issue).",
        "createdAt" : "2020-04-30T04:00:48Z",
        "updatedAt" : "2020-05-01T21:39:59Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "346c7b4fe34cf6870cd6f6d28365d10ef39a141d",
    "line" : 953,
    "diffHunk" : "@@ -1,1 +951,955 @@            LongSerializer.class\n        );\n        config.setProperty(ProducerConfig.PARTITIONER_CLASS_CONFIG, KeyPartitioner.class.getName());\n        IntegrationTestUtils.produceKeyValuesSynchronously(\n            MULTI_PARTITION_INPUT_TOPIC,"
  },
  {
    "id" : "31209f71-7950-4553-a934-2e930259ddc7",
    "prId" : 8648,
    "prUrl" : "https://github.com/apache/kafka/pull/8648#pullrequestreview-410492224",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf85c15a-7230-4096-912a-87f99cc1eff2",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This one actually might not be necessary, but I thought it was useful as a sanity check especially since we're trying to access the stores in some places",
        "createdAt" : "2020-05-12T22:55:41Z",
        "updatedAt" : "2020-05-13T00:20:48Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "5b10e100-0744-4d82-beec-9e12f6a56e1b",
        "parentId" : "bf85c15a-7230-4096-912a-87f99cc1eff2",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Agreed.",
        "createdAt" : "2020-05-12T23:33:51Z",
        "updatedAt" : "2020-05-13T00:20:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "959e2217b04157736fd729fa4109901d3ea08496",
    "line" : 235,
    "diffHunk" : "@@ -1,1 +912,916 @@    }\n\n    private void waitForRunning(final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> observed) throws Exception {\n        waitForCondition(\n            () -> !observed.isEmpty() && observed.get(observed.size() - 1).value.equals(State.RUNNING),"
  },
  {
    "id" : "664ecac7-91d4-4891-9eba-c2c56a584f63",
    "prId" : 8963,
    "prUrl" : "https://github.com/apache/kafka/pull/8963#pullrequestreview-442037539",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "265a2e55-2b1b-419e-9c0f-c784c0e9e2d6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.",
        "createdAt" : "2020-07-02T14:29:40Z",
        "updatedAt" : "2020-07-02T19:27:26Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "91179a05-1743-45b0-b8c2-8e500cd31e19",
        "parentId" : "265a2e55-2b1b-419e-9c0f-c784c0e9e2d6",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "This is only meant to be used when there's a single thread (and single instance running). I just wanted to put in a quick fix for now--I'll leave a comment to warn our future selves that we'll have to tighten this up if we want to extend the test or use it elsewhere with multiple threads/instances ",
        "createdAt" : "2020-07-02T19:17:13Z",
        "updatedAt" : "2020-07-02T19:27:26Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "eab5630f-a1d0-448e-8a1d-1d3705f9fb62",
        "parentId" : "265a2e55-2b1b-419e-9c0f-c784c0e9e2d6",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "sounds good",
        "createdAt" : "2020-07-02T21:48:06Z",
        "updatedAt" : "2020-07-02T21:48:06Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b4b8c635c2887902f405bcfbb6e252678700290",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +170,174 @@                context.commit();\n                requestCommit.set(false);\n            }\n        }\n    }"
  },
  {
    "id" : "cdbe97a4-c25c-40a8-8410-c161e2830c1a",
    "prId" : 8963,
    "prUrl" : "https://github.com/apache/kafka/pull/8963#pullrequestreview-442626820",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf965249-3c22-49ba-a995-cb020335e643",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "There's going to be a separate punctuator per task, right? Does the test account for this?",
        "createdAt" : "2020-07-02T14:31:05Z",
        "updatedAt" : "2020-07-02T19:27:26Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "b297b9c6-7db9-4c07-83b9-acdefee69a88",
        "parentId" : "cf965249-3c22-49ba-a995-cb020335e643",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Sort of; with eos-beta when you need to commit one task, you need to commit all of them, so requesting a commit at all should be sufficient. It's kind of a subtle point, but I think it's actually preferable to just request a commit on one task so this test can also verify that we commit all tasks together",
        "createdAt" : "2020-07-02T19:15:25Z",
        "updatedAt" : "2020-07-02T19:27:26Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "f3e0f878-86fe-4a58-9241-a4d377e2b014",
        "parentId" : "cf965249-3c22-49ba-a995-cb020335e643",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ok, I was thinking more along the lines that we have just one requestCommit instance while we would have multiple punctuator instances all using it. It looked like a bug, but it seems like it'll be fine.",
        "createdAt" : "2020-07-02T21:52:19Z",
        "updatedAt" : "2020-07-02T21:52:19Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "e38f6d4e-9da1-40e6-8a66-0023b56646cc",
        "parentId" : "cf965249-3c22-49ba-a995-cb020335e643",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "In this test we would have multiple punctuator indeed but they would be executed by a single thread sequentially so that's fine.",
        "createdAt" : "2020-07-04T19:14:50Z",
        "updatedAt" : "2020-07-04T19:16:24Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b4b8c635c2887902f405bcfbb6e252678700290",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +869,873 @@                            sharedCommit = commitCounterClient2;\n                        }\n                        punctuator = context.schedule(\n                            Duration.ofMillis(100),\n                            PunctuationType.WALL_CLOCK_TIME,"
  },
  {
    "id" : "9abb4ad6-9e32-4dc6-974c-54652320af2e",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544777988",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b5c98b0-282a-4a3b-ad00-8e47213a1d53",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Side cleanup",
        "createdAt" : "2020-12-04T09:14:31Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +102,106 @@    private static final int NUM_BROKERS = 3;\n    private static final int MAX_POLL_INTERVAL_MS = (int) Duration.ofSeconds(100L).toMillis();\n    private static final long MAX_WAIT_TIME_MS = Duration.ofMinutes(1L).toMillis();\n\n    private static final List<KeyValue<KafkaStreams.State, KafkaStreams.State>> CLOSE ="
  },
  {
    "id" : "b7e85a0b-1561-4078-a268-f90bab0f0399",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544779082",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dceb8be8-6a14-465d-9106-f674d07eda6e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Added some more details/explanations and also renames a few variables below",
        "createdAt" : "2020-12-04T09:15:51Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +294,298 @@            //   p-3: 10 rec + C ---> 5 rec (pending)\n            // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n            //             (we don't crash right away and write one record less)\n            //   p-0: 10 rec + C ---> 4 rec (pending)\n            //   p-1: 10 rec + C ---> 5 rec (pending)"
  },
  {
    "id" : "e8488486-8c90-4424-b7da-2eeade30f189",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544779797",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b629828-6beb-4fe6-9ac1-22b3c3897219",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the first fix: ie how we compute those keys.",
        "createdAt" : "2020-12-04T09:16:49Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 203,
    "diffHunk" : "@@ -1,1 +420,424 @@            waitForRunning(stateTransitions2);\n\n            final Set<Long> newlyCommittedKeys;\n            if (!injectError) {\n                newlyCommittedKeys = keysFromInstance(streams1Beta);"
  },
  {
    "id" : "c4b5cd45-9ccd-4fb1-9ea6-1aecdac49f5b",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-546773445",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff04c143-49fc-4a18-9554-d74195121c63",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the second fix: depending on task movement, we have different set of committed records.",
        "createdAt" : "2020-12-04T09:17:39Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8abb6345-bab7-4e24-a5c6-b1aca34af4a6",
        "parentId" : "ff04c143-49fc-4a18-9554-d74195121c63",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice catch.\r\n\r\nReminds me though, why the second rebalance may not be deterministic in migrating tasks back? I thought our algorithm should produce deterministic results? cc @ableegoldman ",
        "createdAt" : "2020-12-08T06:16:19Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 256,
    "diffHunk" : "@@ -1,1 +459,463 @@                writeInputData(finishSecondBatch);\n\n                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = uncommittedInputDataBeforeFirstUpgrade\n                    .stream()\n                    .filter(pair -> !keysFirstClientAlpha.contains(pair.key))"
  },
  {
    "id" : "61a17e84-6ee6-41ff-9c25-710d7ee75be9",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544781142",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f13f46c-fbe0-4d5b-9ca2-815f62b7c295",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For this, we needed to preserve old `uncommittedState` further above.",
        "createdAt" : "2020-12-04T09:18:36Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 266,
    "diffHunk" : "@@ -1,1 +469,473 @@\n                expectedUncommittedResult.addAll(\n                    computeExpectedResult(finishSecondBatch, uncommittedState)\n                );\n                final List<KeyValue<Long, Long>> expectedCommittedResult ="
  },
  {
    "id" : "b14b526f-b161-4bd7-aeea-b6821afa7c59",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544781714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1fc31b5-6099-417e-9ad5-bf6c329abfb6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Similar fix as above: we compute those keys differently now.",
        "createdAt" : "2020-12-04T09:19:20Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 499,
    "diffHunk" : "@@ -1,1 +770,774 @@            waitForRunning(stateTransitions2);\n\n            newlyCommittedKeys.clear();\n            if (!injectError) {\n                newlyCommittedKeys.addAll(keysFromInstance(streams2Beta));"
  },
  {
    "id" : "eeb4d21b-ade5-408c-82a0-f5a5d183b26c",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-547576069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9cd08f9c-67db-44b8-9f3a-1a44903eb9a9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Similar to above: we need to be more flexible (ie, depend on actual task movement)",
        "createdAt" : "2020-12-04T09:19:55Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5d53e53d-d729-4bc7-bca3-f9fa161376bb",
        "parentId" : "9cd08f9c-67db-44b8-9f3a-1a44903eb9a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I'm guessing the root source of this all is a bad assumption that the assignment would be stable if a stable `CLIENT_ID` was used? I remember we discussed that back when you first wrote this test, I'm sorry for any misinformation I supplied based on my own assumption about how the CLIENT_ID would be used :/",
        "createdAt" : "2020-12-04T19:11:51Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e0a4030f-fd4d-44e6-a798-a53b6f502f18",
        "parentId" : "9cd08f9c-67db-44b8-9f3a-1a44903eb9a9",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes, the test assumed a more stable task->thread mapping during the assignment. But it turns out, that task assignment may \"flip\" (not sure about details)",
        "createdAt" : "2020-12-04T19:44:35Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "759e6cf4-3dbb-4b1f-8e2c-99f7c4af2d52",
        "parentId" : "9cd08f9c-67db-44b8-9f3a-1a44903eb9a9",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@ableegoldman is it related to the UUID randomness? If yes please ignore my other question above.",
        "createdAt" : "2020-12-08T06:17:26Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "becf2819-a1a5-45ac-953f-cdd291ffbea5",
        "parentId" : "9cd08f9c-67db-44b8-9f3a-1a44903eb9a9",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Yes, I think so",
        "createdAt" : "2020-12-08T19:49:47Z",
        "updatedAt" : "2020-12-09T01:21:11Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 549,
    "diffHunk" : "@@ -1,1 +810,814 @@            uncommittedKeys.removeAll(keysSecondClientAlphaTwo);\n            uncommittedKeys.removeAll(newlyCommittedKeys);\n            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = uncommittedInputDataBeforeSecondUpgrade\n                .stream()\n                .filter(pair -> uncommittedKeys.contains(pair.key))"
  },
  {
    "id" : "e77a0f86-85d7-47a8-ba51-db5721480d3c",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544782852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17518627-f779-4c51-ad87-eb00df6f7572",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Increase wait time here, too.",
        "createdAt" : "2020-12-04T09:20:58Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 616,
    "diffHunk" : "@@ -1,1 +1023,1027 @@                MULTI_PARTITION_OUTPUT_TOPIC,\n                numberOfRecords,\n                MAX_WAIT_TIME_MS\n            );\n        }"
  },
  {
    "id" : "6dc137fb-ec0d-4514-89cd-d59aadd45a65",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-544783585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c63b1cc2-2127-4350-b444-987745c854b8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Side cleanup",
        "createdAt" : "2020-12-04T09:21:58Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 681,
    "diffHunk" : "@@ -1,1 +1152,1156 @@\n        @Override\n        public void commitTransaction() {\n            super.flush(); // we flush to ensure that the offsets are written\n            if (!crash.compareAndSet(true, false)) {"
  },
  {
    "id" : "16430c95-3105-4077-9afd-ae5c38a7d2af",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-545228417",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f64026c-9c6b-49b6-b817-dfacb558251e",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Thanks for cleaning up the variable names 🙂 ",
        "createdAt" : "2020-12-04T19:25:11Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 80,
    "diffHunk" : "@@ -1,1 +301,305 @@            final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n            final Set<Long> keysFirstClientAlpha = keysFromInstance(streams1Alpha);\n            final long firstFailingKeyForCrashCase = keysFirstClientAlpha.iterator().next();\n            cleanKeys.remove(firstFailingKeyForCrashCase);\n"
  },
  {
    "id" : "5ea802b0-3216-4983-ac80-4898b0467bc3",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-547759027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06a1c57c-185d-4b78-9e88-a18031955d26",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Are these changes intentional?",
        "createdAt" : "2020-12-08T06:14:54Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "22139d79-a040-42ae-955e-e8b2608c4439",
        "parentId" : "06a1c57c-185d-4b78-9e88-a18031955d26",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes. I wanted to improve the readability of the comment -- the additional blanks separate the the main phases of the test (each main phase write 10 records per partition that should eventually be committed).",
        "createdAt" : "2020-12-09T01:05:37Z",
        "updatedAt" : "2020-12-09T01:21:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 321,
    "diffHunk" : "@@ -1,1 +544,548 @@            //\n            // crash case:\n            //   p-0: 10 rec + C   +   4 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n            //   p-1: 10 rec + C   +   5 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n            //   p-2: 10 rec + C   +   5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C"
  },
  {
    "id" : "9579c925-5e75-4940-bfdc-f48d6458ddc6",
    "prId" : 9688,
    "prUrl" : "https://github.com/apache/kafka/pull/9688#pullrequestreview-547573925",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb8bc40d-e2bc-4115-a0ce-9de2d3a6ea28",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "nit: second failed client?",
        "createdAt" : "2020-12-08T06:15:06Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c95c173d-bde9-4107-a853-afaa002f5b4b",
        "parentId" : "eb8bc40d-e2bc-4115-a0ce-9de2d3a6ea28",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I think \"failed second client\" is correct. It's the 2nd client, which has failed, not the 2nd client to have failed (English is confusing 😣 )",
        "createdAt" : "2020-12-08T19:46:46Z",
        "updatedAt" : "2020-12-09T01:21:10Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e9d366764c808221965bab32abe36ba2a0b475c",
    "line" : 309,
    "diffHunk" : "@@ -1,1 +536,540 @@\n            // 7. only for crash case:\n            //     7a. restart the failed second client in eos-alpha mode and wait until rebalance stabilizes\n            //     7b. write third batch of input data\n            //         * fail the first (i.e., eos-beta) client during commit"
  },
  {
    "id" : "916447b8-b770-4272-8266-1b3bcc898f97",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-571703228",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef697167-22e4-4ea2-9264-0c46de944a52",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Using just `PENDING_ERROR -> ERROR` because the transition to `PENDING_ERROR` can be from multiple sources. Also that transition is already tested so this check implies it",
        "createdAt" : "2021-01-19T22:10:07Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +115,119 @@        Collections.unmodifiableList(\n            Collections.singletonList(\n                KeyValue.pair(State.PENDING_ERROR, State.ERROR)\n            )\n        );"
  },
  {
    "id" : "2886be0c-2349-4be6-8cdf-853efeee5298",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-573770376",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4751c765-d87d-4cb1-b703-12cfa4a68e1b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Can we add the expected transitions, too? Easier to debug if the test fails.",
        "createdAt" : "2021-01-21T21:15:05Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1f0873dd-9222-41ea-adb6-a4f63948b1d9",
        "parentId" : "4751c765-d87d-4cb1-b703-12cfa4a68e1b",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "sure that is fine",
        "createdAt" : "2021-01-21T21:58:12Z",
        "updatedAt" : "2021-01-21T22:43:32Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 128,
    "diffHunk" : "@@ -1,1 +995,999 @@            () -> observed.containsAll(expected),\n            MAX_WAIT_TIME_MS,\n            () -> \"Client did not have the expected state transition on time. Observers transitions: \" + observed\n                    + \"Expected transitions: \" + expected\n        );"
  },
  {
    "id" : "2b999523-7464-4f81-b275-4c6fdd0249de",
    "prId" : 9733,
    "prUrl" : "https://github.com/apache/kafka/pull/9733#pullrequestreview-557409139",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2e31ff7-8824-4f92-a531-4710cb5e2ae5",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: missing space between `or` (line above) and `there`",
        "createdAt" : "2020-12-22T22:45:00Z",
        "updatedAt" : "2021-01-15T11:35:43Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "62cbfb648aed3469ba546b80f7de7060f0934583",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +139,143 @@    private final static String APP_DIR_2 = \"appDir2\";\n    private final static String UNEXPECTED_EXCEPTION_MSG = \"Fail the test since we got an unexpected exception, or \" +\n        \"there are too many exceptions thrown, please check standard error log for more info.\";\n    private final String storeName = \"store\";\n"
  }
]