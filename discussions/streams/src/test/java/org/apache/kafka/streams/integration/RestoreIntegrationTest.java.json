[
  {
    "id" : "39f26cc8-9060-4c0f-8bfa-2a34b2006286",
    "prId" : 5163,
    "prUrl" : "https://github.com/apache/kafka/pull/5163#pullrequestreview-127747977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c8e578f-6fda-4f27-9383-c762c6cbd838",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we use a delta, here, instead of the actual offset we want to commit (ie, 4000) ? Might be simpler to understand the test?",
        "createdAt" : "2018-06-10T20:47:24Z",
        "updatedAt" : "2018-06-11T17:05:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2f790c19-c869-42e7-9940-c387ae4172bf",
        "parentId" : "5c8e578f-6fda-4f27-9383-c762c6cbd838",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "The reason is that in line 150, I need to check exactly how many data were processed, which should be the diff between committed offset to log end offset.\r\n\r\nHowever, for log end offset it is not always numKeys / 2 (num.partitions). In my tests I saw for example 5005 and 4995. So I have to use the limit to say `commit at the log end offset minus that delta`.",
        "createdAt" : "2018-06-11T16:42:17Z",
        "updatedAt" : "2018-06-11T17:05:19Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "696dd680-217b-420f-8fdb-479db9035e08",
        "parentId" : "5c8e578f-6fda-4f27-9383-c762c6cbd838",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack.",
        "createdAt" : "2018-06-11T21:26:03Z",
        "updatedAt" : "2018-06-11T21:26:03Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca40f17ef652a219d23b27ed11e2e8d9dbb748ca",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +129,133 @@        final int offsetCheckpointed = 1000;\n        createStateForRestoration(INPUT_STREAM);\n        setCommittedOffset(INPUT_STREAM, offsetLimitDelta);\n\n        final StateDirectory stateDirectory = new StateDirectory(new StreamsConfig(props), new MockTime());"
  },
  {
    "id" : "99f93d93-f763-42d7-b0dc-bb2dc0978afc",
    "prId" : 5163,
    "prUrl" : "https://github.com/apache/kafka/pull/5163#pullrequestreview-127409417",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b5a4e83-a69e-438c-bbd0-323e10635e0f",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: indention should only be 4 spaces?",
        "createdAt" : "2018-06-10T20:48:53Z",
        "updatedAt" : "2018-06-11T17:05:19Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ca40f17ef652a219d23b27ed11e2e8d9dbb748ca",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +208,212 @@\n        builder.table(INPUT_STREAM, Consumed.with(Serdes.Integer(), Serdes.Integer()), Materialized.as(\"store\"))\n                .toStream()\n                .foreach(new ForeachAction<Integer, Integer>() {\n                    @Override"
  }
]