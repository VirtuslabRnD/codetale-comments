[
  {
    "id" : "2ac4cdbd-355c-4ae4-a4a7-4e75190cc3dd",
    "prId" : 4305,
    "prUrl" : "https://github.com/apache/kafka/pull/4305#pullrequestreview-84956183",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5f2c688-04e5-4f64-9538-b4b4917b55d0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I assume this fails, because KS is still running. This is a valid test, but does test if `StreamsResetter` fails for non-existing topic. ",
        "createdAt" : "2017-12-19T18:31:57Z",
        "updatedAt" : "2017-12-30T19:18:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "3db25f4d-711f-45a6-92e6-60ca26936c4e",
        "parentId" : "f5f2c688-04e5-4f64-9538-b4b4917b55d0",
        "authorId" : "bc886239-fe1b-4ce1-88aa-f750be340c11",
        "body" : "Let me change the input-topics in the parameterlist. Then i believe this should fail for sure.",
        "createdAt" : "2017-12-21T02:45:40Z",
        "updatedAt" : "2017-12-30T19:18:11Z",
        "lastEditedBy" : "bc886239-fe1b-4ce1-88aa-f750be340c11",
        "tags" : [
        ]
      }
    ],
    "commit" : "4536903c0669ad0556c2f2257c97f0deb703dbd7",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +631,635 @@        streams.start();\n\n        final int exitCode = new StreamsResetter().run(parameters, cleanUpConfig);\n        Assert.assertEquals(1, exitCode);\n"
  },
  {
    "id" : "0df5800b-a977-4e64-a2d0-0cb0a5ae22d1",
    "prId" : 4446,
    "prUrl" : "https://github.com/apache/kafka/pull/4446#pullrequestreview-90677504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67d7e80f-2ca2-45f6-aec5-9e40c9b7faf4",
        "parentId" : null,
        "authorId" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "body" : "Are we sure we want `while(true)`? Should we not give up after some period of time so the build doesn't hang?\r\n\r\nAlso, why can't we just put a longer wait in the `TestUtils.waitForCondition(...)`?",
        "createdAt" : "2018-01-19T11:05:29Z",
        "updatedAt" : "2018-01-19T11:05:29Z",
        "lastEditedBy" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "tags" : [
        ]
      },
      {
        "id" : "87a03fb3-21ee-406b-86e3-3e2ee5a9beae",
        "parentId" : "67d7e80f-2ca2-45f6-aec5-9e40c9b7faf4",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The `while(true)` was in the code before the rewrite an not an issue.\r\n\r\nA long wait won't do as `TestUtils.waitForCondition(...)` throws an `AsssertionException` if its wait time passed, while we get a `TimeoutException` from the request itself here if the broker is not available yet. I guess, we could increase the timeout for the request, but we reuse the same condition on other places and their we don't want to have  timeout -- could parametrize it of course....\r\n\r\nLet me know what you think.",
        "createdAt" : "2018-01-19T22:29:23Z",
        "updatedAt" : "2018-01-19T22:29:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "ea366316-dc66-467a-81f4-6e65cbb20d3d",
        "parentId" : "67d7e80f-2ca2-45f6-aec5-9e40c9b7faf4",
        "authorId" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "body" : "no probs - leave as is then",
        "createdAt" : "2018-01-23T00:45:38Z",
        "updatedAt" : "2018-01-23T00:45:38Z",
        "lastEditedBy" : "2c9c4dbb-be9d-424e-8d8a-9f3d67f8372b",
        "tags" : [
        ]
      }
    ],
    "commit" : "3400d4b5c7976d68c00cc15625da429f83546bd9",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +173,177 @@\n        // busy wait until cluster (ie, ConsumerGroupCoordinator) is available\n        while (true) {\n            Thread.sleep(50);\n"
  },
  {
    "id" : "91fa0ad0-8cda-4210-a394-ec253401b938",
    "prId" : 4491,
    "prUrl" : "https://github.com/apache/kafka/pull/4491#pullrequestreview-94481059",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce4108eb-4967-4e26-b9e0-daaa9baba671",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need to generate a new object each time?",
        "createdAt" : "2018-02-06T02:20:51Z",
        "updatedAt" : "2018-02-14T00:45:15Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c17ab942-d176-4622-9f1f-87c062337a3f",
        "parentId" : "ce4108eb-4967-4e26-b9e0-daaa9baba671",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We cannot create an object before any tests are run, because `appID` is not initialized and that would cause test to pause. This is actually the root cause of the failure before.",
        "createdAt" : "2018-02-06T19:45:31Z",
        "updatedAt" : "2018-02-14T00:45:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a66a86136a04896102819d5c5e6da66a44ba46a",
    "line" : 149,
    "diffHunk" : "@@ -1,1 +182,186 @@\n        // busy wait until cluster (ie, ConsumerGroupCoordinator) is available\n        TestUtils.waitForCondition(new ConsumerGroupInactiveCondition(), TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT,\n                \"Test consumer group \" + appID + \" still active even after waiting \" + (TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT) + \" ms.\");\n"
  },
  {
    "id" : "e3e224f5-7c20-4025-8658-6fafa3728a1b",
    "prId" : 4611,
    "prUrl" : "https://github.com/apache/kafka/pull/4611#pullrequestreview-99014854",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d8c3027-99c1-47ac-a60d-faec3f3c6149",
        "parentId" : null,
        "authorId" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "body" : "Seems to have been a bug that we used `--input-topics` before.",
        "createdAt" : "2018-02-23T07:50:45Z",
        "updatedAt" : "2018-02-23T18:45:00Z",
        "lastEditedBy" : "5c21df64-97d8-46ab-9722-a7e9ba1d7c49",
        "tags" : [
        ]
      },
      {
        "id" : "6399718c-6af3-4a2a-8aa2-028f5e50d510",
        "parentId" : "1d8c3027-99c1-47ac-a60d-faec3f3c6149",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "+1.",
        "createdAt" : "2018-02-23T17:59:15Z",
        "updatedAt" : "2018-02-23T18:45:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "db96935a-f021-4588-83b4-1a571695572f",
        "parentId" : "1d8c3027-99c1-47ac-a60d-faec3f3c6149",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack.",
        "createdAt" : "2018-02-23T18:55:35Z",
        "updatedAt" : "2018-02-23T18:57:35Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3ff2fbd8960772e0fe6981d1053d0c2e05552250",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +260,264 @@            \"--application-id\", appID,\n            \"--bootstrap-servers\", cluster.bootstrapServers(),\n            \"--intermediate-topics\", NON_EXISTING_TOPIC,\n            \"--execute\"\n        };"
  },
  {
    "id" : "863ba0af-fbda-4482-951c-ebcf1b74e16b",
    "prId" : 6751,
    "prUrl" : "https://github.com/apache/kafka/pull/6751#pullrequestreview-242856937",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1496555e-a094-409c-b1f0-19b57b95166b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "```suggestion\r\n        final String[] parameters = parameterList.toArray();\r\n```",
        "createdAt" : "2019-05-28T14:43:16Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "181b2f51-0fce-4b4c-af1e-eebca8780cb4",
        "parentId" : "1496555e-a094-409c-b1f0-19b57b95166b",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "If we're not going to pre-size the array, then giving it an empty array is equivalent to not passing in an array at all.",
        "createdAt" : "2019-05-28T14:57:05Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "c7948174-65ce-48d7-82e5-735abed73598",
        "parentId" : "1496555e-a094-409c-b1f0-19b57b95166b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We need to pass in the array to resolve the type. Otherwise the return type is `Object[]` instead of `String[]` and we would need to cast.",
        "createdAt" : "2019-05-28T18:48:16Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f06e10cec644ff9e471ead47982151bbe1e63d0",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +571,575 @@        }\n\n        final String[] parameters = parameterList.toArray(new String[0]);\n\n        final Properties cleanUpConfig = new Properties();"
  },
  {
    "id" : "746b4faa-99dc-4a14-beec-66eda499530c",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-353413525",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c022df82-2099-4d72-bf86-f7fb54a6cfef",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "new method create in test utils class to make is reusable",
        "createdAt" : "2020-02-05T01:19:31Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +173,177 @@        prepareEnvironment();\n\n        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);\n\n        cluster.deleteAndRecreateTopics(INPUT_TOPIC, OUTPUT_TOPIC, OUTPUT_TOPIC_2, OUTPUT_TOPIC_2_RERUN);"
  },
  {
    "id" : "48bdcce7-eccc-4229-bcd1-ed24becc4af3",
    "prId" : 8589,
    "prUrl" : "https://github.com/apache/kafka/pull/8589#pullrequestreview-417243990",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67c6eff0-25ea-456b-8898-44366e0b91be",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "What does `\"\" + ` mean?",
        "createdAt" : "2020-05-21T16:35:08Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "20b19b8a-68c9-4597-a429-f483285c0130",
        "parentId" : "67c6eff0-25ea-456b-8898-44366e0b91be",
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "Without the `\"\" +` to convert the value to String, we will get exception like: it is because `STREAMS_CONSUMER_TIMEOUT = 2000L`, `\"\"+` is widely used in this test, just follow it here without any change to not enlarge the scope of this PR, I can help to create a Jira to enhance it if we think this workaround is not quite intuitive~\r\n\r\n```\r\norg.apache.kafka.common.config.ConfigException: Invalid value 200000 for configuration session.timeout.ms: Expected value to be a 32-bit integer, but it was a java.lang.Long\r\n        at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:672)\r\n        at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:474)\r\n        at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:467)\r\n        at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:108)\r\n        at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:129)\r\n        at org.apache.kafka.clients.consumer.ConsumerConfig.<init>(ConsumerConfig.java:606)\r\n        at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:630)\r\n        at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getRestoreConsumer(DefaultKafkaClientSupplier.java:56)\r\n        at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:313)\r\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:766)\r\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:652)\r\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:562)\r\n        at org.apache.kafka.streams.integration.AbstractResetIntegrationTest.testResetWhenLongSessionTimeoutConfiguredWithForceOption(AbstractResetIntegrationTest.java:270)\r\n        at org.apache.kafka.streams.integration.ResetIntegrationTest.testResetWhenLongSessionTimeoutConfiguredWithForceOption(ResetIntegrationTest.java:77)\r\n\r\n``` ",
        "createdAt" : "2020-05-22T07:16:49Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      },
      {
        "id" : "0993b95e-efa5-474b-9c6d-6586e602909e",
        "parentId" : "67c6eff0-25ea-456b-8898-44366e0b91be",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "I see, this is indeed weird, please file a JIRA so that we could clean in a follow-up PR if others feel the same way.",
        "createdAt" : "2020-05-22T16:20:11Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "0cab9aaf-6d3d-4773-bbb4-a9260230ab2b",
        "parentId" : "67c6eff0-25ea-456b-8898-44366e0b91be",
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "Created https://issues.apache.org/jira/browse/KAFKA-10035 for tracking, thanks!",
        "createdAt" : "2020-05-23T02:44:53Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      }
    ],
    "commit" : "5329315b0fba569e0ffd1e3c2d8cbea002a684ba",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +266,270 @@        appID = testId + \"-with-force-option\";\n        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);\n\n        // Run"
  },
  {
    "id" : "a218204a-da40-411e-864a-87399a89b39f",
    "prId" : 8589,
    "prUrl" : "https://github.com/apache/kafka/pull/8589#pullrequestreview-419499056",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1744047a-65b0-4e70-90cc-c39e5abdbc24",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we need this part? Seems sufficient to end the test here?",
        "createdAt" : "2020-05-27T02:51:46Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "09393fdb-e698-42bb-adc2-a4d0e5283c79",
        "parentId" : "1744047a-65b0-4e70-90cc-c39e5abdbc24",
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "This is to verify that after the `successfully force removal of active members`, the stream application re-run can send exactly the same records again to the output topics",
        "createdAt" : "2020-05-27T15:48:10Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      },
      {
        "id" : "2d24deb2-1d75-4611-87b9-4601feca49ec",
        "parentId" : "1744047a-65b0-4e70-90cc-c39e5abdbc24",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Seems redundant as tested somewhere else. And the purpose of the test is to verify `--force` itself. This additional checks have nothing to do with `--force` IMHO. It seems best to keep test to a \"minimum\". ",
        "createdAt" : "2020-05-27T17:37:06Z",
        "updatedAt" : "2020-05-27T18:01:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "af68b580-b5e0-4aeb-bea5-dbd448456fe8",
        "parentId" : "1744047a-65b0-4e70-90cc-c39e5abdbc24",
        "authorId" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "body" : "Yeah, I totally agree with: `It seems best to keep test to a \"minimum\".`\r\nNot sure if my understanding is correct, but I still think the tests for `resetter` should compare the first run and re-run results, from the test's perspective, it cannot assume that `--force` option won't do something underneath that make the re-run produce different results. \r\nBut I'm ok to remove the RE-RUN part if we do think it's redundant.",
        "createdAt" : "2020-05-27T18:23:50Z",
        "updatedAt" : "2020-05-27T18:23:51Z",
        "lastEditedBy" : "410e5da8-f561-43d9-a4a1-a8ffb52d0269",
        "tags" : [
        ]
      },
      {
        "id" : "94aa7562-f134-4948-9bb8-77efb364c4d1",
        "parentId" : "1744047a-65b0-4e70-90cc-c39e5abdbc24",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Fair enough. Let's leave it as-is.",
        "createdAt" : "2020-05-27T18:28:43Z",
        "updatedAt" : "2020-05-27T18:28:43Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5329315b0fba569e0ffd1e3c2d8cbea002a684ba",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +289,293 @@        assertInternalTopicsGotDeleted(null);\n\n        // RE-RUN\n        streams.start();\n        final List<KeyValue<Long, Long>> resultRerun = IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived(resultConsumerConfig, OUTPUT_TOPIC, 10);"
  },
  {
    "id" : "2faa8f4a-74d0-4ea9-b4f9-09ceb9acd1b9",
    "prId" : 8679,
    "prUrl" : "https://github.com/apache/kafka/pull/8679#pullrequestreview-414845201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22ab1dd7-7c0f-449f-9891-65d117a52055",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We still need to test this, because topics using this pattern are still consider _intermediate_ topics and the `--intermediat-topic` flag in `StreamsResetter` is still useful and not changed.",
        "createdAt" : "2020-05-17T03:02:21Z",
        "updatedAt" : "2020-05-21T21:48:53Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "4b226b41-5072-4779-abf0-173b702b0645",
        "parentId" : "22ab1dd7-7c0f-449f-9891-65d117a52055",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I'm wondering if we should continue testing with `through`, to ensure it continues to work. WDYT?",
        "createdAt" : "2020-05-19T19:23:49Z",
        "updatedAt" : "2020-05-21T21:48:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "feb606a2-081b-4797-8dc9-bc992c0e9e12",
        "parentId" : "22ab1dd7-7c0f-449f-9891-65d117a52055",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well, `through()` is literally implemented as `to()` + `stream()`... But I can revert and add a suppress annotation, too.",
        "createdAt" : "2020-05-19T20:25:39Z",
        "updatedAt" : "2020-05-21T21:48:54Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "df748c0a-11af-4b4f-8147-107d812f3611",
        "parentId" : "22ab1dd7-7c0f-449f-9891-65d117a52055",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "On re-reading, I realize I misunderstood the situation. I revert my comment :grimacing: . ",
        "createdAt" : "2020-05-19T21:43:18Z",
        "updatedAt" : "2020-05-21T21:48:54Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfcb6a3dce9ea006c43ddc1d502eccb07f879c10",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +499,503 @@        } else {\n            input.to(INTERMEDIATE_USER_TOPIC);\n            stream = builder.stream(INTERMEDIATE_USER_TOPIC);\n        }\n        stream.groupByKey()"
  },
  {
    "id" : "67db6405-a3d6-416d-97f4-10821c2ae6f5",
    "prId" : 8864,
    "prUrl" : "https://github.com/apache/kafka/pull/8864#pullrequestreview-430091536",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e78524d-1d4a-4d93-a577-6cff029d1d7b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just some side cleanup. Method does not throw anything",
        "createdAt" : "2020-06-13T00:16:46Z",
        "updatedAt" : "2020-07-21T00:12:06Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e6c10d88f9c6fa9d89cc500112255898e2f24845",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +188,192 @@    }\n\n    private void add10InputElements() {\n        final List<KeyValue<Long, String>> records = Arrays.asList(KeyValue.pair(0L, \"aaa\"),\n                                                                   KeyValue.pair(1L, \"bbb\"),"
  }
]