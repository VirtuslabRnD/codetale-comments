[
  {
    "id" : "d7420603-aae8-4cd2-aed7-6c228bc43604",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-329943278",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "277a061d-315c-4a59-a0c6-4727b2540eea",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This test builds on a basic relational data caricature: a set of articles, each with a set of comments on them.\r\n\r\nWe're doing a couple of \"relational data\" operations to derive the \"augmented\" equivalents of the input data:\r\n* traverse the `Comment-[articleId]->Article` relationship to extract the prefix of the article text and add it to the comment's data structure.\r\n* aggregate the number of comments on each article and add it to the article's data structure.\r\n\r\nThe first operation is using the new feature. The second was already supported in Streams. I'm thinking that if this test proves to be stable, we can flesh it out even more to eventually subsume the other smoke test.",
        "createdAt" : "2019-11-08T03:00:16Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "7c486fef-abd2-49ff-b7bf-b45377ea6177",
        "parentId" : "277a061d-315c-4a59-a0c6-4727b2540eea",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "> I'm thinking that if this test proves to be stable, we can flesh it out even more to eventually subsume the other smoke test.\r\n\r\nTotally, we have too many overlapping `XXXSmokeTest` now and I think we should just consider having one and also trim out system test suite too.\r\n\r\nCould you file a JIRA as a tech debt cleanup?",
        "createdAt" : "2019-11-08T21:50:55Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "706084d1-4dd2-48dd-8f2b-7f88e4651bee",
        "parentId" : "277a061d-315c-4a59-a0c6-4727b2540eea",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Also could you actually add a javadoc section on top of the class with the above description about the application's logic? \r\n\r\n#`put your PR comment into code comment` :P",
        "createdAt" : "2019-11-08T22:02:15Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "f7a5d55f-357f-4f74-b2c1-413b6a7b2d12",
        "parentId" : "277a061d-315c-4a59-a0c6-4727b2540eea",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Filed https://issues.apache.org/jira/browse/KAFKA-9289",
        "createdAt" : "2019-12-10T15:54:08Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +105,109 @@    }\n\n    public static class Article {\n        private final int key;\n        private final long timestamp;"
  },
  {
    "id" : "7dc766f8-4fc9-408f-a318-044176fc1908",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-313755927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4422c9e-b17b-45bc-9c38-77b5d7415f78",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note, running with EOS so that we can verify the results are exactly correct.",
        "createdAt" : "2019-11-08T03:20:29Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 646,
    "diffHunk" : "@@ -1,1 +644,648 @@                    mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, application),\n                    mkEntry(StreamsConfig.CLIENT_ID_CONFIG, id),\n                    mkEntry(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE),\n                    mkEntry(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, \"1000\"),\n                    mkEntry(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\"),"
  },
  {
    "id" : "e45ea8da-e99b-48af-b314-196c0bc04f51",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-314477982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4797c795-1c92-474b-b34f-bccb2f06e137",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Note for those familiar with the other smoke test:\r\n\r\nThis verification works by consuming the same inputs as the topology and then computing what the topology should have computed, given those inputs. Thus, it doesn't depend on every message from the producers actually being delivered exactly once (which is responsible for quite a bit of complexity and flakiness in the other test).",
        "createdAt" : "2019-11-08T03:25:10Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "b92d7c75-980d-445a-bd9a-65ae10757eef",
        "parentId" : "4797c795-1c92-474b-b34f-bccb2f06e137",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "That's great!",
        "createdAt" : "2019-11-08T22:08:29Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 672,
    "diffHunk" : "@@ -1,1 +670,674 @@        }\n\n        public static boolean verifySync(final String broker, final Instant deadline) throws InterruptedException {\n            final Deserializer<Integer> keyDeserializer = intSerde.deserializer();\n"
  },
  {
    "id" : "5ce70b40-6c0a-4bed-bee1-f1b016745864",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-313755927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ce76ed2-ed20-4888-84f7-b79a4191029c",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This also builds on another lesson learned from the other test. Instead of trying to figure out when we've consumed \"all\" the data, we just keep trying to get a passing result until the deadline. The verification logic itself checks to see if we have gotten at least some input data, so it won't pass trivially.",
        "createdAt" : "2019-11-08T03:28:07Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 725,
    "diffHunk" : "@@ -1,1 +723,727 @@                boolean passed = false;\n\n                while (!passed && Instant.now().isBefore(deadline)) {\n                    boolean lastPollWasEmpty = false;\n                    while (!lastPollWasEmpty) {"
  },
  {
    "id" : "5bb1856b-5aac-4cdb-822d-25da4f1b41a9",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-313755927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5a85e2e-71e6-4904-8ec2-15006aa31f58",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "These messages are used by the python code to wait for until the first result output has been observed. This is probably a better wait condition than what we used in the other smoke test (a line printed in a peek in the topology itself), because it means not only that a record got polled, but that it got fully processed and committed in a transaction to the output topic.",
        "createdAt" : "2019-11-08T03:29:41Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 781,
    "diffHunk" : "@@ -1,1 +779,783 @@                    }\n                    if (!printedConsumedAugmentedComment && !consumedAugmentedComments.isEmpty()) {\n                        LOG.info(\"Consumed first AugmentedComment\");\n                        printedConsumedAugmentedComment = true;\n                    }"
  },
  {
    "id" : "1126111d-a52d-49cd-a018-faae5d319082",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-313755927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5662c66f-79e3-4e64-ac87-4198a5ec0db6",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Here's the actual input vs. output data integrity verification.",
        "createdAt" : "2019-11-08T03:32:52Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 826,
    "diffHunk" : "@@ -1,1 +824,828 @@        }\n\n        static boolean verifySync(final boolean logResults,\n                                  final Map<Integer, Article> consumedArticles,\n                                  final Map<Integer, Comment> consumedComments,"
  },
  {
    "id" : "ad0921c7-f6ad-47bd-ad1e-af762799e6c8",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-321301268",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac189ebc-5d2f-4780-a5c2-ed28210db538",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ahh now I remember why I still love Scala (not a comment :P).",
        "createdAt" : "2019-11-08T21:51:33Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "21828364-084f-4a94-a733-a67832c1361a",
        "parentId" : "ac189ebc-5d2f-4780-a5c2-ed28210db538",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "For real. ",
        "createdAt" : "2019-11-22T02:12:45Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 228,
    "diffHunk" : "@@ -1,1 +226,230 @@        }\n\n        public static class CommentSerializer implements Serializer<Comment> {\n\n            @Override"
  },
  {
    "id" : "6ba66da9-ef7d-4987-9ee5-98b4d8ab1c18",
    "prId" : 7664,
    "prUrl" : "https://github.com/apache/kafka/pull/7664#pullrequestreview-314477982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c952c13f-c73c-440d-8672-f9e34ee4015a",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice one on projecting the value!",
        "createdAt" : "2019-11-08T22:03:55Z",
        "updatedAt" : "2019-12-10T16:19:00Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5332705c02453ef86b4a7926d4d1bd8927f19f5c",
    "line" : 616,
    "diffHunk" : "@@ -1,1 +614,618 @@\n            final KTable<Integer, Long> commentCounts =\n                comments.groupBy((key, value) -> new KeyValue<>(value.getArticleId(), (short) 1),\n                                 Grouped.with(Serdes.Integer(), Serdes.Short()))\n                        .count();"
  },
  {
    "id" : "2dc7c2b4-991a-4805-b796-749ed2b5c217",
    "prId" : 8443,
    "prUrl" : "https://github.com/apache/kafka/pull/8443#pullrequestreview-390214621",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7506b932-fc20-4d43-ae9f-c1803647a01f",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Reading from the comment, the RelationalSmokeTest has nothing to do with EOS, why do we need to expand this test? cc @vvcephei ",
        "createdAt" : "2020-04-08T02:30:21Z",
        "updatedAt" : "2020-04-09T01:45:12Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "3008af65-17c4-46f6-9ea1-e1c9b0c6d7f0",
        "parentId" : "7506b932-fc20-4d43-ae9f-c1803647a01f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The test had EOS enabled. So I extended it to now run with both EOS versions.",
        "createdAt" : "2020-04-08T05:42:18Z",
        "updatedAt" : "2020-04-09T01:45:12Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "e8a65727-e60e-4a3c-98ed-35f344cd92d2",
        "parentId" : "7506b932-fc20-4d43-ae9f-c1803647a01f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I think it worth adding both eos mode for this test --- if we only have this test with eos-beta there may be some regressions not captured.\r\n\r\nIn the future, when we deprecate eos-alpha in some release version that requires broker > 2.5 we can remove eos-alpha parameters in all these.",
        "createdAt" : "2020-04-08T18:12:32Z",
        "updatedAt" : "2020-04-09T01:45:12Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "6f7ee56278adb524ab04ec1cde667ec8e06e69ed",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +638,642 @@                                           final String application,\n                                           final String id,\n                                           final String processingGuarantee,\n                                           final String stateDir) {\n            return mkProperties("
  },
  {
    "id" : "d7470d71-1b72-4ef7-92a1-92a07891e46d",
    "prId" : 10631,
    "prUrl" : "https://github.com/apache/kafka/pull/10631#pullrequestreview-652104507",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74eada57-7efe-43bb-ac12-f24edf949752",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "nit: I think that should be formatted like:\r\n\r\n```\r\nassertThat(\r\n    pass,\r\n    report,\r\n    \"comment missing, but found in augmentedComment: \" + key,\r\n    consumedComments.containsKey(key)\r\n);\r\n```",
        "createdAt" : "2021-05-05T09:32:46Z",
        "updatedAt" : "2021-05-05T14:19:10Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "400d0d30e4a6cd006b66556f3fe16b19a93f4e81",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +860,864 @@                        \"comment missing, but found in augmentedComment: \" + key,\n                        consumedComments.containsKey(key)\n                );\n\n                final Comment comment = consumedComments.get(key);"
  }
]