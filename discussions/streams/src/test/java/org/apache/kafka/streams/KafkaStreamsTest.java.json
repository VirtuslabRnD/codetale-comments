[
  {
    "id" : "a0b66daa-c58e-46d4-a3c6-426a73d4f930",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-145830144",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58626ce9-9edb-40e5-9704-4bdf42eb33a7",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is the config to shorten integration test, ditto elsewhere.",
        "createdAt" : "2018-08-10T22:25:24Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e5326429-aafe-4ede-90c7-a6d15b0b94ce",
        "parentId" : "58626ce9-9edb-40e5-9704-4bdf42eb33a7",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "very nice!",
        "createdAt" : "2018-08-13T20:50:19Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +87,91 @@        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);\n        props.put(IntegrationTestUtils.INTERNAL_LEAVE_GROUP_ON_CLOSE, true);\n        streams = new KafkaStreams(builder.build(), props);\n    }"
  },
  {
    "id" : "4ea3025b-a587-4f38-9b15-7040a2ce48b6",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-153572230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d930cce0-d7dd-40ac-a130-4e8643330935",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ditto here, for this test we can still reuse the shared streams.",
        "createdAt" : "2018-09-07T15:57:06Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c924487e-c1aa-403d-8610-6cdc4b077add",
        "parentId" : "d930cce0-d7dd-40ac-a130-4e8643330935",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not here. We need to get `oldInitCount = MockMetricsReporter.INIT_COUNT.get();` before we create `new KafkaStreams()` instance.",
        "createdAt" : "2018-09-09T05:54:06Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 338,
    "diffHunk" : "@@ -1,1 +286,290 @@            assertTrue(\"some reporters should be initialized by calling on construction\", initDiff > 0);\n\n            streams.start();\n            final int oldCloseCount = MockMetricsReporter.CLOSE_COUNT.get();\n            streams.close();"
  },
  {
    "id" : "5174d081-abd3-4f3b-8590-4f1e30ff7fb5",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-155234061",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just out of curiosity, how does this differ from the following?\r\n```\r\nassertTrue(streams.close(10, TimeUnit.SECONDS));\r\n``` ",
        "createdAt" : "2018-09-10T17:08:17Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "1826da7b-48a0-4d1f-92c4-34b8fb139daf",
        "parentId" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure... Seems we could rewrite it. \\cc @guozhangwang @bbejeck WDYT?",
        "createdAt" : "2018-09-11T01:01:40Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f0084740-3b37-43be-8a3f-2e89ff4dd1ca",
        "parentId" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "none from what I can see, but I'm not sure it's worth holding up the PR for it.",
        "createdAt" : "2018-09-13T19:21:35Z",
        "updatedAt" : "2018-09-13T19:21:35Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +143,147 @@            () -> streams.state() == KafkaStreams.State.NOT_RUNNING,\n            10 * 1000,\n            \"Streams never stopped.\");\n\n        // Ensure that any created clients are closed"
  },
  {
    "id" : "c39aad5f-2df5-45f7-84fa-8dfdfbe5a58f",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-155229512",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The fact that we are having to do this in our tests suggests to me that maybe we should think about making KafkaStreams `AutoCloseable`. Should I go ahead and make a jira for this?",
        "createdAt" : "2018-09-10T17:12:57Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "e40d0279-67a2-4ad6-9caa-00050f30b0ec",
        "parentId" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "In general I am in favor to this. \\cc @guozhangwang @bbejeck Thoughts?",
        "createdAt" : "2018-09-11T01:03:21Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5b07d292-1c96-4597-a1f2-3732a84335fd",
        "parentId" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "+1 for me on `AutoCloseable`",
        "createdAt" : "2018-09-13T19:08:54Z",
        "updatedAt" : "2018-09-13T19:08:54Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 314,
    "diffHunk" : "@@ -1,1 +270,274 @@            streams.start();\n        } finally {\n            streams.close();\n        }\n        // There's nothing to assert... We're testing that this operation actually completes."
  },
  {
    "id" : "58cb0bad-2ee5-4110-b064-2a5517241d41",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fc6a39f-cc35-4773-9e0d-5f668170fb47",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just catching up on this PR. Should we wrap the `close()` into a `finally` block?",
        "createdAt" : "2018-09-21T04:19:50Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +104,108 @@        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);\n        streams.close();\n    }\n"
  },
  {
    "id" : "6a1e08a1-b6a5-4960-807f-fdd215242242",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bd13442-5545-43c0-ad73-c712125ef8b4",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: naming -> `shouldAcceptDefaultBufferSizes()`\r\n\r\nAlso, I am wondering why we check for default buffer size? The ticket was about the issue, that `-1` was not accepted. Thus, while having this test is ok, we should actually test for `-1` to have a test that covers the reported issue.",
        "createdAt" : "2018-09-21T04:25:21Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +100,104 @@\n    @Test\n    public void testOsDefaultSocketBufferSizes() {\n        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);\n        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);"
  },
  {
    "id" : "4644aba4-3f9c-4a56-9939-739a3d65f383",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d6d69011-d8d7-451a-915f-cf54d84bc097",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.",
        "createdAt" : "2018-09-21T04:25:38Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +111,115 @@        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);\n        streams.close();\n    }\n"
  },
  {
    "id" : "f0699ca2-adb0-40f0-8459-64bffd1bbca4",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a56e3a2-5e90-4383-ad90-c0a603388083",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: -> `shouldThrowForInvalidSocketSendBufferSize()`",
        "createdAt" : "2018-09-21T04:26:08Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +108,112 @@\n    @Test(expected = KafkaException.class)\n    public void testInvalidSocketSendBufferSize() {\n        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);"
  },
  {
    "id" : "4420e014-a0bb-47a3-b0aa-38b175b0980e",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acf29b2d-32c1-4390-9721-6a2125badc00",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`",
        "createdAt" : "2018-09-21T04:26:19Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +115,119 @@\n    @Test(expected = KafkaException.class)\n    public void testInvalidSocketReceiveBufferSize() {\n        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);"
  },
  {
    "id" : "7ecbd657-963f-4421-9a38-a80acebaf4ab",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-172240851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81392466-1ff6-4abf-9baa-f693b1d29e3b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for the cleanup!",
        "createdAt" : "2018-11-06T21:32:07Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +144,148 @@\n        Assert.assertEquals(KafkaStreams.State.CREATED, globalStreams.state());\n        Assert.assertEquals(0, stateListener.numChanges);\n\n        globalStreams.start();"
  },
  {
    "id" : "07fa0cb1-ccf2-40b0-b9e0-2d398b73257f",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-172328363",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccb23c09-6ea6-4e65-90e8-5f2709da6f9c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Isn't this case covered by `statelessPAPITopologyShouldNotCreateStateDirectory` ? DSL compiles down into a Topology anyway.\r\n\r\nSimilar below.",
        "createdAt" : "2018-11-06T21:37:08Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5bdc3f49-4a56-4ac6-bf9a-8c1867359fbe",
        "parentId" : "ccb23c09-6ea6-4e65-90e8-5f2709da6f9c",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "DSL tests are removed.",
        "createdAt" : "2018-11-07T03:25:09Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 108,
    "diffHunk" : "@@ -1,1 +595,599 @@\n    @Test\n    public void statelessTopologyShouldNotCreateStateDirectory() throws Exception {\n        final String inputTopic = testName.getMethodName() + \"-input\";\n        final String outputTopic = testName.getMethodName() + \"-output\";"
  },
  {
    "id" : "f7d13bd1-4f6b-4354-85f3-4981aed9def4",
    "prId" : 6185,
    "prUrl" : "https://github.com/apache/kafka/pull/6185#pullrequestreview-195815586",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8322872d-b98e-4b8a-9cd3-3ccaa109b08a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the actual fix: as there are two state transitions, we cannot simply check for six transitions, because if we check too early, and only five transitions finished (or maybe none), `stateListener.numChanges` might still be at 4 or 5.",
        "createdAt" : "2019-01-22T22:14:48Z",
        "updatedAt" : "2019-01-22T22:14:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6e504d93-1ed3-46e3-9617-ee30d3de245d",
        "parentId" : "8322872d-b98e-4b8a-9cd3-3ccaa109b08a",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Thanks for the catch! It was my bad for not capturing it last time I modified this test case.",
        "createdAt" : "2019-01-24T00:55:12Z",
        "updatedAt" : "2019-01-24T00:55:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7efd0e4624f5ed980ee1f900a0146251d52dd17e",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +210,214 @@        TestUtils.waitForCondition(\n            () -> stateListener.numChanges == 6,\n            \"Streams never closed.\");\n        Assert.assertEquals(KafkaStreams.State.NOT_RUNNING, globalStreams.state());\n    }"
  },
  {
    "id" : "5249ff28-b03a-4be0-aea5-d3685f8ab3b7",
    "prId" : 6610,
    "prUrl" : "https://github.com/apache/kafka/pull/6610#pullrequestreview-228867086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why we do not want to verify serde classes here? Although it's trivial seems no harm either.",
        "createdAt" : "2019-04-19T16:14:32Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "1ce56221-8fa6-4515-b9ab-16f0670a436b",
        "parentId" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well. What we want to test is, that `Deserializer#configure()` and `Serializer#configure()` are called. Note, that `Serde#configure()` is not called because we extract the `Deserializer` and `Serializer` from the `Serdes`. Thus, it seems to be a distraction of the test purpose.\r\n\r\nIf we would verify the serdes, we would only verify that `Serde#serializer()` or `Serde#deserializer()` are called. But we know that anyway, because otherwise it's impossible to call `configure()` on the wrapped (de)serializers. Also, technical this test does not care if those method are called.",
        "createdAt" : "2019-04-20T01:27:57Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "04a7ebfc-734e-4365-aeb7-87f158d4fa5f",
        "parentId" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack, that makes sense.",
        "createdAt" : "2019-04-20T05:32:37Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "027e398a4c2a3448305ac7acc81f998f7f00cdcb",
    "line" : 156,
    "diffHunk" : "@@ -1,1 +855,859 @@        }\n\n        verify(\n            mockSourceKeyDeserialzer, mockSourceValueDeserialzer,\n            mockThroughKeySerializer, mockThroughValueSerializer, mockThroughKeyDeserializer, mockThroughValueDeserializer,"
  },
  {
    "id" : "03587145-f250-4cdc-a526-ef2cacec3cf2",
    "prId" : 7382,
    "prUrl" : "https://github.com/apache/kafka/pull/7382#pullrequestreview-294494423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76fadd2c-418f-427d-884c-cc6a847b776d",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Why do you need to prepare `KafkaStreams` for testing? Only classes that are mocked and that are either `final` or have static methods need to be prepared. ",
        "createdAt" : "2019-09-26T11:04:29Z",
        "updatedAt" : "2019-09-27T19:06:51Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "dca89cc7-65ec-44d9-958e-083176eef2ee",
        "parentId" : "76fadd2c-418f-427d-884c-cc6a847b776d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We actually need to prepare `KafkaStreams` for cases like metrics reporter registration.",
        "createdAt" : "2019-09-27T18:29:58Z",
        "updatedAt" : "2019-09-27T19:06:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f40f55cb0194c0daccd982aad3e4eebf68a638f",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +84,88 @@\n@RunWith(PowerMockRunner.class)\n@PrepareForTest({KafkaStreams.class, StreamThread.class})\npublic class KafkaStreamsTest {\n"
  },
  {
    "id" : "2a9e3b86-73ce-46af-8d32-5ed8f654b7cd",
    "prId" : 8540,
    "prUrl" : "https://github.com/apache/kafka/pull/8540#pullrequestreview-404331060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The change to reject an empty topology make our testing rather \"ugly\"... Do we really _need_ to reject it?",
        "createdAt" : "2020-04-24T00:16:06Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "79a87e3e-2d6a-4dc0-ad5f-24e3821a6a26",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Is `getBuilderWithSource` really that much uglier than `new StreamsBuilder`? :P ",
        "createdAt" : "2020-04-24T19:49:00Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "d941ee02-b61c-495e-91e3-c07ae4ee6ee9",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Would a class-level `final StreamsBuilder builder = new StreamsBuilder()` that we add a source to in the setUp be any. better iyo?",
        "createdAt" : "2020-04-24T20:07:02Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "fe543b43-5e88-4a05-ba76-0f4cae27cdec",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think the suggestion was more along the lines of _not_ throwing an exception while building an empty topology.\r\n\r\nI'm not sure. It seems kind of nice to find out right away that your program will do absolutely nothing. I'm not totally sure you could really run an empty topology. Can you subscribe a Consumer to \"no topics\"?",
        "createdAt" : "2020-04-24T23:27:50Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "bc0663ae-12f6-46db-b85a-c44027001286",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I realize he wasn't just complaining about the name, but I was trying to keep that discussion in one thread. But I guess you can only do so much to keep PR chatter oriented in one place ",
        "createdAt" : "2020-04-24T23:47:26Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "a70cb486-4b89-454d-8fef-66f7e3b6f0e6",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "But @vvcephei 's last question gets right to the heart of the matter. The answer being \" technically yes, but it will crash if you try to poll for said nothing, so really no\"\r\nThat's why the test was flaky, and the reason for this PR in the first place (Avoiding group overhead is the name of the ticket, but the reality is it will only happen once before all the StreamThreads die due to polling no topics)",
        "createdAt" : "2020-04-24T23:49:16Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "d3a2e2a7-38f4-46ba-afb1-1412b4c742de",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for clarification.",
        "createdAt" : "2020-05-01T18:44:42Z",
        "updatedAt" : "2020-05-01T18:44:42Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "049e3528b83ded730da75e4b888a8256d4955273",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +331,335 @@    @Test\n    public void testShouldTransitToNotRunningIfCloseRightAfterCreated() {\n        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n        streams.close();\n"
  },
  {
    "id" : "17ef0100-181f-4a4c-a3b0-e998a86a7974",
    "prId" : 9221,
    "prUrl" : "https://github.com/apache/kafka/pull/9221#pullrequestreview-475089291",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8da8060a-cb8f-4f02-a970-355faf890ba2",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Converting to the new API. I didn't want to convert over the AbstractProcessor, since that would drag in more changes. I also didn't introduce a new abstract class, since the only thing it does is capture the context.",
        "createdAt" : "2020-08-26T01:53:36Z",
        "updatedAt" : "2020-09-09T17:34:57Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c37687893a08e3bb056f99cc9927a5c679f80d5d",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +858,862 @@        final Topology topology = new Topology();\n        topology.addSource(\"source\", Serdes.String().deserializer(), Serdes.String().deserializer(), inputTopic)\n                .addProcessor(\"process\", () -> new Processor<String, String, String, String>() {\n                    private ProcessorContext<String, String> context;\n"
  },
  {
    "id" : "673b9daf-10d3-43c4-9eb1-c03877d381f1",
    "prId" : 9361,
    "prUrl" : "https://github.com/apache/kafka/pull/9361#pullrequestreview-500554881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72119888-fbb0-4df6-92fc-e91e5eeec989",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "A good example of updating just the value for the child.",
        "createdAt" : "2020-10-01T21:01:04Z",
        "updatedAt" : "2020-10-02T15:50:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +870,874 @@                    public void process(final Record<String, String> record) {\n                        if (record.value().length() % 2 == 0) {\n                            context.forward(record.withValue(record.key() + record.value()));\n                        }\n                    }"
  },
  {
    "id" : "de512c7a-a944-4732-81cc-6714433ccdb9",
    "prId" : 9361,
    "prUrl" : "https://github.com/apache/kafka/pull/9361#pullrequestreview-500554881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b000372-7093-448e-8c53-eb50324995ec",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "You're going to see a lot of these in the tests.",
        "createdAt" : "2020-10-01T21:01:31Z",
        "updatedAt" : "2020-10-02T15:50:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +973,977 @@                    kvStore.put(record.key(), 5L);\n\n                    context.forward(record.withValue(\"5\"));\n                    context.commit();\n                }"
  },
  {
    "id" : "2b2bcc5d-fa7f-4079-af88-59a1baf4dc19",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-520037303",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d05c083-d6c7-4ca4-a592-1d401bf0778f",
        "parentId" : null,
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "extra line",
        "createdAt" : "2020-10-29T20:13:34Z",
        "updatedAt" : "2020-11-18T03:39:13Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +637,641 @@        assertThrows(NullPointerException.class, () -> streams.setUncaughtExceptionHandler((StreamsUncaughtExceptionHandler) null));\n    }\n\n    @Test\n    public void shouldThrowExceptionSettingStateListenerNotInCreateState() {"
  },
  {
    "id" : "3fcfdff6-35a9-4a4e-8385-1b8f379013ca",
    "prId" : 9695,
    "prUrl" : "https://github.com/apache/kafka/pull/9695#pullrequestreview-549170768",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6bd50eca-adbe-4422-bba3-117e10c41d0e",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Why do you not verify the number of the stream threads also here? ",
        "createdAt" : "2020-12-10T13:59:45Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0ebbdbc44ffe154d5bff5ef93ec3d16748b380c",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +670,674 @@        assertThat(streams.removeStreamThread(), equalTo(Optional.empty()));\n        assertThat(streams.threads.size(), equalTo(1));\n    }\n\n    @Test"
  },
  {
    "id" : "47fefc25-95c9-4b8d-988c-b1f1563cead3",
    "prId" : 9695,
    "prUrl" : "https://github.com/apache/kafka/pull/9695#pullrequestreview-550222989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29c84fa7-dfe3-4e3b-b43d-4858f2c66037",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "A test is missing that verifies the behavior when a stream thread in state `DEAD` is in the list of stream threads.",
        "createdAt" : "2020-12-10T14:04:30Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "bc88fd91-1ffe-4bfa-86c0-186b9a0763d9",
        "parentId" : "29c84fa7-dfe3-4e3b-b43d-4858f2c66037",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "There is no case where a streamThread should be dead in the thread list",
        "createdAt" : "2020-12-10T17:39:13Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "4eaa0373-fa1a-4707-86e6-679b688d5214",
        "parentId" : "29c84fa7-dfe3-4e3b-b43d-4858f2c66037",
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Fair enough! Still we need to test also when a thread in not alive, i.e., `thread.isAlive() == false`",
        "createdAt" : "2020-12-11T10:52:34Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "c22fedd7-7861-47cb-9f75-2cc70a1a19de",
        "parentId" : "29c84fa7-dfe3-4e3b-b43d-4858f2c66037",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Sure added",
        "createdAt" : "2020-12-11T15:56:01Z",
        "updatedAt" : "2021-01-07T20:08:37Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0ebbdbc44ffe154d5bff5ef93ec3d16748b380c",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +671,675 @@        assertThat(streams.threads.size(), equalTo(1));\n    }\n\n    @Test\n    public void testCannotStartOnceClosed() {"
  },
  {
    "id" : "10576bf6-072d-4a40-a129-bba79a3e50dc",
    "prId" : 9720,
    "prUrl" : "https://github.com/apache/kafka/pull/9720#pullrequestreview-549586323",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25ce555b-30c6-4aa6-aa81-4ab3a9f298a0",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "removing stream threads does not put the client in error anymore. The global does",
        "createdAt" : "2020-12-10T20:55:09Z",
        "updatedAt" : "2021-01-21T22:43:31Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e235b62f67fd1b2ab2323750f748e28ad87f9a98",
    "line" : 128,
    "diffHunk" : "@@ -1,1 +590,594 @@        final int oldSize = streams.threads.size();\n        streams.start();\n        globalStreamThread.shutdown();\n        assertThat(streams.addStreamThread(), equalTo(Optional.empty()));\n        assertThat(streams.threads.size(), equalTo(oldSize));"
  },
  {
    "id" : "f77f667b-11de-48af-9527-299727a6d162",
    "prId" : 10666,
    "prUrl" : "https://github.com/apache/kafka/pull/10666#pullrequestreview-659214462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e726e014-0fd3-4af2-8d33-dd95131fc699",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "was this over 100?",
        "createdAt" : "2021-05-13T16:50:04Z",
        "updatedAt" : "2021-05-13T16:50:56Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "816a2a55-67fe-4757-9f91-9f51007adea2",
        "parentId" : "e726e014-0fd3-4af2-8d33-dd95131fc699",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "No, I think this was just left over from when I had added a new parameter which put it over 100, but I took it out when I found a better way to do the test.",
        "createdAt" : "2021-05-13T17:58:32Z",
        "updatedAt" : "2021-05-13T17:58:32Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "e6b7737c-d1b7-4875-978a-c9a29be3a713",
        "parentId" : "e726e014-0fd3-4af2-8d33-dd95131fc699",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "I have no problem leaving them on new lines, just didn't understand why when it didn't change the contents",
        "createdAt" : "2021-05-13T18:38:44Z",
        "updatedAt" : "2021-05-13T18:38:44Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "bdaf8570-72fe-41c9-aa6a-043776224770",
        "parentId" : "e726e014-0fd3-4af2-8d33-dd95131fc699",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Yeah, sorry for the confusion",
        "createdAt" : "2021-05-13T19:06:20Z",
        "updatedAt" : "2021-05-13T19:06:20Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      }
    ],
    "commit" : "49ceac21144871aef24d9f13d2aa0557e6182212",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +301,305 @@    }\n\n    private void prepareStreamThread(final StreamThread thread,\n                                     final int threadId,\n                                     final boolean terminable) throws Exception {"
  },
  {
    "id" : "7346fbb3-9522-4ac5-8a5d-348784883b6c",
    "prId" : 10668,
    "prUrl" : "https://github.com/apache/kafka/pull/10668#pullrequestreview-657306973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5a2cee2-972e-448c-97b7-580dd259ca52",
        "parentId" : null,
        "authorId" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "body" : "How about replacing it by ```assertThrows```?",
        "createdAt" : "2021-05-11T14:44:26Z",
        "updatedAt" : "2021-05-11T14:46:10Z",
        "lastEditedBy" : "0f776378-bb23-4193-9bb0-1db5973f3781",
        "tags" : [
        ]
      },
      {
        "id" : "2acfc284-3dae-4948-8522-ddd3f311693e",
        "parentId" : "f5a2cee2-972e-448c-97b7-580dd259ca52",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "Thinks @chia7712 for review. Nice catch. \r\nShould we create another PR to address this case ?",
        "createdAt" : "2021-05-11T23:23:56Z",
        "updatedAt" : "2021-05-11T23:23:56Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "b74be3a3-babb-47b8-90b2-75565543b9d3",
        "parentId" : "f5a2cee2-972e-448c-97b7-580dd259ca52",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "+1 -- also below in other tests.",
        "createdAt" : "2021-05-11T23:24:37Z",
        "updatedAt" : "2021-05-11T23:24:37Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c53e84a66e8920009c86a14069dc6a7e43d05862",
    "line" : 377,
    "diffHunk" : "@@ -1,1 +655,659 @@            try {\n                streams.start();\n                fail(\"Should have throw IllegalStateException\");\n            } catch (final IllegalStateException expected) {\n                // this is ok"
  },
  {
    "id" : "224bc762-7e53-4f7c-b265-dc8b1ed75916",
    "prId" : 10668,
    "prUrl" : "https://github.com/apache/kafka/pull/10668#pullrequestreview-674498904",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We can remove this line now. `close()` will be cause automatically using try-with-resource clause.",
        "createdAt" : "2021-05-11T23:21:45Z",
        "updatedAt" : "2021-05-11T23:21:46Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1e7e0cc0-c7a1-46da-9a30-f41391c779d0",
        "parentId" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "Thanks @mjsax for review. Will do.",
        "createdAt" : "2021-05-11T23:27:40Z",
        "updatedAt" : "2021-05-11T23:27:40Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "a9039dc4-fd7f-4f5b-a25a-3a1d8b2b197f",
        "parentId" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "@mjsax We should not remove this line, otherwise the line 498(original) will throw a timeout exception.\r\nThe streams state will be always **RUNNING** if we skip `close()`",
        "createdAt" : "2021-05-12T03:35:56Z",
        "updatedAt" : "2021-05-12T03:35:56Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "67d1b06a-e90b-4b23-bfe4-a4de29bce314",
        "parentId" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "As `KafkaStreams` implements the `AutoCloseable` interface now, `close()` should be called automatically when the `try {}` block is left -- that is the whole purpose of `AutoClosable` and try-with-resource construct -- it frees you up to call `close()` explicitly (so you cannot forget any longer).",
        "createdAt" : "2021-05-26T21:16:47Z",
        "updatedAt" : "2021-05-26T21:16:47Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "cd2c1136-bf3b-4553-a032-2cd6e63d380f",
        "parentId" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "@mjsax Thanks for the detail description. I knew the things you describe.\r\nBut in this case, after `streams.close()` , we still need to check streams state whether is `NOT_RUNNING`.\r\nIf we remove `streams.close()`, the streams state will still be `RUNNING`, this state will lead to failed of the next checking of `NOT_RUNNING`.\r\n",
        "createdAt" : "2021-05-27T01:00:05Z",
        "updatedAt" : "2021-05-27T01:00:05Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "26694028-1c3c-401a-869b-51cf4693ead5",
        "parentId" : "6205cf01-6d67-4a74-ad07-9ec81b263cdc",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I missed the fact that we moved the `waitForCondition` check _inside_ of the try-catch block... For this case, we need to call `close` explicitly of course, as we are still in the block and `close()` is not auto-called yet...\r\n\r\nSorry for the confusion.",
        "createdAt" : "2021-06-02T17:38:22Z",
        "updatedAt" : "2021-06-02T17:38:23Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c53e84a66e8920009c86a14069dc6a7e43d05862",
    "line" : 183,
    "diffHunk" : "@@ -1,1 +504,508 @@                \"Streams never stopped\"\n            );\n            streams.close();\n\n            waitForCondition("
  },
  {
    "id" : "ff42eb8e-a91e-4add-aa9b-9a16c47ca84c",
    "prId" : 10668,
    "prUrl" : "https://github.com/apache/kafka/pull/10668#pullrequestreview-669546981",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2651abf6-c7f6-4a4c-8ade-fd8060a51f89",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "As above. (Maybe similar elsewhere; won't comment on it explicitly below)",
        "createdAt" : "2021-05-11T23:22:51Z",
        "updatedAt" : "2021-05-11T23:22:51Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "8f2fd128-d35c-45c4-80db-2b5340816d7a",
        "parentId" : "2651abf6-c7f6-4a4c-8ade-fd8060a51f89",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "Ok, will do.",
        "createdAt" : "2021-05-11T23:27:55Z",
        "updatedAt" : "2021-05-11T23:27:55Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "3d67cc3c-782e-44d5-9327-7be4719ae1e3",
        "parentId" : "2651abf6-c7f6-4a4c-8ade-fd8060a51f89",
        "authorId" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "body" : "@mjsax The line 532(original) wait for the streams state equal to **ERROR** after streams closed. \r\nAlthough this test case will pass if we remove `close()`, but it seems we might be better to retain `close()`?\r\n",
        "createdAt" : "2021-05-12T03:50:26Z",
        "updatedAt" : "2021-05-12T03:50:26Z",
        "lastEditedBy" : "6eec2d31-e643-40e1-a430-7a9071e8b0ae",
        "tags" : [
        ]
      },
      {
        "id" : "88f336e8-1447-4350-8bfb-a1a39f98ca4f",
        "parentId" : "2651abf6-c7f6-4a4c-8ade-fd8060a51f89",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Sams comment as above. The Java compiler will insert a `close()` call and there is no need to explicitly call it any longer.",
        "createdAt" : "2021-05-26T21:17:58Z",
        "updatedAt" : "2021-05-26T21:17:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c53e84a66e8920009c86a14069dc6a7e43d05862",
    "line" : 215,
    "diffHunk" : "@@ -1,1 +536,540 @@                \"Thread never stopped.\"\n            );\n            streams.close();\n\n            waitForCondition("
  }
]