[
  {
    "id" : "a0b66daa-c58e-46d4-a3c6-426a73d4f930",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-145830144",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58626ce9-9edb-40e5-9704-4bdf42eb33a7",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This is the config to shorten integration test, ditto elsewhere.",
        "createdAt" : "2018-08-10T22:25:24Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "e5326429-aafe-4ede-90c7-a6d15b0b94ce",
        "parentId" : "58626ce9-9edb-40e5-9704-4bdf42eb33a7",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "very nice!",
        "createdAt" : "2018-08-13T20:50:19Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +87,91 @@        props.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);\n        props.put(IntegrationTestUtils.INTERNAL_LEAVE_GROUP_ON_CLOSE, true);\n        streams = new KafkaStreams(builder.build(), props);\n    }"
  },
  {
    "id" : "4ea3025b-a587-4f38-9b15-7040a2ce48b6",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-153572230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d930cce0-d7dd-40ac-a130-4e8643330935",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ditto here, for this test we can still reuse the shared streams.",
        "createdAt" : "2018-09-07T15:57:06Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "c924487e-c1aa-403d-8610-6cdc4b077add",
        "parentId" : "d930cce0-d7dd-40ac-a130-4e8643330935",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not here. We need to get `oldInitCount = MockMetricsReporter.INIT_COUNT.get();` before we create `new KafkaStreams()` instance.",
        "createdAt" : "2018-09-09T05:54:06Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 338,
    "diffHunk" : "@@ -1,1 +286,290 @@            assertTrue(\"some reporters should be initialized by calling on construction\", initDiff > 0);\n\n            streams.start();\n            final int oldCloseCount = MockMetricsReporter.CLOSE_COUNT.get();\n            streams.close();"
  },
  {
    "id" : "5174d081-abd3-4f3b-8590-4f1e30ff7fb5",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-155234061",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Just out of curiosity, how does this differ from the following?\r\n```\r\nassertTrue(streams.close(10, TimeUnit.SECONDS));\r\n``` ",
        "createdAt" : "2018-09-10T17:08:17Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "1826da7b-48a0-4d1f-92c4-34b8fb139daf",
        "parentId" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not sure... Seems we could rewrite it. \\cc @guozhangwang @bbejeck WDYT?",
        "createdAt" : "2018-09-11T01:01:40Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f0084740-3b37-43be-8a3f-2e89ff4dd1ca",
        "parentId" : "187a108b-1b3b-498d-8a48-1dbba33d7494",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "none from what I can see, but I'm not sure it's worth holding up the PR for it.",
        "createdAt" : "2018-09-13T19:21:35Z",
        "updatedAt" : "2018-09-13T19:21:35Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +143,147 @@            () -> streams.state() == KafkaStreams.State.NOT_RUNNING,\n            10 * 1000,\n            \"Streams never stopped.\");\n\n        // Ensure that any created clients are closed"
  },
  {
    "id" : "c39aad5f-2df5-45f7-84fa-8dfdfbe5a58f",
    "prId" : 5618,
    "prUrl" : "https://github.com/apache/kafka/pull/5618#pullrequestreview-155229512",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The fact that we are having to do this in our tests suggests to me that maybe we should think about making KafkaStreams `AutoCloseable`. Should I go ahead and make a jira for this?",
        "createdAt" : "2018-09-10T17:12:57Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "e40d0279-67a2-4ad6-9caa-00050f30b0ec",
        "parentId" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "In general I am in favor to this. \\cc @guozhangwang @bbejeck Thoughts?",
        "createdAt" : "2018-09-11T01:03:21Z",
        "updatedAt" : "2018-09-11T01:05:10Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5b07d292-1c96-4597-a1f2-3732a84335fd",
        "parentId" : "ff02834d-e1c5-4b41-8ed2-0a8dd00aee9f",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "+1 for me on `AutoCloseable`",
        "createdAt" : "2018-09-13T19:08:54Z",
        "updatedAt" : "2018-09-13T19:08:54Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c072587e1165b53c629304314685ac6e965a3193",
    "line" : 314,
    "diffHunk" : "@@ -1,1 +270,274 @@            streams.start();\n        } finally {\n            streams.close();\n        }\n        // There's nothing to assert... We're testing that this operation actually completes."
  },
  {
    "id" : "58cb0bad-2ee5-4110-b064-2a5517241d41",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fc6a39f-cc35-4773-9e0d-5f668170fb47",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Just catching up on this PR. Should we wrap the `close()` into a `finally` block?",
        "createdAt" : "2018-09-21T04:19:50Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +104,108 @@        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);\n        streams.close();\n    }\n"
  },
  {
    "id" : "6a1e08a1-b6a5-4960-807f-fdd215242242",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bd13442-5545-43c0-ad73-c712125ef8b4",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: naming -> `shouldAcceptDefaultBufferSizes()`\r\n\r\nAlso, I am wondering why we check for default buffer size? The ticket was about the issue, that `-1` was not accepted. Thus, while having this test is ok, we should actually test for `-1` to have a test that covers the reported issue.",
        "createdAt" : "2018-09-21T04:25:21Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +100,104 @@\n    @Test\n    public void testOsDefaultSocketBufferSizes() {\n        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);\n        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, Selectable.USE_DEFAULT_BUFFER_SIZE);"
  },
  {
    "id" : "4644aba4-3f9c-4a56-9939-739a3d65f383",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d6d69011-d8d7-451a-915f-cf54d84bc097",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.",
        "createdAt" : "2018-09-21T04:25:38Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +111,115 @@        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);\n        streams.close();\n    }\n"
  },
  {
    "id" : "f0699ca2-adb0-40f0-8459-64bffd1bbca4",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a56e3a2-5e90-4383-ad90-c0a603388083",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: -> `shouldThrowForInvalidSocketSendBufferSize()`",
        "createdAt" : "2018-09-21T04:26:08Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +108,112 @@\n    @Test(expected = KafkaException.class)\n    public void testInvalidSocketSendBufferSize() {\n        props.put(CommonClientConfigs.SEND_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);"
  },
  {
    "id" : "4420e014-a0bb-47a3-b0aa-38b175b0980e",
    "prId" : 5643,
    "prUrl" : "https://github.com/apache/kafka/pull/5643#pullrequestreview-157541165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acf29b2d-32c1-4390-9721-6a2125badc00",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`",
        "createdAt" : "2018-09-21T04:26:19Z",
        "updatedAt" : "2018-09-21T04:28:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead236f3a3f3405fecf70d8bd150bee553673c3d",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +115,119 @@\n    @Test(expected = KafkaException.class)\n    public void testInvalidSocketReceiveBufferSize() {\n        props.put(CommonClientConfigs.RECEIVE_BUFFER_CONFIG, -2);\n        final KafkaStreams streams = new KafkaStreams(builder.build(), props);"
  },
  {
    "id" : "7ecbd657-963f-4421-9a38-a80acebaf4ab",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-172240851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81392466-1ff6-4abf-9baa-f693b1d29e3b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for the cleanup!",
        "createdAt" : "2018-11-06T21:32:07Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +144,148 @@\n        Assert.assertEquals(KafkaStreams.State.CREATED, globalStreams.state());\n        Assert.assertEquals(0, stateListener.numChanges);\n\n        globalStreams.start();"
  },
  {
    "id" : "07fa0cb1-ccf2-40b0-b9e0-2d398b73257f",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-172328363",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccb23c09-6ea6-4e65-90e8-5f2709da6f9c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Isn't this case covered by `statelessPAPITopologyShouldNotCreateStateDirectory` ? DSL compiles down into a Topology anyway.\r\n\r\nSimilar below.",
        "createdAt" : "2018-11-06T21:37:08Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "5bdc3f49-4a56-4ac6-bf9a-8c1867359fbe",
        "parentId" : "ccb23c09-6ea6-4e65-90e8-5f2709da6f9c",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "DSL tests are removed.",
        "createdAt" : "2018-11-07T03:25:09Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 108,
    "diffHunk" : "@@ -1,1 +595,599 @@\n    @Test\n    public void statelessTopologyShouldNotCreateStateDirectory() throws Exception {\n        final String inputTopic = testName.getMethodName() + \"-input\";\n        final String outputTopic = testName.getMethodName() + \"-output\";"
  },
  {
    "id" : "f7d13bd1-4f6b-4354-85f3-4981aed9def4",
    "prId" : 6185,
    "prUrl" : "https://github.com/apache/kafka/pull/6185#pullrequestreview-195815586",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8322872d-b98e-4b8a-9cd3-3ccaa109b08a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This is the actual fix: as there are two state transitions, we cannot simply check for six transitions, because if we check too early, and only five transitions finished (or maybe none), `stateListener.numChanges` might still be at 4 or 5.",
        "createdAt" : "2019-01-22T22:14:48Z",
        "updatedAt" : "2019-01-22T22:14:48Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6e504d93-1ed3-46e3-9617-ee30d3de245d",
        "parentId" : "8322872d-b98e-4b8a-9cd3-3ccaa109b08a",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Thanks for the catch! It was my bad for not capturing it last time I modified this test case.",
        "createdAt" : "2019-01-24T00:55:12Z",
        "updatedAt" : "2019-01-24T00:55:14Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7efd0e4624f5ed980ee1f900a0146251d52dd17e",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +210,214 @@        TestUtils.waitForCondition(\n            () -> stateListener.numChanges == 6,\n            \"Streams never closed.\");\n        Assert.assertEquals(KafkaStreams.State.NOT_RUNNING, globalStreams.state());\n    }"
  },
  {
    "id" : "5249ff28-b03a-4be0-aea5-d3685f8ab3b7",
    "prId" : 6610,
    "prUrl" : "https://github.com/apache/kafka/pull/6610#pullrequestreview-228867086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why we do not want to verify serde classes here? Although it's trivial seems no harm either.",
        "createdAt" : "2019-04-19T16:14:32Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "1ce56221-8fa6-4515-b9ab-16f0670a436b",
        "parentId" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well. What we want to test is, that `Deserializer#configure()` and `Serializer#configure()` are called. Note, that `Serde#configure()` is not called because we extract the `Deserializer` and `Serializer` from the `Serdes`. Thus, it seems to be a distraction of the test purpose.\r\n\r\nIf we would verify the serdes, we would only verify that `Serde#serializer()` or `Serde#deserializer()` are called. But we know that anyway, because otherwise it's impossible to call `configure()` on the wrapped (de)serializers. Also, technical this test does not care if those method are called.",
        "createdAt" : "2019-04-20T01:27:57Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "04a7ebfc-734e-4365-aeb7-87f158d4fa5f",
        "parentId" : "59add6a8-94f4-4680-a285-75e1fa761051",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ack, that makes sense.",
        "createdAt" : "2019-04-20T05:32:37Z",
        "updatedAt" : "2019-04-20T18:34:03Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "027e398a4c2a3448305ac7acc81f998f7f00cdcb",
    "line" : 156,
    "diffHunk" : "@@ -1,1 +855,859 @@        }\n\n        verify(\n            mockSourceKeyDeserialzer, mockSourceValueDeserialzer,\n            mockThroughKeySerializer, mockThroughValueSerializer, mockThroughKeyDeserializer, mockThroughValueDeserializer,"
  },
  {
    "id" : "03587145-f250-4cdc-a526-ef2cacec3cf2",
    "prId" : 7382,
    "prUrl" : "https://github.com/apache/kafka/pull/7382#pullrequestreview-294494423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76fadd2c-418f-427d-884c-cc6a847b776d",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "Why do you need to prepare `KafkaStreams` for testing? Only classes that are mocked and that are either `final` or have static methods need to be prepared. ",
        "createdAt" : "2019-09-26T11:04:29Z",
        "updatedAt" : "2019-09-27T19:06:51Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "dca89cc7-65ec-44d9-958e-083176eef2ee",
        "parentId" : "76fadd2c-418f-427d-884c-cc6a847b776d",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "We actually need to prepare `KafkaStreams` for cases like metrics reporter registration.",
        "createdAt" : "2019-09-27T18:29:58Z",
        "updatedAt" : "2019-09-27T19:06:51Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f40f55cb0194c0daccd982aad3e4eebf68a638f",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +84,88 @@\n@RunWith(PowerMockRunner.class)\n@PrepareForTest({KafkaStreams.class, StreamThread.class})\npublic class KafkaStreamsTest {\n"
  },
  {
    "id" : "2a9e3b86-73ce-46af-8d32-5ed8f654b7cd",
    "prId" : 8540,
    "prUrl" : "https://github.com/apache/kafka/pull/8540#pullrequestreview-404331060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The change to reject an empty topology make our testing rather \"ugly\"... Do we really _need_ to reject it?",
        "createdAt" : "2020-04-24T00:16:06Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "79a87e3e-2d6a-4dc0-ad5f-24e3821a6a26",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Is `getBuilderWithSource` really that much uglier than `new StreamsBuilder`? :P ",
        "createdAt" : "2020-04-24T19:49:00Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "d941ee02-b61c-495e-91e3-c07ae4ee6ee9",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Would a class-level `final StreamsBuilder builder = new StreamsBuilder()` that we add a source to in the setUp be any. better iyo?",
        "createdAt" : "2020-04-24T20:07:02Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "fe543b43-5e88-4a05-ba76-0f4cae27cdec",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think the suggestion was more along the lines of _not_ throwing an exception while building an empty topology.\r\n\r\nI'm not sure. It seems kind of nice to find out right away that your program will do absolutely nothing. I'm not totally sure you could really run an empty topology. Can you subscribe a Consumer to \"no topics\"?",
        "createdAt" : "2020-04-24T23:27:50Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "bc0663ae-12f6-46db-b85a-c44027001286",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I realize he wasn't just complaining about the name, but I was trying to keep that discussion in one thread. But I guess you can only do so much to keep PR chatter oriented in one place ",
        "createdAt" : "2020-04-24T23:47:26Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "a70cb486-4b89-454d-8fef-66f7e3b6f0e6",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "But @vvcephei 's last question gets right to the heart of the matter. The answer being \" technically yes, but it will crash if you try to poll for said nothing, so really no\"\r\nThat's why the test was flaky, and the reason for this PR in the first place (Avoiding group overhead is the name of the ticket, but the reality is it will only happen once before all the StreamThreads die due to polling no topics)",
        "createdAt" : "2020-04-24T23:49:16Z",
        "updatedAt" : "2020-04-28T16:54:44Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "d3a2e2a7-38f4-46ba-afb1-1412b4c742de",
        "parentId" : "86c0939f-9dcf-44ca-8216-d245ba1693c8",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for clarification.",
        "createdAt" : "2020-05-01T18:44:42Z",
        "updatedAt" : "2020-05-01T18:44:42Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "049e3528b83ded730da75e4b888a8256d4955273",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +331,335 @@    @Test\n    public void testShouldTransitToNotRunningIfCloseRightAfterCreated() {\n        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n        streams.close();\n"
  },
  {
    "id" : "17ef0100-181f-4a4c-a3b0-e998a86a7974",
    "prId" : 9221,
    "prUrl" : "https://github.com/apache/kafka/pull/9221#pullrequestreview-475089291",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8da8060a-cb8f-4f02-a970-355faf890ba2",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Converting to the new API. I didn't want to convert over the AbstractProcessor, since that would drag in more changes. I also didn't introduce a new abstract class, since the only thing it does is capture the context.",
        "createdAt" : "2020-08-26T01:53:36Z",
        "updatedAt" : "2020-09-09T17:34:57Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "c37687893a08e3bb056f99cc9927a5c679f80d5d",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +858,862 @@        final Topology topology = new Topology();\n        topology.addSource(\"source\", Serdes.String().deserializer(), Serdes.String().deserializer(), inputTopic)\n                .addProcessor(\"process\", () -> new Processor<String, String, String, String>() {\n                    private ProcessorContext<String, String> context;\n"
  },
  {
    "id" : "673b9daf-10d3-43c4-9eb1-c03877d381f1",
    "prId" : 9361,
    "prUrl" : "https://github.com/apache/kafka/pull/9361#pullrequestreview-500554881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72119888-fbb0-4df6-92fc-e91e5eeec989",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "A good example of updating just the value for the child.",
        "createdAt" : "2020-10-01T21:01:04Z",
        "updatedAt" : "2020-10-02T15:50:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +870,874 @@                    public void process(final Record<String, String> record) {\n                        if (record.value().length() % 2 == 0) {\n                            context.forward(record.withValue(record.key() + record.value()));\n                        }\n                    }"
  },
  {
    "id" : "de512c7a-a944-4732-81cc-6714433ccdb9",
    "prId" : 9361,
    "prUrl" : "https://github.com/apache/kafka/pull/9361#pullrequestreview-500554881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b000372-7093-448e-8c53-eb50324995ec",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "You're going to see a lot of these in the tests.",
        "createdAt" : "2020-10-01T21:01:31Z",
        "updatedAt" : "2020-10-02T15:50:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +973,977 @@                    kvStore.put(record.key(), 5L);\n\n                    context.forward(record.withValue(\"5\"));\n                    context.commit();\n                }"
  }
]