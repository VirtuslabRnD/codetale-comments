[
  {
    "id" : "be894a95-7147-4f43-a4ba-1b16e343c727",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-146572515",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1d2412c-cac5-4dd6-9d74-77fbbe2a04d0",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we want do disable caching for this test now? This seems to be a change in the test itself rather a set setup change?",
        "createdAt" : "2018-08-14T22:33:33Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "605dc98d-f7a9-422a-8e2d-81c351a63d0b",
        "parentId" : "f1d2412c-cac5-4dd6-9d74-77fbbe2a04d0",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "I'm actually not changing the behavior :) The original `getStreamsConfig()` with did lots of hard-coded customization here: https://github.com/apache/kafka/pull/5488/files/f5d72d7579b31fc6bc793767161f0312457a29db#diff-483f89729093ad48aa4b2451decc095eL48\r\n\r\nWhich I've removed, the motivation is to keep the util functions more intuitive: now we have a few overloads which all calls the underlying\r\n\r\n```\r\nProperties getStreamsConfig(final String applicationId,\r\n                                               final String bootstrapServers,\r\n                                               final String keySerdeClassName,\r\n                                              final String valueSerdeClassName,\r\n                                              final Properties additional)\r\n```\r\n\r\nwhich does not make any customization any more. And because of that I moved all the customizations in the caller.",
        "createdAt" : "2018-08-15T03:17:53Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "b154859f-0301-49a4-a3d1-0d9a411d6de1",
        "parentId" : "f1d2412c-cac5-4dd6-9d74-77fbbe2a04d0",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack. Thanks for clarification.",
        "createdAt" : "2018-08-15T18:52:22Z",
        "updatedAt" : "2018-08-15T18:52:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +165,169 @@                        {\n                            put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n                            put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n                            put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n                            put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_RECORDS_CONFIG), 1);"
  },
  {
    "id" : "bad12132-334c-40de-b8fa-953d4d535693",
    "prId" : 5488,
    "prUrl" : "https://github.com/apache/kafka/pull/5488#pullrequestreview-146276872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0be7cdbe-3107-450f-a949-a29f2834a68c",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above? (more below -- don't put comment each time)",
        "createdAt" : "2018-08-14T22:33:44Z",
        "updatedAt" : "2018-08-15T03:19:02Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7550e3eb5eeb926254dc8822bd9ea87502592a93",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +254,258 @@                    {\n                        put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n                        put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n                        put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n                        put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, \"1000\");"
  },
  {
    "id" : "7424ad28-8aa3-464e-b44a-2429e29588b8",
    "prId" : 6057,
    "prUrl" : "https://github.com/apache/kafka/pull/6057#pullrequestreview-189558839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9b78d57-a812-4f25-b109-bd099ebe7c78",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Do we need to relax this declaration?",
        "createdAt" : "2019-01-03T16:32:03Z",
        "updatedAt" : "2019-01-08T21:43:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "26418eca-4210-41c8-84a3-b0ecd8cc9cb4",
        "parentId" : "b9b78d57-a812-4f25-b109-bd099ebe7c78",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "@mjsax justified this in other PRs... Since the exceptions are unexpected, and they would cause the tests to fail if they happened anyway, detailed throws declarations just pollute the test method declarations.",
        "createdAt" : "2019-01-04T23:01:12Z",
        "updatedAt" : "2019-01-08T21:43:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b2bbee8f3e973aef20b83a20ddbd2e40194c51a",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +100,104 @@\n    @Before\n    public void createTopics() throws Exception {\n        applicationId = \"appId-\" + ++testNumber;\n        CLUSTER.deleteTopicsAndWait("
  },
  {
    "id" : "bb8fa1b9-2e55-425f-b19e-8b36f9660731",
    "prId" : 6057,
    "prUrl" : "https://github.com/apache/kafka/pull/6057#pullrequestreview-189085060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35e3001e-a20a-4786-acbc-4270c7fe1ed5",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "same comment as before.",
        "createdAt" : "2019-01-03T16:43:53Z",
        "updatedAt" : "2019-01-08T21:43:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b2bbee8f3e973aef20b83a20ddbd2e40194c51a",
    "line" : 457,
    "diffHunk" : "@@ -1,1 +684,688 @@\n    private List<KeyValue<Long, Long>> readResult(final int numberOfRecords,\n                                                  final String groupId) throws Exception {\n        if (groupId != null) {\n            return IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived("
  },
  {
    "id" : "fb993b3a-ce31-4430-bcc2-fdcbc3c89b86",
    "prId" : 6057,
    "prUrl" : "https://github.com/apache/kafka/pull/6057#pullrequestreview-189218827",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b0d7a95-af03-412d-afed-dc7eb5e04296",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Why we want to generalize the exception to throw?",
        "createdAt" : "2019-01-03T18:10:45Z",
        "updatedAt" : "2019-01-08T21:43:22Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "d7bf380b-15b9-44d3-95d0-332c6a593381",
        "parentId" : "3b0d7a95-af03-412d-afed-dc7eb5e04296",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Because it's the error case -- nobody is supposed to catch any exception and the test fails anyway. This is the way I was taught to write unit tests with good code style.",
        "createdAt" : "2019-01-03T23:06:19Z",
        "updatedAt" : "2019-01-08T21:43:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b2bbee8f3e973aef20b83a20ddbd2e40194c51a",
    "line" : 457,
    "diffHunk" : "@@ -1,1 +684,688 @@\n    private List<KeyValue<Long, Long>> readResult(final int numberOfRecords,\n                                                  final String groupId) throws Exception {\n        if (groupId != null) {\n            return IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived("
  },
  {
    "id" : "456a2693-78c6-434a-9c68-c45db98c1505",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-355527004",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38b8522c-9f64-4d9d-b379-d8faf3b19e2b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I improve this test a little bit, adding more conditions.",
        "createdAt" : "2020-02-08T03:31:16Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +154,158 @@\n            assertThat(committedOffset, equalTo(consumerPosition));\n            assertThat(committedOffset, equalTo(endOffset));\n        }\n    }"
  },
  {
    "id" : "b50ee703-368a-4901-906d-32f8497e8f25",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-379934452",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba1ab2ca-4a3c-4d5c-b81d-5ea2404c18a7",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "could be named as `processingMode`",
        "createdAt" : "2020-03-23T20:29:03Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "69b9e52d-e3f7-4b5a-b184-8000d1402037",
        "parentId" : "ba1ab2ca-4a3c-4d5c-b81d-5ea2404c18a7",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I called it `eosConfig` because it's string, and because \"at-least-once\" is not a valid config for this case.",
        "createdAt" : "2020-03-24T01:05:19Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +205,209 @@                                   final String outputTopic,\n                                   final boolean inputTopicTransactional,\n                                   final String eosConfig) throws Exception {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KStream<Long, Long> input = builder.stream(inputTopic);"
  },
  {
    "id" : "3c688910-89b2-400b-ae9a-a968c4f894d3",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-382288950",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e944a6d-b26e-47d5-9759-8a01eda97f7e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I realized that the test setup was actually incorrect. We try to use a unique `application.id` per test method and with parallel test execution the variable cannot be `static`",
        "createdAt" : "2020-03-26T18:20:37Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +99,103 @@    );\n\n    private String applicationId;\n    private final static int NUM_TOPIC_PARTITIONS = 2;\n    private final static String CONSUMER_GROUP_ID = \"readCommitted\";"
  },
  {
    "id" : "32127bb7-7496-4e2f-9053-50622d53838b",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-382289184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91336ab2-fe75-49cc-800d-76f3f7480115",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Make this `static` and atomic for parallel test execution",
        "createdAt" : "2020-03-26T18:20:55Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +116,120 @@    private Throwable uncaughtException;\n\n    private static final AtomicInteger TEST_NUMBER = new AtomicInteger(0);\n\n    @Parameters(name = \"{0}\")"
  },
  {
    "id" : "1925e440-d0ba-47b0-bd7b-59f6ab4abe72",
    "prId" : 8411,
    "prUrl" : "https://github.com/apache/kafka/pull/8411#pullrequestreview-386908319",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ea1f4a5-b904-4916-bab1-8a0e7f2e1ce0",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "In `KafkaStreams.close`, we don't interrupt the StreamThreads but set them to `state:=PENDING_SHUTDOWN`. I'm checking both here, though, because the thread might be interrupted for other reasons, though, and it's generally polite to make sure you haven't been interrupted if you're blocking.",
        "createdAt" : "2020-04-03T03:02:05Z",
        "updatedAt" : "2020-04-03T03:03:33Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2403ad99d3725ae021251f0ebee5d8afbafc401",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +657,661 @@                            while (doGC) {\n                                final StreamThread thread = (StreamThread) Thread.currentThread();\n                                if (thread.isInterrupted() || !thread.isRunning()) {\n                                    throw new RuntimeException(\"Detected we've been interrupted.\");\n                                }"
  },
  {
    "id" : "523f3008-f1d4-45eb-bac3-e9126558faec",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-400037911",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "345100e0-de29-43dc-8222-2e0d34d3fbd4",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "While debugging this test, I found the \"garbage collection\" nomenclature confusing (because it is possible to invoke the JVM GC, but that's not what we're doing here), so I transitioned to calling it a \"stall\", which was also a term used in the test comments.",
        "createdAt" : "2020-04-23T23:40:14Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "1c6e2447-ff94-4a98-8450-1bab90a2cac8",
        "parentId" : "345100e0-de29-43dc-8222-2e0d34d3fbd4",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is another case where I've gotten tripped up by the same thing twice, and decided to fix it this time.",
        "createdAt" : "2020-04-24T15:14:34Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +116,120 @@\n    private AtomicBoolean errorInjected;\n    private AtomicBoolean stallInjected;\n    private AtomicReference<String> stallingHost;\n    private volatile boolean doStall = true;"
  },
  {
    "id" : "6e4dec31-5244-41ca-b32f-9337444852a7",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-399543456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99f4fc5c-69f8-40f9-b081-cc2a06bab9ca",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I added an argument to the KafkaStreams builder to set the dummy host name. Previously, it was always \"dummy\" even though we had two instances, which resulted in the metadata map only containing one entry, even though there were two nodes in the cluster. I'm not sure if this was a cause of flakiness (since it seems it would be non-deterministic), but it's definitely not _right_.",
        "createdAt" : "2020-04-23T23:42:23Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +530,534 @@        try (\n            final KafkaStreams streams1 = getKafkaStreams(\"streams1\", false, \"appDir1\", 1, eosConfig);\n            final KafkaStreams streams2 = getKafkaStreams(\"streams2\", false, \"appDir2\", 1, eosConfig)\n        ) {\n            startKafkaStreamsAndWaitForRunningState(streams1, MAX_WAIT_TIME_MS);"
  },
  {
    "id" : "802114d0-232d-46e9-9a0c-46821866530c",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-399543456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79c85d6f-9c62-4e18-b62e-ae79dd785510",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The previous test was seemingly dependent on the non-stalling instance being the one to \"win\" and be present in the metadata map, which is why the metadatas for both instances were `1` before.\r\n\r\nNow, we're being a little more explicit, by actually finding out which instance is the stalled one. Then we can assert that the instance that _isn't_ stalled (the only one still in the group) doesn't see the stalled instance anymore (since it has dropped out), and that it is now assigned both partitions.",
        "createdAt" : "2020-04-23T23:47:22Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +588,592 @@                () -> stallingInstance.allMetadata().size() == 2\n                    && remainingInstance.allMetadata().size() == 1\n                    && remainingInstance.allMetadata().iterator().next().topicPartitions().size() == 2,\n                MAX_WAIT_TIME_MS,\n                () -> \"Should have rebalanced.\\n\" +"
  },
  {
    "id" : "622b037a-20ff-47f5-92c1-9b1710011d5c",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-399543456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "003426de-1c18-4c3f-a730-d0c948193214",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Again, `2` was always the right answer, we were just accidentally overwriting one instance's metadata with the other.",
        "createdAt" : "2020-04-23T23:48:17Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +611,615 @@            waitForCondition(\n                () -> streams1.allMetadata().size() == 2\n                    && streams2.allMetadata().size() == 2\n                    && streams1.allMetadata().stream().mapToLong(meta -> meta.topicPartitions().size()).sum() == 2\n                    && streams2.allMetadata().stream().mapToLong(meta -> meta.topicPartitions().size()).sum() == 2,"
  },
  {
    "id" : "5ce9e1eb-9060-4c95-ba33-361cfc4547ee",
    "prId" : 8541,
    "prUrl" : "https://github.com/apache/kafka/pull/8541#pullrequestreview-399543456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c541733c-7e59-408f-866e-96680b42240b",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "The prior expectation was dependent on the rebalance algorithm's behavior. Now, we relax it and just ensure that all the partitions are assigned.",
        "createdAt" : "2020-04-23T23:49:10Z",
        "updatedAt" : "2020-04-28T03:20:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "d58f62dc73dc3f4832cb89b5be6a8c8ce2f32e60",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +613,617 @@                    && streams2.allMetadata().size() == 2\n                    && streams1.allMetadata().stream().mapToLong(meta -> meta.topicPartitions().size()).sum() == 2\n                    && streams2.allMetadata().stream().mapToLong(meta -> meta.topicPartitions().size()).sum() == 2,\n                MAX_WAIT_TIME_MS,\n                () -> \"Should have rebalanced.\\n\" +"
  },
  {
    "id" : "cb1f3b58-b1ed-4613-b19c-5a3c6c05e1a7",
    "prId" : 8679,
    "prUrl" : "https://github.com/apache/kafka/pull/8679#pullrequestreview-413123253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d59b5a83-6ff1-4d7a-a951-b3fca578c10e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Using `to()` and `steam()` is \"simpler\" as we cleanup topics in-between (and thus avoid internal topics).\r\n\r\nWe could of course also use `repartition()`.",
        "createdAt" : "2020-05-17T03:03:47Z",
        "updatedAt" : "2020-05-21T21:48:53Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfcb6a3dce9ea006c43ddc1d502eccb07f879c10",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +215,219 @@        if (throughTopic != null) {\n            input.to(throughTopic);\n            output = builder.stream(throughTopic);\n        }\n        output.to(outputTopic);"
  },
  {
    "id" : "b9292438-b5da-4ea9-b6bb-8b0dbcfb4822",
    "prId" : 9487,
    "prUrl" : "https://github.com/apache/kafka/pull/9487#pullrequestreview-530218086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "334897bb-a45d-4d08-a17e-ca073bfe06d2",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Does the comment relate to the `@deprecation` suppression? Either way this probably makes more sense as a comment on the PR than in the code.  Given how bad we are about updating comments, I'd try to avoid anything that describes a change and reserve code comments for describing what's currently going on (or better yet, \"why\")",
        "createdAt" : "2020-11-13T04:43:11Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "9ec9a5ec-b7a2-4df2-9824-7a8aa1cf1381",
        "parentId" : "334897bb-a45d-4d08-a17e-ca073bfe06d2",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "When we remove the old handler we either need to remove the test or remove the suppression. That is what I am hoping the comment will do",
        "createdAt" : "2020-11-13T17:21:13Z",
        "updatedAt" : "2020-11-18T03:39:14Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "35dc69a461be58624c13ce4a252ed483d1f4c65d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +648,652 @@    }\n\n    @SuppressWarnings(\"deprecation\") //the threads should no longer fail one thread one at a time\n    private KafkaStreams getKafkaStreams(final String dummyHostName,\n                                         final boolean withState,"
  },
  {
    "id" : "debd601a-8fb5-40d7-90d1-c1c9d3d3f291",
    "prId" : 10301,
    "prUrl" : "https://github.com/apache/kafka/pull/10301#pullrequestreview-609393146",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a29fd85-d7bf-49d9-a43a-47384a4dacc0",
        "parentId" : null,
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "Key to fix the flaky test, by increasing the max.poll.interval.ms for `withState` test.",
        "createdAt" : "2021-03-11T04:52:41Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      }
    ],
    "commit" : "315a11f0fe5ae9911efeaebef8470e88b114b076",
    "line" : 169,
    "diffHunk" : "@@ -1,1 +507,511 @@        // We need more processing time under \"with state\" situation, so increasing the max.poll.interval.ms\n        // to avoid unexpected rebalance during test, which will cause unexpected fail over triggered\n        try (final KafkaStreams streams = getKafkaStreams(\"dummy\", true, \"appDir\", 2, eosConfig, 3 * MAX_POLL_INTERVAL_MS)) {\n            startKafkaStreamsAndWaitForRunningState(streams, MAX_WAIT_TIME_MS);\n"
  },
  {
    "id" : "26c035bd-febf-4e67-99cc-80466413a69a",
    "prId" : 10301,
    "prUrl" : "https://github.com/apache/kafka/pull/10301#pullrequestreview-622819788",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07befb80-b616-4a3a-873a-b3f2c6e6cfc4",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Thanks for this fix! We had the same bug in `EosBetaUpgradeIntegrationTest` and fixed it there already -- we missed that the same issue is in this test.",
        "createdAt" : "2021-03-28T17:54:11Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "fbf3c58b-7d26-490a-b141-85e8d4a1cf5e",
        "parentId" : "07befb80-b616-4a3a-873a-b3f2c6e6cfc4",
        "authorId" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "body" : "Exactly!",
        "createdAt" : "2021-03-29T01:52:35Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "d520dc4e-6bae-4b0b-90d6-4c0a1cabb518",
        "tags" : [
        ]
      }
    ],
    "commit" : "315a11f0fe5ae9911efeaebef8470e88b114b076",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +134,138 @@    private static final AtomicInteger TEST_NUMBER = new AtomicInteger(0);\n\n    private volatile boolean hasUnexpectedError = false;\n\n    @Parameters(name = \"{0}\")"
  },
  {
    "id" : "edd71810-a085-40e7-be1f-22591721c67d",
    "prId" : 10301,
    "prUrl" : "https://github.com/apache/kafka/pull/10301#pullrequestreview-622767931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69221ce7-309e-4e2a-a1e4-358004f72b29",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: formatting (if we break the line, we should break for all parameter:\r\n```\r\nprivate void checkResultPerKey(final List<KeyValue<Long, Long>> result,\r\n                               final List<KeyValue<Long, Long>> expectedResult,\r\n                               final String reason) {\r\n```",
        "createdAt" : "2021-03-28T17:55:15Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "315a11f0fe5ae9911efeaebef8470e88b114b076",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +289,293 @@    private void checkResultPerKey(final List<KeyValue<Long, Long>> result,\n                                   final List<KeyValue<Long, Long>> expectedResult,\n                                   final String reason) {\n        final Set<Long> allKeys = new HashSet<>();\n        addAllKeys(allKeys, result);"
  },
  {
    "id" : "1eab3b8a-6539-44e3-a3f8-0fc7ae57fad2",
    "prId" : 10301,
    "prUrl" : "https://github.com/apache/kafka/pull/10301#pullrequestreview-622767931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de77376a-c89d-4665-a5e7-971c57b8be6e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ok to have, but we don't really need to optimize this in a test... (sounds like a case of premature optimization). In test, we usually prefer simple code over optimized code.",
        "createdAt" : "2021-03-28T17:57:05Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "315a11f0fe5ae9911efeaebef8470e88b114b076",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +410,414 @@\n            final List<KeyValue<Long, Long>> dataBeforeFailure = new ArrayList<>(\n                committedDataBeforeFailure.size() + uncommittedDataBeforeFailure.size());\n            dataBeforeFailure.addAll(committedDataBeforeFailure);\n            dataBeforeFailure.addAll(uncommittedDataBeforeFailure);"
  },
  {
    "id" : "f8fdd9cf-d7d9-408b-8733-7c94d27cfc53",
    "prId" : 10301,
    "prUrl" : "https://github.com/apache/kafka/pull/10301#pullrequestreview-622767931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab94e75e-d209-4997-82b7-4322c2ce00ba",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Nit (as above): if we break the line, we should break per parameter:\r\n```\r\ncheckResultPerKey(\r\n    committedRecords,\r\n    committedDataBeforeFailure,\r\n    \"The committed records before failure do not match what expected\"\r\n);\r\n```",
        "createdAt" : "2021-03-28T17:58:26Z",
        "updatedAt" : "2021-04-07T02:15:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "315a11f0fe5ae9911efeaebef8470e88b114b076",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +431,435 @@                committedRecords,\n                committedDataBeforeFailure,\n                \"The committed records before failure do not match what expected\");\n\n            writeInputData(uncommittedDataBeforeFailure);"
  }
]