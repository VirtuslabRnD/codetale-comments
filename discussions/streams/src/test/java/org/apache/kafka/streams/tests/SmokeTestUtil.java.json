[
  {
    "id" : "95b26062-c8ca-4adc-ade8-c52a8d34e6a7",
    "prId" : 6531,
    "prUrl" : "https://github.com/apache/kafka/pull/6531#pullrequestreview-221892492",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4644026-9d9f-443d-8246-2d34db288a9a",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "These are just for easy debugging.",
        "createdAt" : "2019-04-02T20:44:29Z",
        "updatedAt" : "2019-04-02T20:44:29Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "519967ca8faee6e769eb449ff9e124721ba97167",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +50,54 @@                    public void init(final ProcessorContext context) {\n                        super.init(context);\n                        System.out.println(\"[DEV] initializing processor: topic=\" + topic + \" taskId=\" + context.taskId());\n                        numRecordsProcessed = 0;\n                    }"
  },
  {
    "id" : "1e2b9748-5a58-49af-9bf7-033d4a55a124",
    "prId" : 8440,
    "prUrl" : "https://github.com/apache/kafka/pull/8440#pullrequestreview-389494302",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09d5786f-4acc-4df5-9de0-571eeaf2b483",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For debugging purpose,  we now track the smallest and largest processed offset, too. This helps to understand which task during which phase processed which part of the data.",
        "createdAt" : "2020-04-07T21:12:38Z",
        "updatedAt" : "2020-04-14T23:37:49Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "15e0b98ef384c15022ee76e6ca88b325567e31cb",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +46,50 @@                    private int numRecordsProcessed = 0;\n                    private long smallestOffset = Long.MAX_VALUE;\n                    private long largestOffset = Long.MIN_VALUE;\n\n                    @Override"
  },
  {
    "id" : "0d592917-c835-4d8b-9c4f-79085414865d",
    "prId" : 8938,
    "prUrl" : "https://github.com/apache/kafka/pull/8938#pullrequestreview-438715011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd26115e-3fd5-41ad-871b-e1d12cabb754",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I just happened to notice that the newline was missing when I looked at the stdout. It didn't affect the tests' ability to grep.",
        "createdAt" : "2020-06-27T18:19:36Z",
        "updatedAt" : "2020-07-01T19:49:48Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "0163c8023d3b9fc61df35c0428269ca2752e9e6f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +76,80 @@                    @Override\n                    public void close() {\n                        System.out.printf(\"Close processor for task %s%n\", context().taskId());\n                        System.out.println(\"processed \" + numRecordsProcessed + \" records\");\n                        final long processed;"
  }
]