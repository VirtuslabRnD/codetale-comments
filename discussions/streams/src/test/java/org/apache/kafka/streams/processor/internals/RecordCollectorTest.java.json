[
  {
    "id" : "b28c7630-373f-4f76-8388-b6a760701006",
    "prId" : 5613,
    "prUrl" : "https://github.com/apache/kafka/pull/5613#pullrequestreview-152968181",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "needed to change, looks like the result of a bad cherry-pick maybe? The `0.11.0` branch has the constructor of `public RecordCollectorImpl(final Producer<byte[], byte[]> producer, final String streamTaskId)`",
        "createdAt" : "2018-09-05T13:55:04Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "8bb7e386-a8c0-45bc-9714-670bab4eb5e2",
        "parentId" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Hmm.. why it did not fail the compilation even? Is it because we were always using the wrong (newer) jar?",
        "createdAt" : "2018-09-05T17:45:23Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "22a23596-ccf3-42a8-b92c-7a1ca116838a",
        "parentId" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I don't know, looks like it got added in #5520 ",
        "createdAt" : "2018-09-06T14:48:05Z",
        "updatedAt" : "2018-09-06T14:48:06Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "34402b501d00d4f2af8b421a63004c2af3c3bd34",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +148,152 @@        final MockProducer<byte[], byte[]> producer =\n            new MockProducer<>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer);\n        final RecordCollector collector = new RecordCollectorImpl(producer, \"test\");\n\n        producer.initTransactions();"
  },
  {
    "id" : "28940e8d-b0ae-4497-8e8d-85124692ff43",
    "prId" : 7223,
    "prUrl" : "https://github.com/apache/kafka/pull/7223#pullrequestreview-279653681",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ace9aa3-dfcd-4761-ae53-16bb31c933e5",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "nit: I would remove this line",
        "createdAt" : "2019-08-26T14:03:35Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "09ea9964-3819-47da-8fb8-97a8b2b443b3",
        "parentId" : "5ace9aa3-dfcd-4761-ae53-16bb31c933e5",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "I would argue for keeping this because the change impacts the external behavior of the class. We're making a strong statement here: you will get an exception if you try to modify the contents of the returned map, you must copy this map if you want to make changes. This also distinguishes from the alternative approach we could have used in which we proactively copy the map for the user and where the user could have made a change to the map while still not impacting the underlying map. Given that this is externally facing and there is doc a couple levels up, I will fix that up.\r\n\r\nHappy to discuss further if you strongly disagree.",
        "createdAt" : "2019-08-26T15:14:44Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e0fd82b3fcf3eb7d338aabc674aead40c28e0f6",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +170,174 @@        assertThat(offsets.get(topicPartition), equalTo(2L));\n        assertThrows(UnsupportedOperationException.class, () -> offsets.put(new TopicPartition(topic, 0), 50L));\n\n        assertThat(collector.offsets().get(topicPartition), equalTo(2L));\n    }"
  },
  {
    "id" : "cd714126-e4b2-4e95-8d8e-bb9abb3d9f26",
    "prId" : 8105,
    "prUrl" : "https://github.com/apache/kafka/pull/8105#pullrequestreview-357932948",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd4d5e26-4070-4579-84b1-cfc52c137619",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`MockProducer` does not support the correct handling of callback exceptions, hence, we need to do it manually. (Did not think it worth to extend `MockProducer` -- let me know what you think)",
        "createdAt" : "2020-02-13T03:22:40Z",
        "updatedAt" : "2020-02-21T20:06:35Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ffe90a4254278614feeb110dbd3bde4687e82676",
    "line" : 376,
    "diffHunk" : "@@ -1,1 +359,363 @@                    @Override\n                    public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                        callback.onCompletion(null, exception);\n                        return null;\n                    }"
  },
  {
    "id" : "09d392e4-745a-4752-834f-327f7c5bcae5",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-384225525",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "611de583-70f6-4be8-b412-af5159cf2665",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Shall we also add `EXACTLY_ONCE_BETA` to this test?",
        "createdAt" : "2020-03-23T20:41:36Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "6d5ebeb8-570e-4da4-9323-c279824ab21f",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This test is about `RecrodCollector` and most test use the \"at-least-once\" `StreamsProducer`. In fact, there are only three special test for eos-alpha and those would be the same for eos-beta. Not sure if we would gain anything?",
        "createdAt" : "2020-03-24T01:09:36Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "24a98a49-ba24-438e-afaf-2aeea3460bec",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "For the test completeness, we could optionally duplicate the cases for EOS-alpha and beta just to make sure the passing in processing-mode is taking effect.",
        "createdAt" : "2020-03-25T20:27:12Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "597b3609-22af-45e7-9810-b048ac52b35d",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I was thinking about this, but it would be redundant tests, because the `RecordCollectorImpl` only calls `StreamsProducer.eosEnabled()` that return `true` for eos-alpha and eos-beta and thus the `RecordCollector` cannot distinguish both cases anyway. (And we have unit test in `StreamsProducerTest` to make sure that `eosEnabled()` works correctly.)",
        "createdAt" : "2020-03-30T20:58:56Z",
        "updatedAt" : "2020-03-30T21:41:01Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +104,108 @@    private final MockProducer<byte[], byte[]> mockProducer = new MockProducer<>(\n        cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer);\n    private final StreamsProducer streamsProducer = new StreamsProducer(mockProducer, AT_LEAST_ONCE, logContext);\n\n    private RecordCollectorImpl collector;"
  },
  {
    "id" : "1c1890b4-74c2-46e2-b98c-0ec6a3eeead5",
    "prId" : 8900,
    "prUrl" : "https://github.com/apache/kafka/pull/8900#pullrequestreview-436197583",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b39987eb-0c4f-43e5-a90a-55952154d54c",
        "parentId" : null,
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "These tests used to rely on the fact that the `sendException` was never forgotten by just setting it once and then asserting that multiple subsequent calls also threw it. So now we need to call `send` before each to re-insert the exception",
        "createdAt" : "2020-06-23T04:13:37Z",
        "updatedAt" : "2020-06-23T22:09:07Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "8db42f0d-ad02-4087-af6d-4c2a00bd38c9",
        "parentId" : "b39987eb-0c4f-43e5-a90a-55952154d54c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "For those particular test, considering their names, it seem the tests are void now?",
        "createdAt" : "2020-06-23T21:45:20Z",
        "updatedAt" : "2020-06-23T22:09:07Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "e9197a2f-1de0-4dd0-83fb-139888f4eed3",
        "parentId" : "b39987eb-0c4f-43e5-a90a-55952154d54c",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Maybe I misinterpreted this, but I took the `OnSubsequentCall` in the name to mean that it would throw on the next (ie subsequent) call after the _send_, not that it would continue to throw on all subsequent calls. ie I think it should actually be several different tests (one for each \"call\" that should throw) but got mashed into just one",
        "createdAt" : "2020-06-23T21:49:25Z",
        "updatedAt" : "2020-06-23T22:09:07Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "dac008f5-5eaf-41b7-b838-2fdbc8d5ea90",
        "parentId" : "b39987eb-0c4f-43e5-a90a-55952154d54c",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "I guess I should just break these up into different tests then, huh. Will do",
        "createdAt" : "2020-06-23T21:55:03Z",
        "updatedAt" : "2020-06-23T22:09:07Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "925d22e2-5533-4fb5-9730-12d4bafad001",
        "parentId" : "b39987eb-0c4f-43e5-a90a-55952154d54c",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Not 100% sure how `OnSubsequentCall` is meant either. But what you say seems to make sense and thus it should be different test. Thanks for the extra mile splitting them up!",
        "createdAt" : "2020-06-23T22:15:00Z",
        "updatedAt" : "2020-06-23T22:15:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "20321fd1325d402405a4b5899c22c83a51732b1c",
    "line" : 113,
    "diffHunk" : "@@ -1,1 +488,492 @@        collector.initialize();\n\n        collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner);\n\n        final TaskMigratedException thrown = assertThrows(TaskMigratedException.class, collector::flush);"
  }
]