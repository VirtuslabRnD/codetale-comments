[
  {
    "id" : "b28c7630-373f-4f76-8388-b6a760701006",
    "prId" : 5613,
    "prUrl" : "https://github.com/apache/kafka/pull/5613#pullrequestreview-152968181",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "needed to change, looks like the result of a bad cherry-pick maybe? The `0.11.0` branch has the constructor of `public RecordCollectorImpl(final Producer<byte[], byte[]> producer, final String streamTaskId)`",
        "createdAt" : "2018-09-05T13:55:04Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "8bb7e386-a8c0-45bc-9714-670bab4eb5e2",
        "parentId" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Hmm.. why it did not fail the compilation even? Is it because we were always using the wrong (newer) jar?",
        "createdAt" : "2018-09-05T17:45:23Z",
        "updatedAt" : "2018-09-06T14:24:33Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "22a23596-ccf3-42a8-b92c-7a1ca116838a",
        "parentId" : "1e543238-36c9-4808-ac94-1fbb68668ec3",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I don't know, looks like it got added in #5520 ",
        "createdAt" : "2018-09-06T14:48:05Z",
        "updatedAt" : "2018-09-06T14:48:06Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "34402b501d00d4f2af8b421a63004c2af3c3bd34",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +148,152 @@        final MockProducer<byte[], byte[]> producer =\n            new MockProducer<>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer);\n        final RecordCollector collector = new RecordCollectorImpl(producer, \"test\");\n\n        producer.initTransactions();"
  },
  {
    "id" : "28940e8d-b0ae-4497-8e8d-85124692ff43",
    "prId" : 7223,
    "prUrl" : "https://github.com/apache/kafka/pull/7223#pullrequestreview-279653681",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ace9aa3-dfcd-4761-ae53-16bb31c933e5",
        "parentId" : null,
        "authorId" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "body" : "nit: I would remove this line",
        "createdAt" : "2019-08-26T14:03:35Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "b7cbfdaf-f3e2-4130-8254-501ace9562ac",
        "tags" : [
        ]
      },
      {
        "id" : "09ea9964-3819-47da-8fb8-97a8b2b443b3",
        "parentId" : "5ace9aa3-dfcd-4761-ae53-16bb31c933e5",
        "authorId" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "body" : "I would argue for keeping this because the change impacts the external behavior of the class. We're making a strong statement here: you will get an exception if you try to modify the contents of the returned map, you must copy this map if you want to make changes. This also distinguishes from the alternative approach we could have used in which we proactively copy the map for the user and where the user could have made a change to the map while still not impacting the underlying map. Given that this is externally facing and there is doc a couple levels up, I will fix that up.\r\n\r\nHappy to discuss further if you strongly disagree.",
        "createdAt" : "2019-08-26T15:14:44Z",
        "updatedAt" : "2019-08-26T15:29:28Z",
        "lastEditedBy" : "12543f19-3885-429e-8f77-e0f748c56d1f",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e0fd82b3fcf3eb7d338aabc674aead40c28e0f6",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +170,174 @@        assertThat(offsets.get(topicPartition), equalTo(2L));\n        assertThrows(UnsupportedOperationException.class, () -> offsets.put(new TopicPartition(topic, 0), 50L));\n\n        assertThat(collector.offsets().get(topicPartition), equalTo(2L));\n    }"
  },
  {
    "id" : "cd714126-e4b2-4e95-8d8e-bb9abb3d9f26",
    "prId" : 8105,
    "prUrl" : "https://github.com/apache/kafka/pull/8105#pullrequestreview-357932948",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd4d5e26-4070-4579-84b1-cfc52c137619",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`MockProducer` does not support the correct handling of callback exceptions, hence, we need to do it manually. (Did not think it worth to extend `MockProducer` -- let me know what you think)",
        "createdAt" : "2020-02-13T03:22:40Z",
        "updatedAt" : "2020-02-21T20:06:35Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ffe90a4254278614feeb110dbd3bde4687e82676",
    "line" : 376,
    "diffHunk" : "@@ -1,1 +359,363 @@                    @Override\n                    public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                        callback.onCompletion(null, exception);\n                        return null;\n                    }"
  },
  {
    "id" : "09d392e4-745a-4752-834f-327f7c5bcae5",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-384225525",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "611de583-70f6-4be8-b412-af5159cf2665",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "Shall we also add `EXACTLY_ONCE_BETA` to this test?",
        "createdAt" : "2020-03-23T20:41:36Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "6d5ebeb8-570e-4da4-9323-c279824ab21f",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "This test is about `RecrodCollector` and most test use the \"at-least-once\" `StreamsProducer`. In fact, there are only three special test for eos-alpha and those would be the same for eos-beta. Not sure if we would gain anything?",
        "createdAt" : "2020-03-24T01:09:36Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "24a98a49-ba24-438e-afaf-2aeea3460bec",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "For the test completeness, we could optionally duplicate the cases for EOS-alpha and beta just to make sure the passing in processing-mode is taking effect.",
        "createdAt" : "2020-03-25T20:27:12Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "597b3609-22af-45e7-9810-b048ac52b35d",
        "parentId" : "611de583-70f6-4be8-b412-af5159cf2665",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I was thinking about this, but it would be redundant tests, because the `RecordCollectorImpl` only calls `StreamsProducer.eosEnabled()` that return `true` for eos-alpha and eos-beta and thus the `RecordCollector` cannot distinguish both cases anyway. (And we have unit test in `StreamsProducerTest` to make sure that `eosEnabled()` works correctly.)",
        "createdAt" : "2020-03-30T20:58:56Z",
        "updatedAt" : "2020-03-30T21:41:01Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +104,108 @@    private final MockProducer<byte[], byte[]> mockProducer = new MockProducer<>(\n        cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer);\n    private final StreamsProducer streamsProducer = new StreamsProducer(mockProducer, AT_LEAST_ONCE, logContext);\n\n    private RecordCollectorImpl collector;"
  }
]