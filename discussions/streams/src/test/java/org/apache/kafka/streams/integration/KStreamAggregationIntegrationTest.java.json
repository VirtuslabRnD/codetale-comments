[
  {
    "id" : "8fd43245-5447-4b1f-a47f-3059bce19347",
    "prId" : 4910,
    "prUrl" : "https://github.com/apache/kafka/pull/4910#pullrequestreview-117816102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f35bc2ca-4fdd-4fac-bc91-e331898a6c53",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2018-05-05T14:34:04Z",
        "updatedAt" : "2018-05-07T16:27:08Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0cd66fb819d0320a252d3f37e100f7c16f916eb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +170,174 @@            .reduce(reducer, \"reduce-by-key\")\n            .toStream()\n            .to(Serdes.String(), Serdes.String(), outputTopic);\n\n        startStreams();"
  },
  {
    "id" : "2168202d-4642-462d-a911-bcefbea53cf2",
    "prId" : 4910,
    "prUrl" : "https://github.com/apache/kafka/pull/4910#pullrequestreview-117816102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3360f968-d01b-4a81-b490-bea105742626",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2018-05-05T14:34:13Z",
        "updatedAt" : "2018-05-07T16:27:08Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0cd66fb819d0320a252d3f37e100f7c16f916eb",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +297,301 @@            \"aggregate-by-selected-key\")\n            .toStream()\n            .to(Serdes.String(), Serdes.Integer(), outputTopic);\n\n        startStreams();"
  },
  {
    "id" : "302ef6a8-7c7f-469d-868c-dbf3d177af1b",
    "prId" : 4910,
    "prUrl" : "https://github.com/apache/kafka/pull/4910#pullrequestreview-117816102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eaf78fcf-0f7a-4dc5-9c64-73071718c0fe",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2018-05-05T14:34:39Z",
        "updatedAt" : "2018-05-07T16:27:08Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0cd66fb819d0320a252d3f37e100f7c16f916eb",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +449,453 @@        groupedStream.count(\"count-by-key\")\n                .toStream()\n                .to(Serdes.String(), Serdes.Long(), outputTopic);\n\n        shouldCountHelper();"
  },
  {
    "id" : "2792f479-94b8-409c-99d0-b47ba7f1b5e6",
    "prId" : 4910,
    "prUrl" : "https://github.com/apache/kafka/pull/4910#pullrequestreview-117816102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "406bc313-9a1c-4d40-94e8-c9a4b68c35a9",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "as above",
        "createdAt" : "2018-05-05T14:34:46Z",
        "updatedAt" : "2018-05-07T16:27:08Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0cd66fb819d0320a252d3f37e100f7c16f916eb",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +461,465 @@        groupedStream.count()\n                .toStream()\n                .to(Serdes.String(), Serdes.Long(), outputTopic);\n\n        shouldCountHelper();"
  },
  {
    "id" : "0371b630-5b2a-4821-b117-69fd84924e13",
    "prId" : 5369,
    "prUrl" : "https://github.com/apache/kafka/pull/5369#pullrequestreview-143667598",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d26fc255-f82a-4e2f-ba26-cee3e6895548",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This test didn't depend on the retention period at all.",
        "createdAt" : "2018-08-06T16:57:46Z",
        "updatedAt" : "2018-08-13T21:59:56Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "366bb5a8f10600baf3b4000238cce9f6a8a6ef7d",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +518,522 @@        builder.stream(userSessionsStream, Consumed.with(Serdes.String(), Serdes.String()))\n                .groupByKey(Serialized.with(Serdes.String(), Serdes.String()))\n                .windowedBy(SessionWindows.with(sessionGap))\n                .count()\n                .toStream()"
  },
  {
    "id" : "b41b9832-4cee-4420-9094-31f5cf336d1f",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5e05975-058e-4958-b6b0-555e46d8bc1a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:39:36Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +138,142 @@        reducer = (value1, value2) -> value1 + \":\" + value2;\n        initializer = () -> 0;\n        aggregator = (aggKey, value, aggregate) -> aggregate + value.length();\n    }\n"
  },
  {
    "id" : "6555fcc2-c7bf-4a8c-94ee-b5fdca81406e",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bc6ba6a9-24c7-461e-8211-77a734ef5c97",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:39:41Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +166,170 @@            10);\n\n        Collections.sort(results, KStreamAggregationIntegrationTest::compare);\n\n        assertThat(results, is(Arrays.asList(KeyValue.pair(\"A\", \"A\"),"
  },
  {
    "id" : "b644fd53-ced5-40dc-b341-8ea7156c8b05",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3eb36fc4-e719-4f63-baa0-9a0d50351278",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:39:54Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 120,
    "diffHunk" : "@@ -1,1 +223,227 @@        final Comparator<KeyValue<Windowed<String>, String>>\n            comparator =\n            Comparator.comparing((KeyValue<Windowed<String>, String> o) -> o.key.key()).thenComparing(o -> o.value);\n\n        Collections.sort(windowedOutput, comparator);"
  },
  {
    "id" : "08aad8ab-4945-4375-8062-c4553de07929",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "abf8f6df-784e-4b6b-b6c3-d8008f9ea96b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:40:00Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 158,
    "diffHunk" : "@@ -1,1 +280,284 @@            10);\n\n        Collections.sort(results, KStreamAggregationIntegrationTest::compare);\n\n        assertThat(results, is(Arrays.asList("
  },
  {
    "id" : "4f076b2c-ddaa-4380-84b7-69f6debbaf5c",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a5c0f4b-2fda-44b7-b67f-e576dd4c078e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "add timestamps here",
        "createdAt" : "2018-07-26T00:40:12Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 199,
    "diffHunk" : "@@ -1,1 +329,333 @@            String.class,\n            15,\n            true);\n\n        final Comparator<KeyValue<Windowed<String>, KeyValue<Integer, Long>>>"
  },
  {
    "id" : "c79409d8-9626-4359-8493-306264b9944a",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a05af84-8099-4cd1-86c1-5e20cadc97c2",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:40:16Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 212,
    "diffHunk" : "@@ -1,1 +333,337 @@        final Comparator<KeyValue<Windowed<String>, KeyValue<Integer, Long>>>\n            comparator =\n            Comparator.comparing((KeyValue<Windowed<String>, KeyValue<Integer, Long>> o) -> o.key.key()).thenComparingInt(o -> o.value.key);\n\n        Collections.sort(windowedMessages, comparator);"
  },
  {
    "id" : "df79b71b-3ec1-46bb-8588-bb14cb073924",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4505f1f4-dbbc-4512-a7dc-dd29da2b231e",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:40:23Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 281,
    "diffHunk" : "@@ -1,1 +381,385 @@            new LongDeserializer(),\n            10);\n        Collections.sort(results, KStreamAggregationIntegrationTest::compare);\n\n        assertThat(results, is(Arrays.asList("
  },
  {
    "id" : "e57ce82e-fde2-4d82-816a-f2d94d55b47a",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1220e46b-3061-4db7-af9e-2bae8734adec",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:40:33Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 304,
    "diffHunk" : "@@ -1,1 +428,432 @@                .windowedBy(TimeWindows.of(500L))\n                .count()\n                .toStream((windowedKey, value) -> windowedKey.key() + \"@\" + windowedKey.window().start()).to(outputTopic, Produced.with(Serdes.String(), Serdes.Long()));\n\n        startStreams();"
  },
  {
    "id" : "be910768-93f3-4fad-a739-ae986da1cc2a",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04d1ec1d-2bc9-496c-8060-a7047db92199",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:40:37Z",
        "updatedAt" : "2018-07-26T00:42:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 281,
    "diffHunk" : "@@ -1,1 +436,440 @@            new LongDeserializer(),\n            10);\n        Collections.sort(results, KStreamAggregationIntegrationTest::compare);\n\n        final long window = timestamp / 500 * 500;"
  },
  {
    "id" : "bf882f4a-5959-43c4-a06a-1ee613ab94ad",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8cc8e0e4-ad97-44f9-9310-a12f2509fea5",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "add timestamps here",
        "createdAt" : "2018-07-26T00:40:51Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 327,
    "diffHunk" : "@@ -1,1 +515,519 @@                t4);\n\n        final Map<Windowed<String>, KeyValue<Long, Long>> results = new HashMap<>();\n        final CountDownLatch latch = new CountDownLatch(11);\n"
  },
  {
    "id" : "f2ec54a4-051d-410d-a11d-f876a374a85e",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "415cac2c-b134-4df8-bf44-5ab6c8b3139d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:41:05Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 390,
    "diffHunk" : "@@ -1,1 +620,624 @@                .groupByKey(Serialized.with(Serdes.String(), Serdes.String()))\n                .windowedBy(SessionWindows.with(sessionGap).until(maintainMillis))\n                .reduce((value1, value2) -> value1 + \":\" + value2, Materialized.as(userSessionsStore))\n                .toStream()\n                .foreach((key, value) -> {"
  },
  {
    "id" : "09de0b98-b75a-467e-b640-e56af70db1ff",
    "prId" : 5423,
    "prUrl" : "https://github.com/apache/kafka/pull/5423#pullrequestreview-140546340",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a506688-cef8-425c-bcd2-6af1c2c41264",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Java8 rewrite only",
        "createdAt" : "2018-07-26T00:41:09Z",
        "updatedAt" : "2018-07-26T00:42:25Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "56fc052c29d3f0b0bfd1f5b320d1fe6c79c499e8",
    "line" : 400,
    "diffHunk" : "@@ -1,1 +624,628 @@                .foreach((key, value) -> {\n                    results.put(key, value);\n                    latch.countDown();\n                });\n"
  },
  {
    "id" : "48a3b47a-82f1-40a3-8884-65781e8f9727",
    "prId" : 5536,
    "prUrl" : "https://github.com/apache/kafka/pull/5536#pullrequestreview-148249949",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d5f1373-1152-4692-b1f9-35cc06e63ee9",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I've added this semi-randomly because I noticed we had 0 unlimited windows in integration tests at all. If you can think of some place you'd rather test it, I'm happy to redo it.",
        "createdAt" : "2018-08-21T21:02:41Z",
        "updatedAt" : "2018-08-23T16:25:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a1aa50404ca6fa0007b63eee08b59ddf255f2d25",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +650,654 @@\n    @Test\n    public void shouldCountUnlimitedWindows() throws Exception {\n        final long startTime = mockTime.milliseconds() - TimeUnit.MILLISECONDS.convert(1, TimeUnit.HOURS) + 1;\n        final long incrementTime = Duration.ofDays(1).toMillis();"
  },
  {
    "id" : "78abf1b5-b2ec-47bb-ac90-bfa850cbd889",
    "prId" : 5900,
    "prUrl" : "https://github.com/apache/kafka/pull/5900#pullrequestreview-174675916",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74bb483f-b32a-4215-a864-495641901f5e",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ditto here and below.",
        "createdAt" : "2018-11-14T02:39:53Z",
        "updatedAt" : "2018-11-14T03:33:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d2c25b68fd398d988dc90eaec78c66561d090e5",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +139,143 @@            .groupBy(\n                mapper,\n                org.apache.kafka.streams.kstream.Serialized.with(Serdes.String(), Serdes.String()));\n\n        reducer = (value1, value2) -> value1 + \":\" + value2;"
  },
  {
    "id" : "77ffb9dd-de28-4b90-8d71-95525011a9c4",
    "prId" : 6645,
    "prUrl" : "https://github.com/apache/kafka/pull/6645#pullrequestreview-236047456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2392b8e4-5c91-44a4-83cf-f189af31bb62",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Add a test for out-of-order data to make sure we set the correct timestamp",
        "createdAt" : "2019-05-10T11:05:53Z",
        "updatedAt" : "2019-05-12T13:26:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "43873294c59da42142246aa9c261e0f903f0f3d4",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +509,513 @@                        new Properties()),\n                t4);\n        final long t5 = t4 - 1;\n        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n            userSessionsStream,"
  },
  {
    "id" : "d1678183-5834-43ce-aa3c-dc710e697ba0",
    "prId" : 6645,
    "prUrl" : "https://github.com/apache/kafka/pull/6645#pullrequestreview-236047603",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fbd38021-ed1a-4697-a7b2-1ae52a9d9ebb",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Add test for out-of-order data to make sure we set the correct timestamp",
        "createdAt" : "2019-05-10T11:06:16Z",
        "updatedAt" : "2019-05-12T13:26:58Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "43873294c59da42142246aa9c261e0f903f0f3d4",
    "line" : 190,
    "diffHunk" : "@@ -1,1 +617,621 @@                        new Properties()),\n                t4);\n        final long t5 = t4 - 1;\n        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n            userSessionsStream,"
  },
  {
    "id" : "6a6d0142-edd7-4d68-b94a-acfee7e1eacc",
    "prId" : 6751,
    "prUrl" : "https://github.com/apache/kafka/pull/6751#pullrequestreview-240244632",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9201f6d0-6c2f-4ce8-a46f-cec6606aea01",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "nit: I'm wondering if using `mockTime.milliseconds()` for each timestamp could be a source of test flakiness in the future vs. setting the result in a variable.  I dug a little into `mockTime,` and it looks like the default behavior now is not to increment.  But in the future, if that changes slightly, we could have flaky tests.  I could be a little paranoid here, and the other option is to leave this as is and deal with any changes in the future at that time.\r\n\r\nThis comment applies to other uses below as well.",
        "createdAt" : "2019-05-21T16:03:57Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "4213fa79-354c-4d2b-9e38-6e3c77a2c865",
        "parentId" : "9201f6d0-6c2f-4ce8-a46f-cec6606aea01",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why would it become flaky? The test should fail consistently. Hence, atm I don't see a big issue. If the behavior changes, all test using mock-time and rely ob current behavior should break (and fail consistently) and would need to be updated.",
        "createdAt" : "2019-05-21T19:08:59Z",
        "updatedAt" : "2019-05-28T18:58:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f06e10cec644ff9e471ead47982151bbe1e63d0",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +167,171 @@        results.sort(KStreamAggregationIntegrationTest::compare);\n\n        assertThat(results, is(Arrays.asList(\n            new KeyValueTimestamp(\"A\", \"A\", mockTime.milliseconds()),\n            new KeyValueTimestamp(\"A\", \"A:A\", mockTime.milliseconds()),"
  },
  {
    "id" : "086cc622-95ab-41ea-bafc-a900d3e663e9",
    "prId" : 9039,
    "prUrl" : "https://github.com/apache/kafka/pull/9039#pullrequestreview-462071057",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "129bbbb6-4bb1-4cd4-83fc-067a1500477d",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We should add a fourth batch with ts like 10K to get the windows when the second batch drops outs, too.",
        "createdAt" : "2020-08-04T01:30:05Z",
        "updatedAt" : "2020-08-31T22:19:06Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "364d0750-ea6d-44d4-8e43-caae3b0eecb8",
        "parentId" : "129bbbb6-4bb1-4cd4-83fc-067a1500477d",
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "To clarify, are you wanting to add records that would fall after the third batch _outside_ of all the existing windows, or so that it will fall into the third batch's windows but not the second batch's windows?",
        "createdAt" : "2020-08-04T17:40:13Z",
        "updatedAt" : "2020-08-31T22:19:06Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      },
      {
        "id" : "a5cca6b3-321f-474a-a25d-1fdd8c4b815a",
        "parentId" : "129bbbb6-4bb1-4cd4-83fc-067a1500477d",
        "authorId" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "body" : "Just to clarify, we don't get any additional output when the stream time is advanced and older windows drop out of the grace period. We've already forwarded their final state when the last record to update that window was processed. Not sure if that's what you meant by \"get the windows when the batch drops out\" or not?",
        "createdAt" : "2020-08-04T23:13:03Z",
        "updatedAt" : "2020-08-31T22:19:06Z",
        "lastEditedBy" : "d97f50bf-60f9-45b3-81a0-a24a5f42f740",
        "tags" : [
        ]
      },
      {
        "id" : "a3236cf2-f6d6-4e69-861a-0218bb032121",
        "parentId" : "129bbbb6-4bb1-4cd4-83fc-067a1500477d",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I guess testing both cases would be good. Even if testing the former (fall outside of all existing windows) was my original intent.\r\n\r\nAnd thank for comment Sophie: I tend to forget that we should produce all (non-empty) right windows already upfront/eagerly (and not delayed/lazily when stream-time advances beyond window-end time). In any case, it seems to be a good test case to make sure we don't (re-)emit an (unexpected) window if stream-time jumps ahead?",
        "createdAt" : "2020-08-05T22:00:39Z",
        "updatedAt" : "2020-08-31T22:19:06Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b0c4c7b3-9d6f-43a7-917a-d3be5edbffdb",
        "parentId" : "129bbbb6-4bb1-4cd4-83fc-067a1500477d",
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "That should be covered in `KStreamSlidingWindowAggregateTest`, which goes through more of the edge cases using the `TopologyTestDriver` which is a little easier to manipulate than this set up",
        "createdAt" : "2020-08-05T22:38:04Z",
        "updatedAt" : "2020-08-31T22:19:06Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      }
    ],
    "commit" : "de97db6cf39eb34eab0207f3cc45a5085317b2a4",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +470,474 @@        produceMessages(secondBatchTimestamp);\n        final long thirdBatchTimestamp = firstBatchTimestamp + timeDifference - 100L;\n        produceMessages(thirdBatchTimestamp);\n\n        final Serde<Windowed<String>> windowedSerde = WindowedSerdes.timeWindowedSerdeFrom(String.class);"
  },
  {
    "id" : "cbb30c88-42aa-4ed4-8422-c4133ddba615",
    "prId" : 9253,
    "prUrl" : "https://github.com/apache/kafka/pull/9253#pullrequestreview-574506859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03f925ee-2738-469b-b90d-8cc742190ad5",
        "parentId" : null,
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "Why don't you use `timeDifference` like you did below? ",
        "createdAt" : "2021-01-21T19:41:58Z",
        "updatedAt" : "2021-02-01T19:15:39Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      },
      {
        "id" : "a65e0dbe-69e2-4348-b843-b122092a4e90",
        "parentId" : "03f925ee-2738-469b-b90d-8cc742190ad5",
        "authorId" : "114424ac-2f76-47ba-b653-f85692b08607",
        "body" : "These are time windows so it would be `windowSize`, but I didn't write this test, just updated it to fit with the updated deserializer. I can switch it out to `windowSize` if you think it would help with readability, WYDT?",
        "createdAt" : "2021-01-22T15:14:40Z",
        "updatedAt" : "2021-02-01T19:15:39Z",
        "lastEditedBy" : "114424ac-2f76-47ba-b653-f85692b08607",
        "tags" : [
        ]
      },
      {
        "id" : "a698bea0-f40f-4d01-84b1-41ecdbf4c508",
        "parentId" : "03f925ee-2738-469b-b90d-8cc742190ad5",
        "authorId" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "body" : "It would probably be better practice but it's not necessary to fix. So if you feel like it",
        "createdAt" : "2021-01-22T18:18:48Z",
        "updatedAt" : "2021-02-01T19:15:39Z",
        "lastEditedBy" : "e4e906b3-d01a-4fe6-ad3e-ccca19a6df5c",
        "tags" : [
        ]
      }
    ],
    "commit" : "dcc9395bdc34e8995d5f8bd56aad8dbc891548cc",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +237,241 @@        windowedOutput.sort(comparator);\n        final long firstBatchWindowStart = firstBatchTimestamp / 500 * 500;\n        final long firstBatchWindowEnd = firstBatchWindowStart + 500;\n        final long secondBatchWindowStart = secondBatchTimestamp / 500 * 500;\n        final long secondBatchWindowEnd = secondBatchWindowStart + 500;"
  }
]