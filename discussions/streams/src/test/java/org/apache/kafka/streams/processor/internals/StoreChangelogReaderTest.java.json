[
  {
    "id" : "9de80669-79ea-4932-803d-77c261e807b5",
    "prId" : 4300,
    "prUrl" : "https://github.com/apache/kafka/pull/4300#pullrequestreview-85163574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0f7d5c8-189f-493f-8ba9-dbe0ebaceecd",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think we should verify the state after successful restore?",
        "createdAt" : "2017-12-20T22:09:06Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a39834b1-9a7f-431e-b3a6-87e639e0f479",
        "parentId" : "e0f7d5c8-189f-493f-8ba9-dbe0ebaceecd",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2017-12-21T19:43:33Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "85444fb99e659aeee7638f0183f608115e98a212",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +431,435 @@        replay(active);\n\n        changelogReader.restore(active);\n        assertThat(callback.restored.size(), equalTo(10));\n    }"
  },
  {
    "id" : "e870e6cf-fbe7-4e8e-a2fa-104c289b3c37",
    "prId" : 4300,
    "prUrl" : "https://github.com/apache/kafka/pull/4300#pullrequestreview-85163599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1ce583d-e872-4e39-a50e-f82e9cefbac6",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "verify state after restore?",
        "createdAt" : "2017-12-20T22:10:26Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b9393572-7a6f-4b35-9f49-cbb929f97756",
        "parentId" : "c1ce583d-e872-4e39-a50e-f82e9cefbac6",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2017-12-21T19:43:39Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "85444fb99e659aeee7638f0183f608115e98a212",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +458,462 @@        replay(active);\n\n        changelogReader.restore(active);\n        assertThat(callback.restored.size(), equalTo(10));\n    }"
  },
  {
    "id" : "763608a4-c40c-4cfa-a03f-4a7e267d6d06",
    "prId" : 4300,
    "prUrl" : "https://github.com/apache/kafka/pull/4300#pullrequestreview-85163628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cab36f28-728d-4e3c-a19f-0aad5732281a",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "verify state after restore?",
        "createdAt" : "2017-12-20T22:10:56Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "b0f79584-6a2c-4621-9acf-ddfb45cdd014",
        "parentId" : "cab36f28-728d-4e3c-a19f-0aad5732281a",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack",
        "createdAt" : "2017-12-21T19:43:46Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "85444fb99e659aeee7638f0183f608115e98a212",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +495,499 @@        replay(active);\n\n        changelogReader.restore(active);\n        assertThat(callback.restored.size(), equalTo(10));\n    }"
  },
  {
    "id" : "2ee6f236-de8e-47ba-99d9-760b395d26ad",
    "prId" : 4300,
    "prUrl" : "https://github.com/apache/kafka/pull/4300#pullrequestreview-85195238",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de98f346-874c-4c5d-8fd6-66f2055e1726",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Nit: formatting",
        "createdAt" : "2017-12-21T21:52:07Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "bb4cb3d8-2c25-46a8-a52f-90dd1d008ff6",
        "parentId" : "de98f346-874c-4c5d-8fd6-66f2055e1726",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Ack",
        "createdAt" : "2017-12-21T22:05:33Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "85444fb99e659aeee7638f0183f608115e98a212",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +135,139 @@        });\n        changelogReader.register(new StateRestorer(topicPartition, restoreListener, null, Long.MAX_VALUE, true,\n                                                   \"storeName\"));\n\n        EasyMock.expect(active.restoringTaskFor(topicPartition)).andReturn(task);"
  },
  {
    "id" : "106dbf94-7385-4fb3-a18d-b8fd1c6e31f6",
    "prId" : 4300,
    "prUrl" : "https://github.com/apache/kafka/pull/4300#pullrequestreview-85704574",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "34e876af-b4d1-4680-a4a6-3a999233b5f1",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Final question: some test call `consumer.assign(Collections.<TopicPartition>emptyList());`, other don't. Why?\r\n",
        "createdAt" : "2017-12-22T04:03:02Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "c17ed54e-3e3c-4fea-b9c9-2c83f2f9910e",
        "parentId" : "34e876af-b4d1-4680-a4a6-3a999233b5f1",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "When simulating EOS enabled, I need to manually call all methods encapsulated in the `setupConsumer` method. So actually all tests are using `consumer.assign(...)`, it's just some of them have it abstracted away in the `setupConsumer` call.\r\n\r\nEDIT: NM oversight on my part",
        "createdAt" : "2017-12-27T17:00:46Z",
        "updatedAt" : "2017-12-27T17:53:21Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "85444fb99e659aeee7638f0183f608115e98a212",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +388,392 @@        //EOS enabled commit marker at offset 5 so rest of records 6..10\n        addRecords(5, topicPartition, 6);\n        consumer.assign(Collections.<TopicPartition>emptyList());\n\n        // end offsets should start after commit marker of 5 from above"
  },
  {
    "id" : "796ab333-c762-4b5a-8ffa-b5c843f5a838",
    "prId" : 4507,
    "prUrl" : "https://github.com/apache/kafka/pull/4507#pullrequestreview-93771475",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "656ea487-c7c0-4333-93bf-ddfd65f24d67",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "should `endOffset` be `9L`, too?",
        "createdAt" : "2018-02-02T20:51:43Z",
        "updatedAt" : "2018-02-06T15:46:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "bee9c76c-7fa0-4dc5-bdd7-6cbaaed6f5cb",
        "parentId" : "656ea487-c7c0-4333-93bf-ddfd65f24d67",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "actually, this parameters and variables within the verification need to change.  The last parameter is for the number of records restored.  The last offset restored prior to this PR before was incorrect, it was the offset of the next record, not the offset of the actual last record restored.",
        "createdAt" : "2018-02-02T21:20:46Z",
        "updatedAt" : "2018-02-06T15:46:33Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "40f4d40f-1a49-4e5c-8fc7-b50f3391bf0a",
        "parentId" : "656ea487-c7c0-4333-93bf-ddfd65f24d67",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ok. That makes sense.\r\n\r\nNevertheless, the test passed comparing `restoreListener.restoreEndOffset, equalTo(endOffset)` -- thus, the `MockStateRestoreListener#restoreEndOffset` is set to `10L` -- this sound wrong.\r\n\r\nWhat I try to say is, that this bug does affect the batch-end-offset and the overall-end-offset. Thus, we should update the Jira description and also add an fix to this PR for the overall-end-offset.",
        "createdAt" : "2018-02-02T22:07:33Z",
        "updatedAt" : "2018-02-06T15:46:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "85ea3afe95f5d7e46511406df754cc8a70199a47",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +235,239 @@\n        assertAllCallbackStatesExecuted(callback, \"storeName1\");\n        assertCorrectOffsetsReportedByListener(callback, 0L, 9L, 10L);\n\n        assertAllCallbackStatesExecuted(callbackOne, \"storeName2\");"
  },
  {
    "id" : "5c00b001-6bf6-464e-a246-5ec020bc9773",
    "prId" : 4507,
    "prUrl" : "https://github.com/apache/kafka/pull/4507#pullrequestreview-93751814",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8480f00e-775b-4da8-9c72-45532cb48873",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Great test!",
        "createdAt" : "2018-02-02T20:52:17Z",
        "updatedAt" : "2018-02-06T15:46:33Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "85ea3afe95f5d7e46511406df754cc8a70199a47",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +245,249 @@\n    @Test\n    public void shouldOnlyReportTheLastRestoredOffset() {\n        setupConsumer(10, topicPartition);\n        changelogReader"
  },
  {
    "id" : "32f7c444-ec53-4459-a8fe-d6a2d075c9e7",
    "prId" : 5946,
    "prUrl" : "https://github.com/apache/kafka/pull/5946#pullrequestreview-182997639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26b342df-924b-40c3-ab56-003f6d16baf2",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "nit: formatting -- use one line per parameter:\r\n```\r\nfinal StateRestorer stateRestorer = new StateRestorer(\r\n    topicPartition,\r\n    restoreListener,\r\n    1L,\r\n    Long.MAX_VALUE,\r\n    true,\r\n    \"storeName\");\r\n```\r\n\r\nMaybe introduce variable `long expiredCheckpoint = 1L;` and pass into `StateRestorer` to make this clearer?",
        "createdAt" : "2018-12-09T22:21:59Z",
        "updatedAt" : "2018-12-10T03:38:24Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "18fc9f98f90870a52c491b5c3b22c98f4fd8276a",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +176,180 @@                Long.MAX_VALUE,\n                true,\n                \"storeName\");\n        changelogReader.register(stateRestorer);\n"
  },
  {
    "id" : "0667ce5a-3326-4585-a416-1464c4f10227",
    "prId" : 7626,
    "prUrl" : "https://github.com/apache/kafka/pull/7626#pullrequestreview-313415513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67be01d9-2a93-436f-b78a-01be42821827",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Should we have a reverse test too, that check that a task is not re-initialized if a checkpoint file is found?",
        "createdAt" : "2019-11-01T17:35:04Z",
        "updatedAt" : "2019-11-01T17:35:05Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "a7c935bf-c3f1-4bb7-bd11-ef27abe7e5ba",
        "parentId" : "67be01d9-2a93-436f-b78a-01be42821827",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "ack good point I'll add a test for that.",
        "createdAt" : "2019-11-01T17:45:10Z",
        "updatedAt" : "2019-11-01T17:45:10Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "3fdd36d7-cc24-44a7-9e95-89cbf48a916d",
        "parentId" : "67be01d9-2a93-436f-b78a-01be42821827",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "I'll do a follow-on PR for the additional test",
        "createdAt" : "2019-11-07T15:19:24Z",
        "updatedAt" : "2019-11-07T15:19:24Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e0d763bd0fcecf200dcabec353d9a8559f1c6fd",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +643,647 @@\n    @Test\n    public void shouldReinitializeStateStoresWhenNoCheckpointFoundAndEOSEnabled() {\n        final int totalMessages = 10;\n        setupConsumer(totalMessages, topicPartition);"
  },
  {
    "id" : "b8f418f6-0807-437c-b108-09f2a8d4c892",
    "prId" : 8235,
    "prUrl" : "https://github.com/apache/kafka/pull/8235#pullrequestreview-371593507",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a21f6e38-22c6-44bb-b032-11d4a96d00ea",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Is this really sufficient? We did call `restore()` once above with no available records and thus we don't expect that offset limits are updated. Now we call `restore()` again but would potentially update the offset limits at the very end -- hence would we not need one more call to `restore()` that the offset limits did no change?",
        "createdAt" : "2020-03-09T23:29:21Z",
        "updatedAt" : "2020-03-09T23:29:22Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "22db4a39-16dc-402c-940e-2d7f8e9a5e1f",
        "parentId" : "a21f6e38-22c6-44bb-b032-11d4a96d00ea",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Or is this covered by the mockconsumer that would throw?",
        "createdAt" : "2020-03-09T23:30:26Z",
        "updatedAt" : "2020-03-09T23:30:26Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "00390129ed6c84be7b74018e60f4e6f764efeab9",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +670,674 @@\n        // we should be able to restore to the log end offsets since there's no limit\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());"
  },
  {
    "id" : "74772c07-7390-4e68-90c7-d90bcd54acdb",
    "prId" : 8896,
    "prUrl" : "https://github.com/apache/kafka/pull/8896#pullrequestreview-434292717",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed837608-6ca8-4264-a096-79461602a06f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "This is moderately obnoxious... The addition of logging these values means that these tests will get a NullPointerException unless we mock this call, but the mock is irrelevant to the test outcome.",
        "createdAt" : "2020-06-18T22:15:17Z",
        "updatedAt" : "2020-06-18T22:19:09Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "d03fee24-0f28-4e8f-ad73-ba6b7b1987cb",
        "parentId" : "ed837608-6ca8-4264-a096-79461602a06f",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "This comment seems worth adding to the code :)",
        "createdAt" : "2020-06-19T16:19:38Z",
        "updatedAt" : "2020-06-19T16:20:13Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "06078437-95d3-4116-baa5-d51bed57661c",
        "parentId" : "ed837608-6ca8-4264-a096-79461602a06f",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I didn't think to do this... This might be equivocation, but it seems like if I wrote that in a code comment, it may or may not be true in the future. Looking at the tests, there are already like a dozen cryptic, redundant mocks, so I'm not sure justifying this one really makes a material impact on this test's readability, which is already approaching zero.\r\n\r\nAdding a comment like \"this is just to prevent the logger from throwing an NPE\" carries the risk that it can quickly become untrue in two ways:\r\n1. Maybe we remove or change the log so that it wouldn't need this mock; since it's a \"nice\" mock, we'll never know. In fact, I can't verify this call because the way the logger is configured only to print every ten seconds makes the NPE nondeterministic. Plus, it's not great to verify stuff that is beside the point of the test.\r\n2. Maybe we change the implementation so that it actually does exercise this mocked behavior, then the comment will become untrue, but we may not even notice.\r\n\r\nTypically, having this many specific and complex mocks in a test indicates that we shouldn't be using easymock, but instead configure the component with \"dummy\" state manager, etc. If we re-wrote this test to use that strategy, then we wouldn't need to make explicit expectations like this.\r\n\r\nAnyway, that's why I'm sort of inclined on just declaring bankruptcy on the comprehensibility of this test.",
        "createdAt" : "2020-06-19T19:14:34Z",
        "updatedAt" : "2020-06-19T19:14:34Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "6431b199f51feb7a4fc92b446780d85721e56879",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +227,231 @@    public void shouldPollWithRightTimeout() {\n        EasyMock.expect(storeMetadata.offset()).andReturn(null).andReturn(9L).anyTimes();\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(singletonMap(tp, 5L));\n        EasyMock.replay(stateManager, storeMetadata, store);\n"
  }
]