[
  {
    "id" : "2b162588-e846-4af6-80dc-1945a5ddc9e8",
    "prId" : 4793,
    "prUrl" : "https://github.com/apache/kafka/pull/4793#pullrequestreview-114058728",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f800924-7d2f-4fec-ac6b-23357c04bd08",
        "parentId" : null,
        "authorId" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "body" : "My previous comment about caching compiled pattern applies here as well.",
        "createdAt" : "2018-04-20T16:48:43Z",
        "updatedAt" : "2018-04-20T16:48:43Z",
        "lastEditedBy" : "0c73d886-f3da-4107-8045-92d8e3c8fb75",
        "tags" : [
        ]
      },
      {
        "id" : "2716fc41-b3b9-449d-81de-ab4f5cf8202b",
        "parentId" : "1f800924-7d2f-4fec-ac6b-23357c04bd08",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Yes. Still unclear to me if we need to optimize testing code? Feel free to do a MINOR PR if you think it's important to improve.",
        "createdAt" : "2018-04-20T17:16:17Z",
        "updatedAt" : "2018-04-20T17:16:17Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ae919388471d5c9ab5a3a6c62dd63443ae0bb2c",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +379,383 @@    private void validateSourceTopicNameRegexPattern(final String inputRecordTopic) {\n        for (final String sourceTopicName : internalTopologyBuilder.getSourceTopicNames()) {\n            if (!sourceTopicName.equals(inputRecordTopic) && Pattern.compile(sourceTopicName).matcher(inputRecordTopic).matches()) {\n                throw new TopologyException(\"Topology add source of type String for topic: \" + sourceTopicName +\n                        \" cannot contain regex pattern for input record topic: \" + inputRecordTopic +"
  },
  {
    "id" : "2318560d-3a0b-40bc-bc66-152cb6e93311",
    "prId" : 4832,
    "prUrl" : "https://github.com/apache/kafka/pull/4832#pullrequestreview-115899036",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "364d9cb9-015a-41e9-8c60-433394f12913",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I think this can be package-private, since your wrapper is in the same package.",
        "createdAt" : "2018-04-26T19:10:17Z",
        "updatedAt" : "2018-04-26T19:13:00Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "4d672067-5904-42a6-80b2-4f4d2cff5c3d",
        "parentId" : "364d9cb9-015a-41e9-8c60-433394f12913",
        "authorId" : "796fe0a1-c8b6-4b8f-a416-408b76bf799e",
        "body" : "Yes, it can. I'll change it.",
        "createdAt" : "2018-04-27T11:04:30Z",
        "updatedAt" : "2018-04-27T11:04:31Z",
        "lastEditedBy" : "796fe0a1-c8b6-4b8f-a416-408b76bf799e",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc5df4c3ba297c3fe2933b2adcb7ee623da698b3",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +227,231 @@     * @param config the configuration for the topology\n     */\n    protected TopologyTestDriver(final InternalTopologyBuilder builder,\n                              final Properties config) {\n        this(builder, config,  System.currentTimeMillis());"
  },
  {
    "id" : "00c1b102-da03-4017-bac0-a7db345ae1a3",
    "prId" : 5096,
    "prUrl" : "https://github.com/apache/kafka/pull/5096#pullrequestreview-124249121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffddbbfd-fe58-4adb-b115-a097abb954b1",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Nice move :)",
        "createdAt" : "2018-05-30T04:52:02Z",
        "updatedAt" : "2018-06-05T23:33:19Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a1ff0f5ba20df728f7e3a524462c8c717e4bc222",
    "line" : 129,
    "diffHunk" : "@@ -1,1 +439,443 @@        producer.clear();\n        for (final ProducerRecord<byte[], byte[]> record : output) {\n            outputRecordsByTopic.computeIfAbsent(record.topic(), k -> new LinkedList<>()).add(record);\n\n            // Forward back into the topology if the produced record is to an internal or a source topic ..."
  },
  {
    "id" : "35223e7c-72a1-4fcc-bb62-1c02678ccf31",
    "prId" : 5096,
    "prUrl" : "https://github.com/apache/kafka/pull/5096#pullrequestreview-126560288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d83605b6-4486-4853-ac49-98fcd516c834",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks for cleaning this up. I still can't read the old code without taking notes...",
        "createdAt" : "2018-06-06T20:39:21Z",
        "updatedAt" : "2018-06-06T20:39:22Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "f21981fa-8055-48e4-8f45-80ddd79e57ac",
        "parentId" : "d83605b6-4486-4853-ac49-98fcd516c834",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The old code was wrong... That's why I rewrote it. Also added a corresponding test. The existing test did not cover one case and I hit the issue while working on the original PR using facades.",
        "createdAt" : "2018-06-06T20:43:53Z",
        "updatedAt" : "2018-06-06T20:43:53Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "dc062157-5284-4b2e-93c2-c542ef5fceb4",
        "parentId" : "d83605b6-4486-4853-ac49-98fcd516c834",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Ah, well, then thanks for making it both legible and correct.",
        "createdAt" : "2018-06-06T21:21:13Z",
        "updatedAt" : "2018-06-06T21:21:14Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "a1ff0f5ba20df728f7e3a524462c8c717e4bc222",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +586,590 @@        }\n\n        return null;\n    }\n"
  },
  {
    "id" : "a468a442-e319-4a63-b42e-9de9918ad10c",
    "prId" : 5671,
    "prUrl" : "https://github.com/apache/kafka/pull/5671#pullrequestreview-158263660",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58414bdf-c0f3-496e-9853-975e1732dae3",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "Could we do `final StreamsConfig streamsConfig = new StreamsConfig(config, false);` instead? I tried locally and it worked.",
        "createdAt" : "2018-09-21T22:04:14Z",
        "updatedAt" : "2018-09-29T15:14:27Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "539e2936-67ad-4b29-b578-0a5857917a5b",
        "parentId" : "58414bdf-c0f3-496e-9853-975e1732dae3",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "That works for TopologyTestDriver, but not MockProcessorContext because that constructor is protected, and the TopologyTestDriver happens to be in the same package as StreamsConfig.\r\n\r\nI previously had the QuietStreamsConfig used only in MockProcessorContext, but the feedback was to also use it in TopologyTestDriver.\r\n\r\nSeeing it this way, do you think it makes sense just to use the protected constructor in TopologyTestDriver, and the QuietStreamsConfig in the MockProcessorContext?",
        "createdAt" : "2018-09-23T18:54:25Z",
        "updatedAt" : "2018-09-29T15:14:27Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "e2512792-993d-4474-990d-56dfbbca815f",
        "parentId" : "58414bdf-c0f3-496e-9853-975e1732dae3",
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "With the additional context,  I'm fine with the PR as is.",
        "createdAt" : "2018-09-24T19:41:11Z",
        "updatedAt" : "2018-09-29T15:14:27Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      }
    ],
    "commit" : "cab2084c121436f9360886dfcb89a662beef4e0c",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +237,241 @@                               final Properties config,\n                               final long initialWallClockTimeMs) {\n        final StreamsConfig streamsConfig = new QuietStreamsConfig(config);\n        mockWallClockTime = new MockTime(initialWallClockTimeMs);\n"
  },
  {
    "id" : "f473dbff-00d0-407d-a707-559e884235ea",
    "prId" : 5696,
    "prUrl" : "https://github.com/apache/kafka/pull/5696#pullrequestreview-162986900",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ced7eb95-c6ac-4bca-88a9-1ca87e2b94db",
        "parentId" : null,
        "authorId" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "body" : "nit: this needs to be final \r\n\r\nNote: Since this is in the streams:test-utils module `./gradlew streams:clean streams:test` didn't pick this up. If you run `./gradlew streams:test-utils:clean streams:test-utils:test` you'll see the error.",
        "createdAt" : "2018-10-09T15:59:33Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "4c968502-bb3d-46ee-8719-0c0bdbc6242f",
        "tags" : [
        ]
      },
      {
        "id" : "4a032fde-1a0c-4205-ad0e-fb0540123f06",
        "parentId" : "ced7eb95-c6ac-4bca-88a9-1ca87e2b94db",
        "authorId" : "85578594-6b0b-4724-b709-a8c84f206391",
        "body" : "Thanks for pointing it out. Fixed it.",
        "createdAt" : "2018-10-09T16:38:40Z",
        "updatedAt" : "2018-11-21T09:44:56Z",
        "lastEditedBy" : "85578594-6b0b-4724-b709-a8c84f206391",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdd60cb5ad70b8796e3ef74f1e5a94245cf8f7f9",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +259,263 @@\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n        stateDirectory = new StateDirectory(streamsConfig, mockWallClockTime, createStateDirectory);\n\n        final MetricConfig metricConfig = new MetricConfig()"
  },
  {
    "id" : "0c9e39f7-7efe-4e7b-91ea-11f96a4de432",
    "prId" : 5742,
    "prUrl" : "https://github.com/apache/kafka/pull/5742#pullrequestreview-162551904",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "595b6b43-60bf-4c87-8e46-1ac1d05e8fdf",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I had to configure the metrics in order to verify the metric with TopologyTestDriver. It also seemed like a good idea to pass in the same mock time we use for the driver itself.",
        "createdAt" : "2018-10-08T16:39:59Z",
        "updatedAt" : "2018-10-11T21:06:03Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "51c80eb6ad182197f8e09839b617db13053938ea",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +264,268 @@            .timeWindow(streamsConfig.getLong(StreamsConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS);\n\n        metrics = new Metrics(metricConfig, mockWallClockTime);\n        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(\n            metrics,"
  },
  {
    "id" : "733870ba-aee2-478c-a453-d19d20fd636c",
    "prId" : 6175,
    "prUrl" : "https://github.com/apache/kafka/pull/6175#pullrequestreview-197931032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "004dddcd-2f9c-4e43-afcf-d77f15130d33",
        "parentId" : null,
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Meta comment: I'm not sure if it is necessary to maintain compatibility in the test-utils code.\r\n\r\nIf you have a strong opinion for keeping this, then at least let's add one more comment here that users are recommended to make their test code changes sooner since otherwise it may leads to bad test coverage (e.g. your code actually has a bug that would result in incorrect timestamps, but because of you'd never need to make code changes here you may never capture it).",
        "createdAt" : "2019-01-23T01:47:16Z",
        "updatedAt" : "2019-03-06T01:00:17Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "242d59cf-ce6e-4516-a088-2b72d30821c2",
        "parentId" : "004dddcd-2f9c-4e43-afcf-d77f15130d33",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I don't see a difference in `test-utils` package compare to other code -- it's also public API and we should be compatible -- that was the overall purpose of adding a `test-utils` package.\r\n\r\nWill extend the comment and a WARN log statement that the test code should be updated.",
        "createdAt" : "2019-01-23T03:16:40Z",
        "updatedAt" : "2019-03-06T01:00:17Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f573d8be-27e3-4297-afca-275456b04091",
        "parentId" : "004dddcd-2f9c-4e43-afcf-d77f15130d33",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : ":+1: on preserving compatibility. Also consider that the tests are more useful if the test-driver is roughly analogous to Streams.",
        "createdAt" : "2019-01-30T07:17:03Z",
        "updatedAt" : "2019-03-06T01:00:17Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "e90fea067d3825ac22d63bb7f878748858c6ee79",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +629,633 @@     * The store can be a \"regular\" or global store.\n     * <p>\n     * If the registered store is a {@link TimestampedKeyValueStore} this method will return a value-only query\n     * interface. <strong>It is highly recommended to update the code for this case to avoid bugs and to use\n     * {@link #getTimestampedKeyValueStore(String)} for full store access instead.</strong>"
  },
  {
    "id" : "128aa287-07c6-4d1a-b972-63395a5b4697",
    "prId" : 7378,
    "prUrl" : "https://github.com/apache/kafka/pull/7378#pullrequestreview-296010743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f9a0bbfc-b389-44a3-86c5-3786380f44c4",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "I'm curious why these suppressions were necessary. I'd have thought that the package-private members would all have been here because they were needed by the I/O Topic classes.\r\n\r\nIs it because IDEA thinks that protected is \"stronger\" than package-private?",
        "createdAt" : "2019-10-02T02:07:04Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      },
      {
        "id" : "4f3cea6a-4ad7-4a69-b789-56d65e8287a4",
        "parentId" : "f9a0bbfc-b389-44a3-86c5-3786380f44c4",
        "authorId" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "body" : "Not sure the reason. ",
        "createdAt" : "2019-10-02T04:42:09Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "tags" : [
        ]
      }
    ],
    "commit" : "50cfdc05d22d51ec9864ecb1722a461bb07a7e4a",
    "line" : 408,
    "diffHunk" : "@@ -1,1 +694,698 @@    }\n\n    @SuppressWarnings(\"WeakerAccess\")\n    ProducerRecord<byte[], byte[]> readRecord(final String topic) {\n        final Queue<? extends ProducerRecord<byte[], byte[]>> outputRecords = getRecordsQueue(topic);"
  },
  {
    "id" : "a7aa28b2-4c12-41c1-9ac9-3be099d516d1",
    "prId" : 7378,
    "prUrl" : "https://github.com/apache/kafka/pull/7378#pullrequestreview-297596262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bbe4f81-d9fb-437b-a3e7-4e3682e557c3",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "`outputTopic2`",
        "createdAt" : "2019-10-04T06:47:19Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "6a9a9bc4-1df1-4931-bf3d-0ae8fdbc35f3",
        "parentId" : "9bbe4f81-d9fb-437b-a3e7-4e3682e557c3",
        "authorId" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "body" : "Changed record2 to read from outputTopic2",
        "createdAt" : "2019-10-04T16:51:26Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "tags" : [
        ]
      }
    ],
    "commit" : "50cfdc05d22d51ec9864ecb1722a461bb07a7e4a",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +163,167 @@ * KeyValue<String, String> record1 = outputTopic1.readKeyValue();\n * KeyValue<String, String> record2 = outputTopic2.readKeyValue();\n * KeyValue<String, String> record3 = outputTopic1.readKeyValue();\n * }</pre>\n *"
  },
  {
    "id" : "f04ee6e9-3c17-4ee8-8324-b29a4a04e648",
    "prId" : 7378,
    "prUrl" : "https://github.com/apache/kafka/pull/7378#pullrequestreview-297683650",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61884302-5395-4169-9831-e85b252e5497",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "if `time == null && record.timestamp() == null` we pass `timestamp==0`; is this intended? Sounds like an error case to me (should we throw an exception, or can this never happen anyway?)",
        "createdAt" : "2019-10-04T07:06:48Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "cd527c30-d2df-42e4-a10b-8a21093344dc",
        "parentId" : "61884302-5395-4169-9831-e85b252e5497",
        "authorId" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "body" : "I needed to modify like that to get some old test to work. It might be some non valid test.",
        "createdAt" : "2019-10-04T16:43:40Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "tags" : [
        ]
      },
      {
        "id" : "001439b3-e9ff-463c-9ad3-2158168f0245",
        "parentId" : "61884302-5395-4169-9831-e85b252e5497",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Well. Overwriting the timestamp is fine, however, if we don't pass in `final Instant time`, we should just pass `record.timestamp()` into `pipeRecord()` -- I checked out the code applied the following change an run test (and they passed---hence, I think it fine to be more strict)\r\n\r\n```\r\nlong timestamp;\r\nif (time != null) {\r\n    timestamp = time.toEpochMilli();\r\n} else if (record.timestamp() != null) {\r\n    timestamp = record.timestamp();\r\n} else {\r\n    throw new IllegalStateException(\"Provided `TestRecord` does not have a timestamp and no timestamp overwrite was provided via `time` parameter.\");\r\n}\r\n```",
        "createdAt" : "2019-10-04T19:12:52Z",
        "updatedAt" : "2019-10-04T19:12:52Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "f04bff20-c1a4-4ef9-9a4a-161855ca3417",
        "parentId" : "61884302-5395-4169-9831-e85b252e5497",
        "authorId" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "body" : "Some tests failing if making change like this.",
        "createdAt" : "2019-10-04T19:47:53Z",
        "updatedAt" : "2019-10-04T19:48:09Z",
        "lastEditedBy" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "tags" : [
        ]
      }
    ],
    "commit" : "50cfdc05d22d51ec9864ecb1722a461bb07a7e4a",
    "line" : 449,
    "diffHunk" : "@@ -1,1 +735,739 @@        }\n\n        pipeRecord(topic, timestamp, serializedKey, serializedValue, record.headers());\n    }\n"
  },
  {
    "id" : "420a52a2-d54b-45cc-b772-3d07f2281a38",
    "prId" : 7378,
    "prUrl" : "https://github.com/apache/kafka/pull/7378#pullrequestreview-297635291",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39768a1c-ccee-4e6b-bfed-ece488745906",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Why do we handle this case differently?",
        "createdAt" : "2019-10-04T07:08:41Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "1d06f497-3ace-4b60-8d33-c33daff35027",
        "parentId" : "39768a1c-ccee-4e6b-bfed-ece488745906",
        "authorId" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "body" : "To my understanding null can happen either topic does not exist or no input piped to that topic. \r\nThis is to able to Throw error if topic does not exist at all.",
        "createdAt" : "2019-10-04T16:34:56Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "1888656f-7aef-4ed7-ab66-3b00afb0b9b7",
        "tags" : [
        ]
      },
      {
        "id" : "16ac84bb-8e0b-4076-a6fd-1a6f3cabe21f",
        "parentId" : "39768a1c-ccee-4e6b-bfed-ece488745906",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Ack.",
        "createdAt" : "2019-10-04T18:08:08Z",
        "updatedAt" : "2019-10-04T18:59:11Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "50cfdc05d22d51ec9864ecb1722a461bb07a7e4a",
    "line" : 346,
    "diffHunk" : "@@ -1,1 +632,636 @@        final Queue<ProducerRecord<byte[], byte[]>> outputRecords = outputRecordsByTopic.get(topicName);\n        if (outputRecords == null) {\n            if (!processorTopology.sinkTopics().contains(topicName)) {\n                throw new IllegalArgumentException(\"Unknown topic: \" + topicName);\n            }"
  },
  {
    "id" : "6c7dd75c-5a42-4f4f-aeeb-0de1b83dfa9f",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-353415484",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97bd5584-ba59-436d-9f75-38e751f0fa20",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Because we call `consumer.position()`  now, we need to fix the mock consumer setup in the TTD",
        "createdAt" : "2020-02-05T01:25:46Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +338,342 @@            startOffsets.put(topicPartition, 0L);\n        }\n        consumer.updateBeginningOffsets(startOffsets);\n\n        if (globalTopology != null) {"
  },
  {
    "id" : "ebc92bdf-b4f3-471f-b890-ba8fda7b8e66",
    "prId" : 8040,
    "prUrl" : "https://github.com/apache/kafka/pull/8040#pullrequestreview-354141385",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e8f13f8-16ea-4c17-b304-ae1d813c945b",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "We cannot share the consumer any longer, because the global task calls `unassign()` that nukes our setup from above.",
        "createdAt" : "2020-02-05T01:26:37Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "96c51f48-fb5d-4f29-bfb6-e7600a529167",
        "parentId" : "7e8f13f8-16ea-4c17-b304-ae1d813c945b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Not clear why? In MockConsumer we only do the following:\r\n\r\n```\r\npublic synchronized void unsubscribe() {\r\n        ensureNotClosed();\r\n        committed.clear();\r\n        subscriptions.unsubscribe();\r\n    }\r\n```\r\n\r\nAnd the beginningOffsets map are not nuked.",
        "createdAt" : "2020-02-06T00:27:39Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      },
      {
        "id" : "274305f6-8f39-4813-9f79-bf4c21f05949",
        "parentId" : "7e8f13f8-16ea-4c17-b304-ae1d813c945b",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "The problem is that the `subscription` is nuked and when we call `position()` the `MockConsumer` checks if the passed in partition is in its subscription and fails before it tries to access the `beginningOffsets` map.",
        "createdAt" : "2020-02-06T00:44:24Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "2ef61f40-d973-461d-8c26-a6db0ff4f818",
        "parentId" : "7e8f13f8-16ea-4c17-b304-ae1d813c945b",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "Ah okay, got it.",
        "createdAt" : "2020-02-06T00:52:15Z",
        "updatedAt" : "2020-02-11T03:10:50Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "944fe8ec3720a43d895669f340184d025c880708",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +341,345 @@\n        if (globalTopology != null) {\n            final MockConsumer<byte[], byte[]> globalConsumer = new MockConsumer<>(OffsetResetStrategy.NONE);\n            for (final String topicName : globalTopology.sourceTopics()) {\n                final TopicPartition partition = new TopicPartition(topicName, 0);"
  },
  {
    "id" : "b582b96d-affa-4df2-a5fa-8986a7d10108",
    "prId" : 8065,
    "prUrl" : "https://github.com/apache/kafka/pull/8065#pullrequestreview-356417505",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a903a855-6a34-49b2-bc8c-d6f1b946fd3f",
        "parentId" : null,
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Here's the loop condition I added to let the loop terminate when task idling limits our ability to process enqueued records.",
        "createdAt" : "2020-02-11T04:56:51Z",
        "updatedAt" : "2020-02-11T22:50:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fc4da0e7f0a29845782c4f3a860289bbdfb356a",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +525,529 @@        // For this method, it just means there's nothing to do.\n        if (task != null) {\n            while (task.hasRecordsQueued() && task.isProcessable(mockWallClockTime.milliseconds())) {\n                // Process the record ...\n                task.process(mockWallClockTime.milliseconds());"
  },
  {
    "id" : "6073326b-6b5d-42a7-b061-232c062613cf",
    "prId" : 8065,
    "prUrl" : "https://github.com/apache/kafka/pull/8065#pullrequestreview-356961926",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3d5251b-f5f1-45c6-8c36-157fbff9a816",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "I think we should add a INFO (or WARN) log statement for the case that there is buffered data that cannot be processed yet and inform the use that they need to advance wall-clock time manually.\r\n\r\nWe might also have an INFO log when the TTD is created if we detect that task.idle is non-zero?\r\n\r\nHow should we handle `close()`? I think we should internally advance wall-clock time to ensure we drain all output? If we leave it to the user the might not be able to drain all records if there is a loop in the dataflow (what would required to advance wall-clock time after each new enqueue?). We would also have a test for this case if we implement it that way.",
        "createdAt" : "2020-02-11T17:45:20Z",
        "updatedAt" : "2020-02-11T22:50:50Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "d76228d2-4df8-4931-a6c5-c079deb0013a",
        "parentId" : "f3d5251b-f5f1-45c6-8c36-157fbff9a816",
        "authorId" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "body" : "Thanks, @mjsax !\r\n\r\nAdding both log messages as INFO seems appropriate since this is a slight behavior change, which might affect some programs. I'm not sure about WARN for the \"still buffered\" case, since, you'd be guaranteed to get the log message when using task.idle. I.e., we'd be giving an unavoidable warning telling you that nothing at all is wrong. \"Info\" should be high enough visibility.\r\n\r\nThat's a good point about `close`. How concerning would it be to just have unprocessed records while closing the TTD? That would be the cleanest approach from an implementation perspective, and it seems like the test author couldn't care that much about the results, or they would have actually advanced wall-clock time themselves to get them.",
        "createdAt" : "2020-02-11T20:14:18Z",
        "updatedAt" : "2020-02-11T22:50:50Z",
        "lastEditedBy" : "f84c555e-0e5d-4773-b994-4121b6b8dada",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fc4da0e7f0a29845782c4f3a860289bbdfb356a",
    "line" : 233,
    "diffHunk" : "@@ -1,1 +539,543 @@                         StreamsConfig.MAX_TASK_IDLE_MS_CONFIG);\n            }\n        }\n    }\n"
  },
  {
    "id" : "12ebbd28-eb90-468f-9db9-2a2ed5a0e551",
    "prId" : 8105,
    "prUrl" : "https://github.com/apache/kafka/pull/8105#pullrequestreview-359359735",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a01ef203-af0f-422e-bedd-051ecdf5a620",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Needed to change the constructor to make it shorter (checkstyle failed). Hence, some variables cannot be `final` any longer.",
        "createdAt" : "2020-02-15T18:36:06Z",
        "updatedAt" : "2020-02-21T20:06:35Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ffe90a4254278614feeb110dbd3bde4687e82676",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +201,205 @@    private final LogContext logContext;\n    private final Time mockWallClockTime;\n    private InternalTopologyBuilder internalTopologyBuilder;\n\n    private final static int PARTITION_ID = 0;"
  },
  {
    "id" : "362e8d5c-2954-4bfb-91d6-a58147216560",
    "prId" : 8218,
    "prUrl" : "https://github.com/apache/kafka/pull/8218#pullrequestreview-372440229",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be33864e-de8b-412a-a7cd-3ed93bd2f582",
        "parentId" : null,
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Because we make app method in `StreamsProducer` package private but need access to `commit()` we add `TestDriverProducer` to get access.",
        "createdAt" : "2020-03-11T02:29:59Z",
        "updatedAt" : "2020-03-19T08:49:21Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4b03a487a518756f7c9acd1f3177b12b407867d5",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +217,221 @@    private final MockConsumer<byte[], byte[]> consumer;\n    private final MockProducer<byte[], byte[]> producer;\n    private final TestDriverProducer testDriverProducer;\n\n    private final Map<String, TopicPartition> partitionsByInputTopic = new HashMap<>();"
  },
  {
    "id" : "d329f8bc-122e-4a91-9d13-04bd350b76ee",
    "prId" : 8331,
    "prUrl" : "https://github.com/apache/kafka/pull/8331#pullrequestreview-384273720",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f471982-36a8-49ca-afb2-8940b7920600",
        "parentId" : null,
        "authorId" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "body" : "TBH, Since we are adding public flags, could we just make the `StreamThread` helper functions public so that we don't need to manually write check every time?",
        "createdAt" : "2020-03-23T21:00:40Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "3dfe0270-df82-43af-827f-0681ce1c6ad9",
        "tags" : [
        ]
      },
      {
        "id" : "060ebaf0-d8ad-47e0-a5f0-3d58a48ad678",
        "parentId" : "4f471982-36a8-49ca-afb2-8940b7920600",
        "authorId" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "body" : "Current `StreamThread` helper function are base on `StreamsConfig` and don't do anything with `ProcessingMode` -- and `streamsConfig` is only available in the constructor of TTD on purpose.",
        "createdAt" : "2020-03-24T01:29:25Z",
        "updatedAt" : "2020-03-30T21:41:00Z",
        "lastEditedBy" : "9baadc38-cd41-4762-be0c-791258ced78c",
        "tags" : [
        ]
      },
      {
        "id" : "4f437240-ccaf-4ae6-bc65-f50d90447469",
        "parentId" : "4f471982-36a8-49ca-afb2-8940b7920600",
        "authorId" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "body" : "@mjsax has the fair point here, I think we can defer for future PRs to have a `StreamsUtil` like function for such static functions.",
        "createdAt" : "2020-03-30T22:26:48Z",
        "updatedAt" : "2020-03-30T22:27:15Z",
        "lastEditedBy" : "eba565e8-e1d5-4749-9c9a-5d117de6c96c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c01468233fc24b2deb017a7bdf80dc2c644d92fc",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +598,602 @@\n    private void commit(final Map<TopicPartition, OffsetAndMetadata> offsets) {\n        if (processingMode == EXACTLY_ONCE_ALPHA || processingMode == EXACTLY_ONCE_BETA) {\n            testDriverProducer.commitTransaction(offsets, new ConsumerGroupMetadata(\"dummy-app-id\"));\n        } else {"
  }
]