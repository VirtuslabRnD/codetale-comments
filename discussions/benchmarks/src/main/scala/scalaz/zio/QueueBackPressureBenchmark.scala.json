[
  {
    "id" : "c1f44632-a603-4a6c-ab3a-17f9c6982eb1",
    "prId" : 389,
    "prUrl" : "https://github.com/zio/zio/pull/389#pullrequestreview-180793687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d237ecf7-209d-41fa-a2d2-043e187cb128",
        "parentId" : null,
        "authorId" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "body" : "Could you please add `@Warmup, @Measurement, @Fork` annotation, so it's easy to see what is the recommended setup for this benchmark?",
        "createdAt" : "2018-12-03T14:34:39Z",
        "updatedAt" : "2018-12-03T15:04:02Z",
        "lastEditedBy" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cb229ed92dbf0330f2545e7b12a727dc92fc493",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +10,14 @@@State(Scope.Thread)\n@BenchmarkMode(Array(Mode.Throughput))\n@OutputTimeUnit(TimeUnit.SECONDS)\n/**\n * This benchmark offers and takes a number of items in parallel, with a very small queue to enforce back pressure mechanism is used."
  },
  {
    "id" : "2d531429-a632-4c9b-9199-721926e57e01",
    "prId" : 389,
    "prUrl" : "https://github.com/zio/zio/pull/389#pullrequestreview-180793687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83305a74-c907-46a5-ba82-c4348e4d7b6e",
        "parentId" : null,
        "authorId" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "body" : "This benchmark's performance is dependant on both the parallelism settings and threadpool settings which are defined within RTS (and are dynamic based on hardware configuration). WDYT about fixing the # of threads in the pool for this benchmark, so we have a more stable point?",
        "createdAt" : "2018-12-03T14:38:22Z",
        "updatedAt" : "2018-12-03T15:04:02Z",
        "lastEditedBy" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cb229ed92dbf0330f2545e7b12a727dc92fc493",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +18,22 @@  val queueSize   = 2\n  val totalSize   = 10000\n  val parallelism = 5\n\n  @Benchmark"
  },
  {
    "id" : "716eb060-743e-480e-a8ae-35e02c1652dd",
    "prId" : 389,
    "prUrl" : "https://github.com/zio/zio/pull/389#pullrequestreview-181638300",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "445cc859-8a33-43ea-94be-192a7fb9542e",
        "parentId" : null,
        "authorId" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "body" : "Did you have any particular reason in mind to choose such a small queue size? I'm just a bit concerned that with such a small queue size we won't see pipelinening effect and the threads will contend on the same cache-line all the time. Maybe we could use a larger queue size (maybe 64 elements?) and 64k ops to get a bit more representative measurement?",
        "createdAt" : "2018-12-03T14:45:28Z",
        "updatedAt" : "2018-12-03T15:04:02Z",
        "lastEditedBy" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "tags" : [
        ]
      },
      {
        "id" : "bfa3f05c-6d43-4d1f-a732-28854cb1aaa8",
        "parentId" : "445cc859-8a33-43ea-94be-192a7fb9542e",
        "authorId" : "73db9f28-01ba-4a29-946b-7a2ae5ac5350",
        "body" : "The idea was to use the smallest queue possible to force most items to go through the takers and putters list. What I measure here is the overhead of the back pressure, so if the queue is too large I'm afraid it won't be used at all.",
        "createdAt" : "2018-12-05T00:48:14Z",
        "updatedAt" : "2018-12-05T00:48:14Z",
        "lastEditedBy" : "73db9f28-01ba-4a29-946b-7a2ae5ac5350",
        "tags" : [
        ]
      },
      {
        "id" : "bb17a1e1-0313-4ab6-bb9a-f8b358b4e6f9",
        "parentId" : "445cc859-8a33-43ea-94be-192a7fb9542e",
        "authorId" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "body" : "> What I measure here is the overhead of the back pressure\r\n\r\n@ghostdogpr I see. I'm just a bit concerned that with a queue of size 2 you're not only measuring the cost of back-pressure, but also the cost of L1 cache miss (perfnorm could be helpful here). \r\nA couple more things to consider:\r\n1. If you're not sure that backpressure will be triggered at queue sizes of 64 you can add counters to the benchmark and validate the % of offer/take attempts that are backpressured.\r\n2. Add asymmetry to the bench, e.g. 2x putters vs 1x takers. That would surely trigger bp on the putters side.\r\nWDYT?",
        "createdAt" : "2018-12-05T06:21:35Z",
        "updatedAt" : "2018-12-05T06:21:44Z",
        "lastEditedBy" : "94a9bd21-bc51-4681-8e4e-61d5917ea48f",
        "tags" : [
        ]
      },
      {
        "id" : "537b8802-bc58-4f6d-a5ad-46c2acc9cf2b",
        "parentId" : "445cc859-8a33-43ea-94be-192a7fb9542e",
        "authorId" : "73db9f28-01ba-4a29-946b-7a2ae5ac5350",
        "body" : "Actually the takers are back pressured as well so here I measured both. Instead we could have dedicated tests focused on each of them separately and then we won't need to have a queue so small.",
        "createdAt" : "2018-12-05T08:35:11Z",
        "updatedAt" : "2018-12-05T08:35:12Z",
        "lastEditedBy" : "73db9f28-01ba-4a29-946b-7a2ae5ac5350",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cb229ed92dbf0330f2545e7b12a727dc92fc493",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +16,20 @@class QueueBackPressureBenchmark {\n\n  val queueSize   = 2\n  val totalSize   = 10000\n  val parallelism = 5"
  }
]