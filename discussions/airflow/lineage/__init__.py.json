[
  {
    "id" : "e08a5b45-c61d-49c4-b62c-e7d515540ba1",
    "prId" : 6564,
    "prUrl" : "https://github.com/apache/airflow/pull/6564#pullrequestreview-321120895",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "50fb90ef-3076-44b6-8a1c-12c3aa159fd6",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "a comment for the global variable",
        "createdAt" : "2019-11-14T01:58:07Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "d593f14b-36aa-4208-be11-f780bc598f27",
        "parentId" : "50fb90ef-3076-44b6-8a1c-12c3aa159fd6",
        "authorId" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "body" : "How'd you mean?",
        "createdAt" : "2019-11-21T19:10:45Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "79f244b22120a9add022c1babbafb32c1b58b5b8",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +36,40 @@PIPELINE_OUTLETS = \"pipeline_outlets\"\nPIPELINE_INLETS = \"pipeline_inlets\"\nAUTO = \"auto\"\n\nlog = LoggingMixin().log"
  },
  {
    "id" : "26566350-ba94-40fd-a79a-463e91bdea74",
    "prId" : 6564,
    "prUrl" : "https://github.com/apache/airflow/pull/6564#pullrequestreview-323277366",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70d49dad-185a-4823-97d2-b152c6113e80",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "not sure if you have mentioned before, but for hive operator, we would like the outlet to be the s3 file which most of the time embedded in the hql. Is there a way to figure out the lineage? ",
        "createdAt" : "2019-11-26T19:35:06Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "a8395bb3-83c1-4f7f-96e2-1f24c14aea5c",
        "parentId" : "70d49dad-185a-4823-97d2-b152c6113e80",
        "authorId" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "body" : "There are 3 ways to do this (some of it is future)\r\n\r\n1. Set outlets to \"outlets=File(\"s3a://XXX\", key=\"my_key\")\" and do something like this in your hql spec  (pseudo)\r\n\r\n```\r\nSELECT * FROM {{ inlets['my_table'] }} INTO {{ outlets['my_key'] }}\r\n```\r\n\r\nOf course we might be able to expose the keys directly if they don't collide with existing keywords.\r\n\r\n2. just set the inlets/outlets and make sure they match the HQL\r\n3. We do antlr parsing and have the parser figure it out\r\n\r\n2 and 3 are the least robust and hard to test.",
        "createdAt" : "2019-11-26T20:53:53Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "79f244b22120a9add022c1babbafb32c1b58b5b8",
    "line" : 196,
    "diffHunk" : "@@ -1,1 +157,161 @@\n        elif self._inlets:\n            raise AttributeError(\"inlets is not a list, operator, string or attr annotated object\")\n\n        if not isinstance(self._outlets, list):"
  },
  {
    "id" : "0ec4193e-0a55-4402-a7b0-f7ff907218f3",
    "prId" : 6564,
    "prUrl" : "https://github.com/apache/airflow/pull/6564#pullrequestreview-323277587",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddc6775b-ca29-4413-8205-a381168efbcc",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "didn't know symmetric_difference before :(",
        "createdAt" : "2019-11-26T19:39:17Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "3df832f6-2c72-401a-a005-2f79573f5579",
        "parentId" : "ddc6775b-ca29-4413-8205-a381168efbcc",
        "authorId" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "body" : "With sets you can go crazy ;-)",
        "createdAt" : "2019-11-26T20:54:19Z",
        "updatedAt" : "2019-11-27T08:47:08Z",
        "lastEditedBy" : "537cec6b-32b7-4f8b-9f76-6932246f79b5",
        "tags" : [
        ]
      }
    ],
    "commit" : "79f244b22120a9add022c1babbafb32c1b58b5b8",
    "line" : 180,
    "diffHunk" : "@@ -1,1 +143,147 @@            # pick up unique direct upstream task_ids if AUTO is specified\n            if AUTO.upper() in self._inlets or AUTO.lower() in self._inlets:\n                task_ids = task_ids.union(task_ids.symmetric_difference(self.upstream_task_ids))\n\n            _inlets = self.xcom_pull(context, task_ids=task_ids,"
  }
]