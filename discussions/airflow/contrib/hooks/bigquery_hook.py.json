[
  {
    "id" : "60b00e38-8efc-44d2-977c-e9c89512e8e2",
    "prId" : 981,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9ccfd61c-1c18-4050-905c-2297cfdfed13",
        "parentId" : null,
        "authorId" : "c5902037-3fba-4513-8804-ed0681136579",
        "body" : "looks like this function sets, but does not return, the job id.\n",
        "createdAt" : "2016-02-10T18:42:39Z",
        "updatedAt" : "2016-02-10T18:42:39Z",
        "lastEditedBy" : "c5902037-3fba-4513-8804-ed0681136579",
        "tags" : [
        ]
      }
    ],
    "commit" : "d8a72893a314602a296308312aa658f3afce2d0b",
    "line" : 295,
    "diffHunk" : "@@ -1,1 +302,306 @@    def execute(self, operation, parameters=None):\n        \"\"\"\n        Executes a BigQuery query, and returns the job ID.\n\n        :param operation: The query to execute."
  },
  {
    "id" : "98fcfaf2-ddba-4986-a171-2a398fd371b9",
    "prId" : 3714,
    "prUrl" : "https://github.com/apache/airflow/pull/3714#pullrequestreview-144343949",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "parentId" : null,
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@kaxil  seems it is missed",
        "createdAt" : "2018-08-08T02:18:55Z",
        "updatedAt" : "2018-08-08T02:20:47Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "ff0d073f-7732-4a31-b8b9-ce309236d16e",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "What do you mean? Setting the `{}` in the arguments is bad practice by the way Python creates these objects.",
        "createdAt" : "2018-08-08T07:20:01Z",
        "updatedAt" : "2018-08-08T07:40:16Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "4fd842fe-6fb9-4de3-a044-a1a5b0922bd9",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "@Fokko No no, it is a bad practise to use `{}` or `dict()` as a default argument. Reference: https://docs.python-guide.org/writing/gotchas/#mutable-default-arguments\r\n\r\nThe above change is because we had the below code:\r\n![image](https://user-images.githubusercontent.com/8811558/43825996-141df72c-9aee-11e8-8b2f-c55f383f5ae9.png)\r\n\r\nwhich I changed to the following:\r\n![image](https://user-images.githubusercontent.com/8811558/43826016-1f5c03a4-9aee-11e8-8c2c-06e2f715ae33.png)\r\n",
        "createdAt" : "2018-08-08T08:33:37Z",
        "updatedAt" : "2018-08-08T08:33:38Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "5ca7d90c-6ff6-4d56-9d0f-2449c3d96973",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@kaxil  but why dict() instead of {}?  just want to understand for my self\r\n as I know {} more efficient https://stackoverflow.com/questions/664118/whats-the-difference-between-dict-and. In official docs cannot see any recommendations to use dict() instead {} https://docs.python.org/3.6/library/stdtypes.html#dict \r\nand in standard library used {} not dict() \r\n",
        "createdAt" : "2018-08-08T09:27:07Z",
        "updatedAt" : "2018-08-08T09:27:07Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "9e48e019-181d-45a6-af12-428b762759ba",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "`{}` would probably be better in hindsight, but there's not much in it. On my laptop:\r\n\r\n```\r\nIn [5]: %timeit {}\r\n47.2 ns ± 2.3 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\r\n\r\nIn [6]: %timeit dict()\r\n168 ns ± 1.77 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\r\n```\r\n\r\nso yes dict() is 3 times as \"slow\" as `{}`, but neither is particularly slow.",
        "createdAt" : "2018-08-08T09:30:41Z",
        "updatedAt" : "2018-08-08T09:30:41Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "409e16e6-d498-4318-ab33-e03a8a1ef571",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "@xnuinside Hi, there is no specific reason for me to use `{}` compared to `dict()`. The point for this change as I mentioned earlier was to remove an empty dictionary from default arguments. \r\n\r\nAnd as Ash pointed out `{}` dict literal is faster that dict constructor `dict()` but there is not huge difference as the dict builds up. Check out the below links for more detailed read:\r\n- https://doughellmann.com/blog/2012/11/12/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2/\r\n- https://stackoverflow.com/questions/6610606/is-there-a-difference-between-using-a-dict-literal-and-a-dict-constructor",
        "createdAt" : "2018-08-08T09:43:21Z",
        "updatedAt" : "2018-08-08T09:43:55Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "65440229-4a54-4440-9313-2151589b0a29",
        "parentId" : "0f2b1ffe-871f-4cfa-a7ed-5a32e6277eab",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@kaxil , @ashb , thx!\r\n",
        "createdAt" : "2018-08-08T09:47:15Z",
        "updatedAt" : "2018-08-08T09:47:15Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3b5ea1a3f14df9fa1d62bc8fec7706605ff5096",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +240,244 @@        \"\"\"\n        if time_partitioning is None:\n            time_partitioning = dict()\n        project_id = project_id if project_id is not None else self.project_id\n"
  },
  {
    "id" : "c3f7756e-7721-4e3b-a1c2-7393eb91e841",
    "prId" : 3733,
    "prUrl" : "https://github.com/apache/airflow/pull/3733#pullrequestreview-150828675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35704988-ca4f-4271-ae73-54a304ce4825",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "You can pass the default here, `self. priority` if you don't change the default above",
        "createdAt" : "2018-08-29T23:45:38Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "f9cf1ed0-c941-4ef2-b762-0dcbc02128c0",
        "parentId" : "35704988-ca4f-4271-ae73-54a304ce4825",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "self.priority exist only in BigQueryOperator, BigQueryBaseCursor does not have it ",
        "createdAt" : "2018-08-30T03:27:20Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "4495cde7-9433-44d2-b92c-38e82dd4823a",
        "parentId" : "35704988-ca4f-4271-ae73-54a304ce4825",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "and thanks for review, and sorry for intends, I changed settings in IDE for project to avoid such cases in the next time.",
        "createdAt" : "2018-08-30T03:46:46Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      }
    ],
    "commit" : "642bd9dfe78cff0e10cafeeb6daac6e61e74d5e9",
    "line" : 198,
    "diffHunk" : "@@ -1,1 +634,638 @@        query_param_list = [\n            (sql, 'query', None, str),\n            (priority, 'priority', 'INTERACTIVE', str),\n            (use_legacy_sql, 'useLegacySql', self.use_legacy_sql, bool),\n            (query_params, 'queryParameters', None, dict),"
  },
  {
    "id" : "b5691321-6ca7-45f5-b960-2adbc16b332d",
    "prId" : 3733,
    "prUrl" : "https://github.com/apache/airflow/pull/3733#pullrequestreview-151629126",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f99ac62b-441e-4deb-a3a6-78075aee93a7",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "NIT: Can you change the wording to say (something similar to) that you only need to use this if you want to pass parameters that are not already in this operators. ",
        "createdAt" : "2018-09-02T14:07:22Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "6dd97f8f-4cec-4417-b3dd-82773ea3b08f",
        "parentId" : "f99ac62b-441e-4deb-a3a6-78075aee93a7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Apart from this, it LGTM. \r\n\r\n@tswast @fenglu-g  Any final comments?",
        "createdAt" : "2018-09-02T14:08:06Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "3677b56e-58f8-4690-9309-2f5565aac9d1",
        "parentId" : "f99ac62b-441e-4deb-a3a6-78075aee93a7",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@kaxil check it, pls",
        "createdAt" : "2018-09-02T18:25:52Z",
        "updatedAt" : "2018-09-03T19:47:13Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      }
    ],
    "commit" : "642bd9dfe78cff0e10cafeeb6daac6e61e74d5e9",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +529,533 @@            If `None`, defaults to `self.use_legacy_sql`.\n        :type use_legacy_sql: boolean\n        :param api_resource_configs: a dictionary that contain params\n            'configuration' applied for Google BigQuery Jobs API:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs"
  },
  {
    "id" : "c176ce62-54e6-42ae-bc3c-f6b99b9b2e4e",
    "prId" : 3838,
    "prUrl" : "https://github.com/apache/airflow/pull/3838#pullrequestreview-151954227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f915d881-c475-447e-8951-813c35ac939e",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Maybe separate this logic to a separate function? Since it is defined twice.",
        "createdAt" : "2018-09-03T18:39:34Z",
        "updatedAt" : "2018-09-07T06:48:24Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "a3f24ac7-e26c-498d-b6e6-8da02172ff1b",
        "parentId" : "f915d881-c475-447e-8951-813c35ac939e",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Agree with @Fokko ",
        "createdAt" : "2018-09-03T19:15:10Z",
        "updatedAt" : "2018-09-07T06:48:24Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "f990b657-3986-4c46-b657-b531639b632b",
        "parentId" : "f915d881-c475-447e-8951-813c35ac939e",
        "authorId" : "5588c2b8-6b15-4540-b393-5b3c6321bd90",
        "body" : "After rebasing this morning, the changes made by AIRFLOW-491 (#3733) mean the logic for `run_query` and `run_load` have diverged somewhat, so factoring it out probably now makes less sense.",
        "createdAt" : "2018-09-04T08:13:33Z",
        "updatedAt" : "2018-09-07T06:48:24Z",
        "lastEditedBy" : "5588c2b8-6b15-4540-b393-5b3c6321bd90",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1437e470bcc99b0e010211c78096b8a3a9ce780",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +998,1002 @@            })\n\n        if cluster_fields:\n            configuration['load'].update({'clustering': {'fields': cluster_fields}})\n"
  },
  {
    "id" : "3db42088-da5e-4bc9-a70d-4f2d3bec29d3",
    "prId" : 3880,
    "prUrl" : "https://github.com/apache/airflow/pull/3880#pullrequestreview-255505870",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "This breaks backward compatibility. This is ok if we target it to Airflow 2.0, and add a line to `CONTRIBUTING.md`",
        "createdAt" : "2018-09-11T12:57:53Z",
        "updatedAt" : "2018-09-11T15:05:58Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "347a8a71-9f80-45d6-b3d9-d715ce4b9361",
        "parentId" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@fokko, Exuse me) I can’t catch how it breaks if there are no changes to old args and no logic changes. Just for understanding, seems I miss something. About contributing.md - okay.",
        "createdAt" : "2018-09-11T13:51:02Z",
        "updatedAt" : "2018-09-11T15:05:58Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "d0350b1c-4973-471b-8e22-38e09449c490",
        "parentId" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Well, it changes the order. As a second argument it expects `schema_fields`, and this is moved to the fourth place.",
        "createdAt" : "2018-09-11T14:30:59Z",
        "updatedAt" : "2018-09-11T15:05:58Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "6d7bb281-4b44-4a3e-b17c-68da39f94d8c",
        "parentId" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "@Fokko )) sorry, you right, I forgot about it, I will put it at the end of args list ",
        "createdAt" : "2018-09-11T14:53:06Z",
        "updatedAt" : "2018-09-11T15:05:58Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "d098b266-ffcc-4428-8405-8aab4e1aa94a",
        "parentId" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "authorId" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "body" : "fixed",
        "createdAt" : "2018-09-11T15:06:10Z",
        "updatedAt" : "2018-09-11T15:06:11Z",
        "lastEditedBy" : "741901ab-b9c9-41b9-bb16-5e1c56490c63",
        "tags" : [
        ]
      },
      {
        "id" : "351a8e68-1650-4d35-b02d-af03b457c053",
        "parentId" : "5994c749-a712-4883-bef7-8a57ee81e1bd",
        "authorId" : "ec472562-a7be-4e77-9475-5ad643086045",
        "body" : "this indeed did break backwards compatibility.  previously (on 1.9) I could run `GoogleCloudStorageToBigQueryOperator` with no autodetect or schema fields, with `source_format='NEWLINE_DELIMITED_JSON'` and it worked fine (presumably doing autodetect?)\r\n\r\nnow upgrading to 1.10 it breaks since I haven't explicitly specified autodetect. ",
        "createdAt" : "2019-06-27T22:11:11Z",
        "updatedAt" : "2019-06-27T22:11:11Z",
        "lastEditedBy" : "ec472562-a7be-4e77-9475-5ad643086045",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb4cf61ae7583f5a306aa0cd7faa4d01aef61c33",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +851,855 @@\n    def run_load(self,\n                 destination_project_dataset_table,\n                 source_uris,\n                 schema_fields=None,"
  },
  {
    "id" : "75dde854-2a41-47e2-b0ce-accecf385d4e",
    "prId" : 4299,
    "prUrl" : "https://github.com/apache/airflow/pull/4299#pullrequestreview-191936664",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5155173e-e753-46db-a406-ffe398a7c2ca",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I have updated this as project_id can be None as we take that info from the connection.\r\n\r\nCan you update the tests accordingly.",
        "createdAt" : "2019-01-12T12:23:27Z",
        "updatedAt" : "2019-01-12T12:51:12Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "beef08fc2b4946cc68e82d2f40f6bf45639f330a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +499,503 @@                    dataset_id,\n                    table_id,\n                    project_id=None,\n                    description=None,\n                    expiration_time=None,"
  },
  {
    "id" : "8cd3d60e-baa6-4264-84f5-9352e8d85800",
    "prId" : 4324,
    "prUrl" : "https://github.com/apache/airflow/pull/4324#pullrequestreview-188244741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82d86c48-f106-4143-91d4-1af380c88868",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @kaxil , curious what would happen if the BigQuery data is stored in a region location other than US/EU while user misses to specify `location`? How will the exception be like?\r\n\r\n\r\n`",
        "createdAt" : "2018-12-16T14:18:47Z",
        "updatedAt" : "2018-12-16T14:18:47Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "1ee55490-e130-459a-9a3a-06457315be81",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "They would get the following error if the data is in for example `asia-northeast1` (Japan) location and they don't specify the location:\r\n\r\n```\r\nError executing query job. Message: 404 Not Found\r\n{\r\n  \"code\" : 404,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"message\" : \"Not found: Dataset mybqproject:mybqtable\",\r\n    \"reason\" : \"notFound\"\r\n  } ],\r\n  \"message\" : \"Not found: Dataset mybqproject:mybqtable\"\r\n},\r\n```",
        "createdAt" : "2018-12-16T14:22:41Z",
        "updatedAt" : "2018-12-16T14:24:50Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "ac33b729-888e-41cd-ac5f-4567f59d9210",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "body" : "Hi, I tried to import to a data set in `asia-northeast1` using `GoogleCloudStorageToBigQueryOperator ` and I got the following error as kaxil mentioned.\r\n```[2018-12-26 21:35:47,464] {base_task_runner.py:107} INFO - Job 146: Subtask bq_load_data_into_dest_table_from_gcs [2018-12-26 21:35:47,464] {discovery.py:871} INFO - URL being requested: GET https://www.googleapis.com/bigquery/v2/projects/my-project/jobs/job_abc123?alt=json\r\n[2018-12-26 21:35:47,931] {models.py:1736} ERROR - ('BigQuery job status check failed. Final error was: %s', 404)\r\nTraceback (most recent call last)\r\n  File \"/usr/local/lib/airflow/airflow/contrib/hooks/bigquery_hook.py\", line 981, in run_with_configuratio\r\n    jobId=self.running_job_id).execute(\r\n  File \"/usr/local/lib/python3.6/site-packages/googleapiclient/_helpers.py\", line 130, in positional_wrappe\r\n    return wrapped(*args, **kwargs\r\n  File \"/usr/local/lib/python3.6/site-packages/googleapiclient/http.py\", line 851, in execut\r\n    raise HttpError(resp, content, uri=self.uri\r\ngoogleapiclient.errors.HttpError: <HttpError 404 when requesting https://www.googleapis.com/bigquery/v2/projects/my-project/jobs/job_abc123?alt=json returned \"Not found: Job my-project:job_abc123\"\r\n\r\nDuring handling of the above exception, another exception occurred\r\n\r\nTraceback (most recent call last)\r\n  File \"/usr/local/lib/airflow/airflow/models.py\", line 1633, in _run_raw_tas\r\n    result = task_copy.execute(context=context\r\n  File \"/usr/local/lib/airflow/airflow/contrib/operators/gcs_to_bq.py\", line 237, in execut\r\n    time_partitioning=self.time_partitioning\r\n  File \"/usr/local/lib/airflow/airflow/contrib/hooks/bigquery_hook.py\", line 951, in run_loa\r\n    return self.run_with_configuration(configuration\r\n  File \"/usr/local/lib/airflow/airflow/contrib/hooks/bigquery_hook.py\", line 1003, in run_with_configuratio\r\n    err.resp.status\r\nException: ('BigQuery job status check failed. Final error was: %s', 404\r\n```\r\nhttps://issues.apache.org/jira/browse/AIRFLOW-3571\r\n",
        "createdAt" : "2018-12-27T09:23:24Z",
        "updatedAt" : "2018-12-27T09:23:24Z",
        "lastEditedBy" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "tags" : [
        ]
      },
      {
        "id" : "f7eb7981-54df-4ff2-8c3a-859dd87efd2a",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "@yohei1126 Thanks for confirming, can you also try out with the changes in the PR and see if it fixes the issue for you? \r\n\r\nOnce you confirm, I will then merge it.",
        "createdAt" : "2018-12-27T14:29:50Z",
        "updatedAt" : "2018-12-27T14:29:51Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "bbee2445-2a23-4890-a432-59d5ac0d4b18",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "body" : "OK will do tomorrow",
        "createdAt" : "2018-12-27T14:45:43Z",
        "updatedAt" : "2018-12-27T14:45:43Z",
        "lastEditedBy" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "tags" : [
        ]
      },
      {
        "id" : "6827618d-1ecd-4044-932a-659565c5e5e1",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "body" : "This operator has `destination_dataset_table` so I tested the following four patterns. I suppose it works as expected.\r\n\r\n1. (OK) source dataset in US, destination_dataset in US, no location specified\r\n2. (OK) source dataset in Tokyo, destination_dataset in Tokyo, location specified as `asia-northeast1`\r\n3. (Fail) source dataset in Tokyo, destination_dataset in US, location specified as `asia-northeast1`\r\n4. (Fail) source dataset in US, destination_dataset in Tokyo, no location specified\r\n\r\n\r\n```\r\n# -*- coding: utf-8 -*-\r\nfrom airflow import DAG\r\nfrom operators.bigquery_operator import BigQueryOperator\r\nfrom airflow.utils.dates import days_ago\r\n\r\nARGS = {\r\n    'owner': 'airflow',\r\n    'depends_on_past': False,\r\n    'retries': 0,\r\n    'start_date': days_ago(1)\r\n}\r\n\r\nCOMMON_PARAMS = {}\r\n\r\nwith DAG(\r\n    dag_id='test_bq',\r\n    default_args=ARGS,\r\n    params=COMMON_PARAMS,\r\n    schedule_interval='@once') as dag:\r\n\r\n    # both datasets are in US\r\n    # this should be OK\r\n    t1 = BigQueryOperator(\r\n        task_id='us_to_us',\r\n        sql='SELECT * FROM test_us_ds.test_table',\r\n        bigquery_conn_id='google_cloud_default',\r\n        destination_dataset_table='fr-stg-datalake:test_us_ds.dest_table_us_to_us'\r\n    )\r\n\r\n    # both source dataset and dest dataset are in Tokyo\r\n    # this should be OK\r\n    t2 = BigQueryOperator(\r\n        task_id='tky_to_tky',\r\n        sql='SELECT * FROM test_tokyo_ds.test_table',\r\n        bigquery_conn_id='google_cloud_default',\r\n        location='asia-northeast1',\r\n        destination_dataset_table='fr-stg-datalake:test_tokyo_ds.dest_table_tky_to_tky'\r\n    )\r\n\r\n    # source dataset is in Tokyo but dest table is in US\r\n    # this should fail\r\n    t3 = BigQueryOperator(\r\n        task_id='tky_to_us',\r\n        sql='SELECT * FROM test_tokyo_ds.test_table',\r\n        bigquery_conn_id='google_cloud_default',\r\n        location='asia-northeast1',\r\n        destination_dataset_table='fr-stg-datalake:test_us_ds.dest_table_tky_to_us'\r\n    )\r\n\r\n    # source dataset is in US but dest table is in Tokyo\r\n    # this should fail\r\n    t4 = BigQueryOperator(\r\n        task_id='us_to_tky',\r\n        sql='SELECT * FROM test_us_ds.test_table',\r\n        bigquery_conn_id='google_cloud_default',\r\n        destination_dataset_table='fr-stg-datalake:test_tokyo_ds.dest_table_us_to_tky'\r\n    )\r\n\r\n    t1 >> t2\r\n    t1 >> t3\r\n    t1 >> t4\r\n    globals()[dag] = dag\r\n```",
        "createdAt" : "2018-12-28T07:51:34Z",
        "updatedAt" : "2018-12-28T14:25:56Z",
        "lastEditedBy" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "tags" : [
        ]
      },
      {
        "id" : "4cb8dacd-079d-4bca-b790-6fee1b55258e",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "body" : "FYI: I downloaded `bigquery_operator.py` and `bigquery_hook.py` from this PR and uploaded to my composer (location = `asia-northeast1` ). ",
        "createdAt" : "2018-12-28T07:53:43Z",
        "updatedAt" : "2018-12-28T07:57:40Z",
        "lastEditedBy" : "f7896d17-48a4-405f-bb26-e6e1f70db56a",
        "tags" : [
        ]
      },
      {
        "id" : "3faa271b-54ff-4fd9-ab35-afb428f2736d",
        "parentId" : "82d86c48-f106-4143-91d4-1af380c88868",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Great, thanks for testing it. I will merge this today.",
        "createdAt" : "2018-12-28T08:41:08Z",
        "updatedAt" : "2018-12-28T08:41:08Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "420695045733fdeb71d44442813d23be18130a52",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +589,593 @@        :type cluster_fields: list of str\n        :param location: The geographic location of the job. Required except for\n            US and EU. See details at\n            https://cloud.google.com/bigquery/docs/locations#specifying_your_location\n        :type location: str"
  }
]