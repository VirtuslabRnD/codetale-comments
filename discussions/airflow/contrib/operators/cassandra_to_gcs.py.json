[
  {
    "id" : "1783f9e0-857b-43a5-98ac-080533687651",
    "prId" : 5103,
    "prUrl" : "https://github.com/apache/airflow/pull/5103#pullrequestreview-226676058",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da036610-1bd5-4994-be8a-794b688094de",
        "parentId" : null,
        "authorId" : "fd0eadce-2798-4d2a-a9a2-8863df9c13fa",
        "body" : "As mentioned in another PR.\r\nThis is wrong. The limit is not 4GB it's 5TB:\r\nhttps://cloud.google.com/storage/quotas\r\n\"There is a maximum size limit of 5 TB for individual objects stored in Cloud Storage.\"\r\nI think in general It's best not to mention it at all. The limits can change at will. Airflow can't keep track of all size changes.",
        "createdAt" : "2019-04-15T14:00:07Z",
        "updatedAt" : "2019-04-15T14:00:41Z",
        "lastEditedBy" : "fd0eadce-2798-4d2a-a9a2-8863df9c13fa",
        "tags" : [
        ]
      },
      {
        "id" : "25aac562-521e-487a-8f9a-a7fde48f6935",
        "parentId" : "da036610-1bd5-4994-be8a-794b688094de",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "You are right, this needs to be modified in all GCS related Operators, I will create a PR to remove this lines everywhere and add a reference to `https://cloud.google.com/storage/quotas` page",
        "createdAt" : "2019-04-15T14:21:24Z",
        "updatedAt" : "2019-04-15T14:21:24Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "30106c611f5fe9eb046b33be4245fa7d1ee650a8",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +59,63 @@        to split large table dumps into multiple files (see notes in the\n        filenamed param docs above). Google cloud storage allows for files\n        to be a maximum of 4GB. This param allows developers to specify the\n        file size of the splits.\n    :type approx_max_file_size_bytes: long"
  }
]