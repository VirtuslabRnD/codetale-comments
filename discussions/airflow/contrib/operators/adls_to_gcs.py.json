[
  {
    "id" : "7c5c8c00-d853-4488-bc31-e81356cfe40e",
    "prId" : 4134,
    "prUrl" : "https://github.com/apache/airflow/pull/4134#pullrequestreview-172761565",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4d8f69f-537e-4bbd-a741-f233c07583bb",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Wouldn't this be too big for XCOM? ",
        "createdAt" : "2018-11-05T19:34:14Z",
        "updatedAt" : "2018-11-20T19:49:03Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "53c8796e-54db-4aed-a5ea-730db8a2100e",
        "parentId" : "f4d8f69f-537e-4bbd-a741-f233c07583bb",
        "authorId" : "593397b3-350d-41ca-9156-a073c824f6fd",
        "body" : "Since it's just a collection of strings, it would be pretty unlikely. XCOM values are stored as sqlalchemy.LargeBinary, correct? ",
        "createdAt" : "2018-11-07T16:41:29Z",
        "updatedAt" : "2018-11-20T19:49:03Z",
        "lastEditedBy" : "593397b3-350d-41ca-9156-a073c824f6fd",
        "tags" : [
        ]
      },
      {
        "id" : "8b9673ba-bfe9-4a9b-ae31-4dd7918dbbdc",
        "parentId" : "f4d8f69f-537e-4bbd-a741-f233c07583bb",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Yes, this is true. It will pickle the value and store it in the database. But this is being done for every run.",
        "createdAt" : "2018-11-07T22:28:01Z",
        "updatedAt" : "2018-11-20T19:49:03Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "b9fb726e-c59e-4959-834a-957d9ddc3f42",
        "parentId" : "f4d8f69f-537e-4bbd-a741-f233c07583bb",
        "authorId" : "593397b3-350d-41ca-9156-a073c824f6fd",
        "body" : "I could not return anything to XCOM if you think that makes more sense. I was trying to follow the style of similar operators like S3ToGoogleCloudStorageOperator and GoogleCloudStorageToS3Operator to keep the behavior consistent. ",
        "createdAt" : "2018-11-08T00:24:17Z",
        "updatedAt" : "2018-11-20T19:49:03Z",
        "lastEditedBy" : "593397b3-350d-41ca-9156-a073c824f6fd",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f2a2bfe8f2078a2b14c2a8412d19f5fc5e14bb4",
    "line" : 146,
    "diffHunk" : "@@ -1,1 +144,148 @@            self.log.info(\"In sync, no files needed to be uploaded to GCS\")\n\n        return files"
  },
  {
    "id" : "792789ca-9b66-4221-b610-a7cdb5988f9c",
    "prId" : 4134,
    "prUrl" : "https://github.com/apache/airflow/pull/4134#pullrequestreview-173717969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d6c2f95-1a06-4bf0-8168-4d69771ea28e",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "You need a blank line above this param",
        "createdAt" : "2018-11-11T22:28:29Z",
        "updatedAt" : "2018-11-20T19:49:03Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f2a2bfe8f2078a2b14c2a8412d19f5fc5e14bb4",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +31,35 @@    Synchronizes an Azure Data Lake Storage path with a GCS bucket\n\n    :param src_adls: The Azure Data Lake path to find the objects (templated)\n    :type src_adls: str\n    :param dest_gcs: The Google Cloud Storage bucket and prefix to"
  }
]