[
  {
    "id" : "bb88fab7-a464-4373-a779-029b77fa872d",
    "prId" : 4015,
    "prUrl" : "https://github.com/apache/airflow/pull/4015#pullrequestreview-164252602",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f5d1e63-608e-495d-8eb7-827a6eed7c71",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "This assertion does not make any sense now, right? Since `single_node = num_workers == 0`, the second one will statement always be True.",
        "createdAt" : "2018-10-12T12:07:59Z",
        "updatedAt" : "2018-10-12T12:07:59Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "f2ef50bc-5dd3-4eda-a15b-2a5c46d88f1f",
        "parentId" : "4f5d1e63-608e-495d-8eb7-827a6eed7c71",
        "authorId" : "6283e38d-f887-4b47-9fd7-70b9ef6ff115",
        "body" : "I can imagine someone trying to setup cluster which consists only preemptible workers (`num_preemptible_workers`) and no regular workers (`num_workers`). \r\n\r\nGenerally, we could assert on `num_workers` and `num_preemptible_workers` and allow only cases: \r\n- both values are zeros\r\n- `num_workers` >= 2\r\n\r\nWDYT?",
        "createdAt" : "2018-10-12T13:29:40Z",
        "updatedAt" : "2018-10-12T13:29:40Z",
        "lastEditedBy" : "6283e38d-f887-4b47-9fd7-70b9ef6ff115",
        "tags" : [
        ]
      },
      {
        "id" : "3f405df8-a0e4-4fce-9f7e-cec48bbadf1b",
        "parentId" : "4f5d1e63-608e-495d-8eb7-827a6eed7c71",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Oh, that is true! ;)",
        "createdAt" : "2018-10-12T13:56:10Z",
        "updatedAt" : "2018-10-12T13:56:10Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      }
    ],
    "commit" : "8bf1a3cd284bcec9a0540dd2af2e0ef157cfd437",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +212,216 @@            \"custom_image and image_version can't be both set\"\n\n        assert (\n            not self.single_node or (\n                self.single_node and self.num_preemptible_workers == 0"
  },
  {
    "id" : "7fef2b6d-620c-4eaf-bcd2-7fb912b3fabe",
    "prId" : 4749,
    "prUrl" : "https://github.com/apache/airflow/pull/4749#pullrequestreview-219143407",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "372c754a-bd50-468d-9bd8-9f3972c77f42",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "That is really high. The default on the API is I guess 20 GB or 100GB not sure.",
        "createdAt" : "2019-02-22T14:43:07Z",
        "updatedAt" : "2019-04-15T18:01:39Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "3979606d-740c-4b9f-aff1-c10e77160bdb",
        "parentId" : "372c754a-bd50-468d-9bd8-9f3972c77f42",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "So I did some checking, for both the master and the worker the default is 500gb. If you open up the Dataproc web UI, this is prefilled. Even if I create a 2TB worker, and a 500gb master, it gives the error. Since 500gb is the default, I'm also okay with keeping it like it was.",
        "createdAt" : "2019-02-27T14:18:44Z",
        "updatedAt" : "2019-04-15T18:01:39Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "faafdc11-1e62-42f6-96e9-74c83392d9a1",
        "parentId" : "372c754a-bd50-468d-9bd8-9f3972c77f42",
        "authorId" : "1aceaa64-1d3b-44c8-b7b9-3404a109eb8d",
        "body" : "@DanSedov what's your thoughts? ",
        "createdAt" : "2019-03-02T06:45:47Z",
        "updatedAt" : "2019-04-15T18:01:39Z",
        "lastEditedBy" : "1aceaa64-1d3b-44c8-b7b9-3404a109eb8d",
        "tags" : [
        ]
      },
      {
        "id" : "22861bbc-f67b-443c-aba4-2d153952d687",
        "parentId" : "372c754a-bd50-468d-9bd8-9f3972c77f42",
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "@fenglu-g what are your thoughts? :-)",
        "createdAt" : "2019-03-26T20:30:41Z",
        "updatedAt" : "2019-04-15T18:01:39Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      }
    ],
    "commit" : "96238a0f5dd67c24efb86b25be4fb08966bc9e40",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +161,165 @@                 master_machine_type='n1-standard-4',\n                 master_disk_type='pd-standard',\n                 master_disk_size=1024,\n                 worker_machine_type='n1-standard-4',\n                 worker_disk_type='pd-standard',"
  },
  {
    "id" : "8089fa83-53e0-4210-9cf8-6c2ed08ddead",
    "prId" : 5269,
    "prUrl" : "https://github.com/apache/airflow/pull/5269#pullrequestreview-238036227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8ab6da8-c100-42ef-9383-262735560a5b",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Are you sure it is correct? What was the original problem here and why instanceId was set to random number? I think how it is now is superfluous. RequestId is optional and generating it randomly here makes little sense (it will be generated randomly anyway on the server side). It only makes sense to pass request Id to make sure the operation is idempotent and this will only work when request Id is not randomly generated but passed by the caller explicitly (generated somehow or stored in a local database so that next time we repeat the request we use the same requestID). We need to clarify what we want to achieve here.",
        "createdAt" : "2019-05-14T04:51:11Z",
        "updatedAt" : "2019-05-14T22:29:04Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "9d518228-c15f-4c10-a399-919b084bc7bd",
        "parentId" : "e8ab6da8-c100-42ef-9383-262735560a5b",
        "authorId" : "df66be5c-b6f7-4271-9a3b-5536a375469d",
        "body" : "1 - we're replacing instanceId with requestId. They mean the same thing\r\n2 - you're right that its intended for idempotency. Instead of protecting against Airflow restarts, it guards against first request resulting in HTTP 500 (but succeeding) and then the client retrying and resulting in 2 concurrent dataproc workflows running.\r\n\r\nDoes Airflow provide any internal id that we could use here instead?",
        "createdAt" : "2019-05-14T17:47:40Z",
        "updatedAt" : "2019-05-14T22:29:04Z",
        "lastEditedBy" : "df66be5c-b6f7-4271-9a3b-5536a375469d",
        "tags" : [
        ]
      },
      {
        "id" : "9eaecdbf-7a94-4d7e-8d92-a70d81787df3",
        "parentId" : "e8ab6da8-c100-42ef-9383-262735560a5b",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "1) - I see in the doc instanceId was deprecated and replaced by requestId. so üëç \r\n2) I also see that the docs recommend using UUID so that's also fine üëç ",
        "createdAt" : "2019-05-15T19:52:55Z",
        "updatedAt" : "2019-05-15T19:52:55Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "39e66d77436be2586947843f1847c87fccc55db7",
    "line" : 399,
    "diffHunk" : "@@ -1,1 +1329,1333 @@            .instantiateInline(\n                parent='projects/%s/regions/%s' % (self.project_id, self.region),\n                requestId=str(uuid.uuid4()),\n                body=self.template)\n            .execute())"
  },
  {
    "id" : "1512651f-30a3-41b9-8e6f-8f33ccd40c26",
    "prId" : 5821,
    "prUrl" : "https://github.com/apache/airflow/pull/5821#pullrequestreview-281044236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf1e0d69-6184-4a7a-9497-52f2bc1c8b36",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n    :type optional_components: List[str]\r\n```",
        "createdAt" : "2019-08-21T13:17:00Z",
        "updatedAt" : "2019-08-21T13:17:29Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "02be4bde-bd57-4df7-9667-75c9db767359",
        "parentId" : "bf1e0d69-6184-4a7a-9497-52f2bc1c8b36",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "There is inconsistency in this file in the way types are written. We have to review all types then we will standarize it.  Now the current version is more popular.",
        "createdAt" : "2019-08-28T19:12:06Z",
        "updatedAt" : "2019-08-28T19:12:07Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "634965c6d3b084f2a9f3720146668685676063fa",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +124,128 @@    :param optional_components: List of optional cluster components, for more info see\n        https://cloud.google.com/dataproc/docs/reference/rest/v1/ClusterConfig#Component\n    :type optional_components: list[str]\n    :param num_masters: The # of master nodes to spin up\n    :type num_masters: int"
  }
]