[
  {
    "id" : "0172c229-8682-4480-9f01-24eb633a4a98",
    "prId" : 5663,
    "prUrl" : "https://github.com/apache/airflow/pull/5663#pullrequestreview-267456281",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ee79e65-78de-4ea0-a1c0-ab216a10b2ca",
        "parentId" : null,
        "authorId" : "e7959649-b809-453e-99ab-bb3b572cd83d",
        "body" : "IMO this if block with `break` should be in the end of `while` block?",
        "createdAt" : "2019-07-26T10:59:26Z",
        "updatedAt" : "2019-08-28T05:18:11Z",
        "lastEditedBy" : "e7959649-b809-453e-99ab-bb3b572cd83d",
        "tags" : [
        ]
      },
      {
        "id" : "e98f4c51-f814-40b9-ac92-465c7516c7db",
        "parentId" : "2ee79e65-78de-4ea0-a1c0-ab216a10b2ca",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "The reason I put the here is that there is that if the file size reaches threshold in the last run. It only flush to S3 once in https://github.com/apache/airflow/pull/5663/files#diff-98426c5c739f27ea6aa369d3be536186R124.\r\n\r\nOtherwise if we move the `break` in the end of `while` block, it got flush twice:\r\n1. https://github.com/apache/airflow/pull/5663/files#diff-98426c5c739f27ea6aa369d3be536186R143\r\n2. https://github.com/apache/airflow/pull/5663/files#diff-98426c5c739f27ea6aa369d3be536186R124",
        "createdAt" : "2019-07-27T05:14:34Z",
        "updatedAt" : "2019-08-28T05:18:11Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      }
    ],
    "commit" : "0933de22937468eb7494af9f71f50b79c8808d2a",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +134,138 @@            if 'LastEvaluatedKey' not in response:\n                # no more items to scan\n                break\n\n            last_evaluated_key = response['LastEvaluatedKey']"
  },
  {
    "id" : "cdfe25c2-8740-488d-950c-ba6c9f6f558d",
    "prId" : 6601,
    "prUrl" : "https://github.com/apache/airflow/pull/6601#pullrequestreview-320069197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I am actually still wondering on why we should non-core providers (**contrib** folder) as it is still created by Airflow contributors and not DAG developers !",
        "createdAt" : "2019-11-20T13:55:48Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "1f7abf04-8817-470e-a602-adfef018a1e1",
        "parentId" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "WDYT?",
        "createdAt" : "2019-11-20T13:55:55Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "dd0ee950-99ab-45ee-84c9-b8881b65041f",
        "parentId" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It's mainly because of stability back-forth compatibility but also example for others. If someone develops an external operator or DAG they should use the \"airflow.DAG\", \"airflow.models.BaseOperator\". Those are \"guaranteed\" to be stable. In the future we might decide that for whatever reason we rename the operator to something else and change package, we will still import it here. I really see it as the stable \"API\" of Airflow.\r\n\r\nRegarding the examples - when people create their own operators, they will look at those implemented in core as examples. So better to have them in the way we expect people will be writing them.",
        "createdAt" : "2019-11-20T15:19:01Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "f918c4e3-0dfe-4811-b696-426dc3752c8e",
        "parentId" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I hope it explains it :).",
        "createdAt" : "2019-11-20T15:19:13Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "1bb484cb-747b-4a69-b32d-a64c6fc44841",
        "parentId" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I think we might be talking the same thing or maybe not :D \r\n\r\nWhat I was saying is `airflow.operators` and `airflow.contrib.operators` should use same kind of imports e.g \"airflow.models.BaseOperator\" \"airflow.DAG\" .",
        "createdAt" : "2019-11-20T15:27:03Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "2629e5b8-526e-4f31-8f4d-0171172a068d",
        "parentId" : "73a72452-1506-4672-bc6b-55ded6f781fa",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think they are for operators. The change for DAG is coming as follow-up. Have you seen some place where we use it inconsistently ? I think my pre-commit hooks applies the same checks for \"operators\" and \"contrib\" and \"providers\".",
        "createdAt" : "2019-11-20T16:02:05Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e8be9e171098acda6facbf9f645dd1876b761a3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +33,37 @@\nfrom airflow.contrib.hooks.aws_dynamodb_hook import AwsDynamoDBHook\nfrom airflow.models import BaseOperator\nfrom airflow.providers.amazon.aws.hooks.s3 import S3Hook\n"
  }
]