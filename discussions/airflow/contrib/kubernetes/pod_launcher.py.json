[
  {
    "id" : "33fdf7a8-10a4-44b7-86fd-f9fe7913d22a",
    "prId" : 2853,
    "prUrl" : "https://github.com/apache/airflow/pull/2853#pullrequestreview-88294639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "587efb22-841d-4d2e-965d-15504f368ff3",
        "parentId" : null,
        "authorId" : "4363ee34-34fc-4419-a9b1-8c383c62e81c",
        "body" : "Would it make sense to pass logs from the pod along to airflow, so it appears in the task logs? Eg. so you can track the progress of the worker pod in the airflow web UI. ",
        "createdAt" : "2018-01-05T20:42:53Z",
        "updatedAt" : "2018-01-11T23:31:46Z",
        "lastEditedBy" : "4363ee34-34fc-4419-a9b1-8c383c62e81c",
        "tags" : [
        ]
      },
      {
        "id" : "4f8e5d26-4f44-4251-bba7-6cc4b49d0278",
        "parentId" : "587efb22-841d-4d2e-965d-15504f368ff3",
        "authorId" : "b8b84983-5876-4ccf-886c-2449d94ca22f",
        "body" : "@kevincvlam good point. Should be pretty easy to use the kubernetes client to live-log the results of the pod. This would also handle the logging issues for cases where people don't have ELK (though we probably want this to be optional in case people have their own logging solutions)",
        "createdAt" : "2018-01-05T22:40:53Z",
        "updatedAt" : "2018-01-11T23:31:46Z",
        "lastEditedBy" : "b8b84983-5876-4ccf-886c-2449d94ca22f",
        "tags" : [
        ]
      },
      {
        "id" : "ea8df10b-72d7-4b50-95c9-d2b9ddb2ff91",
        "parentId" : "587efb22-841d-4d2e-965d-15504f368ff3",
        "authorId" : "530497f6-e5e6-42f2-a59c-9d7bbcbecaaf",
        "body" : "@kevincvlam That's a good question and there are a bunch of potential solutions. (You can use a read/write many persistent volume and mount the logs folder into each worker, you can intercept the logs from the kubernetes api itself, you can use a custom airflow logging solution). \r\n\r\nAll of them have tradeoffs, I think we chose not to do anything because there were so many options and not a clear winner. I'm open to exploring this more as I think it's especially important for the executor.",
        "createdAt" : "2018-01-11T20:23:05Z",
        "updatedAt" : "2018-01-11T23:31:46Z",
        "lastEditedBy" : "530497f6-e5e6-42f2-a59c-9d7bbcbecaaf",
        "tags" : [
        ]
      }
    ],
    "commit" : "7fb5906e68fdf351e97acbf04f334b2a86081e81",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +82,86 @@\n        while self.pod_is_running(pod):\n            self.log.info(\"Pod {} has state {}\".format(pod.name, State.RUNNING))\n            time.sleep(2)\n        return self._task_status(self.read_pod(pod))"
  },
  {
    "id" : "0fb9e5fd-8d63-4b6f-bea6-23b3a3d0bf00",
    "prId" : 2853,
    "prUrl" : "https://github.com/apache/airflow/pull/2853#pullrequestreview-87045679",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e41e8aa3-d4cc-4e40-86e8-6bff2135b18d",
        "parentId" : null,
        "authorId" : "7415a51e-f48a-4bc4-96d6-fd0b678c112b",
        "body" : "May want to raise a more helpful exception if this 404s",
        "createdAt" : "2018-01-05T22:55:49Z",
        "updatedAt" : "2018-01-11T23:31:46Z",
        "lastEditedBy" : "7415a51e-f48a-4bc4-96d6-fd0b678c112b",
        "tags" : [
        ]
      }
    ],
    "commit" : "7fb5906e68fdf351e97acbf04f334b2a86081e81",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +102,106 @@        return state != State.SUCCESS and state != State.FAILED\n\n    def read_pod(self, pod):\n        try:\n            return self._client.read_namespaced_pod(pod.name, pod.namespace)"
  }
]