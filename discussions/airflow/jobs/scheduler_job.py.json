[
  {
    "id" : "4998f3fb-c48d-447e-ad76-5339c7f1e357",
    "prId" : 5079,
    "prUrl" : "https://github.com/apache/airflow/pull/5079#pullrequestreview-242973474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a695d6ec-1415-42c8-a049-debe5d603fa8",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Isn't the code below here (handling Pools) now handled by a Dep so this should be removed?",
        "createdAt" : "2019-05-28T16:11:47Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ffe58df7-4a0c-4b62-a280-cfc325d16f4c",
        "parentId" : "a695d6ec-1415-42c8-a049-debe5d603fa8",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "This is the trickiest part: we want to handle this in a Dep in all places, but we do dependencies checks in batch w/o Dep here in the scheduler logic. The current Dep is on the task instance level and doesn't really scale very well in the use case here. I don't yet have a perfect solution to hard weird this part of logic with Deps :( Maybe add batch processing in the current Deps? Feels like belongs to another PR.",
        "createdAt" : "2019-07-07T08:58:39Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "b82718b2d8e5367219f602212d930685d957f12f",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +891,895 @@\n        # Go through each pool, and queue up a task for execution if there are\n        # any open slots in the pool.\n        for pool, task_instances in pool_to_task_instances.items():\n            pool_name = pool"
  },
  {
    "id" : "0dddd880-7282-42e6-a703-11acea5a1fb4",
    "prId" : 5605,
    "prUrl" : "https://github.com/apache/airflow/pull/5605#pullrequestreview-263769431",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae513bc5-6426-490d-9d50-ada44087db88",
        "parentId" : null,
        "authorId" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "body" : "IMO its good to have a fallback value here",
        "createdAt" : "2019-07-18T16:09:25Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "tags" : [
        ]
      },
      {
        "id" : "217d50e9-61e1-4c49-b18c-55378fe14807",
        "parentId" : "ae513bc5-6426-490d-9d50-ada44087db88",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This is already defined in ./airflow/config_templates/default_airflow.cfg so it's not possible to not have a value for this set.",
        "createdAt" : "2019-07-18T16:22:29Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff0878c867134a2f348d46c95fa37586868f4a1f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1276,1280 @@        async_mode = not self.using_sqlite\n\n        processor_timeout_seconds = conf.getint('core', 'dagbag_import_timeout')\n        processor_timeout = timedelta(seconds=processor_timeout_seconds)\n        self.processor_agent = DagFileProcessorAgent(self.subdir,"
  },
  {
    "id" : "de8f1246-fe68-4e40-a83c-37ce04d5c7fd",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265323060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9578167d-e8b3-4b3b-ab6a-f64d9c17e5a9",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I like that we have title for the process :).",
        "createdAt" : "2019-07-23T10:09:02Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "2b37b1d8-592d-4e1e-82cb-326f0d8604b0",
        "parentId" : "9578167d-e8b3-4b3b-ab6a-f64d9c17e5a9",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah, this was something I added to (try) and track down _what_ kind of process was leaking, and I decided to keep it anyway.",
        "createdAt" : "2019-07-23T10:46:21Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +122,126 @@\n        set_context(log, file_path)\n        setproctitle(\"airflow scheduler - DagFileProcessor {}\".format(file_path))\n\n        try:"
  },
  {
    "id" : "efb242b7-b7a1-43f9-84c7-f0c2fdf93df5",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265337855",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think we do not have to join() after we found that _process.is_alive() is False. But it is no harm and it's the kind of sanity way of doing it.",
        "createdAt" : "2019-07-23T10:18:00Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "41cb5161-845c-4572-a222-c4e8f03b17cf",
        "parentId" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "See next comment.",
        "createdAt" : "2019-07-23T10:56:21Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "5596490b-1c51-4869-8098-3bb4a0ffb889",
        "parentId" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Maybe we should then set timeout =0 here as well.",
        "createdAt" : "2019-07-23T11:18:07Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 212,
    "diffHunk" : "@@ -1,1 +261,265 @@            self._done = True\n            self.log.debug(\"Waiting for %s\", self._process)\n            self._process.join()\n            self._parent_channel.close()\n            return True"
  },
  {
    "id" : "926586c3-4e44-409c-90d6-ad6b070797df",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-324909918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b11a72cd-d516-40ec-bb6d-81fd4510ebc9",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Why did SimpleTI get moved but SimpleDag didn't?",
        "createdAt" : "2019-11-30T19:13:58Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "cc6b2f18-71e0-4bda-9207-0edeb4fc4400",
        "parentId" : "b11a72cd-d516-40ec-bb6d-81fd4510ebc9",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Because I realised that SimpleTaskInstance is actually extension of the TaskInstance. Placing it in the dag_processing package was part of the dependency problem. SimpleTaskInstance is just a simpler representation of the Task Instance and it belongs there - not in the DagProcessor. It uses TaskInstance but does not use DagProcessing. \r\n\r\nThere is a chain of dependencies that STI brings if you keep it in DagProcessing, because when you want to use STI you automatically use DagProcessing - which causes cyclic dependencies. Moving STI to TI made it so much simpler and got rid of a number of cyclic deps.",
        "createdAt" : "2019-11-30T21:46:57Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +49,53 @@from airflow.utils import asciiart, helpers, timezone\nfrom airflow.utils.dag_processing import (\n    AbstractDagFileProcessor, DagFileProcessorAgent, SimpleDag, SimpleDagBag,\n)\nfrom airflow.utils.db import provide_session"
  },
  {
    "id" : "5cebfef3-049b-4862-ba87-243952592991",
    "prId" : 6624,
    "prUrl" : "https://github.com/apache/airflow/pull/6624#pullrequestreview-336094470",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f7d93bbf-23e6-44ad-96b5-782d23c63340",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "@mik-laj  @ashb  @kaxil  where is this line supposed to redirect the DagFileProcessor  logs/stdout/stderr to? In CI (using breeze), my observation is that for each DAG, it redirects to individual log files which are in this directory. Looks like it concatenated the absolute path to the dag definition file behind AIRFLOW_HOME. `/root/airflow/opt/airflow/airflow/example_dags/`. \r\n\r\nIs that expected?",
        "createdAt" : "2019-12-24T06:11:51Z",
        "updatedAt" : "2019-12-24T06:11:51Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "75ff53b7e29ed28ab9c43dbca7cba7a11e85ea29",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +129,133 @@        try:\n            # redirect stdout/stderr to log\n            with redirect_stdout(StreamLogWriter(log, logging.INFO)),\\\n                    redirect_stderr(StreamLogWriter(log, logging.WARN)):\n"
  },
  {
    "id" : "5a842864-55d6-4670-84f4-d0b7bf340686",
    "prId" : 6649,
    "prUrl" : "https://github.com/apache/airflow/pull/6649#pullrequestreview-321912917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2242d04-c96e-4af4-b0be-a13fdd285eed",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @kaxil , seems there is the same error in line 758. Do you mind fixing it together?",
        "createdAt" : "2019-11-23T14:26:20Z",
        "updatedAt" : "2019-11-23T14:27:42Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "f4ddcc66-6f68-4c35-bb14-3389fcfd6381",
        "parentId" : "b2242d04-c96e-4af4-b0be-a13fdd285eed",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Done :)",
        "createdAt" : "2019-11-23T14:27:49Z",
        "updatedAt" : "2019-11-23T14:27:49Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a526f526cb8798429e23c7731d0baf2976cede4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +752,756 @@\n        :param old_states: examine TaskInstances in this state\n        :type old_states: list[airflow.utils.state.State]\n        :param new_state: set TaskInstances to this state\n        :type new_state: airflow.utils.state.State"
  },
  {
    "id" : "81c1074d-60ef-4669-944d-6b9009d8b9d2",
    "prId" : 6697,
    "prUrl" : "https://github.com/apache/airflow/pull/6697#pullrequestreview-325802581",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a030803-301f-4f0c-ad0e-101bad7219dd",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "```suggestion\r\n\r\n    :param dag_ids: If specified, only look at these DAG ID's\r\n```",
        "createdAt" : "2019-12-02T23:05:25Z",
        "updatedAt" : "2019-12-08T00:04:17Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "5254e1869916febf54531eafc58d0ec6f3974b19",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +312,316 @@    the file\n\n    :param dag_ids: If specified, only look at these DAG ID's\n    :type dag_ids: List[str]\n    :param log: Logger to save the processing process"
  },
  {
    "id" : "314795bb-2ff0-4f39-86b4-b1282e574dce",
    "prId" : 6697,
    "prUrl" : "https://github.com/apache/airflow/pull/6697#pullrequestreview-328640892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85d1e3f0-27a1-41c3-a5d5-d6ddebf5fd36",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "What I think should happen here as well is to add type annotations and make those classes pylint compliant (and remove --coding--)? \r\n\r\nIt should likely be done in a separate PR. I am working on such PR :)",
        "createdAt" : "2019-12-08T09:52:42Z",
        "updatedAt" : "2019-12-08T22:47:50Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "6fdaf038-7881-47c8-9433-949914c1d1cd",
        "parentId" : "85d1e3f0-27a1-41c3-a5d5-d6ddebf5fd36",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I agree. We should harden the core and this is the first change that does it. Gradually, I will try to introduce further improvements that do this.",
        "createdAt" : "2019-12-08T23:24:04Z",
        "updatedAt" : "2019-12-08T23:24:04Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "5254e1869916febf54531eafc58d0ec6f3974b19",
    "line" : 198,
    "diffHunk" : "@@ -1,1 +313,317 @@\n    :param dag_ids: If specified, only look at these DAG ID's\n    :type dag_ids: List[str]\n    :param log: Logger to save the processing process\n    :type log: logging.Logger"
  },
  {
    "id" : "9a699ee0-21c0-4f08-abbe-93974fa83993",
    "prId" : 7187,
    "prUrl" : "https://github.com/apache/airflow/pull/7187#pullrequestreview-344775658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "We need to write a warning here. It's really dangerous to swallow exceptions silently and it makes it easier to debug any kind of problems you might see in production.",
        "createdAt" : "2020-01-16T11:16:22Z",
        "updatedAt" : "2020-01-16T17:39:23Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "466b63b9-c444-4a4a-9511-b88c3ad485b1",
        "parentId" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "authorId" : "9da97bef-3e93-4c17-8ea6-b1c18b751d15",
        "body" : "I was going to suggest maybe catching a more specific exception subclass (like `AirflowNotFoundException`, `TaskNotFound`, or `TaskInstanceNotFound` as appropriate), but it looks like we really do just throw `AirflowException` in the method: https://github.com/apache/airflow/blob/master/airflow/models/dag.py#L1214. Changing the exception that `get_task` method raises might be out of scope for this PR and have other unanticipated consequences, but it's something to think about...",
        "createdAt" : "2020-01-17T16:02:14Z",
        "updatedAt" : "2020-01-17T16:02:15Z",
        "lastEditedBy" : "9da97bef-3e93-4c17-8ea6-b1c18b751d15",
        "tags" : [
        ]
      },
      {
        "id" : "40c09f50-cef6-4c9f-afa7-73c4ffd7a512",
        "parentId" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "Yeah, that's the first thing came to my mind, I expected that method to throw a more specific exception. I think we should have a clean up PR to change that method's behavior.\r\n\r\nIdeally, i think it should just return None if the task is not found just like a dictionary. Then the caller can explicitly check for the return and handle the edge-case. This way, we won't run into issues like this going forward.",
        "createdAt" : "2020-01-17T18:54:49Z",
        "updatedAt" : "2020-01-17T18:54:50Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      }
    ],
    "commit" : "23dc8c13023c6fb197e2ce5a20ac647b26d22a16",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +435,439 @@                    task = dag.get_task(sla.task_id)\n                except AirflowException:\n                    # task already deleted from DAG, skip it\n                    self.log.warning(\n                        \"Task %s doesn't exist in DAG anymore, skipping SLA miss notification.\","
  },
  {
    "id" : "1f6d502a-e354-4762-8a59-75823a9f8157",
    "prId" : 7370,
    "prUrl" : "https://github.com/apache/airflow/pull/7370#pullrequestreview-363730895",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a74c2c1-beb5-4c23-ba71-dccaaca1f9d1",
        "parentId" : null,
        "authorId" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "body" : "@nuclearpinguin  I believe that this should  be before session.commit(). \r\n\r\nSession.commit() should flush the session, and then sqlalchemy will need to requery each TI individually to reconstruct the STI",
        "createdAt" : "2020-02-24T21:57:46Z",
        "updatedAt" : "2020-02-24T21:57:46Z",
        "lastEditedBy" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "543a91a6388bc2aa134b8cd783bf44b6699c1711",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +1285,1289 @@        # Generate a list of SimpleTaskInstance for the use of queuing\n        # them in the executor.\n        simple_task_instances = [SimpleTaskInstance(ti) for ti in tis_to_set_to_queued]\n\n        task_instance_str = \"\\n\\t\".join([repr(x) for x in tis_to_set_to_queued])"
  },
  {
    "id" : "acb04475-ca6c-46de-ba0e-6f2200d670fe",
    "prId" : 7476,
    "prUrl" : "https://github.com/apache/airflow/pull/7476#pullrequestreview-362582328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3394079-7c95-4989-8504-d57d535ccd89",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "A few lines after this we call self._process_dags, which the makes this same query again. Is it worth passing it in instead?\r\n\r\nThe other thing I'm wondering API wise is if this should be encapsulated inside DagBag (something like a `dagbag.paused_dag_ids` method or accessor) - but that may not play very well with the global/long-lived DagBag object the webserver has.",
        "createdAt" : "2020-02-21T09:25:04Z",
        "updatedAt" : "2020-02-27T17:30:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "7297bdeb-887d-4937-a2b1-ba863418954b",
        "parentId" : "e3394079-7c95-4989-8504-d57d535ccd89",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Good catch. dags parameters contain only active dags, so we don't have to check it a second time.",
        "createdAt" : "2020-02-21T12:00:55Z",
        "updatedAt" : "2020-02-27T17:30:20Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "86d7abc5b8c035f1820531c741ab2dd11d541c83",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +817,821 @@            .filter(DagModel.dag_id.in_(dagbag.dag_ids))\n            .all()\n        )\n\n        # Pickle the DAGs (if necessary) and put them into a SimpleDag"
  },
  {
    "id" : "83f86cd8-50bf-4c25-94cd-202fbf58a216",
    "prId" : 7476,
    "prUrl" : "https://github.com/apache/airflow/pull/7476#pullrequestreview-367131368",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "parentId" : null,
        "authorId" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "body" : "Is IN query recommended here for use cases where we have 10 thousands of paused dag? Shouldn't query be broken into smaller batches? ",
        "createdAt" : "2020-03-02T05:56:47Z",
        "updatedAt" : "2020-03-02T05:56:47Z",
        "lastEditedBy" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "tags" : [
        ]
      },
      {
        "id" : "ad9fec04-f188-494d-aa7f-d01e9e5b8827",
        "parentId" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is executed only for DAGs from one file. In one file you would have to have several thousand DAGs to cause problems. For now, I focused on the situation when we have up to 200 DAGs. If we want to support several thousand DAGs in one file, we need to introduce much more optimization and this one would not change anything.",
        "createdAt" : "2020-03-02T10:10:28Z",
        "updatedAt" : "2020-03-02T10:12:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "5fb17cfc-70d9-499e-9949-107c0be10824",
        "parentId" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "authorId" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "body" : "Sorry for trouble, I missed **DAGs from one file** part earlier I thought we are scanning across folder",
        "createdAt" : "2020-03-02T11:33:37Z",
        "updatedAt" : "2020-03-02T11:34:19Z",
        "lastEditedBy" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "tags" : [
        ]
      }
    ],
    "commit" : "86d7abc5b8c035f1820531c741ab2dd11d541c83",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +815,819 @@            session.query(DagModel.dag_id)\n            .filter(DagModel.is_paused.is_(True))\n            .filter(DagModel.dag_id.in_(dagbag.dag_ids))\n            .all()\n        )"
  },
  {
    "id" : "97fb7a24-bdc3-44f3-91e4-6e8f2b2dc06e",
    "prId" : 7484,
    "prUrl" : "https://github.com/apache/airflow/pull/7484#pullrequestreview-363111910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "What's the no member error here? This one looks unexpected to have to ignore",
        "createdAt" : "2020-02-22T17:11:24Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ca0bbd60-21ec-4c76-931f-e4f85d0ff35b",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "The `is_` for string type of DagRun... ",
        "createdAt" : "2020-02-22T18:52:12Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "f44e93d0-f3be-45c6-a373-1b4601dbe739",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "+1",
        "createdAt" : "2020-02-23T04:32:29Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "35fc19e6-2044-4a4e-b69c-8da031ad6bd4",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Are we just ignoring the other files where we is `is_`?",
        "createdAt" : "2020-02-23T17:59:42Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ae57d098ddf7581b0f311fa8749f4a2195f523",
    "line" : 218,
    "diffHunk" : "@@ -1,1 +1029,1033 @@            .filter(or_(\n                models.DagRun.state != State.RUNNING,\n                models.DagRun.state.is_(None)))  # pylint: disable=no-member\n        # We need to do this for mysql as well because it can cause deadlocks\n        # as discussed in https://issues.apache.org/jira/browse/AIRFLOW-2516"
  },
  {
    "id" : "458d58e0-5576-453e-afac-7dde1cfce073",
    "prId" : 7484,
    "prUrl" : "https://github.com/apache/airflow/pull/7484#pullrequestreview-363064956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d57ff6dc-be16-48da-817d-db1a4d25ab8a",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "same here @kaxil -> no else needed as we have continue.",
        "createdAt" : "2020-02-23T04:33:07Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ae57d098ddf7581b0f311fa8749f4a2195f523",
    "line" : 262,
    "diffHunk" : "@@ -1,1 +1154,1158 @@                continue\n\n            open_slots = pools[pool].open_slots(session=session)\n\n            num_ready = len(task_instances)"
  },
  {
    "id" : "f197d20e-8d2e-4744-ab9c-dad2d0ff7a42",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-363126016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Should the `check_slas` be outside `if dag_runs_for_dag:`?",
        "createdAt" : "2020-02-22T20:56:19Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "e7be8329-b3f7-4434-9caa-c136dbcaf574",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "No, because there must be a DagRun if the task was to be executed. It makes no sense to check the SLA when Dag has never been started.",
        "createdAt" : "2020-02-22T21:04:50Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "cdea8663-2bd8-465a-b4bf-99dc44de7b5f",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I am thinking of a case where a DagRun is just completed and the Dag (or last task) has missed SLA. In which case DagRun won't be in RUNNING state and would be filtered in the following check:\r\n\r\n```\r\ndag_runs = DagRun.find(dag_ids=dag_ids, state=State.RUNNING, session=session)\r\n```\r\n\r\nAnd SLAs won't be triggered for such task",
        "createdAt" : "2020-02-22T21:49:56Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "5e62ff40-1596-46d8-b20a-f954dc065c6c",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "If the task in DAGRun was executed then there must be at least one active DagRun. `DagRun.update_state` method is called by `_process_task_instances.  First, we fetch the runs that are running, and then change from running to another state. If no run was running, then no task should be running.",
        "createdAt" : "2020-02-23T19:35:23Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "37367512-851e-48bf-ad05-771275b47cdb",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Yes, you are right",
        "createdAt" : "2020-02-23T22:07:35Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +731,735 @@                tis_out.extend(self._process_task_instances(dag, dag_runs_for_dag))\n                if check_slas:\n                    self.manage_slas(dag)\n\n        return tis_out"
  },
  {
    "id" : "68d0bacd-259a-4e5b-86ea-c856b16262d2",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-363926153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "057a9cf0-b093-4cdd-9aa4-8a29e6f34fb5",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Nice one, this makes the function far less awkward ",
        "createdAt" : "2020-02-25T07:49:01Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +652,656 @@        # update the state of the previously active dag runs\n        active_dag_runs = 0\n        task_instances_list = []\n        for run in dag_runs:\n            self.log.info(\"Examining DAG run %s\", run)"
  },
  {
    "id" : "bfaa01f1-0ebc-4156-9429-aa2358c10cc3",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-365446936",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13c32cd0-f8b9-4ef8-b422-307c4cd7b647",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "```suggestion\r\n        dag_ids = {dag.dag_id for dag in dags}\r\n```\r\nThis will turn it into a set :)",
        "createdAt" : "2020-02-25T07:50:20Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "14bdc6d7-7d37-4843-b388-fb8b6e58b180",
        "parentId" : "13c32cd0-f8b9-4ef8-b422-307c4cd7b647",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "The list is little faster. \r\nhttps://stackoverflow.com/questions/2831212/python-sets-vs-lists",
        "createdAt" : "2020-02-27T06:51:32Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +703,707 @@\n        tis_out: List[TaskInstanceKeyType] = []\n        dag_ids = [dag.dag_id for dag in dags]\n        dag_runs = DagRun.find(dag_id=dag_ids, state=State.RUNNING, session=session)\n        # As per the docs of groupby (https://docs.python.org/3/library/itertools.html#itertools.groupby)"
  },
  {
    "id" : "131024d4-5f23-4d59-80d4-afd48d01342f",
    "prId" : 7502,
    "prUrl" : "https://github.com/apache/airflow/pull/7502#pullrequestreview-364726969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2fcde8ad-0c0d-4f99-be22-0c07b9e4ddb2",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Actually why do we need this branch? This is a method on DagFileProcessor, so not really user facing.",
        "createdAt" : "2020-02-26T09:05:46Z",
        "updatedAt" : "2020-02-29T11:54:18Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "0d05af1d-a0c7-4243-ba25-937ec54120bf",
        "parentId" : "2fcde8ad-0c0d-4f99-be22-0c07b9e4ddb2",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I did this to facilitate testing of this method both in unit tests and in performance tests. ",
        "createdAt" : "2020-02-26T09:10:00Z",
        "updatedAt" : "2020-02-29T11:54:18Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "616ff6553a70617345a54e11fab81b8da84924b6",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +513,517 @@        # pylint: disable=too-many-nested-blocks\n        if dag.schedule_interval and conf.getboolean('scheduler', 'USE_JOB_SCHEDULE'):\n            if dag_runs is None:\n                active_runs = DagRun.find(\n                    dag_id=dag.dag_id,"
  },
  {
    "id" : "4ad9c378-4225-40ef-8515-70a894dca77b",
    "prId" : 7527,
    "prUrl" : "https://github.com/apache/airflow/pull/7527#pullrequestreview-364194325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@nuclearpinguin This was an example of where we don't need a noqa anymore -- do you know why you did on your pylint fixes to jobs? Is it because we are ignoring this whole file?",
        "createdAt" : "2020-02-25T11:08:25Z",
        "updatedAt" : "2020-02-25T11:36:58Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c11f9634-753d-43fa-b626-bf07e5557c7b",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "`DM.dag_id == None` => disable=singleton-comparison\r\n`DM.dag_id.is_(None)` is correct syntax.",
        "createdAt" : "2020-02-25T11:28:29Z",
        "updatedAt" : "2020-02-25T11:36:58Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "c70abf7d-2e6d-47bd-b79e-66759db2b95a",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah I'm okay with this. My question is why in #7484 does he have\r\n\r\n```\r\nmodels.DagRun.state.is_(None)))  # pylint: disable=no-member\r\n```\r\n\r\nbut we don't need that here?",
        "createdAt" : "2020-02-25T12:06:45Z",
        "updatedAt" : "2020-02-25T12:06:46Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "43388e9f-06fe-4f6f-9193-9d0fa341a314",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(Sorry for not being clear. This comment was not about this PR, but about the other one)",
        "createdAt" : "2020-02-25T13:24:31Z",
        "updatedAt" : "2020-02-25T13:24:32Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "b3def3bc-913c-4d96-a52c-67c157ca34f4",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "I don't know, but here we do not run pylint over this file, do we? @ashb ",
        "createdAt" : "2020-02-25T14:41:39Z",
        "updatedAt" : "2020-02-25T14:41:56Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "d5486de1-2808-4137-96da-6171c12d81a2",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "It's still in TODO list:\r\nhttps://github.com/PolideaInternal/airflow/blob/37c630da636d1ef352273e33fbdb417727914386/scripts/ci/pylint_todo.txt#L11\r\n\r\nAnd I suppose that once I rebase onto new master I will have to fix it in more places...",
        "createdAt" : "2020-02-25T14:43:43Z",
        "updatedAt" : "2020-02-25T14:43:43Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "37c630da636d1ef352273e33fbdb417727914386",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +1104,1108 @@            .filter(or_(DR.run_id.is_(None), not_(DR.run_id.like(BackfillJob.ID_PREFIX + '%'))))\n            .outerjoin(DM, DM.dag_id == TI.dag_id)\n            .filter(or_(DM.dag_id.is_(None), not_(DM.is_paused)))\n            .filter(TI.state == State.SCHEDULED)\n            .all()"
  },
  {
    "id" : "9b8e5c8e-48ad-46cd-9714-d22e7af44dab",
    "prId" : 7561,
    "prUrl" : "https://github.com/apache/airflow/pull/7561#pullrequestreview-366312089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bca60a6b-fbaf-4896-b66b-aab5f6c6757f",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Even one line above we access the processor agent directly.",
        "createdAt" : "2020-02-28T10:26:50Z",
        "updatedAt" : "2020-02-28T10:26:50Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "9a4be397-4488-4d5e-bca3-a062089311b3",
        "parentId" : "bca60a6b-fbaf-4896-b66b-aab5f6c6757f",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "üëç ",
        "createdAt" : "2020-02-28T10:52:22Z",
        "updatedAt" : "2020-02-28T10:52:22Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "521c00b76fb1fa63298b2fcbac3a7bcaa29c4f5d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1550,1554 @@                self.processor_agent.wait_until_finished()\n\n            simple_dags = self.processor_agent.harvest_simple_dags()\n\n            self.log.debug(\"Harvested %d SimpleDAGs\", len(simple_dags))"
  },
  {
    "id" : "695c74cf-fd20-496e-9350-31f42db344fa",
    "prId" : 7674,
    "prUrl" : "https://github.com/apache/airflow/pull/7674#pullrequestreview-371894632",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "567d8101-113e-4c09-b021-21cf13e7b9d0",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n        dagbag: DagBag,\r\n```\r\nCan we use explicit type?",
        "createdAt" : "2020-03-10T11:24:46Z",
        "updatedAt" : "2020-03-11T21:03:58Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "48078329-75f4-4608-be6b-cda80ccf3747",
        "parentId" : "567d8101-113e-4c09-b021-21cf13e7b9d0",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "In other places in this file we use this type of import. I would prefer to keep one convention. I prefer to limit additional changes if I make changes to the core. This makes the review more difficult.\r\n\r\n",
        "createdAt" : "2020-03-10T12:08:58Z",
        "updatedAt" : "2020-03-11T21:03:58Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "4ea2043898dc8c88d1422ae538a5426e320909c5",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +867,871 @@    def _schedule_task_instances(\n        self,\n        dagbag: models.DagBag,\n        ti_keys_to_schedule: List[TaskInstanceKeyType],\n        session=None"
  },
  {
    "id" : "28470df4-64b4-46a5-9dbd-ec70ccf8bd1b",
    "prId" : 9018,
    "prUrl" : "https://github.com/apache/airflow/pull/9018#pullrequestreview-419951191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "574c5b7a-2dbf-4437-b2b9-776c748623d5",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Nice!",
        "createdAt" : "2020-05-28T09:51:29Z",
        "updatedAt" : "2020-05-30T14:14:45Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a83cad9264519c05511d0c21003ae115a25b6b7b",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +390,394 @@            task = dag.get_task(ti.task_id)\n            if not isinstance(task.sla, timedelta):\n                continue\n\n            dttm = dag.following_schedule(ti.execution_date)"
  },
  {
    "id" : "749aa300-53da-4714-8d4f-70b3111228d9",
    "prId" : 9018,
    "prUrl" : "https://github.com/apache/airflow/pull/9018#pullrequestreview-419951191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d924f7c-f9c2-46a9-92a0-eb9877773d6d",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yep :)",
        "createdAt" : "2020-05-28T09:52:59Z",
        "updatedAt" : "2020-05-30T14:14:45Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a83cad9264519c05511d0c21003ae115a25b6b7b",
    "line" : 372,
    "diffHunk" : "@@ -1,1 +1442,1446 @@        \"\"\"\n        if not self.executor.queued_tasks:\n            return\n\n        filter_for_ti_state_change = ("
  },
  {
    "id" : "87648ac2-9d70-4af6-95ca-946bf49ebbb7",
    "prId" : 10729,
    "prUrl" : "https://github.com/apache/airflow/pull/10729#pullrequestreview-482864076",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Can we add this entry to config.yml",
        "createdAt" : "2020-09-04T18:03:40Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "78500651-9eb1-4000-8ecd-c2efdbe7051a",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "or do we want to have a fallback value here",
        "createdAt" : "2020-09-04T18:04:18Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "cbe3a747-e91e-4203-99b6-0675f634d56b",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I thought this already existed - I'll have to check",
        "createdAt" : "2020-09-04T18:17:57Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c0fbe5fc-228a-40b6-93f1-da28eca31825",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "oh you are right, sorry",
        "createdAt" : "2020-09-04T18:23:53Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "83315a9f98c4e68cf749bcd925e42f216b7b7152",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1773,1777 @@        :rtype: int\n        \"\"\"\n        timeout = conf.getint('scheduler', 'scheduler_health_check_threshold')\n\n        num_failed = session.query(SchedulerJob).filter("
  },
  {
    "id" : "95f79bbf-c196-45f4-b1c6-0c0ac5f8c5fe",
    "prId" : 10729,
    "prUrl" : "https://github.com/apache/airflow/pull/10729#pullrequestreview-482921540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "I understand this is \"overwriting\" the same method in the parent class \"BaseJob\", but may be good to mention return type in the docstring (or add type annotations), especially given its return type (returns int) is different from the same method in the parent class (returns list).",
        "createdAt" : "2020-09-04T19:29:02Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "30b20f08-cc76-41c5-b56b-e99c222c591c",
        "parentId" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Ha, I just realise you have remove this method from `BaseJob`.\r\n\r\nBut still good to document down the return type I think.",
        "createdAt" : "2020-09-04T20:17:44Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "efca27ea-6ff9-4652-a526-60d23ee4715e",
        "parentId" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I should make both of them return the same type just for consistency though, good call.",
        "createdAt" : "2020-09-04T20:23:53Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "83315a9f98c4e68cf749bcd925e42f216b7b7152",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1765,1769 @@\n    @provide_session\n    def reset_state_for_orphaned_tasks(self, session: Session = None):\n        \"\"\"\n        Reset any TaskInstance still in QUEUED or SCHEDULED states that were"
  }
]