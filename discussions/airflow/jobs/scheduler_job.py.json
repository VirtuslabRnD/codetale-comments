[
  {
    "id" : "4998f3fb-c48d-447e-ad76-5339c7f1e357",
    "prId" : 5079,
    "prUrl" : "https://github.com/apache/airflow/pull/5079#pullrequestreview-242973474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a695d6ec-1415-42c8-a049-debe5d603fa8",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Isn't the code below here (handling Pools) now handled by a Dep so this should be removed?",
        "createdAt" : "2019-05-28T16:11:47Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ffe58df7-4a0c-4b62-a280-cfc325d16f4c",
        "parentId" : "a695d6ec-1415-42c8-a049-debe5d603fa8",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "This is the trickiest part: we want to handle this in a Dep in all places, but we do dependencies checks in batch w/o Dep here in the scheduler logic. The current Dep is on the task instance level and doesn't really scale very well in the use case here. I don't yet have a perfect solution to hard weird this part of logic with Deps :( Maybe add batch processing in the current Deps? Feels like belongs to another PR.",
        "createdAt" : "2019-07-07T08:58:39Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "b82718b2d8e5367219f602212d930685d957f12f",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +891,895 @@\n        # Go through each pool, and queue up a task for execution if there are\n        # any open slots in the pool.\n        for pool, task_instances in pool_to_task_instances.items():\n            pool_name = pool"
  },
  {
    "id" : "0dddd880-7282-42e6-a703-11acea5a1fb4",
    "prId" : 5605,
    "prUrl" : "https://github.com/apache/airflow/pull/5605#pullrequestreview-263769431",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae513bc5-6426-490d-9d50-ada44087db88",
        "parentId" : null,
        "authorId" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "body" : "IMO its good to have a fallback value here",
        "createdAt" : "2019-07-18T16:09:25Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "tags" : [
        ]
      },
      {
        "id" : "217d50e9-61e1-4c49-b18c-55378fe14807",
        "parentId" : "ae513bc5-6426-490d-9d50-ada44087db88",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This is already defined in ./airflow/config_templates/default_airflow.cfg so it's not possible to not have a value for this set.",
        "createdAt" : "2019-07-18T16:22:29Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff0878c867134a2f348d46c95fa37586868f4a1f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1276,1280 @@        async_mode = not self.using_sqlite\n\n        processor_timeout_seconds = conf.getint('core', 'dagbag_import_timeout')\n        processor_timeout = timedelta(seconds=processor_timeout_seconds)\n        self.processor_agent = DagFileProcessorAgent(self.subdir,"
  },
  {
    "id" : "de8f1246-fe68-4e40-a83c-37ce04d5c7fd",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265323060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9578167d-e8b3-4b3b-ab6a-f64d9c17e5a9",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I like that we have title for the process :).",
        "createdAt" : "2019-07-23T10:09:02Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "2b37b1d8-592d-4e1e-82cb-326f0d8604b0",
        "parentId" : "9578167d-e8b3-4b3b-ab6a-f64d9c17e5a9",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah, this was something I added to (try) and track down _what_ kind of process was leaking, and I decided to keep it anyway.",
        "createdAt" : "2019-07-23T10:46:21Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +122,126 @@\n        set_context(log, file_path)\n        setproctitle(\"airflow scheduler - DagFileProcessor {}\".format(file_path))\n\n        try:"
  },
  {
    "id" : "efb242b7-b7a1-43f9-84c7-f0c2fdf93df5",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265337855",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think we do not have to join() after we found that _process.is_alive() is False. But it is no harm and it's the kind of sanity way of doing it.",
        "createdAt" : "2019-07-23T10:18:00Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "41cb5161-845c-4572-a222-c4e8f03b17cf",
        "parentId" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "See next comment.",
        "createdAt" : "2019-07-23T10:56:21Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "5596490b-1c51-4869-8098-3bb4a0ffb889",
        "parentId" : "99ad33d4-2673-4839-9c5e-93b7245ae753",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Maybe we should then set timeout =0 here as well.",
        "createdAt" : "2019-07-23T11:18:07Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 212,
    "diffHunk" : "@@ -1,1 +261,265 @@            self._done = True\n            self.log.debug(\"Waiting for %s\", self._process)\n            self._process.join()\n            self._parent_channel.close()\n            return True"
  },
  {
    "id" : "926586c3-4e44-409c-90d6-ad6b070797df",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-324909918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b11a72cd-d516-40ec-bb6d-81fd4510ebc9",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Why did SimpleTI get moved but SimpleDag didn't?",
        "createdAt" : "2019-11-30T19:13:58Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "cc6b2f18-71e0-4bda-9207-0edeb4fc4400",
        "parentId" : "b11a72cd-d516-40ec-bb6d-81fd4510ebc9",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Because I realised that SimpleTaskInstance is actually extension of the TaskInstance. Placing it in the dag_processing package was part of the dependency problem. SimpleTaskInstance is just a simpler representation of the Task Instance and it belongs there - not in the DagProcessor. It uses TaskInstance but does not use DagProcessing. \r\n\r\nThere is a chain of dependencies that STI brings if you keep it in DagProcessing, because when you want to use STI you automatically use DagProcessing - which causes cyclic dependencies. Moving STI to TI made it so much simpler and got rid of a number of cyclic deps.",
        "createdAt" : "2019-11-30T21:46:57Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +49,53 @@from airflow.utils import asciiart, helpers, timezone\nfrom airflow.utils.dag_processing import (\n    AbstractDagFileProcessor, DagFileProcessorAgent, SimpleDag, SimpleDagBag,\n)\nfrom airflow.utils.db import provide_session"
  },
  {
    "id" : "5cebfef3-049b-4862-ba87-243952592991",
    "prId" : 6624,
    "prUrl" : "https://github.com/apache/airflow/pull/6624#pullrequestreview-336094470",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f7d93bbf-23e6-44ad-96b5-782d23c63340",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "@mik-laj  @ashb  @kaxil  where is this line supposed to redirect the DagFileProcessor  logs/stdout/stderr to? In CI (using breeze), my observation is that for each DAG, it redirects to individual log files which are in this directory. Looks like it concatenated the absolute path to the dag definition file behind AIRFLOW_HOME. `/root/airflow/opt/airflow/airflow/example_dags/`. \r\n\r\nIs that expected?",
        "createdAt" : "2019-12-24T06:11:51Z",
        "updatedAt" : "2019-12-24T06:11:51Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "75ff53b7e29ed28ab9c43dbca7cba7a11e85ea29",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +129,133 @@        try:\n            # redirect stdout/stderr to log\n            with redirect_stdout(StreamLogWriter(log, logging.INFO)),\\\n                    redirect_stderr(StreamLogWriter(log, logging.WARN)):\n"
  },
  {
    "id" : "5a842864-55d6-4670-84f4-d0b7bf340686",
    "prId" : 6649,
    "prUrl" : "https://github.com/apache/airflow/pull/6649#pullrequestreview-321912917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2242d04-c96e-4af4-b0be-a13fdd285eed",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @kaxil , seems there is the same error in line 758. Do you mind fixing it together?",
        "createdAt" : "2019-11-23T14:26:20Z",
        "updatedAt" : "2019-11-23T14:27:42Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "f4ddcc66-6f68-4c35-bb14-3389fcfd6381",
        "parentId" : "b2242d04-c96e-4af4-b0be-a13fdd285eed",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Done :)",
        "createdAt" : "2019-11-23T14:27:49Z",
        "updatedAt" : "2019-11-23T14:27:49Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a526f526cb8798429e23c7731d0baf2976cede4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +752,756 @@\n        :param old_states: examine TaskInstances in this state\n        :type old_states: list[airflow.utils.state.State]\n        :param new_state: set TaskInstances to this state\n        :type new_state: airflow.utils.state.State"
  },
  {
    "id" : "81c1074d-60ef-4669-944d-6b9009d8b9d2",
    "prId" : 6697,
    "prUrl" : "https://github.com/apache/airflow/pull/6697#pullrequestreview-325802581",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a030803-301f-4f0c-ad0e-101bad7219dd",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "```suggestion\r\n\r\n    :param dag_ids: If specified, only look at these DAG ID's\r\n```",
        "createdAt" : "2019-12-02T23:05:25Z",
        "updatedAt" : "2019-12-08T00:04:17Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "5254e1869916febf54531eafc58d0ec6f3974b19",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +312,316 @@    the file\n\n    :param dag_ids: If specified, only look at these DAG ID's\n    :type dag_ids: List[str]\n    :param log: Logger to save the processing process"
  },
  {
    "id" : "314795bb-2ff0-4f39-86b4-b1282e574dce",
    "prId" : 6697,
    "prUrl" : "https://github.com/apache/airflow/pull/6697#pullrequestreview-328640892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85d1e3f0-27a1-41c3-a5d5-d6ddebf5fd36",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "What I think should happen here as well is to add type annotations and make those classes pylint compliant (and remove --coding--)? \r\n\r\nIt should likely be done in a separate PR. I am working on such PR :)",
        "createdAt" : "2019-12-08T09:52:42Z",
        "updatedAt" : "2019-12-08T22:47:50Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "6fdaf038-7881-47c8-9433-949914c1d1cd",
        "parentId" : "85d1e3f0-27a1-41c3-a5d5-d6ddebf5fd36",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I agree. We should harden the core and this is the first change that does it. Gradually, I will try to introduce further improvements that do this.",
        "createdAt" : "2019-12-08T23:24:04Z",
        "updatedAt" : "2019-12-08T23:24:04Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "5254e1869916febf54531eafc58d0ec6f3974b19",
    "line" : 198,
    "diffHunk" : "@@ -1,1 +313,317 @@\n    :param dag_ids: If specified, only look at these DAG ID's\n    :type dag_ids: List[str]\n    :param log: Logger to save the processing process\n    :type log: logging.Logger"
  },
  {
    "id" : "9a699ee0-21c0-4f08-abbe-93974fa83993",
    "prId" : 7187,
    "prUrl" : "https://github.com/apache/airflow/pull/7187#pullrequestreview-344775658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "We need to write a warning here. It's really dangerous to swallow exceptions silently and it makes it easier to debug any kind of problems you might see in production.",
        "createdAt" : "2020-01-16T11:16:22Z",
        "updatedAt" : "2020-01-16T17:39:23Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "466b63b9-c444-4a4a-9511-b88c3ad485b1",
        "parentId" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "authorId" : "9da97bef-3e93-4c17-8ea6-b1c18b751d15",
        "body" : "I was going to suggest maybe catching a more specific exception subclass (like `AirflowNotFoundException`, `TaskNotFound`, or `TaskInstanceNotFound` as appropriate), but it looks like we really do just throw `AirflowException` in the method: https://github.com/apache/airflow/blob/master/airflow/models/dag.py#L1214. Changing the exception that `get_task` method raises might be out of scope for this PR and have other unanticipated consequences, but it's something to think about...",
        "createdAt" : "2020-01-17T16:02:14Z",
        "updatedAt" : "2020-01-17T16:02:15Z",
        "lastEditedBy" : "9da97bef-3e93-4c17-8ea6-b1c18b751d15",
        "tags" : [
        ]
      },
      {
        "id" : "40c09f50-cef6-4c9f-afa7-73c4ffd7a512",
        "parentId" : "dc53f139-b069-4717-8be7-39794bf805f4",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "Yeah, that's the first thing came to my mind, I expected that method to throw a more specific exception. I think we should have a clean up PR to change that method's behavior.\r\n\r\nIdeally, i think it should just return None if the task is not found just like a dictionary. Then the caller can explicitly check for the return and handle the edge-case. This way, we won't run into issues like this going forward.",
        "createdAt" : "2020-01-17T18:54:49Z",
        "updatedAt" : "2020-01-17T18:54:50Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      }
    ],
    "commit" : "23dc8c13023c6fb197e2ce5a20ac647b26d22a16",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +435,439 @@                    task = dag.get_task(sla.task_id)\n                except AirflowException:\n                    # task already deleted from DAG, skip it\n                    self.log.warning(\n                        \"Task %s doesn't exist in DAG anymore, skipping SLA miss notification.\","
  },
  {
    "id" : "1f6d502a-e354-4762-8a59-75823a9f8157",
    "prId" : 7370,
    "prUrl" : "https://github.com/apache/airflow/pull/7370#pullrequestreview-363730895",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a74c2c1-beb5-4c23-ba71-dccaaca1f9d1",
        "parentId" : null,
        "authorId" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "body" : "@nuclearpinguin  I believe that this should  be before session.commit(). \r\n\r\nSession.commit() should flush the session, and then sqlalchemy will need to requery each TI individually to reconstruct the STI",
        "createdAt" : "2020-02-24T21:57:46Z",
        "updatedAt" : "2020-02-24T21:57:46Z",
        "lastEditedBy" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "543a91a6388bc2aa134b8cd783bf44b6699c1711",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +1285,1289 @@        # Generate a list of SimpleTaskInstance for the use of queuing\n        # them in the executor.\n        simple_task_instances = [SimpleTaskInstance(ti) for ti in tis_to_set_to_queued]\n\n        task_instance_str = \"\\n\\t\".join([repr(x) for x in tis_to_set_to_queued])"
  },
  {
    "id" : "acb04475-ca6c-46de-ba0e-6f2200d670fe",
    "prId" : 7476,
    "prUrl" : "https://github.com/apache/airflow/pull/7476#pullrequestreview-362582328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3394079-7c95-4989-8504-d57d535ccd89",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "A few lines after this we call self._process_dags, which the makes this same query again. Is it worth passing it in instead?\r\n\r\nThe other thing I'm wondering API wise is if this should be encapsulated inside DagBag (something like a `dagbag.paused_dag_ids` method or accessor) - but that may not play very well with the global/long-lived DagBag object the webserver has.",
        "createdAt" : "2020-02-21T09:25:04Z",
        "updatedAt" : "2020-02-27T17:30:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "7297bdeb-887d-4937-a2b1-ba863418954b",
        "parentId" : "e3394079-7c95-4989-8504-d57d535ccd89",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Good catch. dags parameters contain only active dags, so we don't have to check it a second time.",
        "createdAt" : "2020-02-21T12:00:55Z",
        "updatedAt" : "2020-02-27T17:30:20Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "86d7abc5b8c035f1820531c741ab2dd11d541c83",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +817,821 @@            .filter(DagModel.dag_id.in_(dagbag.dag_ids))\n            .all()\n        )\n\n        # Pickle the DAGs (if necessary) and put them into a SimpleDag"
  },
  {
    "id" : "83f86cd8-50bf-4c25-94cd-202fbf58a216",
    "prId" : 7476,
    "prUrl" : "https://github.com/apache/airflow/pull/7476#pullrequestreview-367131368",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "parentId" : null,
        "authorId" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "body" : "Is IN query recommended here for use cases where we have 10 thousands of paused dag? Shouldn't query be broken into smaller batches? ",
        "createdAt" : "2020-03-02T05:56:47Z",
        "updatedAt" : "2020-03-02T05:56:47Z",
        "lastEditedBy" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "tags" : [
        ]
      },
      {
        "id" : "ad9fec04-f188-494d-aa7f-d01e9e5b8827",
        "parentId" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is executed only for DAGs from one file. In one file you would have to have several thousand DAGs to cause problems. For now, I focused on the situation when we have up to 200 DAGs. If we want to support several thousand DAGs in one file, we need to introduce much more optimization and this one would not change anything.",
        "createdAt" : "2020-03-02T10:10:28Z",
        "updatedAt" : "2020-03-02T10:12:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "5fb17cfc-70d9-499e-9949-107c0be10824",
        "parentId" : "33a0df89-9a69-4bd8-a373-5ad80aab4a38",
        "authorId" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "body" : "Sorry for trouble, I missed **DAGs from one file** part earlier I thought we are scanning across folder",
        "createdAt" : "2020-03-02T11:33:37Z",
        "updatedAt" : "2020-03-02T11:34:19Z",
        "lastEditedBy" : "0c0a2937-4012-41eb-b4a4-4716de9ebc4a",
        "tags" : [
        ]
      }
    ],
    "commit" : "86d7abc5b8c035f1820531c741ab2dd11d541c83",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +815,819 @@            session.query(DagModel.dag_id)\n            .filter(DagModel.is_paused.is_(True))\n            .filter(DagModel.dag_id.in_(dagbag.dag_ids))\n            .all()\n        )"
  },
  {
    "id" : "97fb7a24-bdc3-44f3-91e4-6e8f2b2dc06e",
    "prId" : 7484,
    "prUrl" : "https://github.com/apache/airflow/pull/7484#pullrequestreview-363111910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "What's the no member error here? This one looks unexpected to have to ignore",
        "createdAt" : "2020-02-22T17:11:24Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ca0bbd60-21ec-4c76-931f-e4f85d0ff35b",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "The `is_` for string type of DagRun... ",
        "createdAt" : "2020-02-22T18:52:12Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "f44e93d0-f3be-45c6-a373-1b4601dbe739",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "+1",
        "createdAt" : "2020-02-23T04:32:29Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "35fc19e6-2044-4a4e-b69c-8da031ad6bd4",
        "parentId" : "5b19a564-b001-46f4-b934-31b8a328f20b",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Are we just ignoring the other files where we is `is_`?",
        "createdAt" : "2020-02-23T17:59:42Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ae57d098ddf7581b0f311fa8749f4a2195f523",
    "line" : 218,
    "diffHunk" : "@@ -1,1 +1029,1033 @@            .filter(or_(\n                models.DagRun.state != State.RUNNING,\n                models.DagRun.state.is_(None)))  # pylint: disable=no-member\n        # We need to do this for mysql as well because it can cause deadlocks\n        # as discussed in https://issues.apache.org/jira/browse/AIRFLOW-2516"
  },
  {
    "id" : "458d58e0-5576-453e-afac-7dde1cfce073",
    "prId" : 7484,
    "prUrl" : "https://github.com/apache/airflow/pull/7484#pullrequestreview-363064956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d57ff6dc-be16-48da-817d-db1a4d25ab8a",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "same here @kaxil -> no else needed as we have continue.",
        "createdAt" : "2020-02-23T04:33:07Z",
        "updatedAt" : "2020-02-25T15:29:09Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ae57d098ddf7581b0f311fa8749f4a2195f523",
    "line" : 262,
    "diffHunk" : "@@ -1,1 +1154,1158 @@                continue\n\n            open_slots = pools[pool].open_slots(session=session)\n\n            num_ready = len(task_instances)"
  },
  {
    "id" : "f197d20e-8d2e-4744-ab9c-dad2d0ff7a42",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-363126016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Should the `check_slas` be outside `if dag_runs_for_dag:`?",
        "createdAt" : "2020-02-22T20:56:19Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "e7be8329-b3f7-4434-9caa-c136dbcaf574",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "No, because there must be a DagRun if the task was to be executed. It makes no sense to check the SLA when Dag has never been started.",
        "createdAt" : "2020-02-22T21:04:50Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "cdea8663-2bd8-465a-b4bf-99dc44de7b5f",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I am thinking of a case where a DagRun is just completed and the Dag (or last task) has missed SLA. In which case DagRun won't be in RUNNING state and would be filtered in the following check:\r\n\r\n```\r\ndag_runs = DagRun.find(dag_ids=dag_ids, state=State.RUNNING, session=session)\r\n```\r\n\r\nAnd SLAs won't be triggered for such task",
        "createdAt" : "2020-02-22T21:49:56Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "5e62ff40-1596-46d8-b20a-f954dc065c6c",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "If the task in DAGRun was executed then there must be at least one active DagRun. `DagRun.update_state` method is called by `_process_task_instances.  First, we fetch the runs that are running, and then change from running to another state. If no run was running, then no task should be running.",
        "createdAt" : "2020-02-23T19:35:23Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "37367512-851e-48bf-ad05-771275b47cdb",
        "parentId" : "7405c42d-ff17-4d44-af16-04eb828ada41",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Yes, you are right",
        "createdAt" : "2020-02-23T22:07:35Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +731,735 @@                tis_out.extend(self._process_task_instances(dag, dag_runs_for_dag))\n                if check_slas:\n                    self.manage_slas(dag)\n\n        return tis_out"
  },
  {
    "id" : "68d0bacd-259a-4e5b-86ea-c856b16262d2",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-363926153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "057a9cf0-b093-4cdd-9aa4-8a29e6f34fb5",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Nice one, this makes the function far less awkward ",
        "createdAt" : "2020-02-25T07:49:01Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +652,656 @@        # update the state of the previously active dag runs\n        active_dag_runs = 0\n        task_instances_list = []\n        for run in dag_runs:\n            self.log.info(\"Examining DAG run %s\", run)"
  },
  {
    "id" : "bfaa01f1-0ebc-4156-9429-aa2358c10cc3",
    "prId" : 7489,
    "prUrl" : "https://github.com/apache/airflow/pull/7489#pullrequestreview-365446936",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13c32cd0-f8b9-4ef8-b422-307c4cd7b647",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "```suggestion\r\n        dag_ids = {dag.dag_id for dag in dags}\r\n```\r\nThis will turn it into a set :)",
        "createdAt" : "2020-02-25T07:50:20Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "14bdc6d7-7d37-4843-b388-fb8b6e58b180",
        "parentId" : "13c32cd0-f8b9-4ef8-b422-307c4cd7b647",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "The list is little faster. \r\nhttps://stackoverflow.com/questions/2831212/python-sets-vs-lists",
        "createdAt" : "2020-02-27T06:51:32Z",
        "updatedAt" : "2020-02-28T15:32:37Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "79448a80b2ee65873cba0fbab6e7124e75963f1c",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +703,707 @@\n        tis_out: List[TaskInstanceKeyType] = []\n        dag_ids = [dag.dag_id for dag in dags]\n        dag_runs = DagRun.find(dag_id=dag_ids, state=State.RUNNING, session=session)\n        # As per the docs of groupby (https://docs.python.org/3/library/itertools.html#itertools.groupby)"
  },
  {
    "id" : "131024d4-5f23-4d59-80d4-afd48d01342f",
    "prId" : 7502,
    "prUrl" : "https://github.com/apache/airflow/pull/7502#pullrequestreview-364726969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2fcde8ad-0c0d-4f99-be22-0c07b9e4ddb2",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Actually why do we need this branch? This is a method on DagFileProcessor, so not really user facing.",
        "createdAt" : "2020-02-26T09:05:46Z",
        "updatedAt" : "2020-02-29T11:54:18Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "0d05af1d-a0c7-4243-ba25-937ec54120bf",
        "parentId" : "2fcde8ad-0c0d-4f99-be22-0c07b9e4ddb2",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I did this to facilitate testing of this method both in unit tests and in performance tests. ",
        "createdAt" : "2020-02-26T09:10:00Z",
        "updatedAt" : "2020-02-29T11:54:18Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "616ff6553a70617345a54e11fab81b8da84924b6",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +513,517 @@        # pylint: disable=too-many-nested-blocks\n        if dag.schedule_interval and conf.getboolean('scheduler', 'USE_JOB_SCHEDULE'):\n            if dag_runs is None:\n                active_runs = DagRun.find(\n                    dag_id=dag.dag_id,"
  },
  {
    "id" : "4ad9c378-4225-40ef-8515-70a894dca77b",
    "prId" : 7527,
    "prUrl" : "https://github.com/apache/airflow/pull/7527#pullrequestreview-364194325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@nuclearpinguin This was an example of where we don't need a noqa anymore -- do you know why you did on your pylint fixes to jobs? Is it because we are ignoring this whole file?",
        "createdAt" : "2020-02-25T11:08:25Z",
        "updatedAt" : "2020-02-25T11:36:58Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c11f9634-753d-43fa-b626-bf07e5557c7b",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "`DM.dag_id == None` => disable=singleton-comparison\r\n`DM.dag_id.is_(None)` is correct syntax.",
        "createdAt" : "2020-02-25T11:28:29Z",
        "updatedAt" : "2020-02-25T11:36:58Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "c70abf7d-2e6d-47bd-b79e-66759db2b95a",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah I'm okay with this. My question is why in #7484 does he have\r\n\r\n```\r\nmodels.DagRun.state.is_(None)))  # pylint: disable=no-member\r\n```\r\n\r\nbut we don't need that here?",
        "createdAt" : "2020-02-25T12:06:45Z",
        "updatedAt" : "2020-02-25T12:06:46Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "43388e9f-06fe-4f6f-9193-9d0fa341a314",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(Sorry for not being clear. This comment was not about this PR, but about the other one)",
        "createdAt" : "2020-02-25T13:24:31Z",
        "updatedAt" : "2020-02-25T13:24:32Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "b3def3bc-913c-4d96-a52c-67c157ca34f4",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "I don't know, but here we do not run pylint over this file, do we? @ashb ",
        "createdAt" : "2020-02-25T14:41:39Z",
        "updatedAt" : "2020-02-25T14:41:56Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "d5486de1-2808-4137-96da-6171c12d81a2",
        "parentId" : "2acae559-789c-4b1c-8874-1f1c4f8608a4",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "It's still in TODO list:\r\nhttps://github.com/PolideaInternal/airflow/blob/37c630da636d1ef352273e33fbdb417727914386/scripts/ci/pylint_todo.txt#L11\r\n\r\nAnd I suppose that once I rebase onto new master I will have to fix it in more places...",
        "createdAt" : "2020-02-25T14:43:43Z",
        "updatedAt" : "2020-02-25T14:43:43Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "37c630da636d1ef352273e33fbdb417727914386",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +1104,1108 @@            .filter(or_(DR.run_id.is_(None), not_(DR.run_id.like(BackfillJob.ID_PREFIX + '%'))))\n            .outerjoin(DM, DM.dag_id == TI.dag_id)\n            .filter(or_(DM.dag_id.is_(None), not_(DM.is_paused)))\n            .filter(TI.state == State.SCHEDULED)\n            .all()"
  },
  {
    "id" : "9b8e5c8e-48ad-46cd-9714-d22e7af44dab",
    "prId" : 7561,
    "prUrl" : "https://github.com/apache/airflow/pull/7561#pullrequestreview-366312089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bca60a6b-fbaf-4896-b66b-aab5f6c6757f",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Even one line above we access the processor agent directly.",
        "createdAt" : "2020-02-28T10:26:50Z",
        "updatedAt" : "2020-02-28T10:26:50Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "9a4be397-4488-4d5e-bca3-a062089311b3",
        "parentId" : "bca60a6b-fbaf-4896-b66b-aab5f6c6757f",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "ðŸ‘ ",
        "createdAt" : "2020-02-28T10:52:22Z",
        "updatedAt" : "2020-02-28T10:52:22Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "521c00b76fb1fa63298b2fcbac3a7bcaa29c4f5d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1550,1554 @@                self.processor_agent.wait_until_finished()\n\n            simple_dags = self.processor_agent.harvest_simple_dags()\n\n            self.log.debug(\"Harvested %d SimpleDAGs\", len(simple_dags))"
  },
  {
    "id" : "695c74cf-fd20-496e-9350-31f42db344fa",
    "prId" : 7674,
    "prUrl" : "https://github.com/apache/airflow/pull/7674#pullrequestreview-371894632",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "567d8101-113e-4c09-b021-21cf13e7b9d0",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n        dagbag: DagBag,\r\n```\r\nCan we use explicit type?",
        "createdAt" : "2020-03-10T11:24:46Z",
        "updatedAt" : "2020-03-11T21:03:58Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "48078329-75f4-4608-be6b-cda80ccf3747",
        "parentId" : "567d8101-113e-4c09-b021-21cf13e7b9d0",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "In other places in this file we use this type of import. I would prefer to keep one convention. I prefer to limit additional changes if I make changes to the core. This makes the review more difficult.\r\n\r\n",
        "createdAt" : "2020-03-10T12:08:58Z",
        "updatedAt" : "2020-03-11T21:03:58Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "4ea2043898dc8c88d1422ae538a5426e320909c5",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +867,871 @@    def _schedule_task_instances(\n        self,\n        dagbag: models.DagBag,\n        ti_keys_to_schedule: List[TaskInstanceKeyType],\n        session=None"
  },
  {
    "id" : "28470df4-64b4-46a5-9dbd-ec70ccf8bd1b",
    "prId" : 9018,
    "prUrl" : "https://github.com/apache/airflow/pull/9018#pullrequestreview-419951191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "574c5b7a-2dbf-4437-b2b9-776c748623d5",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Nice!",
        "createdAt" : "2020-05-28T09:51:29Z",
        "updatedAt" : "2020-05-30T14:14:45Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a83cad9264519c05511d0c21003ae115a25b6b7b",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +390,394 @@            task = dag.get_task(ti.task_id)\n            if not isinstance(task.sla, timedelta):\n                continue\n\n            dttm = dag.following_schedule(ti.execution_date)"
  },
  {
    "id" : "749aa300-53da-4714-8d4f-70b3111228d9",
    "prId" : 9018,
    "prUrl" : "https://github.com/apache/airflow/pull/9018#pullrequestreview-419951191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d924f7c-f9c2-46a9-92a0-eb9877773d6d",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yep :)",
        "createdAt" : "2020-05-28T09:52:59Z",
        "updatedAt" : "2020-05-30T14:14:45Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a83cad9264519c05511d0c21003ae115a25b6b7b",
    "line" : 372,
    "diffHunk" : "@@ -1,1 +1442,1446 @@        \"\"\"\n        if not self.executor.queued_tasks:\n            return\n\n        filter_for_ti_state_change = ("
  },
  {
    "id" : "87648ac2-9d70-4af6-95ca-946bf49ebbb7",
    "prId" : 10729,
    "prUrl" : "https://github.com/apache/airflow/pull/10729#pullrequestreview-482864076",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Can we add this entry to config.yml",
        "createdAt" : "2020-09-04T18:03:40Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "78500651-9eb1-4000-8ecd-c2efdbe7051a",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "or do we want to have a fallback value here",
        "createdAt" : "2020-09-04T18:04:18Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "cbe3a747-e91e-4203-99b6-0675f634d56b",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I thought this already existed - I'll have to check",
        "createdAt" : "2020-09-04T18:17:57Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c0fbe5fc-228a-40b6-93f1-da28eca31825",
        "parentId" : "79f6d76a-abfd-462f-941e-aaa3d62d10d7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "oh you are right, sorry",
        "createdAt" : "2020-09-04T18:23:53Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "83315a9f98c4e68cf749bcd925e42f216b7b7152",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1773,1777 @@        :rtype: int\n        \"\"\"\n        timeout = conf.getint('scheduler', 'scheduler_health_check_threshold')\n\n        num_failed = session.query(SchedulerJob).filter("
  },
  {
    "id" : "95f79bbf-c196-45f4-b1c6-0c0ac5f8c5fe",
    "prId" : 10729,
    "prUrl" : "https://github.com/apache/airflow/pull/10729#pullrequestreview-482921540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "I understand this is \"overwriting\" the same method in the parent class \"BaseJob\", but may be good to mention return type in the docstring (or add type annotations), especially given its return type (returns int) is different from the same method in the parent class (returns list).",
        "createdAt" : "2020-09-04T19:29:02Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "30b20f08-cc76-41c5-b56b-e99c222c591c",
        "parentId" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Ha, I just realise you have remove this method from `BaseJob`.\r\n\r\nBut still good to document down the return type I think.",
        "createdAt" : "2020-09-04T20:17:44Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "efca27ea-6ff9-4652-a526-60d23ee4715e",
        "parentId" : "f02112ba-7c39-4f5e-98bc-288803481a85",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I should make both of them return the same type just for consistency though, good call.",
        "createdAt" : "2020-09-04T20:23:53Z",
        "updatedAt" : "2020-09-10T14:36:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "83315a9f98c4e68cf749bcd925e42f216b7b7152",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1765,1769 @@\n    @provide_session\n    def reset_state_for_orphaned_tasks(self, session: Session = None):\n        \"\"\"\n        Reset any TaskInstance still in QUEUED or SCHEDULED states that were"
  },
  {
    "id" : "fff9f3e4-019d-4b2f-962a-ab561d01ab3e",
    "prId" : 10949,
    "prUrl" : "https://github.com/apache/airflow/pull/10949#pullrequestreview-489769921",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f4d71eb-bfc6-4998-8b22-0d43a963c139",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Not related, but is this comment still valid?",
        "createdAt" : "2020-09-16T15:08:39Z",
        "updatedAt" : "2020-09-16T17:45:11Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "71df6c80-e11c-40c4-b082-971a550fe4d3",
        "parentId" : "8f4d71eb-bfc6-4998-8b22-0d43a963c139",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Not sure off the top of my head.",
        "createdAt" : "2020-09-16T15:53:45Z",
        "updatedAt" : "2020-09-16T17:45:12Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "092b9c0d0577f60f59534b4fd0914cc5f6da3080",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +1560,1564 @@            state, info = event_buffer.pop(buffer_key)\n\n            # TODO: should we fail RUNNING as well, as we do in Backfills?\n            if state == State.QUEUED:\n                ti.external_executor_id = info"
  },
  {
    "id" : "6ec6f8ba-9347-42f9-8604-041c35842651",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-505739414",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "324f29f4-9e02-4c2a-942a-2de4a88c2ef8",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n        :rtype: Optional[None]\r\n```",
        "createdAt" : "2020-09-15T19:04:01Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "8be840ee-2352-40cf-b65c-47ffc9a1a526",
        "parentId" : "324f29f4-9e02-4c2a-942a-2de4a88c2ef8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Doc typing uses a different syntax to type comments https://www.sphinx-doc.org/en/master/usage/restructuredtext/domains.html#info-field-lists:\r\n\r\n> Multiple types in a type field will be linked automatically if separated by the word â€œorâ€:\r\n> ```\r\n> :type an_arg: int or None\r\n> :vartype a_var: str or int\r\n> :rtype: float or str\r\n> ```\r\n\r\n",
        "createdAt" : "2020-09-16T11:54:19Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "621eb36b-3a61-453e-9268-1771be0c6690",
        "parentId" : "324f29f4-9e02-4c2a-942a-2de4a88c2ef8",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Interesting, TIL ðŸ‘Œ ",
        "createdAt" : "2020-09-16T12:01:15Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "a723c425-c497-4c24-9f17-9aa5a4a7edd0",
        "parentId" : "324f29f4-9e02-4c2a-942a-2de4a88c2ef8",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This function returns tuple or None. The description in the pydocstring is incorrect.\r\n`int or None` != `Optional[Tuple[int, int]]`",
        "createdAt" : "2020-10-09T14:42:12Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +341,345 @@        \"\"\"\n        :return: result of running SchedulerJob.process_file()\n        :rtype: int or None\n        \"\"\"\n        if not self.done:"
  },
  {
    "id" : "94f97249-1ea3-4328-8a95-08293e5d67f3",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-489545130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba6f969e-9bd6-4100-be2a-31fdb28a77f1",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Can you please add a description so people in the future will be able to understand the purpose of this method?",
        "createdAt" : "2020-09-15T19:10:04Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "2eb2d09e-ea9e-43dd-89ee-113216bb7a0a",
        "parentId" : "ba6f969e-9bd6-4100-be2a-31fdb28a77f1",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yes -- I might also rename this method as a critical section has a meaning:\r\n\r\n> In concurrent programming, concurrent accesses to shared resources can lead to unexpected or erroneous behavior, so parts of the program where the shared resource is accessed need to be protected in ways that avoid the concurrent access. This protected section is the critical section or critical region\r\n\r\nBut this entire function isn't critical any longer, just the execute part at the end.",
        "createdAt" : "2020-09-16T09:09:35Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "eeef9285-717e-4800-b6ac-baf1cbfb3d34",
        "parentId" : "ba6f969e-9bd6-4100-be2a-31fdb28a77f1",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Fixed in 783b91162",
        "createdAt" : "2020-09-16T11:52:07Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 1263,
    "diffHunk" : "@@ -1,1 +1425,1429 @@\n    def _do_scheduling(self, session) -> int:\n        \"\"\"\n        This function is where the main scheduling decisions take places. It:\n"
  },
  {
    "id" : "d504cdce-28e5-4387-ae51-e7f591621bc0",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-503126413",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b00bbdd-7932-4689-b2b3-fc4896ddbd7e",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Would you elaborate a bit on the rational behind unconditionally creating a DAG please? Can this break the max_active_runs guarantee? E.g. next_dagrun_create_after is set after the last round of DAG parsing, then someone cleared a couple tasks bringing the DAG run count to its limit, then this part creates another DAG run and no TI will be scheduled for the new DAG runs causing the active DR count stuck above the limit.",
        "createdAt" : "2020-09-19T00:22:45Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "6e25c7a6-cb66-4110-a7b1-9cd0b07deea9",
        "parentId" : "5b00bbdd-7932-4689-b2b3-fc4896ddbd7e",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Unconditional here as the checks are done elsewhere/at the caller.\n\nI'll double check the case you mention - I think it's already covered in the unit tests too",
        "createdAt" : "2020-09-19T08:07:21Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "4f9385d4-d0bb-4543-876c-57c50ea56af9",
        "parentId" : "5b00bbdd-7932-4689-b2b3-fc4896ddbd7e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Got it. I guess then we need some more checks in the caller--currently I haven't noticed other checks except checking the existence of `next_dagrun_create_after` value before we come here create the DAG run. The test `test_runs_respected_after_clear` I think covers part of it, it checks the scheduling part but even if it passed (which I don't think it will given that[ it returns directly when active run > max run](https://github.com/apache/airflow/pull/10956/files/f3c6cf1dc10e509da1b3b1db2a595a58abfab847#diff-c35269bcfbbe386e269ffa7487e86192R1492-R1498) rather than before[ active run += 1 after the run is processed](https://github.com/apache/airflow/pull/10956/files/f3c6cf1dc10e509da1b3b1db2a595a58abfab847#diff-c35269bcfbbe386e269ffa7487e86192L723)), we can still create an extra DAG run here.\r\n",
        "createdAt" : "2020-09-20T09:24:50Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "4da68add-e7f2-4415-bc3e-c451eb77c5d8",
        "parentId" : "5b00bbdd-7932-4689-b2b3-fc4896ddbd7e",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "The extra checks on max active runs etc have been added now.",
        "createdAt" : "2020-10-06T16:02:28Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 1427,
    "diffHunk" : "@@ -1,1 +1551,1555 @@    def _create_dag_runs(self, dag_models: Iterable[DagModel], session: Session) -> None:\n        \"\"\"\n        Unconditionally create a DAG run for the given DAG, and update the dag_model's fields to control\n        if/when the next DAGRun should be created\n        \"\"\""
  },
  {
    "id" : "8f6c53d8-4783-4750-9551-9b2f81a59a6d",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-505772633",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22724b7f-896b-4f4a-8407-ee8fa9dc46aa",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Why we don't initialize the `DagBag` in L607 with this parameter?",
        "createdAt" : "2020-09-21T13:39:26Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "66e23292-4d5a-4110-b398-3daeda904b28",
        "parentId" : "22724b7f-896b-4f4a-8407-ee8fa9dc46aa",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "@turbaszek can you say something more? I see you closed this conversation. ",
        "createdAt" : "2020-10-09T14:45:39Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "d1f3ac6e-313a-4f41-9b98-c2979e620684",
        "parentId" : "22724b7f-896b-4f4a-8407-ee8fa9dc46aa",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Ok. I fount an answer. https://github.com/apache/airflow/pull/10956#discussion_r500572553",
        "createdAt" : "2020-10-09T15:20:47Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 551,
    "diffHunk" : "@@ -1,1 +682,686 @@\n        # Save individual DAGs in the ORM\n        dagbag.read_dags_from_db = True\n\n        # Retry 'dagbag.sync_to_db()' in case of any Operational Errors"
  },
  {
    "id" : "dd943e4c-1bb9-4499-a50f-49b53acd8b23",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-503351614",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Should we separate the DagBag (read_dags_from_db=True) out from the DagBag functionality regarding file reading ? Seems that DagBag(read_dags_from_db=True) is a pass-trought to retrieve Dag via it's Id in a lazy way? ",
        "createdAt" : "2020-09-21T13:52:33Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "79149140-aba8-4aca-b1da-87e53bdb00f8",
        "parentId" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Do you mean have a DbDagBag and a FileDagBag class, or something of that nature?",
        "createdAt" : "2020-09-21T15:45:54Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "112127d3-bfbd-4698-aefb-7d7965435af3",
        "parentId" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Or even `DagDbProxy` - it even can be used by DagBag by composition when needed?\r\n\r\nSeems That DagBag(read_dags_from_db=False) is really used for this: `A dagbag is a collection of dags, parsed out of a folder tree` (from the docstring). Then \"DagBag(read_dags_from_db=True) is rather used as a proxy to retrieve Dags from teh DB only `get me the DAG with this id from the DB no matter in which folder it is`. \r\n\r\nSounds like DagBag could use the DagDbProxy when needed and all the places where we create DagBag(read_dags_from_db=True) we could use directly the proxy. That seems to better fit the single-responsibility principle. ",
        "createdAt" : "2020-09-21T16:31:12Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "78a7d35a-e91a-43b8-8090-d32398526704",
        "parentId" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think this one would make a lot of the code cleaner if we do that. Can you elaborate on that?",
        "createdAt" : "2020-10-05T11:02:15Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "ae2d1f55-e9e1-4e07-ad3e-9775ded273fc",
        "parentId" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It is related to the https://github.com/apache/airflow/pull/10956#discussion_r499491362",
        "createdAt" : "2020-10-05T11:04:25Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "71fc7f37-27ee-4a0d-b31b-4285e1d085c8",
        "parentId" : "66528372-6e32-48b7-ada8-f65786984fe8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We can defer the code split/refactor to later. Will address other comments there.",
        "createdAt" : "2020-10-06T20:55:44Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 721,
    "diffHunk" : "@@ -1,1 +787,791 @@        self.processor_agent: Optional[DagFileProcessorAgent] = None\n\n        self.dagbag = DagBag(read_dags_from_db=True)\n\n    def register_exit_signals(self) -> None:"
  },
  {
    "id" : "46de905c-66f0-4cdd-91b9-2808d6321baa",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-492789468",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e85387e-a642-436d-9f25-c3d5dbefc431",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Is it possible that `DagRun.run_id` will be None?",
        "createdAt" : "2020-09-21T14:02:59Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "5d8d121c-38c3-4d8e-af1f-61b2b12af908",
        "parentId" : "5e85387e-a642-436d-9f25-c3d5dbefc431",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Exceeding unlikely (Maybe if you deleted the dag_run via the Browse -> DagRuns, I think that used to be possible but isn't anymore), but the existing code allowed it, and we have unit tests that check for it, so to keep this change smaller I didn't remove it.",
        "createdAt" : "2020-09-21T15:55:47Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "5a98d204-0806-4b05-9d4d-15fc6bd2f010",
        "parentId" : "5e85387e-a642-436d-9f25-c3d5dbefc431",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yeah. We can remove it later in separate commit.",
        "createdAt" : "2020-09-21T16:31:55Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 831,
    "diffHunk" : "@@ -1,1 +955,959 @@            .query(TI)\n            .outerjoin(TI.dag_run)\n            .filter(or_(DR.run_id.is_(None),\n                        DR.run_type != DagRunType.BACKFILL_JOB.value))\n            .join(TI.dag_model)"
  },
  {
    "id" : "4dd07465-0279-4068-9008-d414bf23f96a",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-502701023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c807ba5-03a3-4969-90eb-7d38599a90bd",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Just a nit, but as we are refactoring code here should we make `manage_slas` private too?",
        "createdAt" : "2020-10-05T20:03:53Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "bb369f7d-9b24-4a43-879e-8ba937b08e95",
        "parentId" : "4c807ba5-03a3-4969-90eb-7d38599a90bd",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I think `manage_slas` is fine being public since you can run perform some actions and tests outside of the Scheduler too. The only reason it is not a static method is because we use self.log",
        "createdAt" : "2020-10-06T08:28:51Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 442,
    "diffHunk" : "@@ -1,1 +587,591 @@                    self._execute_task_callbacks(dagbag, request)\n                elif isinstance(request, SlaCallbackRequest):\n                    self.manage_slas(dagbag.dags.get(request.dag_id))\n                elif isinstance(request, DagCallbackRequest):\n                    self._execute_dag_callbacks(dagbag, request, session)"
  },
  {
    "id" : "8fb30d47-6d02-4f47-9371-b7c6289a8dbd",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-505729292",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d8dc63e-ddc5-498b-819c-b76ac50c4a15",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "This may be more effective as we are not using `unpaused_dags` anywhere else than this loop.\r\n```python\r\nfor dag_id, dag in dagbag.dags.items():\r\n    if dag_id not in paused_dag_ids:\r\n        dag.pickle(session)\r\n```\r\n",
        "createdAt" : "2020-10-07T18:53:08Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "6574d466-96f6-45a4-973b-d82afdcb8d1c",
        "parentId" : "4d8dc63e-ddc5-498b-819c-b76ac50c4a15",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Nice. Changed in 36e23f613",
        "createdAt" : "2020-10-09T14:33:33Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 581,
    "diffHunk" : "@@ -1,1 +709,713 @@\n            for dag in unpaused_dags:\n                dag.pickle(session)\n\n        # Record import errors into the ORM"
  },
  {
    "id" : "9abec473-7ca7-4531-a10f-d4778b2ce276",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-505621963",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Is this somehow configurable or we are just hardcoding it?",
        "createdAt" : "2020-10-07T18:55:14Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "b17ec959-5c63-4b62-a27a-8ab2a84b8f2b",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "It's currently used in tests to limit things. Used, but I chose not to expose it to users.",
        "createdAt" : "2020-10-07T19:03:45Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "28d13256-23a3-4cd4-812e-61b25261d2c6",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "If we are using it only for tests (I suppose to set it to something other than -1) then wouldn't it be better to use something like `if unittest then...` as we already do in many places?",
        "createdAt" : "2020-10-07T19:12:19Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "0baf2c5e-2869-4aa0-8c54-119d164a28d9",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "It's not used in every test is the issue, so we don't want to always set it when unittest is enabled.",
        "createdAt" : "2020-10-08T08:13:10Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "59affe3e-4259-46fc-ad9f-02b1d2cb0d0d",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Got it, no strong opinion here but please, add a comment around this line to leave trace to why we do this",
        "createdAt" : "2020-10-08T10:51:47Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "7b593e7d-12ee-4d69-b8e9-689fe29592ab",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Will do",
        "createdAt" : "2020-10-08T11:13:46Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "acb30ad3-0c6b-4d5b-bba9-dac5eae8ee7a",
        "parentId" : "53aa5464-9967-412f-a45a-48b42498ca48",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Added in d09c846d9 ",
        "createdAt" : "2020-10-09T12:23:41Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 696,
    "diffHunk" : "@@ -1,1 +759,763 @@            subdir: str = settings.DAGS_FOLDER,\n            num_runs: int = conf.getint('scheduler', 'num_runs'),\n            num_times_parse_dags: int = -1,\n            processor_poll_interval: float = conf.getfloat('scheduler', 'processor_poll_interval'),\n            do_pickle: bool = False,"
  },
  {
    "id" : "b1e8d32b-e50b-43fc-865b-5667b448a3af",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-505776495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b171eb7e-a672-4b5e-9fb5-cfa8820f2c59",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "[Previously](https://github.com/apache/airflow/blob/eb5fea7b647e0f4b2338f86eeff6a90e1d6043bc/airflow/jobs/scheduler_job.py#L985), I used `isinstance` to handle still other operators that have no action e.g. [ExternalTaskMarker](https://github.com/apache/airflow/blob/eb5fea7b647e0f4b2338f86eeff6a90e1d6043bc/airflow/sensors/external_task_sensor.py#L225). Can you fix it or add a TODO note about this limitation?",
        "createdAt" : "2020-10-09T15:03:20Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "f611c31c-b16c-4c56-af86-28979e7d7175",
        "parentId" : "b171eb7e-a672-4b5e-9fb5-cfa8820f2c59",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Oh yes. We can't use `isinstance` anymore due to the serialization, unfortunately. Will todo/add an issue shortly.",
        "createdAt" : "2020-10-09T15:11:19Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "a82d73e0-5428-4fac-99a5-5c46d165d738",
        "parentId" : "b171eb7e-a672-4b5e-9fb5-cfa8820f2c59",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I know. For now, we can add a list of all the classes from the core that inherit from DummyOperator. This should be sufficient in most cases.",
        "createdAt" : "2020-10-09T15:25:24Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 1547,
    "diffHunk" : "@@ -1,1 +1671,1675 @@            if\n            (\n                ti.task.task_type == \"DummyOperator\"\n                and not ti.task.on_execute_callback\n                and not ti.task.on_success_callback"
  },
  {
    "id" : "9b54e8b8-510d-400c-94e0-ecc0d2e4e356",
    "prId" : 11257,
    "prUrl" : "https://github.com/apache/airflow/pull/11257#pullrequestreview-504823928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb0e1659-56a1-4338-a236-5820b0b54f2a",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "I'm wondering if we should remove the indentation for this string:\r\n```\r\nIn [1]: x = \"\"\"\\\r\n   ...:             Here's a list of tasks that missed their SLAs:\r\n   ...:             <pre><code>{task_list}\\n<code></pre>\r\n   ...:             Blocking tasks:\r\n   ...:             <pre><code>{blocking_task_list}\\n{bug}<code></pre>\r\n   ...:             \"\"\"\r\n\r\nIn [2]:\r\n\r\nIn [2]: print(x)\r\n            Here's a list of tasks that missed their SLAs:\r\n            <pre><code>{task_list}\r\n<code></pre>\r\n            Blocking tasks:\r\n            <pre><code>{blocking_task_list}\r\n{bug}<code></pre>\r\n```",
        "createdAt" : "2020-10-03T13:07:34Z",
        "updatedAt" : "2020-10-03T14:10:26Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "3a368a59-e1fb-4a50-91cd-5bdc8cb8c1d5",
        "parentId" : "fb0e1659-56a1-4338-a236-5820b0b54f2a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "https://docs.python.org/3/library/textwrap.html?highlight=dedent#textwrap.dedent maybe?",
        "createdAt" : "2020-10-08T13:42:13Z",
        "updatedAt" : "2020-10-08T13:42:13Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "8ebddfcf-e62e-4420-bb93-ed51ae27a99c",
        "parentId" : "fb0e1659-56a1-4338-a236-5820b0b54f2a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Oh, though this is HTML, so whitespace doesn't really matter.",
        "createdAt" : "2020-10-08T13:42:29Z",
        "updatedAt" : "2020-10-08T13:42:30Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "d8ca0b6b-aed3-4f8a-8f61-ca411fb60f2a",
        "parentId" : "fb0e1659-56a1-4338-a236-5820b0b54f2a",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "@ashb yeah that's HTML so indeed it's not a problem as long as the email client can render it ",
        "createdAt" : "2020-10-08T14:09:18Z",
        "updatedAt" : "2020-10-08T14:09:19Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "50f6592a7e2718996ae4ec9baffdb8d49198cbe0",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +466,470 @@            Blocking tasks:\n            <pre><code>{blocking_task_list}<code></pre>\n            \"\"\"\n\n            tasks_missed_sla = []"
  },
  {
    "id" : "1b0c3e22-dbd2-4c35-9ea3-6244d37a4674",
    "prId" : 11358,
    "prUrl" : "https://github.com/apache/airflow/pull/11358#pullrequestreview-505713975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "```suggestion\r\n                    models.TaskInstance.duration: models.TaskInstance.end_date - models.TaskInstance.start_date,\r\n```",
        "createdAt" : "2020-10-09T08:22:25Z",
        "updatedAt" : "2020-10-09T08:22:26Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "8bb688e0-4a9e-4bd1-ba95-f7de3e70664e",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Errors with the following, this will always be 0 so I think setting it to 0 here explicitly is fine compared to casting it to float \r\n\r\n```\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.ProgrammingError: (psycopg2.errors.DatatypeMismatch) column \"duration\" is of type double precision but expression is of type interval\r\nLINE 1: ...09T09:37:10.897145+00:00'::timestamptz, duration=(task_insta...\r\n                                                             ^\r\nHINT:  You will need to rewrite or cast the expression.\r\n\r\n[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, duration=(task_instance.end_date - task_instance.start_date), state=%(state)s FROM (SELECT task_instance.try_number AS try_number, task_instance.task_id AS task_id, task_instance.dag_id AS dag_id, task_instance.execution_date AS execution_date, task_instance.start_date AS start_date, task_instance.end_date AS end_date, task_instance.duration AS duration, task_instance.state AS state, task_instance.max_tries AS max_tries, task_instance.hostname AS hostname, task_instance.unixname AS unixname, task_instance.job_id AS job_id, task_instance.pool AS pool, task_instance.pool_slots AS pool_slots, task_instance.queue AS queue, task_instance.priority_weight AS priority_weight, task_instance.operator AS operator, task_instance.queued_dttm AS queued_dttm, task_instance.queued_by_job_id AS queued_by_job_id, task_instance.pid AS pid, task_instance.executor_config AS executor_config, task_instance.external_executor_id AS external_executor_id\r\nFROM task_instance LEFT OUTER JOIN dag_run ON task_instance.dag_id = dag_run.dag_id AND task_instance.execution_date = dag_run.execution_date\r\nWHERE task_instance.dag_id IN (%(dag_id_1)s) AND task_instance.state IN (%(state_1)s) AND (dag_run.state != %(state_2)s OR dag_run.state IS NULL)) AS anon_1 WHERE task_instance.dag_id = anon_1.dag_id AND task_instance.task_id = anon_1.task_id AND task_instance.execution_date = anon_1.execution_date]\r\n[parameters: {'start_date': datetime.datetime(2020, 10, 9, 9, 37, 10, 897145, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2020, 10, 9, 9, 37, 10, 897145, tzinfo=Timezone('UTC')), 'state': 'failed', 'dag_id_1': 'test_execute_helper_should_change_state_for_tis_without_dagrun', 'state_1': 'up_for_retry', 'state_2': 'running'}]\r\n(Background on this error at: http://sqlalche.me/e/13/f405)\r\n```",
        "createdAt" : "2020-10-09T09:42:03Z",
        "updatedAt" : "2020-10-09T09:42:47Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "e116ce1c-c395-40b5-846d-8c26866d0a5f",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "If the task is in sensing state it won't be 0 is my thought.\r\n\r\nBut this is not trivial to do portably it turns out: On postgres this is `EXTRACT(EPOCH from end_date - start_date)` -- likely not worth it.",
        "createdAt" : "2020-10-09T12:30:41Z",
        "updatedAt" : "2020-10-09T12:30:41Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "d2e957c3-22a1-469f-b6a8-cef51b6d3665",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "We won't be setting 0 for Sensing, only for TIs in `State.finished()` which is failed, success or skipped",
        "createdAt" : "2020-10-09T12:32:03Z",
        "updatedAt" : "2020-10-09T12:32:17Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "87f9a178-50a7-4157-a6b4-a1034526d87c",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "If it's finished, then won't it already have a duration?",
        "createdAt" : "2020-10-09T13:02:20Z",
        "updatedAt" : "2020-10-09T13:02:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "72cfb035-c500-4a24-97b6-96c9d56dcc04",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I was not clear before, it is the `new_state` i.e which state we want to set it to, check the following code block.\r\n\r\nhttps://github.com/apache/airflow/blob/3b0d977d413b38e6b394287a6cbc85a6bc25b414/airflow/jobs/scheduler_job.py#L1787-L1802\r\n\r\nSo we only want to set the end_date and duration when we are setting the new_state to Failed and not when we are setting it to `None` since that task will be run again",
        "createdAt" : "2020-10-09T13:08:08Z",
        "updatedAt" : "2020-10-09T13:11:38Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "c3a299c9-859f-421c-ab39-36a2db198d8b",
        "parentId" : "a26c53e9-8194-4d1d-9746-fa55d3729470",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Ahhh, right yes.",
        "createdAt" : "2020-10-09T14:16:07Z",
        "updatedAt" : "2020-10-09T14:16:07Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b0d977d413b38e6b394287a6cbc85a6bc25b414",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1173,1177 @@                ti_prop_update.update({\n                    models.TaskInstance.end_date: current_time,\n                    models.TaskInstance.duration: 0,\n                })\n"
  },
  {
    "id" : "0151c50e-2238-41f9-b0af-4e6c6d60df20",
    "prId" : 11589,
    "prUrl" : "https://github.com/apache/airflow/pull/11589#pullrequestreview-511005536",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de714def-c27a-4a4d-9e11-87e949aa2d34",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "It seems to me that we should also move the comment. Now it has lost context.",
        "createdAt" : "2020-10-17T00:27:11Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "5974aeed-2506-47fe-8a29-002dcd3e80ff",
        "parentId" : "de714def-c27a-4a4d-9e11-87e949aa2d34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This comment doesn't make sense when called on a (instance) method on DagRun, as that almost by definition only operators on a single dag run. The comment is kept here in the scheduler because that's where might think we want to batch the queries up, but shouldn't.",
        "createdAt" : "2020-10-17T18:20:22Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "613da86bd2bd844366d66e14f911ce7057bef43a",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +1653,1657 @@        self._send_dag_callbacks_to_processor(dag_run, callback_to_run)\n\n        # This will do one query per dag run. We \"could\" build up a complex\n        # query to update all the TIs across all the execution dates and dag\n        # IDs in a single query, but it turns out that can be _very very slow_"
  },
  {
    "id" : "d5b7542a-b8b9-493c-b7f0-41260db2d753",
    "prId" : 11732,
    "prUrl" : "https://github.com/apache/airflow/pull/11732#pullrequestreview-514601504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "908ef5ea-06b9-46f1-99ea-cc4fb70c9f2e",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "not needed for this PR but should we change this to DEBUG as I remember it was a bit spammy",
        "createdAt" : "2020-10-22T10:53:35Z",
        "updatedAt" : "2020-10-22T18:00:42Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "ecb83950-368a-4249-b007-f6ee8f3a2ca5",
        "parentId" : "908ef5ea-06b9-46f1-99ea-cc4fb70c9f2e",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "With this change it should happen a lot lot less anyway, but yes, or we fix it properly:\r\n\r\n> This approach works around the problem for now, but a better longer term fix for this would be to introduce a \"queued\" state for DagRuns, and then when manually creating dag runs (or clearing) set it to queued, and only have the scheduler set DagRuns to running, nothing else -- this would mean we wouldn't need to examine active runs in the TI part of the scheduler loop, only in DagRun creation part.",
        "createdAt" : "2020-10-22T10:55:53Z",
        "updatedAt" : "2020-10-22T18:00:42Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd0a92a959b0ea6aeb03c5bfd80abef9258afaa8",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1655,1659 @@            if len(currently_active_runs) >= dag.max_active_runs and \\\n               dag_run.execution_date not in currently_active_runs:\n                self.log.info(\n                    \"DAG %s already has %d active runs, not queuing any tasks for run %s\",\n                    dag.dag_id,"
  },
  {
    "id" : "27bd9578-27ea-414c-9fdf-4b4ccfa9ac65",
    "prId" : 12323,
    "prUrl" : "https://github.com/apache/airflow/pull/12323#pullrequestreview-529434987",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99817301-079f-459d-98c8-76b6c82c0c5f",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Just moving the flush later in the code so that we flush it for MySQL and SQLite too\r\n\r\nhttps://github.com/apache/airflow/blob/02b584a40acc29a213f471c0d85976d9e6acc6fc/airflow/jobs/scheduler_job.py#L824-L835",
        "createdAt" : "2020-11-12T19:42:34Z",
        "updatedAt" : "2020-11-13T00:58:58Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "dac0ddf134f822077d6cad8fa06f8602785aae18",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +855,859 @@\n        if tis_changed > 0:\n            session.flush()\n            self.log.warning(\n                \"Set %s task instances to state=%s as their associated DagRun was not in RUNNING state\","
  }
]