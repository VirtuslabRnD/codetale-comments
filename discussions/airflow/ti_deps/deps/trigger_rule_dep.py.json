[
  {
    "id" : "fb327278-931a-4fb3-8953-adb0d1dba83c",
    "prId" : 4182,
    "prUrl" : "https://github.com/apache/airflow/pull/4182#pullrequestreview-353219304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73050f37-1293-4a92-8f60-06c5c2280357",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "@rmn36 @kaxil @ashb @Fokko \r\n\r\nI'm trying to understand the rationale behind this line. E.g. for a dag that looks like this, with just op1 >> op2. When we run the DAG, both op1 and op2 become skipped. The reason is op1 raises `AirflowSkipException`, so op1 is skipped. op2 is set to `none_failed`. But op2 is also skipped because this line checks `skipped == upstream` and marks op2 as skipped.\r\n\r\nHowever, the doc for \"Trigger Rule\" says:\r\n```none_failed: all parents have not failed (failed or upstream_failed) i.e. all parents have succeeded or been skipped```\r\n\r\nSo if I interpret this correctly, when all of op2's upstream tasks are skipped, none of them have failed. So op2 should be success rather than skip. \r\n\r\nThis may be a feature or a bug. If it's a feature, we need to update the doc. Or if it's a bug we should fix this line.\r\n\r\nWhat do you think?\r\n\r\n```\r\nwith DAG(\"skip_exception\", schedule_interval=None, start_date=pendulum.parse(\"20190101\")) as dag:\r\n    def raise_skip():\r\n        raise AirflowSkipException\r\n    op1 = PythonOperator(task_id=\"op1\", python_callable=raise_skip)\r\n    op2 = DummyOperator(task_id=\"op2\", trigger_rule=\"none_failed\")\r\n    op1 >> op2\r\n```",
        "createdAt" : "2019-12-24T05:18:31Z",
        "updatedAt" : "2019-12-24T05:18:31Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "5859e625-0903-4c36-a085-34eb18eda89d",
        "parentId" : "73050f37-1293-4a92-8f60-06c5c2280357",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "Pls note that this can be a feature worth preserving, because if someone wants his task op2 to only run if at least some upstream tasks have succeeded (while others can be skipped), he can use \"none_failed\" to do that because that's exactly what this line does. \r\n\r\nHowever, if he wants to have his task op2 succeed as long as none of the upstream tasks fail (either skipped for success), he can still use \"none_failed\" for it. The only workaround he needs to add is to introduce a DummyOperator that always succeeds directly upstream of op2.\r\n\r\nSo we can keep this feature, but we should make it clear in the doc that if all the upstream tasks are skipped, a task marked with \"none_failed\" will be skipped. Pls let me know. i don't mind creating a PR to update the doc.",
        "createdAt" : "2019-12-24T05:31:01Z",
        "updatedAt" : "2019-12-24T05:31:01Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "f03b1fee-8714-4d49-b744-a8b57099385e",
        "parentId" : "73050f37-1293-4a92-8f60-06c5c2280357",
        "authorId" : "b9562236-3520-4646-a0a5-de434b259a58",
        "body" : "> Pls note that this can be a feature worth preserving, because if someone wants his task op2 to only run if at least some upstream tasks have succeeded (while others can be skipped), he can use \"none_failed\" to do that because that's exactly what this line does.\r\n> \r\n> However, if he wants to have his task op2 succeed as long as none of the upstream tasks fail (either skipped for success), he can still use \"none_failed\" for it. The only workaround he needs to add is to introduce a DummyOperator that always succeeds directly upstream of op2.\r\n> \r\n> So we can keep this feature, but we should make it clear in the doc that if all the upstream tasks are skipped, a task marked with \"none_failed\" will be skipped. Pls let me know. i don't mind creating a PR to update the doc.\r\n\r\nIn my opinion, this isn't a reasonable workaround. I'm developing complex DAGs that consist of several tasks with only one upstream dependency-- all of which could be potentially skipped. The `none_failed` trigger rule seemed to be the perfect rule for my use case, but anytime I skip a task, skips propagate down until the next task with multiple upstream deps. Wouldn't the reason you mentioned to preserve this feature be satisfied by the ONE_SUCCESS trigger rule? Either way, I believe that `none_failed` communicates \"trigger if all upstream are success or skipped\" as your docs suggest.",
        "createdAt" : "2020-01-03T16:03:59Z",
        "updatedAt" : "2020-01-06T14:00:29Z",
        "lastEditedBy" : "b9562236-3520-4646-a0a5-de434b259a58",
        "tags" : [
        ]
      },
      {
        "id" : "69f661f0-ba0d-4330-bae6-a8f3dd009dc8",
        "parentId" : "73050f37-1293-4a92-8f60-06c5c2280357",
        "authorId" : "b9562236-3520-4646-a0a5-de434b259a58",
        "body" : "cc: @rmn36 @kaxil @ashb @Fokko @yuqian90 \r\n\r\nDo you all agree? Should I file a JIRA for this?",
        "createdAt" : "2020-01-06T14:00:04Z",
        "updatedAt" : "2020-01-06T14:00:04Z",
        "lastEditedBy" : "b9562236-3520-4646-a0a5-de434b259a58",
        "tags" : [
        ]
      },
      {
        "id" : "a53e9bc9-901e-4c33-acc1-7b9d94faab86",
        "parentId" : "73050f37-1293-4a92-8f60-06c5c2280357",
        "authorId" : "b226f603-38da-43d4-b4d1-a7520720964c",
        "body" : "@ChrisEverling leaving a note here for others who find this conversation, a JIRA ticket was filed for this:  https://issues.apache.org/jira/browse/AIRFLOW-4453",
        "createdAt" : "2020-02-04T18:54:30Z",
        "updatedAt" : "2020-02-04T18:54:30Z",
        "lastEditedBy" : "b226f603-38da-43d4-b4d1-a7520720964c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8178702a2004b4c3f60ad5cad29932405a303564",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +156,160 @@                if upstream_failed or failed:\n                    ti.set_state(State.UPSTREAM_FAILED, session)\n                elif skipped == upstream:\n                    ti.set_state(State.SKIPPED, session)\n"
  },
  {
    "id" : "bca4a894-189e-43f8-ab98-0c8495841b92",
    "prId" : 4751,
    "prUrl" : "https://github.com/apache/airflow/pull/4751#pullrequestreview-317918331",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1230ce8b-e028-4d2a-8fab-d2d3214cb4c8",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Add 1-liner description of what this method does",
        "createdAt" : "2019-11-15T23:15:55Z",
        "updatedAt" : "2020-01-16T17:32:56Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "589061958ca3c54b9cfb01d32ebf97d112d54a24",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +38,42 @@    @provide_session\n    def _get_states_count_upstream_ti(ti, finished_tasks, session):\n        \"\"\"\n        This function returns the states of the upstream tis for a specific ti in order to determine\n        whether this ti can run in this iteration"
  },
  {
    "id" : "0d6ac928-220e-415b-aa4d-f9338f8d95e5",
    "prId" : 8962,
    "prUrl" : "https://github.com/apache/airflow/pull/8962#pullrequestreview-416782674",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d55361ce-6c92-4545-acb3-c37bfe53e4dd",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Is this a related change? ",
        "createdAt" : "2020-05-22T09:56:03Z",
        "updatedAt" : "2020-06-23T18:02:27Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "3dd411303e2604e1e0a81d91b186b189733db332",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +22,26 @@from airflow.utils.session import provide_session\nfrom airflow.utils.state import State\nfrom airflow.utils.trigger_rule import TriggerRule as TR\n\n"
  },
  {
    "id" : "1d0e006c-63a2-499e-a639-395505bd04ca",
    "prId" : 8962,
    "prUrl" : "https://github.com/apache/airflow/pull/8962#pullrequestreview-417033794",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9764c170-44d4-45ca-bd88-98ace7ccabc1",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This change seems unrelated?",
        "createdAt" : "2020-05-22T10:08:01Z",
        "updatedAt" : "2020-06-23T18:02:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "d5e705f7-e258-4069-99b9-1c058e2bec9f",
        "parentId" : "9764c170-44d4-45ca-bd88-98ace7ccabc1",
        "authorId" : "d22b786b-b06e-462c-a530-7ee1b6ae12d3",
        "body" : "Had to resolve it because it created a circular import when I added the decorator as `airflow.task`",
        "createdAt" : "2020-05-22T16:53:58Z",
        "updatedAt" : "2020-06-23T18:02:27Z",
        "lastEditedBy" : "d22b786b-b06e-462c-a530-7ee1b6ae12d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "3dd411303e2604e1e0a81d91b186b189733db332",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +22,26 @@from airflow.utils.session import provide_session\nfrom airflow.utils.state import State\nfrom airflow.utils.trigger_rule import TriggerRule as TR\n\n"
  }
]