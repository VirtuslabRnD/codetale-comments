[
  {
    "id" : "86dafedc-bc95-4a10-9f05-4fa51aeac968",
    "prId" : 3873,
    "prUrl" : "https://github.com/apache/airflow/pull/3873#pullrequestreview-156137587",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e56cfa6f-fdb6-4d35-9ed0-d62d682e953e",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "it seems  the class doesn't have method. how about using Namedtuple instead of creating a class which will look a lot simpler? ",
        "createdAt" : "2018-09-17T21:38:25Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "f2105d9c-ed97-4c32-9346-920119096870",
        "parentId" : "e56cfa6f-fdb6-4d35-9ed0-d62d682e953e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Good to know about Namedtuple :D Tho I plan to add some more stuff into this class including methods([PR](https://github.com/yrqls21/incubator-airflow/pull/4) WIP). I might explore to see if there's cleaner way to write it as the class indeed is going to be mostly holding variables.",
        "createdAt" : "2018-09-17T22:04:24Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "14cf345b6247b62d502ac32076130beaf0f923a3",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +138,142 @@\n\nclass SimpleTaskInstance(object):\n    def __init__(self, ti):\n        self._dag_id = ti.dag_id"
  },
  {
    "id" : "a24ad3ce-8cc5-4b56-b4ba-79f0e1f3e06a",
    "prId" : 3873,
    "prUrl" : "https://github.com/apache/airflow/pull/3873#pullrequestreview-157827230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b00ce308-1b3a-46a7-9525-0498afbdbb53",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Something really minor: do we still want to keep this TODO comment (understand it's \"copied\" from `airflow/jobs.py`)?\r\n\r\nIf we consider this timeout value as a magic number and do want to keep this TODO comment, possibly the same comment needs to be added to line 598 in this file as well. https://github.com/apache/incubator-airflow/blob/c45cc19d87faa49cba1bbb4755940d3113adc522/airflow/utils/dag_processing.py#L596-L598 ",
        "createdAt" : "2018-09-21T17:09:39Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "5ccc3b50-2f17-446d-8fcc-3438e013b27d",
        "parentId" : "b00ce308-1b3a-46a7-9525-0498afbdbb53",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "I'll actually add another TODO comment there. It may require some more thought on how to remove it( somehow it works quite well) and potential avoid adding another small config option( as pointed out by @Fokko we already have a lot config to tune).",
        "createdAt" : "2018-09-21T19:22:21Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "14cf345b6247b62d502ac32076130beaf0f923a3",
    "line" : 773,
    "diffHunk" : "@@ -1,1 +1208,1212 @@                self.log.info(\"Terminating child PID: {}\".format(child.pid))\n                child.terminate()\n            # TODO: Remove magic number\n            timeout = 5\n            self.log.info("
  },
  {
    "id" : "ae16dab0-fee3-483f-84f0-da4acc2a2280",
    "prId" : 3873,
    "prUrl" : "https://github.com/apache/airflow/pull/3873#pullrequestreview-157832924",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "346bc540-8ac9-405a-8d31-8bfb8f8c8078",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Does this timeout need to be configureable?",
        "createdAt" : "2018-09-21T18:41:46Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "daab8816-010b-4349-ae18-eb659ffc550f",
        "parentId" : "346bc540-8ac9-405a-8d31-8bfb8f8c8078",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "I'll be adding a TODO comment here to make it aligned with the existing code. I might later on start another discussion around this magic number.",
        "createdAt" : "2018-09-21T19:40:58Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "14cf345b6247b62d502ac32076130beaf0f923a3",
    "line" : 299,
    "diffHunk" : "@@ -1,1 +579,583 @@            manager_process.terminate()\n            # TODO: Remove magic number\n            timeout = 5\n            self.log.info(\"Waiting up to {}s for manager process to exit...\"\n                          .format(timeout))"
  },
  {
    "id" : "ddfa477c-7842-449a-adfd-17822b5380f6",
    "prId" : 3873,
    "prUrl" : "https://github.com/apache/airflow/pull/3873#pullrequestreview-157898315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9118aa3b-8ee7-43f9-a22d-0b8ea40159b6",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Is this another magic number?",
        "createdAt" : "2018-09-22T00:22:49Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "c64c6a01-e2bd-485c-92dc-dc7978832eaf",
        "parentId" : "9118aa3b-8ee7-43f9-a22d-0b8ea40159b6",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Yes it is. Will put a similar TODO here and revisit it together with termination timeout magic number later.",
        "createdAt" : "2018-09-22T04:00:02Z",
        "updatedAt" : "2018-10-15T05:28:31Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "14cf345b6247b62d502ac32076130beaf0f923a3",
    "line" : 407,
    "diffHunk" : "@@ -1,1 +678,682 @@        self.last_stat_print_time = timezone.datetime(2000, 1, 1)\n        # TODO: Remove magic number\n        self._zombie_query_interval = 10\n        # Map from file path to the number of runs\n        self._run_count = defaultdict(int)"
  },
  {
    "id" : "a0255809-55f5-4ec1-bd3f-170e0e4fe4d4",
    "prId" : 4234,
    "prUrl" : "https://github.com/apache/airflow/pull/4234#pullrequestreview-178738703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ef0052a-0405-4469-bc64-c42605bd513e",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Minor: One empty line is expected before this line to render Sphinx properly",
        "createdAt" : "2018-11-27T11:46:50Z",
        "updatedAt" : "2018-11-27T21:39:13Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      }
    ],
    "commit" : "554b4cf08bcf371a95415d9a0cd88820f2d9272c",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +216,220 @@        Construct a TaskInstance from the database based on the primary key\n\n        :param session: DB session.\n        :param lock_for_update: if True, indicates that the database should\n            lock the TaskInstance (issuing a FOR UPDATE clause) until the"
  },
  {
    "id" : "7eaf2124-0884-40c7-bfc9-454d6b9becde",
    "prId" : 4253,
    "prUrl" : "https://github.com/apache/airflow/pull/4253#pullrequestreview-180556894",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3e4ffe4-a6b6-4a90-a7ac-6e9c420a139a",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Do we need `[0]` here ?? `.rsplit('.',1)` would just have one item right??",
        "createdAt" : "2018-12-01T20:40:19Z",
        "updatedAt" : "2018-12-01T20:44:50Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "6d6b9399-5be3-44e5-b14c-08e3a97456de",
        "parentId" : "a3e4ffe4-a6b6-4a90-a7ac-6e9c420a139a",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "It will actually [return a list as split](https://docs.python.org/2/library/string.html#string.rsplit). If not it will fail the newly added unit test :D",
        "createdAt" : "2018-12-02T00:50:49Z",
        "updatedAt" : "2018-12-02T00:50:49Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "fa8579fd-2601-4140-a4d5-0e4eb06b108c",
        "parentId" : "a3e4ffe4-a6b6-4a90-a7ac-6e9c420a139a",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Oh yes, my bad ðŸ˜„ ",
        "createdAt" : "2018-12-02T11:13:52Z",
        "updatedAt" : "2018-12-02T11:13:52Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "eecc75ae06ed96172114a829513abdc182d1d8eb",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +544,548 @@            # Replicating the behavior of how logging module was loaded\n            # in logging_config.py\n            reload_module(import_module(logging_class_path.rsplit('.', 1)[0]))\n            reload_module(airflow.settings)\n            del os.environ['CONFIG_PROCESSOR_MANAGER_LOGGER']"
  },
  {
    "id" : "fdbd36e6-c37c-4d06-8808-7e8725c62cb0",
    "prId" : 4730,
    "prUrl" : "https://github.com/apache/airflow/pull/4730#pullrequestreview-204998621",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5893f9a6-e2d2-48ea-accf-3ccb68937fdc",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "This change makes no difference to me.",
        "createdAt" : "2019-02-19T01:21:43Z",
        "updatedAt" : "2019-02-19T01:22:12Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "f97a0ab3-a460-4a93-a90e-15ef149e0ddf",
        "parentId" : "5893f9a6-e2d2-48ea-accf-3ccb68937fdc",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @feng-tao , understand this PR is merged and it does bring significant improvement (big thanks to @astahlman !).\r\n\r\nBut may you check my comment? It's a very minor point, but not really necessary to add a separate check here (Kindly let me know if I missed anything). Thanks.",
        "createdAt" : "2019-02-19T01:26:37Z",
        "updatedAt" : "2019-02-19T01:26:37Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "b65193b2-6271-4d09-9040-3a94f28ec179",
        "parentId" : "5893f9a6-e2d2-48ea-accf-3ccb68937fdc",
        "authorId" : "8ae8c9e1-93ac-446d-b3f6-18d36b79bd39",
        "body" : "This was needed because of [the way that Python handles default arguments](https://docs.python-guide.org/writing/gotchas/#mutable-default-arguments): the default value is evaluated when the function is defined, not when it is called. Therefore, our mocked implementation of `getboolean` wouldn't get called here, and `include_examples` will be always be `True`.\r\n\r\nThis way, we call `getboolean` every time the function is evaluated, so our mock implementation does get used and `getboolean('core', 'LOAD_EXAMPLES')` evaluates to `False`.",
        "createdAt" : "2019-02-19T01:32:09Z",
        "updatedAt" : "2019-02-19T01:32:09Z",
        "lastEditedBy" : "8ae8c9e1-93ac-446d-b3f6-18d36b79bd39",
        "tags" : [
        ]
      },
      {
        "id" : "bb23e89e-c835-4c96-8966-defd471ecf4a",
        "parentId" : "5893f9a6-e2d2-48ea-accf-3ccb68937fdc",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Get it. Thanks for the clarification @astahlman ",
        "createdAt" : "2019-02-19T01:35:57Z",
        "updatedAt" : "2019-02-19T01:35:57Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      }
    ],
    "commit" : "010ca8cdc2264e4338d5dcc494d3b9cc1d3941df",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +278,282 @@\ndef list_py_file_paths(directory, safe_mode=True,\n                       include_examples=None):\n    \"\"\"\n    Traverse a directory and look for Python files."
  },
  {
    "id" : "3dee3941-a1ba-412a-83d4-925b420ec473",
    "prId" : 5605,
    "prUrl" : "https://github.com/apache/airflow/pull/5605#pullrequestreview-263772008",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "def3455c-f0ba-4a75-b637-5bcd8f31774a",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Lets add a metric for number of parsing processes killed.",
        "createdAt" : "2019-07-18T16:23:28Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "cc5cbf42-2d4f-4676-be7f-8b3c9b344aab",
        "parentId" : "def3455c-f0ba-4a75-b637-5bcd8f31774a",
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "Agreed, will add.",
        "createdAt" : "2019-07-18T16:27:10Z",
        "updatedAt" : "2019-07-19T12:34:28Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff0878c867134a2f348d46c95fa37586868f4a1f",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +1257,1261 @@                    processor.file_path, processor.pid, processor.start_time.isoformat())\n                Stats.incr('dag_file_processor_timeouts', 1, 1)\n                processor.kill()\n\n    def max_runs_reached(self):"
  },
  {
    "id" : "194e3fb7-a9c2-44ea-a3e7-9eae009d8476",
    "prId" : 5605,
    "prUrl" : "https://github.com/apache/airflow/pull/5605#pullrequestreview-265070486",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8966a21d-af48-49ae-afbb-4e4ebfcf8a62",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "This line seems to cause scheduler to crash. There is no `.kill()`. Do you mean `.terminate()` ?\r\n\r\n```\r\n  File \"/usr/local/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/local/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/airflow/airflow/utils/dag_processing.py\", line 581, in helper\r\n    processor_manager.start()\r\n  File \"/opt/airflow/airflow/utils/dag_processing.py\", line 825, in start\r\n    self.start_in_sync()\r\n  File \"/opt/airflow/airflow/utils/dag_processing.py\", line 891, in start_in_sync\r\n    simple_dags = self.heartbeat()\r\n  File \"/opt/airflow/airflow/utils/dag_processing.py\", line 1153, in heartbeat\r\n    self._kill_timed_out_processors()\r\n  File \"/opt/airflow/airflow/utils/dag_processing.py\", line 1259, in _kill_timed_out_processors\r\n    processor.kill()\r\nAttributeError: 'DagFileProcessor' object has no attribute 'kill'\r\n```",
        "createdAt" : "2019-07-20T04:23:38Z",
        "updatedAt" : "2019-07-20T04:23:38Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "491184cf-3000-46c3-a319-2bb9e3c45ffc",
        "parentId" : "8966a21d-af48-49ae-afbb-4e4ebfcf8a62",
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "This was a rebase issue since a lot of the code got refactored, kill is a new method. I'll fix and add an integration test to make sure that this code path is actually run.",
        "createdAt" : "2019-07-22T17:20:24Z",
        "updatedAt" : "2019-07-22T17:20:31Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      },
      {
        "id" : "c3adf9cb-c85a-4018-8dd0-f3177ac75e2f",
        "parentId" : "8966a21d-af48-49ae-afbb-4e4ebfcf8a62",
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "Fix is here: https://github.com/apache/airflow/pull/5639",
        "createdAt" : "2019-07-22T21:35:40Z",
        "updatedAt" : "2019-07-22T21:35:41Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff0878c867134a2f348d46c95fa37586868f4a1f",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +1257,1261 @@                    processor.file_path, processor.pid, processor.start_time.isoformat())\n                Stats.incr('dag_file_processor_timeouts', 1, 1)\n                processor.kill()\n\n    def max_runs_reached(self):"
  },
  {
    "id" : "42097cfc-9d47-44cc-b653-e18197f13be1",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265327758",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4441f7b8-40b2-4572-811f-65738ede81c5",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Why do we join here with timeout = 0 ?",
        "createdAt" : "2019-07-23T10:20:51Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "f50bd762-fa1c-4b44-91f5-1205121ff1ea",
        "parentId" : "4441f7b8-40b2-4572-811f-65738ede81c5",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "See next comment.",
        "createdAt" : "2019-07-23T10:56:05Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 261,
    "diffHunk" : "@@ -1,1 +633,637 @@        \"\"\"\n        if self._process and not self._process.is_alive():\n            self._process.join(timeout=0)\n            if not self.done:\n                self.log.warning("
  },
  {
    "id" : "63ac8f11-205b-4d23-859d-8b5a7f2c62c3",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265337601",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72cfaee7-2770-46f3-825e-ce5a9824aefe",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Again here - do we have to join() here if process is not alive() ?",
        "createdAt" : "2019-07-23T10:40:57Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "3f406dc0-28e3-459f-bd90-1719da59490b",
        "parentId" : "72cfaee7-2770-46f3-825e-ce5a9824aefe",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Based on the code in Py3.5 yes I think we do :https://github.com/python/cpython/blob/3.5/Lib/multiprocessing/process.py#L118-L138 - without joining the process we never remove the process from the `_children` internal state in the MP module.",
        "createdAt" : "2019-07-23T10:54:06Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "8dcd9e2a-bf44-4654-a427-e0009d399df6",
        "parentId" : "72cfaee7-2770-46f3-825e-ce5a9824aefe",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "OK. good",
        "createdAt" : "2019-07-23T11:17:33Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 261,
    "diffHunk" : "@@ -1,1 +633,637 @@        \"\"\"\n        if self._process and not self._process.is_alive():\n            self._process.join(timeout=0)\n            if not self.done:\n                self.log.warning("
  },
  {
    "id" : "c687824f-2ae9-4598-a3fb-8107406db833",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-265337923",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6d88c4e-debd-42c6-a9c3-bcf9c44facfb",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "So I understand that we use one Pipe to send both Stats and parsing results? Nice.",
        "createdAt" : "2019-07-23T10:42:09Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "93a2fe1f-6975-42be-b3fd-17d37cc624c5",
        "parentId" : "a6d88c4e-debd-42c6-a9c3-bcf9c44facfb",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yes - a single pipe that both(all) types ofmessages get sent over. Again, this is sort of where I approached it as \"how would I do it in golang\", and running things with `go test --race` has sort of taught me to do it this way.",
        "createdAt" : "2019-07-23T10:55:43Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ab2fdadd-0e78-4ed1-9df3-c3f3846343ae",
        "parentId" : "a6d88c4e-debd-42c6-a9c3-bcf9c44facfb",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Perfect!",
        "createdAt" : "2019-07-23T11:18:17Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 224,
    "diffHunk" : "@@ -1,1 +607,611 @@        \"\"\"\n        # Receive any pending messages before checking if the process has exited.\n        while self._parent_signal_conn.poll():\n            try:\n                result = self._parent_signal_conn.recv()"
  },
  {
    "id" : "bd75c4e8-300f-4c5f-8d79-2f26a605dda9",
    "prId" : 5615,
    "prUrl" : "https://github.com/apache/airflow/pull/5615#pullrequestreview-267640560",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee079059-f151-4ec0-a779-5bc716424578",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "NIT: In this case maybe combine the two if/else block on `self._async_mode`? ( the other in `def run()`)",
        "createdAt" : "2019-07-26T23:34:51Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "40496f4e-3de5-4462-9bfb-aff9bdd6e7e0",
        "parentId" : "ee079059-f151-4ec0-a779-5bc716424578",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah, now I've combined start_in_sync and start_in_async we don't actually need two functions anymore.",
        "createdAt" : "2019-07-29T08:40:23Z",
        "updatedAt" : "2019-07-29T15:20:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "057c4628a64f64eb2772bbb184814e24fa8d9234",
    "line" : 375,
    "diffHunk" : "@@ -1,1 +799,803 @@        # In sync mode we want timeout=None -- wait forever until a message is received\n        poll_time = None  # type: Optional[float]\n        if self._async_mode:\n            poll_time = 0.0\n            self.log.debug(\"Starting DagFileProcessorManager in async mode\")"
  },
  {
    "id" : "5b3faa33-5463-4f66-9265-d43e8fd5ff88",
    "prId" : 5908,
    "prUrl" : "https://github.com/apache/airflow/pull/5908#pullrequestreview-285191282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14bcb8c1-2db1-43d9-9ee2-a43e7d236485",
        "parentId" : null,
        "authorId" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "body" : "I wondered if the list should be copied, but it's fine because `_find_zombies()` creates a new list and swaps `self._zombies`.",
        "createdAt" : "2019-09-07T14:05:03Z",
        "updatedAt" : "2019-10-14T20:30:23Z",
        "lastEditedBy" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "tags" : [
        ]
      },
      {
        "id" : "b4373565-1103-43ac-9b4e-7dac55ed75e7",
        "parentId" : "14bcb8c1-2db1-43d9-9ee2-a43e7d236485",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Since we're using multiprocessing, the list will always be copied as they won't be able to share any object. Even it shares it's still fine since we only read from it.\r\n\r\nA quick demo on the no share part:\r\n\r\n```\r\nroot@7949bc1f5c5c:/opt/airflow# python test.py\r\n['123']\r\nroot@7949bc1f5c5c:/opt/airflow# cat test.py\r\nimport multiprocessing\r\nfrom pprint import pprint\r\n\r\ndef worker(the_list):\r\n    \"\"\"worker function\"\"\"\r\n    the_list.append(multiprocessing.current_process().name)\r\n    return\r\n\r\nif __name__ == '__main__':\r\n    jobs = []\r\n    the_list = ['123']\r\n    for i in range(3):\r\n        p = multiprocessing.Process(target=worker, args=(the_list, ), name=\"subprocess-{}\".format(i))\r\n        jobs.append(p)\r\n        p.start()\r\n    pprint(the_list)\r\n```",
        "createdAt" : "2019-09-07T23:31:42Z",
        "updatedAt" : "2019-10-14T20:30:23Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "4ad08eccef59fa62871849fc2a66ac3a6bcad50c",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +1242,1246 @@               len(self._file_path_queue) > 0):\n            file_path = self._file_path_queue.pop(0)\n            processor = self._processor_factory(file_path, self._zombies)\n            Stats.incr('dag_processing.processes')\n"
  },
  {
    "id" : "e18d8d12-5d27-4f6a-9fb5-6b43a923e382",
    "prId" : 6314,
    "prUrl" : "https://github.com/apache/airflow/pull/6314#pullrequestreview-301016989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28b97adc-4f14-4a8a-9992-ef7415df3c13",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "```suggestion\r\n         to safe.\r\n    :type safe_mode: bool\r\n```",
        "createdAt" : "2019-10-12T18:19:50Z",
        "updatedAt" : "2019-10-14T20:08:32Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "dd872fdae338dd1c736d7b8d4530cf3571da7918",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +298,302 @@        contains Airflow DAG definitions. If not provided, use the\n        core.DAG_DISCOVERY_SAFE_MODE configuration setting. If not set, default\n        to safe.\n    :type safe_mode: bool\n    :param include_examples: include example DAGs"
  },
  {
    "id" : "9b6b0765-5254-4a2b-bcb0-4ec892b0b911",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-323787248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b317c981-cad8-44b4-b865-d69528fb61ef",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "```suggestion\r\n```",
        "createdAt" : "2019-11-27T12:35:25Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "1a3813a2-8261-4a63-bd70-045e937ecd5c",
        "parentId" : "b317c981-cad8-44b4-b865-d69528fb61ef",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Unfortunately :(",
        "createdAt" : "2019-11-27T16:06:44Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 269,
    "diffHunk" : "@@ -1,1 +160,164 @@        \"\"\"\n        :return: IDs of all the DAGs in this\n        :rtype: list[unicode]\n        \"\"\"\n        return self.dag_id_to_simple_dag.keys()"
  },
  {
    "id" : "47f1829d-0ced-4b87-88dc-69f5b940f5de",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-323783127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b47dbef7-d03e-41e4-9c0b-589cbdd81859",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "Same here. `:rtype: airflow.utils.dag_processing.SimpleDag` can be removed, right?",
        "createdAt" : "2019-11-27T12:36:03Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "bc87fe6c-0b1f-4fbd-8334-146859cc1a5f",
        "parentId" : "b47dbef7-d03e-41e4-9c0b-589cbdd81859",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "No not really - type hints and docs are sadly separate right now.",
        "createdAt" : "2019-11-27T13:11:35Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "f0faefdd-2737-43a3-9b80-e14726b7c0ba",
        "parentId" : "b47dbef7-d03e-41e4-9c0b-589cbdd81859",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "> Nope. I added sphinx-autodoc-typehint that will add those automatically. I will review all the types in the affected files and see if there are any :type left.\r\n\r\nhttps://github.com/apache/airflow/pull/6596#discussion_r351287732 I would prefer doing it like this.",
        "createdAt" : "2019-11-27T14:00:55Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "c287102c-0ed0-464c-8dbc-acf2f8f5236f",
        "parentId" : "b47dbef7-d03e-41e4-9c0b-589cbdd81859",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yeah. I am testing if it *Really* works as advertised now. ",
        "createdAt" : "2019-11-27T15:42:56Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "1309ed9f-e5b8-4a51-bbd7-dc814543c940",
        "parentId" : "b47dbef7-d03e-41e4-9c0b-589cbdd81859",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Unfortunately autodoc won't work with autoapi-type-hints extensions. I will leave both for now in the future we would like need to change api generation to autodoc :( :( very bad.",
        "createdAt" : "2019-11-27T16:01:01Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 274,
    "diffHunk" : "@@ -1,1 +164,168 @@        return self.dag_id_to_simple_dag.keys()\n\n    def get_dag(self, dag_id: str) -> SimpleDag:\n        \"\"\"\n        :param dag_id: DAG ID"
  },
  {
    "id" : "a5ff329b-4157-42d8-915c-e2d31a9a5d7d",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-324911188",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14669444-ef4d-4384-95c8-72260c866689",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "API change?",
        "createdAt" : "2019-11-30T19:22:35Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "9e3ba7b6-03b2-44c6-bd89-5a1d650e6dfc",
        "parentId" : "14669444-ef4d-4384-95c8-72260c866689",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "We just add a new property. This is an additional property added, without breaking current API. Why do you think it's an API change ?",
        "createdAt" : "2019-11-30T22:26:45Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 664,
    "diffHunk" : "@@ -1,1 +1202,1206 @@    @property\n    def file_paths(self):\n        return self._file_paths"
  },
  {
    "id" : "ca22b85b-38ad-4366-893e-94a7122bb9ec",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-325846477",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27c0d87a-a410-4ecb-aab7-01c5797b52c7",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Good catch",
        "createdAt" : "2019-12-02T23:36:19Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "cb8cef00-941c-4ac4-888d-35a551ae1157",
        "parentId" : "27c0d87a-a410-4ecb-aab7-01c5797b52c7",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It's not me. It's pylint :).",
        "createdAt" : "2019-12-03T01:21:17Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 505,
    "diffHunk" : "@@ -1,1 +550,554 @@        if 'sqlite' in conf.get('core', 'sql_alchemy_conn') and self._parallelism > 1:\n            self.log.warning(\n                \"Because we cannot use more than 1 thread (max_threads = \"\n                \"%d ) when using sqlite. So we set parallelism to 1.\", self._parallelism\n            )"
  }
]