[
  {
    "id" : "ecde3a63-42e0-42a6-8f56-46da2f4aa190",
    "prId" : 948,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "This is the actual fix, the rest is just search and replace\n",
        "createdAt" : "2016-02-03T18:25:17Z",
        "updatedAt" : "2016-02-03T18:25:17Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "0d5cb747-763e-4e4e-b745-ce359828d442",
        "parentId" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "Cool. I can help test it once you merge it, but looks good to the eye!\n",
        "createdAt" : "2016-02-03T21:03:52Z",
        "updatedAt" : "2016-02-03T21:03:52Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      },
      {
        "id" : "fdc9354f-1aa6-4d54-9fed-f81ba2a090ce",
        "parentId" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "This fix addresses the problem raised by the reporter in https://github.com/airbnb/airflow/issues/920, but I've raised some concerns about how we are managing configuration in that issue, which we can fix by providing an easy way to inspect a unified view of the winning configuration in one place. \n",
        "createdAt" : "2016-02-03T21:17:37Z",
        "updatedAt" : "2016-02-03T21:17:37Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5ed58c112f447276627e6484b6dab60d6bfc65a",
    "line" : 127,
    "diffHunk" : "@@ -1,1 +2100,2104 @@    @classmethod\n    def alert_fernet_key(cls):\n        return conf.get('core', 'fernet_key') is None\n\n    @classmethod"
  },
  {
    "id" : "7510ccf1-b48a-41ef-9cfb-29ac5f73c632",
    "prId" : 1504,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9a0da3d-0fca-4692-a33b-3dd221a50d5e",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "the current working directory may not be the one you think it is. I'd use something like `os.path.join(settings.AIRFLOW_HOME, 'git_version')`\n",
        "createdAt" : "2016-05-19T15:28:09Z",
        "updatedAt" : "2016-05-19T15:28:09Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "7dbbd8e7-66d0-40fd-97f5-ce7527487b55",
        "parentId" : "a9a0da3d-0fca-4692-a33b-3dd221a50d5e",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "Done, though I am using os.path.join(*[settings.AIRFLOW_HOME, 'airflow', 'git_version']) here and in setup.py\n",
        "createdAt" : "2016-05-19T18:06:29Z",
        "updatedAt" : "2016-05-19T18:06:29Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d32c174f34132bf79abbef6a397a07f20bf5ecd",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +2308,2312 @@        git_version = None\n        try:\n            with open(\"airflow/git_version\") as f:\n                git_version = f.readline()\n        except Exception as e:"
  },
  {
    "id" : "91ae1db7-c20a-40b2-afaf-9a9254a12f9e",
    "prId" : 1523,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99a5ceb2-62af-4cd9-bb83-c97da90d4dd8",
        "parentId" : null,
        "authorId" : "366b1763-372e-4924-9c92-2ea8968443bd",
        "body" : "Curious about this. Do you guys run with AIRFLOW_HOME containing the entire AIRFLOW code base? We `pip install` airflow, and AIRFLOW_HOME points to a separate directory that just has airflow.cfg, dags dir, etc. I'm not sure that this would work for us, since `git_version` would be under the Python package dir, not AIRFLOW_HOME.\n",
        "createdAt" : "2016-05-19T18:56:26Z",
        "updatedAt" : "2016-05-19T19:25:53Z",
        "lastEditedBy" : "366b1763-372e-4924-9c92-2ea8968443bd",
        "tags" : [
        ]
      },
      {
        "id" : "18adbfe8-d242-4998-a199-6c064cfb677d",
        "parentId" : "99a5ceb2-62af-4cd9-bb83-c97da90d4dd8",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "We will need to iterate on this as we learn more about how different companies install. This feature could be the forcing function.\n",
        "createdAt" : "2016-05-19T22:22:21Z",
        "updatedAt" : "2016-05-19T22:22:21Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "aedb667d50e512655a590ec2af03504947dd9acb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2308,2312 @@        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME, 'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:"
  },
  {
    "id" : "80372cc6-2f66-4fbf-b1d8-d2dedfdaa2df",
    "prId" : 4368,
    "prUrl" : "https://github.com/apache/airflow/pull/4368#pullrequestreview-187873400",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89b7e136-a514-407e-a79d-9a77dfdb9e9f",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Maybe give this a bit more meaningful name? Something like `dag_state_stats`.",
        "createdAt" : "2018-12-26T09:54:52Z",
        "updatedAt" : "2018-12-26T20:52:20Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "78fd35d4-b829-4fb9-9209-40addcf432ef",
        "parentId" : "89b7e136-a514-407e-a79d-9a77dfdb9e9f",
        "authorId" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "body" : "üëç ",
        "createdAt" : "2018-12-26T10:38:08Z",
        "updatedAt" : "2018-12-26T20:52:20Z",
        "lastEditedBy" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "tags" : [
        ]
      }
    ],
    "commit" : "4db22b18a8f323bbb01b309b457c8fb5b3ca7a4c",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +557,561 @@        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state)).group_by(dr.dag_id, dr.state)\n\n        data = {}\n        for (dag_id, ) in dag_ids:\n            data[dag_id] = {}"
  },
  {
    "id" : "d8d15d59-451c-47ec-8836-3131d5bfbbbf",
    "prId" : 4401,
    "prUrl" : "https://github.com/apache/airflow/pull/4401#pullrequestreview-190373846",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f8d361d-b5e7-4298-9399-d2aa0a5d91b6",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "thanks. I go back and check https://github.com/apache/airflow/blob/master/airflow/models/__init__.py#L3560 which we define active_run to only running state. Initially, I thought scheduled would be one of them as well.",
        "createdAt" : "2019-01-08T18:11:43Z",
        "updatedAt" : "2019-01-08T18:11:43Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "740067ba14e5c086a254eefcb871ff391e888535",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +685,689 @@        active_runs = models.DagRun.find(\n            dag_id=dag.dag_id,\n            state=State.RUNNING,\n            external_trigger=False,\n            session=session"
  },
  {
    "id" : "fb5369bc-3414-47ed-bc06-604f879b4e27",
    "prId" : 4492,
    "prUrl" : "https://github.com/apache/airflow/pull/4492#pullrequestreview-193103618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I never was happy with this whole next_try_number hack - I should find time to have one row per try instead\r\nof a row per TI that gets altered.",
        "createdAt" : "2019-01-14T10:01:36Z",
        "updatedAt" : "2019-01-14T10:01:36Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "b4ab59ec-5647-46b7-b5b8-985b5c78e2a3",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "fa4e8b53-4987-4d88-99c9-e25f26d1515b",
        "body" : "@ashb I'd like that as well! Is there an issue for that work?",
        "createdAt" : "2019-01-15T14:51:29Z",
        "updatedAt" : "2019-01-15T14:51:29Z",
        "lastEditedBy" : "fa4e8b53-4987-4d88-99c9-e25f26d1515b",
        "tags" : [
        ]
      },
      {
        "id" : "2c9883a1-0bb5-4e67-ae2f-39103b82db26",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I don't think so. We'd need to work out how to do the migration so that viewing old tasks still works.\r\n\r\nIf you create a Jira ticket we can discuss some of the details on there.",
        "createdAt" : "2019-01-15T21:17:00Z",
        "updatedAt" : "2019-01-15T21:17:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "86034769-55a2-4c80-8f17-7e3e4e99d4b6",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "body" : "There is already the `task_fail` table which has one row per try. But only in case the task failed and is retried. However when a task is cleared (via UI) then there is no indication why there are more tries. ",
        "createdAt" : "2019-01-15T23:03:53Z",
        "updatedAt" : "2019-01-15T23:03:53Z",
        "lastEditedBy" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "tags" : [
        ]
      },
      {
        "id" : "e496ec23-0eed-40ed-bab0-f1bae013a1cd",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Another thing I would like to remove: \"clear\"ing tasks as it deletes history :) Instead I would like a \"retry\" button in the UI and ending up with \"Attempt 3 of 2\" sort of thing.\r\n\r\nThe other advantage of having each try/attempt being a row is that we could then store the URL of the log against that row, to have old logs still be readable even after a future change to Airflow's logging pattern. (Both 1.9 and 1.10 made logs from previous versions no-longer-readable in the UI.)",
        "createdAt" : "2019-01-16T12:07:52Z",
        "updatedAt" : "2019-01-16T12:07:53Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e87a7c0153bd0a0afe613584a42e81c850e8365",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +872,876 @@        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number"
  },
  {
    "id" : "3fe23184-4880-463d-92ab-f5774621280e",
    "prId" : 4502,
    "prUrl" : "https://github.com/apache/airflow/pull/4502#pullrequestreview-194191862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5daa5106-5e8b-4513-8af4-6e6426bda634",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Lol so much easier :D",
        "createdAt" : "2019-01-18T16:59:54Z",
        "updatedAt" : "2019-01-18T17:00:32Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f62097fc4d635e7cf7f2b0573159a367b7fde0e",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +1737,1741 @@        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED))\n\n        tasks = []"
  },
  {
    "id" : "115e3935-9300-47d5-bfc6-28ebc15ca098",
    "prId" : 4597,
    "prUrl" : "https://github.com/apache/airflow/pull/4597#pullrequestreview-196814172",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29acd2b1-351f-466b-94b5-c934bf911e15",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "@astahlman , since you are at this function, maybe we should consider add a check and see whether the user has permission to do refresh_all view.\r\n\r\nThe AirflowSecurityManager provides a way to check whether the user's role(https://github.com/apache/airflow/blob/master/airflow/www/security.py#L283). But we could do it in a different pr.",
        "createdAt" : "2019-01-27T06:49:09Z",
        "updatedAt" : "2019-01-27T16:09:47Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5cdec70adae317e90497e30606086184d453410d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1690,1694 @@        for dag_id in dagbag.dags:\n            # sync permissions for all dags\n            appbuilder.sm.sync_perm_for_dag(dag_id)\n        flash(\"All DAGs are now up to date\")\n        return redirect('/')"
  },
  {
    "id" : "5b558510-2537-473a-bbe8-78b968d39537",
    "prId" : 4863,
    "prUrl" : "https://github.com/apache/airflow/pull/4863#pullrequestreview-211765017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32e3da71-2020-4d18-bb80-07fcf24378f4",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We've already got a `session` object in scope here.",
        "createdAt" : "2019-03-07T10:59:37Z",
        "updatedAt" : "2019-03-08T10:24:10Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "3a89e98d-bac4-41b8-afc3-c642f98604f4",
        "parentId" : "32e3da71-2020-4d18-bb80-07fcf24378f4",
        "authorId" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "body" : "not anymore, just did remove that",
        "createdAt" : "2019-03-07T12:55:48Z",
        "updatedAt" : "2019-03-08T10:24:10Z",
        "lastEditedBy" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "tags" : [
        ]
      }
    ],
    "commit" : "3207bd2f8b66eb881dab4286365a53c31291009e",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1186,1190 @@            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)"
  },
  {
    "id" : "dc1fb52c-f3f4-4300-bfc0-6dbb3cd2b3b1",
    "prId" : 5037,
    "prUrl" : "https://github.com/apache/airflow/pull/5037#pullrequestreview-256090337",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Does this mean `try_count` can at most be 2?",
        "createdAt" : "2019-05-14T23:34:40Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "83741537-b25c-492d-985f-ef8834224c9e",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "No, actually try_count was initialised out of the block. Now made the correction. ",
        "createdAt" : "2019-05-15T14:55:07Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "130d4d86-c319-4d2d-95cb-77d2f7f6f899",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "If `ti_fails` is not sorted this piece of logic won't work correct, will it? If it is sorted, you still need to reset `try_count`. Also can you elaborate the difference of the bar items we are adding here versus the items we were adding [here](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1744) please?",
        "createdAt" : "2019-05-17T22:16:44Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "5e08ce37-da29-48fa-9108-24a65457209e",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "1. ti_fails will always be in sorted order because of the nature of task_fail table having auto increment key. \r\n2. try_count is always reset as 1 in the starting of the for loop of ti_fails. But yeah thanks for catching this. I have to reset it once new failed task instance comes into the picture. \r\n3. gantt_bar_items appended against the tis metadata are having the state as success or running or final fail from task_instance table so having the try_number for the same only. It doesn't capture the all the failed instances. In case of failed tasks, entries go into task_fail table and we can't get the try number from there directly hence I am incrementing the try_count and appending the same against ti_fails metadata because of the nature of task_fail table.",
        "createdAt" : "2019-05-21T07:50:17Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "6b844f4d-0321-4c3f-b13b-d31e92d80812",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "1. I don't think having auto increment key has anything to do with the order of data returned. A quick search gave me [this](https://dba.stackexchange.com/questions/5774/why-is-ssms-inserting-new-rows-at-the-top-of-a-table-not-the-bottom/5775#5775https://dba.stackexchange.com/questions/5774/why-is-ssms-inserting-new-rows-at-the-top-of-a-table-not-the-bottom/5775#5775).\r\n3. Assuming appending twice will not create two row for the same task instance in the graph( please confirm this), we are showing total try count only if the task instance is in FAILED state. This can be quite confusing. We need to probably revisit and decide what exactly we want to display and at least make sure it is consistent between task instances in different states.",
        "createdAt" : "2019-05-23T21:24:17Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "7d2a9e09-4187-47a5-87ae-7828cc1baf9c",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "Answer to your questions -\r\n1. I understand the fact but that order is already maintained through this ordered [list](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1728)  keeping the gantt chart in mind. Anyhow metadata apart from try number is coming in sorted order.\r\nExample can be understood by the below use case -\r\n\r\nmysql> select * from task_fail as tf  where TF.task_id = 'get_op'  AND TF.execution_date = '2019-05-29 05:30:00.000000' AND TF.dag_id='example_http_operator1';\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| id | task_id | dag_id                 | execution_date             | start_date                 | end_date                   | duration |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n|  8 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:37:45.177828 | 2019-05-30 22:37:51.449197 |        6 |\r\n| 27 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:43:08.766188 | 2019-05-30 22:43:10.270735 |        2 |\r\n| 46 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:48:20.494280 | 2019-05-30 22:48:22.069887 |        2 |\r\n| 62 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:53:27.867508 | 2019-05-30 22:53:29.474945 |        2 |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n4 rows in set (0.00 sec)\r\n\r\nmysql> select * from task_fail as tf  where TF.task_id = 'post_op'  AND TF.execution_date = '2019-05-29 05:30:00.000000' AND TF.dag_id='example_http_operator1';\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| id | task_id | dag_id                 | execution_date             | start_date                 | end_date                   | duration |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| 17 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:38:19.100704 | 2019-05-30 22:38:26.619226 |        8 |\r\n| 36 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:43:36.747317 | 2019-05-30 22:43:38.238442 |        1 |\r\n| 53 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:48:48.267570 | 2019-05-30 22:48:49.595367 |        1 |\r\n| 69 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:53:55.739041 | 2019-05-30 22:53:57.038769 |        1 |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n4 rows in set (0.00 sec)\r\nExplanation : list has been formed by taking each individual task like appending the above result. Please find the below screenshot to validate the same results -\r\n<img width=\"1560\" alt=\"Screen Shot 2019-05-31 at 12 24 37 AM\" src=\"https://user-images.githubusercontent.com/20847563/58656806-93a64500-833a-11e9-8df3-ab91d5ce1c65.png\">\r\n\r\n2. Yes, It is not appending twice. reasoning is same as above. All the metadata except try count is populated through the same logic. I have just added this only in both the gantt_bar_items. Above than that, I am showing the try count in every state. As task_fail doesn't have try number in it's table so I have made the logic to get the same and that's how try number is appended in gantt_bar_items of the failed tasks as well. \r\nMoreover, the conclusion is that we need to display try_count every-time user the Gantt UI of airflow irrespective of state and that is consistent across different states. \r\n",
        "createdAt" : "2019-05-30T19:00:58Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "bf2f41fb-18df-4d03-a09a-4942f928e808",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "1. Yes all task fails are grouped by task_id as we have only one ti for each task, missed this part earlier.  Tho we can still have wrong order of task fails. Result is that in the gantt chart, we can have a try with later start date appear on the left side of a try with earlier start date.\r\n2. Mb misunderstood the state there, didn't get that append will create a new column in the row. In this case, did we append the last try for failed tasks twice?( visually doesn't seem to create a problem tho)",
        "createdAt" : "2019-06-25T00:01:03Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "5a8b5925-ec5d-4dcf-b684-5d3e7402a4d1",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "Please find my answers -\r\n1. Start date is already coming in the correct order even with out introducing my changes. I have only added the try number in every column. So gantt chart will not have any case in which later start date appears on the left side as compare to earlier start date.\r\n2. Even in this, append is already creating the column twice with out introducing my changes and yes there is no problem with this as well. ",
        "createdAt" : "2019-06-26T14:16:52Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "da3b6d39-b087-4fd9-9948-17db4b0835af",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "The value of [ti_fails](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1728) is not guaranteed to be ordered but you don't have to include a fix in your PR as it is not newly introduced. I'll submit a new JIRA for it.",
        "createdAt" : "2019-06-30T20:48:39Z",
        "updatedAt" : "2019-06-30T20:48:48Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a7cf89e13707c23c9f6afb5868880e03580c1f5",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1750,1754 @@            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1"
  },
  {
    "id" : "75ae628f-8654-4ad4-8899-888529412e1a",
    "prId" : 5079,
    "prUrl" : "https://github.com/apache/airflow/pull/5079#pullrequestreview-243166032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Could you avoid/remove the import ordering/format changes? Having these in here makes it much harder to cherry-pick fixes back to the 1-10 release branch.",
        "createdAt" : "2019-05-28T16:06:01Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c1f5d707-8a6d-4053-974b-9344181c7d12",
        "parentId" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Roger that",
        "createdAt" : "2019-05-28T23:43:42Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "cc7d0ed0-f486-4683-b668-5bf22e5b7bae",
        "parentId" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(And make it less likely to conflict too)",
        "createdAt" : "2019-05-29T10:18:56Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "b82718b2d8e5367219f602212d930685d957f12f",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +66,70 @@from airflow.www.forms import (ConnectionForm, DagRunForm, DateTimeForm,\n                               DateTimeWithNumRunsForm,\n                               DateTimeWithNumRunsWithDagRunsForm)\nfrom airflow.www.widgets import AirflowModelListWidget\n"
  },
  {
    "id" : "687e0803-063f-47eb-a72e-4a0d854fb338",
    "prId" : 5177,
    "prUrl" : "https://github.com/apache/airflow/pull/5177#pullrequestreview-236947928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa352889-be17-473d-bd62-f86bc05d86d4",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "NIT: `if ti:`",
        "createdAt" : "2019-05-13T22:22:27Z",
        "updatedAt" : "2019-05-13T23:30:05Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f5c6009bdace52a9929b16b726926122a2492b2",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +556,560 @@\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)"
  },
  {
    "id" : "bbb573e8-718a-43d0-885d-96ff8fa2984d",
    "prId" : 5339,
    "prUrl" : "https://github.com/apache/airflow/pull/5339#pullrequestreview-243916741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe3ceed9-90ae-4784-90cf-05d02e120d79",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This should probably be `.isoformat()`? (or at least include seconds and MS)",
        "createdAt" : "2019-05-30T16:12:33Z",
        "updatedAt" : "2019-06-06T14:38:33Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "e9664a67-58a5-4134-8d35-f20c338f8b73",
        "parentId" : "fe3ceed9-90ae-4784-90cf-05d02e120d79",
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "That might make the UI look too crowded, and not sure if there is value to users to have this additional information. This PR maintains the same format as before in the non-async version: https://github.com/apache/airflow/pull/5339/files#diff-f38558559ea1b4c30ddf132b7f223cf9L111",
        "createdAt" : "2019-05-30T17:14:20Z",
        "updatedAt" : "2019-06-06T14:38:33Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "693e141cb1bace0b23883ec2ed6ee7bb7ab71abc",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +426,430 @@                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n"
  },
  {
    "id" : "d75359b1-123e-4548-9703-ce5c95793259",
    "prId" : 5525,
    "prUrl" : "https://github.com/apache/airflow/pull/5525#pullrequestreview-257570934",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f88e7e86-a03d-44af-84e8-101adb1ccc26",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Could we use `m.log_url` here?",
        "createdAt" : "2019-07-03T15:30:10Z",
        "updatedAt" : "2019-07-03T18:23:15Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "a837ec7e-d742-4488-a3d7-f401a1197b10",
        "parentId" : "f88e7e86-a03d-44af-84e8-101adb1ccc26",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "True.",
        "createdAt" : "2019-07-03T15:31:15Z",
        "updatedAt" : "2019-07-03T18:23:15Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d2a3ef58f629ef54c98879b34dadf7d269d2986",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +123,127 @@\ndef log_url_formatter(v, c, m, p):\n    url = url_for(\n        'airflow.log',\n        dag_id=m.dag_id,"
  },
  {
    "id" : "644fc6ed-1124-4bdc-849e-827be71de641",
    "prId" : 5527,
    "prUrl" : "https://github.com/apache/airflow/pull/5527#pullrequestreview-257943441",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7471288-5714-4fbd-af33-cee9a5fc3235",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "üëç  -> checked that numRetries  can be 0 as well",
        "createdAt" : "2019-07-04T09:52:06Z",
        "updatedAt" : "2019-07-04T09:53:01Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0326528da3669a3b79417f89421b12c4ada79659",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +3049,3053 @@            validators=[\n                validators.Optional(strip_whitespace=True),\n                validators.NumberRange(min=0),\n            ],\n        ),"
  },
  {
    "id" : "85231ceb-0b92-4980-ab02-2a15d07ad7d8",
    "prId" : 5527,
    "prUrl" : "https://github.com/apache/airflow/pull/5527#pullrequestreview-320170735",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ee66b1f-e12c-40d5-a43e-2671a39d93a6",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Does this need to change too ?\r\n\r\n```diff\r\n- 'extra__grpc__credentials_pem_file': StringField('Credential Keyfile Path'),\r\n+ 'extra__grpc__credential_pem_file': StringField('Credential Keyfile Path'),\r\n```",
        "createdAt" : "2019-11-20T18:09:53Z",
        "updatedAt" : "2019-11-20T18:09:54Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d166e6e1-7ffa-4dfb-a4e2-e44cda468945",
        "parentId" : "2ee66b1f-e12c-40d5-a43e-2671a39d93a6",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Ah. yes or the other side should be `extra__grpc__credentials_pem_file`.",
        "createdAt" : "2019-11-20T18:11:26Z",
        "updatedAt" : "2019-11-20T18:11:26Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "0326528da3669a3b79417f89421b12c4ada79659",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +3053,3057 @@        ),\n        'extra__grpc__auth_type': StringField('Grpc Auth Type'),\n        'extra__grpc__credentials_pem_file': StringField('Credential Keyfile Path'),\n        'extra__grpc__scopes': StringField('Scopes (comma separated)'),\n    }"
  },
  {
    "id" : "08040b99-982e-455f-ad55-53b367950c0e",
    "prId" : 6650,
    "prUrl" : "https://github.com/apache/airflow/pull/6650#pullrequestreview-322878664",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "```suggestion\r\n                if ti and dag:\r\n```",
        "createdAt" : "2019-11-25T15:54:25Z",
        "updatedAt" : "2019-11-25T15:58:50Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "a72a0bd0-5d31-4c5f-b56f-9e3cf9afb62c",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "so you can remove `if ti is not None:`",
        "createdAt" : "2019-11-25T15:54:44Z",
        "updatedAt" : "2019-11-25T15:58:51Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "0a227f71-b723-4b5e-8746-42015daf8084",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I am not sure. There may be a task instance without DAG or DAG without task. These are the correct cases. Please note that dag variable is None, when task is not found.  This is the most important thing in this change. If we have task instances, we are looking for DAG. If we find DAG, we are looking for a task, but if we don't find DAG, then we do nothing.",
        "createdAt" : "2019-11-25T21:53:45Z",
        "updatedAt" : "2019-11-25T21:55:04Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "b5900b91-7fe2-4289-9aa7-eb3210a96fe9",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "I got it. üëç ",
        "createdAt" : "2019-11-26T10:36:45Z",
        "updatedAt" : "2019-11-26T10:36:45Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "35969fe35ca4532f97b53ad4c5d40ea3276edde1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +579,583 @@            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                if dag:\n                    ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':"
  },
  {
    "id" : "e872bf69-30dc-4c6c-872e-30906ada7de9",
    "prId" : 7251,
    "prUrl" : "https://github.com/apache/airflow/pull/7251#pullrequestreview-363294960",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Looks good -- only question is around if we need `unquote` here or not (I wouldn't have thought we do.)",
        "createdAt" : "2020-02-24T10:04:14Z",
        "updatedAt" : "2020-02-24T10:04:15Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "df64688a-f554-4168-9c69-7aa77ee5a6fb",
        "parentId" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "authorId" : "82aa078f-2a60-4ac5-95fc-0d69bea786b5",
        "body" : "So i just tested this locally https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams does URL encoding for us so we need the unquote. Its unlikely that a dag_id would have any special character but the owner field could potentially have anything.",
        "createdAt" : "2020-02-24T10:17:31Z",
        "updatedAt" : "2020-02-24T10:17:31Z",
        "lastEditedBy" : "82aa078f-2a60-4ac5-95fc-0d69bea786b5",
        "tags" : [
        ]
      },
      {
        "id" : "90c30dbb-17fc-48aa-818d-0cd37edbba97",
        "parentId" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I was surprised that `request.args` didn't unquote tbh. Quoting on input is 100% the behaviour we want.",
        "createdAt" : "2020-02-24T10:37:45Z",
        "updatedAt" : "2020-02-24T10:37:45Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e47b6114c68559818500c8b09e8d7913c179c5b",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +2721,2725 @@    @expose('/autocomplete')\n    def autocomplete(self, session=None):\n        query = unquote(request.args.get('query', ''))\n\n        if not query:"
  },
  {
    "id" : "98b2ab69-5130-4b23-9222-dad76449c7fc",
    "prId" : 7492,
    "prUrl" : "https://github.com/apache/airflow/pull/7492#pullrequestreview-364480367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Does this change the default/current view behaviour?",
        "createdAt" : "2020-02-24T12:42:05Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "edbd017c-4e0d-4aa7-9a93-7b6ddb82cf45",
        "parentId" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "It shouldn't, at least for the DAGs that I have tried so far, the rendering behavior remains unchanged and trees are expanded properly. Do you have specific cases that you want to test for?",
        "createdAt" : "2020-02-24T16:10:40Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "1865a8d3-e895-4464-ba72-7578e2a19a46",
        "parentId" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Nope, what you've done sounds good.",
        "createdAt" : "2020-02-25T21:59:27Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "f57038e24b0cf0663fe5a8fb8f06638ed8fd04cf",
    "line" : 160,
    "diffHunk" : "@@ -1,1 +1444,1448 @@                # repeated nodes are collapsed by default.\n                if task.task_id not in expanded:\n                    children_key = 'children'\n                    expanded.add(task.task_id)\n                else:"
  },
  {
    "id" : "124902f0-92f6-451e-b362-9745c17338cc",
    "prId" : 7492,
    "prUrl" : "https://github.com/apache/airflow/pull/7492#pullrequestreview-365674497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "How much does it reduce it by? Is stripping of _all_ ms noticable? (Could we perhaps limit to 3 or 6 sig. fig.?)",
        "createdAt" : "2020-02-25T22:12:31Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "fc38c3e6-5142-4d94-823d-8e50e28f1766",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "not much for task node since we don't have too many of them, that's why i didn't add the rounding in the first place here. It did make a big difference for task instance node since we have lots of them, IIRC, probably around 10-20% size reduction.\r\n\r\nI can change it to round to 3 sig. fig. everywhere to see what the performance implication would be.",
        "createdAt" : "2020-02-25T22:18:04Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "2c695134-4774-46b3-a811-f07d7a207514",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "@ashb round to 3 sig. fig. increases the overall payload size by 15%. The question now is do we care about millisecond accuracy for task start/end time enough to take this 15% performance hit?\r\n\r\nSo far, I found second granularity has been good enough for us, but I might be missing other use-cases.",
        "createdAt" : "2020-02-25T22:43:50Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "b0055e93-be50-4916-827a-f9509f3ce5f3",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Probably not needed.\n\nIs it worth making it a config option do you think?",
        "createdAt" : "2020-02-25T23:33:21Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "6ec0d10f-cade-4e15-8363-802392141aa6",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "This code path has a very hot function call loop that's very sensitive to if statements. For the large DAG that we have, adding one extra if statement increases the response time by more than 400ms. That's why `simplify reduce_nodes() logic, remove unnecessary if statements` is in the optimization list :)\r\n\r\nThat and based on the understanding that we are rewriting Airflow web into a proper SPA, I think it's best not to introduce a config for this change. I would prefer us giving round to second a try and come back to add more sig. fig. or add a config later on if any real use-case comes up. It's better to not engineer solutions when we don't have a good use-case in mind.\r\n\r\nIf you are really concerned about the precision, we can perhaps change it to round to 1 sig. fig. for a 7% performance hit. I can't really think of a case where knowing 0.01 second difference of runtime is important.\r\n\r\n",
        "createdAt" : "2020-02-27T01:40:58Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "c08eaaf2-2237-4baa-9b68-ed32a2c5510f",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Good reasoning. I'll copy some/most of this in to the commit message for future-proofing.",
        "createdAt" : "2020-02-27T13:20:55Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "052cf8f4-6709-4658-8e28-5f15b12ec48a",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Leaving this unresolved as a reminder to myself.",
        "createdAt" : "2020-02-27T13:23:22Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "f57038e24b0cf0663fe5a8fb8f06638ed8fd04cf",
    "line" : 169,
    "diffHunk" : "@@ -1,1 +1453,1457 @@                node['depends_on_past'] = task.depends_on_past\n            if task.start_date:\n                # round to seconds to reduce payload size\n                node['start_ts'] = int(task.start_date.timestamp())\n                if task.end_date:"
  },
  {
    "id" : "07fc1ba4-3da7-493c-a4be-5251f88c9788",
    "prId" : 8106,
    "prUrl" : "https://github.com/apache/airflow/pull/8106#pullrequestreview-389266654",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "743f5b4a-672e-4550-ae42-af8cd16cf8e5",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This does three queries - we could do it with two very easily as `count_all == count_active+count_paused`, right?\r\n\r\n(We could _attempt_ to do it as one query with `SELECT is_paused, count(*) ... GROUP BY is_paused` but that may or may not be more efficient in the end)",
        "createdAt" : "2020-04-07T12:14:59Z",
        "updatedAt" : "2020-04-08T18:26:47Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "94d20274-b56f-4da0-9426-b2e0ebf35aaa",
        "parentId" : "743f5b4a-672e-4550-ae42-af8cd16cf8e5",
        "authorId" : "f59eb591-c12e-407d-b1ee-57f70f09b390",
        "body" : "Updated (with your sum suggestion).",
        "createdAt" : "2020-04-07T16:03:35Z",
        "updatedAt" : "2020-04-08T18:26:47Z",
        "lastEditedBy" : "f59eb591-c12e-407d-b1ee-57f70f09b390",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a1834fc2e519eb8e7806f7f5791d3e6c83ea50c",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +331,335 @@\n        status_count_active = active_dags.count()\n        status_count_paused = paused_dags.count()\n        status_count_all = status_count_active + status_count_paused\n"
  },
  {
    "id" : "ac1793c9-4f1e-46f6-9a54-0e192322332c",
    "prId" : 8106,
    "prUrl" : "https://github.com/apache/airflow/pull/8106#pullrequestreview-389056446",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "692b7f92-edfe-4f55-9acf-ca4e8d454d7c",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Not sure off the top of my head how this auto-complete works, but might it be better to allow auto-completing of all dags, even ones that aren't shown? Or is the filtering/searching done client side based on the visible data only?\r\n\r\n",
        "createdAt" : "2020-04-07T12:16:18Z",
        "updatedAt" : "2020-04-08T18:26:47Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "7539e8e1-6ee1-417b-9186-c3acab9faf2b",
        "parentId" : "692b7f92-edfe-4f55-9acf-ca4e8d454d7c",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I guess this is the \"same\" behaviour as before, just updated to the new mechanism so this is fine.",
        "createdAt" : "2020-04-07T12:16:47Z",
        "updatedAt" : "2020-04-08T18:26:47Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a1834fc2e519eb8e7806f7f5791d3e6c83ea50c",
    "line" : 129,
    "diffHunk" : "@@ -1,1 +2805,2809 @@            DagModel.owners.ilike('%' + query + '%'))\n\n        # Hide DAGs if not showing status: \"all\"\n        status = flask_session.get(FILTER_STATUS_COOKIE)\n        if status == 'active':"
  },
  {
    "id" : "92b5acb3-9f6c-4342-8a5d-cbb1b021fdcf",
    "prId" : 8742,
    "prUrl" : "https://github.com/apache/airflow/pull/8742#pullrequestreview-407350980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b71b0e12-b2fc-4a08-9055-0ccee4c1da8b",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "`None` is one of the keys in `State.state_color`, and it cannot be handled by Flask's `tojson` directly. So a special treatment is needed here.\r\n\r\nA related issue I raised in Flask: https://github.com/pallets/flask/issues/3599",
        "createdAt" : "2020-05-06T18:46:16Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "5fdf4cf7-fe55-40b8-9744-023a8825f081",
        "parentId" : "b71b0e12-b2fc-4a08-9055-0ccee4c1da8b",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Keys in JSON must be strings, so `{ null: \"x\"}` isn't valid JSON. So it _sort_ of makes sense that it doesn't get added. Sort of.",
        "createdAt" : "2020-05-07T10:33:05Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "5621b6d0-d5c5-4aaf-9ef7-ba26670a90f6",
        "parentId" : "b71b0e12-b2fc-4a08-9055-0ccee4c1da8b",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Python already handles it for us:\r\n```python\r\nimport json\r\nprint(json.dumps({None: 123}))\r\n```\r\ngives us `{\"null\": 123}`.\r\n\r\nThe issue is the `sort_keys` argument when we run `json.dumps()`.\r\n",
        "createdAt" : "2020-05-07T10:38:29Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      }
    ],
    "commit" : "390282b026fd38280e8e84e36cd24e22ffee6424",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +339,343 @@\n        state_color_mapping = State.state_color.copy()\n        state_color_mapping[\"null\"] = state_color_mapping.pop(None)\n\n        return self.render_template("
  },
  {
    "id" : "08d923db-865b-42c9-aab9-bbeb9aa8e012",
    "prId" : 8742,
    "prUrl" : "https://github.com/apache/airflow/pull/8742#pullrequestreview-407234885",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "378695bb-c06b-464b-a8d8-231c17f9a3b5",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Hi. Would you like to add a test that will check if the correct value was passed to the template? A method has been added today that makes it easy. I think it's worth gradually extending this idea to other tests to increase the confidence of the Web UI tests.\r\nhttps://github.com/apache/airflow/pull/8505",
        "createdAt" : "2020-05-06T20:23:48Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "3dcc5c52-9338-44ea-ae68-c60689ffd1cb",
        "parentId" : "378695bb-c06b-464b-a8d8-231c17f9a3b5",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @mik-laj , thanks for the suggestion.\r\n\r\nI have done an update by adding an assert in an existing test, which should suffice the purpose here.\r\n\r\nLet me know if you have any other suggestion? Cheers.",
        "createdAt" : "2020-05-06T20:37:56Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "95d741f3-b477-40c3-a5ce-306bc83af34d",
        "parentId" : "378695bb-c06b-464b-a8d8-231c17f9a3b5",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Hi @mik-laj , I have further updated the UI test code using the method you shared. Please take a look when you get time.\r\n\r\nTwo tests are failing, https://travis-ci.org/github/apache/airflow/jobs/684134650#L16198 and https://github.com/apache/airflow/pull/8742/checks?check_run_id=652054298 . But both seem interim and irrelevant to the changes of this PR",
        "createdAt" : "2020-05-07T08:00:07Z",
        "updatedAt" : "2020-05-10T16:33:21Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      }
    ],
    "commit" : "390282b026fd38280e8e84e36cd24e22ffee6424",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +357,361 @@            num_runs=num_runs,\n            tags=tags,\n            state_color=state_color_mapping,\n            status_filter=arg_status_filter,\n            status_count_all=all_dags_count,"
  },
  {
    "id" : "6c701dbb-9988-48c5-b3c4-f973f8173985",
    "prId" : 9354,
    "prUrl" : "https://github.com/apache/airflow/pull/9354#pullrequestreview-438702315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3760fac1-e84b-4d44-a502-023c3f038567",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Can you handle missing TI here? You should probably redirect the user to the main page + display flash message.",
        "createdAt" : "2020-06-26T09:53:44Z",
        "updatedAt" : "2020-06-28T19:28:55Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "055b281d-6da6-49b5-865d-98f083cce723",
        "parentId" : "3760fac1-e84b-4d44-a502-023c3f038567",
        "authorId" : "e531d078-ea28-4210-9107-b646ee4d0200",
        "body" : "Done.",
        "createdAt" : "2020-06-27T14:33:21Z",
        "updatedAt" : "2020-06-28T19:28:55Z",
        "lastEditedBy" : "e531d078-ea28-4210-9107-b646ee4d0200",
        "tags" : [
        ]
      }
    ],
    "commit" : "38c5d9d33e45126d20e62b1892cb6b4533712f02",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +777,781 @@            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        if not ti:\n            flash(f\"Task [{dag_id}.{task_id}] does not exist\", \"error\")"
  },
  {
    "id" : "1ea51ebe-5b74-4a3f-90b9-0319bc1d4511",
    "prId" : 9391,
    "prUrl" : "https://github.com/apache/airflow/pull/9391#pullrequestreview-433692351",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "147b4e99-bc63-472a-967c-156c9d78a49d",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Does Javascript need to be updated? ",
        "createdAt" : "2020-06-18T20:55:36Z",
        "updatedAt" : "2020-06-19T10:27:46Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "7d26c24c-f43f-4ce1-b00d-514340d64f3b",
        "parentId" : "147b4e99-bc63-472a-967c-156c9d78a49d",
        "authorId" : "c7b0cb1c-ff95-4ec9-a0c6-a9f1b5135a52",
        "body" : "Everything is fine with the logging on the website",
        "createdAt" : "2020-06-18T22:36:54Z",
        "updatedAt" : "2020-06-19T10:27:46Z",
        "lastEditedBy" : "c7b0cb1c-ff95-4ec9-a0c6-a9f1b5135a52",
        "tags" : [
        ]
      }
    ],
    "commit" : "63419e1a7dd3f4b41b8fd4fb6ff0cf9431290541",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +676,680 @@        if not task_log_reader.is_supported:\n            return jsonify(\n                message=\"Task log handler does not support read logs.\",\n                error=True,\n                metadata={"
  },
  {
    "id" : "355b5a30-35e4-4334-be6c-06ac6f61df11",
    "prId" : 10162,
    "prUrl" : "https://github.com/apache/airflow/pull/10162#pullrequestreview-490854530",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18088808-d22c-4260-9ffb-af1f805cc2fb",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Why do we need both?",
        "createdAt" : "2020-09-17T11:16:19Z",
        "updatedAt" : "2021-02-16T20:58:04Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "de741c74-f90b-423e-8383-d7b21591a636",
        "parentId" : "18088808-d22c-4260-9ffb-af1f805cc2fb",
        "authorId" : "99131d83-46cd-430f-8b42-6e937e9ce893",
        "body" : "I'll double check this, but if not needed for the UI will remove.",
        "createdAt" : "2020-09-17T17:44:25Z",
        "updatedAt" : "2021-02-16T20:58:04Z",
        "lastEditedBy" : "99131d83-46cd-430f-8b42-6e937e9ce893",
        "tags" : [
        ]
      },
      {
        "id" : "42f4d85f-0314-4371-a525-75aba0263878",
        "parentId" : "18088808-d22c-4260-9ffb-af1f805cc2fb",
        "authorId" : "99131d83-46cd-430f-8b42-6e937e9ce893",
        "body" : "Have amended the code slightly so that `Airflow - DAGs - CustomText` appears as the site_title and the `<h2>` renders the page_title as per the original suggestion.",
        "createdAt" : "2020-09-17T17:59:38Z",
        "updatedAt" : "2021-02-16T20:58:04Z",
        "lastEditedBy" : "99131d83-46cd-430f-8b42-6e937e9ce893",
        "tags" : [
        ]
      }
    ],
    "commit" : "86e252dd7d5100eaf5e664f4f869a561852bd3f2",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +582,586 @@            current_page=current_page,\n            search_query=arg_search_query if arg_search_query else '',\n            page_title=page_title,\n            page_size=dags_per_page,\n            num_of_pages=num_of_pages,"
  },
  {
    "id" : "b6536dc0-904a-441e-8fca-43a58a75302d",
    "prId" : 10498,
    "prUrl" : "https://github.com/apache/airflow/pull/10498#pullrequestreview-473726002",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47314cc0-044e-4dd6-8587-715e47eedf2f",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Was this necessary? Personally I would define `DR` and `TI` on module level to remove a  few lines and reduce number of changes at the same time.",
        "createdAt" : "2020-08-23T16:11:50Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "0f1892a3-b106-4aca-85a2-c9956691e357",
        "parentId" : "47314cc0-044e-4dd6-8587-715e47eedf2f",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It was not strictly necessarym but it increases the readability IMHO. It shortens the name but it also increases the mental effort to look up TI and DR elsewhere. I think the code is much more readable when you explicitly spell the class that you use rather than use shorter, two letter names. This is the same reason why pylint disallows short variable names and prefers longer alternatives that spell the actual variable name (df/dtm/fn etc.). That's why I put it as the same change.\r\n\r\nIn general the code IMHO should be optimised for being more readable explicitely then shorter-writeable.",
        "createdAt" : "2020-08-24T01:03:31Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "453e5964-b502-471d-ac6d-4e84039209c3",
        "parentId" : "47314cc0-044e-4dd6-8587-715e47eedf2f",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Should we add DR, TI and others to unallowed stuff then? ",
        "createdAt" : "2020-08-24T09:10:10Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "700978bd-0c73-4e32-8369-f54e14403dd9",
        "parentId" : "47314cc0-044e-4dd6-8587-715e47eedf2f",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "We might ad it later indeed :) ",
        "createdAt" : "2020-08-24T17:49:58Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b088cba788144203f10d011f36a7e228f5199d",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +117,121 @@\n    drs = (\n        session.query(DagRun)\n        .filter(\n            DagRun.dag_id == dag.dag_id,"
  },
  {
    "id" : "7d5a4a79-1e61-4c46-91ed-9dfbb5a13355",
    "prId" : 10498,
    "prUrl" : "https://github.com/apache/airflow/pull/10498#pullrequestreview-473067049",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "671aaa96-d37e-41dc-9fc0-c399f33d4cb5",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n                if not isinstance(attr, type(self.task)):\r\n```\r\nWDYT?",
        "createdAt" : "2020-08-23T16:19:35Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "f0cf8d36-b10d-4fbd-a7d7-236188bb01b6",
        "parentId" : "671aaa96-d37e-41dc-9fc0-c399f33d4cb5",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I prefer to keep it as it is. There is a subtle difference between the two statemenets. The original one is true if the two types are the same, the second is true when the attr derives from the \"self.task\" type (but it can be a subclass). I prefer to stay with the original behaviour even if I have to add the exception. ",
        "createdAt" : "2020-08-24T01:06:19Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b088cba788144203f10d011f36a7e228f5199d",
    "line" : 468,
    "diffHunk" : "@@ -1,1 +865,869 @@            if not attr_name.startswith('_'):\n                attr = getattr(ti, attr_name)\n                if type(attr) != type(self.task):  # noqa pylint: disable=unidiomatic-typecheck\n                    ti_attrs.append((attr_name, str(attr)))\n"
  },
  {
    "id" : "b30d2048-857f-48d4-beec-941c5acc8b06",
    "prId" : 10498,
    "prUrl" : "https://github.com/apache/airflow/pull/10498#pullrequestreview-473067382",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "976c6f27-12a9-411f-96df-47461231094c",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Was this necessary? I think `ti` is quite known in Airflow context and we have `ti` as the allowed value in pylinrc. ",
        "createdAt" : "2020-08-23T16:22:22Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "afdfbcd0-7689-4097-81f2-f0c54b43a125",
        "parentId" : "976c6f27-12a9-411f-96df-47461231094c",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It was overriding ti from module level - defined elsewhere higher in the stack, that's why I renamed it.. ",
        "createdAt" : "2020-08-24T01:08:19Z",
        "updatedAt" : "2020-08-24T19:34:33Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b088cba788144203f10d011f36a7e228f5199d",
    "line" : 690,
    "diffHunk" : "@@ -1,1 +1502,1506 @@                    task_instance_data[3] = int(task_instance.duration)\n\n            return task_instance_data\n\n        def recurse_nodes(task, visited):"
  },
  {
    "id" : "c1fc3305-f9c9-4401-9e6f-3daacdcf965b",
    "prId" : 10637,
    "prUrl" : "https://github.com/apache/airflow/pull/10637#pullrequestreview-512203793",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eebed975-2826-4a7b-8965-22dfad7c1715",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This could be incorrect an some (unlikely) circumstance:\r\n\r\nIf I create an dag run for an older execution_date, this would show mixed values.\r\n\r\nUnfortunately doing this correctly in a single SQL query is harder.",
        "createdAt" : "2020-09-08T17:08:49Z",
        "updatedAt" : "2020-10-19T22:25:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "9af6fa99-b5f7-4ebe-899a-eff57a49b2bc",
        "parentId" : "eebed975-2826-4a7b-8965-22dfad7c1715",
        "authorId" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "body" : "I can test for that, thanks for the heads up. However I would think the value above it, the execution_date, would be wrong to get the max value in the query, not the run_date. I don't recall that being the case as that query has been the same for a long time now (I just renamed the column alais) but if it is wrong, I'll try and fix it.",
        "createdAt" : "2020-09-09T03:46:51Z",
        "updatedAt" : "2020-10-19T22:25:25Z",
        "lastEditedBy" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "tags" : [
        ]
      },
      {
        "id" : "b457509e-5e15-4cf5-8ea9-450989a08137",
        "parentId" : "eebed975-2826-4a7b-8965-22dfad7c1715",
        "authorId" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "body" : "Sorry, got busy with other stuff, I'll look into this soon",
        "createdAt" : "2020-09-28T16:26:09Z",
        "updatedAt" : "2020-10-19T22:25:25Z",
        "lastEditedBy" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "tags" : [
        ]
      },
      {
        "id" : "62b6052a-9b10-448b-b47e-36b5cad81ab4",
        "parentId" : "eebed975-2826-4a7b-8965-22dfad7c1715",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Fair point -- if you could rebase this PR we can merge this as is, as this is right in most cases, and better than the current broken behavior.",
        "createdAt" : "2020-10-19T11:03:57Z",
        "updatedAt" : "2020-10-19T22:25:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "6c656523-7582-4320-a41c-58edfee16538",
        "parentId" : "eebed975-2826-4a7b-8965-22dfad7c1715",
        "authorId" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "body" : "rebased now",
        "createdAt" : "2020-10-19T22:26:54Z",
        "updatedAt" : "2020-10-19T22:26:54Z",
        "lastEditedBy" : "54ef9b5d-b7ff-483c-b9ee-dd4fa2fe3976",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e24bf4d1e445c1eea7eb540e2789615692ad715",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +729,733 @@            DagRun.dag_id,\n            sqla.func.max(DagRun.execution_date).label('execution_date'),\n            sqla.func.max(DagRun.start_date).label('start_date'),\n        ).group_by(DagRun.dag_id)\n"
  },
  {
    "id" : "5514fcee-bec9-4ba6-8ddf-faa5355efa4e",
    "prId" : 10770,
    "prUrl" : "https://github.com/apache/airflow/pull/10770#pullrequestreview-504323748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "025e379c-c40e-4ede-b7c4-36605a67898d",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "```suggestion\r\n\r\n    default_view = 'list'\r\n```",
        "createdAt" : "2020-10-07T22:56:47Z",
        "updatedAt" : "2020-10-17T10:44:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "aad57de573e98199b4c1261047d64f761f01bdee",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +2550,2554 @@    \"\"\"View to show Airflow Plugins\"\"\"\n\n    default_view = 'list'\n\n    plugins_attributes_to_dump = ["
  },
  {
    "id" : "3a10cbb4-7907-459d-bea1-9d552771883b",
    "prId" : 10839,
    "prUrl" : "https://github.com/apache/airflow/pull/10839#pullrequestreview-511641693",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5ebf32b-bee7-41f3-a9f9-3d566d600172",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This should have a try-catch around it -- it's entirely possible that something might be in the params that is not JSON-serializable (such as a datetime object).",
        "createdAt" : "2020-10-19T10:56:48Z",
        "updatedAt" : "2020-10-19T13:17:08Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d39be28e3d9fdbebbee2574636c1bf5dfb1d2a9",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1252,1256 @@                try:\n                    dag = current_app.dag_bag.get_dag(dag_id)\n                    default_conf = json.dumps(dag.params, indent=4)\n                except TypeError:\n                    flash(\"Could not pre-populate conf field due to non-JSON-serializable data-types\")"
  },
  {
    "id" : "49b9b3cd-2c74-4b41-9843-cad099c18cfb",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-514104126",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "174f7a6f-2e0e-4b04-8935-411bdd095acd",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Doesn't the pylint comment want to be on the next line?",
        "createdAt" : "2020-10-19T10:17:09Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "b971c7fd-7a92-4d74-9df6-2f868ff40e77",
        "parentId" : "174f7a6f-2e0e-4b04-8935-411bdd095acd",
        "authorId" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "body" : "Nope. See the other comment. I'm not sure why‚Äôd , but it throws it at this level for some reason. I presume it has to do with the reassigning the view function data to the output of the wrapper function.\r\n",
        "createdAt" : "2020-10-21T19:19:48Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +393,397 @@    @auth.has_access([\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),\n    ])  # pylint: disable=too-many-locals,too-many-statements\n    def index(self):\n        \"\"\"Home view.\"\"\""
  },
  {
    "id" : "1186c574-f624-4298-97eb-6d5a45240925",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-511614810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3fdfebe5-71dd-4ec8-a31f-6801a3379f95",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "```suggestion\r\n        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG_RUN),\r\n```\r\n\r\nPossibly _also_ can_delete TI",
        "createdAt" : "2020-10-19T10:20:59Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 302,
    "diffHunk" : "@@ -1,1 +1447,1451 @@    @auth.has_access([\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),\n        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_TASK_INSTANCE),\n    ])\n    @action_logging"
  },
  {
    "id" : "2e267472-c502-45ad-ada3-b989de0e0d8c",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-513698427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f256c42-b744-4ccd-b76a-a17b5a3b669c",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Errant pylint comment on decorator?",
        "createdAt" : "2020-10-19T10:22:24Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "893fbb25-9c99-4891-a03a-4f006519019b",
        "parentId" : "4f256c42-b744-4ccd-b76a-a17b5a3b669c",
        "authorId" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "body" : "Surprisingly, no. Pylint gets mad if this isn't applied to the decorator, rather than the function itself. Not entirely sure why.",
        "createdAt" : "2020-10-21T13:42:55Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 426,
    "diffHunk" : "@@ -1,1 +1951,1955 @@    ])\n    @action_logging  # pylint: disable=too-many-locals\n    @provide_session  # pylint: disable=too-many-locals\n    def duration(self, session=None):\n        \"\"\"Get Dag as duration graph.\"\"\""
  },
  {
    "id" : "d337e808-b388-446f-a32a-15c017654d57",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-511614810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99d3df99-ed5e-4850-9704-6456194f2355",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "So other than this one case, the website permission feels entirely needless. I wonder if this one could use `CAN_READ, RESOURCE_DAGS` here, and entirely the website permissions.\r\n\r\n(can read dags here, because the home page is effectively a list of the DAGs)",
        "createdAt" : "2020-10-19T10:28:32Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +392,396 @@    @expose('/home')\n    @auth.has_access([\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),\n    ])  # pylint: disable=too-many-locals,too-many-statements\n    def index(self):"
  },
  {
    "id" : "0f76de61-76df-49ca-8a05-7fdfa4ca5490",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-516635333",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c243fe65-1bf9-4fd6-918c-ce3951e2ab6e",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We should create a follow up PR to not make read task logs a requirement -- and if the permission is missing just don't do the `if task_log_reader.supports_external_link` bit.",
        "createdAt" : "2020-10-26T10:20:43Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 407,
    "diffHunk" : "@@ -1,1 +1860,1864 @@        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_INSTANCE),\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_LOG),\n    ])\n    @gzipped"
  },
  {
    "id" : "38cc44ab-b434-4cf5-af35-d6878d9299f1",
    "prId" : 11362,
    "prUrl" : "https://github.com/apache/airflow/pull/11362#pullrequestreview-516635333",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe098209-79a5-45ff-a5f1-bec27d9db850",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We should create a follow up PR to not make read task logs a requirement -- and if the permission is missing just don't do the `if task_log_reader.supports_external_link` bit.",
        "createdAt" : "2020-10-26T10:21:01Z",
        "updatedAt" : "2020-10-28T22:50:50Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "34a22f26c1eacd79b81e5ec050408b60f866b0a0",
    "line" : 390,
    "diffHunk" : "@@ -1,1 +1691,1695 @@        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_INSTANCE),\n        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_LOG),\n    ])\n    @gzipped  # pylint: disable=too-many-locals"
  },
  {
    "id" : "af4f1e77-af8a-42cb-926a-0e03dc75e8fc",
    "prId" : 11559,
    "prUrl" : "https://github.com/apache/airflow/pull/11559#pullrequestreview-509825346",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f270adb-7d67-4642-9a7f-984fd75be4bc",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I was mostly thinking of the current DagRun i.e. if this DagRun isn't running we don't refresh as with the current change, if another DagRun is running, this will still refresh automatically\r\n\r\nYou can get the state of it already using `dt_nr_dr_data['dr_state']` (also used on L1839)",
        "createdAt" : "2020-10-15T18:59:42Z",
        "updatedAt" : "2020-10-15T21:32:40Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "0f5abbc5-fff0-4a2a-8015-8f252cf728c5",
        "parentId" : "0f270adb-7d67-4642-9a7f-984fd75be4bc",
        "authorId" : "f59eb591-c12e-407d-b1ee-57f70f09b390",
        "body" : "Fixed, thanks @kaxil!",
        "createdAt" : "2020-10-15T21:33:35Z",
        "updatedAt" : "2020-10-15T21:33:35Z",
        "lastEditedBy" : "f59eb591-c12e-407d-b1ee-57f70f09b390",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5edbda2c823ddcb3dc7139a04bb82f438e5e73a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1843,1847 @@            edges=edges,\n            show_external_log_redirect=task_log_reader.supports_external_link,\n            external_log_name=external_log_name,\n            dag_run_state=dt_nr_dr_data['dr_state'])\n"
  },
  {
    "id" : "0f111ef4-ede5-40f1-8fd5-6801f538e60c",
    "prId" : 12459,
    "prUrl" : "https://github.com/apache/airflow/pull/12459#pullrequestreview-533864773",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "859fda98-858e-49b4-8df3-5c0ad525980f",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Using a private method isn't great. Do we have to?",
        "createdAt" : "2020-11-18T20:13:23Z",
        "updatedAt" : "2020-11-18T21:08:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "1807fd13-4179-4eaa-abd7-a7b693b22988",
        "parentId" : "859fda98-858e-49b4-8df3-5c0ad525980f",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "It is NamedTuple's _replace method: https://docs.python.org/3/library/collections.html#collections.somenamedtuple._replace\r\n\r\nJust returns a new instance of the named tuple replacing specified fields with new values\r\n\r\n",
        "createdAt" : "2020-11-18T20:46:13Z",
        "updatedAt" : "2020-11-18T21:08:56Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "c661a80f-2a10-420e-8dac-4067f3453c74",
        "parentId" : "859fda98-858e-49b4-8df3-5c0ad525980f",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Right, so not private, just looks like it. Funsies.",
        "createdAt" : "2020-11-18T20:50:58Z",
        "updatedAt" : "2020-11-18T21:08:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "7486153f451e4d2bb1c6fd9cbb5a63430157c99c",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +115,119 @@\n    query = parse_qsl(parsed.query, keep_blank_values=True)\n    url = parsed._replace(query=urlencode(query)).geturl()\n\n    if parsed.scheme in valid_schemes and parsed.netloc in valid_netlocs:"
  },
  {
    "id" : "6f1ec084-ac7f-4a96-88cc-ba9dc7c6c01a",
    "prId" : 12558,
    "prUrl" : "https://github.com/apache/airflow/pull/12558#pullrequestreview-546478753",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "142409d0-105a-430b-a9c0-5a1b9f708ec8",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "This is how I pass the \"field behaviours\" - Connection Form Widget is available to the \"edit\" and \"create\" templates when rendered so I can pss the field_behaviours via the widget.",
        "createdAt" : "2020-12-07T19:44:46Z",
        "updatedAt" : "2020-12-08T13:01:52Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "67ad0ffc2211b5a321de0d6b6ae82a14bb46c36f",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +2824,2828 @@# See airflow.hooks.base_hook.DiscoverableHook for details on how to customize your Hooks.\n# those field behaviours are rendered as scripts in the conn_create.html and conn_edit.html templates\nclass ConnectionFormWidget(FormWidget):\n    \"\"\"Form widget used to display connection\"\"\"\n"
  },
  {
    "id" : "e5c9a8c7-0c8b-46fc-8239-f027e21ca892",
    "prId" : 13037,
    "prUrl" : "https://github.com/apache/airflow/pull/13037#pullrequestreview-666775301",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b463474-f7df-45ea-ab74-3409348c9993",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Can you add tests for it @yuqian90 ",
        "createdAt" : "2021-05-24T14:09:49Z",
        "updatedAt" : "2021-05-24T14:09:55Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "430efe5a5202aaa0efe70b37d37327735791335c",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1811,1815 @@\n        if confirmed:\n            with create_session() as session:\n                altered = set_state(\n                    tasks=[task],"
  },
  {
    "id" : "0c77fab6-27da-42d4-8eda-82a40ee48200",
    "prId" : 13640,
    "prUrl" : "https://github.com/apache/airflow/pull/13640#pullrequestreview-566799844",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f64d44d-18b7-4fbf-9482-518fa9428b94",
        "parentId" : null,
        "authorId" : "59084487-c961-42ea-a4e0-21abbd0856de",
        "body" : "This assumes that the key already exists in `form.data`. (`if key in form.data ...`)\r\n\r\nIn `prefill_form` below, this may not necessarily the case?\r\n\r\n",
        "createdAt" : "2021-01-12T23:27:55Z",
        "updatedAt" : "2021-01-12T23:38:36Z",
        "lastEditedBy" : "59084487-c961-42ea-a4e0-21abbd0856de",
        "tags" : [
        ]
      },
      {
        "id" : "04e86143-f623-4611-aabb-31334e4315d9",
        "parentId" : "2f64d44d-18b7-4fbf-9482-518fa9428b94",
        "authorId" : "59084487-c961-42ea-a4e0-21abbd0856de",
        "body" : "```Python\r\n    def prefill_form(self, form, pk):\r\n        \"\"\"Prefill the form.\"\"\"\r\n        try:\r\n            extra = form.data.get('extra')\r\n            if extra is None:\r\n                extra_dictionary = {}\r\n            else:\r\n                extra_dictionary = json.loads(extra)\r\n        except JSONDecodeError:\r\n            extra_dictionary = {}\r\n        if not isinstance(extra_dictionary, dict):\r\n            logging.warning('extra field for %s is not a dictionary', form.data.get('conn_id', '<unknown>'))\r\n            return\r\n        for field in self.extra_fields:\r\n            value = extra_dictionary.get(field, '')\r\n            if value:  # !! This only adds data for the form.field if it previously exists in the extra\r\n                field = getattr(form, field)\r\n                field.data = value\r\n```\r\n-> could it be that hence, the `form.data` does not contain the keys for the extra widgets?\r\n\r\nGenerally, shouldnt `process_form` and `prefill_form` be analogous? From `prefill_form`, I could imagine something along those lines:\r\n\r\n```Python\r\n    def process_form(self, form, is_created):\r\n        \"\"\"Process form data.\"\"\"\r\n        conn_type = form.data['conn_type']\r\n        extra = {\r\n            key: getattr(form, key).data\r\n            for key in self.extra_fields\r\n            if hasattr(form, key) and key.startswith(f\"extra__{conn_type}__\") and getattr(form, key).data\r\n        }\r\n        if extra.keys():\r\n            form.extra.data = json.dumps(extra)\r\n```",
        "createdAt" : "2021-01-12T23:35:31Z",
        "updatedAt" : "2021-01-12T23:38:36Z",
        "lastEditedBy" : "59084487-c961-42ea-a4e0-21abbd0856de",
        "tags" : [
        ]
      },
      {
        "id" : "0386ce2a-3fdf-48a0-ab60-2a2cb19b3696",
        "parentId" : "2f64d44d-18b7-4fbf-9482-518fa9428b94",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Nope. That looks ok. Keys in form.data will be there is there are some fields added and you entered some value there (or it will be pre-fiiled) . The value will only be prefilled if the extra is already in the the connection and is not empty. The code looks good.",
        "createdAt" : "2021-01-13T00:06:15Z",
        "updatedAt" : "2021-01-13T00:06:15Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "77f0ca5682017ef50dbf90f84df75362e5da5c8b",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +2899,2903 @@            key: form.data[key]\n            for key in self.extra_fields\n            if key in form.data and key.startswith(f\"extra__{conn_type}__\")\n        }\n        if extra.keys():"
  }
]