[
  {
    "id" : "ecde3a63-42e0-42a6-8f56-46da2f4aa190",
    "prId" : 948,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "This is the actual fix, the rest is just search and replace\n",
        "createdAt" : "2016-02-03T18:25:17Z",
        "updatedAt" : "2016-02-03T18:25:17Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "0d5cb747-763e-4e4e-b745-ce359828d442",
        "parentId" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "Cool. I can help test it once you merge it, but looks good to the eye!\n",
        "createdAt" : "2016-02-03T21:03:52Z",
        "updatedAt" : "2016-02-03T21:03:52Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      },
      {
        "id" : "fdc9354f-1aa6-4d54-9fed-f81ba2a090ce",
        "parentId" : "240afa8d-392a-4d23-af52-ed4fa2f09f71",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "This fix addresses the problem raised by the reporter in https://github.com/airbnb/airflow/issues/920, but I've raised some concerns about how we are managing configuration in that issue, which we can fix by providing an easy way to inspect a unified view of the winning configuration in one place. \n",
        "createdAt" : "2016-02-03T21:17:37Z",
        "updatedAt" : "2016-02-03T21:17:37Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5ed58c112f447276627e6484b6dab60d6bfc65a",
    "line" : 127,
    "diffHunk" : "@@ -1,1 +2100,2104 @@    @classmethod\n    def alert_fernet_key(cls):\n        return conf.get('core', 'fernet_key') is None\n\n    @classmethod"
  },
  {
    "id" : "7510ccf1-b48a-41ef-9cfb-29ac5f73c632",
    "prId" : 1504,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9a0da3d-0fca-4692-a33b-3dd221a50d5e",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "the current working directory may not be the one you think it is. I'd use something like `os.path.join(settings.AIRFLOW_HOME, 'git_version')`\n",
        "createdAt" : "2016-05-19T15:28:09Z",
        "updatedAt" : "2016-05-19T15:28:09Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "7dbbd8e7-66d0-40fd-97f5-ce7527487b55",
        "parentId" : "a9a0da3d-0fca-4692-a33b-3dd221a50d5e",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "Done, though I am using os.path.join(*[settings.AIRFLOW_HOME, 'airflow', 'git_version']) here and in setup.py\n",
        "createdAt" : "2016-05-19T18:06:29Z",
        "updatedAt" : "2016-05-19T18:06:29Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d32c174f34132bf79abbef6a397a07f20bf5ecd",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +2308,2312 @@        git_version = None\n        try:\n            with open(\"airflow/git_version\") as f:\n                git_version = f.readline()\n        except Exception as e:"
  },
  {
    "id" : "91ae1db7-c20a-40b2-afaf-9a9254a12f9e",
    "prId" : 1523,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99a5ceb2-62af-4cd9-bb83-c97da90d4dd8",
        "parentId" : null,
        "authorId" : "366b1763-372e-4924-9c92-2ea8968443bd",
        "body" : "Curious about this. Do you guys run with AIRFLOW_HOME containing the entire AIRFLOW code base? We `pip install` airflow, and AIRFLOW_HOME points to a separate directory that just has airflow.cfg, dags dir, etc. I'm not sure that this would work for us, since `git_version` would be under the Python package dir, not AIRFLOW_HOME.\n",
        "createdAt" : "2016-05-19T18:56:26Z",
        "updatedAt" : "2016-05-19T19:25:53Z",
        "lastEditedBy" : "366b1763-372e-4924-9c92-2ea8968443bd",
        "tags" : [
        ]
      },
      {
        "id" : "18adbfe8-d242-4998-a199-6c064cfb677d",
        "parentId" : "99a5ceb2-62af-4cd9-bb83-c97da90d4dd8",
        "authorId" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "body" : "We will need to iterate on this as we learn more about how different companies install. This feature could be the forcing function.\n",
        "createdAt" : "2016-05-19T22:22:21Z",
        "updatedAt" : "2016-05-19T22:22:21Z",
        "lastEditedBy" : "92e402fb-479e-4b08-88f2-3b82c356ecc3",
        "tags" : [
        ]
      }
    ],
    "commit" : "aedb667d50e512655a590ec2af03504947dd9acb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2308,2312 @@        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME, 'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:"
  },
  {
    "id" : "80372cc6-2f66-4fbf-b1d8-d2dedfdaa2df",
    "prId" : 4368,
    "prUrl" : "https://github.com/apache/airflow/pull/4368#pullrequestreview-187873400",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89b7e136-a514-407e-a79d-9a77dfdb9e9f",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Maybe give this a bit more meaningful name? Something like `dag_state_stats`.",
        "createdAt" : "2018-12-26T09:54:52Z",
        "updatedAt" : "2018-12-26T20:52:20Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "78fd35d4-b829-4fb9-9209-40addcf432ef",
        "parentId" : "89b7e136-a514-407e-a79d-9a77dfdb9e9f",
        "authorId" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "body" : "üëç ",
        "createdAt" : "2018-12-26T10:38:08Z",
        "updatedAt" : "2018-12-26T20:52:20Z",
        "lastEditedBy" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "tags" : [
        ]
      }
    ],
    "commit" : "4db22b18a8f323bbb01b309b457c8fb5b3ca7a4c",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +557,561 @@        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state)).group_by(dr.dag_id, dr.state)\n\n        data = {}\n        for (dag_id, ) in dag_ids:\n            data[dag_id] = {}"
  },
  {
    "id" : "d8d15d59-451c-47ec-8836-3131d5bfbbbf",
    "prId" : 4401,
    "prUrl" : "https://github.com/apache/airflow/pull/4401#pullrequestreview-190373846",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f8d361d-b5e7-4298-9399-d2aa0a5d91b6",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "thanks. I go back and check https://github.com/apache/airflow/blob/master/airflow/models/__init__.py#L3560 which we define active_run to only running state. Initially, I thought scheduled would be one of them as well.",
        "createdAt" : "2019-01-08T18:11:43Z",
        "updatedAt" : "2019-01-08T18:11:43Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "740067ba14e5c086a254eefcb871ff391e888535",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +685,689 @@        active_runs = models.DagRun.find(\n            dag_id=dag.dag_id,\n            state=State.RUNNING,\n            external_trigger=False,\n            session=session"
  },
  {
    "id" : "fb5369bc-3414-47ed-bc06-604f879b4e27",
    "prId" : 4492,
    "prUrl" : "https://github.com/apache/airflow/pull/4492#pullrequestreview-193103618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I never was happy with this whole next_try_number hack - I should find time to have one row per try instead\r\nof a row per TI that gets altered.",
        "createdAt" : "2019-01-14T10:01:36Z",
        "updatedAt" : "2019-01-14T10:01:36Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "b4ab59ec-5647-46b7-b5b8-985b5c78e2a3",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "fa4e8b53-4987-4d88-99c9-e25f26d1515b",
        "body" : "@ashb I'd like that as well! Is there an issue for that work?",
        "createdAt" : "2019-01-15T14:51:29Z",
        "updatedAt" : "2019-01-15T14:51:29Z",
        "lastEditedBy" : "fa4e8b53-4987-4d88-99c9-e25f26d1515b",
        "tags" : [
        ]
      },
      {
        "id" : "2c9883a1-0bb5-4e67-ae2f-39103b82db26",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I don't think so. We'd need to work out how to do the migration so that viewing old tasks still works.\r\n\r\nIf you create a Jira ticket we can discuss some of the details on there.",
        "createdAt" : "2019-01-15T21:17:00Z",
        "updatedAt" : "2019-01-15T21:17:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "86034769-55a2-4c80-8f17-7e3e4e99d4b6",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "body" : "There is already the `task_fail` table which has one row per try. But only in case the task failed and is retried. However when a task is cleared (via UI) then there is no indication why there are more tries. ",
        "createdAt" : "2019-01-15T23:03:53Z",
        "updatedAt" : "2019-01-15T23:03:53Z",
        "lastEditedBy" : "44a4606a-9224-404a-87fd-9a2417fd2610",
        "tags" : [
        ]
      },
      {
        "id" : "e496ec23-0eed-40ed-bab0-f1bae013a1cd",
        "parentId" : "cbde251d-48ae-4e79-9fc9-24e2708d7d3a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Another thing I would like to remove: \"clear\"ing tasks as it deletes history :) Instead I would like a \"retry\" button in the UI and ending up with \"Attempt 3 of 2\" sort of thing.\r\n\r\nThe other advantage of having each try/attempt being a row is that we could then store the URL of the log against that row, to have old logs still be readable even after a future change to Airflow's logging pattern. (Both 1.9 and 1.10 made logs from previous versions no-longer-readable in the UI.)",
        "createdAt" : "2019-01-16T12:07:52Z",
        "updatedAt" : "2019-01-16T12:07:53Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e87a7c0153bd0a0afe613584a42e81c850e8365",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +872,876 @@        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number"
  },
  {
    "id" : "3fe23184-4880-463d-92ab-f5774621280e",
    "prId" : 4502,
    "prUrl" : "https://github.com/apache/airflow/pull/4502#pullrequestreview-194191862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5daa5106-5e8b-4513-8af4-6e6426bda634",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Lol so much easier :D",
        "createdAt" : "2019-01-18T16:59:54Z",
        "updatedAt" : "2019-01-18T17:00:32Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f62097fc4d635e7cf7f2b0573159a367b7fde0e",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +1737,1741 @@        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED))\n\n        tasks = []"
  },
  {
    "id" : "115e3935-9300-47d5-bfc6-28ebc15ca098",
    "prId" : 4597,
    "prUrl" : "https://github.com/apache/airflow/pull/4597#pullrequestreview-196814172",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29acd2b1-351f-466b-94b5-c934bf911e15",
        "parentId" : null,
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "@astahlman , since you are at this function, maybe we should consider add a check and see whether the user has permission to do refresh_all view.\r\n\r\nThe AirflowSecurityManager provides a way to check whether the user's role(https://github.com/apache/airflow/blob/master/airflow/www/security.py#L283). But we could do it in a different pr.",
        "createdAt" : "2019-01-27T06:49:09Z",
        "updatedAt" : "2019-01-27T16:09:47Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5cdec70adae317e90497e30606086184d453410d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1690,1694 @@        for dag_id in dagbag.dags:\n            # sync permissions for all dags\n            appbuilder.sm.sync_perm_for_dag(dag_id)\n        flash(\"All DAGs are now up to date\")\n        return redirect('/')"
  },
  {
    "id" : "5b558510-2537-473a-bbe8-78b968d39537",
    "prId" : 4863,
    "prUrl" : "https://github.com/apache/airflow/pull/4863#pullrequestreview-211765017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32e3da71-2020-4d18-bb80-07fcf24378f4",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We've already got a `session` object in scope here.",
        "createdAt" : "2019-03-07T10:59:37Z",
        "updatedAt" : "2019-03-08T10:24:10Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "3a89e98d-bac4-41b8-afc3-c642f98604f4",
        "parentId" : "32e3da71-2020-4d18-bb80-07fcf24378f4",
        "authorId" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "body" : "not anymore, just did remove that",
        "createdAt" : "2019-03-07T12:55:48Z",
        "updatedAt" : "2019-03-08T10:24:10Z",
        "lastEditedBy" : "0706c3c0-d32f-4dda-aba2-181cb4e0f0e8",
        "tags" : [
        ]
      }
    ],
    "commit" : "3207bd2f8b66eb881dab4286365a53c31291009e",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +1186,1190 @@            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)"
  },
  {
    "id" : "dc1fb52c-f3f4-4300-bfc0-6dbb3cd2b3b1",
    "prId" : 5037,
    "prUrl" : "https://github.com/apache/airflow/pull/5037#pullrequestreview-256090337",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Does this mean `try_count` can at most be 2?",
        "createdAt" : "2019-05-14T23:34:40Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "83741537-b25c-492d-985f-ef8834224c9e",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "No, actually try_count was initialised out of the block. Now made the correction. ",
        "createdAt" : "2019-05-15T14:55:07Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "130d4d86-c319-4d2d-95cb-77d2f7f6f899",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "If `ti_fails` is not sorted this piece of logic won't work correct, will it? If it is sorted, you still need to reset `try_count`. Also can you elaborate the difference of the bar items we are adding here versus the items we were adding [here](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1744) please?",
        "createdAt" : "2019-05-17T22:16:44Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "5e08ce37-da29-48fa-9108-24a65457209e",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "1. ti_fails will always be in sorted order because of the nature of task_fail table having auto increment key. \r\n2. try_count is always reset as 1 in the starting of the for loop of ti_fails. But yeah thanks for catching this. I have to reset it once new failed task instance comes into the picture. \r\n3. gantt_bar_items appended against the tis metadata are having the state as success or running or final fail from task_instance table so having the try_number for the same only. It doesn't capture the all the failed instances. In case of failed tasks, entries go into task_fail table and we can't get the try number from there directly hence I am incrementing the try_count and appending the same against ti_fails metadata because of the nature of task_fail table.",
        "createdAt" : "2019-05-21T07:50:17Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "6b844f4d-0321-4c3f-b13b-d31e92d80812",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "1. I don't think having auto increment key has anything to do with the order of data returned. A quick search gave me [this](https://dba.stackexchange.com/questions/5774/why-is-ssms-inserting-new-rows-at-the-top-of-a-table-not-the-bottom/5775#5775https://dba.stackexchange.com/questions/5774/why-is-ssms-inserting-new-rows-at-the-top-of-a-table-not-the-bottom/5775#5775).\r\n3. Assuming appending twice will not create two row for the same task instance in the graph( please confirm this), we are showing total try count only if the task instance is in FAILED state. This can be quite confusing. We need to probably revisit and decide what exactly we want to display and at least make sure it is consistent between task instances in different states.",
        "createdAt" : "2019-05-23T21:24:17Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "7d2a9e09-4187-47a5-87ae-7828cc1baf9c",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "Answer to your questions -\r\n1. I understand the fact but that order is already maintained through this ordered [list](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1728)  keeping the gantt chart in mind. Anyhow metadata apart from try number is coming in sorted order.\r\nExample can be understood by the below use case -\r\n\r\nmysql> select * from task_fail as tf  where TF.task_id = 'get_op'  AND TF.execution_date = '2019-05-29 05:30:00.000000' AND TF.dag_id='example_http_operator1';\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| id | task_id | dag_id                 | execution_date             | start_date                 | end_date                   | duration |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n|  8 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:37:45.177828 | 2019-05-30 22:37:51.449197 |        6 |\r\n| 27 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:43:08.766188 | 2019-05-30 22:43:10.270735 |        2 |\r\n| 46 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:48:20.494280 | 2019-05-30 22:48:22.069887 |        2 |\r\n| 62 | get_op  | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:53:27.867508 | 2019-05-30 22:53:29.474945 |        2 |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n4 rows in set (0.00 sec)\r\n\r\nmysql> select * from task_fail as tf  where TF.task_id = 'post_op'  AND TF.execution_date = '2019-05-29 05:30:00.000000' AND TF.dag_id='example_http_operator1';\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| id | task_id | dag_id                 | execution_date             | start_date                 | end_date                   | duration |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n| 17 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:38:19.100704 | 2019-05-30 22:38:26.619226 |        8 |\r\n| 36 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:43:36.747317 | 2019-05-30 22:43:38.238442 |        1 |\r\n| 53 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:48:48.267570 | 2019-05-30 22:48:49.595367 |        1 |\r\n| 69 | post_op | example_http_operator1 | 2019-05-29 05:30:00.000000 | 2019-05-30 22:53:55.739041 | 2019-05-30 22:53:57.038769 |        1 |\r\n+----+---------+------------------------+----------------------------+----------------------------+----------------------------+----------+\r\n4 rows in set (0.00 sec)\r\nExplanation : list has been formed by taking each individual task like appending the above result. Please find the below screenshot to validate the same results -\r\n<img width=\"1560\" alt=\"Screen Shot 2019-05-31 at 12 24 37 AM\" src=\"https://user-images.githubusercontent.com/20847563/58656806-93a64500-833a-11e9-8df3-ab91d5ce1c65.png\">\r\n\r\n2. Yes, It is not appending twice. reasoning is same as above. All the metadata except try count is populated through the same logic. I have just added this only in both the gantt_bar_items. Above than that, I am showing the try count in every state. As task_fail doesn't have try number in it's table so I have made the logic to get the same and that's how try number is appended in gantt_bar_items of the failed tasks as well. \r\nMoreover, the conclusion is that we need to display try_count every-time user the Gantt UI of airflow irrespective of state and that is consistent across different states. \r\n",
        "createdAt" : "2019-05-30T19:00:58Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "bf2f41fb-18df-4d03-a09a-4942f928e808",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "1. Yes all task fails are grouped by task_id as we have only one ti for each task, missed this part earlier.  Tho we can still have wrong order of task fails. Result is that in the gantt chart, we can have a try with later start date appear on the left side of a try with earlier start date.\r\n2. Mb misunderstood the state there, didn't get that append will create a new column in the row. In this case, did we append the last try for failed tasks twice?( visually doesn't seem to create a problem tho)",
        "createdAt" : "2019-06-25T00:01:03Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "5a8b5925-ec5d-4dcf-b684-5d3e7402a4d1",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "body" : "Please find my answers -\r\n1. Start date is already coming in the correct order even with out introducing my changes. I have only added the try number in every column. So gantt chart will not have any case in which later start date appears on the left side as compare to earlier start date.\r\n2. Even in this, append is already creating the column twice with out introducing my changes and yes there is no problem with this as well. ",
        "createdAt" : "2019-06-26T14:16:52Z",
        "updatedAt" : "2019-06-26T14:18:19Z",
        "lastEditedBy" : "c1f7098b-8541-4270-af2c-b615763c584e",
        "tags" : [
        ]
      },
      {
        "id" : "da3b6d39-b087-4fd9-9948-17db4b0835af",
        "parentId" : "8d656a16-b601-4401-afac-efbb20cbf55e",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "The value of [ti_fails](https://github.com/apache/airflow/pull/5037/files#diff-948e87b4f8f644b3ad8c7950958df033R1728) is not guaranteed to be ordered but you don't have to include a fix in your PR as it is not newly introduced. I'll submit a new JIRA for it.",
        "createdAt" : "2019-06-30T20:48:39Z",
        "updatedAt" : "2019-06-30T20:48:48Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a7cf89e13707c23c9f6afb5868880e03580c1f5",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1750,1754 @@            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1"
  },
  {
    "id" : "75ae628f-8654-4ad4-8899-888529412e1a",
    "prId" : 5079,
    "prUrl" : "https://github.com/apache/airflow/pull/5079#pullrequestreview-243166032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Could you avoid/remove the import ordering/format changes? Having these in here makes it much harder to cherry-pick fixes back to the 1-10 release branch.",
        "createdAt" : "2019-05-28T16:06:01Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "c1f5d707-8a6d-4053-974b-9344181c7d12",
        "parentId" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "Roger that",
        "createdAt" : "2019-05-28T23:43:42Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      },
      {
        "id" : "cc7d0ed0-f486-4683-b668-5bf22e5b7bae",
        "parentId" : "b14a5ae8-1c71-459e-b745-9bc98e71b2c8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(And make it less likely to conflict too)",
        "createdAt" : "2019-05-29T10:18:56Z",
        "updatedAt" : "2019-08-13T00:04:27Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "b82718b2d8e5367219f602212d930685d957f12f",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +66,70 @@from airflow.www.forms import (ConnectionForm, DagRunForm, DateTimeForm,\n                               DateTimeWithNumRunsForm,\n                               DateTimeWithNumRunsWithDagRunsForm)\nfrom airflow.www.widgets import AirflowModelListWidget\n"
  },
  {
    "id" : "687e0803-063f-47eb-a72e-4a0d854fb338",
    "prId" : 5177,
    "prUrl" : "https://github.com/apache/airflow/pull/5177#pullrequestreview-236947928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa352889-be17-473d-bd62-f86bc05d86d4",
        "parentId" : null,
        "authorId" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "body" : "NIT: `if ti:`",
        "createdAt" : "2019-05-13T22:22:27Z",
        "updatedAt" : "2019-05-13T23:30:05Z",
        "lastEditedBy" : "a3c64a30-509c-4788-80d1-4f17cb3b5530",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f5c6009bdace52a9929b16b726926122a2492b2",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +556,560 @@\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)"
  },
  {
    "id" : "bbb573e8-718a-43d0-885d-96ff8fa2984d",
    "prId" : 5339,
    "prUrl" : "https://github.com/apache/airflow/pull/5339#pullrequestreview-243916741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe3ceed9-90ae-4784-90cf-05d02e120d79",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This should probably be `.isoformat()`? (or at least include seconds and MS)",
        "createdAt" : "2019-05-30T16:12:33Z",
        "updatedAt" : "2019-06-06T14:38:33Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "e9664a67-58a5-4134-8d35-f20c338f8b73",
        "parentId" : "fe3ceed9-90ae-4784-90cf-05d02e120d79",
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "That might make the UI look too crowded, and not sure if there is value to users to have this additional information. This PR maintains the same format as before in the non-async version: https://github.com/apache/airflow/pull/5339/files#diff-f38558559ea1b4c30ddf132b7f223cf9L111",
        "createdAt" : "2019-05-30T17:14:20Z",
        "updatedAt" : "2019-06-06T14:38:33Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "693e141cb1bace0b23883ec2ed6ee7bb7ab71abc",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +426,430 @@                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n"
  },
  {
    "id" : "d75359b1-123e-4548-9703-ce5c95793259",
    "prId" : 5525,
    "prUrl" : "https://github.com/apache/airflow/pull/5525#pullrequestreview-257570934",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f88e7e86-a03d-44af-84e8-101adb1ccc26",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Could we use `m.log_url` here?",
        "createdAt" : "2019-07-03T15:30:10Z",
        "updatedAt" : "2019-07-03T18:23:15Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "a837ec7e-d742-4488-a3d7-f401a1197b10",
        "parentId" : "f88e7e86-a03d-44af-84e8-101adb1ccc26",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "True.",
        "createdAt" : "2019-07-03T15:31:15Z",
        "updatedAt" : "2019-07-03T18:23:15Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d2a3ef58f629ef54c98879b34dadf7d269d2986",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +123,127 @@\ndef log_url_formatter(v, c, m, p):\n    url = url_for(\n        'airflow.log',\n        dag_id=m.dag_id,"
  },
  {
    "id" : "644fc6ed-1124-4bdc-849e-827be71de641",
    "prId" : 5527,
    "prUrl" : "https://github.com/apache/airflow/pull/5527#pullrequestreview-257943441",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7471288-5714-4fbd-af33-cee9a5fc3235",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "üëç  -> checked that numRetries  can be 0 as well",
        "createdAt" : "2019-07-04T09:52:06Z",
        "updatedAt" : "2019-07-04T09:53:01Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0326528da3669a3b79417f89421b12c4ada79659",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +3049,3053 @@            validators=[\n                validators.Optional(strip_whitespace=True),\n                validators.NumberRange(min=0),\n            ],\n        ),"
  },
  {
    "id" : "85231ceb-0b92-4980-ab02-2a15d07ad7d8",
    "prId" : 5527,
    "prUrl" : "https://github.com/apache/airflow/pull/5527#pullrequestreview-320170735",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ee66b1f-e12c-40d5-a43e-2671a39d93a6",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Does this need to change too ?\r\n\r\n```diff\r\n- 'extra__grpc__credentials_pem_file': StringField('Credential Keyfile Path'),\r\n+ 'extra__grpc__credential_pem_file': StringField('Credential Keyfile Path'),\r\n```",
        "createdAt" : "2019-11-20T18:09:53Z",
        "updatedAt" : "2019-11-20T18:09:54Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d166e6e1-7ffa-4dfb-a4e2-e44cda468945",
        "parentId" : "2ee66b1f-e12c-40d5-a43e-2671a39d93a6",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Ah. yes or the other side should be `extra__grpc__credentials_pem_file`.",
        "createdAt" : "2019-11-20T18:11:26Z",
        "updatedAt" : "2019-11-20T18:11:26Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "0326528da3669a3b79417f89421b12c4ada79659",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +3053,3057 @@        ),\n        'extra__grpc__auth_type': StringField('Grpc Auth Type'),\n        'extra__grpc__credentials_pem_file': StringField('Credential Keyfile Path'),\n        'extra__grpc__scopes': StringField('Scopes (comma separated)'),\n    }"
  },
  {
    "id" : "08040b99-982e-455f-ad55-53b367950c0e",
    "prId" : 6650,
    "prUrl" : "https://github.com/apache/airflow/pull/6650#pullrequestreview-322878664",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "```suggestion\r\n                if ti and dag:\r\n```",
        "createdAt" : "2019-11-25T15:54:25Z",
        "updatedAt" : "2019-11-25T15:58:50Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "a72a0bd0-5d31-4c5f-b56f-9e3cf9afb62c",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "so you can remove `if ti is not None:`",
        "createdAt" : "2019-11-25T15:54:44Z",
        "updatedAt" : "2019-11-25T15:58:51Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "0a227f71-b723-4b5e-8746-42015daf8084",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I am not sure. There may be a task instance without DAG or DAG without task. These are the correct cases. Please note that dag variable is None, when task is not found.  This is the most important thing in this change. If we have task instances, we are looking for DAG. If we find DAG, we are looking for a task, but if we don't find DAG, then we do nothing.",
        "createdAt" : "2019-11-25T21:53:45Z",
        "updatedAt" : "2019-11-25T21:55:04Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "b5900b91-7fe2-4289-9aa7-eb3210a96fe9",
        "parentId" : "8f27ef82-b4a1-4905-97b2-56651bac0f0a",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "I got it. üëç ",
        "createdAt" : "2019-11-26T10:36:45Z",
        "updatedAt" : "2019-11-26T10:36:45Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "35969fe35ca4532f97b53ad4c5d40ea3276edde1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +579,583 @@            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                if dag:\n                    ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':"
  },
  {
    "id" : "e872bf69-30dc-4c6c-872e-30906ada7de9",
    "prId" : 7251,
    "prUrl" : "https://github.com/apache/airflow/pull/7251#pullrequestreview-363294960",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Looks good -- only question is around if we need `unquote` here or not (I wouldn't have thought we do.)",
        "createdAt" : "2020-02-24T10:04:14Z",
        "updatedAt" : "2020-02-24T10:04:15Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "df64688a-f554-4168-9c69-7aa77ee5a6fb",
        "parentId" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "authorId" : "82aa078f-2a60-4ac5-95fc-0d69bea786b5",
        "body" : "So i just tested this locally https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams does URL encoding for us so we need the unquote. Its unlikely that a dag_id would have any special character but the owner field could potentially have anything.",
        "createdAt" : "2020-02-24T10:17:31Z",
        "updatedAt" : "2020-02-24T10:17:31Z",
        "lastEditedBy" : "82aa078f-2a60-4ac5-95fc-0d69bea786b5",
        "tags" : [
        ]
      },
      {
        "id" : "90c30dbb-17fc-48aa-818d-0cd37edbba97",
        "parentId" : "0569a734-fe2d-44a9-a4f1-c5d987cfbbf3",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I was surprised that `request.args` didn't unquote tbh. Quoting on input is 100% the behaviour we want.",
        "createdAt" : "2020-02-24T10:37:45Z",
        "updatedAt" : "2020-02-24T10:37:45Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e47b6114c68559818500c8b09e8d7913c179c5b",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +2721,2725 @@    @expose('/autocomplete')\n    def autocomplete(self, session=None):\n        query = unquote(request.args.get('query', ''))\n\n        if not query:"
  },
  {
    "id" : "98b2ab69-5130-4b23-9222-dad76449c7fc",
    "prId" : 7492,
    "prUrl" : "https://github.com/apache/airflow/pull/7492#pullrequestreview-364480367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Does this change the default/current view behaviour?",
        "createdAt" : "2020-02-24T12:42:05Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "edbd017c-4e0d-4aa7-9a93-7b6ddb82cf45",
        "parentId" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "It shouldn't, at least for the DAGs that I have tried so far, the rendering behavior remains unchanged and trees are expanded properly. Do you have specific cases that you want to test for?",
        "createdAt" : "2020-02-24T16:10:40Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "1865a8d3-e895-4464-ba72-7578e2a19a46",
        "parentId" : "bbb1d7b2-69d8-48f5-9f50-e140eb6e799a",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Nope, what you've done sounds good.",
        "createdAt" : "2020-02-25T21:59:27Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "f57038e24b0cf0663fe5a8fb8f06638ed8fd04cf",
    "line" : 160,
    "diffHunk" : "@@ -1,1 +1444,1448 @@                # repeated nodes are collapsed by default.\n                if task.task_id not in expanded:\n                    children_key = 'children'\n                    expanded.add(task.task_id)\n                else:"
  },
  {
    "id" : "124902f0-92f6-451e-b362-9745c17338cc",
    "prId" : 7492,
    "prUrl" : "https://github.com/apache/airflow/pull/7492#pullrequestreview-365674497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "How much does it reduce it by? Is stripping of _all_ ms noticable? (Could we perhaps limit to 3 or 6 sig. fig.?)",
        "createdAt" : "2020-02-25T22:12:31Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "fc38c3e6-5142-4d94-823d-8e50e28f1766",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "not much for task node since we don't have too many of them, that's why i didn't add the rounding in the first place here. It did make a big difference for task instance node since we have lots of them, IIRC, probably around 10-20% size reduction.\r\n\r\nI can change it to round to 3 sig. fig. everywhere to see what the performance implication would be.",
        "createdAt" : "2020-02-25T22:18:04Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "2c695134-4774-46b3-a811-f07d7a207514",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "@ashb round to 3 sig. fig. increases the overall payload size by 15%. The question now is do we care about millisecond accuracy for task start/end time enough to take this 15% performance hit?\r\n\r\nSo far, I found second granularity has been good enough for us, but I might be missing other use-cases.",
        "createdAt" : "2020-02-25T22:43:50Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "b0055e93-be50-4916-827a-f9509f3ce5f3",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Probably not needed.\n\nIs it worth making it a config option do you think?",
        "createdAt" : "2020-02-25T23:33:21Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "6ec0d10f-cade-4e15-8363-802392141aa6",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "This code path has a very hot function call loop that's very sensitive to if statements. For the large DAG that we have, adding one extra if statement increases the response time by more than 400ms. That's why `simplify reduce_nodes() logic, remove unnecessary if statements` is in the optimization list :)\r\n\r\nThat and based on the understanding that we are rewriting Airflow web into a proper SPA, I think it's best not to introduce a config for this change. I would prefer us giving round to second a try and come back to add more sig. fig. or add a config later on if any real use-case comes up. It's better to not engineer solutions when we don't have a good use-case in mind.\r\n\r\nIf you are really concerned about the precision, we can perhaps change it to round to 1 sig. fig. for a 7% performance hit. I can't really think of a case where knowing 0.01 second difference of runtime is important.\r\n\r\n",
        "createdAt" : "2020-02-27T01:40:58Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "c08eaaf2-2237-4baa-9b68-ed32a2c5510f",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Good reasoning. I'll copy some/most of this in to the commit message for future-proofing.",
        "createdAt" : "2020-02-27T13:20:55Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "052cf8f4-6709-4658-8e28-5f15b12ec48a",
        "parentId" : "f72e225d-0149-4ef7-9bf7-1039f655d576",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Leaving this unresolved as a reminder to myself.",
        "createdAt" : "2020-02-27T13:23:22Z",
        "updatedAt" : "2020-02-28T16:00:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "f57038e24b0cf0663fe5a8fb8f06638ed8fd04cf",
    "line" : 169,
    "diffHunk" : "@@ -1,1 +1453,1457 @@                node['depends_on_past'] = task.depends_on_past\n            if task.start_date:\n                # round to seconds to reduce payload size\n                node['start_ts'] = int(task.start_date.timestamp())\n                if task.end_date:"
  }
]