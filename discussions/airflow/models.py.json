[
  {
    "id" : "608a72b6-e87f-44d9-b440-11ab3573d971",
    "prId" : 83,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "94170efe-6be8-409c-afc0-730c0b7af575",
        "parentId" : null,
        "authorId" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "body" : "What is an example of the second inequality being strict?\n",
        "createdAt" : "2015-06-26T19:07:45Z",
        "updatedAt" : "2015-06-26T19:07:45Z",
        "lastEditedBy" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "tags" : [
        ]
      },
      {
        "id" : "1af0cff8-3034-431f-aed0-e7c16bc71085",
        "parentId" : "94170efe-6be8-409c-afc0-730c0b7af575",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "if should actually read  `if successes < done == len(task._upstream_list):` but I didn't know whether it would parse. But yeah, it's basically skipping tasks that have one or many `failed` or `upstream_failed` upstream and they may have other succeeded tasks, but they have to be all finished processing.\n",
        "createdAt" : "2015-06-26T19:46:36Z",
        "updatedAt" : "2015-06-26T19:46:36Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "447bb088b87c9ad5d9f5747e95ba011f3e29982c",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +659,663 @@            )\n            successes, done  = qry[0]\n            if successes < done >= len(task._upstream_list):\n                self.state = State.UPSTREAM_FAILED\n                self.start_date = datetime.now()"
  },
  {
    "id" : "14e08a15-92bc-4214-b00c-8ca32c9783bf",
    "prId" : 147,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1910225e-b83a-406d-8fa7-851a5cedcfb3",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "it's not super explicit here that list is used as a way to cast an iterable. btw:\n\n```\n>>> list('abc')\n['a', 'b', 'c']\n```\n\nwhat about, instead of the try block:\n\n```\nif not isinstance(task_list, (tuple, list):\n    task_list = [task_list]\n```\n",
        "createdAt" : "2015-07-17T19:11:44Z",
        "updatedAt" : "2015-07-17T19:11:44Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "52b33797-390b-404d-9dbe-6ef4e407494c",
        "parentId" : "1910225e-b83a-406d-8fa7-851a5cedcfb3",
        "authorId" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "body" : "I can change it to that if you prefer, however it doesn't allow you to have custom classes where **iter** is defined to be passed in here. Would a comment alleviate your concerns?\n",
        "createdAt" : "2015-07-17T19:18:28Z",
        "updatedAt" : "2015-07-17T19:18:28Z",
        "lastEditedBy" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "42d99d7dadb46ac0f4ad8cd15631e5d012aa6171",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +1369,1373 @@    def _set_relatives(self, task_or_task_list, upstream=False):\n        try:\n            task_list = list(task_or_task_list)\n        except TypeError:\n            task_list = [task_or_task_list]"
  },
  {
    "id" : "e6afa9f7-3d3f-43e1-a3d9-e3677abea352",
    "prId" : 151,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "parentId" : null,
        "authorId" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "body" : "would it be possible to make this a list of callbacks?\n",
        "createdAt" : "2015-07-17T18:16:55Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "tags" : [
        ]
      },
      {
        "id" : "79e7f618-8a54-4719-be42-c5cefb99a21e",
        "parentId" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "authorId" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "body" : "If we are going that route, maybe a dictionary would make more sense ? \n\n```\n{\"on_success\": callback_callable, \"on_failure\": notification_callback, \"on_retry\": email_callback}\n```\n\nBut I think it's makes the interface less clear.\n",
        "createdAt" : "2015-07-17T18:22:12Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "tags" : [
        ]
      },
      {
        "id" : "300f21b3-8de0-42c7-818b-e3c4796d22b4",
        "parentId" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "authorId" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "body" : "oh... I meant, instead of passing a single callback for on_failure, pass a list, so you can do multiple things if a task fails without wrapping wrapping callbacks inside themselves.\n",
        "createdAt" : "2015-07-17T18:37:00Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "tags" : [
        ]
      },
      {
        "id" : "8a0d01c4-91bf-40ed-9dc2-28e995043136",
        "parentId" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "authorId" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "body" : "Sorry, I misunderstood. Sounds reasonable to me.\n",
        "createdAt" : "2015-07-17T18:47:11Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "tags" : [
        ]
      },
      {
        "id" : "4aaef6db-9ec0-4d16-ab54-bf5ae1cc0652",
        "parentId" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "I think it muddies the API to expect a list or either a callable or a list of callable and for the Airflow to have to deal with etheir using type inspection. If you need to call multiple things, write a function that calls multiple things, or wrap it in a lambda that calls something like this\n\n```\ndef calls(funcs, *args, **args):\n    return [f(*args, **args) for f in funcs]\n```\n",
        "createdAt" : "2015-07-17T18:59:16Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "00d0b155-0a71-421c-8505-004bbcdaf60b",
        "parentId" : "9b23d8e7-7feb-4482-b725-26610788049d",
        "authorId" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "body" : "that is fine for me. I can make it work either way. thanks!\n",
        "createdAt" : "2015-07-17T22:15:58Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "4009a9e6b91afce2d8eedde1ed53b3b60d0d8e12",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +1152,1156 @@        self.on_failure_callback = on_failure_callback\n        self.on_success_callback = on_success_callback\n        self.on_retry_callback = on_retry_callback\n        if isinstance(retry_delay, timedelta):\n            self.retry_delay = retry_delay"
  },
  {
    "id" : "af7b867c-021e-4bee-8c7a-cb10208f6e90",
    "prId" : 151,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "749e289e-c355-4b66-8d65-b930a50a8442",
        "parentId" : null,
        "authorId" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "body" : "it might be nice to also always email when the email is set.\n\nWould it be possible to have callbacks be a list and always seed the list with the email callback?\n",
        "createdAt" : "2015-07-17T18:20:36Z",
        "updatedAt" : "2015-07-18T01:10:16Z",
        "lastEditedBy" : "1e336686-2e66-4dfa-a3d5-95009d8e01ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "4009a9e6b91afce2d8eedde1ed53b3b60d0d8e12",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +881,885 @@\n        # Handling callbacks pessimistically\n        try:\n            if self.state == State.UP_FOR_RETRY and task.on_retry_callback:\n                task.on_retry_callback(context)"
  },
  {
    "id" : "5cc8f157-443e-4611-b229-9a918abebcf9",
    "prId" : 169,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58711bf3-58a1-4f83-b89b-6f19e3e76bb8",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "This line right here\n",
        "createdAt" : "2015-07-23T06:53:24Z",
        "updatedAt" : "2015-07-23T06:53:24Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eeead06c72c638ad3f0451fbd727abcda2b1c46",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +936,940 @@            'ti': self,\n            'task_instance_key_str': ti_key_str,\n            'conf': conf,\n        }\n"
  },
  {
    "id" : "6b3ca3de-e517-497e-a684-162f17c874f9",
    "prId" : 254,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a08fd82d-bdb5-4985-bfd6-cfa29dccd08a",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "I'm surprised that `urlparse` doens't urldecode... I guess hostname is not expected to have slashes in it...\n",
        "createdAt" : "2015-08-31T20:56:51Z",
        "updatedAt" : "2015-08-31T22:37:26Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bc95e230c3740aa3d601a17670b72c23a1dcfa4",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +337,341 @@        temp_uri = urlparse(uri)\n        hostname = temp_uri.hostname or ''\n        if '%2f' in hostname:\n            hostname = hostname.replace('%2f', '/').replace('%2F', '/')\n        self.host = hostname"
  },
  {
    "id" : "24705773-e4f2-4600-a421-a645f67d887c",
    "prId" : 260,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "906106cc-26ba-4a9e-b2ac-ab89c0a0652b",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "the `@provide_session` decorator will commit for you if no external session is passed to the function, if a session is passed, it assumes the caller is in charge of the transaction and doesn't want the function to commit on its behalf. \n",
        "createdAt" : "2015-08-18T16:32:44Z",
        "updatedAt" : "2015-08-20T17:31:05Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "123fbd80-9a48-4dfc-b7eb-5d13f616c054",
        "parentId" : "906106cc-26ba-4a9e-b2ac-ab89c0a0652b",
        "authorId" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "body" : "got it -- that's great. I think I copied all this boilerplate from somewhere to be safe. I'll pull it out.\n",
        "createdAt" : "2015-08-19T01:52:32Z",
        "updatedAt" : "2015-08-20T17:31:05Z",
        "lastEditedBy" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "tags" : [
        ]
      },
      {
        "id" : "5da60613-4366-4fa3-8b48-13e4f5928e04",
        "parentId" : "906106cc-26ba-4a9e-b2ac-ab89c0a0652b",
        "authorId" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "body" : "Actually... looking at `@provide_session`, it calls `expunge_all()` _after_ the function runs (line 279 of `utils.py`), meaning the XCom is removed from the session before `commit` is called. I think that's why I needed to add these lines explicitly. It looks like all the other uses of `@provide_session` are for getting data, not setting it, so this hasn't been an issue in the past.\n",
        "createdAt" : "2015-08-19T02:46:12Z",
        "updatedAt" : "2015-08-20T17:31:05Z",
        "lastEditedBy" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0235a9bfc2a37e98f769228a2e50bc4dc8841e6b",
    "line" : null,
    "diffHunk" : "@@ -1,1 +2190,2194 @@            dag_id=dag_id))\n\n        session.commit()\n\n    @classmethod"
  },
  {
    "id" : "b22cfe63-87b4-4188-a009-774bd58a25dd",
    "prId" : 260,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "712aa793-65a9-45c3-b0c4-12cda8e27c86",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "As much as I like pandas dataframe, I still think that returning an array of expunged XCom objects would be more comprehensive. The XCom object has all the metadata and the value so it's ideal. \n\nAlso maybe there's a need for distinct methods to `get` one or `get_many`, and matching with `pull` and `pull_many`\n",
        "createdAt" : "2015-08-18T16:41:59Z",
        "updatedAt" : "2015-08-20T17:31:05Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "a41a8c87-dbdf-426a-b9b8-d1346c3aebc4",
        "parentId" : "712aa793-65a9-45c3-b0c4-12cda8e27c86",
        "authorId" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "body" : "Ok. the DataFrame was more useful in the previous (more complicated) version, where there were more fields to query. Let's drop it. And while we're at it, maybe we drop the whole `limit` concept entirely? It was great for debugging but I think it just confuses things -- I'm not sure what the real world use case would be. If users really want the XCom objects instead of values (though I'm not sure they will), then maybe a `return_xcom=True` argument could be added.\n\nSo there are two return types:\n\n``` python\nti.xcom_pull(key=optional, task_id=t) # returns a value\nti.xcom_pull(key=optional, task_id=[t1, t2, t3]) # returns a list of 3 values\n```\n",
        "createdAt" : "2015-08-19T02:02:20Z",
        "updatedAt" : "2015-08-20T17:31:05Z",
        "lastEditedBy" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0235a9bfc2a37e98f769228a2e50bc4dc8841e6b",
    "line" : null,
    "diffHunk" : "@@ -1,1 +2222,2226 @@            .order_by(cls.execution_date.desc(), cls.timestamp.desc())\n            .limit(1))\n\n        result = query.first()\n        if result:"
  },
  {
    "id" : "e6cb46ad-58e5-4f96-9db7-ac96b5b1b808",
    "prId" : 364,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2d31ae8-1541-4ea9-b1f5-e13cd10c61e7",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "nit: use double quotes for sentences so that you don't have to escape apostrophes\n",
        "createdAt" : "2015-09-07T23:25:18Z",
        "updatedAt" : "2015-09-07T23:25:18Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "b67a1198-6b49-4cc0-8fcc-9aa8354327f4",
        "parentId" : "d2d31ae8-1541-4ea9-b1f5-e13cd10c61e7",
        "authorId" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "body" : "will do!\n",
        "createdAt" : "2015-09-08T22:36:35Z",
        "updatedAt" : "2015-09-08T22:36:35Z",
        "lastEditedBy" : "0a40f9fd-4a0a-426e-b6f5-f97a4905eb99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fe611498ccc837e18c227a4276c14905f007953",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +817,821 @@        )\n        if not pool:\n            raise ValueError('Task specified a pool ({}) but the pool '\n                             'doesn\\'t exist!').format(self.task.pool)\n        open_slots = pool.open_slots(session=session)"
  },
  {
    "id" : "7c11a311-4e7b-4b68-a4b1-83a80ce737e5",
    "prId" : 712,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cc45871-e569-42c7-b6c2-0cce51ce0bde",
        "parentId" : null,
        "authorId" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "body" : "Shouldn't the base table still be the job? Or I guess in a way I feel that we need to kill the full outer join of this : \nCase 1) Zombie task instance TI.state == State.Running and LJ.State != State.Running and \n         2) LJ.State == State.Running and TI.state != State.Running.\n\nStill need to think about some of this.\n",
        "createdAt" : "2015-12-02T07:46:09Z",
        "updatedAt" : "2015-12-11T01:43:39Z",
        "lastEditedBy" : "0ff67aea-e186-487e-bd0f-83d1c809bd31",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a00f85c9467d5183878028e75485b843cb7aeba",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +228,232 @@            \"Failing jobs without heartbeat after {}\".format(limit_dttm))\n\n        tis = (\n            session.query(TI)\n            .join(LJ)"
  },
  {
    "id" : "1afbf258-5d30-40f3-af2e-a103f5bb2c0d",
    "prId" : 958,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81f34af0-94b0-41b6-8fa2-26bc071899b3",
        "parentId" : null,
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "this line isn't needed anymore...\n",
        "createdAt" : "2016-02-05T23:56:35Z",
        "updatedAt" : "2016-02-05T23:56:35Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbed0b23506cc4dcb5f31089686b58dda57474d3",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +985,989 @@                                                tot_tries)\n            self.try_number += 1\n            msg = msg.format(**locals())\n            logging.info(HR + msg + HR)\n            self.start_date = datetime.now()"
  },
  {
    "id" : "67fa3063-35ba-4928-96b7-8dbd35bb9253",
    "prId" : 976,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a054b14-0fe2-4f07-bdf7-032578b60adc",
        "parentId" : null,
        "authorId" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "body" : "Looks better. is it possible at this stage to get even more information e.g. which of (possibly many) dependencies failed.\nBTW. I got confused - isn't it upstream task that is a dependency here, not a downstream one?\n",
        "createdAt" : "2016-02-09T08:57:17Z",
        "updatedAt" : "2016-02-09T08:57:17Z",
        "lastEditedBy" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "tags" : [
        ]
      },
      {
        "id" : "3a6011d7-fa56-49e5-870c-96da82556eb7",
        "parentId" : "5a054b14-0fe2-4f07-bdf7-032578b60adc",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "Downstream jobs run after, so they depend on upstream jobs.\n",
        "createdAt" : "2016-02-09T19:37:24Z",
        "updatedAt" : "2016-02-09T19:37:24Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "48cb817c-49e1-4f8f-a61a-12667d6cdf51",
        "parentId" : "5a054b14-0fe2-4f07-bdf7-032578b60adc",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "wait_for_downstream is a very specific flag it's documented in the docs.\n",
        "createdAt" : "2016-02-09T19:38:00Z",
        "updatedAt" : "2016-02-09T19:38:00Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      },
      {
        "id" : "013b1cf9-536e-4032-923b-e6f50fa5ee45",
        "parentId" : "5a054b14-0fe2-4f07-bdf7-032578b60adc",
        "authorId" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "body" : "yes, I get it now, 'wait_for_downstream' could be more precisely called 'wait_for_past_downstream'.\n",
        "createdAt" : "2016-02-10T20:46:04Z",
        "updatedAt" : "2016-02-10T20:46:04Z",
        "lastEditedBy" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "tags" : [
        ]
      },
      {
        "id" : "aa735709-14cd-4b56-8162-0e2dc41534a3",
        "parentId" : "5a054b14-0fe2-4f07-bdf7-032578b60adc",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "right, I added the feature early on and can't change the API easily anymore...\n",
        "createdAt" : "2016-02-10T21:11:42Z",
        "updatedAt" : "2016-02-10T21:11:42Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9101ea043b53b88722f2da70791761d4133af33c",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +842,846 @@                    previous_ti.are_dependents_done(session):\n                if verbose:\n                    logging.warning(\"wait_for_downstream not satisfied\")\n                return False\n"
  },
  {
    "id" : "6ab08f25-5588-4631-a1ea-966e3f252a56",
    "prId" : 976,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41f4cc9b-ab23-418a-8b51-95e3e57710b3",
        "parentId" : null,
        "authorId" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "body" : "here in task._upstream_list we have a list of upstream dependencies, but if some is not satisfied we would still just see e.g. 'Trigger rule `ALL_SUCCESS` not satisfied' while airflow user would more likely be interested in the list of upstream tasks missing. This does not matter for ONE_SUCCESS and ONE_FAILED but for ALL_\\* it does.\nGiven the way the query is done now (using just sum of tasks in a specific state) it is not that straightforward to print it all out here, but you could consider that at some point.\n",
        "createdAt" : "2016-02-10T20:50:12Z",
        "updatedAt" : "2016-02-10T20:50:12Z",
        "lastEditedBy" : "c96e8c12-7762-41e2-aa7e-96b2c1ddbcd1",
        "tags" : [
        ]
      },
      {
        "id" : "318cd684-98bb-40ce-88d4-ba7f2e6415ee",
        "parentId" : "41f4cc9b-ab23-418a-8b51-95e3e57710b3",
        "authorId" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "body" : "Right, it'd be nice to show the details but would cost. This query above is optimize for a single scan and return the minimum amount of info to be able to do the job...\n\nI'm planning to get in this area of the code and change things a bit eventually to power a UI page detailing the dependencies and explaining which ones are met and which ones aren't. This would answer clearly the most common question \"Why isn't my task running?\"\n",
        "createdAt" : "2016-02-10T21:14:21Z",
        "updatedAt" : "2016-02-10T21:14:21Z",
        "lastEditedBy" : "0624866b-ba3a-41a3-abab-e487a9cfb78c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9101ea043b53b88722f2da70791761d4133af33c",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +907,911 @@            session.close()\n        if verbose:\n            logging.warning(\"Trigger rule `{}` not satisfied\".format(tr))\n        return False\n"
  },
  {
    "id" : "c2e13176-86ec-4e58-be5f-c6a0c59d5321",
    "prId" : 1378,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6cb7e17-235a-4341-b39b-4b942c724b19",
        "parentId" : null,
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "document lock_for_update\n",
        "createdAt" : "2016-05-09T18:38:57Z",
        "updatedAt" : "2016-05-09T21:19:15Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "c1aa93f1a7c9dbe88889b78b541b3abe05ded081",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +818,822 @@\n    @provide_session\n    def refresh_from_db(self, session=None, lock_for_update=False):\n        \"\"\"\n        Refreshes the task instance from the database based on the primary key"
  },
  {
    "id" : "3b4f4769-fee2-4893-82f2-ec73a54b396c",
    "prId" : 1406,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "adb9b6de-c256-4857-97b7-1919ce5178ad",
        "parentId" : null,
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "maybe attempts_to_rerun_succeeded_tasks or something a bit more clear\n",
        "createdAt" : "2016-04-19T23:50:39Z",
        "updatedAt" : "2016-04-19T23:50:39Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      }
    ],
    "commit" : "211a85907e6def416b9f7465b4e3e488a226b46b",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1130,1134 @@                \" on {self.end_date}\".format(**locals())\n            )\n            Stats.incr('previously_succeeded', 1, 1)\n        elif (\n                not ignore_dependencies and"
  },
  {
    "id" : "1dec784d-a354-4803-be1f-6c77fb6e36af",
    "prId" : 1406,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d92a2969-e111-46df-aa46-8eb83826483d",
        "parentId" : null,
        "authorId" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "body" : "maybe collect_dags_seconds so that it's clear it's a time measurement\n",
        "createdAt" : "2016-04-19T23:50:44Z",
        "updatedAt" : "2016-04-19T23:50:44Z",
        "lastEditedBy" : "06a356e2-8fb5-4f99-b8bb-46ce12d2daa0",
        "tags" : [
        ]
      },
      {
        "id" : "c4c52301-b3bf-4900-aaaf-7325dcaf5e72",
        "parentId" : "d92a2969-e111-46df-aa46-8eb83826483d",
        "authorId" : "08b40e03-e1f4-45e1-80c0-b73f75b29580",
        "body" : "dag_collection_time_seconds? Also, I'm not too familiar with how these metrics appear on the user end. Is it just this string or is there any additional context about which module it came from?\n",
        "createdAt" : "2016-04-20T00:12:08Z",
        "updatedAt" : "2016-04-20T00:12:08Z",
        "lastEditedBy" : "08b40e03-e1f4-45e1-80c0-b73f75b29580",
        "tags" : [
        ]
      }
    ],
    "commit" : "211a85907e6def416b9f7465b4e3e488a226b46b",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +408,412 @@                        logging.warning(e)\n        Stats.gauge(\n            'collect_dags', (datetime.now() - start_dttm).total_seconds(), 1)\n        Stats.gauge(\n            'dagbag_size', len(self.dags), 1)"
  },
  {
    "id" : "6e35f568-7314-48ca-9ac9-71ccbd940472",
    "prId" : 1406,
    "prUrl" : null,
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7fdec160-1074-438b-a7e7-5e88945599d1",
        "parentId" : null,
        "authorId" : "08b40e03-e1f4-45e1-80c0-b73f75b29580",
        "body" : "Could you also add `Stats.gauge('import_errors', len(self.import_errors), 1)`? \n",
        "createdAt" : "2016-04-21T02:27:28Z",
        "updatedAt" : "2016-04-21T02:27:28Z",
        "lastEditedBy" : "08b40e03-e1f4-45e1-80c0-b73f75b29580",
        "tags" : [
        ]
      }
    ],
    "commit" : "211a85907e6def416b9f7465b4e3e488a226b46b",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +410,414 @@            'collect_dags', (datetime.now() - start_dttm).total_seconds(), 1)\n        Stats.gauge(\n            'dagbag_size', len(self.dags), 1)\n\n    def deactivate_inactive_dags(self):"
  }
]