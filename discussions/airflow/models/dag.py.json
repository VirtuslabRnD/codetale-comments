[
  {
    "id" : "e5e12b1c-10af-45a3-a188-59212a89d0a8",
    "prId" : 5144,
    "prUrl" : "https://github.com/apache/airflow/pull/5144#pullrequestreview-228975920",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6300e188-c898-4bbd-8e6c-7537cae14623",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "You should add new line after description. Otherwise, the documentation will not generate properly",
        "createdAt" : "2019-04-21T22:26:20Z",
        "updatedAt" : "2019-04-22T07:00:41Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "437ab68d-a4c9-4075-8424-75c7b5f5e50f",
        "parentId" : "6300e188-c898-4bbd-8e6c-7537cae14623",
        "authorId" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "body" : "Thanks! Fixed.",
        "createdAt" : "2019-04-22T07:02:21Z",
        "updatedAt" : "2019-04-22T07:02:21Z",
        "lastEditedBy" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b6cdb730dae23e0426ae8060124d634826cc5c8",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +546,550 @@        Return list of all owners found in DAG tasks.\n\n        :return: Comma separated list of owners in DAG tasks\n        :rtype: str\n        \"\"\""
  },
  {
    "id" : "abf2f04c-a0bb-48ea-95df-e8e677b44437",
    "prId" : 5283,
    "prUrl" : "https://github.com/apache/airflow/pull/5283#pullrequestreview-243620749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd853885-24a7-45d0-aac5-06fe8b04d140",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@milton0825 Creating a full DagBag is a potentially very expensive operation. Please can you create a new PR (against the same Jira ticket) to change this so that we don't parse all Dags here?\r\n\r\nAdditionally there is already a `subdags` property on the DAG class that we should use instead of duplicating this logic in _find_dag_ids_including_subdags. (We possiibly don't need that fn anymore either? `[dag.dag_id] + [ dag.dag_id for dag in dag.subdags]`. (The subdags will recurse in to find nested subdags already)\r\n\r\n Could this be done by looking at the DAG model only? Or at least only loading the one specific subdag, or at least not loading all dags even when pausing a dag that doesn't contain any subdags?\r\n\r\nCreating a DagBag is probably a code smell now.",
        "createdAt" : "2019-05-29T12:05:35Z",
        "updatedAt" : "2019-05-29T12:05:36Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "f089ef9b-b86a-465e-b8c7-efdc88029906",
        "parentId" : "fd853885-24a7-45d0-aac5-06fe8b04d140",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "I see. I will create another PR to avoid loading the whole DagBag",
        "createdAt" : "2019-05-30T02:47:25Z",
        "updatedAt" : "2019-05-30T02:47:26Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      },
      {
        "id" : "9425b0b4-d3cf-43c1-aed6-f410916b4262",
        "parentId" : "fd853885-24a7-45d0-aac5-06fe8b04d140",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "@ashb https://github.com/apache/airflow/pull/5342",
        "createdAt" : "2019-05-30T04:25:59Z",
        "updatedAt" : "2019-05-30T04:26:00Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      }
    ],
    "commit" : "a78eac62d1249b700cb7cd70ae5d77d1b6476330",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +1553,1557 @@        dag_ids = []  # type: List[str]\n        if including_subdags:\n            dagbag = DagBag(dag_folder=subdir)\n            dag_ids.extend(cls._find_dag_ids_including_subdags(dagbag.get_dag(dag_id)))\n        else:"
  },
  {
    "id" : "c4119053-b45c-490a-aefe-4fdad273c404",
    "prId" : 5283,
    "prUrl" : "https://github.com/apache/airflow/pull/5283#pullrequestreview-243213115",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3a568c0-16dc-4061-bb92-e03f7a47cd6f",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Instead of a subdir argument could we use `dag.fileloc` instead? (I don't know if that would load subdags or not.)",
        "createdAt" : "2019-05-29T12:07:11Z",
        "updatedAt" : "2019-05-29T12:07:11Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "a78eac62d1249b700cb7cd70ae5d77d1b6476330",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1540,1544 @@                      is_paused: bool,\n                      including_subdags: bool = True,\n                      subdir: str = None,\n                      session=None) -> None:\n        \"\"\""
  },
  {
    "id" : "8a5b2c37-c638-4395-8ed2-f6def591c348",
    "prId" : 5327,
    "prUrl" : "https://github.com/apache/airflow/pull/5327#pullrequestreview-242010852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "176e381d-cd71-4ebe-93b7-aa76867806c0",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Same here.",
        "createdAt" : "2019-05-25T17:56:31Z",
        "updatedAt" : "2019-05-25T17:57:31Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "82c2f6afec272c2f2f0fb5e32cca5196178454b7",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +171,175 @@        description: str = '',\n        schedule_interval: Optional[ScheduleInterval] = timedelta(days=1),\n        start_date: Optional[datetime] = None,\n        end_date: Optional[datetime] = None,\n        full_filepath: Optional[str] = None,"
  },
  {
    "id" : "d47b5ff9-d6e0-4466-8231-47a54007bb7c",
    "prId" : 5874,
    "prUrl" : "https://github.com/apache/airflow/pull/5874#pullrequestreview-277377186",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5026dced-e87c-49b9-b858-11057d1b153c",
        "parentId" : null,
        "authorId" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "body" : "Is this correct?",
        "createdAt" : "2019-08-20T18:54:37Z",
        "updatedAt" : "2019-08-20T20:44:59Z",
        "lastEditedBy" : "03e41e23-f438-4a06-9652-8f20638d2c3a",
        "tags" : [
        ]
      },
      {
        "id" : "2a485efa-2002-42fa-b03d-33bc6610cd6c",
        "parentId" : "5026dced-e87c-49b9-b858-11057d1b153c",
        "authorId" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "body" : "Yes :( We actually fill it with Operators, not TaskInstances. The mixing of \"operator\" and \"task\" throughout the codebase is rather confusing.",
        "createdAt" : "2019-08-20T19:02:15Z",
        "updatedAt" : "2019-08-20T20:44:59Z",
        "lastEditedBy" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "tags" : [
        ]
      },
      {
        "id" : "fa54bb57-2876-4074-8943-b459bfc92973",
        "parentId" : "5026dced-e87c-49b9-b858-11057d1b153c",
        "authorId" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "body" : "I changed it in this PR because my IDE (PyCharm) was not suggesting the correct methods.",
        "createdAt" : "2019-08-20T19:02:49Z",
        "updatedAt" : "2019-08-20T20:44:59Z",
        "lastEditedBy" : "db6eb8b7-c895-4f19-9e3d-6fa0535f27e2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9467bc893342dc43618b6342eb5b3e30d9516831",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +228,232 @@        # set file location to caller source path\n        self.fileloc = sys._getframe().f_back.f_code.co_filename\n        self.task_dict = dict()  # type: Dict[str, BaseOperator]\n\n        # set timezone from start_date"
  },
  {
    "id" : "2de5c19c-bc86-4a5b-a404-914844b2206b",
    "prId" : 5943,
    "prUrl" : "https://github.com/apache/airflow/pull/5943#pullrequestreview-281459216",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8e47513-771b-476e-b298-8c42103ca078",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Can we add this parameter in docstring of DAG class please?",
        "createdAt" : "2019-08-29T13:31:23Z",
        "updatedAt" : "2019-08-29T16:33:34Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "412fc1d84611ba650b273c1842b2baeba7ed2d6b",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +222,226 @@        access_control: Optional[Dict] = None,\n        is_paused_upon_creation: Optional[bool] = None,\n        jinja_environment_kwargs: Optional[Dict] = None\n    ):\n        self.user_defined_macros = user_defined_macros"
  },
  {
    "id" : "befe5ff5-5423-41a9-a94d-c1043ad2889d",
    "prId" : 6489,
    "prUrl" : "https://github.com/apache/airflow/pull/6489#pullrequestreview-333204745",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I wonder if it would be better to use a JSON column on the Dag table, rather than needing a new dag-tag table.\r\n\r\nSQLAlchemy has built in support for JSON columns for mysql, sqlite and postgres, and with postgres we could even add an index on it.",
        "createdAt" : "2019-11-15T21:35:27Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "4a2f691b-15a5-4a3a-a548-b6021d31095a",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "+1  on using JSON column. Don't mind if it is in same table or different. Maybe makes sense to have it in the same Dag table just for consistency and won't need a new class DagTag :D ",
        "createdAt" : "2019-11-15T23:24:08Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "74dad139-0796-44d3-a74d-1f150aa69847",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "body" : "@ashb @kaxil As far as I know, sqlalchemy doesn't fully support JSON Arrays, it's not possible to check if value X is in the list.\r\nAm I missing something?",
        "createdAt" : "2019-11-16T12:16:34Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "tags" : [
        ]
      },
      {
        "id" : "e763d265-6fc3-4112-9bdc-4ed43f10185a",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Oh. It's possible, but we have to handle the DB differences our selves :( https://stackoverflow.com/questions/39470239/sqlalchemy-json-column-how-to-preform-a-contains-query\r\n ",
        "createdAt" : "2019-11-18T16:01:44Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "2ecada0e-9bdc-4668-9b65-7d489c187478",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "body" : "Yep, it doesn't sounds best practice.\r\nWDYT?",
        "createdAt" : "2019-11-18T16:26:05Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "tags" : [
        ]
      },
      {
        "id" : "a6f5879c-e858-4831-a9e6-eafc20f605e7",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "dd9d6a00-558d-46ea-b524-e24aa17ff9ab",
        "body" : "Why does it need JSON column?\r\nIf table is on DAG level... each row represent dag then labels are just dimension on this DAG. It can be array type.\r\nEach change in label affect only 1 DAG so it's just updating one cell",
        "createdAt" : "2019-12-17T07:57:01Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "dd9d6a00-558d-46ea-b524-e24aa17ff9ab",
        "tags" : [
        ]
      },
      {
        "id" : "cfee8003-7291-4791-8545-676ddbb79bdb",
        "parentId" : "2e4acd4c-32d5-4445-854d-208e6f6c2ff7",
        "authorId" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "body" : "@OmerJog ARRAY type is currently working only with PostgreSQL.",
        "createdAt" : "2019-12-17T11:24:13Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "tags" : [
        ]
      }
    ],
    "commit" : "6b1f6e0cde5927ad5283e60914145d42dc5db42a",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +1386,1390 @@        orm_dag.description = self.description\n        orm_dag.schedule_interval = self.schedule_interval\n        orm_dag.tags = self.get_dagtags(session=session)\n\n        session.commit()"
  },
  {
    "id" : "ae2cce2c-f32d-4cfe-91b5-7437659f5878",
    "prId" : 6489,
    "prUrl" : "https://github.com/apache/airflow/pull/6489#pullrequestreview-317970078",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25ea1cef-ab26-44e4-a5c8-d36fa3e8063b",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Should we add logic to remove duplicate tags? Example: `['example', 'example']`",
        "createdAt" : "2019-11-15T23:27:38Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "dce62b69-92d9-454d-bdad-19fd6278ac9b",
        "parentId" : "25ea1cef-ab26-44e4-a5c8-d36fa3e8063b",
        "authorId" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "body" : "See `get_dagtags` function, it convert the tags list (if not None) to a set.",
        "createdAt" : "2019-11-16T10:29:14Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "676ef054-9bc4-4f4d-a9e6-43cf8ac4587e",
        "tags" : [
        ]
      },
      {
        "id" : "bbb24128-9417-40e0-a6ee-f472bab4897b",
        "parentId" : "25ea1cef-ab26-44e4-a5c8-d36fa3e8063b",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Awesome",
        "createdAt" : "2019-11-16T13:14:38Z",
        "updatedAt" : "2020-01-09T12:44:55Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "6b1f6e0cde5927ad5283e60914145d42dc5db42a",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +315,319 @@\n        self.jinja_environment_kwargs = jinja_environment_kwargs\n        self.tags = tags\n\n    def __repr__(self):"
  },
  {
    "id" : "18b91722-6c6f-45c6-acad-15acbe466984",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-325431882",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbb3b353-d3cb-48e3-9416-16eb6a090ede",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(Not for this PR, but I do wonder if we should remove this functionality as it feels somewhat out of place with the \"normal\" way that `airflow tasks run` is used. It's almost closer to `airflow tasks submit` in nature. But it also bypasses lots of the scheduler \"gating\" that maybe it shouldn't.)",
        "createdAt" : "2019-12-02T12:20:08Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ddde2179-e566-4463-bf85-76914b511889",
        "parentId" : "cbb3b353-d3cb-48e3-9416-16eb6a090ede",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I also do not feel confident about having pluginnable executors. I was quite surprised to see that it was possible. ",
        "createdAt" : "2019-12-02T18:11:52Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +1257,1261 @@            executor = LocalExecutor()\n        elif not executor:\n            from airflow.executors.executor_loader import ExecutorLoader\n            executor = ExecutorLoader.get_default_executor()\n        job = BackfillJob("
  },
  {
    "id" : "a04d60e6-0699-4686-8a4d-5e06ecd4bb61",
    "prId" : 6601,
    "prUrl" : "https://github.com/apache/airflow/pull/6601#pullrequestreview-322548462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d067589f-853e-444e-9347-1e1c85883fb3",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "I would like to have some more description of this. :)",
        "createdAt" : "2019-11-25T11:21:32Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "1af99497-e9e0-4030-901e-565ea23049e4",
        "parentId" : "d067589f-853e-444e-9347-1e1c85883fb3",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Done :)/",
        "createdAt" : "2019-11-25T20:11:13Z",
        "updatedAt" : "2019-11-26T20:29:13Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e8be9e171098acda6facbf9f645dd1876b761a3",
    "line" : 131,
    "diffHunk" : "@@ -1,1 +1709,1713 @@\n\nclass DagContext:\n    \"\"\"\n    DAG context is used to keep the current DAG when DAG is used as ContextManager."
  },
  {
    "id" : "87867def-4175-43cd-acd0-8abfc4a871c7",
    "prId" : 6633,
    "prUrl" : "https://github.com/apache/airflow/pull/6633#pullrequestreview-332604942",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Isn't `ti.operator` a class? So this is basically doing `if Class() == \"Class\"` isn't it?",
        "createdAt" : "2019-12-16T10:11:29Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "e29ad3ee-6582-4f6f-87ce-e24086988910",
        "parentId" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "I looked into taskinstance.py. TaskInstance.operator is a String stored in the database. It's assigned the name of the class during its construction.\r\n```\r\noperator = Column(String(1000))\r\n```\r\n\r\nHowever, you have a point that this line is a little awkward. Is there a better way to say \"if this taskinstance is created from a instance of `ExternalTaskMarker`\" ?",
        "createdAt" : "2019-12-16T10:19:30Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "7ce9f12b-8f96-4859-ae2f-f654f6fdbedf",
        "parentId" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "`isinstance(ti.task, ExternalTaskMarker)` -- make sure that the import for this is \"delayed\" until it's needed, i.e. somewhere in \"this\" block. (not the loop, but the \"if clearing these dags\")\r\n\r\n@kaxil Which of these is better from a Dag Serialization PoV? Doesn't matter right? ",
        "createdAt" : "2019-12-16T11:24:17Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "9c4c1a15-aab3-4caa-a19d-d21e39365410",
        "parentId" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "Hi @ashb I tried the following:\r\n\r\n```\r\nisinstance(ti.task, ExternalTaskMarker)\r\n```\r\n\r\nUnfortunately I realized that ti.task is not set if `TaskInstance` is not created from the constructor `__init__`. \r\n```\r\nE.g. the following raises `AttributeError` in this scope.\r\n(Pdb++) p ti.task\r\n*** AttributeError: 'TaskInstance' object has no attribute 'task'\r\n(Pdb++) p isinstance(ti.task, ExternalTaskMarker)\r\n*** AttributeError: 'TaskInstance' object has no attribute 'task'\r\n\r\nThis works:\r\n(Pdb++) p ti.operator\r\n'ExternalTaskMarker'\r\n```\r\n\r\nIf `isinstance` is preferred, one other way do it is something like this:\r\n\r\n```\r\ntask = self.get_task(ti.task_id)\r\n\r\nif isinstance(task, ExternalTaskMarker):\r\n    if recursion_depth == 0:\r\n        # Maximum recursion depth allowed is the recursion_depth of the first\r\n        # ExternalTaskMarker in the tasks to be cleared.\r\n        max_recursion_depth = task.recursion_depth\r\n    ...\r\n```\r\n\r\nThis always gets the task object from the dag, even when it's not needed. So it's likely slightly slower than checking the value of `ti.operator`. We should only do it if there's a strong reason.\r\n\r\n@ashb  @kaxil what do you think?",
        "createdAt" : "2019-12-16T13:11:12Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "d1967fa1-10ce-497a-aaf8-a1d1e0bf0187",
        "parentId" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Probably stick with it as you have it then?",
        "createdAt" : "2019-12-16T14:15:37Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "ae5a36c0-6cb6-4ef5-9b4b-78dbaccf39ff",
        "parentId" : "40a3f35a-463a-4a32-868c-0ad4ca7f5d1f",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "@ashb  Sure, will do. I have also moved the `import ExternalTaskMarker` inline into the `if` block like you recommended. Thank you!",
        "createdAt" : "2019-12-16T14:27:52Z",
        "updatedAt" : "2020-01-08T06:41:17Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "1e0602555e12fd8a8abf041a7c0d970ed9d7b7f0",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +1000,1004 @@            instances = tis.all()\n            for ti in instances:\n                if ti.operator == ExternalTaskMarker.__name__:\n                    ti.task = self.get_task(ti.task_id)\n"
  },
  {
    "id" : "f1242d2f-9288-4e88-8dda-16518ff10ea7",
    "prId" : 6900,
    "prUrl" : "https://github.com/apache/airflow/pull/6900#pullrequestreview-352146975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93266258-ac57-4724-af0d-0ddc2c8c5135",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Do f-strings work in py3.6?",
        "createdAt" : "2020-02-02T10:16:41Z",
        "updatedAt" : "2020-02-18T07:49:34Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "a2f52991-b842-41a9-9eb7-2d71d670deec",
        "parentId" : "93266258-ac57-4724-af0d-0ddc2c8c5135",
        "authorId" : "8c680a1a-3743-44ea-9ab0-a9f70d8fd124",
        "body" : "Yeah, I think it work in py3.6 https://www.python.org/dev/peps/pep-0498/",
        "createdAt" : "2020-02-03T10:18:04Z",
        "updatedAt" : "2020-02-18T07:49:34Z",
        "lastEditedBy" : "8c680a1a-3743-44ea-9ab0-a9f70d8fd124",
        "tags" : [
        ]
      }
    ],
    "commit" : "9b6466f22f42d04d22f516d372a600bba2fc0193",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +311,315 @@        else:\n            raise AirflowException(f'Invalid values of dag.default_view: only support '\n                                   f'{DEFAULT_VIEW_PRESETS}, but get {default_view}')\n        if orientation in ORIENTATION_PRESETS:\n            self.orientation = orientation"
  },
  {
    "id" : "67929296-6802-47ff-8a9e-a33ea07bf092",
    "prId" : 7038,
    "prUrl" : "https://github.com/apache/airflow/pull/7038#pullrequestreview-338945150",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63d4c065-25f5-4081-aeb7-971e0133a5e1",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "This change to `get_task_instances()` seems to be newly included from the previously closed PR? This is going to change the TI returned to include those considered in the \"future\".  Why is this change necessary?\r\n\r\nIf it is indeed needed, you should probably consider doing the same as what you did in `scheduler_job.py`, i.e. only include \"future\" tasks if `RUN_FUTURE_EXEC_DATES` is True **and** `dag.schedule_interval` is None ",
        "createdAt" : "2020-01-06T02:18:12Z",
        "updatedAt" : "2020-01-20T23:26:14Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "cbee5463-bcae-44bd-b938-7b1d6912eb58",
        "parentId" : "63d4c065-25f5-4081-aeb7-971e0133a5e1",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "Okay this does look necessary. And it's easy to fix. How about adding this property to `class DAG`?\r\n\r\n```python\r\nclass DAG:\r\n    ...\r\n    @property\r\n    def allow_future_exec_dates(self):\r\n        return conf.getboolean('scheduler', 'RUN_FUTURE_EXEC_DATES', fallback=False) and self.schedule_interval is None\r\n```\r\n\r\n\r\nThis line can become:\r\n```python\r\n        tis = session.query(TaskInstance).filter(TaskInstance.dag_id == self.dag_id,\r\n                                                 TaskInstance.execution_date >= start_date,\r\n                                                 TaskInstance.task_id.in_([t.task_id for t in self.tasks]))\r\n\r\n        if end_date or not self.allow_future_exec_dates:\r\n            end_date = end_date or timezone.utcnow()\r\n            tis = tis.filter(TaskInstance.execution_date <= end_date)\r\n```\r\n\r\nAnd you may want to use `dag.allow_future_exec_dates` in the two other places that you checked the same conditions too, i.e. scheduler_job.py and runnable_exec_date_dep.py",
        "createdAt" : "2020-01-06T03:13:05Z",
        "updatedAt" : "2020-01-20T23:26:14Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "100affef-5339-4f8f-ab9d-de520b931930",
        "parentId" : "63d4c065-25f5-4081-aeb7-971e0133a5e1",
        "authorId" : "f544d16a-6b8c-4985-b9b6-3c5bd6a31970",
        "body" : "updated",
        "createdAt" : "2020-01-06T22:54:08Z",
        "updatedAt" : "2020-01-20T23:26:14Z",
        "lastEditedBy" : "f544d16a-6b8c-4985-b9b6-3c5bd6a31970",
        "tags" : [
        ]
      }
    ],
    "commit" : "40d17bad2808e91e073ba3cd288da02d2fb3e230",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +789,793 @@            start_date = timezone.make_aware(\n                datetime.combine(start_date, datetime.min.time()))\n\n        tis = session.query(TaskInstance).filter(\n            TaskInstance.dag_id == self.dag_id,"
  },
  {
    "id" : "9ede57e7-c229-4ad3-8bdc-754185f6ea10",
    "prId" : 7038,
    "prUrl" : "https://github.com/apache/airflow/pull/7038#pullrequestreview-345089088",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "382d808b-58f5-4f4d-9394-e27463387e06",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Let's add a test for this piece of code.",
        "createdAt" : "2020-01-15T21:18:19Z",
        "updatedAt" : "2020-01-20T23:26:14Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "04e8ab68-d583-4376-a48b-d241ef8247b0",
        "parentId" : "382d808b-58f5-4f4d-9394-e27463387e06",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "@tooptoop4 , maybe add a test for this code to `test_taskinstance.py`, unless you find some better place for the test.",
        "createdAt" : "2020-01-20T07:22:22Z",
        "updatedAt" : "2020-01-20T23:26:14Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "40d17bad2808e91e073ba3cd288da02d2fb3e230",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +798,802 @@        if end_date or not self.allow_future_exec_dates:\n            end_date = end_date or timezone.utcnow()\n            tis = tis.filter(TaskInstance.execution_date <= end_date)\n\n        if state:"
  },
  {
    "id" : "4e64b0d7-6dd2-4af6-985d-fe2d14c54e84",
    "prId" : 7477,
    "prUrl" : "https://github.com/apache/airflow/pull/7477#pullrequestreview-362559859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01ce44d3-5fd1-450a-8b3e-749b99fe3200",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "If we made this a method on DagBag instead dag_by_ids is `self.dags` - it's possibly a micro-optimization, but right now the only case of \"bulk_sync\" is being called with `DAG.bulk_sync_to_db(dagbag.dags.values())` -- so we're throwing away the info we've already got to re-compute it.",
        "createdAt" : "2020-02-21T09:33:15Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "402b810a-b14f-43e2-a7a6-6f5b4d4287aa",
        "parentId" : "01ce44d3-5fd1-450a-8b3e-749b99fe3200",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I checked and it doesn't have a big impact on performance. I left the current code to keep the code legible. ",
        "createdAt" : "2020-02-21T11:14:30Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "51bb35951e7702d0a31487238f75854c0360929e",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1477,1481 @@            sync_time = timezone.utcnow()\n        log.info(\"Sync %s DAGs\", len(dags))\n        dag_by_ids = {dag.dag_id: dag for dag in dags}\n        dag_ids = set(dag_by_ids.keys())\n        orm_dags = ("
  },
  {
    "id" : "f5d0c3e5-e414-41b9-a32f-e3844c14d5be",
    "prId" : 7477,
    "prUrl" : "https://github.com/apache/airflow/pull/7477#pullrequestreview-362527126",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3972934c-5a95-492e-a3d4-b8e41eeb23fb",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This I think is going to go back to the DB, ignoring the joinedload you did earlier? Or does this somehow work because of the smarts in the SQLASession?",
        "createdAt" : "2020-02-21T09:42:01Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "d77d25bb-e994-4dd8-9c51-ca086b5ce6c8",
        "parentId" : "3972934c-5a95-492e-a3d4-b8e41eeb23fb",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "SQLAlchemy is smart enough.\r\nWhen I did following changes:\r\n```diff\r\n-        orm_dags = session.query(DagModel) \\\r\n-            .options(\r\n-            joinedload(DagModel.tags, innerjoin=False)\r\n-        ) \\\r\n-            .filter(DagModel.dag_id.in_(dag_ids)).all()\r\n+        orm_dags = session.query(DagModel)\\\r\n+            .filter(DagModel.dag_id.in_(dag_ids)).all()\r\n``` \r\nI got following values - \r\nBefore - 200 DAGs:\r\n```\r\nQuery count:  602\r\nAverage took 3736.448 ms\r\n```\r\nAfter:\r\n```\r\nQuery count:  801\r\nAverage took 3946.783 ms\r\n```",
        "createdAt" : "2020-02-21T10:00:15Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "37f6e9f5-92a0-44b8-ac46-6ced205963c3",
        "parentId" : "3972934c-5a95-492e-a3d4-b8e41eeb23fb",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "~I think you have before and after backwards here :)~\r\n\r\nAh no I see. \r\n\r\nAnyway, cool",
        "createdAt" : "2020-02-21T10:17:14Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "51bb35951e7702d0a31487238f75854c0360929e",
    "line" : 108,
    "diffHunk" : "@@ -1,1 +1516,1520 @@            orm_dag.description = dag.description\n            orm_dag.schedule_interval = dag.schedule_interval\n            orm_dag.tags = dag.get_dagtags(session=session)\n\n        session.commit()"
  },
  {
    "id" : "b2c250ba-beb5-4c29-a682-8c826133607d",
    "prId" : 7477,
    "prUrl" : "https://github.com/apache/airflow/pull/7477#pullrequestreview-363739912",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e458469-02e3-4c91-ad27-7e924bb64cfe",
        "parentId" : null,
        "authorId" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "body" : "it might be worth doing this in smaller batches rather than one gigantic commit. I don't think atomicity is a concern but large transactions may be.",
        "createdAt" : "2020-02-24T21:33:07Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "8649c9db-e4a7-4aa4-8d8f-c2c7fc5ae1ec",
        "tags" : [
        ]
      },
      {
        "id" : "a53d5ec3-fca4-4f97-aeba-2cb05420ae2c",
        "parentId" : "1e458469-02e3-4c91-ad27-7e924bb64cfe",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is only done from DAGs from one file. I suspect that even if someone puts 200+ DAG in one file, adding up to 200+ entry to DB in one transaction is not a problem. ",
        "createdAt" : "2020-02-24T22:14:16Z",
        "updatedAt" : "2020-02-27T06:27:44Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "51bb35951e7702d0a31487238f75854c0360929e",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +1518,1522 @@            orm_dag.tags = dag.get_dagtags(session=session)\n\n        session.commit()\n\n        for dag in dags:"
  }
]