[
  {
    "id" : "c01d96dc-9a2a-4389-93fb-69284b9db573",
    "prId" : 7402,
    "prUrl" : "https://github.com/apache/airflow/pull/7402#pullrequestreview-361883496",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f721951-4de2-4b72-8598-588cf491f919",
        "parentId" : null,
        "authorId" : "de0913b8-801a-48db-b90d-7fdb204a5376",
        "body" : "why not use  `get_ready_tis`? \r\n",
        "createdAt" : "2020-02-20T13:05:21Z",
        "updatedAt" : "2020-02-20T13:05:21Z",
        "lastEditedBy" : "de0913b8-801a-48db-b90d-7fdb204a5376",
        "tags" : [
        ]
      }
    ],
    "commit" : "16db3f1449d2e00c9de5b34612aacef29ea42023",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +299,303 @@                # slow path\n                for ti in scheduleable_tasks:\n                    if ti.are_dependencies_met(\n                        dep_context=DepContext(flag_upstream_failed=True),\n                        session=session"
  },
  {
    "id" : "5d0d6126-368a-4920-a335-e8676f6cbc66",
    "prId" : 8227,
    "prUrl" : "https://github.com/apache/airflow/pull/8227#pullrequestreview-414636955",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Probably it's worth to use this column in index as mentioned in the original issue",
        "createdAt" : "2020-04-09T10:14:51Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "87a62599-928a-495c-93f4-0559ab5fb65d",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Yeah, we should look at how we query dag_run table, as I'd guess we want a multi-column index on run_type + something else (exeuction date? dag id?) as we don't (I think) ever select just by run_type?",
        "createdAt" : "2020-04-09T10:27:00Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "fc59e691-6144-4022-8f46-0464560c97fc",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@turbaszek What indexes did we decide on?",
        "createdAt" : "2020-05-12T20:43:08Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "a758637b-4832-4ed1-acb2-4d8edd936145",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "I think we should keep the one we have. The DagRunType is only used in query only in `dag_list_dag_runs` and in `_trigger_dag`",
        "createdAt" : "2020-05-12T20:58:13Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "917f19b2-d504-4412-91e6-525837c6a2d5",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "https://github.com/apache/airflow/blob/bae5cc2f5ca32e0f61c3b92008fbd484184448ef/airflow/jobs/scheduler_job.py#L573 Can you look at it?",
        "createdAt" : "2020-05-19T14:14:58Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "406196fd-20fa-4025-bae0-44553f7546b4",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "The scheduler (well dag parsing process) looks at DagRuns where type is not Backfill.",
        "createdAt" : "2020-05-19T15:58:41Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "2fdd2f12-aa6e-4cab-be8e-82f204214fda",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "https://github.com/apache/airflow/blob/bae5cc2f5ca32e0f61c3b92008fbd484184448ef/airflow/jobs/scheduler_job.py#L1158-L1188",
        "createdAt" : "2020-05-19T16:45:26Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "11d696db-6fab-46dc-9c31-07855a5470cf",
        "parentId" : "1e913896-f5f5-4974-be41-9923f2e60f34",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "(As Kamil already commented. Missed that comment somehow)",
        "createdAt" : "2020-05-19T16:47:51Z",
        "updatedAt" : "2020-06-04T13:00:56Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "70e9dd016f6b34f47b66bbbbf5c3d377521e6a0b",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +75,79 @@        self.conf = conf\n        self.state = state\n        self.run_type = run_type\n        super().__init__()\n"
  },
  {
    "id" : "ca4657eb-080f-4f9e-8403-103f0d328acb",
    "prId" : 8852,
    "prUrl" : "https://github.com/apache/airflow/pull/8852#pullrequestreview-415682245",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c394503-c37c-473a-915a-3d5158f17867",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Why do we need it here? this TIs are received from DB.\r\n\r\nI think we should only mutate before storing it to DB",
        "createdAt" : "2020-05-20T17:33:05Z",
        "updatedAt" : "2020-06-12T07:05:23Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "ccaf4d9f-0e8f-457f-a94d-2f0608336c5f",
        "parentId" : "3c394503-c37c-473a-915a-3d5158f17867",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "For cases that we want to mutate task instances before each executions. For example, re-routing to different queue for retries.",
        "createdAt" : "2020-05-20T19:12:20Z",
        "updatedAt" : "2020-06-12T07:05:23Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      },
      {
        "id" : "e4ef51b4-c117-4aa6-9a3a-225d83e71f09",
        "parentId" : "3c394503-c37c-473a-915a-3d5158f17867",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "But you are already adding it before saving it to DB on L468, so is it needed here too is my question?",
        "createdAt" : "2020-05-20T19:16:42Z",
        "updatedAt" : "2020-06-12T07:05:23Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "01d0117e-076a-49d3-afb2-f94530367ce3",
        "parentId" : "3c394503-c37c-473a-915a-3d5158f17867",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "L468 is reached when the task instance does not exist thus you create the task instance. However, during retries, the task instance already exists so it won't reach L468",
        "createdAt" : "2020-05-20T19:37:29Z",
        "updatedAt" : "2020-06-12T07:05:23Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      },
      {
        "id" : "0b254f48-09cf-4a71-bf45-96ef3418ab78",
        "parentId" : "3c394503-c37c-473a-915a-3d5158f17867",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "aah yes if you want to have a different queue for TI's that are up for retry this does makes sense",
        "createdAt" : "2020-05-20T20:17:01Z",
        "updatedAt" : "2020-06-12T07:05:23Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "8138738c9762f3f0fcfcd1a6a07376257115aea1",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +434,438 @@        task_ids = []\n        for ti in tis:\n            task_instance_mutation_hook(ti)\n            task_ids.append(ti.task_id)\n            task = None"
  },
  {
    "id" : "3365bbcc-b648-4944-89a3-eac09327b4a6",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-496354463",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "519bd03c-0e1b-4c00-9cb5-03a865d4e5c0",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "What's the reason for the integrity error here? Is the Integrity error here still valid if we do not commit to the database? I think flush is not likely to generate Integrity Error at all.\r\n\r\nShoudl we start caring about isolation level of the transactions we have ? Will it work when we have different isolation levels set ?",
        "createdAt" : "2020-09-23T12:07:47Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "6045a85c-07e2-41f3-9df7-2447c3ac7ef6",
        "parentId" : "519bd03c-0e1b-4c00-9cb5-03a865d4e5c0",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Not sure yet -- https://github.com/apache/airflow/pull/10136 was where this was added only recently.",
        "createdAt" : "2020-09-25T11:59:09Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 237,
    "diffHunk" : "@@ -1,1 +582,586 @@\n        try:\n            session.flush()\n        except IntegrityError as err:\n            self.log.info(str(err))"
  },
  {
    "id" : "94c4cef1-665e-4e8d-afc4-46a795f74538",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-502369702",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a3e3af6-c4ae-4a15-9cf7-9548f9b930ad",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Should we change this method to also update state of the tasks? I think it is only used in two places (schedule_job and backfill_job) and the \"update_state\" method returning tasks sounds a bit weird. I'd rather think about update the task instances as well when update_state is run so that it is all encapsulated within one \"update_state\" method.",
        "createdAt" : "2020-09-23T12:21:25Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "37fc9dbb-91dd-48a4-9310-62df9ea04c4a",
        "parentId" : "1a3e3af6-c4ae-4a15-9cf7-9548f9b930ad",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Already had that thought :) \r\nhttps://github.com/apache/airflow/blob/b28d67332bb052441bc2ffd00030d620aac381c8/airflow/jobs/scheduler_job.py#L1565-L1567",
        "createdAt" : "2020-09-25T12:06:51Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "e231f333-4917-4662-82c3-ff7e0b60f330",
        "parentId" : "1a3e3af6-c4ae-4a15-9cf7-9548f9b930ad",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Any further thoughts ?",
        "createdAt" : "2020-10-05T11:08:52Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "11244c20-a3b7-45fe-9edd-1a8060e4c270",
        "parentId" : "1a3e3af6-c4ae-4a15-9cf7-9548f9b930ad",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Defer to later I think -- not changed in name or behaviour in this PR. ",
        "createdAt" : "2020-10-05T19:49:45Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 145,
    "diffHunk" : "@@ -1,1 +376,380 @@        callback: Optional[callback_requests.DagCallbackRequest] = None\n\n        start_dttm = timezone.utcnow()\n        self.last_scheduling_decision = start_dttm\n"
  },
  {
    "id" : "fb625dd7-7fcf-4971-a3c1-3d4ef66deb06",
    "prId" : 11589,
    "prUrl" : "https://github.com/apache/airflow/pull/11589#pullrequestreview-518297828",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a396fb43-2d37-44d4-8429-9c737de061e8",
        "parentId" : null,
        "authorId" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "body" : "@ashb It looks like `are_runnable_tasks` isn't used until line 456. Is there a reason this conditional needs to be here rather than right before it's used?",
        "createdAt" : "2020-10-27T17:38:57Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "tags" : [
        ]
      },
      {
        "id" : "3f96ab3e-41f9-44bd-91fd-9fa4329d99d1",
        "parentId" : "a396fb43-2d37-44d4-8429-9c737de061e8",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Bad/lazy refactor most likely.",
        "createdAt" : "2020-10-27T17:40:50Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "7bb310b7-c0c5-4eab-afd2-c02e8de800f7",
        "parentId" : "a396fb43-2d37-44d4-8429-9c737de061e8",
        "authorId" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "body" : "Ah looks like it's there so it's outside the conditional. nvm.",
        "createdAt" : "2020-10-28T03:24:03Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f30d90ba-101c-4671-a1df-fa45531fa887",
        "tags" : [
        ]
      }
    ],
    "commit" : "613da86bd2bd844366d66e14f911ce7057bef43a",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +403,407 @@\n        if unfinished_tasks and none_depends_on_past and none_task_concurrency:\n            # small speed up\n            are_runnable_tasks = schedulable_tis or self._are_premature_tis(\n                unfinished_tasks, finished_tasks, session) or changed_tis"
  },
  {
    "id" : "ce4ed48c-be9e-4bf9-a925-38209a663c3d",
    "prId" : 11589,
    "prUrl" : "https://github.com/apache/airflow/pull/11589#pullrequestreview-521908706",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6417b51d-05a4-4123-811c-7c9d6fa62771",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Will it work for operators that inherit from `DummyOperator`?",
        "createdAt" : "2020-11-02T17:56:54Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "3789d25a-ca26-40e1-92b1-2cc1859002f1",
        "parentId" : "6417b51d-05a4-4123-811c-7c9d6fa62771",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "No, there is already an issue for that though",
        "createdAt" : "2020-11-02T18:39:55Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "44bb442a-4cd8-4418-861d-97bc72cddfc4",
        "parentId" : "6417b51d-05a4-4123-811c-7c9d6fa62771",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "#11393",
        "createdAt" : "2020-11-02T18:53:23Z",
        "updatedAt" : "2020-11-02T20:36:09Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "613da86bd2bd844366d66e14f911ce7057bef43a",
    "line" : 126,
    "diffHunk" : "@@ -1,1 +690,694 @@            if\n            (\n                ti.task.task_type == \"DummyOperator\"\n                and not ti.task.on_execute_callback\n                and not ti.task.on_success_callback"
  },
  {
    "id" : "7a2dde5e-b3ea-42db-861e-3bfeafba451e",
    "prId" : 12815,
    "prUrl" : "https://github.com/apache/airflow/pull/12815#pullrequestreview-545211315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "50ebdebf-edca-4bbb-833f-77ab697df662",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "This change is to ensure we traverse `schedulable_tis` only once, rather than twice. ",
        "createdAt" : "2020-12-04T18:04:59Z",
        "updatedAt" : "2020-12-04T18:50:07Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "0d1e4a58-7113-4cb5-b88b-913996a8025c",
        "parentId" : "50ebdebf-edca-4bbb-833f-77ab697df662",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Do you think it is worth moving these logics to a separate function? See: ``airflow.utils.helpers.partition``",
        "createdAt" : "2020-12-04T18:29:57Z",
        "updatedAt" : "2020-12-04T18:50:07Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "8cba87db-5ee9-4c39-b343-d6610e0cfaef",
        "parentId" : "50ebdebf-edca-4bbb-833f-77ab697df662",
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "Personally I don't find it necessary (for now).\r\n\r\nOn the other hand, if we abstract this into a separate function, at least to what I can see, it's sort of \"duplicated\" with `helpers.partition()` (I don't want to use `helpers.partition()` here because it still traverse the iterable twice.)",
        "createdAt" : "2020-12-04T18:46:47Z",
        "updatedAt" : "2020-12-04T18:50:07Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      }
    ],
    "commit" : "3863d9168815c91a0fe44685b2a7c6a19796c5f5",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +733,737 @@                schedulable_ti_ids.append(ti.task_id)\n\n        count = 0\n\n        if schedulable_ti_ids:"
  },
  {
    "id" : "6ab8047c-7bcf-4831-8e82-a1650caa88f7",
    "prId" : 12835,
    "prUrl" : "https://github.com/apache/airflow/pull/12835#pullrequestreview-545866369",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ac4cb64-546f-4010-aa0e-f4cdd22c1f21",
        "parentId" : null,
        "authorId" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "body" : "A question not relating to the changes made in this PR: why not we directly have something like\r\n\r\n`first_start_date = min(ti.start_date for ti in finished_tis)`",
        "createdAt" : "2020-12-05T15:42:56Z",
        "updatedAt" : "2020-12-05T15:43:03Z",
        "lastEditedBy" : "59d531be-9d1e-478d-99a0-6e20963d3e21",
        "tags" : [
        ]
      },
      {
        "id" : "bbd694ec-d319-48cd-9202-40ecf8c0c7bf",
        "parentId" : "1ac4cb64-546f-4010-aa0e-f4cdd22c1f21",
        "authorId" : "f9c9040d-953b-42bd-b86e-16e5f8556f20",
        "body" : "hey @XD-DENG yes agree you can do that and simplify this :) Feel free to add that refactor!",
        "createdAt" : "2020-12-07T06:45:26Z",
        "updatedAt" : "2020-12-07T06:45:27Z",
        "lastEditedBy" : "f9c9040d-953b-42bd-b86e-16e5f8556f20",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ecdcc615053dad86ac68d511b3765011455537e",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +590,594 @@            ordered_tis_by_start_date = [ti for ti in finished_tis if ti.start_date]\n            ordered_tis_by_start_date.sort(key=lambda ti: ti.start_date, reverse=False)\n            first_start_date = ordered_tis_by_start_date[0].start_date\n            if first_start_date:\n                # dag.following_schedule calculates the expected start datetime for a scheduled dagrun"
  },
  {
    "id" : "4a567ccc-c8aa-4580-866b-58bb3c41d996",
    "prId" : 15851,
    "prUrl" : "https://github.com/apache/airflow/pull/15851#pullrequestreview-660018028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b843d863-cea9-44a6-b1d1-0a0566828570",
        "parentId" : null,
        "authorId" : "9b04e80c-b051-4ea8-b3ef-44cbfa62f945",
        "body" : "```suggestion\r\nfrom airflow.models.taskinstance import TaskInstance as TI\r\nfrom airflow.settings import task_instance_mutation_hook\r\n```",
        "createdAt" : "2021-05-14T16:38:15Z",
        "updatedAt" : "2021-05-14T16:38:24Z",
        "lastEditedBy" : "9b04e80c-b051-4ea8-b3ef-44cbfa62f945",
        "tags" : [
        ]
      },
      {
        "id" : "4102b799-5763-4001-a979-cfb0b41b6d68",
        "parentId" : "b843d863-cea9-44a6-b1d1-0a0566828570",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "The fix is to quite literally delay the import, to avoid an import cycle.\r\n\r\nAt the point this _was_ imported, the local settings hadn't been applied, so this was always going to be a no-op.",
        "createdAt" : "2021-05-14T16:42:35Z",
        "updatedAt" : "2021-05-14T16:59:37Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "50cb9553294b3a8be51c8d8fcbdeef084dcbadbf",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +41,45 @@from airflow.exceptions import AirflowException, TaskNotFound\nfrom airflow.models.base import ID_LEN, Base\nfrom airflow.models.taskinstance import TaskInstance as TI\nfrom airflow.stats import Stats\nfrom airflow.ti_deps.dep_context import DepContext"
  }
]