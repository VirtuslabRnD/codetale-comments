[
  {
    "id" : "b9168b14-cb97-469a-966d-2121c3345a38",
    "prId" : 5499,
    "prUrl" : "https://github.com/apache/airflow/pull/5499#pullrequestreview-465262534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4161a02a-0e23-4a55-b059-36cd13a4cb09",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Just to confirm here, the state of SENSING just means the \"Sensor DAG\" has this task, or does it mean this TI is currently being Poked ?",
        "createdAt" : "2020-08-07T15:42:24Z",
        "updatedAt" : "2020-09-08T11:37:36Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d6bbb2f5-40b4-4d88-b1c7-148217385a50",
        "parentId" : "4161a02a-0e23-4a55-b059-36cd13a4cb09",
        "authorId" : "b2325481-de41-4b6d-a7c1-7152249759ba",
        "body" : "\"sensing\" state means this TI is currently being poked by smart sensor.",
        "createdAt" : "2020-08-11T17:05:27Z",
        "updatedAt" : "2020-09-08T11:37:36Z",
        "lastEditedBy" : "b2325481-de41-4b6d-a7c1-7152249759ba",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b5bbff3492fab908dd1c8142ba3beaa3fb274c2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +284,288 @@        # This is designed so that task logs end up in the right file.\n        # TODO: whether we need sensing here or not (in sensor and task_instance state machine)\n        if self.state in State.running():\n            return self._try_number\n        return self._try_number + 1"
  },
  {
    "id" : "1a0ea48f-524c-4906-b622-ee6b1603384a",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-323709508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "In my opinion it doesn't make sense to specify the return type if it's `None`.",
        "createdAt" : "2019-11-27T11:26:44Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "4924110b-e2cb-4eb5-a3e1-1c94bfbff885",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "There is a subtle difference explained here: https://realpython.com/python-type-checking/#functions-without-return-values  \r\n\r\nIf you specify -> None, then you will get warning if you try to assign return value to a variable. If you don't - you get no warning (None is still a valid return value that you can assign to something). So I started to add it (but not consistently, True). \r\nI might review the changes and add -> None in all the affected non-return functions and try to do it in the future as well.\r\n\r\nWDYT @feluelle ?",
        "createdAt" : "2019-11-27T13:23:32Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "89de60cd-0ba5-4cc2-96fb-4a51c3d9d259",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "If we do it consistently then I am fine with it (actually I like it more :D). Because it programming languages like Java or C# I got used to specify `void` for no return value.\r\n\r\nSo if we can somehow force this to be defined I would go for it. 👍 ",
        "createdAt" : "2019-11-27T13:58:32Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "d013f62c-0998-4478-ba1d-b1a76d3001a9",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Some time in the future :)",
        "createdAt" : "2019-11-27T14:23:03Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +422,426 @@\n    @provide_session\n    def refresh_from_db(self, session=None, lock_for_update=False, refresh_executor_config=False) -> None:\n        \"\"\"\n        Refreshes the task instance from the database based on the primary key"
  },
  {
    "id" : "cf2b3f8e-5b5e-42cf-a88d-f8c2c2bb9239",
    "prId" : 6740,
    "prUrl" : "https://github.com/apache/airflow/pull/6740#pullrequestreview-328176986",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c7c73ea-b6ba-4dcd-bb2f-0ddddd3268e0",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It would be great to explain why in a comment.",
        "createdAt" : "2019-12-06T09:11:05Z",
        "updatedAt" : "2019-12-12T14:03:46Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "2c7c0db8-9b51-4385-8b2a-820ef57e2f62",
        "parentId" : "7c7c73ea-b6ba-4dcd-bb2f-0ddddd3268e0",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Done",
        "createdAt" : "2019-12-06T12:37:12Z",
        "updatedAt" : "2019-12-12T14:03:46Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbae6ac73ac71041c17bb41c66256137810d6475",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +899,903 @@\n                task_copy = copy.copy(task)\n\n                # Sensors in `poke` mode can block execution of DAGs when running\n                # with single process executor, thus we change the mode to`reschedule`"
  },
  {
    "id" : "0a499019-b55c-4f1d-8139-74d0646d1400",
    "prId" : 6788,
    "prUrl" : "https://github.com/apache/airflow/pull/6788#pullrequestreview-371062339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b496d51-bb60-499c-8267-e9de8d490dd5",
        "parentId" : null,
        "authorId" : "6f949a1e-f537-44c5-bf07-bd4c568b44ba",
        "body" : "Quite generic question, maybe even an open discussion here.\r\nSTORE_SERIALIZED_DAGS comes from settings.py and is loaded when application (like webserver or scheduler) starts.\r\nIf we use such variables this property stops being dynamic.\r\nBut with scheduler reloading dags every now and then, it could be.\r\n\r\nDo we want to enforce that changing core.store_serialized_dags only takes effect if you restart?\r\nIt is not crucial that it is dynamic but if it can be dynamic why should not it be?",
        "createdAt" : "2020-03-08T19:37:03Z",
        "updatedAt" : "2020-03-12T00:21:48Z",
        "lastEditedBy" : "6f949a1e-f537-44c5-bf07-bd4c568b44ba",
        "tags" : [
        ]
      },
      {
        "id" : "11b56dea-c74d-45fa-b44f-fde622e041a6",
        "parentId" : "9b496d51-bb60-499c-8267-e9de8d490dd5",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "constant vs reading from `conf.getboolean` everytime wouldn't make a difference, as the `airflow.config` is loaded once at main-process start up, and the parsing sub-process forks so keeps the same loaded config -- i.e. it doesn't re-read the config file.",
        "createdAt" : "2020-03-09T10:41:58Z",
        "updatedAt" : "2020-03-12T00:21:48Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "84d5e27e49ffd0154c6a2846d33f962ab4942a8d",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +930,934 @@\n                self.render_templates(context=context)\n                if STORE_SERIALIZED_DAGS:\n                    RTIF.write(RTIF(ti=self, render_templates=False), session=session)\n                    RTIF.delete_old_records(self.task_id, self.dag_id, session=session)"
  },
  {
    "id" : "c7c22e60-b66a-4a6d-8553-928089202309",
    "prId" : 7257,
    "prUrl" : "https://github.com/apache/airflow/pull/7257#pullrequestreview-348372203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I think this attribute should always be created. If it is not needed, it should have an empty value. It is better to solve the problem of missing attributes than to hide the problem. All attributes, that the class has, should be created in the __init__ method.\r\n```python\r\nself.start_date.strftime('%Y%m%dT%H%M%S') if self.start_date else None,\r\n```\r\nThe use of getattr is a trick that allows you to write dynamic code, but we have a known class here that has known attributes.  We don't need dynamic objects here, but stable and solid types.",
        "createdAt" : "2020-01-25T12:11:07Z",
        "updatedAt" : "2020-01-25T12:29:14Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "4efa6632-38d2-44e6-8d93-30e8b9508aaf",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I agree in principle. It should be as you described. But currently we face different reality. Solving it in the way you describe is much bigger task.\r\n\r\nI just want to solve current tests not to show failures where there are no failures at all. Failing exception in \"log\" is not a good \"test\" so it does not hide the problem. Logs should never \"detect\" a problem - they should print the current state of the object and not randomly fail.\r\n\r\nRight now in logs you see unrelated failures, you have inconsistency in the way how those attributes are treated - and sometimes you think those are the problems with tests - where they aren't. \r\n\r\nSo right now I am not trying to solve this \"bigger\" problem only the small one. But I created \r\nthe issue and marked you there https://issues.apache.org/jira/browse/AIRFLOW-6640 to solve the bigger issue. ",
        "createdAt" : "2020-01-25T21:36:44Z",
        "updatedAt" : "2020-01-25T21:36:44Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "e062ffe9-cbeb-47b7-a9c9-2bdc7229e377",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Can you indicate which test has this problem?  It seems to me that the test in this place may fail only in one situation - when execution_date == None, because the existence of the attribute is guaranteed by metaclase - SQlAlchemy.",
        "createdAt" : "2020-01-26T03:59:43Z",
        "updatedAt" : "2020-01-26T03:59:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "61159875-c20b-411d-85a7-63bd9550290f",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I saw it in a few tests, but one particularly that I could see it happening was:\r\n`pytest tests/task/task_runner/test_standard_task_runner.py  -s`\r\n\r\nYou can run it in v1-10-test branch (commit ca0bbba19add1aef564c3379a9b8dfce55000cf1) to reproduce it. I have already applied this change with formatting while testing v1-10-test branch so it does not occur in the v1-10-test branch tip.\r\n\r\nI am now trying to fix all the flakiness and make v1-10-test stable and remove all the false information printed/flaky tests etc. so if you would like to spend quite some time and investigate it and make sure that it's fixed better - I am happy if you can help with this tasks. \r\n\r\nJust to give you perspective - I had quite a lot to do to fix all the various test flakiness so I have no time to analyse all the path of TaskInstance printing and adding if's is the easiest one so I do not have think about this as well. So if you have time and can do it better I am more than happy. I assigned it to you then and maybe we can fix it together: https://issues.apache.org/jira/browse/AIRFLOW-6640 \r\n",
        "createdAt" : "2020-01-26T10:59:38Z",
        "updatedAt" : "2020-01-26T10:59:38Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "da2a4288-d8b5-48a4-917b-eeba63a0da63",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "This is the error I originally had. The test was still passing and the ERROR sigterm logs were expected (on kill). But then apparently in signal processing path task instance was being printed to log and it was producing this misleading exceptions about NoneType not having strftime.  I looked at other places where task instance was printed and I simply aligned all the places to be the same (with getattr and checking for empty) - just to have a consistent approach.\r\n\r\nIf you can modify all the places to not use getattra and maybe even extract taskinstance printing to separate method and trace down where the attributes could have been missing and make sure it is all tested for all cases, I am happy if you do it. \r\n\r\nNote that you should do it for both master and v1-10-test because primary problem was in 1.10 branch.\r\n\r\n```\r\ntests/task/task_runner/test_standard_task_runner.py::TestStandardTaskRunner::test_on_kill ========================= AIRFLOW ==========================\r\nAirflow home /root/airflow\r\nHome of the user: /root\r\nSkipping initializing of the DB as it was initialized already.\r\nYou can re-initialize the database by adding --with-db-init flag when running tests.\r\n[2020-01-25 11:38:56,950] {{__init__.py:51}} INFO - Using executor SequentialExecutor\r\n[2020-01-25 11:38:56,951] {{dagbag.py:403}} INFO - Filling up the DagBag from /opt/airflow/tests/dags\r\n[2020-01-25 11:38:57,050] {test_task_view_type_check.py:50} INFO - class_instance type: <class 'unusual_prefix_5d280a9b385120fec3c40cfe5be04e2f41b6b5e8_test_task_view_type_check.CallableClass'>\r\n[2020-01-25 11:38:57,085] {{dagbag.py:271}} INFO - File /opt/airflow/tests/dags/test_zip.zip assumed to contain no DAGs. Skipping.\r\n[2020-01-25 11:38:57,144] {{standard_task_runner.py:52}} INFO - Started process 235 to run task\r\n[2020-01-25 11:38:57,196] {{dagbag.py:403}} INFO - Filling up the DagBag from /opt/airflow/tests/dags/test_on_kill.py\r\nRunning %s on host %s <TaskInstance: test_on_kill.task1 2016-01-01T00:00:00+00:00 [None]> 7f8368b91b67\r\n[2020-01-25 11:39:00,161] {{helpers.py:322}} INFO - Sending Signals.SIGTERM to GPID 235\r\n[2020-01-25 11:39:00,162] {{taskinstance.py:941}} ERROR - Received SIGTERM. Terminating subprocesses.\r\n[2020-01-25 11:39:00,164] {{test_on_kill.py:36}} INFO - Executing on_kill\r\n[2020-01-25 11:39:00,162] {{taskinstance.py:941}} ERROR - Received SIGTERM. Terminating subprocesses.\r\n[2020-01-25 11:39:00,165] {{test_on_kill.py:36}} INFO - Executing on_kill\r\n[2020-01-25 11:39:00,185] {{taskinstance.py:1122}} ERROR - Task received SIGTERM signal\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 32, in execute\r\n    os.system('sleep 10')\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n[2020-01-25 11:39:00,185] {{taskinstance.py:1122}} ERROR - Task received SIGTERM signal\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 33, in execute\r\n    time.sleep(10)\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n[2020-01-25 11:39:00,194] {{taskinstance.py:1171}} ERROR - Failed to send email to: None\r\n[2020-01-25 11:39:00,194] {{taskinstance.py:1171}} ERROR - Failed to send email to: None\r\n[2020-01-25 11:39:00,201] {{taskinstance.py:1172}} ERROR - 'NoneType' object has no attribute 'strftime'\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 33, in execute\r\n    time.sleep(10)\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 1166, in handle_failure\r\n    self.start_date.strftime('%Y%m%dT%H%M%S'),\r\nAttributeError: 'NoneType' object has no attribute 'strftime'\r\n[2020-01-25 11:39:00,201] {{taskinstance.py:1172}} ERROR - 'NoneType' object has no attribute 'strftime'\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 32, in execute\r\n    os.system('sleep 10')\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 1166, in handle_failure\r\n    self.start_date.strftime('%Y%m%dT%H%M%S'),\r\nAttributeError: 'NoneType' object has no attribute 'strftime'\r\n[2020-01-25 11:39:00,257] {{helpers.py:288}} INFO - Process psutil.Process(pid=235, status='terminated') (235) terminated with exit code 1\r\n[2020-01-25 11:39:00,258] {{helpers.py:288}} INFO - Process psutil.Process(pid=238, status='terminated') (238) terminated with exit code None\r\n[2020-01-25 11:39:00,259] {{helpers.py:288}} INFO - Process psutil.Process(pid=237, status='terminated') (237) terminated with exit code None\r\n[2020-01-25 11:39:00,288] {{helpers.py:288}} INFO - Process psutil.Process(pid=236, status='terminated') (236) terminated with exit code None\r\nPASSED\r\n```",
        "createdAt" : "2020-01-26T11:05:50Z",
        "updatedAt" : "2020-01-26T11:05:50Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "61bb3c9c-9aa5-40b2-93f4-bf03b7cd50cf",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Let me know how you want to proceed please :)",
        "createdAt" : "2020-01-26T11:06:44Z",
        "updatedAt" : "2020-01-26T11:06:44Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9de1854bf78afa0a9bcdf247c975ec2ff57ad2b4",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1150,1154 @@                            self,\n                            'start_date') and self.start_date else '',\n                        self.end_date.strftime('%Y%m%dT%H%M%S') if hasattr(\n                            self,\n                            'end_date') and self.end_date else '')"
  },
  {
    "id" : "e7eb7c9c-ffde-4677-8002-2071690e55c3",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/airflow/pull/7324#pullrequestreview-359343843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e650d6e-14d2-46f3-85ce-da477faa4ae7",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Is it needed here if we call `self.refresh_from_db` immediately? ",
        "createdAt" : "2020-02-15T12:33:53Z",
        "updatedAt" : "2020-02-15T12:33:54Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "39780e74-1d07-4e89-ac8e-4bce84b1cf7b",
        "parentId" : "8e650d6e-14d2-46f3-85ce-da477faa4ae7",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "This is mostly trying to preserve the existing behavior and also move some duplicated code into `refresh_from_task()`. However, you are right that this part is not perfect:\r\n\r\nIdeally we should first call `refresh_from_db()` and then call `refresh_from_task()`. The call to `refresh_from_db()` is to load those **cumulative** values such as `self.try_number` and `self.max_tries` from db so that individual runs of the task can increment these numbers. The call to `refresh_from_task()` is to get those configurable values from the latest DAG definition. However at the moment `refresh_from_db()` is loading both cumulative values and configurable attributes. So it also sets configurable values such as `self.queue` and `self.operator` which are most likely more useful to be read from DAG definition via `refresh_task()`. \r\n\r\nThis PR is not trying to fix everything. It only consolidate some duplicated code and make attributes such as `self.queue` and `self.pool` update-able when tasks are cleared in `clear_task_instances()`. It's probably worth a separate and bigger PR to make sure `refresh_from_db()` is only reading those attributes that really should come from db and leave other attributes to `refresh_from_task()`.",
        "createdAt" : "2020-02-15T12:46:03Z",
        "updatedAt" : "2020-02-15T12:46:04Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "278638df00a050ebd3e742387856fb35fe13ee24",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +901,905 @@        task = self.task\n        self.test_mode = test_mode\n        self.refresh_from_task(task, pool_override=pool)\n        self.refresh_from_db(session=session)\n        self.job_id = job_id"
  },
  {
    "id" : "77201bef-e9dd-4f7d-bab7-9dfb94102faa",
    "prId" : 7576,
    "prUrl" : "https://github.com/apache/airflow/pull/7576#pullrequestreview-366323128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8109899-3c6b-4291-92ff-9925cf683868",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n                vars = [list(i) for i in airflov_context_vars.items()] \r\n                self.log.info(\"Exporting the following env vars:\\n\" + \"%s=%s\\n\" * len(vars), *sum(vars, []))\r\n```\r\nWhat do you think? In this way we will fix one pylint error (not caught yet because this file is still in todo) :)\r\n(the `sum(vars, [])` is a fastest flat map in python)\r\n\r\nEdit: that's not necessary as we only use `.format` to create arguments passed to log message.",
        "createdAt" : "2020-02-28T11:11:39Z",
        "updatedAt" : "2020-02-28T19:56:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "c341b7d590f49fd4fb4d3683ebdec238500b337c",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +920,924 @@                airflow_context_vars = context_to_airflow_vars(context, in_env_var_format=True)\n                self.log.info(\"Exporting the following env vars:\\n%s\",\n                              '\\n'.join([\"{}={}\".format(k, v)\n                                         for k, v in airflow_context_vars.items()]))\n                os.environ.update(airflow_context_vars)"
  }
]