[
  {
    "id" : "b9168b14-cb97-469a-966d-2121c3345a38",
    "prId" : 5499,
    "prUrl" : "https://github.com/apache/airflow/pull/5499#pullrequestreview-465262534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4161a02a-0e23-4a55-b059-36cd13a4cb09",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Just to confirm here, the state of SENSING just means the \"Sensor DAG\" has this task, or does it mean this TI is currently being Poked ?",
        "createdAt" : "2020-08-07T15:42:24Z",
        "updatedAt" : "2020-09-08T11:37:36Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d6bbb2f5-40b4-4d88-b1c7-148217385a50",
        "parentId" : "4161a02a-0e23-4a55-b059-36cd13a4cb09",
        "authorId" : "b2325481-de41-4b6d-a7c1-7152249759ba",
        "body" : "\"sensing\" state means this TI is currently being poked by smart sensor.",
        "createdAt" : "2020-08-11T17:05:27Z",
        "updatedAt" : "2020-09-08T11:37:36Z",
        "lastEditedBy" : "b2325481-de41-4b6d-a7c1-7152249759ba",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b5bbff3492fab908dd1c8142ba3beaa3fb274c2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +284,288 @@        # This is designed so that task logs end up in the right file.\n        # TODO: whether we need sensing here or not (in sensor and task_instance state machine)\n        if self.state in State.running():\n            return self._try_number\n        return self._try_number + 1"
  },
  {
    "id" : "1a0ea48f-524c-4906-b622-ee6b1603384a",
    "prId" : 6596,
    "prUrl" : "https://github.com/apache/airflow/pull/6596#pullrequestreview-323709508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "parentId" : null,
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "In my opinion it doesn't make sense to specify the return type if it's `None`.",
        "createdAt" : "2019-11-27T11:26:44Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "4924110b-e2cb-4eb5-a3e1-1c94bfbff885",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "There is a subtle difference explained here: https://realpython.com/python-type-checking/#functions-without-return-values  \r\n\r\nIf you specify -> None, then you will get warning if you try to assign return value to a variable. If you don't - you get no warning (None is still a valid return value that you can assign to something). So I started to add it (but not consistently, True). \r\nI might review the changes and add -> None in all the affected non-return functions and try to do it in the future as well.\r\n\r\nWDYT @feluelle ?",
        "createdAt" : "2019-11-27T13:23:32Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "89de60cd-0ba5-4cc2-96fb-4a51c3d9d259",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "If we do it consistently then I am fine with it (actually I like it more :D). Because it programming languages like Java or C# I got used to specify `void` for no return value.\r\n\r\nSo if we can somehow force this to be defined I would go for it. 👍 ",
        "createdAt" : "2019-11-27T13:58:32Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "d013f62c-0998-4478-ba1d-b1a76d3001a9",
        "parentId" : "556643bc-f654-4cc8-a460-84c6014a529e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Some time in the future :)",
        "createdAt" : "2019-11-27T14:23:03Z",
        "updatedAt" : "2019-12-03T13:41:00Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "0904b516d3537e9ca52592972e6380ee6fb25125",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +422,426 @@\n    @provide_session\n    def refresh_from_db(self, session=None, lock_for_update=False, refresh_executor_config=False) -> None:\n        \"\"\"\n        Refreshes the task instance from the database based on the primary key"
  },
  {
    "id" : "cf2b3f8e-5b5e-42cf-a88d-f8c2c2bb9239",
    "prId" : 6740,
    "prUrl" : "https://github.com/apache/airflow/pull/6740#pullrequestreview-328176986",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c7c73ea-b6ba-4dcd-bb2f-0ddddd3268e0",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "It would be great to explain why in a comment.",
        "createdAt" : "2019-12-06T09:11:05Z",
        "updatedAt" : "2019-12-12T14:03:46Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "2c7c0db8-9b51-4385-8b2a-820ef57e2f62",
        "parentId" : "7c7c73ea-b6ba-4dcd-bb2f-0ddddd3268e0",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Done",
        "createdAt" : "2019-12-06T12:37:12Z",
        "updatedAt" : "2019-12-12T14:03:46Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "fbae6ac73ac71041c17bb41c66256137810d6475",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +899,903 @@\n                task_copy = copy.copy(task)\n\n                # Sensors in `poke` mode can block execution of DAGs when running\n                # with single process executor, thus we change the mode to`reschedule`"
  },
  {
    "id" : "0a499019-b55c-4f1d-8139-74d0646d1400",
    "prId" : 6788,
    "prUrl" : "https://github.com/apache/airflow/pull/6788#pullrequestreview-371062339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b496d51-bb60-499c-8267-e9de8d490dd5",
        "parentId" : null,
        "authorId" : "6f949a1e-f537-44c5-bf07-bd4c568b44ba",
        "body" : "Quite generic question, maybe even an open discussion here.\r\nSTORE_SERIALIZED_DAGS comes from settings.py and is loaded when application (like webserver or scheduler) starts.\r\nIf we use such variables this property stops being dynamic.\r\nBut with scheduler reloading dags every now and then, it could be.\r\n\r\nDo we want to enforce that changing core.store_serialized_dags only takes effect if you restart?\r\nIt is not crucial that it is dynamic but if it can be dynamic why should not it be?",
        "createdAt" : "2020-03-08T19:37:03Z",
        "updatedAt" : "2020-03-12T00:21:48Z",
        "lastEditedBy" : "6f949a1e-f537-44c5-bf07-bd4c568b44ba",
        "tags" : [
        ]
      },
      {
        "id" : "11b56dea-c74d-45fa-b44f-fde622e041a6",
        "parentId" : "9b496d51-bb60-499c-8267-e9de8d490dd5",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "constant vs reading from `conf.getboolean` everytime wouldn't make a difference, as the `airflow.config` is loaded once at main-process start up, and the parsing sub-process forks so keeps the same loaded config -- i.e. it doesn't re-read the config file.",
        "createdAt" : "2020-03-09T10:41:58Z",
        "updatedAt" : "2020-03-12T00:21:48Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "84d5e27e49ffd0154c6a2846d33f962ab4942a8d",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +930,934 @@\n                self.render_templates(context=context)\n                if STORE_SERIALIZED_DAGS:\n                    RTIF.write(RTIF(ti=self, render_templates=False), session=session)\n                    RTIF.delete_old_records(self.task_id, self.dag_id, session=session)"
  },
  {
    "id" : "c7c22e60-b66a-4a6d-8553-928089202309",
    "prId" : 7257,
    "prUrl" : "https://github.com/apache/airflow/pull/7257#pullrequestreview-348372203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I think this attribute should always be created. If it is not needed, it should have an empty value. It is better to solve the problem of missing attributes than to hide the problem. All attributes, that the class has, should be created in the __init__ method.\r\n```python\r\nself.start_date.strftime('%Y%m%dT%H%M%S') if self.start_date else None,\r\n```\r\nThe use of getattr is a trick that allows you to write dynamic code, but we have a known class here that has known attributes.  We don't need dynamic objects here, but stable and solid types.",
        "createdAt" : "2020-01-25T12:11:07Z",
        "updatedAt" : "2020-01-25T12:29:14Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "4efa6632-38d2-44e6-8d93-30e8b9508aaf",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I agree in principle. It should be as you described. But currently we face different reality. Solving it in the way you describe is much bigger task.\r\n\r\nI just want to solve current tests not to show failures where there are no failures at all. Failing exception in \"log\" is not a good \"test\" so it does not hide the problem. Logs should never \"detect\" a problem - they should print the current state of the object and not randomly fail.\r\n\r\nRight now in logs you see unrelated failures, you have inconsistency in the way how those attributes are treated - and sometimes you think those are the problems with tests - where they aren't. \r\n\r\nSo right now I am not trying to solve this \"bigger\" problem only the small one. But I created \r\nthe issue and marked you there https://issues.apache.org/jira/browse/AIRFLOW-6640 to solve the bigger issue. ",
        "createdAt" : "2020-01-25T21:36:44Z",
        "updatedAt" : "2020-01-25T21:36:44Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "e062ffe9-cbeb-47b7-a9c9-2bdc7229e377",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Can you indicate which test has this problem?  It seems to me that the test in this place may fail only in one situation - when execution_date == None, because the existence of the attribute is guaranteed by metaclase - SQlAlchemy.",
        "createdAt" : "2020-01-26T03:59:43Z",
        "updatedAt" : "2020-01-26T03:59:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "61159875-c20b-411d-85a7-63bd9550290f",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I saw it in a few tests, but one particularly that I could see it happening was:\r\n`pytest tests/task/task_runner/test_standard_task_runner.py  -s`\r\n\r\nYou can run it in v1-10-test branch (commit ca0bbba19add1aef564c3379a9b8dfce55000cf1) to reproduce it. I have already applied this change with formatting while testing v1-10-test branch so it does not occur in the v1-10-test branch tip.\r\n\r\nI am now trying to fix all the flakiness and make v1-10-test stable and remove all the false information printed/flaky tests etc. so if you would like to spend quite some time and investigate it and make sure that it's fixed better - I am happy if you can help with this tasks. \r\n\r\nJust to give you perspective - I had quite a lot to do to fix all the various test flakiness so I have no time to analyse all the path of TaskInstance printing and adding if's is the easiest one so I do not have think about this as well. So if you have time and can do it better I am more than happy. I assigned it to you then and maybe we can fix it together: https://issues.apache.org/jira/browse/AIRFLOW-6640 \r\n",
        "createdAt" : "2020-01-26T10:59:38Z",
        "updatedAt" : "2020-01-26T10:59:38Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "da2a4288-d8b5-48a4-917b-eeba63a0da63",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "This is the error I originally had. The test was still passing and the ERROR sigterm logs were expected (on kill). But then apparently in signal processing path task instance was being printed to log and it was producing this misleading exceptions about NoneType not having strftime.  I looked at other places where task instance was printed and I simply aligned all the places to be the same (with getattr and checking for empty) - just to have a consistent approach.\r\n\r\nIf you can modify all the places to not use getattra and maybe even extract taskinstance printing to separate method and trace down where the attributes could have been missing and make sure it is all tested for all cases, I am happy if you do it. \r\n\r\nNote that you should do it for both master and v1-10-test because primary problem was in 1.10 branch.\r\n\r\n```\r\ntests/task/task_runner/test_standard_task_runner.py::TestStandardTaskRunner::test_on_kill ========================= AIRFLOW ==========================\r\nAirflow home /root/airflow\r\nHome of the user: /root\r\nSkipping initializing of the DB as it was initialized already.\r\nYou can re-initialize the database by adding --with-db-init flag when running tests.\r\n[2020-01-25 11:38:56,950] {{__init__.py:51}} INFO - Using executor SequentialExecutor\r\n[2020-01-25 11:38:56,951] {{dagbag.py:403}} INFO - Filling up the DagBag from /opt/airflow/tests/dags\r\n[2020-01-25 11:38:57,050] {test_task_view_type_check.py:50} INFO - class_instance type: <class 'unusual_prefix_5d280a9b385120fec3c40cfe5be04e2f41b6b5e8_test_task_view_type_check.CallableClass'>\r\n[2020-01-25 11:38:57,085] {{dagbag.py:271}} INFO - File /opt/airflow/tests/dags/test_zip.zip assumed to contain no DAGs. Skipping.\r\n[2020-01-25 11:38:57,144] {{standard_task_runner.py:52}} INFO - Started process 235 to run task\r\n[2020-01-25 11:38:57,196] {{dagbag.py:403}} INFO - Filling up the DagBag from /opt/airflow/tests/dags/test_on_kill.py\r\nRunning %s on host %s <TaskInstance: test_on_kill.task1 2016-01-01T00:00:00+00:00 [None]> 7f8368b91b67\r\n[2020-01-25 11:39:00,161] {{helpers.py:322}} INFO - Sending Signals.SIGTERM to GPID 235\r\n[2020-01-25 11:39:00,162] {{taskinstance.py:941}} ERROR - Received SIGTERM. Terminating subprocesses.\r\n[2020-01-25 11:39:00,164] {{test_on_kill.py:36}} INFO - Executing on_kill\r\n[2020-01-25 11:39:00,162] {{taskinstance.py:941}} ERROR - Received SIGTERM. Terminating subprocesses.\r\n[2020-01-25 11:39:00,165] {{test_on_kill.py:36}} INFO - Executing on_kill\r\n[2020-01-25 11:39:00,185] {{taskinstance.py:1122}} ERROR - Task received SIGTERM signal\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 32, in execute\r\n    os.system('sleep 10')\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n[2020-01-25 11:39:00,185] {{taskinstance.py:1122}} ERROR - Task received SIGTERM signal\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 33, in execute\r\n    time.sleep(10)\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n[2020-01-25 11:39:00,194] {{taskinstance.py:1171}} ERROR - Failed to send email to: None\r\n[2020-01-25 11:39:00,194] {{taskinstance.py:1171}} ERROR - Failed to send email to: None\r\n[2020-01-25 11:39:00,201] {{taskinstance.py:1172}} ERROR - 'NoneType' object has no attribute 'strftime'\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 33, in execute\r\n    time.sleep(10)\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 1166, in handle_failure\r\n    self.start_date.strftime('%Y%m%dT%H%M%S'),\r\nAttributeError: 'NoneType' object has no attribute 'strftime'\r\n[2020-01-25 11:39:00,201] {{taskinstance.py:1172}} ERROR - 'NoneType' object has no attribute 'strftime'\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 966, in _run_raw_task\r\n    result = task_copy.execute(context=context)\r\n  File \"/opt/airflow/tests/dags/test_on_kill.py\", line 32, in execute\r\n    os.system('sleep 10')\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 943, in signal_handler\r\n    raise AirflowException(\"Task received SIGTERM signal\")\r\nairflow.exceptions.AirflowException: Task received SIGTERM signal\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/airflow/airflow/models/taskinstance.py\", line 1166, in handle_failure\r\n    self.start_date.strftime('%Y%m%dT%H%M%S'),\r\nAttributeError: 'NoneType' object has no attribute 'strftime'\r\n[2020-01-25 11:39:00,257] {{helpers.py:288}} INFO - Process psutil.Process(pid=235, status='terminated') (235) terminated with exit code 1\r\n[2020-01-25 11:39:00,258] {{helpers.py:288}} INFO - Process psutil.Process(pid=238, status='terminated') (238) terminated with exit code None\r\n[2020-01-25 11:39:00,259] {{helpers.py:288}} INFO - Process psutil.Process(pid=237, status='terminated') (237) terminated with exit code None\r\n[2020-01-25 11:39:00,288] {{helpers.py:288}} INFO - Process psutil.Process(pid=236, status='terminated') (236) terminated with exit code None\r\nPASSED\r\n```",
        "createdAt" : "2020-01-26T11:05:50Z",
        "updatedAt" : "2020-01-26T11:05:50Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "61bb3c9c-9aa5-40b2-93f4-bf03b7cd50cf",
        "parentId" : "71bf5886-a93b-4b27-b4ae-5fb047edb59d",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Let me know how you want to proceed please :)",
        "createdAt" : "2020-01-26T11:06:44Z",
        "updatedAt" : "2020-01-26T11:06:44Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9de1854bf78afa0a9bcdf247c975ec2ff57ad2b4",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1150,1154 @@                            self,\n                            'start_date') and self.start_date else '',\n                        self.end_date.strftime('%Y%m%dT%H%M%S') if hasattr(\n                            self,\n                            'end_date') and self.end_date else '')"
  },
  {
    "id" : "e7eb7c9c-ffde-4677-8002-2071690e55c3",
    "prId" : 7324,
    "prUrl" : "https://github.com/apache/airflow/pull/7324#pullrequestreview-359343843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e650d6e-14d2-46f3-85ce-da477faa4ae7",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Is it needed here if we call `self.refresh_from_db` immediately? ",
        "createdAt" : "2020-02-15T12:33:53Z",
        "updatedAt" : "2020-02-15T12:33:54Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "39780e74-1d07-4e89-ac8e-4bce84b1cf7b",
        "parentId" : "8e650d6e-14d2-46f3-85ce-da477faa4ae7",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "This is mostly trying to preserve the existing behavior and also move some duplicated code into `refresh_from_task()`. However, you are right that this part is not perfect:\r\n\r\nIdeally we should first call `refresh_from_db()` and then call `refresh_from_task()`. The call to `refresh_from_db()` is to load those **cumulative** values such as `self.try_number` and `self.max_tries` from db so that individual runs of the task can increment these numbers. The call to `refresh_from_task()` is to get those configurable values from the latest DAG definition. However at the moment `refresh_from_db()` is loading both cumulative values and configurable attributes. So it also sets configurable values such as `self.queue` and `self.operator` which are most likely more useful to be read from DAG definition via `refresh_task()`. \r\n\r\nThis PR is not trying to fix everything. It only consolidate some duplicated code and make attributes such as `self.queue` and `self.pool` update-able when tasks are cleared in `clear_task_instances()`. It's probably worth a separate and bigger PR to make sure `refresh_from_db()` is only reading those attributes that really should come from db and leave other attributes to `refresh_from_task()`.",
        "createdAt" : "2020-02-15T12:46:03Z",
        "updatedAt" : "2020-02-15T12:46:04Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "278638df00a050ebd3e742387856fb35fe13ee24",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +901,905 @@        task = self.task\n        self.test_mode = test_mode\n        self.refresh_from_task(task, pool_override=pool)\n        self.refresh_from_db(session=session)\n        self.job_id = job_id"
  },
  {
    "id" : "77201bef-e9dd-4f7d-bab7-9dfb94102faa",
    "prId" : 7576,
    "prUrl" : "https://github.com/apache/airflow/pull/7576#pullrequestreview-366323128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8109899-3c6b-4291-92ff-9925cf683868",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n                vars = [list(i) for i in airflov_context_vars.items()] \r\n                self.log.info(\"Exporting the following env vars:\\n\" + \"%s=%s\\n\" * len(vars), *sum(vars, []))\r\n```\r\nWhat do you think? In this way we will fix one pylint error (not caught yet because this file is still in todo) :)\r\n(the `sum(vars, [])` is a fastest flat map in python)\r\n\r\nEdit: that's not necessary as we only use `.format` to create arguments passed to log message.",
        "createdAt" : "2020-02-28T11:11:39Z",
        "updatedAt" : "2020-02-28T19:56:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "c341b7d590f49fd4fb4d3683ebdec238500b337c",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +920,924 @@                airflow_context_vars = context_to_airflow_vars(context, in_env_var_format=True)\n                self.log.info(\"Exporting the following env vars:\\n%s\",\n                              '\\n'.join([\"{}={}\".format(k, v)\n                                         for k, v in airflow_context_vars.items()]))\n                os.environ.update(airflow_context_vars)"
  },
  {
    "id" : "d4e36843-1d05-468d-b362-0ca15b0f2ec8",
    "prId" : 9631,
    "prUrl" : "https://github.com/apache/airflow/pull/9631#pullrequestreview-449784711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "parentId" : null,
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "I am curious what's the contract for `get_current_context` here. For any function/method that takes context argument during task execution, should they expect the passed in context to be the same as what gets returned from `get_current_context`?\r\n\r\nAsking this because post_execute callback is not wrapped in the same context that _execute_task is in.",
        "createdAt" : "2020-07-10T17:07:49Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "03fe0b20-66d5-49fc-a75c-33eed2b046ca",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Hm, I think the `get_current_context` is only for \"functional dags\" (using `@task` to decorate functions) and there's no support for pre a post executes. So in my opinion only `execute` should be wrapped in this context. @casassg \r\n\r\nWhat is more, the context mutation does not affect the global context so it will be same in execute, post_execute etc",
        "createdAt" : "2020-07-11T11:54:24Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "dfcd4838-6d3c-43bf-a61f-e49b351e402c",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "Sounds good, just wanted to make sure this expected behavior. Probably worth documenting since the method name itself doesn't convey the message that it should only be used within functional dags.",
        "createdAt" : "2020-07-11T20:29:58Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "d0055878-6871-497c-a1c1-3d67600bacc7",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Yeah we should add a note if this is strictly for functional DAG",
        "createdAt" : "2020-07-11T21:58:57Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "dcdd1a77-921f-484d-96b3-4f85be14687e",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Since it is used only functional DAG, why are we making changes to task instanace?",
        "createdAt" : "2020-07-14T13:40:14Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "6ae19a17-f56b-4a54-828e-97924801c7d8",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "If we can move the logic into functional dag module, that would be definitely more explicit and easier to maintain going forward.",
        "createdAt" : "2020-07-14T15:14:08Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      },
      {
        "id" : "81dc383b-526a-4522-820c-f5f91a869465",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Agree. functional dag module is better for that.",
        "createdAt" : "2020-07-15T06:53:27Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "40a560fd-2d2e-4ae2-b775-6465e2bec100",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "> Since it is used only functional DAG, why are we making changes to task instanace?\r\n\r\nNot sure about this question. We make changes in ti because that's where the logic persists. Also we have to remember that the \"functiona approach\" is not only about `@task` decorator. It includes the `.output` attribute of `BaseOperator` and as discussed previously once the AIP-31 is fully implemented we should consider rewriting our documentation to encourage people to use `my_task.output` instead of `\"{{ ti.xcom_pull(...) }}\"`",
        "createdAt" : "2020-07-15T08:32:39Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "e071103c-9691-43a1-8d43-1152eb4a9081",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "d22b786b-b06e-462c-a530-7ee1b6ae12d3",
        "body" : "Yup agree to that. Also, we are modifying task instance due to this being the best module to set the current context (as it's the wrapper for any operator execution.\r\n\r\nRegarding wrapping pre_execute/post_execute, we could discuss this but  I think it should be fine for now to keep it at execute (and make sure we write docs about this)",
        "createdAt" : "2020-07-15T23:15:53Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "d22b786b-b06e-462c-a530-7ee1b6ae12d3",
        "tags" : [
        ]
      },
      {
        "id" : "bd498d20-3385-40ec-82e0-fa559e67abda",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "@mik-laj @potiuk WDYT?",
        "createdAt" : "2020-07-16T10:28:33Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "d30bbbd5-814b-47c8-9994-1f4c24c10b7c",
        "parentId" : "7573f4ca-c0db-4b39-a9d2-609e2007d46c",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Fine for me",
        "createdAt" : "2020-07-16T12:09:21Z",
        "updatedAt" : "2020-07-21T14:38:27Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa8291c6d78f34902b6d20939ee0286b75d16acf",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +1156,1160 @@\n        # Execute the task\n        with set_current_context(context):\n            result = self._execute_task(context, task_copy)\n"
  },
  {
    "id" : "9857613e-1b84-4944-ab2b-3dcfe55b4379",
    "prId" : 9674,
    "prUrl" : "https://github.com/apache/airflow/pull/9674#pullrequestreview-442859782",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12d203da-3aa4-4fa7-92a6-447c9015ab13",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I am not sure. Will it initialize both Base and Mixin :)? Just checking.",
        "createdAt" : "2020-07-05T20:41:52Z",
        "updatedAt" : "2020-07-06T13:46:53Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "a1353194-807d-498e-b488-76d176cb1827",
        "parentId" : "12d203da-3aa4-4fa7-92a6-447c9015ab13",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "As far as I understand - no -> https://stackoverflow.com/a/16310777/9713409\r\nBut it's not a problem here because we nearly never initialize the `LoggingMixin`, I think the constructor in it is part of backward compatibility ",
        "createdAt" : "2020-07-06T08:09:37Z",
        "updatedAt" : "2020-07-06T13:46:53Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "694a6e3c05f78b8be84eadf2732422d6254b7ba8",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +181,185 @@\n    def __init__(self, task, execution_date: datetime, state: Optional[str] = None):\n        super().__init__()\n        self.dag_id = task.dag_id\n        self.task_id = task.task_id"
  },
  {
    "id" : "f3b7c0c3-a113-469d-b21c-dfc9227533b1",
    "prId" : 9674,
    "prUrl" : "https://github.com/apache/airflow/pull/9674#pullrequestreview-442705052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "249a5db7-b8b7-44ce-897e-6e62a908ea2e",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "👍 ",
        "createdAt" : "2020-07-05T20:43:08Z",
        "updatedAt" : "2020-07-06T13:46:53Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "694a6e3c05f78b8be84eadf2732422d6254b7ba8",
    "line" : 119,
    "diffHunk" : "@@ -1,1 +500,504 @@            self.state = None\n\n        self.log.debug(\"Refreshed TaskInstance %s\", self)\n\n    def refresh_from_task(self, task, pool_override=None):"
  },
  {
    "id" : "ee85eca3-8f6b-46bb-9a64-71c49183790a",
    "prId" : 9674,
    "prUrl" : "https://github.com/apache/airflow/pull/9674#pullrequestreview-442705052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5df4485b-1d01-4268-aa99-39406da999ed",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "❤️ ",
        "createdAt" : "2020-07-05T20:43:40Z",
        "updatedAt" : "2020-07-06T13:46:53Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "694a6e3c05f78b8be84eadf2732422d6254b7ba8",
    "line" : 148,
    "diffHunk" : "@@ -1,1 +547,551 @@    def set_state(self, state, session=None, commit=True):\n        \"\"\"\n        Set TaskInstance state\n\n        :param state: State to set for the TI"
  },
  {
    "id" : "8c1de74f-3fc5-4252-8a9a-11cf3e8cda9c",
    "prId" : 9674,
    "prUrl" : "https://github.com/apache/airflow/pull/9674#pullrequestreview-442995086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ee1d52e-dd90-42bd-842f-9f0dc070ad55",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : ":heart: \r\n",
        "createdAt" : "2020-07-06T11:32:24Z",
        "updatedAt" : "2020-07-06T13:46:53Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "694a6e3c05f78b8be84eadf2732422d6254b7ba8",
    "line" : 412,
    "diffHunk" : "@@ -1,1 +1083,1087 @@        session.commit()\n\n    def _prepare_and_execute_task_with_callbacks(self, context, session, task):\n        \"\"\"\n        Prepare Task for Execution"
  },
  {
    "id" : "6db1b5c6-eb40-4c5e-a5c8-2d5a1e6066f8",
    "prId" : 10499,
    "prUrl" : "https://github.com/apache/airflow/pull/10499#pullrequestreview-473809558",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26bf6a4f-7781-44cd-bdb7-9b6daf22000e",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "If we decide on long names then we should remove TR from global scope, shouldn't we?",
        "createdAt" : "2020-08-24T09:22:16Z",
        "updatedAt" : "2020-08-24T19:54:38Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "d6875392-e29c-4c17-a791-eb8c4161b913",
        "parentId" : "26bf6a4f-7781-44cd-bdb7-9b6daf22000e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "> Is this another attempt to fix cyclic imports? #9674\r\n\r\nIt was not supposed to be, but it turned out to be exactly this :). ",
        "createdAt" : "2020-08-24T09:23:16Z",
        "updatedAt" : "2020-08-24T19:54:38Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "17d34414-493e-4bf3-8041-d2dd734fce4e",
        "parentId" : "26bf6a4f-7781-44cd-bdb7-9b6daf22000e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yes. ",
        "createdAt" : "2020-08-24T09:23:34Z",
        "updatedAt" : "2020-08-24T19:54:38Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "8406e56b-2673-4ea5-bb92-40f178f83143",
        "parentId" : "26bf6a4f-7781-44cd-bdb7-9b6daf22000e",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Ahh. I fixed it in a simple way I think :)",
        "createdAt" : "2020-08-24T19:53:12Z",
        "updatedAt" : "2020-08-24T19:54:38Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "139e020a22780fe950a937554a284bf956990398",
    "line" : 209,
    "diffHunk" : "@@ -1,1 +1768,1772 @@            filter_for_tis = ([and_(TaskInstance.dag_id == ti.dag_id,\n                                    TaskInstance.task_id == ti.task_id,\n                                    TaskInstance.execution_date == ti.execution_date)\n                               for ti in tis])\n            return or_(*filter_for_tis)"
  },
  {
    "id" : "ed5d3c0d-f888-4435-b701-b95d897ff8df",
    "prId" : 10632,
    "prUrl" : "https://github.com/apache/airflow/pull/10632#pullrequestreview-478116129",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03a6bac0-6aea-4d47-9593-e9347c49580c",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Isn't that microseconds ?",
        "createdAt" : "2020-08-28T19:48:48Z",
        "updatedAt" : "2020-10-23T12:38:20Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "98ef4be2-d3e3-44c1-b390-f47d70d30054",
        "parentId" : "03a6bac0-6aea-4d47-9593-e9347c49580c",
        "authorId" : "d3cb8bb5-cff2-4a3d-9608-a158861d1d07",
        "body" : "No, `time.time()` is a float value representing seconds, see the [documentation](https://docs.python.org/3/library/time.html#time.time). So `duration` is the difference, in seconds, between start and end time.",
        "createdAt" : "2020-08-29T10:09:32Z",
        "updatedAt" : "2020-10-23T12:38:20Z",
        "lastEditedBy" : "d3cb8bb5-cff2-4a3d-9608-a158861d1d07",
        "tags" : [
        ]
      }
    ],
    "commit" : "04e6a0ec0704f735170f093c916bffb87eabd6e8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1201,1205 @@\n        end_time = time.time()\n        duration = timedelta(seconds=end_time - start_time)\n        Stats.timing('dag.{dag_id}.{task_id}.duration'.format(dag_id=task_copy.dag_id,\n                                                              task_id=task_copy.task_id),"
  },
  {
    "id" : "46c8d546-80f6-451a-8de4-5cf9468cc84b",
    "prId" : 10917,
    "prUrl" : "https://github.com/apache/airflow/pull/10917#pullrequestreview-532091201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "773f00a1-812a-47bf-bdee-00808d4021d7",
        "parentId" : null,
        "authorId" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "body" : "@ashb minor change in behavior here. if user raises an exception from locally scoped class definition during task execution, we won't be able to pickle it, so we will have to serialize it as string instead. however, this should not be a breaking change since `context['exception']` has always been carrying a union type of `str` and `Exception`, so user code should not be expecting it to always be an `Exception` anyway.",
        "createdAt" : "2020-11-17T07:48:44Z",
        "updatedAt" : "2021-01-18T20:26:24Z",
        "lastEditedBy" : "00f2d683-1e14-4545-aec8-d448205f3465",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2923d61e7e51e04d176341da08b3b982e8c169a",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +125,129 @@        try:\n            pickle.dump(error, fd)\n        except Exception:  # pylint: disable=broad-except\n            # local class objects cannot be pickled, so we fallback\n            # to store the string representation instead"
  },
  {
    "id" : "1d6f1a9d-357a-4ed1-976b-c7a263b5b3a3",
    "prId" : 11147,
    "prUrl" : "https://github.com/apache/airflow/pull/11147#pullrequestreview-496673499",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1eb18b0a-1c2d-479e-a5e1-6b136091fb8d",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I'm not sure how common this case is, and if it's situational/only in our tests, but there was a case from tests when scheduling the same task on 10 dag runs -- it doesn't seem expensive to check this (as soon as the first different task id is found it'll stop) -- so excluding \"degenerate\" case where 999 tasks have the same task_id and task 1000 has a different one this'll be fine. And even then this is all in memory so should be \"fast enough\".\r\n\r\nWDYT?",
        "createdAt" : "2020-09-25T17:42:57Z",
        "updatedAt" : "2020-09-25T17:42:58Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "24fe9b44-c31a-49e1-9c69-94f77ed34149",
        "parentId" : "1eb18b0a-1c2d-479e-a5e1-6b136091fb8d",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "A case where there are tasks with same task_id inside the same dag should fail in Master / 2.0",
        "createdAt" : "2020-09-25T18:21:28Z",
        "updatedAt" : "2020-09-25T18:21:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "1e3d3575-c70e-4765-afa4-c59768652a3d",
        "parentId" : "1eb18b0a-1c2d-479e-a5e1-6b136091fb8d",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Same task_id, but different execution date.",
        "createdAt" : "2020-09-25T18:26:28Z",
        "updatedAt" : "2020-09-25T18:26:29Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "0c244faf-9d48-47e6-897a-6ff0dbf38797",
        "parentId" : "1eb18b0a-1c2d-479e-a5e1-6b136091fb8d",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "aah yes - it should still be faster than the previous code, so I am fine with this",
        "createdAt" : "2020-09-25T18:36:10Z",
        "updatedAt" : "2020-09-25T18:36:10Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "806506240bedb0bab2af245e3108c07ee5d990b3",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1827,1831 @@                TaskInstance.task_id.in_(t.task_id for t in tis),\n            )\n        if all(t.dag_id == dag_id and t.task_id == first_task_id for t in tis):\n            return and_(\n                TaskInstance.dag_id == dag_id,"
  },
  {
    "id" : "03fa74ce-1ec6-4ff7-8c6b-c3953972cd43",
    "prId" : 11335,
    "prUrl" : "https://github.com/apache/airflow/pull/11335#pullrequestreview-574024691",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "912ac255-f222-4773-8d27-8d20b9240ac1",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "Hi @kaxil , if using Airflow 2.0 or using Airflow 1.10.* with `store_serialized_dags = True` turned on, we hit this error here when user clicks on \"Rendered Template\" on tasks that are using `user_defined_macros` in jinja template fields.\r\n\r\nWe also hit a similar problem if user clears `ExternalTaskMarker` that uses `user_defined_macros` in the jinja template fields (because the `dag.clear()` function calls `ti.render_templates()` to figure out the actual values of the template fields. \r\n\r\nHow do you recommend addressing these issues going forward? Should we allow some webserver functions to get access to these `user_defined_macros`? Or should we serialize the rendered template values so that webserver can access them?",
        "createdAt" : "2021-01-21T11:54:55Z",
        "updatedAt" : "2021-01-21T11:54:55Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      },
      {
        "id" : "5603fddf-04c7-4400-b067-f26423ecbe1b",
        "parentId" : "912ac255-f222-4773-8d27-8d20b9240ac1",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "This error is already handled in the Webserver:\r\n\r\nhttps://github.com/apache/airflow/blob/10b8ecc86f24739a38e56347dcc8dc60e3e43975/airflow/www/views.py#L883-L890\r\n\r\ni.e we just ask users to run it via a CLI instead.\r\n\r\nThe `flash` message is so that they know where to look for i.e. run it using the CLI\r\n\r\nThe `ExternalTaskMarker` does it cause failure in Scheduler or Webserver ",
        "createdAt" : "2021-01-21T16:56:50Z",
        "updatedAt" : "2021-01-21T16:56:50Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "7070b0d6-451d-48f4-a146-3b55c0e89312",
        "parentId" : "912ac255-f222-4773-8d27-8d20b9240ac1",
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "Hi, @kaxil . Thanks for pointing out that the \"Rendered Template\" error is handled with an error message. Then that issue is a small annoyance for the user because they cannot see the rendered arguments in the website.\r\n\r\nHowever, the `ExternalTaskMarker` actually causes issue in the Webserver when user hits Clear. I opened an issue here https://github.com/apache/airflow/issues/13827\r\n\r\nI don't mind working on a fix. Just wondering if you have any suggestions how to do it.",
        "createdAt" : "2021-01-22T08:01:45Z",
        "updatedAt" : "2021-01-22T08:01:45Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "690e80b82b12ab1d7232d6f02ea6bddd1d71750c",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +1586,1590 @@            except (TemplateAssertionError, UndefinedError) as e:\n                raise AirflowException(\n                    \"Webserver does not have access to User-defined Macros or Filters \"\n                    \"when Dag Serialization is enabled. Hence for the task that have not yet \"\n                    \"started running, please use 'airflow tasks render' for debugging the \""
  },
  {
    "id" : "d1ba08f3-408b-4eee-a08f-df018cbaa947",
    "prId" : 11589,
    "prUrl" : "https://github.com/apache/airflow/pull/11589#pullrequestreview-522317407",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4e189df-4a71-4a97-b4c7-25c98e6e7f4d",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "It may happened that we will do `rollback` on session we already committed, is is expected @jhtimmins ? ",
        "createdAt" : "2020-11-03T09:33:23Z",
        "updatedAt" : "2020-11-03T09:33:23Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "613da86bd2bd844366d66e14f911ce7057bef43a",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1140,1144 @@        session.commit()\n\n        self._run_mini_scheduler_on_child_tasks(session)\n\n    @provide_session"
  },
  {
    "id" : "ada94017-ee74-47ed-b9b6-52aa592cafec",
    "prId" : 11815,
    "prUrl" : "https://github.com/apache/airflow/pull/11815#pullrequestreview-526303759",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19dc7009-0219-47b9-b816-510687678162",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "There are currently no tests for this method",
        "createdAt" : "2020-11-09T12:33:19Z",
        "updatedAt" : "2020-11-09T18:14:25Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "de1c2734-218d-4947-b0fd-e7b3bed8332d",
        "parentId" : "19dc7009-0219-47b9-b816-510687678162",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Added in 8d6ef136a",
        "createdAt" : "2020-11-09T14:23:11Z",
        "updatedAt" : "2020-11-09T18:14:25Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a10bba554c368c6d166c9a15db50aa4b36454ac",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +1665,1669 @@                ) from e\n\n    def get_rendered_k8s_spec(self):\n        \"\"\"Fetch rendered template fields from DB\"\"\"\n        from airflow.models.renderedtifields import RenderedTaskInstanceFields"
  },
  {
    "id" : "d848966f-98f1-485d-9939-c254f1e258de",
    "prId" : 11934,
    "prUrl" : "https://github.com/apache/airflow/pull/11934#pullrequestreview-519717810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "951ebc5f-674d-49b4-b30e-f036b45438c6",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "```suggestion\r\n                '(dag_id=%s, task_id=%s, execution_date=%s, start_date=%s, end_date=%s)',\r\n```\r\nJust an idea to make it more \"structured\" but definitely not a blocker",
        "createdAt" : "2020-10-29T14:22:26Z",
        "updatedAt" : "2020-10-29T21:42:37Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "eba1dab726a19007052ba562317d865b273cbd3d",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1089,1093 @@            self.log.info(\n                'Marking task as SKIPPED. '\n                'dag_id=%s, task_id=%s, execution_date=%s, start_date=%s, end_date=%s',\n                self.dag_id,\n                self.task_id,"
  },
  {
    "id" : "2396c39a-307d-426a-b9ec-7201b13c2e39",
    "prId" : 15382,
    "prUrl" : "https://github.com/apache/airflow/pull/15382#pullrequestreview-637413386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "def4294f-5463-4e29-9d76-bdbc227e98d1",
        "parentId" : null,
        "authorId" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "body" : "This filter is fixed. Previously it assumes execution_dates of all the DagRun are the same, which is not always true. The fix is to query by dag_id and execution_dates in a hierarchical manner.",
        "createdAt" : "2021-04-16T07:36:50Z",
        "updatedAt" : "2021-04-26T13:51:21Z",
        "lastEditedBy" : "f85ef659-e88b-40c6-856b-c86350e0d001",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a84b45dc722bfd2a45711bf56e7c23ed916127c",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +217,221 @@            .filter(\n                or_(\n                    and_(DagRun.dag_id == dag_id, DagRun.execution_date.in_(dates))\n                    for dag_id, dates in dates_by_dag_id.items()\n                )"
  },
  {
    "id" : "5a06c5a0-b18c-4646-9208-49b3a0886ddf",
    "prId" : 15912,
    "prUrl" : "https://github.com/apache/airflow/pull/15912#pullrequestreview-661823469",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e5e5d0a-d49a-4e87-a73c-099bab86862d",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This change was made because I was looking for all cases of jinaj2.Environment, and since 3 lines down we render _fixed_ templates, we know it would never product a Native object, so we don't need it.\r\n\r\nThis change isn't required here, and I can split it out to a separate PR.",
        "createdAt" : "2021-05-18T09:01:02Z",
        "updatedAt" : "2021-05-18T09:01:02Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ac177d2047508285eeea71be6d3d7449c2a90ed8",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1840,1844 @@            jinja_env = jinja2.Environment(\n                loader=jinja2.FileSystemLoader(os.path.dirname(__file__)), autoescape=True\n            )\n            subject = jinja_env.from_string(default_subject).render(**jinja_context)\n            html_content = jinja_env.from_string(default_html_content).render(**jinja_context)"
  }
]