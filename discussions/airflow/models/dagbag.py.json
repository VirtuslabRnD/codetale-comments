[
  {
    "id" : "f9104b96-00de-4e0c-b4d5-191551f78179",
    "prId" : 5350,
    "prUrl" : "https://github.com/apache/airflow/pull/5350#pullrequestreview-278819261",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "parentId" : null,
        "authorId" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "body" : "hey @XD-DENG / @feng-tao / @milton0825 \r\nabout the `dag_names = '_'.join(dag_ids)`; we have some files generating 100s of dags, which makes this metric quite unusable.\r\n- could you advise how does statsd handles such a long metric name (we are actually using a [statsd to prometheus exporter](https://github.com/prometheus/statsd_exporter) so im not that familiar with statsd)?\r\n- is it not possible to get the name of the file where the dags are generated instead?\r\n- the description in docs/metrics.rst doesn't quite match the current implementation",
        "createdAt" : "2019-08-20T16:01:29Z",
        "updatedAt" : "2019-08-20T16:01:30Z",
        "lastEditedBy" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "tags" : [
        ]
      },
      {
        "id" : "288e5ec3-3664-4476-9ca3-99d183256958",
        "parentId" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "I think it may make more sense to name the metrics by the filename given that there can be a lot of dynamic DAGs that come out of a single file.",
        "createdAt" : "2019-08-20T16:42:45Z",
        "updatedAt" : "2019-08-20T16:42:45Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      },
      {
        "id" : "004c8ebb-e06a-46de-9687-70efc39d3863",
        "parentId" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "authorId" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "body" : "Can you file a ticket in https://issues.apache.org/jira/projects/AIRFLOW/issues?",
        "createdAt" : "2019-08-20T16:43:44Z",
        "updatedAt" : "2019-08-20T16:43:45Z",
        "lastEditedBy" : "7fbede4f-85b0-4371-a620-3b1f92a91855",
        "tags" : [
        ]
      },
      {
        "id" : "6274169b-8a25-46ab-94c7-ecb001dadb8c",
        "parentId" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "authorId" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "body" : "cheers - https://issues.apache.org/jira/browse/AIRFLOW-5274",
        "createdAt" : "2019-08-21T09:09:54Z",
        "updatedAt" : "2019-08-21T09:09:54Z",
        "lastEditedBy" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "tags" : [
        ]
      },
      {
        "id" : "b6cc64dc-6da2-4190-b3fc-d66c479935aa",
        "parentId" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "@marengaz make sense. I could take this one.",
        "createdAt" : "2019-08-21T16:54:41Z",
        "updatedAt" : "2019-08-21T16:54:41Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "8f891b78-7ee9-4e34-81d9-b71090b4f34c",
        "parentId" : "41b3c785-e14d-4dcb-917a-53a67b01dec5",
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "@milton0825 @marengaz https://github.com/apache/airflow/pull/5890",
        "createdAt" : "2019-08-23T06:41:28Z",
        "updatedAt" : "2019-08-23T06:41:28Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "5375a9af21db970651c17f947558b6fc180f0dd3",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +401,405 @@            if file_stat.dag_num >= 1:\n                # if we found multiple dags per file, the stat is 'dag_id1 _ dag_id2'\n                dag_names = '_'.join(dag_ids)\n                Stats.timing('dag.loading-duration.{}'.\n                             format(dag_names),"
  },
  {
    "id" : "67442ebc-9984-49d1-a8cc-4cec3177319b",
    "prId" : 5511,
    "prUrl" : "https://github.com/apache/airflow/pull/5511#pullrequestreview-257970056",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31d33075-d32b-486d-8725-175249479115",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This works (I guess it must) even though dags is a dict?",
        "createdAt" : "2019-07-04T10:44:20Z",
        "updatedAt" : "2019-07-04T10:44:21Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "e90ec4d60b735668e532e0badf3a26763f73840d",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +294,298 @@            .join(LJ, TI.job_id == LJ.id)\n            .filter(TI.state == State.RUNNING)\n            .filter(TI.dag_id.in_(self.dags))\n            .filter(\n                or_("
  },
  {
    "id" : "4447725e-0648-4d2d-b78a-871c39522845",
    "prId" : 5890,
    "prUrl" : "https://github.com/apache/airflow/pull/5890#pullrequestreview-280858669",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d7782692-b929-4a7f-b240-52daf626df6c",
        "parentId" : null,
        "authorId" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "body" : "it's possible to have the same file name in different folders. please can we join the split, instead of just taking the filename? eg.\r\n```\r\nfilename = '.'.join(file_stat.file.split('/')).replace('.py', '')\r\n```",
        "createdAt" : "2019-08-27T08:47:44Z",
        "updatedAt" : "2019-08-27T08:47:44Z",
        "lastEditedBy" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "tags" : [
        ]
      },
      {
        "id" : "1b3ec1e4-7a89-4189-851d-afd53c2299fd",
        "parentId" : "d7782692-b929-4a7f-b240-52daf626df6c",
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "I think it would be a bad practice to have the same file name for different DAGs. If you think this would be an issue on your side, feel free to raise a pr.",
        "createdAt" : "2019-08-27T20:37:23Z",
        "updatedAt" : "2019-08-27T20:37:23Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "d5d6be14-59ed-4b1b-bb6b-680653f104bf",
        "parentId" : "d7782692-b929-4a7f-b240-52daf626df6c",
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : "Besides if we join all the subdir, it will make those stats unreadable if the dir for the dag file is very deep. Personally I am not favor of this. Not sure how other committer thinks.",
        "createdAt" : "2019-08-27T20:38:31Z",
        "updatedAt" : "2019-08-27T20:38:31Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      },
      {
        "id" : "6e24a8b5-b5c8-411d-b491-fa5b56ae2f7c",
        "parentId" : "d7782692-b929-4a7f-b240-52daf626df6c",
        "authorId" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "body" : "i was imagining a file structure like the for example. it doesn't seem too unreasonable a structure?\r\n```\r\ndag_dir\r\n   +->dag_module_1\r\n   |       +->dag_definition.py\r\n   |       |->callbacks.py\r\n   |       |->functions.py\r\n   |       |->config.json\r\n   +->dag_module_2\r\n           +->dag_definition.py\r\n           |->callbacks.py\r\n           |->functions.py\r\n           |->config.json\r\n```\r\n",
        "createdAt" : "2019-08-28T13:26:11Z",
        "updatedAt" : "2019-08-28T13:26:11Z",
        "lastEditedBy" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "tags" : [
        ]
      },
      {
        "id" : "a6011df8-816a-44ff-8bac-3a859415ccc9",
        "parentId" : "d7782692-b929-4a7f-b240-52daf626df6c",
        "authorId" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "body" : "but yea, we dont use that dir structure, so im happy with the merge :)",
        "createdAt" : "2019-08-28T14:10:28Z",
        "updatedAt" : "2019-08-28T14:10:28Z",
        "lastEditedBy" : "184cc303-98cf-4d5b-ad98-45629c6e79a0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2fad69a964db5f7ba72f2ecada78953b67b65261",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +407,411 @@        for file_stat in self.dagbag_stats:\n            # file_stat.file similar format: /subdir/dag_name.py\n            filename = file_stat.file.split('/')[-1].replace('.py', '')\n            Stats.timing('dag.loading-duration.{}'.\n                         format(filename),"
  },
  {
    "id" : "2aea6cba-6180-41f1-8173-4765da0635df",
    "prId" : 6157,
    "prUrl" : "https://github.com/apache/airflow/pull/6157#pullrequestreview-291278675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "403d2db1-a7e8-4bf5-9dff-63a047915dcd",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@milton0825 This was causing the parse time to metric to be emited as `dag.loading-duration.`. Whoops :D",
        "createdAt" : "2019-09-20T12:38:25Z",
        "updatedAt" : "2019-09-23T13:36:24Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "7b2f2e57-f2e4-45b5-a68b-73f153d0f5df",
        "parentId" : "403d2db1-a7e8-4bf5-9dff-63a047915dcd",
        "authorId" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "body" : ".....",
        "createdAt" : "2019-09-20T16:47:17Z",
        "updatedAt" : "2019-09-23T13:36:24Z",
        "lastEditedBy" : "38d80383-47b9-439a-9efe-9282f79f8b2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "3088eb9e3a0a649f980ed6d3544ffafef6799682",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +389,393 @@                    float(td.microseconds) / 1000000)\n                stats.append(FileLoadStat(\n                    filepath.replace(settings.DAGS_FOLDER, ''),\n                    td,\n                    len(found_dags),"
  },
  {
    "id" : "af6e4948-b921-489e-8090-f132b385db29",
    "prId" : 7099,
    "prUrl" : "https://github.com/apache/airflow/pull/7099#pullrequestreview-341133324",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "We don't need this, do we?",
        "createdAt" : "2020-01-08T21:08:09Z",
        "updatedAt" : "2020-01-08T21:08:10Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "16096745-903e-4ce3-a935-81ca3f2d9707",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "The following should also work:\r\n\r\n```python\r\nspec = importlib.util.spec_from_file_location(module_name, module_path)\r\nmodule = importlib.util.module_from_spec(spec)\r\nspec.loader.exec_module(module\r\n```",
        "createdAt" : "2020-01-08T21:15:38Z",
        "updatedAt" : "2020-01-08T21:15:38Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "bd9d6585-c007-4245-8415-8b9a19ea2d10",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "body" : "Thanks for you comment.\r\nWhat you suggested is actually my first approach.\r\nhttps://github.com/apache/airflow/pull/7099/commits/7fd424457a10e161e819bf376b601716e481f194\r\n\r\nBut it doesn't pass tests.",
        "createdAt" : "2020-01-08T23:05:22Z",
        "updatedAt" : "2020-01-08T23:05:22Z",
        "lastEditedBy" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "tags" : [
        ]
      },
      {
        "id" : "d62b541c-7373-4e39-baa6-5cf3004777c2",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Ok but you should not need \"sys.modules[spec.name] = m\"",
        "createdAt" : "2020-01-08T23:07:44Z",
        "updatedAt" : "2020-01-08T23:07:44Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "9bb5a3dd-54bc-4d1f-abd2-edcbf67e4468",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "body" : "It's the second approach.\r\nhttps://github.com/apache/airflow/pull/7099/commits/68c539fdcd74b900bcc60f441ac5ceb3b4f1b63d\r\nThat approach successfully finishes some test-cases that the first one fails.\r\nBut still fails a test-case.\r\n`test_backfill_job.py::TestBackfillJob::test_backfill_examples_2_example_skip_dag`",
        "createdAt" : "2020-01-08T23:39:04Z",
        "updatedAt" : "2020-01-08T23:39:50Z",
        "lastEditedBy" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "tags" : [
        ]
      },
      {
        "id" : "88001f73-7935-44e3-aae7-c20cf73e3a34",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "We shouldn't be updating the sys.modules directly.\r\n\r\nI will fallback to what other committers think @potiuk @ashb : ",
        "createdAt" : "2020-01-09T20:43:33Z",
        "updatedAt" : "2020-01-09T20:43:33Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d1cb65f7-3ed1-4a2a-9afe-0a18d98c3a68",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "body" : "FYI:\r\nThe way manipulating `sys.modules` directly is introduced in [the Python official document](https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly).",
        "createdAt" : "2020-01-10T06:56:57Z",
        "updatedAt" : "2020-01-10T06:56:58Z",
        "lastEditedBy" : "2d36589a-baf6-4b3b-974e-382691030ce5",
        "tags" : [
        ]
      },
      {
        "id" : "820ef14d-0956-4729-85eb-43f6f3c2ba20",
        "parentId" : "154f6f52-d4ce-44fe-b7c6-a8f81e418e2f",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "You are right, thanks for pointing out that link.",
        "createdAt" : "2020-01-10T12:31:26Z",
        "updatedAt" : "2020-01-10T12:31:26Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "f826a47826a2bed7a3fe9ec6db70f3da0e1f09bd",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +251,255 @@                    spec = importlib.util.spec_from_loader(mod_name, loader)\n                    m = importlib.util.module_from_spec(spec)\n                    sys.modules[spec.name] = m\n                    loader.exec_module(m)\n                    mods.append(m)"
  },
  {
    "id" : "bba0e876-1dd0-450d-a013-b4e9934f785b",
    "prId" : 7488,
    "prUrl" : "https://github.com/apache/airflow/pull/7488#pullrequestreview-362790700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89dbaa24-f93b-4346-8255-af8beef8497f",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Is this still needed in here? Feels like it shouldn't be",
        "createdAt" : "2020-02-21T16:48:15Z",
        "updatedAt" : "2020-02-21T16:48:15Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "bb8b78cc-6146-4689-9dee-b46eae07452f",
        "parentId" : "89dbaa24-f93b-4346-8255-af8beef8497f",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I don't know. I just do simple refactoring. I don't know the history of this option.",
        "createdAt" : "2020-02-21T17:23:02Z",
        "updatedAt" : "2020-02-21T17:23:02Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "27e572b9f9c56b057b85a169406f1ba1e84da927",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +83,87 @@    CYCLE_DONE = 2\n    DAGBAG_IMPORT_TIMEOUT = conf.getint('core', 'DAGBAG_IMPORT_TIMEOUT')\n    SCHEDULER_ZOMBIE_TASK_THRESHOLD = conf.getint('scheduler', 'scheduler_zombie_task_threshold')\n\n    def __init__("
  },
  {
    "id" : "32ee5800-f730-44d9-bc3a-8338d61c3f06",
    "prId" : 8739,
    "prUrl" : "https://github.com/apache/airflow/pull/8739#pullrequestreview-412767731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6910e96-d252-4be2-98bb-e4da087c0752",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "@kaxil FYI, plus the next hunk to models/s10n_dag.",
        "createdAt" : "2020-05-15T14:26:24Z",
        "updatedAt" : "2020-05-29T16:42:12Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "d6c14b96-acfa-4fad-a48a-3e5d9a9332c4",
        "parentId" : "a6910e96-d252-4be2-98bb-e4da087c0752",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Means I can do\r\n\r\n```\r\n        non_serialized_dagbag = DagBag(store_serialized_dags=False, include_examples=False)\r\n        non_serialized_dagbag.store_serialized_dags = True\r\n        non_serialized_dagbag.sync_to_db()\r\n```",
        "createdAt" : "2020-05-15T14:26:50Z",
        "updatedAt" : "2020-05-29T16:42:12Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "9817503f-e9d8-4c15-bf00-ab3c5eb645bd",
        "parentId" : "a6910e96-d252-4be2-98bb-e4da087c0752",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Nice",
        "createdAt" : "2020-05-15T15:51:23Z",
        "updatedAt" : "2020-05-29T16:42:12Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "da07181097b98a18d248607452e94bea7eea00a6",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +458,462 @@        DAG.bulk_sync_to_db(self.dags.values())\n        if self.store_serialized_dags:\n            SerializedDagModel.bulk_sync_to_db(self.dags.values())"
  },
  {
    "id" : "eb63ffee-2d72-4920-bdb2-dd200fad80b0",
    "prId" : 9676,
    "prUrl" : "https://github.com/apache/airflow/pull/9676#pullrequestreview-442710231",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0575e52f-f7df-46da-b405-8cb4136a4061",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "setf.dags.keys returns [KeysView](https://docs.python.org/3/library/collections.abc.html#collections.abc.KeysView). We want to have an non-llive object.",
        "createdAt" : "2020-07-05T22:13:18Z",
        "updatedAt" : "2020-07-05T23:43:21Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "37c8be171f88c28830a3b6d2859f9cb4e11ded20",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +108,112 @@    @property\n    def dag_ids(self) -> List[str]:\n        return list(self.dags.keys())\n\n    def get_dag(self, dag_id):"
  },
  {
    "id" : "54e55923-dffa-438c-b13f-2ab95ce96155",
    "prId" : 9836,
    "prUrl" : "https://github.com/apache/airflow/pull/9836#pullrequestreview-449050626",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d840dda6-812a-433d-ab83-dfab3c905ee8",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "Why do we want to do this? If we do this then wouldn't _every_ dagbag start writing to the DB?",
        "createdAt" : "2020-07-15T14:53:29Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "089c599c-0ced-4b25-a71d-0d183ade6786",
        "parentId" : "d840dda6-812a-433d-ab83-dfab3c905ee8",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "This is only run when dagbag.sync_to_db() is called",
        "createdAt" : "2020-07-15T14:54:06Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "d2c2b112-32b1-4932-a593-8da318d21294",
        "parentId" : "d840dda6-812a-433d-ab83-dfab3c905ee8",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "And whenever `sync_to_db` is called we want to write the SerializedDAGs to the DB if DAG Serialization was turned on.\r\n\r\n",
        "createdAt" : "2020-07-15T14:55:25Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "9d7b9a14-e369-4988-8741-c79fe774fb25",
        "parentId" : "d840dda6-812a-433d-ab83-dfab3c905ee8",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "And a note: `DagBag().sync_to_db` is only called at 2 places:\r\n\r\n1. SchedulerJob.process_file\r\n2. in `initdb`",
        "createdAt" : "2020-07-15T15:03:02Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "980fbff998d0401eb8225d9b2e4bb2520a709913",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +441,445 @@        # Write Serialized DAGs to DB if DAG Serialization is turned on\n        # Even though self.store_serialized_dags is False\n        if settings.STORE_SERIALIZED_DAGS:\n            self.log.debug(\"Calling the SerializedDagModel.bulk_sync_to_db method\")\n            SerializedDagModel.bulk_sync_to_db(self.dags.values())"
  },
  {
    "id" : "fc368efb-a8e7-49c2-811c-f9d060e796c2",
    "prId" : 9836,
    "prUrl" : "https://github.com/apache/airflow/pull/9836#pullrequestreview-449174593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5124a772-098d-4841-a8cd-5e8238cc498e",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "What do you think about rename this parameter? Its name is not correct. In my opinion, it should be called \"read_dags_from_db\" or something similar. If it had a better name from the beginning, we could avoid the current bug.",
        "createdAt" : "2020-07-15T15:01:10Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "ed311cb4-44a8-4861-9b3e-ab61db7e26c6",
        "parentId" : "5124a772-098d-4841-a8cd-5e8238cc498e",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I like the idea",
        "createdAt" : "2020-07-15T15:10:49Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "56e0ab19-ec2e-4c7f-8d40-9956d0488986",
        "parentId" : "5124a772-098d-4841-a8cd-5e8238cc498e",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Will update",
        "createdAt" : "2020-07-15T15:12:40Z",
        "updatedAt" : "2020-07-15T16:43:29Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "342b1b72-ac65-46e6-826b-26be639bcea8",
        "parentId" : "5124a772-098d-4841-a8cd-5e8238cc498e",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "I have renamed it in another PR : https://github.com/apache/airflow/pull/9838",
        "createdAt" : "2020-07-15T17:25:10Z",
        "updatedAt" : "2020-07-15T17:25:11Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "980fbff998d0401eb8225d9b2e4bb2520a709913",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +70,74 @@        with airflow or not\n    :type include_examples: bool\n    :param store_serialized_dags: Read DAGs from DB if store_serialized_dags is ``True``.\n        If ``False`` DAGs are read from python files. This property is not used when\n        determining whether or not to write Serialized DAGs, that is done by checking"
  },
  {
    "id" : "9861b631-06f8-47af-b17a-fe1cde2e4457",
    "prId" : 9851,
    "prUrl" : "https://github.com/apache/airflow/pull/9851#pullrequestreview-450592670",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea145352-639f-45c7-b388-fd322cbc6a01",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We can return here -- if we've just loaded it we don't need to do any of these checks, do we?",
        "createdAt" : "2020-07-17T09:09:59Z",
        "updatedAt" : "2020-07-20T11:43:20Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "34a5e3d5-0b05-47e8-8bef-8e283a22d5e7",
        "parentId" : "ea145352-639f-45c7-b388-fd322cbc6a01",
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Updated in https://github.com/apache/airflow/pull/9851/commits/02856d63a5d500788c8aab7c49a235b036800364",
        "createdAt" : "2020-07-17T11:50:46Z",
        "updatedAt" : "2020-07-20T11:43:20Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      }
    ],
    "commit" : "cf554414b4f0523bd2a12807054b852931138b34",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +150,154 @@            if dag_id not in self.dags:\n                # Load from DB if not (yet) in the bag\n                self._add_dag_from_db(dag_id=dag_id)\n                return self.dags.get(dag_id)\n"
  },
  {
    "id" : "e9c4c59e-9ab6-4172-94ed-0e487dfe1b59",
    "prId" : 10282,
    "prUrl" : "https://github.com/apache/airflow/pull/10282#pullrequestreview-464539715",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90e42feb-ff1f-4836-bc77-4ba6e40436d7",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This change is not covered by the unit tests.",
        "createdAt" : "2020-08-10T20:03:53Z",
        "updatedAt" : "2020-08-12T20:01:14Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4b13ba1bd061eaf40902563b128c7b92db7c588",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +345,349 @@                    file_last_changed_on_disk\n            except (AirflowDagCycleException,\n                    AirflowClusterPolicyViolation) as exception:\n                self.log.exception(\"Failed to bag_dag: %s\", dag.full_filepath)\n                self.import_errors[dag.full_filepath] = str(exception)"
  },
  {
    "id" : "cd1d4223-ae30-4ef7-b0e0-7a45b6c62fe5",
    "prId" : 10956,
    "prUrl" : "https://github.com/apache/airflow/pull/10956#pullrequestreview-503328327",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fd98b81-5d63-4aef-86bd-601d6cf3a74f",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Can you tell a little more about it? How do you want serialization of the same object to a database to produce different results?  Is it by adding the `next_dagrun`, `next_dagrun_create_after` fields to the DAG in the sync_to_db method?",
        "createdAt" : "2020-09-16T10:55:14Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "67344493-e07d-4891-ace9-85a82fa461f4",
        "parentId" : "9fd98b81-5d63-4aef-86bd-601d6cf3a74f",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "@ashb can you please take a look here?",
        "createdAt" : "2020-10-05T10:16:33Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "757bf66d-d31d-471a-9e62-970da6b8c32b",
        "parentId" : "9fd98b81-5d63-4aef-86bd-601d6cf3a74f",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "This change was a bit of a hack here, and we'll tidy it up.\r\n\r\nSince the scheduler now requires DAG serialization to operate, we need a way for dag bags to Load dags from given files only, and not from the DB, but then also a way to make them _write_ things back to the DB.\r\n\r\nWe'll pull this out in to a separate PR, essentially removing the `STORE_SERIALIZED_DAGS` option entirely, and then this bulk_sync_to_db can then just always write to the DB.",
        "createdAt" : "2020-10-06T20:21:52Z",
        "updatedAt" : "2020-10-09T20:52:25Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee0a79a69534e5b3f969e3b496d9518c8e735fe2",
    "line" : 119,
    "diffHunk" : "@@ -1,1 +536,540 @@        # Write Serialized DAGs to DB if DAG Serialization is turned on\n        # Even though self.read_dags_from_db is False\n        if settings.STORE_SERIALIZED_DAGS or self.read_dags_from_db:\n            self.log.debug(\"Calling the SerializedDagModel.bulk_sync_to_db method\")\n            SerializedDagModel.bulk_sync_to_db(self.dags.values(), session=session)"
  },
  {
    "id" : "0c0cea45-a09f-493b-8e2d-440ae4a40b96",
    "prId" : 11344,
    "prUrl" : "https://github.com/apache/airflow/pull/11344#pullrequestreview-504956436",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95a4d729-db92-4f90-a1f3-d27cf70c1973",
        "parentId" : null,
        "authorId" : "c25957e2-1132-4c48-a536-3824307fd862",
        "body" : "Can we add a simple test case for this, i.e. to show what happens when a garbage value is provided to schedule-interval it throws an error",
        "createdAt" : "2020-10-08T10:19:27Z",
        "updatedAt" : "2020-10-09T06:41:39Z",
        "lastEditedBy" : "c25957e2-1132-4c48-a536-3824307fd862",
        "tags" : [
        ]
      },
      {
        "id" : "0dd1e02f-1986-4355-8036-ac95ecd5d3ea",
        "parentId" : "95a4d729-db92-4f90-a1f3-d27cf70c1973",
        "authorId" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "body" : "@kaxil found that such a testcase already exists, so added a check to assert the dagbag size on top of it. ",
        "createdAt" : "2020-10-08T16:23:43Z",
        "updatedAt" : "2020-10-09T06:41:39Z",
        "lastEditedBy" : "73893400-eac1-4c2c-8fdc-49a7c6b2dae8",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6428592064a2b96c1e0318b1c41689b813df6b0",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +355,359 @@                if isinstance(dag.normalized_schedule_interval, str):\n                    croniter(dag.normalized_schedule_interval)\n                self.bag_dag(dag=dag, root_dag=dag)\n                found_dags.append(dag)\n                found_dags += dag.subdags"
  },
  {
    "id" : "349d7df4-9b6b-492d-aa4b-718ae8867e2e",
    "prId" : 12184,
    "prUrl" : "https://github.com/apache/airflow/pull/12184#pullrequestreview-525836395",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d8f4804-9b50-49a7-a4b9-137a0e179e0f",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Here we should check if 'policy' is defined and run it as well but with deprecation warning.",
        "createdAt" : "2020-11-08T18:08:01Z",
        "updatedAt" : "2020-11-13T10:57:33Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "b54c2880-7fca-4744-a15c-0dc0fc0f3e5f",
        "parentId" : "6d8f4804-9b50-49a7-a4b9-137a0e179e0f",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Done, this is what users will see:\r\n```\r\nroot@817b1471dabe:/opt/airflow# airflow scheduler\r\n/opt/airflow/airflow/models/dag.py:61: DeprecationWarning: Using `policy` in airflow_local_settings.py is deprecated. Please rename your `policy` to `task_policy`.\r\n  from airflow.models.dagbag import DagBag\r\n  ____________       _____________\r\n ____    |__( )_________  __/__  /________      __\r\n____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\r\n___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\r\n _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\r\n[2020-11-08 19:09:09,005] {scheduler_job.py:1248} INFO - Starting the scheduler\r\n[2020-11-08 19:09:09,005] {scheduler_job.py:1253} INFO - Processing each file at most -1 times\r\n[2020-11-08 19:09:09,114] {scheduler_job.py:1275} INFO - Resetting orphaned tasks for active dag runs\r\n```",
        "createdAt" : "2020-11-08T19:13:45Z",
        "updatedAt" : "2020-11-13T10:57:33Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "340c13062a1aa8906afaa5765bd3ff3141b2f852",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +391,395 @@\n        for task in dag.tasks:\n            settings.task_policy(task)\n\n        subdags = dag.subdags"
  }
]