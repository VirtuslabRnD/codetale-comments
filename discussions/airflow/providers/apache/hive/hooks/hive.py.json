[
  {
    "id" : "c1a59d12-d5b3-49f7-8c7c-cf40173351f5",
    "prId" : 9472,
    "prUrl" : "https://github.com/apache/airflow/pull/9472#pullrequestreview-442059133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80584a89-1c62-4c24-8787-cff4f83cf5d6",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Please add type annotations",
        "createdAt" : "2020-07-02T10:48:45Z",
        "updatedAt" : "2020-07-17T19:59:47Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "7060b836-151d-413f-89e3-ab2eb1103681",
        "parentId" : "80584a89-1c62-4c24-8787-cff4f83cf5d6",
        "authorId" : "df24ac26-f47a-4f26-8647-e612bec62587",
        "body" : "Done",
        "createdAt" : "2020-07-02T22:50:59Z",
        "updatedAt" : "2020-07-17T19:59:47Z",
        "lastEditedBy" : "df24ac26-f47a-4f26-8647-e612bec62587",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2a464daedf896e720b65ef0289605196db02295",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +776,780 @@            return False\n\n    def drop_partitions(self, table_name, part_vals, delete_data=False, db='default'):\n        \"\"\"\n        Drop partitions from the given table matching the part_vals input"
  },
  {
    "id" : "ba7b7aaf-7989-497c-8a1b-a9568d74bcbe",
    "prId" : 9472,
    "prUrl" : "https://github.com/apache/airflow/pull/9472#pullrequestreview-442059222",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74bfe29d-2acb-4b18-ba61-d618f152964f",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Please add arguments information using `:param xxx:` and `:type xxx:`",
        "createdAt" : "2020-07-02T10:49:14Z",
        "updatedAt" : "2020-07-17T19:59:47Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "790dd1c8-ea25-4d23-9c9a-363b1343f028",
        "parentId" : "74bfe29d-2acb-4b18-ba61-d618f152964f",
        "authorId" : "df24ac26-f47a-4f26-8647-e612bec62587",
        "body" : "Done!",
        "createdAt" : "2020-07-02T22:51:14Z",
        "updatedAt" : "2020-07-17T19:59:47Z",
        "lastEditedBy" : "df24ac26-f47a-4f26-8647-e612bec62587",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2a464daedf896e720b65ef0289605196db02295",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +793,797 @@        >>> hh.drop_partitions(db='airflow', table_name='static_babynames',\n        part_vals=\"['2020-05-01']\")\n        True\n        \"\"\"\n        if self.table_exists(table_name, db):"
  },
  {
    "id" : "8b7217f4-f843-45e6-8bb4-aeded2e5cca4",
    "prId" : 12466,
    "prUrl" : "https://github.com/apache/airflow/pull/12466#pullrequestreview-536806608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b3d88f1-06b1-48ab-89c2-9fc46c9a4337",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "We could, if we wanted, use `inspect.signature` to get the default value for the hook:\r\n\r\n```ipython\r\nIn [3]: from airflow.providers.apache.hive.hooks.hive import HiveCliHook                                                                                                                                                                                                                                    \r\n\r\nIn [4]: import inspect                                                                                                                                                                                                                                                                                      \r\n\r\nIn [5]: inspect.signature(HiveCliHook).parameters['hive_cli_conn_id'].default                                                                                                                                                                                                                               \r\nOut[5]: 'hive_cli_default'\r\n```\r\n\r\nNot needed, and might be overkill, but is just one less thing to need in the \"interface\"",
        "createdAt" : "2020-11-23T14:06:45Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "131b080c-d86e-4c72-91f5-29c6a526d229",
        "parentId" : "0b3d88f1-06b1-48ab-89c2-9fc46c9a4337",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I want to do a miniumum set of changes for this discovery to pass, we can definitely improve it in the future. ",
        "createdAt" : "2020-11-23T14:40:51Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "4e2edfae-dd0e-494c-818a-9b4cad91db0e",
        "parentId" : "0b3d88f1-06b1-48ab-89c2-9fc46c9a4337",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I really want to avoid creating new \"Hook\" interface now. My goal is to have provider hook discovery for now. Adding, standardizing documenting and polishing \"common Hook API\"  should be next step IMHO - possibly at the time when we introduce reading Hooks via \" plugin-lilke\" interface.",
        "createdAt" : "2020-11-23T14:45:38Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "92e805bc-55a6-42dd-95c0-0b73ab0827fc",
        "parentId" : "0b3d88f1-06b1-48ab-89c2-9fc46c9a4337",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "You might not have explicitly stated it, but this is creating a new Hook interface.\r\n\r\nI guess the main thing is this is opt-in, so existing sub-classes don't suddenly break. Good point. :+1: ",
        "createdAt" : "2020-11-23T20:06:28Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      }
    ],
    "commit" : "034c19e23cbd96c064866eae0ab99ffa6e33189c",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +85,89 @@    def __init__(\n        self,\n        hive_cli_conn_id: str = default_conn_name,\n        run_as: Optional[str] = None,\n        mapred_queue: Optional[str] = None,"
  },
  {
    "id" : "ce5ee9d6-d5bb-45d5-b50f-b2c4e2c34c0f",
    "prId" : 12466,
    "prUrl" : "https://github.com/apache/airflow/pull/12466#pullrequestreview-537429093",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e9475bc-1cdd-4e7d-a4dd-b3efa3de04bd",
        "parentId" : null,
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "What was your thinking for `conn_name_attr` instead of `CONN_NAME_ATTR`?\r\n\r\n(My default would be to use the latter, as it's a common signifier that it's a constant.)",
        "createdAt" : "2020-11-23T14:12:31Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "db7034f0-aeb5-4263-832b-473ee3bfa677",
        "parentId" : "6e9475bc-1cdd-4e7d-a4dd-b3efa3de04bd",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Just following \"do the same as others\"  simply we already had other connection class attributes lowercase (convention used in the SQL Hooks). So I just followed it.",
        "createdAt" : "2020-11-23T14:39:50Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "863b6ac1-e655-472c-80e8-56fb10188dc4",
        "parentId" : "6e9475bc-1cdd-4e7d-a4dd-b3efa3de04bd",
        "authorId" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "body" : "I'm not sure the convention from SQL hooks is the best one -- those are some of the oldest parts of Airflow and not very \"Good Practice\".\r\n\r\nI'm okay with it if you think this way is better, but may other places in Airflow we have UPPERCASE style.",
        "createdAt" : "2020-11-23T20:07:31Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "f73f66ab-2657-4a50-be7a-2ca3ca98c202",
        "tags" : [
        ]
      },
      {
        "id" : "6cfcfbc6-fbce-457b-adb1-e16668f2c6a4",
        "parentId" : "6e9475bc-1cdd-4e7d-a4dd-b3efa3de04bd",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I fully agree. But I did not want to break the compatibility (potentially someone could have used those values - especially the defaults. And my goal was just to make it works for providers, not having to deal with back-compatibility :). \r\n\r\nThere is a polish sentence I tend to use in such cases which I learned from my friend (but it has some curse-words and rhymes, so I won't translate it here verbatim, but it roughly translates to \"consistent is better than perfect\".\r\n\r\nI fully agree constants *should* be UPPERCASE of course. \r\n",
        "createdAt" : "2020-11-24T12:08:56Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "4477b9cd-b379-4ef2-a8aa-eec21f95ede3",
        "parentId" : "6e9475bc-1cdd-4e7d-a4dd-b3efa3de04bd",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "BTW. Happy to make a change later (maybe even we manage in 2.0 if you think it's ok to break compatibility with the names. Once it is consistent, we can do global rename.",
        "createdAt" : "2020-11-24T12:10:00Z",
        "updatedAt" : "2020-11-29T13:02:51Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "034c19e23cbd96c064866eae0ab99ffa6e33189c",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +79,83 @@    \"\"\"\n\n    conn_name_attr = 'hive_cli_conn_id'\n    default_conn_name = 'hive_cli_default'\n    conn_type = 'hive_cli'"
  }
]