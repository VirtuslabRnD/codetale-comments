[
  {
    "id" : "3006f07c-ad9f-49fd-b079-16d6a1c700d6",
    "prId" : 8145,
    "prUrl" : "https://github.com/apache/airflow/pull/8145#pullrequestreview-391747222",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c103bcf7-2109-4aef-915d-69e10bf299fa",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think it needs an entry in UPDATING.md. If someone uses positional args - it will break.",
        "createdAt" : "2020-04-09T18:06:17Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "69aa1098-d514-4547-bab7-05bf51725cd2",
        "parentId" : "c103bcf7-2109-4aef-915d-69e10bf299fa",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This method must be called using keywords arguments. Please look at this expectation added by @potiuk  https://github.com/apache/airflow/blob/master/airflow/providers/google/common/hooks/base_google.py#L333-L336\r\n\r\n",
        "createdAt" : "2020-04-11T02:00:29Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "2f61aaf9-87f5-44a3-8737-f47926fc2111",
        "parentId" : "c103bcf7-2109-4aef-915d-69e10bf299fa",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Ah.. Right :) ",
        "createdAt" : "2020-04-11T08:18:47Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "5cb1e35a-d728-4454-bfd1-b77c14bd66de",
        "parentId" : "c103bcf7-2109-4aef-915d-69e10bf299fa",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Totally forgot about it ! It was some 1.5 year ago! Thanks @mik-laj for reminding :)",
        "createdAt" : "2020-04-11T08:19:33Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "f33e29ec38375da3d79fc3df5ce5e2b2a8a0bb7d",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +580,584 @@        dataflow: str,\n        py_options: List[str],\n        project_id: str,\n        py_interpreter: str = \"python3\",\n        py_requirements: Optional[List[str]] = None,"
  },
  {
    "id" : "0c26dc17-f7ef-46cd-b910-11bb8e25cec2",
    "prId" : 8145,
    "prUrl" : "https://github.com/apache/airflow/pull/8145#pullrequestreview-391725798",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d992e6b-603a-4b3c-8734-31f68bcd32ff",
        "parentId" : null,
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Same here -> I think it needs UPDATING.md entry",
        "createdAt" : "2020-04-09T18:06:38Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      },
      {
        "id" : "e42ec268-9247-47c3-9d1e-ba5db3cc7b7d",
        "parentId" : "4d992e6b-603a-4b3c-8734-31f68bcd32ff",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "It is the only keyword argument method. ",
        "createdAt" : "2020-04-11T02:01:00Z",
        "updatedAt" : "2020-04-12T21:39:47Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "f33e29ec38375da3d79fc3df5ce5e2b2a8a0bb7d",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +719,723 @@    def cancel_job(\n        self,\n        project_id: str,\n        job_name: Optional[str] = None,\n        job_id: Optional[str] = None,"
  },
  {
    "id" : "807642a1-bcbf-48d7-b5cf-4671a2c3371d",
    "prId" : 8531,
    "prUrl" : "https://github.com/apache/airflow/pull/8531#pullrequestreview-401375232",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9938527a-7225-4b96-8cfd-2e846043b20b",
        "parentId" : null,
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "What is the difference between parameters and variables?",
        "createdAt" : "2020-04-27T20:53:08Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "67f641a2-b5c3-4753-b8a9-8e044bf68622",
        "parentId" : "9938527a-7225-4b96-8cfd-2e846043b20b",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is problematic, but someone once created a parameter and called `variables`.  He used the same name elsewhere. Now I am trying to maintain backward compatibility. In the next PR I will try to change the names of the arguments, but this will require more work to maintain backward compatibility. \r\n\r\nFormerly `variables` parameters contain environments + project id + region. It was similar to the native pipeline, where the region was also passed as an argument. `python pipeline.py --region=europe-west-1`.  However, this was changed when I introduced the changes required by the [GCP guidelines](https://docs.google.com/document/d/1_rTdJSLCt0eyrAylmmgYc3yZr-_h51fVlnvMmWqhCkY/edit).  Now it contains only environment parameters ",
        "createdAt" : "2020-04-27T21:48:09Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "c293cfbe-c5a0-451b-8157-0ee42df606f4",
        "parentId" : "9938527a-7225-4b96-8cfd-2e846043b20b",
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "got it. thank you for cleaning things, and keeping them backward compatible.\r\n\r\nHow about adding a new clean flag and marking the old one as deprecated?",
        "createdAt" : "2020-04-27T21:58:31Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "d13bc8ed-b645-4828-849a-aef10e4ece6d",
        "parentId" : "9938527a-7225-4b96-8cfd-2e846043b20b",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I want to change names for more parameters in many places. I will probably do it with a special decorator that will allow me to do it cleverly.\r\n```\r\n    @rename_parameter({'variables': 'environment'})\r\n    def start_template_dataflow(\r\n        self,\r\n        job_name: str,\r\n        variables: Dict,\r\n        parameters: Dict,\r\n        dataflow_template: str,\r\n        project_id: str,\r\n        append_job_name: bool = True,\r\n        on_new_job_id_callback: Optional[Callable[[str], None]] = None,\r\n        location: str = DEFAULT_DATAFLOW_LOCATION\r\n    ) -> Dict:\r\n```\r\nThat way, we won't have so much outdated code in the repository.\r\n\r\nThis change from a perspective will be much more problematic and I would like to test it in various IDEs, etc\r\n![Screenshot 2020-04-28 at 00 31 57](https://user-images.githubusercontent.com/12058428/80427302-bee93980-88e7-11ea-97bb-a8b0bdbec6f2.png)\r\nI would like to get similar messages when the user updates the operator.\r\n\r\nIt looks simple but still needs testing and I will do it in a separate PR.\r\n",
        "createdAt" : "2020-04-27T22:35:13Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfbd059cf157beee09569649b54ecd1c185366ce",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +564,568 @@                \"jobName\": name,\n                \"parameters\": parameters,\n                \"environment\": variables\n            }\n        )"
  },
  {
    "id" : "40885b35-05ca-4170-b921-d6af777f3117",
    "prId" : 8531,
    "prUrl" : "https://github.com/apache/airflow/pull/8531#pullrequestreview-401350718",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75d0d0f1-392a-4019-bd74-3759dfc33c60",
        "parentId" : null,
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "Is this bug ( #8300) only affecting templates?",
        "createdAt" : "2020-04-27T21:27:08Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "8923f88a-eeef-41d7-8729-9350051af049",
        "parentId" : "75d0d0f1-392a-4019-bd74-3759dfc33c60",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Yes. It only affects templates.  Native pipelines were not affected by this issue.",
        "createdAt" : "2020-04-27T21:46:10Z",
        "updatedAt" : "2020-05-06T01:04:43Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfbd059cf157beee09569649b54ecd1c185366ce",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +531,535 @@        Starts Dataflow template job.\n\n        :param job_name: The name of the job.\n        :type job_name: str\n        :param variables: Map of job runtime environment options."
  },
  {
    "id" : "e64d3f4a-c6e5-444f-abd5-e09c3c6ec665",
    "prId" : 8550,
    "prUrl" : "https://github.com/apache/airflow/pull/8550#pullrequestreview-498374938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d63dc0e-7868-4123-835b-935918035c06",
        "parentId" : null,
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "This file is also modified in https://github.com/apache/airflow/pull/8553. I am assuming it is the same changes, skipping this file for the review.",
        "createdAt" : "2020-04-27T20:41:35Z",
        "updatedAt" : "2020-10-16T10:12:46Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "dee801ca-4a5e-46ff-ad3b-caf1e06b9165",
        "parentId" : "1d63dc0e-7868-4123-835b-935918035c06",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "I replied here https://github.com/apache/airflow/pull/8553#discussion_r496513620 and changed here https://github.com/apache/airflow/pull/8550/commits/92858ebbc39c242376304d4a9d9106263aed7369",
        "createdAt" : "2020-09-29T11:35:27Z",
        "updatedAt" : "2020-10-16T10:12:46Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "e204c619e44f8eaf60769273925bb60b968231d2",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +97,101 @@    \"\"\"\n    Helper class with Dataflow job statuses.\n    Reference: https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState\n    \"\"\"\n"
  },
  {
    "id" : "cb585454-404a-418e-b7ea-caa1f7598a18",
    "prId" : 8550,
    "prUrl" : "https://github.com/apache/airflow/pull/8550#pullrequestreview-414755157",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d54dbf38-e49e-4d2d-b92e-d8d5194125a8",
        "parentId" : null,
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "@mik-laj was reflecting on this in light of the data fusion operator issue.\r\nThis is \"start\" naming confusing.\r\n\r\nThis method (and Dataflow*Start*FlexTemplateOperator) are called \"start\" flex template but this appears like you are waiting for the job to complete.\r\n\r\nThe existing dataflow operators do not have this start word and I think the user expectation is that they poll the job to completion. Otherwise you can't do much useful downstream in the DAG without having some sensor that waits on this job completion.\r\n\r\nIf we want to support blocking or not blocking I'd suggest having a `wait_for_done` kwarg that defaults to `True` (the expected behavior based on similar operators). This might mean that we need a new method in the controller `wait_for_running` that blocks until the pipeline enters the RUNNING state.\r\n\r\nWhat do you think?\r\n\r\nsame applies for #8553 ",
        "createdAt" : "2020-05-19T18:08:24Z",
        "updatedAt" : "2020-10-16T10:12:46Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "c7d10f6c-af7f-476b-a1b5-fe98a6dbc98c",
        "parentId" : "d54dbf38-e49e-4d2d-b92e-d8d5194125a8",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I am trying to imitate the naming conventions that we currently have in this integration.\r\nDataflowTemplatedJobStartOperator\r\nIt uses the verb \"Start\" to describe identical operations.  \r\n\r\nI plan to add a blocking and non-blocking mode to all operators in a separate PR, because this requires the development of sensors. For now, I only wanted to focus on one issue.",
        "createdAt" : "2020-05-19T19:24:49Z",
        "updatedAt" : "2020-10-16T10:12:46Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "e204c619e44f8eaf60769273925bb60b968231d2",
    "line" : 162,
    "diffHunk" : "@@ -1,1 +690,694 @@            num_retries=self.num_retries,\n        )\n        jobs_controller.wait_for_done()\n\n        return jobs_controller.get_jobs(refresh=True)[0]"
  },
  {
    "id" : "47305a03-bb75-47d4-9999-fbd3a05e323f",
    "prId" : 8553,
    "prUrl" : "https://github.com/apache/airflow/pull/8553#pullrequestreview-503925609",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "parentId" : null,
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "What does shlex.quote() do?",
        "createdAt" : "2020-04-27T20:35:28Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "396e9bae-814c-41e5-872c-37f9f7b4facb",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Adds escape characters if needed. \r\nExample:\r\nIf you want to display the contents of the `/tmp/` directory then you can use the command `ls /tmp/`\r\nIf you want to display the contents of the `/tmp/i love pizza` directory then you can use the command `ls '/tmp/ i love pizza'`. `ls /tmp/i love pizza` is incorrect command. The decision about quotation characeters was made by shlex.quote. This also supports other cases required by sh e.g. quote character in an argument\r\n",
        "createdAt" : "2020-04-27T21:10:10Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "8f88e561-d176-4a61-bab4-eb35a37ecc27",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "but this is only for logging? Do users normally copy paste these commands out of the logs?",
        "createdAt" : "2020-04-27T21:56:55Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "12cabaa5-a6b3-4abb-8065-c847ef4e967c",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is only for logs. I used it to test this operator.  A normal user will not copy it, but it may be helpful to him for debugging only.",
        "createdAt" : "2020-04-27T22:16:57Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "3b372f22-e6c4-4617-9818-5ddcd266f009",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "These logs are available in Airflow Web UI, so a normal user can easily access them.",
        "createdAt" : "2020-04-27T22:21:13Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "2da09d72-c086-4b8b-88fd-f9a52195751c",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "body" : "Is this really required if it is only for logs? subprocess.run does not need to escape them anyway.",
        "createdAt" : "2020-04-28T02:42:09Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "faa559fa-1122-468b-8ebd-7d04c5c97279",
        "tags" : [
        ]
      },
      {
        "id" : "c464d5d7-6979-4693-8df9-351be146fbae",
        "parentId" : "05f3770c-3a9d-4c31-9a44-3af9e334bede",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "IMHO it is not particularly required but nice to have it :)",
        "createdAt" : "2020-10-07T14:13:44Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "92d18b05df81205d9d36863dca57c4358b57ee53",
    "line" : 494,
    "diffHunk" : "@@ -1,1 +981,985 @@        ]\n        self.log.info(\"Executing command: %s\", \" \".join([shlex.quote(c) for c in cmd]))\n        with self.provide_authorized_gcloud():\n            proc = subprocess.run(  # pylint: disable=subprocess-run-check\n                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE"
  },
  {
    "id" : "cce54d45-4a4f-46c6-9382-7cdd574fb69f",
    "prId" : 8553,
    "prUrl" : "https://github.com/apache/airflow/pull/8553#pullrequestreview-508216516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ea7f240-8af0-4c76-85a3-b4e52033e881",
        "parentId" : null,
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "This makes me think (larger scope than just SQL operator) of should we have Beam Operators that support other runners?\r\n\r\nFor example some users it does not make sense Dataflow for smaller/shorter batch jobs say (because you have the overhead of waiting for workers to come up) For a job < 30 mins worker spin up time can be 10% performance hit. But they may still want to use Apache Beam (on say spark runner) that submits to non-ephemeral cluster (dataproc, EMR, spark on k8s, on prem infra, etc). \r\n\r\nWould this be easy enough to achieve on Dataproc / EMR / Spark Operators ? ",
        "createdAt" : "2020-05-02T19:22:45Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "5ba62d0d-dea8-4a8e-aed6-7c384c73850d",
        "parentId" : "4ea7f240-8af0-4c76-85a3-b4e52033e881",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "It will be quite huge task to write Apache Beam Hooks and Operators but worth to keep it in mind to do this in future.",
        "createdAt" : "2020-10-14T10:33:52Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      },
      {
        "id" : "00f8c58b-9407-4493-b763-d1f07284dc57",
        "parentId" : "4ea7f240-8af0-4c76-85a3-b4e52033e881",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "In current Q, we want to start working on operators for Apache Beam.",
        "createdAt" : "2020-10-14T10:40:37Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      }
    ],
    "commit" : "92d18b05df81205d9d36863dca57c4358b57ee53",
    "line" : 240,
    "diffHunk" : "@@ -1,1 +480,484 @@    ) -> None:\n        cmd = command_prefix + [\n            \"--runner=DataflowRunner\",\n            f\"--project={project_id}\",\n        ]"
  },
  {
    "id" : "86e0e7ab-119c-45af-886e-2bd0b62c73cd",
    "prId" : 8553,
    "prUrl" : "https://github.com/apache/airflow/pull/8553#pullrequestreview-512162018",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d6481fae-30cf-41aa-8a37-8c480bab132b",
        "parentId" : null,
        "authorId" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "body" : "Unless you have a good reason to rename this `location`, I would use `region` because it is more specific and consistent with Beam/Dataflow usage.\r\n",
        "createdAt" : "2020-05-05T19:19:32Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "tags" : [
        ]
      },
      {
        "id" : "37f18a70-e912-44c0-a2f0-774cdc8b882e",
        "parentId" : "d6481fae-30cf-41aa-8a37-8c480bab132b",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "The main reason behind it is to keep consistency across all google provider which uses `location` parameter.",
        "createdAt" : "2020-10-14T10:36:29Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      },
      {
        "id" : "f1e23525-b048-4088-8bea-8448ec5028ed",
        "parentId" : "d6481fae-30cf-41aa-8a37-8c480bab132b",
        "authorId" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "body" : "I'm not sure which other GCP products you are referring to, but in Dataflow it's usually `--region`.\r\nhttps://cloud.google.com/dataflow/docs/concepts/regional-endpoints",
        "createdAt" : "2020-10-19T20:07:45Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "tags" : [
        ]
      },
      {
        "id" : "4016edae-8d25-4975-99ea-a4192158a8e4",
        "parentId" : "d6481fae-30cf-41aa-8a37-8c480bab132b",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "This is an essential feature of Airflow. In Airflow, you can define default arguments that will be all operators, but the parameter name must be consistent across all operators.\r\n```python\r\ndefault_args = {\r\n    'dataflow_default_options': {\r\n        'tempLocation': GCS_TMP,\r\n        'stagingLocation': GCS_STAGING,\r\n    },\r\n    'location': 'europe-west3'\r\n}\r\n\r\nwith models.DAG(\r\n    \"example_gcp_dataflow_native_java\",\r\n    schedule_interval=None,  # Override to match your needs\r\n    start_date=days_ago(1),\r\n    tags=['example'],\r\n) as dag_native_java:\r\n    start_java_job = DataflowCreateJavaJobOperator(\r\n        task_id=\"start-java-job\",\r\n        jar=GCS_JAR,\r\n        job_name='{{task.task_id}}',\r\n        options={\r\n            'output': GCS_OUTPUT,\r\n        },\r\n        poll_sleep=10,\r\n        job_class='org.apache.beam.examples.WordCount',\r\n        check_if_running=CheckJobRunning.IgnoreJob,\r\n        location='europe-west3',\r\n    )\r\n\r\n    # [START howto_operator_bigquery_create_table]\r\n    create_table = BigQueryCreateEmptyTableOperator(\r\n        task_id=\"create_table\",\r\n        dataset_id=DATASET_NAME,\r\n        table_id=\"test_table\",\r\n        schema_fields=[\r\n            {\"name\": \"emp_name\", \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\r\n            {\"name\": \"salary\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\r\n        ],\r\n    )\r\n    # [END howto_operator_bigquery_create_table]\r\n```\r\nIn the above example, task `create_table` and `start-java-job` is executed in one location - `europe-west3`. \r\n\r\nDataflow also uses the word \"location\" in its API to denote this field.\r\n![Screenshot 2020-10-19 at 22 36 49](https://user-images.githubusercontent.com/12058428/96508938-9ec58200-125b-11eb-9547-75b27aec7e93.png)\r\n\r\nhttps://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.jobs/get\r\n\r\n",
        "createdAt" : "2020-10-19T20:39:27Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "ea15e585-5495-4a0b-92aa-c0125bb92c00",
        "parentId" : "d6481fae-30cf-41aa-8a37-8c480bab132b",
        "authorId" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "body" : "> In Airflow, you can define default arguments that will be all operators, but the parameter name must be consistent across all operators.\r\n\r\nMakes sense, thanks for the explanation.",
        "createdAt" : "2020-10-19T21:10:29Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "tags" : [
        ]
      }
    ],
    "commit" : "92d18b05df81205d9d36863dca57c4358b57ee53",
    "line" : 472,
    "diffHunk" : "@@ -1,1 +959,963 @@            <gcloud beta dataflow sql query>`__\n            command reference\n        :param location: The location of the Dataflow job (for example europe-west1)\n        :type location: str\n        :param project_id: The ID of the GCP project that owns the job."
  },
  {
    "id" : "331c0a0a-66d1-49c8-bc3b-d8ede0e1e41a",
    "prId" : 8553,
    "prUrl" : "https://github.com/apache/airflow/pull/8553#pullrequestreview-512880390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85d7ce84-0555-400c-866f-7beaccee34fa",
        "parentId" : null,
        "authorId" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "body" : "Nit: `parameters` itself is one of the arguments that can be passed here (see https://cloud.google.com/dataflow/docs/guides/sql/parameterized-queries). Maybe use \"arguments\" instead.",
        "createdAt" : "2020-05-05T19:21:31Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "tags" : [
        ]
      },
      {
        "id" : "ab5323f0-8f48-4e6f-8ed9-ed071b957f28",
        "parentId" : "85d7ce84-0555-400c-866f-7beaccee34fa",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "This is related to what @mik-laj said here: https://github.com/apache/airflow/pull/8553#discussion_r508048041\r\nI added parametrization to example dag so it would be nice hint for the users in case of doubts how to use it.",
        "createdAt" : "2020-10-20T08:47:31Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      },
      {
        "id" : "453da4c9-b2ae-4fde-a398-e67d1914e449",
        "parentId" : "85d7ce84-0555-400c-866f-7beaccee34fa",
        "authorId" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "body" : "Sounds good.",
        "createdAt" : "2020-10-20T15:45:51Z",
        "updatedAt" : "2020-11-04T10:40:45Z",
        "lastEditedBy" : "5496d688-c1dc-47bc-9a8f-dff3cf0ab5e0",
        "tags" : [
        ]
      }
    ],
    "commit" : "92d18b05df81205d9d36863dca57c4358b57ee53",
    "line" : 467,
    "diffHunk" : "@@ -1,1 +954,958 @@        :param query: The SQL query to execute.\n        :type query: str\n        :param options: Job parameters to be executed.\n            For more information, look at:\n            `https://cloud.google.com/sdk/gcloud/reference/beta/dataflow/sql/query"
  },
  {
    "id" : "7fdead7e-cbab-4e1a-82e4-8132d2633acf",
    "prId" : 11501,
    "prUrl" : "https://github.com/apache/airflow/pull/11501#pullrequestreview-514435149",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "445aff69-e702-45b5-aa27-e4a1295313ee",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "What other type of field do you envision here? The method signature uses ʻint`. Did you want to support `Optional[Int]` here?",
        "createdAt" : "2020-10-20T03:12:46Z",
        "updatedAt" : "2020-11-04T22:10:33Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "8d360349-214c-43f2-b82b-1330e904c46e",
        "parentId" : "445aff69-e702-45b5-aa27-e4a1295313ee",
        "authorId" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "body" : "Yes. I updated type annotations to `Optional[Int]`. Thank you for pointing this out.",
        "createdAt" : "2020-10-22T07:32:21Z",
        "updatedAt" : "2020-11-04T22:10:33Z",
        "lastEditedBy" : "684d7067-ead9-4707-b609-f796c2e1f8ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9a6865ecfa9acacc81974639e8534ce454b0260",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +370,374 @@                )\n            batch.execute()\n            if self._cancel_timeout and isinstance(self._cancel_timeout, int):\n                timeout_error_message = \"Canceling jobs failed due to timeout ({}s): {}\".format(\n                    self._cancel_timeout, \", \".join(job_ids)"
  }
]