[
  {
    "id" : "97f301b8-7290-47d9-8a5a-4811ca8bf688",
    "prId" : 9593,
    "prUrl" : "https://github.com/apache/airflow/pull/9593#pullrequestreview-459861493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74d6cfcd-7889-4290-953a-ba3bc1e3b2ef",
        "parentId" : null,
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "if cluster is in creating state should you block til it reaches running?",
        "createdAt" : "2020-07-10T00:01:47Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "7cf626fa-d763-491e-9dcf-afa9721b2559",
        "parentId" : "74d6cfcd-7889-4290-953a-ba3bc1e3b2ef",
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "If cluster already exists (I assume this is checked by cluster id / name) then you should assert that it matches the any configuration explicitly specified in this operator by the user (e.g. a cluster could exist with this ID but have different dataproc version / missing init actions / etc.) you would not want to consider this a successful run of this operator as it did not meet it's contract of creating a cluster with explicit XYZ config provided by the user.\r\n\r\nIMO this should result in a task failure as it is not clear what the operator should do in this scenario? delete the existing cluster? add a uuid suffix to avoid the name clash and create a new cluster?",
        "createdAt" : "2020-07-10T00:06:49Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "8ba9dda5-afdd-4364-a71f-3956b9aadbae",
        "parentId" : "74d6cfcd-7889-4290-953a-ba3bc1e3b2ef",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "@jaketf is there any bulletproof, simple way to compare cluster configuration? Comparing dicts doesn't sound like a way to go because created cluster includes more information than the user provided config",
        "createdAt" : "2020-07-27T09:25:18Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      },
      {
        "id" : "0f1adbfc-a79a-444b-8ca4-03aeeb50e90b",
        "parentId" : "74d6cfcd-7889-4290-953a-ba3bc1e3b2ef",
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "I think you'd just compare the keys of the dict that were specified by the user.\r\nThis might be easier said than done.",
        "createdAt" : "2020-07-29T23:17:10Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "14f318ec-060d-4a57-afb7-bd30b6e3e843",
        "parentId" : "74d6cfcd-7889-4290-953a-ba3bc1e3b2ef",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "Yeah. See my \"terraform\" comment above. I think we are pretty good with manual deletion of the cluster in case we want to change configuration, I don't think we should handle all potential complexity of computing difference between expected/actual cluster configuration.",
        "createdAt" : "2020-08-03T09:01:54Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "09d1ff8337d5443aee0e4c397369013a81bda130",
    "line" : 199,
    "diffHunk" : "@@ -1,1 +611,615 @@                raise\n            self.log.info(\"Cluster already exists.\")\n            cluster = self._get_cluster(hook)\n\n        # Check if cluster is not in ERROR state"
  },
  {
    "id" : "7afd2763-221f-4173-afa7-f2fdf8abc1cb",
    "prId" : 9593,
    "prUrl" : "https://github.com/apache/airflow/pull/9593#pullrequestreview-459861493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b943844-3159-4fd4-903c-943790c343ba",
        "parentId" : null,
        "authorId" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "body" : "should there be a similar configurable parameter like \"delete_on_configuration_mismatch\" that defaults to False?",
        "createdAt" : "2020-07-10T00:27:06Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "c6742e4c-543e-4eea-b495-c6ec28597226",
        "tags" : [
        ]
      },
      {
        "id" : "86931081-528c-4671-854a-54ad5e54d56d",
        "parentId" : "6b943844-3159-4fd4-903c-943790c343ba",
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "I think this case will be difficult to handle in all cases correctly. You will not always need to create a new cluster when the configuration is different eg. additional components installed do not affect the usability of the cluster.",
        "createdAt" : "2020-07-29T10:19:56Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "11b2a3ac-f660-4f57-87c1-22bf129202dc",
        "parentId" : "6b943844-3159-4fd4-903c-943790c343ba",
        "authorId" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "body" : "I think this is not really something that should be handled by the operator itself. I'd argue that if you really want to change configuration of cluster you can simply delete it manually and let it be re-created. I think working in a \"terraformy\" or \"kubectly\" \"apply\" fashion in this case should be left to terraform. I.e. if you really want to use this kind of approach, why not write a terraform script and run terraform.\r\n\r\nBTW. Offtop - but should not we think about adding a Terraform/Terragrunt operator to Airflow ? I'd say it might be a good idea to have such an operator with some pre-defined ways on how to get terraform/terragrunt scripts in and how to integrate with airflow's JINJA templating. ",
        "createdAt" : "2020-08-03T08:58:58Z",
        "updatedAt" : "2020-08-05T09:26:40Z",
        "lastEditedBy" : "e8563344-32ea-4c07-9731-a2fed8d2edf2",
        "tags" : [
        ]
      }
    ],
    "commit" : "09d1ff8337d5443aee0e4c397369013a81bda130",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +444,448 @@    :parm delete_on_error: If true the cluster will be deleted if created with ERROR state. Default\n        value is true.\n    :type delete_on_error: bool\n    :parm use_if_exists: If true use existing cluster\n    :type use_if_exists: bool"
  },
  {
    "id" : "98149ef4-57eb-47e9-bbd8-d7e6a4b214fd",
    "prId" : 10403,
    "prUrl" : "https://github.com/apache/airflow/pull/10403#pullrequestreview-470399490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2635f76-a10b-4b3b-9093-66555caa4e98",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Not related but simplifies things. Reference:\r\n>Optional. The Compute Engine machine type used for cluster instances.\r\n>A full URL, partial URI, or short name are valid. Examples:\r\n> - https://www.googleapis.com/compute/v1/projects/[projectId]/zones/us-east1-a/machineTypes/n1-standard-2\r\n> - projects/[projectId]/zones/us-east1-a/machineTypes/n1-standard-2\r\n> - n1-standard-2",
        "createdAt" : "2020-08-19T12:19:30Z",
        "updatedAt" : "2020-09-04T08:29:00Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "16aa9b3313d51203182b577f1d91b13594f2a00d",
    "line" : 128,
    "diffHunk" : "@@ -1,1 +296,300 @@            )\n            worker_type_uri = (\n                f\"projects/{self.project_id}/zones/{self.zone}/machineTypes/{self.worker_machine_type}\"\n            )\n        else:"
  },
  {
    "id" : "e906d237-18b8-4566-b9cc-791dd80e856e",
    "prId" : 10403,
    "prUrl" : "https://github.com/apache/airflow/pull/10403#pullrequestreview-478561027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71301107-bf87-4169-a0b6-1a93fb2a7564",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Should we add fallback for project ID from service account?",
        "createdAt" : "2020-08-31T11:20:35Z",
        "updatedAt" : "2020-09-04T08:29:01Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "f42628df-fea7-415c-8269-a1f0090c386f",
        "parentId" : "71301107-bf87-4169-a0b6-1a93fb2a7564",
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Added",
        "createdAt" : "2020-08-31T12:12:56Z",
        "updatedAt" : "2020-09-04T08:29:01Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "16aa9b3313d51203182b577f1d91b13594f2a00d",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +157,161 @@    def __init__(\n        self,\n        project_id: str,\n        num_workers: Optional[int] = None,\n        zone: Optional[str] = None,"
  },
  {
    "id" : "7b5c9ef2-9ad0-4395-afc4-a7b0093d8afa",
    "prId" : 10403,
    "prUrl" : "https://github.com/apache/airflow/pull/10403#pullrequestreview-481737899",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d94087f9-ac43-4fa7-9be9-cadd0e1d4fc6",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "This backward compatible with 1.10.X:\r\nhttps://github.com/apache/airflow/blob/827a717fecc675b4d58fa202be003dee8e423632/airflow/contrib/operators/dataproc_operator.py#L192-L193",
        "createdAt" : "2020-09-03T11:16:27Z",
        "updatedAt" : "2020-09-04T08:29:01Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "16aa9b3313d51203182b577f1d91b13594f2a00d",
    "line" : 280,
    "diffHunk" : "@@ -1,1 +466,470 @@        self,\n        *,\n        cluster_name: str,\n        region: str = 'global',\n        project_id: Optional[str] = None,"
  },
  {
    "id" : "c1ef1a11-d015-480f-a892-6b415f5e8e23",
    "prId" : 10403,
    "prUrl" : "https://github.com/apache/airflow/pull/10403#pullrequestreview-481738277",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f3907c3-9ff5-4612-95f8-70181b94536f",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "That should not be problem when migrating from 1.10.X becaue it should be in kwargs\r\nhttps://github.com/apache/airflow/blob/827a717fecc675b4d58fa202be003dee8e423632/airflow/contrib/operators/dataproc_operator.py#L192-L193",
        "createdAt" : "2020-09-03T11:17:01Z",
        "updatedAt" : "2020-09-04T08:29:01Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "16aa9b3313d51203182b577f1d91b13594f2a00d",
    "line" : 311,
    "diffHunk" : "@@ -1,1 +498,502 @@            if project_id is None:\n                raise AirflowException(\n                    \"project_id argument is required when building cluster from keywords parameters\"\n                )\n            kwargs[\"project_id\"] = project_id"
  },
  {
    "id" : "7e510a6e-963e-4a21-a4b7-6f195d2e646b",
    "prId" : 10772,
    "prUrl" : "https://github.com/apache/airflow/pull/10772#pullrequestreview-483358561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6fc9cd91-2b89-4008-83b3-c12f0f6f1836",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "We should update `region` description in docstring to avoid any confusion ",
        "createdAt" : "2020-09-07T08:32:13Z",
        "updatedAt" : "2020-09-07T21:19:06Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0f363d7ff6115411461bcd4d599ae1489588be4",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +467,471 @@        *,\n        cluster_name: str,\n        region: Optional[str] = None,\n        project_id: Optional[str] = None,\n        cluster_config: Optional[Dict] = None,"
  },
  {
    "id" : "6ea95383-b2a0-46e1-ad2a-efeeacdb64e8",
    "prId" : 10847,
    "prUrl" : "https://github.com/apache/airflow/pull/10847#pullrequestreview-485807169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58203415-104c-4d8c-b781-e350a6b2574a",
        "parentId" : null,
        "authorId" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "body" : "Can you add please this parameter to docstring so user can understand what it does?",
        "createdAt" : "2020-09-10T10:45:58Z",
        "updatedAt" : "2020-09-10T10:56:20Z",
        "lastEditedBy" : "0d4fd7c4-f8ab-4371-acfe-b9cca6decaf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "e369a61705060cfb3f271e478ff1f0e46636cd8d",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1811,1815 @@        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,\n        asynchronous: bool = False,\n        cancel_on_kill: bool = True,\n        **kwargs,\n    ) -> None:"
  },
  {
    "id" : "13381e07-8705-4b9e-848b-d24b6095a3cb",
    "prId" : 14981,
    "prUrl" : "https://github.com/apache/airflow/pull/14981#pullrequestreview-619849912",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69e39b7a-9e7f-4c0f-bce1-a6f7c9fc833c",
        "parentId" : null,
        "authorId" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "body" : "Hook should be initialized in execute method to avoid connection to metadata  server at dag loading. ",
        "createdAt" : "2021-03-24T14:26:14Z",
        "updatedAt" : "2021-03-25T14:25:42Z",
        "lastEditedBy" : "07638d17-cc8b-40a4-abdc-7b39759362ab",
        "tags" : [
        ]
      },
      {
        "id" : "e95254da-e4c4-432b-acfd-57ffc63ed552",
        "parentId" : "69e39b7a-9e7f-4c0f-bce1-a6f7c9fc833c",
        "authorId" : "50a23f60-50f7-4dc8-9e9f-213bf010d57f",
        "body" : "Thats a really good point, but we won't be able to get the project_id from the hook if the hook is not yet instantiated 🤔 We would also have to update the generate_job function in all of the operators which inherit from this one. \r\n\r\nMaybe that should be saved for a separate issue? let me know what you think.",
        "createdAt" : "2021-03-24T15:11:16Z",
        "updatedAt" : "2021-03-25T14:25:42Z",
        "lastEditedBy" : "50a23f60-50f7-4dc8-9e9f-213bf010d57f",
        "tags" : [
        ]
      }
    ],
    "commit" : "6ea3dab328029cfbaefa9de8e90b4126785c316c",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +948,952 @@        self.job_error_states = job_error_states if job_error_states is not None else {'ERROR'}\n        self.impersonation_chain = impersonation_chain\n        self.hook = DataprocHook(gcp_conn_id=gcp_conn_id, impersonation_chain=impersonation_chain)\n        self.project_id = self.hook.project_id if project_id is None else project_id\n        self.job_template = None"
  }
]