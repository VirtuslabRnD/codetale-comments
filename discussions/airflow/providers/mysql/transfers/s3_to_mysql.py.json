[
  {
    "id" : "b3ccb2b2-6da4-49d4-a1f6-c58773cc1eab",
    "prId" : 9320,
    "prUrl" : "https://github.com/apache/airflow/pull/9320#pullrequestreview-460108824",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "parentId" : null,
        "authorId" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "body" : "Can I ask what's the requirement S3 file format for this Operator? json? csv? parquet and etc.",
        "createdAt" : "2020-07-30T10:41:31Z",
        "updatedAt" : "2020-07-30T10:41:32Z",
        "lastEditedBy" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "tags" : [
        ]
      },
      {
        "id" : "69274117-e41f-412f-9a70-8fc0b49a1832",
        "parentId" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "It calls [bulk_load_custom](https://github.com/apache/airflow/blob/68d1714f296989b7aad1a04b75dc033e76afb747/airflow/providers/mysql/hooks/mysql.py#L217) which uses [LOAD DATA](https://dev.mysql.com/doc/refman/8.0/en/load-data.html)",
        "createdAt" : "2020-07-30T14:36:51Z",
        "updatedAt" : "2020-07-30T14:39:29Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "12940b98-c791-487c-af61-0000368a5985",
        "parentId" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "> The LOAD DATA statement reads rows from a text file into a table at a very high speed.\r\n\r\nYou can define sth like:\r\n```\r\n    [{FIELDS | COLUMNS}\r\n        [TERMINATED BY 'string']\r\n        [[OPTIONALLY] ENCLOSED BY 'char']\r\n        [ESCAPED BY 'char']\r\n    ]\r\n    [LINES\r\n        [STARTING BY 'string']\r\n        [TERMINATED BY 'string']\r\n    ]\r\n```\r\nfor csv files.",
        "createdAt" : "2020-07-30T14:43:15Z",
        "updatedAt" : "2020-07-30T14:43:15Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      },
      {
        "id" : "4fb239dc-cc13-4622-a559-f7a06a7e037a",
        "parentId" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "authorId" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "body" : "Thanks @feluelle, this helped a lot!",
        "createdAt" : "2020-07-31T00:55:31Z",
        "updatedAt" : "2020-07-31T00:55:32Z",
        "lastEditedBy" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "tags" : [
        ]
      },
      {
        "id" : "7a8bdf07-df4a-4920-b493-af1b7bbd9ca4",
        "parentId" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "authorId" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "body" : "One more question! Does this work with parquet files? After looking into the docs, I don't think it does. Right?",
        "createdAt" : "2020-08-03T06:13:07Z",
        "updatedAt" : "2020-08-03T06:13:08Z",
        "lastEditedBy" : "42583464-433a-4d73-91f4-cd6d6d3408f0",
        "tags" : [
        ]
      },
      {
        "id" : "3784e797-27b1-4d80-b21a-127b5a7a3509",
        "parentId" : "ff9d8c65-60f9-4337-a44f-79d6bc285bec",
        "authorId" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "body" : "No I don't think it works directly. You would have to convert parquet to csv and load csv to mysql.",
        "createdAt" : "2020-08-03T15:10:45Z",
        "updatedAt" : "2020-08-03T15:10:45Z",
        "lastEditedBy" : "e29ffafb-ac51-434b-b9e0-af262caae1ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "08cf97ec957d000c96618199046d226a5272c994",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +27,31 @@class S3ToMySqlOperator(BaseOperator):\n    \"\"\"\n    Loads a file from S3 into a MySQL table.\n\n    :param s3_source_key: The path to the file (S3 key) that will be loaded into MySQL."
  }
]